A geo or gio (/ɡjoʊ/ GYOH, from Old Norse gjá[1]) is an inlet, a gully or a narrow and deep cleft in the face of a cliff. Geos are common on the coastline of the Shetland and Orkney islands. They are created by the wave driven erosion of cliffs along faults and bedding planes in the rock. Geos may have sea caves at their heads. Such sea caves may collapse, extending the geo, or leaving depressions inland from the geo.[2]				
The Integrated Authority File (German: Gemeinsame Normdatei, also known as: Universal Authority File) or GND is an international authority file for the organisation of personal names, subject headings and corporate bodies from catalogues. It is used mainly for documentation in libraries and increasingly also by archives and museums. The GND is managed by the German National Library (German: Deutsche Nationalbibliothek; DNB) in cooperation with various regional library networks in German-speaking Europe and other partners. The GND falls under the Creative Commons Zero (CC0) license.[1]		The GND specification provides a hierarchy of high-level entities and sub-classes, useful in library classification, and an approach to unambiguous identification of single elements. It also comprises an ontology intended for knowledge representation in the semantic web, available in the RDF format.[2]		The Integrated Authority File became operational in April 2012 and integrates the content of the following authority files which have since been discontinued:		At the time of its introduction ("GND-Grundbestand" from 5 April 2012), the GND holds 9,493,860 files, including 2,650,000 personalized names.						There are seven main types of GND entities:[3]		
The wrack zone is part of the shore just above the mean high tide line where kelp is deposited on the sand. This area is identified by the piles of kelp and other debris (e.g. old pier pilings, driftwood), and is often located on a slight "shelf" above the moist sand that slopes down toward the water.				
Coordinates: 45°10′N 15°30′E﻿ / ﻿45.167°N 15.500°E﻿ / 45.167; 15.500		– in Europe  (green & dark grey) – in the European Union  (green)  –  [Legend]		Croatia (/kroʊˈeɪʃə/ ( listen) kroh-AY-shə; Croatian: Hrvatska [xř̩ʋaːtskaː]), officially the Republic of Croatia (Croatian: Republika Hrvatska,  listen (help·info)), is a country between Central and Southeast Europe, on the Adriatic Sea. Its capital city is Zagreb, which forms one of the country's primary subdivisions, along with its twenty counties. Croatia has an area of 56,594 square kilometres (21,851 square miles) and a population of 4.28 million, most of whom are Roman Catholics.		The Croats arrived in the area of present-day Croatia during the early part of the 7th century AD. They organised the state into two duchies by the 9th century. Tomislav became the first king by 925, elevating Croatia to the status of a kingdom. The Kingdom of Croatia retained its sovereignty for nearly two centuries, reaching its peak during the rule of Kings Petar Krešimir IV and Dmitar Zvonimir. Croatia entered a personal union with Hungary in 1102. In 1527, faced with Ottoman conquest, the Croatian Parliament elected Ferdinand I of the House of Habsburg to the Croatian throne. During the early 19th century, parts of the country were split into the French Illyrian Provinces, and Austria-Hungary occupied its Bosnia and Herzegovina side–a dispute settled by the 1878 Treaty of Berlin. In 1918, after World War I, Croatia was included in the unrecognized State of Slovenes, Croats and Serbs which seceded from Austria-Hungary and merged into the Kingdom of Yugoslavia. A fascist Croatian puppet state backed by Fascist Italy and Nazi Germany existed in World War II. After the war, Croatia became a founding member and a federal constituent of the Socialist Federal Republic of Yugoslavia, a constitutionally socialist state. On 25 June 1991, Croatia declared independence, which came wholly into effect on 8 October of the same year. The Croatian War of Independence was fought successfully for four years following the declaration.		Croatia is a republic governed under a parliamentary system. The International Monetary Fund classified Croatia as an emerging and developing economy, and the World Bank identified it as a high-income economy. Croatia is a member of the European Union (EU), United Nations (UN), the Council of Europe, NATO, the World Trade Organization (WTO) and a founding member of the Union for the Mediterranean. As an active participant in the UN peacekeeping forces, Croatia has contributed troops to the NATO-led mission in Afghanistan and took a non-permanent seat on the UN Security Council for the 2008–2009 term.		The service sector dominates Croatia's economy, followed by the industrial sector and agriculture. International Tourism is a significant source of revenue during the summer, with Croatia ranked the 18th most popular tourist destination in the world. The state controls a part of the economy, with substantial government expenditure. The European Union is Croatia's most important trading partner. Since 2000, the Croatian government has constantly invested in infrastructure, especially transport routes and facilities along the Pan-European corridors. Internal sources produce a significant portion of energy in Croatia; the rest is imported. Croatia provides a universal health care system and free primary and secondary education, while supporting culture through numerous public institutions and corporate investments in media and publishing.						The name of Croatia derives from Medieval Latin Croātia – compare DUX CRUATORVM [sic] ("Duke of the Croats") attested in the Branimir inscription – itself a derivation of North-West Slavic *Xrovat-, by liquid metathesis from proposed Common Slavic period *Xorvat, from proposed Proto-Slavic *Xarwāt- (*Xъrvatъ) or *Xŭrvatŭ (*xъrvatъ).[7]		The origin of the name is uncertain, but is thought to be a Gothic or Indo-Aryan term assigned to a Slavic tribe.[8] The oldest preserved record of the Croatian ethnonym *xъrvatъ is of variable stem, attested in the Baška tablet in style zvъnъmirъ kralъ xrъvatъskъ ("Zvonimir, Croatian king").[9]		The first attestation of the Latin term is attributed to a charter of Duke Trpimir from the year 852. The original is lost, and just a 1568 copy is preserved—leading to doubts over the authenticity of the claim.[10] The oldest preserved stone inscription is the 9th-century Branimir Inscription (found near Benkovac), where Duke Branimir is styled as Dux Cruatorvm. The inscription is not believed to be dated accurately, but is likely to be from during the period of 879–892, during Branimir's rule.[11]		The area known as Croatia today was inhabited throughout the prehistoric period. Fossils of Neanderthals dating to the middle Palaeolithic period have been unearthed in northern Croatia, with the most famous and the best presented site in Krapina.[12] Remnants of several Neolithic and Chalcolithic cultures were found in all regions of the country.[13] The largest proportion of the sites is in the river valleys of northern Croatia, and the most significant cultures whose presence was discovered include Starčevo, Vučedol and Baden cultures.[14][15] The Iron Age left traces of the early Illyrian Hallstatt culture and the Celtic La Tène culture.[16]		Much later, the region was settled by Liburnians and Illyrians, while the first Greek colonies were established on the islands of Korčula, Hvar[17] and Vis.[18] In 9 AD the territory of today's Croatia became part of the Roman Empire. Emperor Diocletian built a large palace in Split when he retired in AD 305.[19]		During the 5th century, one of the last Emperors of the Western Roman Empire, Julius Nepos, ruled his small empire from the palace.[20] The period ends with Avar and Croat invasions in the first half of the 7th century and destruction of almost all Roman towns. Roman survivors retreated to more favourable sites on the coast, islands and mountains. The city of Dubrovnik was founded by such survivors from Epidaurum.[21]		The ethnogenesis of Croats is uncertain and there are several competing theories, Slavic and Iranian being the most frequently put forward. The most widely accepted of these, the Slavic theory, proposes migration of White Croats from the territory of White Croatia during the Migration Period. Conversely, the Iranian theory proposes Iranian origin, based on Tanais Tablets containing Greek inscription of given names Χορούαθ[ος], Χοροάθος and Χορόαθος (Khoroúathos, Khoroáthos, and Khoróathos) and their interpretation as anthroponyms of Croatian people.[22]		According to the work De Administrando Imperio written by the 10th-century Byzantine Emperor Constantine VII, the Croats had arrived in what is today Croatia in the early 7th century; however, that claim is disputed and competing hypotheses date the event between the 6th and the 9th centuries.[23] Eventually two dukedoms were formed—Duchy of Pannonia and Duchy of Croatia, ruled by Liudewit and Borna, as attested by chronicles of Einhard starting in 818. The record represents the first document of Croatian realms, vassal states of Francia at the time.[24]		The Frankish overlordship ended during the reign of Mislav two decades later.[25] According to the Constantine VII Christianization of Croats began in the 7th century, but the claim is disputed and generally Christianization is associated with the 9th century.[26] The first native Croatian ruler recognised by the Pope was Duke Branimir, who received papal recognition from Pope John VIII on 7 June 879.[11]		Tomislav was the first ruler of Croatia who was styled a king in a letter from the Pope John X, dating kingdom of Croatia to year 925. Tomislav defeated Hungarian and Bulgarian invasions, spreading the influence of Croatian kings.[27] The medieval Croatian kingdom reached its peak in the 11th century during the reigns of Petar Krešimir IV (1058–1074) and Dmitar Zvonimir (1075–1089).[28] When Stjepan II died in 1091 ending the Trpimirović dynasty, Ladislaus I of Hungary claimed the Croatian crown in name of his sister Helena, wife of King Dmitar Zvonimir. Opposition to the claim led to a war and personal union of Croatia and Hungary in 1102, ruled by Coloman.[29]		For the next four centuries, the Kingdom of Croatia was ruled by the Sabor (parliament) and a Ban (viceroy) appointed by the king.[30] The period saw increasing threat of Ottoman conquest and struggle against the Republic of Venice for control of coastal areas. The Venetians gained control over most of Dalmatia by 1428, with exception of the city-state of Dubrovnik which became independent. Ottoman conquests led to the 1493 Battle of Krbava field and 1526 Battle of Mohács, both ending in decisive Ottoman victories. King Louis II died at Mohács, and in 1527, the Croatian Parliament met in Cetin and chose Ferdinand I of the House of Habsburg as new ruler of Croatia, under the condition that he provide protection to Croatia against the Ottoman Empire while respecting its political rights.[30][31] This period saw the rise of influential nobility such as the Frankopan and Zrinski families to prominence and ultimately numerous Bans from the two families.[32]		Following the decisive Ottoman victories, Croatia was split into civilian and military territories, with the partition formed in 1538. The military territories would become known as the Croatian Military Frontier and were under direct Imperial control. Ottoman advances in the Croatian territory continued until the 1593 Battle of Sisak, the first decisive Ottoman defeat, and stabilisation of borders.[31]		During the Great Turkish War (1683–1698), Slavonia was regained but western Bosnia, which had been part of Croatia before the Ottoman conquest, remained outside Croatian control.[31] The present-day border between the two countries is a remnant of this outcome. Dalmatia, the southern part of the border, was similarly defined by the Fifth and the Seventh Ottoman–Venetian Wars.[33]		The Ottoman wars instigated great demographic changes. Croats migrated towards Austria and the present-day Burgenland Croats are direct descendants of these settlers.[34] To replace the fleeing population, the Habsburgs encouraged the Christian populations of Bosnia and Serbia to provide military service in the Croatian Military Frontier. Serb migration into this region peaked during the Great Serb Migrations of 1690 and 1737–39.[35]		The Croatian Parliament supported Emperor Charles's Pragmatic Sanction and signed their own Pragmatic Sanction in 1712.[36] Subsequently, the emperor pledged to respect all privileges and political rights of Kingdom of Croatia and the empress Maria Theresa made significant contributions to Croatian matters.		Between 1797 and 1809 the First French Empire gradually occupied the entire eastern Adriatic coastline and a substantial part of its hinterland, ending the Venetian and the Ragusan republics, establishing the Illyrian Provinces.[31] In response the Royal Navy started the blockade of the Adriatic Sea leading to the Battle of Vis in 1811.[37] The Illyrian Provinces were captured by the Austrians in 1813, and absorbed by the Austrian Empire following the Congress of Vienna in 1815. This led to formation of the Kingdom of Dalmatia and restoration of the Croatian Littoral to the Kingdom of Croatia, now both under the same crown.[38] The 1830s and 1840s saw romantic nationalism inspire the Croatian National Revival, a political and cultural campaign advocating the unity of all South Slavs in the empire. Its primary focus was the establishment of a standard language as a counterweight to Hungarian, along with the promotion of Croatian literature and culture.[39] During the Hungarian Revolution of 1848 Croatia sided with the Austrians, Ban Josip Jelačić helping defeat the Hungarian forces in 1849, and ushering a period of Germanization policy.[40]		By the 1860s, failure of the policy became apparent, leading to the Austro-Hungarian Compromise of 1867 and creation of a personal union between the crowns of the Austrian Empire and the Kingdom of Hungary. The treaty left the issue of Croatia's status to Hungary, and the status was resolved by the Croatian–Hungarian Settlement of 1868, when kingdoms of Croatia and Slavonia were united.[41] The Kingdom of Dalmatia remained under de facto Austrian control, while Rijeka retained the status of Corpus separatum introduced in 1779.[29]		After Austria-Hungary occupied Bosnia and Herzegovina following the 1878 Treaty of Berlin, the Croatian Military Frontier was abolished and the territory returned to Croatia in 1881,[31] pursuant to provisions of the Croatian-Hungarian settlement.[42][43] Renewed efforts to reform Austria-Hungary, entailing federalisation with Croatia as a federal unit, were stopped by advent of World War I.[44]		On 29 October 1918 the Croatian Parliament (Sabor) declared independence and decided to join the newly formed State of Slovenes, Croats and Serbs,[30] which in turn entered into union with the Kingdom of Serbia on 4 December 1918 to form the Kingdom of Serbs, Croats, and Slovenes.[45] The Croatian Parliament never ratified a decision to unite with Serbia and Montenegro.[30] The 1921 constitution defining the country as a unitary state and abolition of Croatian Parliament and historical administrative divisions effectively ended Croatian autonomy. The new constitution was opposed by the most widely supported national political party—the Croatian Peasant Party (HSS) led by Stjepan Radić.[46]		The political situation deteriorated further as Radić was assassinated in the National Assembly in 1928, leading to the dictatorship of King Alexander in January 1929.[47] The dictatorship formally ended in 1931 when the king imposed a more unitarian constitution, and changed the name of the country to Yugoslavia.[48] The HSS, now led by Vladko Maček, continued to advocate federalisation of Yugoslavia, resulting in the Cvetković–Maček Agreement of August 1939 and the autonomous Banovina of Croatia. The Yugoslav government retained control of defence, internal security, foreign affairs, trade, and transport while other matters were left to the Croatian Sabor and a crown-appointed Ban.[49]		In April 1941, Yugoslavia was occupied by Germany and Italy. Following the invasion the territory, parts of Croatia, Bosnia and Herzegovina, and the region of Syrmia were incorporated into the Independent State of Croatia (NDH), a Nazi-backed puppet state. Parts of Dalmatia were annexed by Italy and the northern Croatian regions of Baranja and Međimurje were annexed by Hungary.[50] The NDH regime was led by Ante Pavelić and ultranationalist Ustaše. The regime introduced anti-semitic laws and conducted a campaign of ethnic cleansing and genocide against Serb and Roma inhabitants of the NDH, exemplified by the Jasenovac and Stara Gradiška concentration camps.[51]		It is estimated that out of 39,000 Jews in the country only 9,000 survived; the rest were either killed or deported to Germany, both by the local authorities and the German Army itself.[52] Croatian and Serbian sources disagree on the exact figures.[53]		Furthermore, a significant number of Serbs were killed by the Ustaše on the territory of the NDH during the war. According to Midlarsky, the number of Serbs killed by the regime was at least half a million,[54] but the figure is contradicted by Bogoljub Kočović and Vladimir Žerjavić. Kočović estimated total number of Serbs killed throughout Yugoslav territory in various circumstances at 487,000, while Žerjavić put the figure at 530,000. Žerjavić indicated that 320,000 Serbs were killed in the NDH, including 82,000 killed among the Yugoslav Partisans, 23,000 killed as Axis collaborators, 25,000 victims of typhoid epidemic, 45,000 killed by Germans and 15,000 by Italians. Kočović's and Žerjavić's total Yugoslav losses are in agreement with estimates made by Mayers and Campbell of the United States Census Bureau.[55] The number of Croats killed in the NDH is estimated to be approximately 200,000, either by the Croatian fascist regime, as members of the armed resistance, or as Axis collaborators.[53][56] Several thousand of these were killed by the Chetniks; most Croatian historians place the number of Croats killed by the Chetniks on the territory of modern-day Croatia at between 3,000 and 3,500. Croatian estimates for the number of Croats killed by Chetniks in the whole of Yugoslavia range from 18,000 to 32,000 (both combatants and civilians).[57]		A resistance movement soon emerged. On 22 June 1941,[58] the 1st Sisak Partisan Detachment was formed near Sisak, as the first military unit formed by a resistance movement in occupied Europe.[59] This sparked the beginning of the Yugoslav Partisan movement, a communist multi-ethnic anti-fascist resistance group led by Josip Broz Tito.[60] The movement grew rapidly and at the Tehran Conference in December 1943 the Partisans gained recognition from the Allies.[61]		With Allied support in logistics, equipment, training and air power, and with the assistance of Soviet troops taking part in the 1944 Belgrade Offensive, the Partisans gained control of Yugoslavia and the border regions of Italy and Austria by May 1945, during which thousands of members of the Ustaše, as well as Croat refugees, were killed by the Yugoslav Partisans.[62]		The political aspirations of the Partisan movement were reflected in the State Anti-fascist Council for the National Liberation of Croatia, which developed in 1943 as the bearer of Croatian statehood and later transformed into the Parliament of Croatia in 1945, and AVNOJ—its counterpart at the Yugoslav level.[63][64]		After World War II, Croatia became a single-party socialist federal unit of the SFR Yugoslavia, ruled by the Communists, but enjoying a degree of autonomy within the federation. In 1967, Croatian authors and linguists published a Declaration on the Status and Name of the Croatian Standard Language demanding greater autonomy for Croatian language.[65] The declaration contributed to a national movement seeking greater civil rights and decentralization of the Yugoslav economy, culminating in the Croatian Spring of 1971, suppressed by Yugoslav leadership.[66] Still, the 1974 Yugoslav Constitution gave increased autonomy to federal units, basically fulfilling a goal of the Croatian Spring, and providing a legal basis for independence of the federative constituents.[67]		Following the death of Yugoslav president Josip Broz Tito in 1980, the political situation in Yugoslavia deteriorated, with national tension fanned by the 1986 Serbian SANU Memorandum and the 1989 coups in Vojvodina, Kosovo and Montenegro.[68][69] In January 1990, the Communist Party fragmented along national lines, with the Croatian faction demanding a looser federation.[70] In the same year, the first multi-party elections were held in Croatia, with Franjo Tuđman's win raising nationalist tensions further.[71] Some of Serbs in Croatia left Sabor and declared the autonomy of areas that would soon become the unrecognised Republic of Serbian Krajina, intent on achieving independence from Croatia.[72][73]		As tensions rose, Croatia declared independence on 25 June 1991; however, the full implementation of declaration only came into effect on 8 October 1991.[74][75] In the meantime, tensions escalated into overt war when the Yugoslav People's Army (JNA) and various Serb paramilitary groups attacked Croatia.[76] By the end of 1991, a high-intensity conflict fought along a wide front reduced Croatia to control of only about two-thirds of its territory.[77][78] The various Serb paramilitary groups then began pursuing a campaign of killing, terror and expulsion against the non-Serb population in the rebel territories, killing hundreds of Croat civilians and forcing a further 170,000 from their homes.[79]		On 15 January 1992, Croatia gained diplomatic recognition by the European Economic Community members, and subsequently the United Nations.[80][81] The war effectively ended in August 1995 with a decisive victory by Croatia.[82] This was accompanied by the exodus of about 200,000 Serbs from the rebel territories, whose lands were subsequently settled by Croat refugees from Bosnia and Herzegovina.[83] The remaining occupied areas were restored to Croatia pursuant to the Erdut Agreement of November 1995, with the process concluded in January 1998.[84] Croatia became a World Trade Organization (WTO) member on 30 November 2000. The country signed a Stabilization and Association Agreement (SAA) with the European Union in October 2001. Croatia became a member of NATO on 1 April 2009, and joined the European Union on 1 July 2013.		Croatia is located in Central and Southeast Europe, bordering Hungary to the northeast, Serbia to the east, Bosnia and Herzegovina to the southeast, Montenegro to the southeast, the Adriatic Sea to the southwest and Slovenia to the northwest. It lies mostly between latitudes 42° and 47° N and longitudes 13° and 20° E. Part of the territory in the extreme south surrounding Dubrovnik is a practical exclave connected to the rest of the mainland by territorial waters, but separated on land by a short coastline strip belonging to Bosnia and Herzegovina around Neum.[85]		The territory covers 56,594 square kilometres (21,851 square miles), consisting of 56,414 square kilometres (21,782 square miles) of land and 128 square kilometres (49 square miles) of water. It is the 127th largest country in the world.[86] Elevation ranges from the mountains of the Dinaric Alps with the highest point of the Dinara peak at 1,831 metres (6,007 feet) near the border with Bosnia and Herzegovina in the south[86] to the shore of the Adriatic Sea which makes up its entire southwest border. Insular Croatia consists of over a thousand islands and islets varying in size, 48 of which are permanently inhabited. The largest islands are Cres and Krk,[86] each of them having an area of around 405 square kilometres (156 square miles).		The hilly northern parts of Hrvatsko Zagorje and the flat plains of Slavonia in the east (which is part of the Pannonian Basin) are traversed by major rivers such as Sava, Drava, Kupa and Danube. The Danube, Europe's second longest river, runs through the city of Vukovar in the extreme east and forms part of the border with Serbia. The central and southern regions near the Adriatic coastline and islands consist of low mountains and forested highlands. Natural resources found in the country in quantities significant enough for production include oil, coal, bauxite, low-grade iron ore, calcium, gypsum, natural asphalt, silica, mica, clays, salt and hydropower.[86]		Karst topography makes up about half of Croatia and is especially prominent in the Dinaric Alps.[87] There are a number of deep caves in Croatia, 49 of which are deeper than 250 m (820.21 ft), 14 of them deeper than 500 m (1,640.42 ft) and three deeper than 1,000 m (3,280.84 ft). Croatia's most famous lakes are the Plitvice lakes, a system of 16 lakes with waterfalls connecting them over dolomite and limestone cascades. The lakes are renowned for their distinctive colours, ranging from turquoise to mint green, grey or blue.[88]		Most of Croatia has a moderately warm and rainy continental climate as defined by the Köppen climate classification. Mean monthly temperature ranges between −3 °C (27 °F) (in January) and 18 °C (64 °F) (in July). The coldest parts of the country are Lika and Gorski Kotar where snowy forested climate is found at elevations above 1,200 metres (3,900 feet). The warmest areas of Croatia are at the Adriatic coast and especially in its immediate hinterland characterised by the Mediterranean climate, as the temperature highs are moderated by the sea. Consequently, temperature peaks are more pronounced in the continental areas—the lowest temperature of −35.5 °C (−31.9 °F) was recorded on 3 February 1919 in Čakovec, and the highest temperature of 42.4 °C (108.3 °F) was recorded on 5 July 1950 in Karlovac.[89]		Mean annual precipitation ranges between 600 millimetres (24 inches) and 3,500 millimetres (140 inches) depending on geographic region and prevailing climate type. The least precipitation is recorded in the outer islands (Vis, Lastovo, Biševo, Svetac) and in the eastern parts of Slavonia; however, in the latter case, it occurs mostly during the growing season. The maximum precipitation levels are observed on the Dinara mountain range and in Gorski kotar.[89]		Prevailing winds in the interior are light to moderate northeast or southwest, and in the coastal area prevailing winds are determined by local area features. Higher wind velocities are more often recorded in cooler months along the coast, generally as bura or less frequently as sirocco. The sunniest parts of the country are the outer islands, Hvar and Korčula, where more than 2700 hours of sunshine are recorded per year, followed by the middle and southern Adriatic Sea area in general and northern Adriatic coast, all with more than 2000 hours of sunshine per year.[90]		Croatia can be subdivided between a number of ecoregions because of its climate and geomorphology. The country is consequently one of the richest in Europe in terms of biodiversity. There are four types of biogeographical regions in Croatia—Mediterranean along the coast and in its immediate hinterland, Alpine in most of Lika and Gorski Kotar, Pannonian along Drava and Danube, and continental in the remaining areas. One of the most significant are karst habitats which include submerged karst, such as Zrmanja and Krka canyons and tufa barriers, as well as underground habitats.		The karst geology harbours approximately 7,000 caves and pits, some of which are habitat of the only known aquatic cave vertebrate—the olm. Forests are also significantly present in the country, as they cover 2,490,000 hectares (6,200,000 acres) representing 44% of Croatian land surface. Other habitat types include wetlands, grasslands, bogs, fens, scrub habitats, coastal and marine habitats.[91] In terms of phytogeography, Croatia is a part of the Boreal Kingdom and is a part of Illyrian and Central European provinces of the Circumboreal Region and the Adriatic province of the Mediterranean Region. The World Wide Fund for Nature divides Croatia between three ecoregions—Pannonian mixed forests, Dinaric Mountains mixed forests and Illyrian deciduous forests.[92]		There are 37,000 known species in Croatia, but their actual number is estimated to be between 50,000 and 100,000.[91] The claim is supported by nearly 400 new taxa of invertebrates discovered in Croatia in the first half of the 2000s (decade) alone.[91] There are more than a thousand endemic species, especially in Velebit and Biokovo mountains, Adriatic islands and karst rivers. Legislation protects 1,131 species.[91] The most serious threat to species is loss and degradation of habitats. A further problem is presented by invasive alien species, especially Caulerpa taxifolia algae.		The invasive algae are regularly monitored and removed to protect the benthic habitat. Indigenous sorts of cultivated plants and breeds of domesticated animals are also numerous. Those include five breeds of horses, five breeds of cattle, eight breeds of sheep, two breeds of pigs and a poultry breed. Even the indigenous breeds include nine endangered or critically endangered ones.[91] There are 444 protected areas of Croatia, encompassing 9% of the country. Those include eight national parks, two strict reserves, and ten nature parks. The most famous protected area and the oldest national park in Croatia is the Plitvice Lakes National Park, a UNESCO World Heritage Site. Velebit Nature Park is a part of the UNESCO Man and the Biosphere Programme. The strict and special reserves, as well as the national and nature parks, are managed and protected by the central government, while other protected areas are managed by counties. In 2005, the National Ecological Network was set up, as the first step in preparation of the EU accession and joining of the Natura 2000 network.[91]		The Republic of Croatia is a unitary state using a parliamentary system of governance. With the collapse of the ruling communist party in SFR Yugoslavia, Croatia organized its first multi-party elections and adopted its present constitution in 1990.[93] It declared independence on 8 October 1991 which led to the break-up of Yugoslavia and countries international recognition by the United Nations in 1992.[75][81] Under its 1990 constitution, Croatia operated a semi-presidential system until 2000 when it switched to a parliamentary system.[94] Government powers in Croatia are divided into legislative, executive and judiciary powers.[95]		The President of the Republic (Croatian: Predsjednik Republike) is the head of state, directly elected to a five-year term and is limited by the Constitution to a maximum of two terms. In addition to being the commander in chief of the armed forces, the president has the procedural duty of appointing the prime minister with the consent of the parliament, and has some influence on foreign policy.[95] The most recent presidential elections were held on 11 January 2015, when Kolinda Grabar-Kitarović won. She took the oath of office on 15 February 2015.[96] The government is headed by the Prime Minister, who has four deputy prime ministers and 16 ministers in charge of particular sectors of activity.[97] As the executive branch, it is responsible for proposing legislation and a budget, executing the laws, and guiding the foreign and internal policies of the republic. The government is seated at Banski dvori in Zagreb.[95] Since 19 October 2016, Croatian Prime Minister has been Andrej Plenković.		The parliament (Sabor) is a unicameral legislative body. A second chamber, the House of Counties, set up in 1993 pursuant to the 1990 Constitution, was abolished in 2001. The number of Sabor members can vary from 100 to 160; they are all elected by popular vote to serve four-year terms. The sessions of the Sabor take place from 15 January to 15 July, and from 15 September to 15 December.[98] The two largest political parties in Croatia are the Croatian Democratic Union and the Social Democratic Party of Croatia.[99]		Croatia has a civil law legal system in which law arises primarily from written statutes, with judges serving merely as implementers, and not creators of law. Its development was largely influenced by German and Austrian legal systems. Croatian law is divided into two principal areas – private and public law. By the time EU accession negotiations were completed on 30 June 2010, Croatian legislation was fully harmonised with the Community acquis.[100] The main law in the county is the Constitution adopted on December 22, 1990.		The main national courts are the Constitutional Court, which oversees violations of the Constitution, and the Supreme Court, which is the highest court of appeal. In addition, there are also County, Municipal, Misdemeanor, Commercial, and Administrative courts.[101] Cases falling within judicial jurisdiction are in the first instance decided by a single professional judge, while appeals are deliberated in mixed tribunals of professional judges. Lay magistrates also participate in trials.[102] State's Attorney Office is the judicial body constituted of public prosecutors that is empowered to instigate prosecution of perpetrators of offences.		Law enforcement agencies are organised under the authority of the Ministry of the Interior which consist primarily of the national police force. Croatia's security service is the Security and Intelligence Agency (SOA).		Croatia was first subdivided into counties in the Middle Ages.[103] The divisions changed over time to reflect losses of territory to Ottoman conquest and subsequent liberation of the same territory, changes of political status of Dalmatia, Dubrovnik and Istria. Traditional division of the country into counties was abolished in the 1920s, when the Kingdom of Serbs, Croats and Slovenes and subsequent Kingdom of Yugoslavia introduced oblasts and banovinas respectively.[104]		Communist-ruled Croatia, as a constituent part of post-World War II Yugoslavia, abolished earlier divisions and introduced municipalities, subdividing Croatia into approximately one hundred municipalities. Counties were reintroduced in 1992 legislation, significantly altered in terms of territory relative to the pre-1920s subdivisions: In 1918, the Transleithanian part of Croatia was divided into eight counties with their seats in Bjelovar, Gospić, Ogulin, Požega, Vukovar, Varaždin, Osijek and Zagreb, and the 1992 legislation established 14 counties in the same territory.[105][106]		Since the counties were re-established in 1992, Croatia is divided into 20 counties and the capital city of Zagreb, the latter having the authority and legal status of a county and a city at the same time. Borders of the counties changed in some instances since, with the latest revision taking place in 2006. The counties subdivide into 127 cities and 429 municipalities.[107] Nomenclature of Territorial Units for Statistics (NUTS) division of Croatia is performed in several tiers. NUTS 1 level places the entire country in a single unit, while there are three NUTS 2 regions. Those are Northwest Croatia, Central and Eastern (Pannonian) Croatia and Adriatic Croatia. The latter encompasses all the counties along the Adriatic coast. The Northwest Croatia includes the city of Zagreb, Zagreb, Krapina-Zagorje, Varaždin, Koprivnica-Križevci and Međimurje counties, and the Central and Eastern (Pannonian) Croatia includes the remaining areas—Bjelovar-Bilogora, Virovitica-Podravina, Požega-Slavonia, Brod-Posavina, Osijek-Baranja, Vukovar-Syrmia, Karlovac and Sisak-Moslavina counties. Individual counties and the city of Zagreb also represent NUTS 3 level subdivision units in Croatia. The NUTS Local administrative unit divisions are two-tiered. LAU 1 divisions match the counties and the city of Zagreb in effect making those the same as NUTS 3 units, while LAU 2 subdivisions correspond to the cities and municipalities of Croatia.[108]		Croatia has established diplomatic relations with 181 countries.[109] As of 2009[update], Croatia maintains a network of 51 embassies, 24 consulates and eight permanent diplomatic missions abroad. Furthermore, there are 52 foreign embassies and 69 consulates in the Republic of Croatia in addition to offices of international organisations such as the European Bank for Reconstruction and Development, International Organization for Migration, OSCE, World Bank, World Health Organization (WHO), International Criminal Tribunal for the former Yugoslavia (ICTY), United Nations Development Programme, United Nations High Commissioner for Refugees and UNICEF.[110] In 2009, the Croatian Ministry of Foreign Affairs and European Integration employed 1,381 personnel and expended 648.2 million kuna (€86.4 million).[111] Stated aims of Croatian foreign policy include enhancing relations with neighbouring countries, developing international co-operation and promotion of the Croatian economy and Croatia itself.[112]		Since 2003, Croatian foreign policy has focused on achieving the strategic goal of becoming a member state of the European Union (EU).[113][114] In December 2011, Croatia completed the EU accession negotiations and signed an EU accession treaty on 9 December 2011.[115][116] Croatia joined the European Union on 1 July 2013 marking the end of a process started in 2001 by signing of the Stabilisation and Association Agreement and Croatian application for the EU membership in 2003.[117] A recurring obstacle to the negotiations was Croatia's ICTY co-operation record and Slovenian blocking of the negotiations because of Croatia–Slovenia border disputes.[118][119] The latter was resolved through an Arbitration Agreement of 4 November 2009, approved by national parliaments and a referendum in Slovenia.[120]		Another strategic Croatian foreign policy goal for the 2000s was NATO membership.[113][114] Croatia was included in the Partnership for Peace in 2000, invited to NATO membership in 2008 and formally joined the alliance on 1 April 2009.[121][122] Croatia became a member of the United Nations Security Council for the 2008–2009 term, assuming presidency in December 2008.[123] The country is preparing to join the Schengen Area.[124]		The Croatian Armed Forces (CAF) consist of the Army, Navy and Air Force branches in addition to the Education and Training Command and Support Command. The CAF is headed by the General Staff, which reports to the Defence Minister, who in turn reports to the President of Croatia. According to the constitution, the President is commander-in-chief of the armed forces and in case of immediate threat during wartime he issues orders directly to the General Staff.[125]		Following the 1991–95 war defence spending and CAF size have been in constant decline. As of 2005[update] military spending was an estimated 2.39% of the country's GDP, which placed Croatia 64th in a ranking of all countries.[86] Since 2005 the budget was kept below 2% of GDP, down from the record high of 11.1% in 1994.[126] Traditionally relying on a large number of conscripts, CAF also went through a period of reforms focused on downsizing, restructuring and professionalisation in the years prior to Croatia's accession to NATO in April 2009. According to a presidential decree issued in 2006 the CAF is set to employ 18,100 active duty military personnel, 3,000 civilians and 2,000 voluntary conscripts between the ages of 18 and 30 in peacetime.[125]		Compulsory conscription was abolished in January 2008.[86] Until 2008 military service was compulsory for men at age 18 and conscripts served six-month tours of duty, reduced in 2001 from the earlier scheme of nine-month conscription tours. Conscientious objectors could instead opt for an eight-month civilian service.[127] As of April 2011[update] the Croatian military had 120 members stationed in foreign countries as part of United Nations-led international peacekeeping forces, including 95 serving as part of the UNDOF in the Golan Heights.[128] As of 2011[update] an additional 350 troops serve as part of the NATO-led ISAF force in Afghanistan and another 20 with the KFOR in Kosovo.[129][130]		Croatia also has a significant military industry sector which exported around US$120 million worth of military equipment and armament in 2010.[131] Croatian-made weapons and vehicles used by CAF include the standard sidearm HS2000 manufactured by HS Produkt and the M-84D battle tank designed by the Đuro Đaković factory. Uniforms and helmets worn by CAF soldiers are also locally produced and successfully marketed to other countries.[131]		Croatia has an upper-middle income economy. [134] International Monetary Fund data projects that Croatian nominal GDP stands at $52 billion, or $12,405 per capita for year 2017, while purchasing power parity GDP stands at $97 billion, or $23,171 per capita.[4] According to Eurostat data, Croatian PPS GDP per capita stood at 61% of the EU average in 2012.[135]		Real GDP growth in 2007 was 6.0 per cent.[136] The average net salary of a Croatian worker in January 2017 was 5,895 HRK per month, and the average gross salary was 7,911 HRK per month.[137] As of February 2017, registered unemployment rate in Croatia was 15.3%.[138]		In 2010, economic output was dominated by the service sector which accounted for 66% of GDP, followed by the industrial sector with 27.2% and agriculture accounting for 6.8% of GDP.[139] According to 2004 data, 2.7% of the workforce were employed in agriculture, 32.8% by industry and 64.5% in services.[86][140] The industrial sector is dominated by shipbuilding, food processing, pharmaceuticals, information technology, biochemical and timber industry. In 2010, Croatian exports were valued at 64.9 billion kuna (€8.65 billion) with 110.3 billion kuna (€14.7 billion) worth of imports. The largest trading partner is rest of the European Union.[141] More than half of Croatia's trade is with other European Union member states.[142]		Privatization and the drive toward a market economy had barely begun under the new Croatian Government when war broke out in 1991. As a result of the war, the economic infrastructure sustained massive damage, particularly the revenue-rich tourism industry. From 1989 to 1993, the GDP fell 40.5%. The Croatian state still controls a significant part of the economy, with government expenditures accounting for as much as 40% of GDP.[143] A backlogged judiciary system, combined with inefficient public administration, especially on issues of land ownership and corruption, are particular concerns. In the 2015 Corruption Perceptions Index, published by Transparency International, the country is ranked joint 50th with a score of 51, where zero denotes "highly corrupt" and 100 "very clean".[144] In June 2013, the national debt stood at 59.5% of the nation's GDP.[145]		Tourism dominates the Croatian service sector and accounts for up to 20% of Croatian GDP. Annual tourist industry income for 2014 was estimated at €7.4 billion.[146] Its positive effects are felt throughout the economy of Croatia in terms of increased business volume observed in retail business, processing industry orders and summer seasonal employment. The industry is considered an export business, because it significantly reduces the country's external trade imbalance.[147] Since the conclusion of the Croatian War of Independence, the tourist industry has grown rapidly, recording a fourfold rise in tourist numbers, with more than 11 million tourists each year.[148] The most numerous are tourists from Germany, Slovenia, Austria, Italy and the Czech Republic as well as Croatia itself.[149] Length of a tourist stay in Croatia averages 4.9 days.[150]		The bulk of the tourist industry is concentrated along the Adriatic Sea coast. Opatija was the first holiday resort since the middle of the 19th century. By the 1890s, it became one of the most significant European health resorts.[151] Later a number of resorts sprang up along the coast and islands, offering services ranging from mass tourism to catering and various niche markets, the most significant being nautical tourism, as there are numerous marinas with more than 16 thousand berths, cultural tourism relying on appeal of medieval coastal cities and numerous cultural events taking place during the summer. Inland areas offer mountain resorts, agrotourism and spas. Zagreb is also a significant tourist destination, rivalling major coastal cities and resorts.[152]		Croatia has unpolluted marine areas reflected through numerous nature reserves and 116 Blue Flag beaches.[153] Croatia is ranked as the 18th most popular tourist destination in the world.[154] About 15% of these visitors (over one million per year) are involved with naturism, an industry for which Croatia is world famous. It was also the first European country to develop commercial naturist resorts.[155]		The highlight of Croatia's recent infrastructure developments is its rapidly developed motorway network, largely built in the late 1990s and especially in the 2000s (decade). By September 2011, Croatia had completed more than 1,100 kilometres (680 miles) of motorways, connecting Zagreb to most other regions and following various European routes and four Pan-European corridors.[156][157][158] The busiest motorways are the A1, connecting Zagreb to Split and the A3, passing east–west through northwest Croatia and Slavonia.[159] A widespread network of state roads in Croatia acts as motorway feeder roads while connecting all major settlements in the country. The high quality and safety levels of the Croatian motorway network were tested and confirmed by several EuroTAP and EuroTest programs.[160][161]		Croatia has an extensive rail network spanning 2,722 kilometres (1,691 miles), including 984 kilometres (611 miles) of electrified railways and 254 kilometres (158 miles) of double track railways.[162] The most significant railways in Croatia are found within the Pan-European transport corridors Vb and X connecting Rijeka to Budapest and Ljubljana to Belgrade, both via Zagreb.[156] All rail services are operated by Croatian Railways.[163]		There are international airports in Zagreb, Zadar, Split, Dubrovnik, Rijeka, Osijek and Pula.[164] The largest and busiest is Franjo Tuđman Airport.[165] As of January 2011, Croatia complies with International Civil Aviation Organization aviation safety standards and the Federal Aviation Administration upgraded it to Category 1 rating.[166]		The busiest cargo seaport in Croatia is the Port of Rijeka and the busiest passenger ports are Split and Zadar.[167][168] In addition to those, a large number of minor ports serve an extensive system of ferries connecting numerous islands and coastal cities in addition to ferry lines to several cities in Italy.[169] The largest river port is Vukovar, located on the Danube, representing the nation's outlet to the Pan-European transport corridor VII.[156][170]		There are 610 kilometres (380 miles) of crude oil pipelines in Croatia, connecting the Port of Rijeka oil terminal with refineries in Rijeka and Sisak, as well as several transhipment terminals. The system has a capacity of 20 million tonnes per year.[171] The natural gas transportation system comprises 2,113 kilometres (1,313 miles) of trunk and regional natural gas pipelines, and more than 300 associated structures, connecting production rigs, the Okoli natural gas storage facility, 27 end-users and 37 distribution systems.[172]		Croatian production of energy sources covers 85% of nationwide natural gas demand and 19% of oil demand. In 2008, 47.6% of Croatia's primary energy production structure comprised use of natural gas (47.7%), crude oil (18.0%), fuel wood (8.4%), hydro power (25.4%) and other renewable energy sources (0.5%). In 2009, net total electrical power production in Croatia reached 12,725 GWh and Croatia imported 28.5% of its electric power energy needs.[85] The bulk of Croatian imports are supplied by the Krško Nuclear Power Plant, 50% owned by Hrvatska elektroprivreda, providing 15% of Croatia's electricity.[173]		With its estimated population of 4,20 million in 2015, Croatia ranks 125th by population in the world. Its population density stands at 75.9 inhabitants per square kilometre. The overall life expectancy in Croatia at birth was 78 years in 2012.[174] The total fertility rate of 1.5 children per mother, is one of the lowest in the world. Since 1991, Croatia's death rate has continuously exceeded its birth rate.[85] Since the late 1990s, there has been a positive net migration into Croatia, reaching a level of more than 7,000 net immigrants in 2006.[175] According to the 2013 United Nations report, 17.6% of Croatia's population were foreign-born immigrants.[176]		The Croatian Bureau of Statistics forecast that the population may shrink to 3.1 million by 2051, depending on actual birth rate and the level of net migration.[177] The population of Croatia rose steadily from 2.1 million in 1857 until 1991, when it peaked at 4.7 million, with exception of censuses taken in 1921 and 1948, i.e. following two world wars.[85] The natural growth rate of the population is currently negative[86] with the demographic transition completed in the 1970s.[178] In recent years, the Croatian government has been pressured each year to add 40% to work permit quotas for foreign workers.[179] In accordance with its immigration policy, Croatia is trying to entice emigrants to return.[180]		The population decrease was also a result of the Croatian War of Independence. During the war, large sections of the population were displaced and emigration increased. In 1991, in predominantly Serb areas, more than 400,000 Croats and other non-Serbs were either removed from their homes by the Croatian Serb forces or fled the violence.[181] During the final days of the war in 1995, more than 120,000 Serbs,[182] and perhaps as many as 200,000,[183] fled the country before arrival of Croatian forces during Operation Storm. Within a decade following the end of the war, only 117,000 Serb refugees returned out of 300,000 displaced during the entire war.[184] Most of Croatia's remaining Serbs never lived in areas occupied in the Croatian War of Independence. Serbs have been only partially re-settled in the regions they previously inhabited while some of the settlements previously inhabited by Serbs were settled by Croat refugees from Bosnia and Herzegovina, mostly from Republika Srpska.[185][186]		Croatia is inhabited mostly by Croats (90.4%) and is ethnically the most homogeneous of the six countries of former Yugoslavia. Minority groups include Serbs (4.4%), Bosniaks, Hungarians, Italians, Slovenes, Germans, Czechs, Romani people and others (5.9%).[1]		Croatia has no official religion. Freedom of religion is a right defined by the Constitution which also defines all religious communities as equal in front of the law and separated from the state.		According to the 2011 census, 91.36% of Croatians identify as Christian; of these, Roman Catholics make up the largest group, accounting for 86.28% of the population, after which follows Eastern Orthodoxy (4.44%), Protestantism (0.34%) and other Christianity (0.30%). Second largest religion is Islam (1.47%). 4.57% of the population describes themselves as non-religious.[188]		In the Eurostat Eurobarometer Poll of 2005, 67% of the population of Croatia responded that "they believe there is a God".[189] In a 2009 Gallup poll, 70% answered yes to the question "Is religion an important part of your daily life?".[190] However, only 24% of the population attends religious services regularly.[191]				Zagreb Split Rijeka Osijek		Zadar Pula Slavonski Brod Karlovac		Croatian is the official language of Croatia, and became the 24th official language of the European Union upon its accession in 2013.[193][194] Minority languages are in official use in local government units where more than a third of population consists of national minorities or where local legislation defines so. Those languages are Czech, Hungarian, Italian, Ruthenian, Serbian and Slovakian.[195]		According to the 2011 Census, 95.6% of citizens of Croatia declared Croatian as their native language, 1.2% declared Serbian as their native language, while no other language is represented in Croatia by more than 0.5% of native speakers among population of Croatia.[196] Croatian is one of the three standard varieties of the Serbo-Croatian language of the South Slavic group of languages. Croatian is written using the Latin alphabet. Croatia has three major dialects of Serbo-Croatian represented, with standard Croatian based on the Shtokavian dialect. The Chakavian and Kajkavian dialects are distinguished by their lexicon, phonology, and syntax.[197]		From 1961 to 1991, the official language was Serbo-Croatian. Even during socialist rule, Croats often referred to their language as Croato-Serbian (instead of Serbo-Croatian) or as Croatian.[198] Croatian and Serbian variants of the language were not officially recognised as different at the time, but referred to as the west and east version, and had different alphabets: the Latin alphabet and Serbian Cyrillic.[197] Croatians are protective of their Croatian language from foreign influences, as the language was under constant change and threats imposed by previous rulers (i.e. Austrian German, Hungarian, Italian and Turkish words were changed and altered to "Slavic" looking/sounding ones). Efforts made to impose policies to alter Croatian into "Serbo-Croatian" or "South Slavic" language, met resistance from Croats in form of Croatian linguistic purism. Croatian replaced Latin as the official language of the Croatian government in the 19th century.[199]		A 2011 survey revealed that 78% of Croatians claim knowledge of at least one foreign language.[200] According to a survey ordered by the European Commission in 2005, 49% of Croatians speak English as the second language, 34% speak German, and 14% speak Italian. French and Russian are spoken by 4% each, and 2% of Croatians speak Spanish. However, there are large municipalities that have minority languages that include substantial populations that speak these languages. A odd-majority of Slovenes (59%) have a certain level of knowledge of Croatian.[201] The country is a part of various language-based international associations most notably, the Organisation internationale de la Francophonie and the European Union Language Association.		Literacy in Croatia stands at 99.2 per cent.[202] A worldwide study about the quality of living in different countries published by Newsweek in August 2010 ranked the Croatian education system at 22nd, to share the position with Austria.[203] Primary education in Croatia starts at the age of six or seven and consists of eight grades. In 2007 a law was passed to increase free, noncompulsory education until 18 years of age. Compulsory education consists of eight grades of elementary school. Secondary education is provided by gymnasiums and vocational schools. As of 2014[update], there are 2,055 elementary schools and 707 schools providing various forms of secondary education.[204] Primary and secondary education are also available in languages of recognized minorities in Croatia, where classes are held in Czech, Hungarian, Italian, Serbian and German languages.[205]		There are 132 elementary and secondary level music and art schools, as well as 120 schools for disabled children and youth and 74 schools for adults.[204] Nationwide leaving exams (Croatian: državna matura) were introduced for secondary education students in the school year 2009–2010. It comprises three compulsory subjects (Croatian language, mathematics, and a foreign language) and optional subjects and is a prerequisite for university education.[206]		Croatia has 8 public universities, the University of Dubrovnik, University of Osijek, University of Pula, University of Rijeka, University of Split, University of Zadar and University of Zagreb, and 2 private universities, Catholic University of Croatia and Dubrovnik International University.[207] The University of Zadar, the first university in Croatia, was founded in 1396 and remained active until 1807, when other institutions of higher education took over until the foundation of the renewed University of Zadar in 2002.[208] The University of Zagreb, founded in 1669, is the oldest continuously operating university in Southeast Europe.[209] There are also 15 polytechnics, of which 2 are private, and 30 higher education institutions, of which 27 are private.[207] In total, there are 55 institutions of higher education in Croatia, attended by more than 157 thousand students.[204]		There are 205 companies, government or education system institutions and non-profit organisations in Croatia pursuing scientific research and development of technology. Combined, they spent more than 3 billion kuna (€400 million) and employed 10,191 full-time research staff in 2008.[85] Among the scientific institutes operating in Croatia, the largest is the Ruđer Bošković Institute in Zagreb.[210] The Croatian Academy of Sciences and Arts in Zagreb is a learned society promoting language, culture, arts and science from its inception in 1866.[211] Croatia has also produced inventors and two Croatians received the Nobel Prize.		Croatia has a universal health care system, whose roots can be traced back to the Hungarian-Croatian Parliament Act of 1891, providing a form of mandatory insurance of all factory workers and craftsmen.[212] The population is covered by a basic health insurance plan provided by statute and optional insurance. In 2012, annual healthcare related expenditures reached 21.0 billion kuna (€2.8 billion).[213] Healthcare expenditures comprise only 0.6% of private health insurance and public spending.[214] In 2010, Croatia spent 6.9% of its GDP on healthcare.[215]		Croatia ranked around the 40th in the world in life expectancy with 74 years for men and 81 years for women, and it had a low infant mortality rate of 5 per 1,000 live births.[174][216]		There are hundreds of healthcare institutions in Croatia, including 79 hospitals and clinics with 23,967 beds. The hospitals and clinics care for more than 700 thousand patients per year and employ 5,205 medical doctors, including 3,929 specialists. There are 6,379 private practice offices, and a total of 41,271 health workers in the country. There are 63 emergency medical service units, responding to more than a million calls. The principal cause of death in 2008 was cardiovascular disease at 43.5% for men and 57.2% for women, followed by tumours, at 29.4% for men and 21.4% for women. In 2009 only 13 Croatians had been infected with HIV/AIDS and 6 had died from the disease.[85] In 2008 it was estimated by the WHO that 27.4% of Croatians over age of 15 are smokers.[217] According to 2003 WHO data, 22% of the Croatian adult population is obese.[218]		Because of its geographic position, Croatia represents a blend of four different cultural spheres. It has been a crossroad of influences of the western culture and the east—ever since division of the Western Roman Empire and the Byzantine Empire—as well as of the Mitteleuropa and the Mediterranean culture.[219] The Illyrian movement was the most significant period of national cultural history, as the 19th-century period proved crucial in emancipation of the Croatian language and saw unprecedented developments in all fields of art and culture, giving rise to a number of historical figures.[39]		The Ministry of Culture of the Republic of Croatia is tasked with preserving the nation's cultural and natural heritage and overseeing its development. Further activities supporting development of culture are undertaken at local government level.[220] The UNESCO's World Heritage List includes seven sites in Croatia.[221] The country is also rich with Intangible culture and holds ten of UNESCO's World's intangible culture masterpieces, surpassing all countries in Europe except Spain which possesses an equal number of the listed items.[222] A global cultural contribution from Croatia is the necktie, derived from the cravat originally worn by the 17th-century Croatian mercenaries in France.[223][224]		As of 2012[update], Croatia has 60 professional theatres, 17 professional children's theatres and 60 amateur theatres visited by more than 1.8 million viewers per year. The professional theatres employ 1,121 artists. There are 23 professional orchestras, ensembles and choirs in the country, attracting an annual attendance of 294 thousand. There are 162 cinemas with attendance exceeding 4 million.[225] Croatia has 175 museums, visited by nearly 2.2 million people in 2009. Furthermore, there are 1,731 libraries in the country, containing 24.5 million volumes, and 18 archives.[226]		In 2009, more than 7,200 books and brochures were published, along with 2,678 magazines and 314 newspapers. There are also 146 radio stations and 21 TV stations operating in the country. In past five years, film production in Croatia produced up to five feature films and 10 to 51 short films, with an additional 76 to 112 TV films. As of 2009[update], there are 784 amateur cultural and artistic associations and more than 10 thousand cultural, educational and artistic events held annually.[85] The book publishing market is dominated by several major publishers and the industry's centrepiece event—Interliber exhibition held annually at Zagreb Fair.[228]		Croatia has established a high level of human development and gender equality in terms of the Human Development Index.[229] It promotes disability rights.[230] Recognition of same-sex unions in Croatia has gradually improved over the past decade, culminating in registered civil unions in July 2014, granting same-sex couples equal inheritance rights, tax deductions and limited adoption rights.[231] However, in December 2013 Croatians voted in favour of a constitutional referendum, backed by conservative groups, defining marriage as a "life union of woman and man".[232]		Architecture in Croatia reflects influences of bordering nations. Austrian and Hungarian influence is visible in public spaces and buildings in the north and in the central regions, architecture found along coasts of Dalmatia and Istria exhibits Venetian influence.[233] Large squares named after culture heroes, well-groomed parks, and pedestrian-only zones, are features of these orderly towns and cities, especially where large scale Baroque urban planning took place, for instance in Osijek (Tvrđa), Varaždin and Karlovac.[234][235] Subsequent influence of the Art Nouveau was reflected in contemporary architecture.[236] Along the coast, the architecture is Mediterranean with a strong Venetian and Renaissance influence in major urban areas exemplified in works of Giorgio da Sebenico and Niccolò Fiorentino such as the Cathedral of St. James in Šibenik. The oldest preserved examples of Croatian architecture are the 9th-century churches, with the largest and the most representative among them being Church of St. Donatus in Zadar.[237][238]		Besides the architecture encompassing the oldest artworks in Croatia, there is a long history of artists in Croatia reaching to the Middle Ages. In that period the stone portal of the Trogir Cathedral was made by Radovan, representing the most important monument of Romanesque sculpture from Medieval Croatia. The Renaissance had the greatest impact on the Adriatic Sea coast since the remainder of Croatia was embroiled in the Hundred Years' Croatian–Ottoman War. With the waning of the Ottoman Empire, art flourished during the Baroque and Rococo. The 19th and the 20th centuries brought about affirmation of numerous Croatian artisans, helped by several patrons of the arts such as bishop Josip Juraj Strossmayer.[239] Croatian artists of the period achieving worldwide renown were Vlaho Bukovac and Ivan Meštrović.[237]		The Baška tablet, a stone inscribed with the glagolitic alphabet found on the Krk island and dated to 1100, is considered to be the oldest surviving prose in Croatian.[240] The beginning of more vigorous development of Croatian literature is marked by the Renaissance and Marko Marulić. Besides Marulić, Renaissance playwright Marin Držić, Baroque poet Ivan Gundulić, Croatian national revival poet Ivan Mažuranić, novelist, playwright and poet August Šenoa, children's writer Ivana Brlić-Mažuranić, writer and journalist Marija Jurić Zagorka, poet and writer Antun Gustav Matoš, poet Antun Branko Šimić, expressionist and realist writer Miroslav Krleža, poet Tin Ujević and novelist and short story writer Ivo Andrić are often cited as the greatest figures in Croatian literature.[241][242]		The freedom of the press and the freedom of speech are guaranteed by the constitution of Croatia.[243] Croatia ranked 62nd in the 2010 Press Freedom Index report compiled by Reporters Without Borders.[244] The state-owned news agency HINA runs a wire service in Croatian and English on politics, economics, society and culture.[245]		Nevertheless, despite the provisions fixed in the constitution, freedoms of press and speech in Croatia have been classified as partly free since 2000 by Freedom House, the independent nongovernmental organisation that monitors press freedom worldwide. Namely the country has been ranked 85th (of 196 countries),[247] and the 2011 Freedom House report noted improvement of applicable legislation reflecting Croatia's accession to the EU, yet pointed out instances of politicians' attempts to hinder investigative journalism and influence news reports contents, difficulties regarding public access to information, and that most of print media market is controlled by German-owned Europapress Holding and Austrian-owned Styria Media Group.[248] Amnesty International reports that in 2009 in Croatia there was an increase in the number of physical attacks and murders of journalists. The incidents were mainly perpetrated against journalists investigating war crimes and organised crime.[249]		As of October 2011, there are nine nationwide free-to-air DVB-T television channels, with Croatian Radiotelevision (HRT), Nova TV and RTL Televizija operating two of the channels each, and the remaining three operated by the Croatian Olympic Committee, Kapital Net d.o.o. and Author d.o.o. companies. In addition there are 21 regional or local DVB-T television channels.[250] The HRT is also broadcasting a satellite TV channel.[251] In 2012, there were 146 radio stations and 25 TV stations in Croatia.[252] Cable television and IPTV networks are gaining ground in the country, as the cable TV networks already serve 450 thousand people, 10% of the total population of the country.[253][254]		There are 314 newspapers and 2,678 magazines published in Croatia.[85] The print media market is dominated by Europapress Holding and Styria Media Group who publish their flagship dailies Jutarnji list, Večernji list and 24sata. Other influential newspapers are Novi list and Slobodna Dalmacija.[255][256] In 2013, 24sata was the most widely circulated daily newspaper, followed by Večernji list and Jutarnji list.[257]		Croatia's film industry is small and heavily subsidised by the government, mainly through grants approved by the Ministry of Culture with films often being co-produced by HRT.[258][259] Pula Film Festival, the national film awards event held annually in Pula, is the most prestigious film event featuring national and international productions.[260] The greatest accomplishment by Croatian filmmakers was achieved by Dušan Vukotić when he won the 1961 Academy Award for Best Animated Short Film for Ersatz (Croatian: Surogat).[261]		Croatian traditional cuisine varies from one region to another. Dalmatia and Istria draw upon culinary influences of Italian and other Mediterranean cuisines which prominently feature various seafood, cooked vegetables and pasta, as well as condiments such as olive oil and garlic. The continental cuisine is heavily influenced by Hungarian, Austrian and Turkish culinary styles. In that area, meats, freshwater fish and vegetable dishes are predominant.[262]		There are two distinct wine-producing regions in Croatia. The continental region in the northeast of the country, especially Slavonia, is capable of producing premium wines, particularly whites. Along the north coast, Istrian and Krk wines are similar to those produced in neighbouring Italy, while further south in Dalmatia, Mediterranean-style red wines are the norm.[262] Annual production of wine exceeds 140 million litres.[85] Croatia was almost exclusively a wine-consuming country up until the late 18th century when a more massive production and consumption of beer started;[263] the annual consumption of beer in 2008 was 83.3 litres per capita which placed Croatia in 15th place among the world's countries.[264]		There are more than 400,000 active sportspeople in Croatia.[265] Out of that number, 277,000 are members of sports associations and nearly 4,000 are members of chess and contract bridge associations.[85] Association football is the most popular sport. The Croatian Football Federation (Croatian: Hrvatski nogometni savez), with more than 118,000 registered players, is the largest sporting association in the country.[266] The Prva HNL football league attracts the highest average attendance of any professional sports league in the country. In season 2010–11, it attracted 458,746 spectators.[267]		Croatian athletes competing at international events since Croatian independence in 1991 won 44 Olympic medals, including fifteen gold medals—at the 1996 and 2004 Summer Olympics in handball, 2000 Summer Olympics in weightlifting, 2002 and 2006 Winter Olympics in alpine skiing, 2012 Summer Olympics in discus throw, trap shooting, and water polo, and in 2016 Summer Olympics in shooting, rowing, discus throw, sailing and javelin throw.[268] In addition, Croatian athletes won 14 gold medals at world championships, including two in athletics at the World Championships in Athletics held in 2007 and 2009, one in handball at the 2003 World Men's Handball Championship, two in water polo at the 2007 World Aquatics Championships and 2017 World Aquatics Championships, one in rowing at the 2010 World Rowing Championships, six in alpine skiing at the FIS Alpine World Ski Championships held in 2003 and 2005 and two at the World Taekwondo Championships in 2011 and 2007. Croatian athletes also won the 2005 Davis Cup.		Croatia hosted several major sport competitions, including the 2009 World Men's Handball Championship, the 2007 World Table Tennis Championships, the 2000 World Rowing Championships, the 1987 Summer Universiade, the 1979 Mediterranean Games and several European Championships. The governing sports authority in the country is the Croatian Olympic Committee (Croatian: Hrvatski olimpijski odbor), founded on 10 September 1991 and recognised by the International Olympic Committee since 17 January 1992, in time to permit the Croatian athletes to appear at the 1992 Winter Olympics in Albertville, France representing the newly independent nation for the first time at the Olympic Games.[269]		1. All twenty-eight member states of the European Union are also members of the WTO in their own right:		2. Special administrative regions of the People's Republic of China, participates as "Hong Kong, China" and "Macao China". 3. Officially the Republic of China, participates as "Separate Customs Territory of Taiwan, Penghu, Kinmen and Matsu", and "Chinese Taipei" in short.		
K'gari (Fraser Island) is a heritage-listed island located along the southeastern coast of the state of Queensland, Australia. It is approximately 250 kilometres (160 mi) north of the state capital, Brisbane.[2] It is a locality within the Fraser Coast local government in the Wide Bay–Burnett region.[3] Its length is about 120 kilometres (75 mi) and its width is approximately 24 kilometres (15 mi).[4] It was inscribed as a World Heritage Site in 1992.[5] The island is considered to be the largest sand island in the world at 1,840 km2.[6] It is also Queensland's largest island, Australia's sixth largest island and the largest island on the East Coast of Australia.		The island has rainforests, eucalyptus woodland, mangrove forests, wallum and peat swamps, sand dunes and coastal heaths. It is made up of sand that has been accumulating for approximately 750,000 years on volcanic bedrock that provides a natural catchment for the sediment which is carried on a strong offshore current northwards along the coast. Unlike on many sand dunes, plant life is abundant due to the naturally occurring mycorrhizal fungi present in the sand, which release nutrients in a form that can be absorbed by the plants.[7] Fraser Island is home to a small number of mammal species,[8] as well as a diverse range of birds, reptiles and amphibians, including the occasional saltwater crocodile. The island is protected in the Great Sandy National Park.		Fraser Island has been inhabited by humans for as much as 5,000 years.[7] Explorer James Cook sailed by the island in May 1770. Matthew Flinders landed near the most northern point of the island in 1802. For a short period the island was known as Great Sandy Island. The island became known as Fraser due to the stories of a shipwreck survivor named Eliza Fraser. Today the island is a popular tourism destination. Its resident human population was 194 at the 2011 Australian Census.[9]		In 2009 as part of the Q150 celebrations, the Fraser Island was announced as one of the Q150 Icons of Queensland for its role as a "Natural attraction".[10]						Fraser Island is separated from the mainland by Great Sandy Strait. The southern tip, near Tin Can Bay, is situated to the north of Inskip Peninsula. The most northern point of the island is Sandy Cape where the Sandy Cape Light operated from 1870 to 1994.[11] The establishment of the lighthouse was the first permanent European settlement on the island.[12] The nearest large town to Fraser Island is Hervey Bay, while Maryborough and Bundaberg are also close by. The bay on the north east coast is called Marloo Bay and on the north west coast is Platypus Bay. The most westerly place on the island is Moon Point.[13]		Eli Creek is the largest creek on the east coast of the island with a flow of 80 million litres per day.[14] Eli Creek has its own unique and varied wild life. Coongul Creek on the west coast has a flow rate of four to five million litres per hour.[13] Some of the swamps on the island are fens, particularly near Moon Point. This was only discovered in 1996 when a group of experts who had attended a Ramsar conference in Brisbane flew over the island and conducted an aerial survey.[15] From above they noticed the distinct patterns of potholed peat which are devoid of trees. This was the first instance of fens found in Australia and in a sub-tropical region, although more were subsequently found on the adjacent Cooloola coast.		The total volume of sand above sea level on Fraser Island is directly proportional to the mass of 113 cubic kilometres (27 cubic miles).[16] All of the sand, which originated in the Hawkesbury, Hunter and Clarence River catchments in New South Wales has been transported north by longshore transport.[16] Along the eastern coast of the island the process is removing more sand than it is depositing, resulting in the slow erosion of beaches which may accelerate with sea level rises attributed to climate change. The sand consists of 98% quartz.[13]		All hills on the island have been formed by sandblowing. Sandblows are parabolic dunes which move across the island via the wind and are devoid of vegetation. In 2004, there was an estimated total of 36 sandblows on the island.[13] With year-round south-easterly wind, the sand dunes on the island move at the rate of 1 to 2 metres a year and grow to a height of 244 metres. The dune movement creates overlapping dunes and sometimes intersects waterways and covers forests. Dune-building has occurred in episodes as the sea levels have changed and once extended much further to the east.[17] The oldest dune system has been dated at 700,000 years, which is the world's oldest recorded sequence.[17]		The coloured sands found at Rainbow Gorge, The Cathedrals, The Pinnacles and Red Canyon are examples of where the sand has been stained over thousands of years due to the sand conglomerating with clay.[17] Hematite, the mineral pigment responsible for the staining acts like cement. This allows the steeper cliffs of coloured sand to form. Coffee rock, so-called because when it is dissolved in water it turns the colour of coffee, is found in outcrops along the beaches on both sides of the island.[13]		The 120 kilometres (75 mi) beach runs along most of the east coast of Fraser Island. It is used as a landing strip for planes and is officially designated as a main road (highway rules state that vehicles must give way to aircraft if they are oncoming). Along the beach are the Champagne Pools, Indian Head, the Maheno Wreck and the outflow of Eli Creek. Exposed volcanic rocks are found at Indian Head, Waddy Point and Middle Rocks as well as near Boon Boon Creek.[13]		Fraser Island has over 100 freshwater lakes,[18] as well as the second highest concentration of lakes in Australia after Tasmania.[14] The freshwater lakes on Fraser Island are some of the cleanest lakes in the world.[7] A popular tourist area is Lake McKenzie which is located inland from the small town of Eurong. It is a perched lake sitting on top of compact sand and vegetable matter 100 metres (330 ft) above sea level. Lake McKenzie has an area of 150 hectares and is just over 5 metres (16 ft) in depth. The beach sand of Lake McKenzie is nearly pure silica. The lakes have very few nutrients and pH varies, though sunscreen and soaps are a problem as a form of pollution. Freshwater on the island may become stained by organic acids found in decaying vegetation. Because of the organic acids a pH level of 3.7 has been measured in some of the island's perched lakes.[13] The high acidity levels prevent many species from finding habitat in the lakes.		Another perched lake on the island is Lake Boomanjin, which at 200 hectares in size, is the largest perched lake on the sea islands in the world.[19] In total there are 40 perched lakes on the island, half of all known lakes of this kind on the planet.[8] Lake Boomanjin is fed by two creeks that pass through a wallum swamp where it collects tannins which tint the water red.[13] Lake Wabby is the deepest lake on the island, at 12 metres (39 ft) in depth and also the least acidic which means it has the most aquatic life of all the lakes.		Some of the lakes on Fraser Island are window lakes. These form when the water table has risen to a point higher than the surrounding land. Most of the valleys on the islands have creeks which are fed by springs.[13] Motor boats and jet skis are banned from the island's lakes.[20]		Fraser Islands climate is generally mild and is not subject to extremes in temperature due to the moderating influence of the ocean. Temperatures rarely rise above 35 °C (95 °F) or drop below 5 °C (41 °F) and humidity is consistently high. Rainfall is heaviest during the summer and early autumn, and the annual average is 1,271 mm (50.04 in). Cyclones can be a threat; Cyclone Hamish brushed the island as a category 5 in March 2009, while Cyclone Oswald in January 2013 was significantly weaker at a Category 1. Both storms however caused severe beach erosion, particularly on the islands northern tip.[21]		Estimates of the number of mammal species present on the island range from 25 to 50.[18][23] Mammals found on Fraser Island include swamp wallabies, echidnas, ringtail and brushtail possums, sugar gliders, squirrel gliders, phascogales, bandicoots, potoroos, flying foxes and dingoes. The swamp wallaby finds protection from dingos in the swampy areas which have dense undergrowth.[24] There are 19 species of bats which live on or visit Fraser Island.[24]		Until 2003, when they were removed by the Environmental Protection Agency,[25] there were a few brumbies (horses) on the island, descendants of Arab stock turned loose for breeding purposes, and joined in 1879 by horses brought over for the logging industry.[26][27]		Dingoes were once common on the island, but are now decreasing. The Fraser Island dingoes are reputedly some of the last remaining pure dingoes in Eastern Australia and to prevent cross-breeding, dogs are not allowed on the island. According to DNA-examinations from the year 2004, the dingoes on Fraser Island are "pure".[28] However, skull measurements from the 1990s detected crossbreeds between dingoes and domestic dogs among the population.[29]		Up until 1995, there were no official records of dingoes attacking humans on Fraser Island. In April 2001, a boy named Clinton Gage wandered away from his family and was attacked and killed by several dingoes.[30] Over 120 dingoes were killed by rangers as a result of the incident, though locals believe the number was much greater.[26] After the 2001 attack, four dedicated rangers were allocated dingo management roles and ranger patrols were increased.[31] There are fines for feeding dingoes or leaving food and rubbish out which may attract them.[23]		As of January 2008, the number of dingoes on the island was estimated to be 120 to 150, and sightings have become less common. A University of Queensland researcher, Nick Baker, claims the dingoes on Fraser Island have adopted unusual behaviour. Rather than hunt in small packs, Fraser Island dingoes had developed a tolerance for each other and work together in one big hunting pack.[31] Dingo-proof fences, consisting of metals bars across a concrete pit and a 1.8 m high mesh fence were built around nine island settlements in 2008, to keep the dingoes out of the townships.[32]		In late 2009, a former ranger (no actual formal records of him being employed by QPWS can be found) on the island, Ray Revill, claimed 70% of the dingo population, which was then estimated at between 100 and 120 animals, was malnourished.[33] In March 2010, three separate reports of dingos biting tourists were made.[34] Tourists have been criticised for ignoring advice from park rangers as they try to provoke reactions from dingoes while taking photographs.[34]		As of 2015[update], the number of dingoes on the island was estimated to be around 180 to 220.[35]		There has been a total of 74 different species of reptiles recorded on Fraser Island.[24] 18 species of snakes have been identified with one third of them considered dangerous, including the extremely venomous eastern brown snake.[18] Goannas, snakes, geckos, skinks and frogs are all present on the island. Some frog species have evolved to cope with the acidic waters of lakes and swamps on the island, and are appropriately called acid frogs.[23][27] The island is home to the recently discovered Fraser Island sand skink. Freshwater turtles such as Kreffts river turtle are found in the island's lakes and creeks.		Saltwater crocodiles are exclusively tropical reptiles and usually found in Far North Queensland (several hundred kilometres north-west of Fraser Island,) however, occasionally during the warmer season (December through March, when water temperatures reach consistent tropical temperatures) crocodiles may appear in areas in and around Fraser Island. During the 2008–2009 summer several crocodiles (one over 4 metres in length) were present in the surrounding ocean.[36] It is thought that these reptiles are seasonal visitors, as they always disappear during the cold months (presumably returning to tropical northern Queensland.) This sort of activity was apparently reported but unverified decades ago (a handful of crocodiles have also historically been observed on very rare occurrences around Brisbane, the Gold Coast and Sunshine Coasts during the warmer season) but within recent years has been proven and observed more often. Crocodiles do not breed nor do they appear to have any permanent populations living on Fraser Island.		Fraser Island forms part of the Cooloola and Fraser Coast Important Bird Area (IBA).[37] There are over 350 different species of birds on the island.[8] Birds of prey include sea eagles, peregrine falcon, osprey and kites. Other common birds include pelicans, terns, honeyeaters, gulls, kingfishers, kookaburra, owls, doves, thornbills, ducks, brolgas, and cockatoos. The island is visited by 20 species of migratory wader birds from as far afield as Siberia.[24] The island provides habitat for 22 different species of gull and tern, four species of falcon and six species of kingfisher.[38] A rare bird on the island is the eastern ground parrot, already extinct in some parts of Australia.[26][27]		Cetaceans, such as humpback whales and some species of dolphins are frequent visitors to the area. Dugongs and sea turtles can also be found in surrounding waters.[23] Great white, bull and tiger sharks can be found, with the latter species sometimes approaching fishermen wading in the surf.[23] Mud crabs are found on the western side of the island near mangrove-lined estuaries.[19] 24 freshwater fish species are found in the island's lakes.[18]		There has been 300 species of ants recorded on Fraser Island.[24] Long finned eels and giant earthworms are also found on the island.		The flora of Fraser Island is diverse. More than 865 species of plants thrive on the island.[13] It is the only place on earth where tall rainforest grows in sand.[23] The island contains the largest extent of wallum heath remnants in Queensland. In Pile Valley, 1,000-year-old rough-barked satinays are found.[23] Despite being logged the kauri pines dominate in some areas. Scribbly gums, red gums, piccabeen palms, blue quandong, brush box and pandanus all grow on Fraser Island. Along the coast, the foredunes are dominated by salt-tolerant species which includes pigface, goats foot vine and beach spinifex.[17] Spinifex sericeus is an important foundation species. Decayed matter from this dune grass breaks down in the sand, providing vital nutrients for other plant species, such as the beach oak.[13] The rare Angiopteris evecta, a species of fern that has the largest fronds in the world, grows on Fraser Island.[18] The southwest coast is dominated by mangroves.[13] Persoonia prostrata was a shrub native to the island which is now extinct.		As one travels from east to west across the island, the dune age increases. This leads to the progressive maturing of vegetation in the same direction, except for some areas along the western coast where soil leaching has decreased the nutrient soil layer to a depth beyond the reach of plant roots.[24] Each lake on Fraser Island is surrounded by concentric vegetation zones. Typically these zones range from rushes in the shallows, then a mix of pioneer species on the beaches, through to sedges, heath, paperbarks, shrubs and finally eucalypt or banksia woodlands.[24]		Fraser Island is part of the local government area Fraser Coast Region, which was created in March 2008 as a result of the report of the Local Government Reform Commission released in July 2007. Before the local government reorganisation, the island was split up evenly between the City of Hervey Bay (northern part) and the City of Maryborough (southern part).		Fraser Island South is Local Area 8 of the City of Maryborough, and includes the existing village community of Eurong, the Kingfisher Bay Resort, and Dilli Village.[39]		In 1971, the northern half of the island was declared a national park.[17] Now almost all of Fraser Island is included in the Great Sandy National Park, which is administered by Queensland's Environmental Protection Agency. This was extended in 1992 when heritage listing was granted. Except for a few small urban areas the island is protected by a Wild Rivers declaration.[40]		Domestic dogs are not permitted on the island and fines can be given for non-compliance. The ban, first applied in 1981,[30] is imposed so that the island's dingo population is not exposed to diseases.[41]		In 2010, the management of the park, particularly the treatment of dingos by the Department of Environment and Resource Management was called into question by Glen Elmes in the Queensland Parliament.[42] Camp grounds are sometimes closed so as to reduce human contact with dingo populations.[34]		Fraser Island has a number of heritage-listed sites, including:		The island was placed on the Australian National Heritage List on the 21 May 2007.[44]		The earliest known name of the island is 'K'gari' in the Butchulla people's language (pronounced 'Gurri'). It means paradise.[8][45]		According to Aboriginal legend, when humans were created and needed a place to live, the mighty god Beiral sent his messenger Yendingie with the goddess K’gari down from heaven to create the land and mountains, rivers and sea. K’gari fell in love with the earth’s beauty and did not want to leave it. So Yendingie changed her into a heavenly island – Fraser Island.		The name Fraser Island comes from Eliza Fraser and her story of survival from a shipwreck on the island. Captain James Fraser and his wife, Eliza Fraser, were shipwrecked on the island in 1836. Their ship, the Stirling Castle, set sail from Sydney to Singapore with 18 crew and passengers. The ship was holed on coral while travelling through the Great Barrier Reef north of the island.[7] Transferring to two lifeboats, the crew set a course south, attempting to reach the settlement at Moreton (now Brisbane). During this trip in the lifeboats, Captain Fraser's pregnant wife gave birth in the leaking lifeboat. The infant died soon after birth. The Captain's lifeboat was becoming more and more unseaworthy and was soon left behind by the other lifeboat which continued on. The sinking boat and its crew was beached on what was then known as the Great Sandy Island. Whether the survivors died due to disease, hunger, exhaustion or battles with the native population will never be known for sure; most likely a little of all of the above. Captain Fraser died leaving Eliza living among the local peoples. She was rescued 6 weeks after being shipwrecked by a convict, John Graham,[12] who had lived in the bush as an escapee, and who spoke the Aboriginal language. He was sent from the settlement at Moreton by the authorities there who had heard about Eliza's plight, and negotiated her return. Within 6 months, Eliza had married another sea captain. She moved to England and became a sideshow attraction in Hyde Park telling ever more lurid tales about her experiences with white slavery, cannibalism, torture and murder. As she is known to have told several versions of the story, it is unknown which version is the most accurate.[46] [47] She was killed in a carriage accident in Melbourne in 1858 during a visit.[7]		Archaeological research and evidence shows that Aboriginal Australians occupied Fraser Island at least 5,000 years ago. There was a permanent population of 400–600 that grew to 2,000–3,000 in the winter months due to abundant seafood resources. The arrival of European settlers in the area was an overwhelming disaster for the Badtjala people. European settlement in the 1840s overwhelmed the Aboriginal lifestyle with weapons, disease and lack of food.[8] By the year 1890, Aboriginal numbers had been reduced to only 300 people.[48] Most of the remaining Aborigines, the Badtjala tribe, left the island in 1904 as they were relocated to missions in Yarrabah and Durundur, Queensland.[49] It is estimated that up to 500 indigenous archaeological sites are located on the island.[20]		In October 2014, Native title rights were granted to the Badtjala people by the Federal Court. This essentially enabled the indigenous people to hunt, fish and take water for domestic purposes; and could open the island up to economic opportunities for current and future generations of Butchulla people through ecotourism and related business development.[50]		Initial European contact was limited to explorers and shipwrecks. The first recorded European to sight Fraser Island was James Cook who passed along the coast of the island between 18 and 20 May 1770. He named Indian Head after viewing a number of Aboriginal people gathered on the headland. After Cook's passage the Aboriginals composed a song to commemorate the event. This was later recognized as the first preserved oral testimony of indigenous observation of Europeans.[51] Matthew Flinders sailed past the island in 1799, and again in 1802, this time landing at Sandy Cape,[52] while charting Hervey Bay. His 1814 chart is a combination of both voyages, but did not confirm Fraser Island as being separate from the mainland. However, Flinders did suggest the presence of shallow swampy areas at the lower part of the bay. Flinders was told of an opening at Hook Point, between Fraser Island and the mainland, by two American whalers who were hunting whales in Hervey Bay.[53] In 1842, Andrew Petrie discovered good pastoral lands and forests, attracting graziers to the island.[17] Lieutenant Robert Dayman was the first European to sail between Fraser Island and the mainland in 1847.[12]		Logging on the island began in 1863, initiated by American Jack Piggott (known as 'Yankee Jack').[17] Blackbutt trees (Eucalyptus pilularis), Queensland kauri (Agathis robusta) and satinay or Fraser Island turpentine (Syncarpia hillii) were extensively exploited as they provided excellent timber.[17][54] Satinay logs were sent to Egypt to be used in the construction of the Suez Canal.[19] For the first 70 years of logging, bullock drays were used to haul the timber to loading points on the beach.[19] Railway tracks were laid through the forest to facilitate logging, but were later removed. The logging industry continued until 1991, ceasing following concerns raised by the Commission of Inquiry into the Conservation, Management and Use of Fraser Island and the Great Sandy Region, appointed by the Goss Labor government and chaired by Justice Tony Fitzgerald.[55]		The geological wealth of the island lay in its rich deposits of rutile, ilmenite, zircon and monazite. Sand mining leases were first granted in 1950, and mining continued until 1977.[46] Without public knowledge the Queensland Government granted mining leases to the American mining company Dillingham-Murphyores in the 1960s. In 1971, the Fraser Island Defense Organisation (FIDO) opposed the granting of more leases to the company. Despite more than 1,300 submissions that were made to the local mining warden objecting to new leases, the submission was granted.[56] FIDO took the case to the High Court of Australia which overruled the decision noting that the public interest was not being upheld. Dillingham-Murphyores continued mining. The Whitlam Government established Australia's first environmental impact inquiry which recommended that mining cease.[56] Eventually Malcolm Fraser canceled the company's mineral export license which halted mining on the island. This represented a significant win for the conservation movement in Australia.[56] Fraser Island then became the first place to be included in the Australian Heritage Commission's Register of the National Estate.[57]		A major landmark on Fraser Island is the shipwreck of the S.S. Maheno. The Maheno was built in Scotland in 1905 as a luxury passenger ship for the trans-Tasman crossing. During the First World War she served as a hospital ship in the English Channel, and was then returned to her owners to resume her usual commercial operation. By 1935 the ship had been taken out of service and was sold to a ship-breaker in Japan. On 25 June 1935, while being towed to Osaka to be broken up, she was caught in a strong cyclone about 80 kilometres (50 miles) off the coast of Queensland. The towline parted, and on 9 July 1935 the Maheno became beached on the east coast of Fraser Island.		During the Second World War the wreck served as target bombing practice for the RAAF and was used as an explosives demolition target by special forces from the Fraser Commando School. The remains of the ship are now severely rusted, with almost three and a half storeys buried under the sand. Because of the danger it poses, climbing on the wreck is not permitted.[58]		During World War Two, the area near McKenzie's Jetty was used by the Services Reconnaissance Department (popularly known as "Z Special Unit") as a special forces training camp – the Fraser Commando School. Thousands of soldiers were trained here because the conditions were similar to those found on Pacific Islands where the Japanese were fought.[19] Lake McKenzie was used for parachute training and the wreck of the Maheno was used for explosive demolitions practice.		Visitors to the site of the Fraser Commando School today can still see various relics of its military past including armour plates used to test armour piercing explosive charges and weapons and a concrete relief map of Singapore Harbour used as an aid in operations planning.		As part of ongoing meetings in the United Nations Trusteeship Council on the Conditions in the Trust Territories, the Republic of Nauru expressed concern that its phosphate mining exportation would be depleted by the end of the century, endangering the future of the island.[59][60] In 1961, Fraser Island was proposed by Australia as a location for the resettlement of the entire population of the Republic of Nauru. The timber industry on Fraser Island managed to ensure that resettlement on Fraser Island did not proceed.[61] In 1964 in the 31st session of United Nations Trusteeship Council meetings it was concluded that Curtis Island could provide a more satisfactory resettlement for the population of Nauru.[60] Nauru rejected the offer of moving the entire population to Curtis Island due to political independence considerations that Australia would not agree to.[59] Although a resettlement never did occur, the Republic of Nauru went on to achieve independence on 31 January 1968.		Estimates of the number of visitors to the island each year range from 350,000 to 500,000.[30][62] The chance of seeing a dingo in its natural setting is one of the main reasons people visit the island.[30] The use of boardwalks and marked tracks by visitors is encouraged to reduce erosion.[20]		Urinating tourists have created environmental problems in Fraser Island lakes and on coastal dunes. The foredunes are used as a toilet by bush campers, who are estimated to number 90,000 each year.[62] Many of the perched lakes have no outflow or inflow which exacerbates the problem. Water quality in some lakes is being affected by storm water run-off from dune roads, and by swimmers' use of sunscreen.		In April 2009, a vehicle overturned on the beach after being hit by a wave. Two backpackers were killed in the accident. Following the incident speed limits on the beach were reduced from 100 km/h to 80 km/h, and from 40 km/h to 30 km/h inland.[63] Everyone who hires a vehicle on the island from an organisation accredited by the Fraser Coast 4WD Operators Association must attend a one-hour-long briefing on vehicle safety.		"Central Station", which was formerly the hub of the forestry industry when there was logging on Fraser Island, is now a popular tourist destination. Some of the rarest ferns grow in the rainforest near the location.		The island can be reached by a ferry from River Heads (South of Hervey Bay) to Kingfisher Bay and Wanggoolba Creek or Inskip Point to north of Rainbow Beach to Hook Point, or by chartered flight from Maroochydore Airport.[64]		A four-wheel drive is required for all landings (except Kingfisher Bay), and travel on the island (except within the Kingfisher Bay Resort). A permit is required for vehicles and is obtainable on-line from DERM and several outlets at Rainbow Beach. Several firms provide four-wheel drive vehicles for hire.[65] Tour buses travel the island as well as several kinds of self-drive tours departing regularly from Hervey Bay, Rainbow Beach and Noosa.[66]		Tailor is one of the more common species sought by anglers on Fraser Island and along the Queensland coast. Other fish caught on the eastern coast include jewfish, golden trevally and surf bream, while whiting, flathead and surf bream prefer the calmer western waters.[19] Pilchards, bloodworms, yabbies, pipi and sandworms can all be used for bait. Fishing is banned in the island's creeks and lakes.[24]		There are many campgrounds on Fraser Island with varying amenities and access. The main camping areas are: Dundubara Campground, Cathedrals on Fraser, Waddy Point campground, Central Station Tent Sites, Waddy Beach (tent only campsites), Cornwells Break (large group site), One Tree Rocks camp zone (Eurong-One Tree Rocks), however there are others. Permits are required for camping and also for vehicle access.[67]		There are various possibilities for overnight hiking on the island. Most notable is the 90 km long Fraser Island Great Walk. A shorter hike would be for example to start in Kingfisher Bay (ferry drop off) and head to Lake McKenzie, stay there for one night, and then hike back.[citation needed]		
Convolvulus pes-caprae L. Ipomoea biloba Forssk.[1]		Ipomoea pes-caprae, also known as bayhops, beach morning glory or goat's foot, is a common pantropical creeping vine belonging to the family Convolvulaceae. It grows on the upper parts of beaches and endures salted air. It is one of the most common and most widely distributed salt tolerant plants and provides one of the best known examples of oceanic dispersal. Its seeds float and are unaffected by salt water.		Originally described by Linnaeus, it was placed in its current genus by Robert Brown in 1818.						This species can be found on the sandy shores of the tropical Atlantic, Pacific, and Indian Oceans. Goat's Foot is common on the sand dunes of Australia's upper north coast of New South Wales, and can also be found along the entire Queensland coastline.		Goat's Foot is a primary sand stabilizer, being one of the first plants to colonise the dune. It grows on almost all parts of the dune but is usually found on the seaward slopes, sending long runners down towards the toe of the dune. The sprawling runners spread out from the woody rootstock, but the large two-lobed leaves are sparse and a dense cover on the sand is rarely achieved except in protected situations. This plant grows in association with sand spinifex grass and is a useful sand binder, thriving under conditions of sand blast and salt spray.		Community species: Ipomoea pes-caprae has been observed in community situations, studied for their endurance of difficult growing conditions (on dunes) with some other tough species.		Together with Melanthera biflora, Portulaca oleracea and Digitaria ciliaris, Ipomoea pes-caprae is usually one of the first species colonizing degraded or altered environments in tropical zones of the planet.[3]		In Australia, it is a commonly used aboriginal medicine used as poultice for sting ray and stone fish stings.[4]		In Brazil, this plant – namely the subspecies brasiliensis – is known as salsa-da-praia in folk medicine, and is used to treat inflammation and gastrointestinal disorders.		In the Philippines, the plant is known locally as Bagasua and is used to treat rheumatism, colic, oedema, whitlow, and piles.[5]		Vines on a pebble beach		Beach morning glory in Malaysia		Beach morning glory, Muzhappilangad Beach		Beach morning glory, Muzhappilangad Beach		Beach morning glory, Muzhappilangad Beach		Beach morning glory, Muzhappilangad Beach		Beach morning glory, Muzhappilangad Beach				
Coastal management is defence against flooding and erosion, and techniques that stop erosion to claim lands.[1]		Coastal zones occupy less than 15% of the Earth's land area, while they host more than 40% of the world population. Nearly 1.2 billion people live within 100 km of a shoreline and 100 m of sea level, with an average density nearly 3 times higher than the global average for population.[2] With three-quarters of the world population expected to reside in the coastal zone by 2025, human activities originating from this small land area will impose heavy pressure on coasts. Coastal zones contain rich resources to produce goods and services and are home to most commercial and industrial activities.		In the European Union, almost half of the population lives within 50 kilometres of the sea and coastal resources produce much of the Union's economic wealth. The fishing, shipping and tourism industries all compete for space along Europe's estimated 89,000 km of coastline and coastal zones contain some of Europe's most fragile and valuable natural habitats.		Protection against sea level rise in the 21st century will be especially important, as sea level rise accelerates. Changes in sea level damage beaches and coastal systems. Coastal sediments are disturbed and suspended by wave and tide energy.		Coastal engineering of harbours began with the origin of maritime traffic, perhaps before 3500 B.C. Docks, breakwaters and other harbour works were built by hand, often in a grand scale.		Ancient harbour works are still visible. Most of the grander ancient harbor works disappeared following the fall of the Western Roman Empire.		Most coastal efforts were directed to port structures. Venice and its lagoon is an example of measures not related to ports. Protection of the shore in Italy, England and the Netherlands began in the 6th century or earlier. The ancients understood phenomena such as Mediterranean currents and wind patterns and the wind-wave cause-effect link.		The Romans introduced many innovations in harbor design. They built walls underwater and constructed solid breakwaters. In some cases wave reflection was used to prevent silting. They used surface-height breakwaters to trip the waves before they reached the main breakwater. They were the first dredgers in the Netherlands to maintain the harbour at Velsen. Silting problems there were solved when the previously sealed solid piers were replaced with new "open"-piled jetties.		Attack from the sea caused many coastal towns and their harbours to be abandoned. Other harbours were lost due to natural causes such as rapid silting, shoreline advance or retreat, etc. The Venetian Lagoon was one of the few populated coastal areas with continuous prosperity and development where written reports document the evolution of coastal protection works.		Little improvement took place beyond the Roman approach to harbour construction after the Renaissance. Then in the early 19th century, the advent of the steam engine, the search for new lands and trade routes, the expansion of the British Empire through her colonies, and other influences, all contributed to the revitalization of sea trade and a renewed interest in port works.		Prior to the 1950s, the general practice was to use hard structures to protect against beach erosion or storm damages. These structures included seawalls and revetments or sand-trapping structures such as groynes. During the 1920s and '30s, private or local community interests protected many coastal areas using these techniques on an ad hoc basis. In certain resort areas, structures proliferated to such an extent that the protection impeded recreational uses. Erosion continued, but the structures remained, resulting in a loss of beach area.		The obtrusiveness and cost of these structures led in the late 1940s and early 1950s, to a more dynamic approach. Projects attempted to replicate the protective characteristics of natural beach and dune systems. The resultant use of artificial beaches and stabilized dunes as an engineering approach was economically viable and more environmentally friendly.		Limited knowledge of coastal sediment transport processes often resulted in inappropriate measures of coastal erosion mitigation. In many cases, measures worked locally, but exacerbated problems at other locations -up to tens of kilometers away- or generated other environmental problems.		The essential source on coastal engineering is the European Code of Conduct for Coastal Zones issued by the European Council in 1999. This document was prepared by the Group of Specialists on Coastal Protection and underlies national legislation and practice.		The Group of Specialists originated in 1995, pursuant to a decision by the Committee of Ministers of the Council of Europe. It emphasized the need for integrated management and planning, but that coastal areas continued to deteriorate. The Group claimed that this was due to difficulties in implementing the concept of "integrated management". The Group proposed that the Council of Europe, cooperate with the Coastal & Marine Union (EUCC) and United Nations Environment Programme (UNEP).		Five generic strategies are involved in coastal defense:[3]		The choice of strategy is site-specific, depending on pattern of sea-level change, geomorphological setting, sediment availability and erosion, as well as social, economic and political factors.		Alternatively, integrated coastal zone management approaches may be used to prevent development in erosion- or flood-prone areas, reducing the need to address the changes. Growth management can be a challenge for local authorities who must provide the infrastructure required by new residents.[4]		Managed retreat is an alternative to constructing or maintaining coastal structures. Managed retreat allows an area to erode. Managed retreat is often a response to a change in sediment budget or to sea level rise. The technique is used when the land adjacent to the sea is low in value. A decision is made to allow the land to erode and flood, creating new shoreline habitats. This process may continue over many years.		The earliest managed retreat in the UK was an area of 0.8 ha at Northey Island flooded in 1991. This was followed by Tollesbury and Orplands in Essex, where the sea walls were breached in 1995.[5] In the Ebro Delta (Spain) coastal authorities planned a managed retreat.[6]		The main cost is generally the purchase of land to be abandoned. Relocation compensation may be needed. Human-made structures that will be engulfed by the sea may need to be removed. In some cases, armouring is used to protect land beyond the area to be flooded. Costs may be lowest if existing defences are left to fail naturally, but the realignment project may be more actively managed, for example by creating an artificial breach in existing defences to allow the sea in at a particular place in a controlled fashion, or by pre-forming drainage channels for created salt-marsh.		Holding the line typically involves shoreline hardening techniques, e.g., using permanent concrete and rock constructions. These techniques--seawalls, groynes, detached breakwaters, and revetments—represent more than 70% of protected shoreline in Europe.		Alternatively, soft engineering techniques supporting natural processes and relying on natural elements such as dunes and vegetation can prevent erosive forces from reaching the back-shore. These techniques include beach nourishment and sand dune stabilisation.		Historically coastal strategies were heavily based on static structures, while coastal areas otherwise reflect a dynamic equilibrium.[7] Armouring often has the unintended consequence of moving the problem to another part of the coast. Soft options such as beach nourishment protect coastlines and help to restore the natural dynamism, although they require repeated applications. Maintenance costs can eventually require a strategy change.		In some cases a seaward strategy can be adopted. Examples from erosion include: Koge Bay (Dk), Western Scheldt estuary (Nl), Chatelaillon (Fr) and Ebro delta (Sp).[3]		There is an obvious downside to this strategy. Coastal erosion is already widespread, and there are many coasts where exceptional high tides or storm surges result in encroachment on the shore, impinging on human activity. If the sea rises, many coasts that are developed with infrastructure along or close to the shoreline will be unable to accommodate erosion. They will experience a so-called "coastal squeeze" whereby ecological or geomorphological zones that would normally retreat landwards encounter solid structures and can migrate no further. Wetlands, salt marshes, mangroves and adjacent fresh water wetlands are particularly vulnerable to such a squeeze.		An upside to the strategy is that moving seaward (and upward) can create land of high value which can bring investment.		Limited intervention is an action taken whereby the management only addresses the problem to a certain extent, usually in areas of low economic significance. Limited intervention often includes the succession of haloseres, including salt marshes and sand dunes. This normally results in protecting the land behind the halosere, as wave energy dissipates throughout the accumulated sediment and additional vegetation in the new habitat. Although the halosere is not strictly man-made, as many natural processes contribute to the succession, anthropogenic factors are partially responsible for the formation, since an initial factor was needed to help start the process of succession.		Groynes are barriers or walls perpendicular to the coastline, often made of greenharts, concrete, rock or wood. Material builds up on the downdrift side, where littoral drift is predominantly in one direction, creating a wider and a more plentiful beach, thereby protecting the coast because the sand material filters and absorbs wave energy. However, there is a corresponding loss of beach material on the updrift side, requiring another groyne there. Groynes do not protect the beach against storm-driven waves and if placed too close together create currents that carry material offshore.		Groynes are cost-effective, require little maintenance and are one of the most common defences. However, groynes are increasingly viewed as detrimental to the aesthetics of the coastline and face opposition in many coastal communities.[8]		Groynes can be considered a "soft" solution because of the beach enhancement.		Groyne construction creates a problem known as terminal groyne syndrome. The terminal groyne prevents longshore drift from bringing material to other nearby places. This is a problem along the Hampshire and Sussex coastline in the UK; e.g., at Worthing.		Walls of concrete or rock, are used to protect a settlement against erosion or flooding. They are typically about 3–5 metres (10–16 ft) high. Older-style vertical seawalls reflected all the energy of the waves back out to sea, and for this purpose were often given recurved crest walls which increased local turbulence, and thus increased entrainment of sand and sediment. During storms, sea walls help longshore drift.		Modern seawalls aim to re-direct most of the incident energy in the form of sloping revetments, resulting in low reflected waves and much reduced turbulence. Designs use porous designs of rock, concrete armour (Seabees, SHEDs, Xblocs) with flights of steps for beach access.		The location of a seawall, must consider the swept prism of the beach profile, the consequences of long-term beach recession and amenity crest level, including cost implications.		Sea walls can cause beaches to dissipate. Their presence also alters the landscape that they are trying to protect.		Modern examples can be found at Cronulla (NSW, 1985-6),[9] Blackpool (1986–2001),[10] Lincolnshire (1992–1997)[11] and Wallasey (1983–1993).[12] At Sandwich, Kent the Seabee seawall is buried at the back of the beach under the shingle with crest level at road kerb level.		Sea walls typically cost £10,000 per metre (depending on material, height and width), £10,000,000 per km (depending on material, height and width).[citation needed]		Revetments are slanted or upright blockades, built parallel to the coast, usually towards the back of the beach to protect the area beyond. The most basic revetments consist of timber slants with a possible rock infill. Waves break against the revetments, which dissipate and absorb the energy. The shoreline is protected by the beach material held behind the barriers, as the revetments trap some of the material. They may be watertight, covering the slope completely, or porous, to allow water to filter through after the wave energy has been dissipated. Most revetments do not significantly interfere with transport of longshore drift. Since the wall absorbs energy instead of reflecting, the surf progressively erodes and destroys the revetment; therefore, maintenance is ongoing, as determined by the structural material and product quality.		Rock armour is large rocks placed at the sea edge using local material. This is generally used to absorb wave energy and hold beach material. Although effective, this solution is unpopular for aesthetic reasons. Longshore drift is not hindered. Rock armour has a limited lifespan, is not effective in storm conditions and reduces recreational values.		Boulders and rocks are wired into mesh cages and placed in front of areas vulnerable to erosion: sometimes at cliffs edges or at right angles to the beach. When the ocean lands on the gabion, the water drains through leaving sediment, while the structure absorbs a moderate amount of wave energy.		Gabions need to be securely tied to protect the structure.		Downsides include wear rates and visual intrusiveness.		Concrete blocks and/or boulders are sunk offshore to alter wave direction and to filter wave and tide energy. The waves break further offshore and therefore lose erosive power. This leads to wider beaches, which further absorb wave energy. Dolos has replaced the use of concrete blocks because it is more resistant to wave action and requires less concrete to produce a superior result. Similar concrete objects like Dolos are A-jack, Akmon, Xbloc, Tetrapod and Accropode.		Cliff stabilization can be accomplished through drainage of excess rainwater of through terracing, planting and wiring to hold cliffs in place.		Training walls are built to constrain a river or creek as it discharges across a sandy coastline. The walls stabilise and deepen the channel which benefits navigation, flood management, river erosion and water quality, but can cause coastal erosion by interrupting longshore drift. One solution is a sand bypassing system to pump sand under/around the training walls.		Storm surge barriers, or floodgates, were introduced after the North Sea Flood of 1953 and prevent damage from storm surges or any other type of natural disaster that could harm the area they protect. They are habitually open and allow free passage, but close under threat of a storm surge. The Thames Barrier is an example of such a structure.		Beach replenishment/nourishment involves importing sand from elsewhere and adding it to the existing beach. The imported sand should be of a similar quality to the existing beach material so it can meld with the natural local processes and without adverse effects. Beach nourishment can be used in combination with groynes. The scheme requires repeated applications on an annual or multi-year cycle.		Stabilising dunes can help protect beaches by catching windblown sand, increasing natural beach formation. Dune stabilisation/sand dune management employs public amenities such as car parks, footpaths, Dutch Ladders and boardwalks to reduce erosion and the removal of sand by humans. Noticeboards, leaflets and beach wardens explain to visitors how to avoid damaging the area. Beach areas can be closed to the public to reduce damage. Fences can allow sand traps to create blowouts and increase windblown sand capture. Plants such as Ammophila (Marram grass) can bind the sediment.		Beach drainage or beach face dewatering lowers the water table locally beneath the beach face. This causes accretion of sand above the drainage system.[13]		Beach watertables have an important bearing on deposition/erosion across the foreshore.[14] In one study a high watertable coincided with accelerated beach erosion, while a low watertable coincided with pronounced aggradation of the foreshore. A lower watertable (unsaturated beach face) facilitates deposition by reducing flow velocities during backwash and prolonging laminar flow. With the beach in a saturated state, backwash velocity is accelerated by the addition of groundwater seepage out of the beach within the effluent zone.		However, no case studies provide indisputable evidence of positive results, although in some cases overall positive performance was reported. Long-term monitoring was not undertaken at a frequency high enough to discriminate the response to high energy erosive events.		A useful side effect of the system is that collected seawater is relatively pure because of sand's filtration effect. Such water may be discharged or be used to oxygenate stagnant inland lagoons/marinas or used as feed for heat pumps, desalination plants, land-based aquaculture, aquariums or swimming pools.		Beach drainage systems have been installed in many locations around the world to halt and reverse erosion trends in sand beaches. Twenty four beach drainage systems have been installed since 1981 in Denmark, USA, UK, Japan, Spain, Sweden, France, Italy and Malaysia.		The costs of installation and operation vary due to:		Coastal managers must compensate for error and uncertainty in the information regarding the erosive processes. Video-based monitoring can collect data continuously and produce analyses of shoreline processes.		Event warning systems, such as tsunami warnings and storm surge warnings, can be used to minimize the human impact of catastrophic events that cause coastal erosion. Storm surge warnings can help determine when to close floodgates.		Wireless sensor networks can aid monitoring.		Defining the shoreline is a difficult task due to its dynamic nature and the intended application.[15][16] The relevant mapping scale is dependent on the context of the investigation.[16] Generally, the coast comprises the interface between land and sea, and the shoreline is represented by the margin between the two.[17] Investigators adopt the use of shoreline indicators to represent the true shoreline position.[16]		The choice of shoreline indicator is a primary consideration. Indicators must be easily identified in the field and on aerial photography.[19] Shoreline indicators may be morphological features such as the berm crest, scarp edge, vegetation line, dune toe, dune crest and cliff or the bluff crest and toe. Alternatively, non-morphological features may be used such as water level (high water line (HWL), mean high water line) wet/dry boundary and the physical water line.[20] Figure 1 provides a sketch of the spatial relationships between commonly used shoreline indicators.		The HWL (H in Figure 1) is the most commonly used shoreline indicator because it is visible in the field, and can be interpreted on both colour and grey scale aerial photographs.[19][21] The HWL represents the landward extent of the most recent high tide and is characterised by a change in sand colour due to repeated, periodic inundation by high tides. The HWL is portrayed on aerial photographs by the most landward change in colour or grey tone.[16]		The shoreline location and its changing position over time is of fundamental importance to coastal scientists, engineers and managers.[16] [20] Shoreline monitoring campaigns provide information about historic shoreline location and movement, and about predictions of future change.[22] More specifically the position of the shoreline in the past, at present and where it is predicted to be in the future is useful for in the design of coastal protection, to calibrate and verify numerical models to assess sea level rise, map hazard zones and to regulate coastal development. The location of the shoreline also provides information regarding shoreline reorientation adjacent to structures, beach width, volume and rates of historical change.[16][20]		A variety of data sources are available for examining shoreline position. However, the availability of historical data is limited at many coastal sites and so the choice of data source is largely limited to what is available for the site at a given time.[16] Shoreline mapping techniques have become more automated. The frequent changes in technology prevented the emergence of one standard mapping approach. Each data source and associated method have capabilities and shortcomings.[23]		In the event that a study requires the shoreline position from before aerial photographs, or if the location has poor photographic coverage, historical maps provide an alternative.[23] Many errors are associated with early maps and charts. Such errors may be associated with scale, datum changes, distortions from uneven shrinkage, stretching, creases, tears and folds, different surveying standards, different publication standards and projection errors.[16] The severity of these errors depends on the accuracy of the map and the physical changes that occurred after it was made.[24] The oldest reliable source of shoreline data in the United States dates is the U.S Coast and Geodetic Survey/National Ocean Service T-sheets and dates to the early-to-mid-19th century.[25] In the United Kingdom, many pre-1750 maps and charts were deemed to be inaccurate. The founding of the Ordnance Survey in 1791 improved mapping accuracy.		Aerial photographs began to be used in the 1920s to provide topographical data. They provide a good database for compilation of shoreline change maps. Aerial photographs are the most commonly used data source because many coastal areas have extensive aerial photo coverage.[23]Aerial photographs generally provide good spatial coverage. However, temporal coverage is site specific. The interpretation of shoreline position is subjective given the dynamic nature of the coastal environment. This combined with various distortions inherent in aerial photographs can lead to significant error levels.[23] The minimisation of further errors is discussed below.		Conditions outside of the camera can cause objects in an image to appear displaced from their true ground position. Such conditions may include ground relief, camera tilt and atmospheric refraction.		Relief displacement is prominent when photographing a variety of elevations. This situation causes objects above sea level to be displaced outward from the centre of the photograph and objects below ground level to be displaced toward the centre of the image (Figure 2). The severity of the displacement is negatively associated with decreases in flight altitude and as radial distance from the centre of the photograph increases. This distortion can be minimised by photographing multiple swaths and creating a mosaic of the images. This technique creates a focus for the centre of each photograph where distortion is minimised. This error is not common in shoreline mapping as the relief is fairly constant. It is however important to consider when mapping cliffs.[23]		Ideally aerial photographs are taken so the optical axis of the camera is perfectly perpendicular to the ground surface, thereby creating a vertical photograph. Unfortunately this is often not the case and virtually all aerial photographs experience tilt up to 3°.[26] In this situation the scale of the image is larger on the upward side of the tilt axis and smaller on the downward side. Many coastal researchers do not consider this in their work.[23]		Lens distortion varies as a function of radial distance from the iso-centre of the photograph meaning that the centre of the image is relatively distortion free, but as the angle of view increases distortion. This is a significant source of error in earlier aerial photography. Such a distortion is impossible to correct for without knowing the details of the lens used to capture the image. Overlapping images can be used to resolve errors.[21]		The dynamic nature of coasts compromises shoreline mapping. This uncertainty arises because at any given time the position of the shoreline is influenced by the immediate tidal effects and a variety of long-term effects such as relative sea-level rise and along shore littoral sediment movement. This affects the accuracy of computed historic shoreline position and predictions.[22] HWL is most commonly used as a shoreline indicator. Many errors are associated with using the wet/dry line as a proxy for the HWL and shoreline. The errors of largest concern are the short-term migration of the wet/dry line, interpretation of the wet/dry line on a photograph and measurement of the interpreted line position.[19][23] Systematic errors such as the migration of the wet/dry line arise from tidal and seasonal changes. Erosion may cause the wet/dry line to migrate. Field investigations have shown that these changes can be minimised by using only summertime data.;[23] [19] Furthermore, the error bar can be significantly reduced by using the longest record of reliable data to calculate erosion rates.[19] Errors may arise due to the difficulty of measuring a single line on a photograph. For example, where the pen line is 0.13 mm thick this translates to an error of ±2.6 m on a 1:20000 scale photograph.		Beach profiling surveys are typically repeated at regular intervals along the coast in order to measure short-term (daily to annual) variations in shoreline position and beach volume.[27] Beach profiling is a very accurate source of information. However, measurements are generally subject to the limitations of conventional surveying techniques. Shoreline data derived from beach profiling is often spatially and temporally limited due to the high cost associated with that labour-intensive activity. Shorelines are generally derived by interpolating from a series of discrete beach profiles. The distance between the profiles is usually quite large, limiting the accuracy of the interpolating. Survey data is limited to smaller lengths of shoreline generally less than ten kilometres.[16] Beach profiling data is commonly available in from regional councils in New Zealand.[28]		A range of airborne, satellite and land based remote sensing techniques can provide additional, mappable data.[27] Remotely sensed data sources include:		Remote sensing techniques can be cost effective, reduce manual error and reduce the subjectivity of conventional field techniques.[29] Remote sensing is a relatively new concept, limiting extensive historical observations. Coastal morphology observations must be quantified by coupling remotely sensed data with other sources of information detailing historic shoreline position from archived sources.[22]		Video analysis provides quantitative, cost-effective, continuous and long-term monitoring beaches.[30] The advancement of coastal video systems in the twenty-first century enabled the extraction of large amounts of geophysical data from images. The data describes coastal morphology, surface currents and wave parameters. The main advantage of video analysis lies in the ability to reliably quantify these parameters with high resolution space and time coverage. This highlights their potential as an effective coastal monitoring system and an aid to coastal zone management.[31] Interesting case studies have been carried out using video analysis. One group used a video-based ARGUS coastal imaging system[30][32] to monitor and quantify the regional-scale coastal response to sand nourishment and construction of the world-first Gold Coast artificial surfing reef in Australia. Another assessed the added value of high resolution video observations for short-term predictions of near shore hydrodynamic and morphological processes, at temporal scales of meters to kilometres and days to seasons.[33]		Video analysis gives coastal zone managers the opportunity to obtain bathymetry.[34][35][36] It can be used to obtain inter-tidal topographies and sub-tidal bathymetries and measure coastal zone resilience [as in available beach volume as well as sub-tidal bar configuration]. Video-based depth estimations were applied in micro/meso tidal environments at DUCK, NC[35] and highly energetic wave climates with a macro tidal regime at Porthtowan in the United Kingdom.[36] The latter showed the application of video-based depth estimations during extreme storms.[37][38]		
A spit or sandspit is a deposition bar or beach landform off coasts or lake shores. It develops in places where re-entrance occurs, such as at a cove's headlands, by the process of longshore drift by longshore currents. The drift occurs due to waves meeting the beach at an oblique angle, moving sediment down the beach in a zigzag pattern. This is complemented by longshore currents, which further transport sediment through the water alongside the beach. These currents are caused by the same waves that cause the drift.[1]						Where the direction of the shore inland re-enters, or changes direction, for example at a headland, the longshore current spreads out or dissipates. No longer able to carry the full load, much of the sediment is dropped. This is called deposition. This submerged bar of sediment allows longshore drift or littoral drift to continue to transport sediment in the direction the waves are breaking, forming an above-water spit. Without the complementary process of littoral drift, the bar would not build above the surface of the waves becoming a spit and would instead be leveled off underwater.		Spits occur when longshore drift reaches a section of headland where the turn is greater than 30 degrees. The spit will continue out into the sea until water pressure (e.g. from a river) becomes too great to allow the sand to deposit. Vegetation may then start to grow on the spit, and the spit may become stable and often fertile. A spit may be considered a special form of a shoal. As spits grow, the water behind them is sheltered from wind and waves, and a salt marsh is likely to develop.		Wave refraction can occur at the end of a spit, carrying sediment around the end to form a hook or recurved spit.[2] Refraction in multiple directions may create a complex spit. Waves that arrive in a direction other than obliquely along the spit will halt the growth of the spit, shorten it, or eventually destroy it entirely.[2]		The sediments that make up spits come from a variety of sources including rivers and eroding bluffs, and changes there can have a major effect on spits and other coastal landforms. Activities such as logging and farming upstream can increase the sediment load of rivers, which may hurt the intertidal environments around spits by smothering delicate habitats. Roads or bulkheads built along bluffs can drastically reduce the volume of sediment eroded, so that not enough material is being pushed along to maintain the spit.		If the supply of sediment is interrupted the sand at the neck (landward end) of the spit may be moved towards the head, eventually creating an island. If the supply is not interrupted, and the spit is not breached by the sea (or, if across an estuary, the river), the spit may become a bar, with both ends joined to land, and form a lagoon behind the bar. If an island lies offshore near where the coast changes direction, and the spit continues to grow until it connects the island to the mainland, it is called a tombolo.		The end of a spit attached to land is called the proximal end, and the end jutting out into water is called the distal end.		The longest spit in the world is the Arabat Spit in the Sea of Azov. It is approximately 110 kilometres (68 mi) long.		The longest spit in a freshwater body of water is Long Point, Ontario, which extends approximately 32 km (20 mi) into Lake Erie.		Farewell Spit in New Zealand, at 32 km (20 mi), in the north-west area of South Island, is believed to be caused by the strong prevailing winds and currents, bringing sand eroded from the Southern Alps of the South Island and depositing these into Golden Bay.		A well-known spit in the UK is Spurn Point at the mouth of the Humber River; it is approximately 4.8 km (3.0 mi) long.		The Curonian Spit, off the coast of Lithuania and Kaliningrad Oblast of Russia, separates the Curonian Lagoon from the Baltic Sea; it is 98 km long (61 mi). In a similar fashion, the Vistula Spit separates the Vistula Lagoon from the Gdańsk Bay off the coast of Poland.		Zlatni Rat, a popular pebble beach jutting southward from the harbor town of Bol, on the Croatian island of Brač, is formed by Adriatic currents flowing east and west through the Hvar Channel, along the southern side of the island. The spit bends slightly west or east, changing its direction gradually, depending on the conditions of the tides and weather.		Since prehistory humans have chosen certain spit formations as sites for human habitation. In some cases, these sites have been chosen for proximity to marine resource exploitation; the Chumash Native American prehistorical settlement on the Morro Bay is one such location.[3]		
Swash, or forewash in geography, is a turbulent layer of water that washes up on the beach after an incoming wave has broken. The swash action can move beach materials up and down the beach, which results in the cross-shore sediment exchange.[1] The time-scale of swash motion varies from seconds to minutes depending on the type of beach (see Figure 1 for beach types). Greater swash generally occurs on flatter beaches.[2] The swash motion plays the primary role in the formation of morphological features and their changes in the swash zone. The swash action also plays an important role as one of the instantaneous processes in wider coastal morphodynamics.		There are two approaches that describe swash motions: (1) swash resulting from the collapse of high-frequency bores (f>0.05 Hz) on the beachface; and (2) swash characterised by standing, low-frequency (f<0.05 Hz) motions. Which type of swash motion prevails is dependent on the wave conditions and the beach morphology and this can be predicted by calculating the surf similarity parameter εb (Guza & Inman 1975):		Where Hb is the breaker height, g is gravity, T is the incident-wave period and tan β is the beach gradient. Values εb>20 indicate dissipative conditions where swash is characterised by standing long-wave motion. Values εb<2.5 indicate reflective conditions where swash is dominated by wave bores.[3]						Swash consists of two phases: uprush (onshore flow) and backwash (offshore flow). Generally uprush velocities are greater but of shorter duration compared to the backwash. Onshore velocities are at greatest at the start of the uprush and then decrease, whereas offshore velocities increase towards the end of the backwash. The direction of the uprush varies with the prevailing wind, whereas the backwash is always perpendicular to the coastline. This asymmetrical motion of swash can cause longshore drift as well as cross-shore sediment transport.[4][5]		The swash zone is the upper part of the beach between backbeach and surf zone, where intense erosion occurs during storms (Figure 2). The swash zone is alternately wet and dry. Infiltration (hydrology) (above the water table) and exfiltration (below the water table) take place between the swash flow and the beach groundwater table. Beachface, berm, beach step and beach cusps are the typical morphological features associated with swash motion. Infiltration (hydrology) and sediment transport by swash motion are important factors that govern the gradient of the beachface.[4]		The beachface is the planar, relatively steep section of the beach profile that is subject to swash processes (Figure 2). The beachface extends from the berm to the low tide level. The beachface is in dynamic equilibrium with swash action when the amount of sediment transport by uprush and backwash are equal. If the beachface is flatter than the equilibrium gradient, more sediment is transported by the uprush to result in net onshore sediment transport. If the beachface is steeper than the equilibrium gradient, the sediment transport is dominated by the backwash and this results in net offshore sediment transport. The equilibrium beachface gradient is governed by a complex interrelationship of factors such as the sediment size, permeability, and fall velocity in the swash zone as well as the wave height and the wave period. The beachface cannot be considered in isolation from the surf zone to understand the morphological changes and equilibriums as they are strongly affected by the surf zone and shoaling wave processes as well as the swash zone processes.[4][5]		The berm is the relatively planar part of the swash zone where the accumulation of sediment occurs at the landward farthest of swash motion (Figure 2). The berm protects the backbeach and coastal dunes from waves but erosion can occur under high energy conditions such as storms. The berm is more easily defined on gravel beaches and there can be multiple berms at different elevations. On sandy beaches in contrast, the gradient of backbeach, berm and beachface can be similar. The height of the berm is governed by the maximum elevation of sediment transport during the uprush.[4] The berm height can be predicted using the equation by Takeda and Sunamura (1982)		where Hb is the breaker height, g is gravity and T is the wave period.		The beach step is a submerged scarp at the base of the beachface (Figure 2). The beach steps generally comprise the coarsest material and the height can vary from several centimetres to over a metre. Beach steps form where the backwash interacts with the oncoming incident wave and generate vortex. Hughes and Cowell (1987) proposed the equation to predict the step height Zstep		where 'ws' is the sediment fall velocity. Step height increases with increasing wave (breaker) height (Hb), wave period (T) and sediment size.[4]		The beach cusp is a crescent-shaped accumulation of sand or gravel surrounding a semicircular depression on a beach. They are formed by swash action and more common on gravel beaches than sand. The spacing of the cusps is related to the horizontal extent of the swash motion and can range from 10 cm to 50 m. Coarser sediments are found on the steep-gradient, seaward pointing ‘cusp horns’ (Figure 3). Currently there are two theories that provide an adequate explanation for the formation of the rhythmic beach cusps: standing edge waves and self-organization.[4]		The standing edge wave theory, which was introduced by Guza and Inman (1975), suggests that swash is superimposed upon the motion of standing edge waves that travel alongshore. This produces a variation in swash height along the shore and consequently results in regular patterns of erosion. The cusp embayments form at the eroding points and cusp horns occur at the edge wave nodes. The beach cusp spacing can be predicted using the sub-harmonic edge wave model		where T is incident wave period and tanβ is beach gradient.		This model only explains the initial formation of the cusps but not the continuing growth of the cusps. The amplitude of the edge wave reduces as the cusps grow, hence it is a self-limiting process.[4]		The self-organization theory was introduced by Werner and Fink (1993) and it suggests that beach cusps form due to a combination of positive feedback that is operated by beach morphology and swash motion encouraging the topographic irregularity and negative feedback that discourages accretion or erosion on well-developed beach cusps. It is relatively recent that the computational resources and sediment transport formulations became available to show that the stable and rhythmic morphological features can be produced by such feedback systems.[4] The beach cusp spacing, based on the self-organization model, is proportional to the horizontal extent of the swash motion S using the equation		where the constant of proportionality f is c. 1.5.		The cross-shore sediment exchange, between the subaerial and sub-aqueous zones of the beach, is primarily provided by the swash motion.[6] The transport rates in the swash zone are much higher compared to the surf zone and suspended sediment concentrations can exceed 100 kg/m3 close to the bed.[4] The onshore and offshore sediment transport by swash thus plays a significant role in accretion and erosion of the beach.		There are fundamental differences in sediment transport between the uprush and backwash of the swash flow. The uprush, which is mainly dominated by bore turbulence, especially on steep beaches, generally suspend sediments to transport. Flow velocities, suspended sediment concentrations and suspended fluxes are at greatest at the start of the uprush when the turbulence is maximum. Then the turbulence dissipates towards the end of the onshore flow, settling the suspended sediment to the bed. In contrast, the backwash is dominated by the sheet flow and bedload sediment transport. The flow velocity increases towards the end of the backwash causing more bed-generated turbulence, which results in sediment transport near the bed. The direction of the net sediment transport (onshore or offshore) is largely governed by the beachface gradient.[5]		Longshore drift by swash occurs either due to beach cusp morphology or due to oblique incoming waves causing strong alongshore swash motion. Under the influence of longshore drift, when there is no slack-water phase during backwash flows, sediments can remain suspended to result in offshore sediment transport. Beachface erosion by swash processes is not very common but erosion can occur where swash has a significant alongshore component.		The swash zone is highly dynamic, accessible and susceptible to human activities. This zone can be very close to developed properties. It is said that at least 100 million people on the globe live within one meter of mean sea level.[7] Understanding the swash zone processes and wise management is vital for coastal communities which can be affected by coastal hazards, such as erosion and storm surge. It is important to note that the swash zone processes cannot be considered in isolation as it is strongly linked with the surf zone processes. Many other factors, including human activities and climate change, can also influence the morphodynamics in the swash zone. Understanding the wider morphodynamics is essential in successful coastal management.		Construction of sea walls has been a common tool to protect developed property, such as roads and buildings, from coastal erosion and recession. However, more often than not, protecting the property by building a seawall does not achieve the retention of the beach. Building an impermeable structure such as a seawall within the swash zone can interfere with the morphodynamics system in the swash zone. Building a seawall can raise the water table, increase wave reflection and intensify turbulence against the wall. This ultimately results in erosion of the adjacent beach or failure of the structure.[8] Boulder ramparts (also known as revetments or riprap) and tetrapods are less reflective than impermeable sea walls, as waves are expected to break across the materials to produce swash and backwash that do not cause erosion. Rocky debris is sometimes placed in front of a sea wall in the attempt to reduce the wave impact, as well as to allow the eroded beach to recover.[9]		Understanding the sediment transport system in the swash zone is also vital for beach nourishment projects. Swash plays a significant role in transportation and distribution of the sand that is added to the beach. There have been failures in the past due to inadequate understanding.[9] Understanding and prediction of the sediment movements, both in the swash and surf zone, is vital for the nourishment project to succeed.		The coastal management at Black Rock, on the north-east coast of Phillip Bay, Australia, provides a good example of a structural response to beach erosion which resulted in morphological changes in the swash zone. In the 1930s, a sea wall was built to protect the cliff from recession at Black Rock. This resulted in depletion of the beach in front of the sea wall, which was damaged by repeated storms in winter time. In 1969, the beach was nourished with approximately 5000m3 of sand from inland in order to increase the volume of sand on the beach to protect the sea wall. This increased the sand volume by about 10%, however, the sand was carried away by northward drifting in autumn to leave the sea wall exposed to the impacts of winter storms again. The project had failed to take the seasonal patterns of longshore drift into account and had underestimated the amount of sand to nourish with, especially on the southern part of the beach.[9]		It is said that conduct of morphology research and field measurements in the swash zone is challenging since it is a shallow and aerated environment with rapid and unsteady swash flows.[5][10] Despite the accessibility to the swash zone and the capability to take measurements with high resolution compared to the other parts of the nearshore zone, irregularity of the data has been an impediment for analysis as well as critical comparisons between theory and observation.[5] Various and unique methods have been used for field measurements in the swash zone. For wave run-up measurements, for example, Guza and Thornton (1981, 1982) used an 80m long dual-resistance wire stretched across the beach profile and held about 3 cm above the sand by non-conducting supports. Holman and Sallenger (1985) conducted run-up investigation by taking videos of the swash to digitise the positions of the waterline over time. Many of the studies involved engineering structures, including seawalls, jetties and breakwaters, to establish design criteria that protect the structures from overtopping by extreme run-ups.[2] Since the 1990s, swash hydrodynamics have been more actively investigated by coastal researchers, such as Hughes M.G., Masselink J. and Puleo J.A., contributing to the better understanding of the morphodynamics in the swash zone including turbulence, flow velocities, interaction with the beach groundwater table, and sediment transport. However, the gaps in understanding still remain in swash research including turbulence, sheet flow, bedload sediment transport and hydrodynamics on ultra-dissipative beaches.[5]		Swash plays an important role as one of the instantaneous coastal processes and it is as important as the long-term processes such as sea level rise and geological processes in coastal morphodynamics. Swash zone is one of the most dynamic and rapidly changing environments on the coast and it is strongly linked with the surf zone processes. Understanding the swash mechanism is essential for the understanding of formation and changes of the swash zone morphology. More importantly, understanding of the swash zone processes is vital for society to manage coast wisely. There has been significant progress in the last two decades, however, gaps in understanding and knowledge in swash research still remain today.		
Toplessness refers to the state in which a female's torso is exposed above her waist or hips, or with at least her breasts, areola, and nipples being exposed, especially in a public place or in a visual medium. The male equivalent is barechestedness, also commonly called shirtlessness.		In the past and in some cases until the present, social conventions and concepts of modesty in some cultures required females to completely cover their bodies below the neck, and sometimes above as well. Exposure of the torso, breasts, midriff and navel were especially taboo. While exposed breasts were and are normal in many indigenous societies, most First World cultures today have formal or informal dress codes, legal statutes, or religious teachings that require females to cover their breasts in public from adolescence onward. Contemporary Western cultures permit displays of cleavage in appropriate social contexts, but exposing the areola and nipples is usually regarded as immodest and is sometimes prosecuted as indecent exposure, lewd, or even disorderly conduct. The topfreedom movement challenges laws that forbid females to go topless in places where males are permitted to be barechested, arguing that such restrictions amount to gender discrimination.		Toplessness is more common and less controversial in the fields of entertainment, fashion, and the arts than it is in society as a whole, especially when it is perceived to have artistic merit. From early prehistoric art to the present day, women have been depicted topless in visual media from painting and sculpture to film and photography. In contemporary mainstream cinema, Academy Award–winning actresses such as Halle Berry, Kate Winslet, and Nicole Kidman have appeared topless in their films. Cabaret and burlesque shows, as well as haute couture fashion shows and pictorials, frequently include toplessness or see-through clothing.		Societies tend to view more unfavourably exposure of women's breasts in public if the intent is sexual arousal. Toplessness in adult entertainment, such as in strip clubs or in softcore pornography, is regarded by some as indecent and is subject to more stringent government regulation or prohibitions.		Public toplessness may occasionally be considered acceptable, depending on location and context. Many jurisdictions legally protect women's right to breastfeed in public or exempt breastfeeding from public indecency laws. In many parts of Europe and Australia, as well as at many resort destinations around the world, it has become culturally and often legally acceptable for women to sunbathe topless on beaches. Topless sunbathing may also be permitted in non-beach areas, such as some European parks and lakes, designated areas on some cruise ships, and swimming pools at some hotels.						The word "topless" usually refers to a woman who is naked above her waist or hips or, at least, whose breasts are exposed to public view, specifically including her areola and nipples. It can describe a woman who appears, poses, or performs with at least her breasts exposed, such as a "topless model" or "topless dancer", or to an activity undertaken while not wearing a top, such as "topless sunbathing". It may indicate a designated location where one might expect to find women not wearing tops, such as a "topless beach" or "topless bar". It can also be used to describe a garment that is specifically designed to reveal the breasts, such as the "topless swimsuit" (also known as the monokini) designed by Rudi Gernreich in the 1960s.[1]		The word "topless" may carry sexual or exhibitionist connotations. Because of this, advocates of women's legal right to uncover their breasts wherever men may go bare-chested have adopted the alternative term "topfree", which is not perceived to have these connotations.[2]		Attitudes towards toplessness have varied considerably across cultures and over time. The lack of clothing above the waist for both females and males was the norm in traditional cultures of North America, Africa, Australia and the Pacific Islands until the arrival of Christian missionaries, and it continues to be the norm in many indigenous cultures today. The practice was also the norm in various Asian cultures before Muslim expansion in the 13th and 14th centuries.[3]		In many parts of northern India before the Muslim conquest of India, upper-class women in Maharashtra and the Ganges basin were fully clothed, while lower-class women were topless.[4][5] Malayali people of Kerala required women other than Brahmins and Kshatriya class to strip to waist in public until 1858 when the Kingdom of Travancore granted all women the right to cover their breasts in public.[6]		Toplessness was the norm for women among several indigenous peoples of South India until the 19th or early 20th century, including the Tamils along the Coromandel Coast, Tiyan and other peoples on the Malabar Coast, Kadar of Cochin Island, Toda, Nayar, Cheruman (Pulayar), Kuruba, Koraga, Nicobarese, and the Uriya.[7]		In Thailand, the government of Field Marshal Plaek Pibulsonggram issued a series of cultural standards between 1939 and 1942. Mandate 10 issued on 8 September 1941 instructed Thai people to not appear in public places "without being appropriately dressed". Inappropriate dress included "wearing no shirt or wearing a wraparound cloth".[8][9] Before the introduction of Western dress codes, Thai women were depicted both fully clothed and topless in public. Until the early 20th century, women from northern Thailand wore a long tube-skirt (Pha-Sin), tied high above their waist and below their breasts, which were uncovered. In the late 19th century the influence of missionaries and modernization under King Chulalongkorn encouraged local women to cover their breasts with blouses.[10]		In Laos, Henri Mouhot took a picture in 1858 of Laotian women depicting virgins with clothed breasts and married women who revealed whole breasts in public, because the breast functioning for breastfeeding was considered to be nonsexual.[11]		In the Indonesian region, toplessness was the norm among the Dayak, Javanese, and the Balinese people of Indonesia before the introduction of Islam and contact with Western cultures. In Javanese and Balinese societies, women had gone topless to work or rest comfortably. Among the Dayak, only bi- breasted women or married women with sagging breasts covered their breasts because their breasts interfered with their work.[7][clarification needed]		In most Middle Eastern countries, toplessness has not been socially accepted since at least the beginning of Islam (7th century), because of Islamic standards for female modesty. However, toplessness was the norm in earlier cultures within Arabia, Egypt, Assyria and Mesopotamia. Tunisia and Egypt are an exception among Arabic states, allowing foreign tourists to swim topless on private beaches.[12]		Among Himba women of northern Namibia and Hamar of southern Ethiopia, besides other traditional groups in Africa, the social norm is for women to be bare-breasted. Female toplessness can also constitute an important aspect of indigenous cultural celebrations. For example, in the annual Reed Dance festival mature girls between the ages of 16 and 20 dance topless before the Zulu king.[13]		Traditional topless practices can lead to cross-cultural and legal conflict. In 2004, Australian police banned members of the Papunya community from using a public park in the city of Alice Springs to practice a traditional Aboriginal dance that included topless women.[14]		In the South Pacific, toplessness was common prior to contact with Western missionaries, but is less common today. On the French territory of Moorea, toplessness is common.[15] In the Marshall Islands, women were traditionally topless before contact with Western missionaries and still do not sexually objectify female breasts as is common in much of Western society.[16] Marshall Island women typically swim in their muumuus which today are made of a fine polyester that dries quickly.[17] Wearing of bikinis and one-piece, breast-covering swimsuits in the Marshall Islands is mainly seen at Western, restricted-access beaches and swimming pools like those at private resorts or on United States government facilities on the Kwajalein Atoll within the Ronald Reagan Ballistic Missile Defense Test Site.[18][19]		In much of contemporary Western society, it is not culturally acceptable for women to expose their nipples and areola in public. In most Western societies, once girls enter adolescence, it is the social norm for them to behave modestly and cover their breasts in public. Until recent times, women who went topless were cited for indecent exposure or lewd. Women and the law in most western countries generally do not regard breasts as indecent. However, wearing a top in public is a social norm and most women are reluctant to go against it. The strictness of the etiquette varies depending on the social context. For example, at specific cultural events the norm may be relaxed, such as at the Mardi Gras in New Orleans and Carnaval in Rio de Janeiro. The same may also apply at a designated topless beach.		In many European societies between the Renaissance and the 19th century, exposed breasts were acceptable while a woman's bared legs, ankles or shoulders were considered risqué.[20] During the Renaissance, many artists were strongly influenced by classical Greek styles and culture,[21] and images of nude and semi-nude subjects in many forms proliferated in art, sculpture and architecture of the period.[21] In aristocratic and upper-class circles the display of breasts also invoked associations with classical Greek nude sculptures and art and a classic breast shape was at times regarded as a status symbol, as a sign of beauty, wealth or social position. To maintain youthful-looking bosoms women could employ wet nurses to breastfeed their children.[22]		Breast-baring female fashions have been traced to 15th-century courtesan Agnès Sorel, mistress to Charles VII of France, whose gowns in the French court sometimes exposed one or both of her breasts. (Jean Fouquet's portrayal of the Virgin Mary with her left breast uncovered is believed to have taken Sorel as a model.) Aristocratic women sought to immortalise their breasts in paint, as in the case of Simonetta Vespucci, whose portrait with exposed breasts was painted by Piero di Cosimo in c.1480. During the 16th century, women's fashions displaying their breasts were common in society, from Queens to common prostitutes, and emulated by all classes.[23]		Similar fashions became popular in England during the 17th century when they were worn by Queen Mary II and by Henrietta Maria, wife of Charles I of England, for whom architect Inigo Jones designed a masque costume that fully revealed both of her breasts.[21]		In a survey of 190 different societies, researches found that very few associated exposed breasts with sexuality, but that there was an insistence that women conceal their breasts.[24] Different standards apply to art, with one example being the dome of the United States Capitol featuring an 1865 fresco depicting goddesses with their breasts exposed.[citation needed]		Although some social attitudes to increased body exposure began to soften during the late 1960s, contemporary Western societies still generally view toplessness unfavorably. During a short period in 1964, "topless" dress designs appeared at fashion shows, but those who wore the dresses in public found themselves arrested on indecency charges.[25] However, toplessness has come to be a feature in contemporary haute couture fashion shows.		A wide-ranging review of 190 different societies during 1951 found that few insisted that women conceal their breasts. In Europe, topless swimming and sunbathing on public beaches has become socially acceptable. In 1994-95, Australian researchers asked 118 college-age students to rate the behavior of women who go topless on an 8-point scale, ranging from "Women should have the same right to topless as men" to "Topless women are exhibitionists". They found that 88% of Australian university students of either gender considered it acceptable for women to go topless on public beaches, although they felt that women exposing their breasts in other contexts, such as public parks, was inappropriate.[24][27] They did not find a correlation between exposed breasts and sexuality in social situations.		A more recent study of 116 college-age women in Australia found that those who had gone topless were more accepting of toplessness generally, more sexual, and had higher self-esteem and higher body image.[24] In contemporary society, the extent to which a woman may expose her breasts depends on social and cultural context. Women's swimsuits and bikinis commonly reveal the tops and sides of the breasts. Displaying cleavage is considered permissible in many settings, and is even a sign of elegance and sophistication on many formal social occasions, but it may be prohibited by dress codes in settings such as workplaces and schools, where sexualized displays of the female breast may be considered inappropriate. In a number of cultures, including Europe and other Westernized countries outside the United States, there are fewer social restrictions against sunbathing or swimming topless.[28]		An online poll found that 99% of Germans and 93% of Britons were accepting of toplessness on a beach, compared to 92% of Swedes, 91% of Italians, and 67% of Russians.[29] In Canada, a poll in 1992 found that 38% favored general female public toplessness. Following that survey, several legal rulings in Canadian courts from 1996 to 2000 made public toplessness legal, but very few women go topless in public.[30]		Some cultures have even begun to expand social prohibitions on female toplessness to prepubescent and even infant girls. This trend toward covering the female nipple from infancy onward is particularly noticeable in the United States, Eastern Asia and the Middle East, but is much less common in Europe.[31]		Around the world, it is common for women to breastfeed in public.[32] In the United States during the 1990s and later, there were a number of legal incidents where women were harassed or cited for exposing their breasts while breastfeeding in public. A public backlash spurred legislators in some jurisdictions to specifically legalize public breastfeeding. The federal government passed a law in 1999 that specifically provides that "a woman may breastfeed her child at any location in a Federal building or on Federal property, if the woman and her child are otherwise authorized to be present at the location."[33] Some women have engaged in acts of "lactivism", or acts of politically motivated public breastfeeding, to assert these rights.[34]		In many indigenous, non-Western cultures it is generally acceptable for both men and women to go without clothing that covers the torso. Female toplessness can also be a traditional aspect in indigenous cultural celebrations. However, this can lead to cross-cultural and legal conflict. During 2004, Australian police banned female members of the Papunya community from using a public park in the city of Alice Springs to practice a traditional Aboriginal dance while topless.[14]		Many societies consider women who expose their nipples and areola as immodest and contrary to social norms. Most jurisdictions do not have laws prohibiting toplessness directly, but in many jurisdictions a topless woman may be socially or officially harassed or cited for public lewdness, indecent exposure, public indecency or disorderly conduct.[35] Enforcement of such standards is subject to community standards, which are subject to change over time. Most prosecutions commence with a complaint being made to the police by a member of the public, and a judge would be required to adjudicate as to the indecency etc. of the exposure.		In the United States, GoTopless.org claims that women have the same constitutional right to be bare chested in public places as men. They further claim constitutional equality between men and women on being topless in public. They have successfully joined in legal challenges that have resulted in laws permitting women to expose their breasts just as men do in New York State and in Ontario, Canada. In 2009, they used 26 August (Women's Equality Day), as a day of national protest.[36] The topfreedom movement has claimed success in a few instances in persuading federal courts in the United States to overturn some state laws on the basis of sex discrimination, arguing that a woman should be free to expose her chest in any context in which a man can expose his. In March 2008, after a year-long campaign by a pressure group, the Topless Front, Copenhagen's Culture and Leisure Committee concluded that there were no regulations against topless bathing by women in public swimbaths, thus no reason to specifically allow it.[37] Also in 2008, the city council in Vancouver, British Columbia, location of the World Naked Bike Ride, gave women the right to go topless in public, not solely at swimming pools and beaches.[38]		In 2009, members of the Swedish feminist organization Bara Bröst (Just Breast or Bare Breast) went topless at the city pools in Malmö, Sweden. This triggered a vote by the city's sports and recreation committee, which backed away from requiring women to wear a top, only stipulating that everyone must wear a swimsuit. Their ruling allows women in Sweden to swim topless in Malmö's public swimming pools.[39][40] "We don't decide what men should do with their torso, why then do women have to listen to the men. Moreover, many men have larger breasts than women", the committee chair said.[41]		While an exposed breast in public can have many associated connotations, some women in America today argue the exposed breast is a symbol of liberation. They speak against the proposed notion that their rightful place was below their male counterparts. Throughout the late 20th Century, more and more women began to link the struggle for female equality and the repossession of the female body. This can be especially seen in the work of Second Wave Feminists beginning in the early 1960s.[citation needed]		The reaction to exposed breast as a symbol of liberation was two-sided. Women who took part in the movement expressed their desire to turn attention away from the excessive eroticization of the female body in American popular culture to more essential societal needs.[42] Opposition to the braless movement ironically viewed it as an attack to American morals and public decency. The bralessness movement evolved into a bare-breasted movement, which became another way for women to "thumb one's nose at society".[42] While some women exposed their breasts individually, there was also an upsurge in topless demonstrations used to gather public attention for women's issues such as pornography and sexism.[42] The sexualization of the breast is unique to only a few Western nations, and this, many women argue, causes women to turn to plastic surgery and view their breasts as determinants of beauty rather than potentially nourishing life forces.[43] Because of this, women are able to liberate their breasts as a way to gain attention, make political statements, and combat breast exposure laws' reinforcement of the supposed uncontrollable seductive nature of women's breasts.[citation needed]		In Western countries, toplessness in public often generates media coverage, leading some female political demonstrators to deliberately expose their breasts in public to draw media and public attention to their cause. For example, in January 2012, three members of the Ukrainian protest group FEMEN attracted worldwide media attention after they staged a topless protest at the World Economic Forum in Davos, Switzerland.[44]		Toplessness in a public place is most commonly practised or encountered near water, either as part of a swimming activity or sunbathing. The introduction of the bikini in 1946 and increasingly common glamour shots of popular actresses and models on either side of the Atlantic wearing the minimal swimsuit design played a large part in bringing the bikini and sunbathing into the mainstream.[45][46]		In 1964, fashion designer Rudi Gernreich went further and designed and produced a topless swimsuit, which he called the "monokini" in the United States.[47] The design was first printed by Look magazine.[48] Gernreich's monokini, consisting of only a brief, close-fitting bottom,[49] was the first women's topless swimsuit.[50] His revolutionary and controversial design included a bottom that "extended from the midriff to the upper thigh"[51] and was "held up by shoestring laces that make a halter around the neck".[52] A photograph of Peggy Moffitt, the famous model for the suit, appeared in Women's Wear Daily, Life and numerous other publications.[53]		Despite the negative reaction of fashion critics and church officials, shoppers purchased about 3000 of his swimsuit design at $24 each that summer, though the only woman to wear it to a beach in the United States was arrested.[54] The novelty of the design caught significant attention. Life writer Shana Alexander noted in an article about the introduction of the monokini in July 1964, "One funny thing about toplessness is that it really doesn't have much to do with breasts. Breasts of course are not absurd; topless swimsuits are. Lately people keep getting the two things mixed up."[55]		The topless swimsuit was not successful in the United States where only one woman wore it on a beach.[56] The Soviet government called it "barbarism" and a sign of social "decay". The New York City Police Department was strictly instructed to arrest any woman wearing a swimsuit by the commissioner of parks.[57] In Chicago, a 19-year-old female beachgoer was fined US$100 for wearing a topless swimsuit on a public beach.[57] Copious coverage of the event helped to send the image of exposed breasts across the world. Women's clubs and the church were particularly active in their condemnation.[57] In Italy and Spain, the Catholic Church warned against the topless fashion.[58] In France in 1964, Roger Frey led the prosecution of the use of the monokini, describing it as "a public offense against the sense of decency, punishable according to article 330 of the penal code. Consequently, the police chiefs must employ the services of the police so that the women who wear this bathing suit in public places are prosecuted."[59][60] At St. Tropez on the French Riviera, where toplessness later became the norm, the mayor ordered police to ban toplessness and to watch over the beach via helicopter.[57] Jean-Luc Godard, a founding mover of French New Wave cinema, incorporated a shot of a woman in a topless swimsuit on the Riviera into his film A Married Woman, but it was edited out by the censors.[61]		A number of Caribbean locations, especially those that were formerly French and Dutch colonies, permit nude and topless sunbathing, like the French West Indies islands of St. Barths, Guadeloupe, Martinique, and St. Maarten.[62]		Topless sunbathing slowly spread to other Western countries throughout Europe and Australia, many of which now allow topless sunbathing on some or all of their beaches, either through legal statute or by generally accepted practice, and beaches were designated for nude or topless bathers. A topless, or top-optional, beach differs from a nude beach in that beach goers of both sexes are required to keep their genital area covered, although females have the option to remove their tops without fearing legal prosecution or official harassment.[citation needed]		However, media reports in recent years note that the number of women sunbathing topless on French beaches has markedly declined, and that younger French women have become more disapproving of exposing breasts in public.[63] Even in some parts of Europe generally considered to have a liberal attitude towards toplessness, such as Sweden, surveys show there is considerable resistance to its acceptance.[64]		The French have traditionally been relaxed with nudity and toplessness in entertainment, and dancers and actresses performed topless during the 1910s and beyond in musical theater and cinema. Toplessness in entertainment has survived to this day at the Folies Bergère and the Moulin Rouge. Some female groups have also performed topless, such as the female group The Ladybirds, which performed topless in the 1960s.[65]		Women are also at times employed in adult-only venues to perform or pose topless in forms of commercial erotic entertainment. Such venues can range from downmarket strip clubs and topless bars to upmarket cabarets, such as the Moulin Rouge. Topless entertainment may also include competitions such as wet T-shirt contests in which women display their breasts through translucent wet fabric—and may end up removing their T-shirts in front of the audience.[citation needed]		Female toplessness has also become somewhat common during Mardi Gras in New Orleans[66] during which women "flash" (briefly expose) their breasts in return for strings of plastic beads,[67] and at Carnaval in Rio de Janeiro, where floats occasionally feature topless women.[68]		Pasties are sometimes worn by erotic dancers or burlesque entertainers to given the impression of toplessness while avoiding prosecution under local public indecency laws which prohibit exposure of the nipple and areola. To stay within the law, liquid latex pasties may be used.[69] Pasties may be worn by neo-burlesque performers and are also found in night clubs, fetish parties and parades, such as Pride Parades.		In many Western cultures today, images of topless women are regularly featured in magazines, calendars, and other print media, often covering their breasts in a handbra. In the United Kingdom, following a tradition established by the British newspaper The Sun in 1970, several mainstream tabloid newspapers feature topless female models on their third page, known as Page 3 girls. The subject of glamour photography is often a topless woman.		Although images of topless women are increasingly prevalent in Western magazines and film, images of topless girls under the age of eighteen years are controversial, and are potentially considered child pornography in some jurisdictions.[citation needed] Photographers such as Jock Sturges and Bill Henson, whose work regularly depicts topless and naked adolescent girls, have been prosecuted or been embroiled in controversy because of these images.[70] Even insinuated toplessness by minors can cause controversy.		In the 1920s, toplessness was featured in some Hollywood silent films as well as on the stage, though not without objections from various groups, and several jurisdictions in the United States and elsewhere set up film censorship boards to censor films. In the 1930s, the Hays Code brought an end to nudity in all its forms, including toplessness, in Hollywood films. To remain within the censors' guidelines or community standards of decency and modesty, actresses in an otherwise topless scene would cover their breasts, especially the nipples and areolae, with their hands (using a handbra gesture), arms, towel, pasties or some other object.		Film making in other centres were not subject to the Hays Code, but were subject to various national censorship regimes. The Italian film Era lui... sì! sì! (1951), for example, also had a French version which included topless actresses in the harem scene. This version was especially made for the French market, where censorship was less rigorous than in Italy.[71] Social and official attitudes to toplessness and nudity had eased by the 1960s and the Hays Code came under repeated challenge, and in 1968 the Code was replaced by the MPAA film rating system. For example, in Mutiny on the Bounty (1962) all Tahitian girls were topless and there was a long native dance scene, though the topless female dancers' breasts were covered by leis. The historical epic film Hawaii (1966) also featured scenes of topless native girls, with breasts being strategically covered by leis. Rapa-Nui (1994) featured repeated scenes of bare-breasted native women. Film critic Roger Ebert said the producers got away with ongoing toplessness because of the women's brown skin:		Rapa Nui slips through the National Geographic Loophole. This is the Hollywood convention which teaches us that brown breasts are not as sinful as white ones, and so while it may be evil to gaze upon a blond Playboy centerfold and feel lust in our hearts, it is educational to watch Polynesian maidens frolicking topless in the surf. This isn't sex; it's geography.[72]		Women now appear topless in mainstream cinema, although usually somewhat briefly. Besides those actresses who have appeared nude or partially nude in films, it has also become increasingly common for actresses to appear topless in movies. Notable actresses who have appeared topless include Jane Fonda (Coming Home, 1978), Julie Andrews (S.O.B., 1981), Kate Winslet (Titanic, 1997), Gwyneth Paltrow (Shakespeare in Love, 1998), Reese Witherspoon (Twilight, 1998), Rene Russo (The Thomas Crown Affair, 1999), Katie Holmes (The Gift, 2000), and Halle Berry (Swordfish, 2001). In an interview in March 2007, Halle Berry said that her toplessness in Swordfish was "gratuitous" to the movie, but that she needed to do the scene to get over her fear of nudity, and that it was the best thing she did for her career. Having overcome her inhibitions, she went on to a role in Monster's Ball, which included a nude scene and which won her an Oscar for best actress.[73] Some actresses prefer not to expose their breasts and use a body double.[74][75]		Pasties were and may still be worn by some actresses while filming an otherwise apparently topless or nude scene, which is not caught by the camera angle.		On 12 June 1964, the San Francisco Chronicle featured a woman wearing a monokini with her exposed breasts on its first page.[57] Two weeks later on 22 June 1964, the public relations manager of the Condor Club in San Francisco's North Beach district gave former prune picker, file clerk, and waitress Carol Doda Gernreich's monokini to wear for her act. Her debut as a topless dancer was featured in Playboy magazine in April 1965. Doda was the first modern topless dancer in the United States,[57]:25 renewing the burlesque era of the early 20th Century in the U.S. San Francisco Mayor John Shelley said, "topless is at the bottom of porn."[76] Within a few days, women were baring their breasts in many of the clubs lining San Francisco's Broadway St., ushering in the era of the topless bar.[76]		San Francisco public officials tolerated the topless bars until 22 April 1965, when the San Francisco Police Department arrested Doda on indecency charges. Hundreds of protesters gathered outside the police department, calling for release of both Doda and free speech activist Mario Savio, held in the same station.[76] Doda rapidly became a symbol of sexual freedom, while topless restaurants, shoeshine parlors, ice-cream stands and girl bands proliferated in San Francisco and elsewhere. Journalist Earl Wilson wrote in his syndicated column, "Are we ready for girls in topless gowns? Heck, we may not even notice them." English designers created topless evening gowns inspired by the idea.[57] The San Francisco Examiner published a real estate advertisement that promised "bare top swimsuits are possible here".[76]		The artifacts in the Ancient Siam open-air museum near Bangkok depict Thai women topless. The Ramakien Mural representing the epic lives of the Thai people found at the Wat Phra Kaew Temple depict women wearing only a skirt in public.[citation needed]		As a result of the Renaissance, in many European societies artists were strongly influenced by classical Greek styles and culture.[21] As a result, images of nude and semi-nude subjects in many forms proliferated in art and sculpture.[citation needed]		During the Victorian era, French Orientalist painters such as Jean-Léon Gérôme presented an idealized depiction of female toplessness in Muslim harem baths,[77] while Eugène Delacroix, a French romantic artist, invoked images of liberty as a topless woman.		Portrait of Simonetta Vespucci (c.1480) by Piero di Cosimo		Wild Women with Unicorn, c. 1500–1510		Portrait of a Woman by Bartolomeo Veneto, (traditionally assumed to be Lucrezia Borgia)		Liberty Leading the People (1830) by Eugène Delacroix		Blonde Woman with Bare Breasts (c.1878) by Édouard Manet		Diana the Huntress by Gaston Casimir Saint-Pierre		Harem Pool by Jean-Léon Gérôme		Portrait of a Gipsy Maiden (1870) by Carol Szathmari		In European pre-historic societies, sculptures of female figures with pronounced or highly exaggerated breasts were common. A typical example is the so-called Venus of Willendorf, one of many Venus figurines from the Paleolithic era with ample hips and bosom. Artifacts such as bowls, rock carvings and sacred statues with breasts have been recorded from 15,000 BC up to late antiquity all across Europe, North Africa and the Middle East. Many female deities representing love and fertility were associated with breasts and breast milk. Figures of the Phoenician goddess Astarte were represented as pillars studded with breasts. Isis, an Egyptian goddess who represented, among many other things, ideal motherhood, was often portrayed as suckling pharaohs, thereby confirming their divine status as rulers. Even certain male deities representing regeneration and fertility were occasionally depicted with breast-like appendices, such as the river god Hapy who was considered to be responsible for the annual overflowing of the Nile. Female breasts were also prominent in the Minoan civilization in the form of the famous Snake Goddess statuettes.[citation needed]		In Ancient Greece there were several cults worshiping the "Kourotrophos", the suckling mother, represented by goddesses such as Gaia, Hera and Artemis. The worship of deities symbolized by the female breast in Greece became less common during the first millennium. The popular adoration of female goddesses decreased significantly during the rise of the Greek city states, a legacy which was passed on to the later Roman Empire.[78]		During the middle of the first millennium BC, Greek culture experienced a gradual change in the perception of female breasts. Women in art were covered in clothing from the neck down, including female goddesses like Athena, the patron of Athens who represented heroic endeavor. There were exceptions: Aphrodite, the goddess of love, was more frequently portrayed fully nude, though in postures that were intended to portray shyness or modesty, a portrayal that has been compared to modern pin-ups by historian Marilyn Yalom.[79] Although nude men were depicted standing upright, most depictions of female nudity in Greek art occurred "usually with drapery near at hand and with a forward-bending, self-protecting posture".[80] A popular legend at the time was of the Amazons, a tribe of fierce female warriors who socialized with men only for procreation and even removed one breast to become better warriors. The legend was a popular motif in art during Greek and Roman antiquity and served as an antithetical cautionary tale.		Barechestedness is the state of a man wearing no clothes above the waist, exposing the upper torso. Bare male chests are generally considered acceptable at beaches, swimming pools and sunbathing areas. However, some stores and restaurants have a "no shirt, no service" rule to prevent barechested men from coming inside. While going barechested at outdoor activities may be acceptable, it is taboo at office workplaces, churches and other settings.		In most societies, barechestedness is much more common than toplessness, as exposure of the male pectoral muscles is often considered to be far less taboo than of the female breasts, despite some considering them equally erogenous. Male barechestedness is often due to practical reasons such as heath, or the ability to move the body without being restricted by an upper body garment. In several sports it is encouraged or even obligatory to be barechested. Barechestedness may also be used as a display of power, or to draw attention to oneself, especially if the upper body muscles are well-developed.				
Snowmaking is the production of snow by forcing water and pressurized air through a "snow gun," also known as a "snow cannon", on ski slopes. Snowmaking is mainly used at ski resorts to supplement natural snow. This allows ski resorts to improve the reliability of their snow cover and to extend their ski seasons from late autumn to early spring. Indoor ski slopes often use snowmaking. They can generally do so year-round as they have a climate-controlled environment.		The production of snow requires low temperatures. The threshold temperature for snowmaking increases as humidity decreases. Wet bulb temperature is used as a metric since it takes air temperature and relative humidity into account. Snowmaking is a relatively expensive process in its energy use, thereby limiting its use.						Art Hunt, Dave Richey, and Wayne Pierce invented the snow cannon in 1950,[1][2] but secured a patent sometime later.[3] In 1952, Grossinger's Catskill Resort Hotel became the first in the world to use artificial snow.[4] Snowmaking began to be used extensively in the early 1970s. Many ski resorts depend heavily upon snowmaking.		Snowmaking has achieved greater efficiency with increasing complexity. Traditionally, snowmaking quality depended upon the skill of the equipment operator. Computer control supplements that skill with greater precision, such that a snow gun operates only when snowmaking is optimal. All-weather snowmakers have been developed by IDE.[5]		The key considerations in snow production are increasing water and energy efficiency and increasing the environmental window in which snow can be made.		Snowmaking plants require water pumps and sometimes air compressors when using lances, that are both very large and expensive. The energy required to make artificial snow is about 0.6 - 0.7 kW h/m³ for lances and 1 - 2 kW h/m³ for fan guns. The density of artificial snow is between 400 and 500 kg/m³ and the water consumption for producing snow is roughly equal to that number.[6]		Snowmaking begins with a water supply such as a river or reservoir. Water is pushed up a pipeline on the mountain using very large electric pumps in a pump house. This water is distributed through an intricate series of valves and pipes to any trails that require snowmaking. Many resorts also add a nucleating agent to ensure that as much water as possible freezes and turns into snow. These products are organic or inorganic materials that facilitate the water molecules to form the proper shape to freeze into ice crystals. The products are non-toxic and biodegradable.		The next step in the snowmaking process is to add air using an air plant. This plant is often a building which contains electric or diesel industrial air compressors the size of a van or truck. However, in some instances air compression is provided using diesel-powered, portable trailer-mounted compressors which can be added to the system. Many fan-type snow guns have on-board electric air compressors, which allows for cheaper, and more compact operation. A ski area may have the required high-output water pumps, but not an air pump. Onboard compressors are cheaper and easier than having a dedicated pumping house. The air is generally cooled and excess moisture is removed before it is sent out of the plant. Some systems even cool the water before it enters the system. This improves the snowmaking process as the less heat in the air and water, the less heat must be dissipated to the atmosphere to freeze the water. From this plant the air travels up a separate pipeline following the same path as the water pipeline.		The water is sometimes mixed with ina (ice nucleation-active) proteins from the bacterium Pseudomonas syringae. These proteins serve as effective nuclei to initiate the formation of ice crystals at relatively high temperatures, so that the droplets will turn into ice before falling to the ground. The bacterium itself uses these ina proteins in order to injure plants.[7]		The pipes following the trails are equipped with shelters containing hydrants, electrical power and, optionally, communication lines mounted. Whereas shelters for fan guns require only water, power and maybe communication, lance-shelters usually need air hydrants as well. Hybrid shelters allow maximum flexibility to connect each snow machine type as they have all supplies available. The typical distance for lance shelters is 100–150 feet (30–46 m), for fan guns 250–300 feet (76–91 m). From these hydrants  1 1⁄2"–2" pressure resistant hoses are connected similar to fire hoses with camlocks to the snow machine.		There are many forms of snowmaking guns; however, they all share the basic principle of combining air and water to form snow. For most guns the type or "quality" of snow can be changed by regulating the amount of water in the mixture. For others, the water and air are simply on or off and the snow quality is determined by the air temperature and humidity.		In general there are three types of snowmaking guns: Internal Mixing, External Mixing and Fan Guns. These come in two main styles of makers: air water guns and fan guns.		An air water gun can be mounted on a tower or on a stand on the ground. It uses higher pressure water and air, while a fan gun uses a powerful axial fan to propel the water jet to a great distance.		A modern snow fan usually consists of one or more rings of nozzles which inject water into the fan air stream. A separate nozzle or small group of nozzles is fed with a mix of water and compressed air and produces the nucleation points for the snow crystals. The small droplets of water and the tiny ice crystals are then mixed and propelled out by a powerful fan, after which they further cool through evaporation in the surrounding air as they fall to the ground. The crystals of ice act as seeds to make the water droplets freeze at 0 °C (32 °F). Without these crystals the water would supercool instead of freezing. This method can produce snow when the wet-bulb temperature of the air is as high as -1 °C (30.2 °F).[8][9] The lower the air temperature is, the more and the better snow a cannon can make. This is one of the main reasons snow cannons are usually operated in the night. The quality of the mixing of the water and air streams and their relative pressures is crucial to the amount of snow made and its quality.		Modern snow cannons are fully computerized and can operate autonomously or be remotely controlled from a central location. Operational parameters are: starting and stopping time, quality of snow, maximum wet-bulb temperature in which to operate, maximum windspeed, horizontal and vertical orientation, and sweep angle (to cover a wider or narrower area). Sweep angle and area may follow wind direction.		Smaller versions of the snow machines found at ski resorts exist, scaled down to run off household size air and water supplies. Home snowmakers receive their water supply either from a garden hose or from a pressure washer, which makes more snow per hour. Plans also exist for do-it-yourself snowmaking machines made out of plumbing fittings and special nozzles.		Volumes of snow output by home snowmakers depend on the air/water mixture, temperature, wind variations, pumping capacity, water supply, air supply, and other factors. Using a household spray bottle will not work unless temperatures are well below the freezing point of water.		In Swedish, the phrase "snow cannon" (Snökanon) is used to designate the Lake-effect snow weather phenomenon. For example, if the Baltic sea is not yet frozen in January, cold winds from Siberia may lead to significant snowfall.		A snow making machine at Smiggin Holes, New South Wales, Australia		Full blast snow cannon at The Nordic Centre, Canmore, Alberta, Canada		
The Ninety Mile Beach is a sandy stretch of beach on the south-eastern coastline of the East Gippsland region of Victoria in Australia. The beach faces Bass Strait and backs the Gippsland Lakes. The beach is just over 151 kilometres (94 mi) in length, running north-eastward from a spit near Port Albert to the man-made channel at Lakes Entrance.		Behind the beach are long sandy dunes that separate the Gippsland Lakes from Bass Strait.[1] The beach is an uninterrupted stretch of untamed coastline; it does not have any rocky headlands or platforms, and offshore there are only a few ribbons of reef which are periodically covered by sand.[2]		In the northern section, the beach runs along a sandbar on what amounts to a series of tidal islands. Behind this are several large lakes and numerous shallow littoral lagoons. The three main lakes are Lake King, Lake Victoria and Lake Wellington, partially contained within The Lakes National Park.						The Ninety Mile Beach is located about 260 kilometres (160 mi) from Melbourne[3] and can be reached from the South Gippsland Highway passing the coastal towns of McLoughlins Beach, Woodside, Seaspray, Golden Beach, and Loch Sport. The beach is located within the Gippsland Lakes Coastal Park, with the Ninety Mile Beach Marine National Park located off-shore.		Ninety Mile Beach attracts a large number of visitors each year and offers a wide variety of activities such as camping, picnicking, whale watching, and beach and water-based activities.[4] The beach has golden sand,[5] with crashing waves and a natural bush environment.		It is part of the Ninety Mile Beach Marine National Park, which covers 2,750 hectares and 5 kilometres (3.1 mi) of coastline, 30 kilometres (19 mi) south of Sale.[6] There are basic camping facilities within the park at Emu Bight, as well as accommodation at Seaspray and Lakes Entrance.		Rotamah Island, which is part of the Lakes National Park, has a large bird observatory, and can be visited by boat from Paynesville, about 6 kilometres (3.7 mi) away.		Coastal towns of Woodside, Lochsport, Seaspray, Golden Beach and Lakes Entrance are popular tourist towns, attracting large numbers of visitors during the warmer months. Woodside, Seaspray and Lakes Entrance have life saving beach patrols during the summer season.[7]		Surf fishing is a key drawcard for the area, with main varieties of fish including snapper, flathead and gummy sharks. Port Albert, McLoughlins Beach, Lochsport and Lakes Entrance have jetties and temporary berthing facilities.[8][9]		The beach's length ensures that the waves break too close to the beach for good surfing, and there are strong rip currents and cross-currents that make conditions rather hazardous. The local authorities recommend that anyone who wishes to swim should do so at Woodside, Seaspray and Lakes Entrance, which have life saving beach patrols during the summer season.		The beach is believed to be the fourth longest uninterrupted beach in the world, behind Praia do Cassino on the Brazilian southern coast, Padre Island on the US Gulf Coast and Eighty Mile Beach in Western Australia, which is actually 140 miles (230 km) long.		Wild horses were introduced to the park after the islands were explored to help eat and trample down small areas of bush so it could be more easily explored but they were left unchecked and their numbers quickly increased. Their large numbers grew and over time started to caused concern as environmental damage became an issue, but once the park was established as a national heritage the horses were rounded up and transported back across to the mainland.		Western edge of Ninety Mile Beach		Ninety Mile Beach at Lakes Entrance		Ninety Mile Beach at Lakes Entrance		Ninety Mile Beach/ McLoughlins Beach at Seaspray		
See text		Donax is a genus of small, edible saltwater clams, marine bivalve mollusks. The genus is sometimes known as bean clams or wedge shells; however, Donax species have numerous different common names in different parts of the world. In the southeastern US they are known as "coquina", a word that is also used for the hard limestone concretions of their shells and those of other marine organisms.						Species of Donax live, sometimes in high concentrations, vertically aligned in the sand on exposed beaches, on tropical and temperate coasts worldwide. When the waves wash these small clams out of the sand, they can dig back in again quite rapidly. They are filter feeders. Some species, such as Donax variabilis, migrate vertically and horizontally with changes in the tides. These coquina clams are found extensively on the east coast beaches of Trinidad (Mayaro) and widely available in Venezuela. They are called "Chip Chip" in Trinidad & Tobago and "Chipi Chipi" in Venezuela.		Species within the genus Donax include:		The empty small (15 to 25 mm) shells of Donax variabilis and Donax fossor may be found washed up on the beach, especially at low tide. The living animals can often be seen where the waves wash the sand around in the most shallow part of the littoral zone as the tidal level changes. These clams can use the action of waves to move themselves up and down the beach, quickly burrowing into a new location before they can be swept away (the so-called "dance of the coquina").		
Central Pier is one of three piers in the town of Blackpool, England.						The pier is central in that it is located between the other two, but it was close to the site of the now-defunct Blackpool Central railway station about 550 yards south of Blackpool Tower. Since the coastline is very straight and flat, the pier simply extends at right angles to the sea front, roughly level with the promenade.		The success of the North Pier prompted the formation of the Blackpool South Jetty Company one year later in 1864. Impressed with the construction of Blackpool Pier (North Pier), the company hired the same contractor, Richard Laidlaw and Son of Glasgow for the project. This time, however, the company used the designs of Lieutenant-Colonel John Isaac Mawson rather than those of Eugenius Birch. When the pier was opened on 30 May 1868, it was 503 yards in length, 131 yards of which was a landing jetty for use at low tide. The first manager of the pier was Robert Bickerstaffe, coxswain of the first Blackpool lifeboat. Blackpool's lifeboat station is located next to Central Pier.		From the start, the new pier's emphasis was on fun rather than the genteel relaxation provided at North Pier. In the early days fun was provided mainly by dancing facilities, but in the 20th century, roller skating was introduced along with fairground rides and amusement machines. Steamboat excursions departed from the landing jetty as they did from North Pier. The dance halls became less popular after the Second World War and the facilities were adapted into a theatre, bars and amusement arcades by the 1970s.		The pierhead theatre was modernised in 1986 and became known as "Peggy Sue's Showboat". A striking addition came in 1990 when a 33 metre high Ferris wheel was erected, a half-scale reference to the Victorian attraction that had been part of the Winter Gardens complex a century earlier.		The pier now known as South Pier was built 30 years later.		Central Pier is constructed mostly of cast iron with wooden decking. The piles on which the structure rests were driven using the screw pile method pioneered by Eugenius Birch. This involved twisting screw-tipped cast iron piles down through the sand until they hit bedrock. The materials and building techniques were similar to those used for North Pier but the structure of Central is a little more delicate in appearance.		The pier has suffered relatively little damage save for fires in 1964 and 1973 which gutted the theatre buildings. The main structural alterations have been the removal of the obsolete 131 yards (120 m) low tide jetty in 1975 and the construction of the Ferris wheel in 1990. The addition of the wheel required the midsection of the pier to be strengthened to cope with the extra weight.		
A coastline or a seashore is the area where land meets the sea or ocean,[1] or a line that forms the boundary between the land and the ocean or a lake.[2] A precise line that can be called a coastline cannot be determined due to the Coastline paradox.		The term coastal zone is a region where interaction of the sea and land processes occurs.[3] Both the terms coast and coastal are often used to describe a geographic location or region; for example, New Zealand's West Coast, or the East and West Coasts of the United States. Edinburgh for example is a city on the coast of Scotland.		A pelagic coast refers to a coast which fronts the open ocean, as opposed to a more sheltered coast in a gulf or bay. A shore, on the other hand, can refer to parts of the land which adjoin any large body of water, including oceans (sea shore) and lakes (lake shore). Similarly, the somewhat related term "[Stream bed/bank]" refers to the land alongside or sloping down to a river (riverbank) or to a body of water smaller than a lake. "Bank" is also used in some parts of the world to refer to an artificial ridge of earth intended to retain the water of a river or pond; in other places this may be called a levee.		While many scientific experts might agree on a common definition of the term "coast", the delineation of the extents of a coast differ according to jurisdiction, with many scientific and government authorities in various countries differing for economic and social policy reasons. According to the UN atlas, 44% of people live within 150 kilometres (93 miles) of the sea.[4]						Tides often determine the range over which sediment is deposited or eroded. Areas with high tidal ranges allow waves to reach farther up the shore, and areas with lower tidal ranges produce deprossosition at a smaller elevation interval. The tidal range is influenced by the size and shape of the coastline. Tides do not typically cause erosion by themselves; however, tidal bores can erode as the waves surge up river estuaries from the ocean.[5]		Waves erode coastline as they break on shore releasing their energy; the larger the wave the more energy it releases and the more sediment it moves. Coastlines with longer shores have more room for the waves to disperse their energy, while coasts with cliffs and short shore faces give little room for the wave energy to be dispersed. In these areas the wave energy breaking against the cliffs is higher, and air and water are compressed into cracks in the rock, forcing the rock apart, breaking it down. Sediment deposited by waves comes from eroded cliff faces and is moved along the coastline by the waves. This forms an abrasion or cliffed coast.		Sediment deposited by rivers is the dominant influence on the amount of sediment located on a coastline.[6] Today riverine deposition at the coast is often blocked by dams and other human regulatory devices, which remove the sediment from the stream by causing it to be deposited inland.		Like the ocean which shapes them, coasts are a dynamic environment with constant change. The Earth's natural processes, particularly sea level rises, waves and various weather phenomena, have resulted in the erosion, accretion and reshaping of coasts as well as flooding and creation of continental shelves and drowned river valleys (rias).		The coast and its adjacent areas on and off shore are an important part of a local ecosystem: the mixture of fresh water and salt water (brackish water) in estuaries provides many nutrients for marine life. Salt marshes and beaches also support a diversity of plants, animals and insects crucial to the food chain.		The high level of biodiversity creates a high level of biological activity, which has attracted human activity for thousands of years.		More and more of the world's people live in coastal regions.[7] Many major cities are on or near good harbors and have port facilities. Some landlocked places have achieved port status by building canals.		The coast is a frontier that nations have typically defended against military invaders, smugglers and illegal migrants. Fixed coastal defenses have long been erected in many nations and coastal countries typically have a navy and some form of coast guard.		Coasts, especially those with beaches and warm water, attract tourists. In many island nations such as those of the Mediterranean, South Pacific and Caribbean, tourism is central to the economy. Coasts offer recreational activities such as swimming, fishing, surfing, boating, and sunbathing. Growth management can be a challenge for coastal local authorities who often struggle to provide the infrastructure required by new residents.		Coasts also face many human-induced environmental impacts. The human influence on climate change is thought to contribute to an accelerated trend in sea level rise which threatens coastal habitats.		Pollution can occur from a number of sources: garbage and industrial debris; the transportation of petroleum in tankers, increasing the probability of large oil spills; small oil spills created by large and small vessels, which flush bilge water into the ocean.		Fishing has declined due to habitat degradation, overfishing, trawling, bycatch and climate change. Since the growth of global fishing enterprises after the 1950s, intensive fishing has spread from a few concentrated areas to encompass nearly all fisheries. The scraping of the ocean floor in bottom dragging is devastating to coral, sponges and other long-lived species that do not recover quickly. This destruction alters the functioning of the ecosystem and can permanently alter species composition and biodiversity. Bycatch, the capture of unintended species in the course of fishing, is typically returned to the ocean only to die from injuries or exposure. Bycatch represents about a quarter of all marine catch. In the case of shrimp capture, the bycatch is five times larger than the shrimp caught.		It is believed that melting Arctic ice will cause sea levels to rise and flood coastal areas.		Extraordinary population growth in the 21st century has placed stress on the planet's ecosystems. For example, on Saint Lucia, harvesting mangrove for timber and clearing for fishing reduced the mangrove forests, resulting in a loss of habitat and spawning grounds for marine life that was unique to the area. These forests also helped to stabilize the coastline. Conservation efforts since the 1980s have partially restored the ecosystem.		According to one principle of classification, an emergent coastline is a coastline which has experienced a fall in sea level, because of either a global sea level change, or local uplift. Emergent coastlines are identifiable by the coastal landforms, which are above the high tide mark, such as raised beaches. In contrast, a submergent coastline is one where the sea level has risen, due to a global sea level change, local subsidence, or isostatic rebound. Submergent coastlines are identifiable by their submerged, or "drowned" landforms, such as rias (drowned valleys) and fjords.		According to a second principle of classification, a concordant coastline is a coastline where bands of different rock types run parallel to the shore. These rock types are usually of varying resistance, so the coastline forms distinctive landforms, such as coves. Discordant coastlines feature distinctive landforms because the rocks are eroded by ocean waves. The less resistant rocks erode faster, creating inlets or bay; the more resistant rocks erode more slowly, remaining as headlands or outcroppings.		Other coastal categories:		The following articles describe some coastal landforms		The following articles describe the various geologic processes that affect a coastal zone:		Some of the animals live along a typical coast. There are animals like puffins, sea turtles and rockhopper penguins. Sea snails and various kinds of barnacles live on the coast and scavenge on food deposited by the sea. Most coastal animals are used to humans in developed areas, such as dolphins and seagulls who eat food thrown for them by tourists. Since the coastal areas are all part of the littoral zone, there is a profusion of marine life found just off-coast.		There are many kinds of seabirds on the coast. Pelicans and cormorants join up with terns and oystercatchers to forage for fish and shellfish on the coast. There are sea lions on the coast of Wales and other countries.		Coastal areas are famous for their kelp beds. Kelp is a fast-growing seaweed that grows up to a metre a day. Corals and sea anemones are true animals, but live a lifestyle similar to that of plants. Mangroves, seagrasses and salt marsh are important coastal vegetation types in tropical and temperate environments respectively.		Shortly before 1951, Lewis Fry Richardson, in researching the possible effect of border lengths on the probability of war, noticed that the Portuguese reported their measured border with Spain to be 987 km, but the Spanish reported it as 1214 km. This was the beginning of the coastline problem, which is a mathematical uncertainty inherent in the measurement of boundaries that are irregular.[8]		The prevailing method of estimating the length of a border (or coastline) was to lay out n equal straight-line segments of length ℓ with dividers on a map or aerial photograph. Each end of the segment must be on the boundary. Investigating the discrepancies in border estimation, Richardson discovered what is now termed the Richardson Effect: the sum of the segments is inversely proportional to the common length of the segments. In effect, the shorter the ruler, the longer the measured border; the Spanish and Portuguese geographers were simply using different-length rulers.		The result most astounding to Richardson is that, under certain circumstances, as ℓ approaches zero, the length of the coastline approaches infinity. Richardson had believed, based on Euclidean geometry, that a coastline would approach a fixed length, as do similar estimations of regular geometric figures. For example, the perimeter of a regular polygon inscribed in a circle approaches the circumference with increasing numbers of sides (and decrease in the length of one side). In geometric measure theory such a smooth curve as the circle that can be approximated by small straight segments with a definite limit is termed a rectifiable curve.		More than a decade after Richardson completed his work, Benoit Mandelbrot developed a new branch of mathematics, fractal geometry, to describe just such non-rectifiable complexes in nature as the infinite coastline.[9] His own definition of the new figure serving as the basis for his study is:[10]		I coined fractal from the Latin adjective fractus. The corresponding Latin verb frangere means "to break:" to create irregular fragments. It is therefore sensible ... that, in addition to "fragmented" ... fractus should also mean "irregular."		A key property of the fractal is self-similarity; that is, at any scale the same general configuration appears. A coastline is perceived as bays alternating with promontories. In the hypothetical situation that a given coastline has this property of self-similarity, then no matter how greatly any one small section of coastline is magnified, a similar pattern of smaller bays and promontories superimposed on larger bays and promontories appears, right down to the grains of sand. At that scale the coastline appears as a momentarily shifting, potentially infinitely long thread with a stochastic arrangement of bays and promontories formed from the small objects at hand. In such an environment (as opposed to smooth curves) Mandelbrot asserts[9] "coastline length turns out to be an elusive notion that slips between the fingers of those who want to grasp it."		There are different kinds of fractals. A coastline with the stated property is in "a first category of fractals, namely curves whose fractal dimension is greater than 1." That last statement represents an extension by Mandelbrot of Richardson's thought. Mandelbrot's statement of the Richardson Effect is:[11]		where L, coastline length, a function of the measurement unit, ε, is approximated by the expression. F is a constant and D is a parameter that Richardson found depended on the coastline approximated by L. He gave no theoretical explanation but Mandelbrot identified D with a non-integer form of the Hausdorff dimension, later the fractal dimension. Rearranging the right side of the expression obtains:		where Fε−D must be the number of units ε required to obtain L. The fractal dimension is the number of the dimensions of the figure being used to approximate the fractal: 0 for a dot, 1 for a line, 2 for a square. D in the expression is between 1 and 2, for coastlines typically less than 1.5. The broken line measuring the coast does not extend in one direction nor does it represent an area, but is intermediate. It can be interpreted as a thick line or band of width 2ε. More broken coastlines have greater D and therefore L is longer for the same ε. Mandelbrot showed that D is independent of ε.		
Machair (Scottish Gaelic pronunciation: [ˈmaxɪɾʲ]; sometimes machar in English) refers to a fertile low-lying grassy plain found on part of the northwest coastlines of Ireland and Scotland, in particular the Outer Hebrides. The best examples are to be found on North and South Uist, Harris and Lewis.[1]						Machair is a Gaelic word meaning "fertile plain", but the word is now also used in scientific literature to describe the dune grassland unique to Western Scotland and north-west Ireland.[2] It had been used by naturalists since 1926, but the term was not adopted by scientists until the 1940s.[3] The word is used in a number of placenames in Ireland and Scotland, even in areas where no machair has ever been supported.[3] In Scotland, some Gaelic speakers use "machair" as a general term for the whole dune system, including the dune ridge, while others restrict its use to the extensive flat grasslands inland of the dune ridge.[3] In Ireland, the word has been used only in place-names, and the habitat’s existence there was only recently confirmed.[3]		In 1976, an effort was made to strictly define machair,[4] although a number of systems still evade classification.[3] This proved a difficulty when the habitat was listed on Annex I of the Habitats Directive in 1992, leading to the distinction between "machair grassland" and the "machair system."[3]		Machair is distinguished from the links on the east coast of Scotland by a lower mineral content, whereas the links are high in silica.[5] Machair plains are highly calcareous, with calcium carbonate concentrations of between 20% to 80% on the beaches, and decreasing further away from the shore.[5] The pH of a machair is typically greater than 7, i.e. it is alkaline.[3]		The inner side of a machair is often wet or marshy, and may contain lochs.[3][6]		The modern theory of machair formation was first set out by William MacGillivray in 1830.[5] He worked out that shell fragments are rolled by waves towards the shore, where they are broken up further. The small shell fragments are blown up the beach to form hillocks, which are then blown inland.[5]		Human activity has an important role in the creation of the machair. Archaeological evidence indicates that some trees had been cleared for agriculture by around 6000 BC, but there was still some woodland on the coast of South Uist as late as 1549.[5] Seaweed deposited by early farmers provided a protective cover and added nutrients to the soil.[5] The grass is kept short by cattle and sheep, which also add trample and add texture to the sward, forming tussocks that favour a number of bird species.[5]		The soil is low in a number of key nutrients, including trace elements such as copper, cobalt and manganese, which makes it necessary to feed cattle supplements or take them to summer pastures elsewhere.[5] The sandy soil does not hold nutrients well, making artificial fertilisers ineffective and limiting the crops that can be grown to certain strains of oats and rye, and bere barley.[5]		Machairs have received considerable ecological and conservational attention, chiefly because of their unique ecosystems.		Kelp in the sea next to the machair softens the impact of waves, reducing erosion, and when it is washed ashore by storms, forms a protective barrier on the beach.[5] As it rots, the sand flies it abounds in provide rich feeding for flocks of starlings and other passerines, wintering waders, gulls and others.[5] If covered with sand, it will compost to form a fertile bed where annual coastal flowers and marram grass will thrive.[5]		They can house rare carpet flowers, including orchids such as Irish lady's tresses and the Hebridean Spotted Orchid (Dactylorhiza fuchii ssp hebridensis) and other plants such as the yellow rattle.		Bird species including the corn crake, twite, dunlin, common redshank and ringed plover, as well as rare insects such as the northern colletes bee.		Arable and fallow machair is threatened by changes to the way the land is managed, where the original system of crofts is under threat from a reduction in the number of crofters and the use of "modern" techniques.[7] Changes to the Common Agricultural Policy, where production was decoupled from subsidies, reduced the amount of grazing taking place in many crofting areas, and led some areas to be undergrazed or abandoned.[7][8][9] A lack of native seed increases the need for fertilizers and herbicides.[7]		Rising sea levels caused by global warming also pose a threat to low-lying coastal areas, leading to increased erosion.[5][10][11] In January 1993, the storm which ran MV Braer aground off Shetland eroded 3 metres (9.8 ft) of machair along the entire length of Uist and Barra.[5] On 11/12 January 2005, a storm blowing consistently in excess of hurricane force 12 destroyed hectares of machair and killed a family of five.[5]		
A strait is a naturally formed, narrow, typically navigable waterway that connects two larger bodies of water. Most commonly it is a channel of water that lies between two land masses. Some straits are not navigable, for example because they are too shallow, or because of an unnavigable reef or archipelago.						The terms channel, pass or passage, can be synonymous and used interchangeably with strait, although each is sometimes differentiated with varying senses. In Scotland firth or kyle are also sometimes used as synonyms for strait.		Many straits are economically important. Straits can be important shipping routes, and wars have been fought for control of them.		Numerous artificial channels, called canals, have been constructed to connect two bodies of water over land, such as the Suez Canal. Although rivers and canals often provide passage between two large lakes or a lake and a sea, and these seem to suit the formal definition of strait, they are not usually referred to as such. The term strait is typically reserved for much larger, wider features of the marine environment. There are exceptions, with straits being called canals, Pearse Canal, for example.		Straits are the converse of isthmuses. That is, while a strait lies between two land masses and connects two larger bodies of water, an isthmus lies between two bodies of water and connects two larger land masses.		Some straits have the potential to generate significant tidal power using tidal stream turbines. Tides are more predictable than wave power or wind power. The Pentland Firth (actually a strait) may be capable of generating 10 GW.[1] Cook Strait in New Zealand may be capable of generating 5.6 GW[2] even though the total energy available in the flow is 15 GW[3]		Straits used for international navigation through the territorial sea between one part of the high seas or an exclusive economic zone and another part of the high seas or an exclusive economic zone are subject to the legal regime of transit passage (Strait of Gibraltar, Dover Strait, Strait of Hormuz). The regime of innocent passage applies in straits used for international navigation (1) that connect a part of high seas or an exclusive economic zone with the territorial sea of coastal nation (Strait of Tiran, Strait of Juan de Fuca, Strait of Baltiysk) and (2) in straits formed by an island of a state bordering the strait and its mainland if there exists seaward of the island a route through the high seas or through an exclusive economic zone of similar convenience with respect to navigational and hydrographical characteristics (Strait of Messina, Pentland Firth). There may be no suspension of innocent passage through such straits.		Media related to Straits at Wikimedia Commons		
The Caribbean (/ˌkærᵻˈbiːən/ or /kəˈrɪbiən/) is a region that consists of the Caribbean Sea, its islands (some surrounded by the Caribbean Sea[3] and some bordering both the Caribbean Sea and the North Atlantic Ocean[4]) and the surrounding coasts. The region is southeast of the Gulf of Mexico and the North American mainland, east of Central America, and north of South America.		Situated largely on the Caribbean Plate, the region comprises more than 700 islands, islets, reefs and cays. (See the list.) These islands generally form island arcs that delineate the eastern and northern edges of the Caribbean Sea.[5] The Caribbean islands, consisting of the Greater Antilles on the north and the Lesser Antilles on the south and east (including the Leeward Antilles), are part of the somewhat larger West Indies grouping, which also includes the Lucayan Archipelago (comprising the Bahamas and Turks and Caicos Islands) north of the Greater Antilles and Caribbean Sea. In a wider sense, the mainland countries of Belize, Guyana, Suriname and French Guiana are often included due to their political and cultural ties with the region.[6]		Geopolitically, the Caribbean islands are usually regarded as a subregion of North America[7][8][9][10][11] and are organized into 30 territories including sovereign states, overseas departments, and dependencies. From December 15, 1954, to October 10, 2010, there was a country known as the Netherlands Antilles composed of five states, all of which were Dutch dependencies.[12] From January 3, 1958, to May 31, 1962, there was also a short-lived country called the Federation of the West Indies composed of ten English-speaking Caribbean territories, all of which were then British dependencies. The West Indies cricket team continues to represent many of those nations.						The region takes its name from that of the Caribs, an ethnic group present in the Lesser Antilles and parts of adjacent South America at the time of the Spanish conquest of America.[13]		The two most prevalent pronunciations of "Caribbean" are KARR-ə-BEE-ən, with the primary accent on the third syllable, and kə-RIB-ee-ən, with the accent on the second. The former pronunciation is the older of the two, although the stressed-second-syllable variant has been established for over 75 years.[14] It has been suggested that speakers of British English prefer KARR-ə-BEE-ən while North American speakers more typically use kə-RIB-ee-ən,[15] although not all sources agree.[16] Usage is split within Caribbean English itself.[17]		The word "Caribbean" has multiple uses. Its principal ones are geographical and political. The Caribbean can also be expanded to include territories with strong cultural and historical connections to slavery, European colonisation and the plantation system.		The geography and climate in the Caribbean region varies: Some islands in the region have relatively flat terrain of non-volcanic origin. These islands include Aruba (possessing only minor volcanic features), Barbados, Bonaire, the Cayman Islands, Saint Croix, the Bahamas, and Antigua. Others possess rugged towering mountain-ranges like the islands of Cuba, Hispaniola, Puerto Rico, Jamaica, Dominica, Montserrat, Saba, Saint Kitts, Saint Lucia, Saint Thomas, Saint John, Tortola, Grenada, Saint Vincent, Guadeloupe, Martinique and Trinidad and Tobago.		Definitions of the terms Greater Antilles and Lesser Antilles often vary. The Virgin Islands as part of the Puerto Rican bank are sometimes included with the Greater Antilles. The term Lesser Antilles is often used to define an island arc that includes Grenada but excludes Trinidad and Tobago and the Leeward Antilles.		The waters of the Caribbean Sea host large, migratory schools of fish, turtles, and coral reef formations. The Puerto Rico trench, located on the fringe of the Atlantic Ocean and Caribbean Sea just to the north of the island of Puerto Rico, is the deepest point in all of the Atlantic Ocean.[19]		The region sits in the line of several major shipping routes with the Panama Canal connecting the western Caribbean Sea with the Pacific Ocean.		The climate of the area is tropical to subtropical in Cuba, the Bahamas and Puerto Rico. Rainfall varies with elevation, size and water currents (cool upwellings keep the ABC islands arid). Warm, moist trade winds blow consistently from the east creating rain forest /semi desert divisions on mountainous islands. Occasional north westerlies affect the northern islands in the winter. The region enjoys year-round sunshine, divided into 'dry' and 'wet' seasons, with the latter six months of the year being wetter than the first half.		Hurricane season is from June to November, but they occur more frequently in August and September and more common in the northern islands of the Caribbean. Hurricanes that sometimes batter the region usually strike northwards of Grenada and to the west of Barbados. The principal hurricane belt arcs to northwest of the island of Barbados in the Eastern Caribbean.		Water temperatures vary from 31 °C (88 °F) to 22 °C (72 °F) all around the year. The air temperature is warm, in the 20s and 30s °C (70s, 80s and 90s °F) during the year, only varies from winter to summer about 2–5 degrees on the southern islands and about 10–20 degrees difference can occur in the northern islands of the Caribbean. The northern islands, like the Bahamas, Cuba, Puerto Rico and the Dominican Republic, may be influenced by continental masses during winter months, such as cold fronts.		Aruba: Latitude 12°N		Puerto Rico: Latitude 18°N		Cuba: at Latitude 22°N		Lucayan Archipelago[a]		Greater Antilles		Lesser Antilles		All islands at some point were, and a few still are, colonies of European nations; a few are overseas or dependent territories:		The British West Indies were united by the United Kingdom into a West Indies Federation between 1958 and 1962. The independent countries formerly part of the B.W.I. still have a joint cricket team that competes in Test matches, One Day Internationals and Twenty20 Internationals. The West Indian cricket team includes the South American nation of Guyana, the only former British colony on the mainland of that continent.		In addition, these countries share the University of the West Indies as a regional entity. The university consists of three main campuses in Jamaica, Barbados and Trinidad and Tobago, a smaller campus in the Bahamas and Resident Tutors in other contributing territories such as Trinidad.		The Caribbean islands are remarkable for the diversity of their animals, fungi and plants, and have been classified as one of Conservation International's biodiversity hotspots because of their exceptionally diverse terrestrial and marine ecosystems, ranging from montane cloud forests to cactus scrublands. The region also contains about 8% (by surface area) of the world's coral reefs[25] along with extensive seagrass meadows,[26] both of which are frequently found in the shallow marine waters bordering the island and continental coasts of the region.		For the fungi, there is a modern checklist based on nearly 90,000 records derived from specimens in reference collections, published accounts and field observations.[27] That checklist includes more than 11250 species of fungi recorded from the region. As its authors note, the work is far from exhaustive, and it is likely that the true total number of fungal species already known from the Caribbean is higher. The true total number of fungal species occurring in the Caribbean, including species not yet recorded, is likely far higher given the generally accepted estimate that only about 7% of all fungi worldwide have been discovered.[28] Though the amount of available information is still small, a first effort has been made to estimate the number of fungal species endemic to some Caribbean islands. For Cuba, 2200 species of fungi have been tentatively identified as possible endemics of the island;[29] for Puerto Rico, the number is 789 species;[30] for the Dominican Republic, the number is 699 species;[31] for Trinidad and Tobago, the number is 407 species.[32]		Many of the ecosystems of the Caribbean islands have been devastated by deforestation, pollution, and human encroachment. The arrival of the first humans is correlated with extinction of giant owls and dwarf ground sloths.[33] The hotspot contains dozens of highly threatened animals (ranging from birds, to mammals and reptiles), fungi and plants. Examples of threatened animals include the Puerto Rican amazon, two species of solenodon (giant shrews) in Cuba and the Hispaniola island, and the Cuban crocodile.		The region's coral reefs, which contain about 70 species of hard corals and between 500–700 species of reef-associated fishes[34] have undergone rapid decline in ecosystem integrity in recent years, and are considered particularly vulnerable to global warming and ocean acidification.[35] According to a UNEP report, the Caribbean coral reefs might get extinct in next 20 years due to population explosion along the coast lines, overfishing, the pollution of coastal areas and global warming.[36]		Some Caribbean islands have terrain that Europeans found suitable for cultivation for agriculture. Tobacco was an important early crop during the colonial era, but was eventually overtaken by sugarcane production as the region's staple crop. Sugar was produced from sugarcane for export to Europe. Cuba and Barbados were historically the largest producers of sugar. The tropical plantation system thus came to dominate Caribbean settlement. Other islands were found to have terrain unsuited for agriculture, for example Dominica, which remains heavily forested. The islands in the southern Lesser Antilles, Aruba, Bonaire and Curaçao, are extremely arid, making them unsuitable for agriculture. However, they have salt pans that were exploited by the Dutch. Sea water was pumped into shallow ponds, producing coarse salt when the water evaporated.[37]		The natural environmental diversity of the Caribbean islands has led to recent growth in eco-tourism. This type of tourism is growing on islands lacking sandy beaches and dense human populations.[38]		Epiphytes (bromeliads, climbing palms) in the rainforest of Dominica.		A green and black poison frog, Dendrobates auratus		Caesalpinia pulcherrima, Guadeloupe.		Costus speciosus, a marsh plant, Guadeloupe.		An Atlantic ghost crab (Ocypode quadrata) in Martinique.		Crescentia cujete, or calabash fruit, Martinique.		Thalassoma bifasciatum (bluehead wrasse fish), over Bispira brunnea (social feather duster worms).		Two Stenopus hispidus (banded cleaner shrimp) on a Xestospongia muta (giant barrel sponge).		A pair of Cyphoma signatum (fingerprint cowry), off coastal Haiti.		The Martinique amazon, Amazona martinicana, is an extinct species of parrot in the family Psittacidae.		Anastrepha suspensa, a Caribbean fruit fly.		Hemidactylus mabouia, a tropical gecko, in Dominica.		At the time of European contact, the dominant ethnic groups in the Caribbean included the Taíno of the Greater Antilles and northern Lesser Antilles, the Island Caribs of the southern Lesser Antilles, and smaller distinct groups such as the Guanajatabey of western Cuba and the Ciguayo of eastern Hispaniola. The population of the Caribbean is estimated to have been around 750,000 immediately before European contact, although lower and higher figures are given. After contact, social disruption and epidemic diseases such as smallpox and measles (to which they had no natural immunity)[39] led to a decline in the Amerindian population.[40] From 1500 to 1800 the population rose as slaves arrived from West Africa[41] such as the Kongo, Igbo, Akan, Fon and Yoruba as well as military prisoners from Ireland, who were deported during the Cromwellian reign in England.[citation needed] Immigrants from Britain, Italy, France, Spain, the Netherlands, Portugal and Denmark also arrived, although the mortality rate was high for both groups.[42]		The population is estimated to have reached 2.2 million by 1800.[43] Immigrants from India, China, Indonesia, and other countries arrived in the mid-19th century as indentured servants.[44] After the ending of the Atlantic slave trade, the population increased naturally.[45] The total regional population was estimated at 37.5 million by 2000.[46]		The majority of the Caribbean has populations of mainly Africans in the French Caribbean, Anglophone Caribbean and Dutch Caribbean, there are minorities of mixed-race (including Mulatto-Creole, Dougla, Mestizo, Quadroon, Cholo, Castizo, Criollo, Zambo, Pardo, Asian Latin Americans, Chindian, Cocoa panyols, and Eurasian); and European people of Spanish, Dutch, English, French, Italian, and Portuguese ancestry. Asians, especially those of Chinese, Indian descent, and Javenese Indonesians, form a significant minority in the region and also contribute to multiracial communities. Indians form a majority of the population in Trinidad and Tobago, Guyana, and Suriname. Most of their ancestors arrived in the 19th century as indentured laborers.		The Spanish-speaking Caribbean have primarily mixed race, African, or European majorities. Puerto Rico has a European majority with a mixture of European-African-Native American (tri-racial), and a large Mulatto (European-West African) and West African minority. One third of Cuba's (largest Caribbean island) population is of African descent, with a sizable Mulatto (mixed African–European) population, and European majority. The Dominican Republic has the largest mixed race population, primarily descended from Europeans, West Africans, and Amerindians.		Larger islands such as Jamaica, have a very large African majority, in addition to a significant mixed race, and has Chinese, Europeans, Indians, Latinos, Jews, and Arabs populations. This is a result of years of importation of slaves and indentured laborers, and migration. Most multi-racial Jamaicans refer to themselves as either mixed race or brown. Similar populations can be found in the Caricom states of Belize, Guyana and Trinidad and Tobago. Trinidad and Tobago has a multi-racial cosmopolitan society due to the arrivals of Africans, Indians, Chinese, Arabs, Jews, Spanish, Portuguese, and Europeans along with the Native Amerindians population. This multi-racial mix has created sub-ethnicities that often straddle the boundaries of major ethnicities and include Dougla, Chindian, Mulatto-Creole, Afro-Asians, Eurasian, Cocoa panyols, and Asian Latin Americans		Spanish, English, Portuguese, French, Dutch, Haitian Creole, Antillean Creole French, and Papiamento are the predominant official languages of various countries in the region, though a handful of unique creole languages or dialects can also be found from one country to another. Other languages such as Caribbean Hindustani, Tamil, Telugu, Danish, Italian, Irish, Swedish, Arabic, Chinese, Indonesian, Javanese, Yoruba, Yiddish, Hebrew, Amerindian languages, other African languages, other European languages, other Indian languages, and other Indonesian languages can also be found.		Christianity is the predominant religion in the Caribbean (84.7%).[47] Other religious groups in the region are Hinduism, Islam, Judaism, Rastafarianism, Buddhism, Chinese folk religion (Taoism and Confucianism), Bahá'í, Jainism, Sikhism, Zorastrianism, Kebatinan, Traditional African religions, Afro-American religions, Yoruba (Santería, Trinidad Orisha, Palo, Umbanda, Brujería, Hoodoo, Candomblé, Quimbanda, Orisha, Xangô de Recife, Xangô do Nordeste, Comfa, Espiritismo, Santo Daime, Obeah, Candomblé, Abakuá, Kumina, Winti, Sanse, Cuban Vodú, Dominican Vudú, Louisiana Voodoo, Haitian Vodou, and Vodun).		Caribbean societies are very different from other Western societies in terms of size, culture, and degree of mobility of their citizens.[48] The current economic and political problems the states face individually are common to all Caribbean states. Regional development has contributed to attempts to subdue current problems and avoid projected problems. From a political and economic perspective, regionalism serves to make Caribbean states active participants in current international affairs through collective coalitions. In 1973, the first political regionalism in the Caribbean Basin was created by advances of the English-speaking Caribbean nations through the institution known as the Caribbean Common Market and Community (CARICOM)[49] which is located in Guyana.		Certain scholars have argued both for and against generalizing the political structures of the Caribbean. On the one hand the Caribbean states are politically diverse, ranging from communist systems such as Cuba toward more capitalist Westminster-style parliamentary systems as in the Commonwealth Caribbean. Other scholars argue that these differences are superficial, and that they tend to undermine commonalities in the various Caribbean states. Contemporary Caribbean systems seem to reflect a "blending of traditional and modern patterns, yielding hybrid systems that exhibit significant structural variations and divergent constitutional traditions yet ultimately appear to function in similar ways."[50] The political systems of the Caribbean states share similar practices.		The influence of regionalism in the Caribbean is often marginalized. Some scholars believe that regionalism cannot exist in the Caribbean because each small state is unique. On the other hand, scholars also suggest that there are commonalities amongst the Caribbean nations that suggest regionalism exists. "Proximity as well as historical ties among the Caribbean nations has led to cooperation as well as a desire for collective action."[51] These attempts at regionalization reflect the nations' desires to compete in the international economic system.[51]		Furthermore, a lack of interest from other major states promoted regionalism in the region. In recent years the Caribbean has suffered from a lack of U.S. interest. "With the end of the Cold War, U.S. security and economic interests have been focused on other areas. As a result there has been a significant reduction in U.S. aid and investment to the Caribbean."[52] The lack of international support for these small, relatively poor states, helped regionalism prosper.		Following the Cold War another issue of importance in the Caribbean has been the reduced economic growth of some Caribbean States due to the United States and European Union's allegations of special treatment toward the region by each other. [clarification needed]		The United States under President Bill Clinton launched a challenge in the World Trade Organization against the EU over Europe's preferential program, known as the Lomé Convention, which allowed banana exports from the former colonies of the Group of African, Caribbean and Pacific states (ACP) to enter Europe cheaply.[53] The World Trade Organization sided in the United States' favour and the beneficial elements of the convention to African, Caribbean and Pacific states has been partially dismantled and replaced by the Cotonou Agreement.[54]		During the US/EU dispute, the United States imposed large tariffs on European Union goods (up to 100%) to pressure Europe to change the agreement with the Caribbean nations in favour of the Cotonou Agreement.[55]		Farmers in the Caribbean have complained of falling profits and rising costs as the Lomé Convention weakens. Some farmers have faced increased pressure to turn towards the cultivation of illegal drugs, which has a higher profit margin and fills the sizable demand for these illegal drugs in North America and Europe.[56][57]		Caribbean nations have also started to more closely cooperate in the Caribbean Financial Action Task Force and other instruments to add oversight of the offshore industry. One of the most important associations that deal with regionalism amongst the nations of the Caribbean Basin has been the Association of Caribbean States (ACS). Proposed by CARICOM in 1992, the ACS soon won the support of the other countries of the region. It was founded in July 1994. The ACS maintains regionalism within the Caribbean on issues unique to the Caribbean Basin. Through coalition building, like the ACS and CARICOM, regionalism has become an undeniable part of the politics and economics of the Caribbean. The successes of region-building initiatives are still debated by scholars, yet regionalism remains prevalent throughout the Caribbean.		The President of Venezuela, Hugo Chavez launched an economic group called the Bolivarian Alliance for the Americas (ALBA), which several eastern Caribbean islands joined. In 2012, the nation of Haiti, with 9 million people, became the largest CARICOM nation that sought to join the union.[58]		Here are some of the bodies that several islands share in collaboration:		Geography:		Coordinates: 14°31′32″N 75°49′06″W﻿ / ﻿14.52556°N 75.81833°W﻿ / 14.52556; -75.81833		
A swimming pool, swimming bath, wading pool, or paddling pool is a structure designed to hold water to enable swimming or other leisure activities. Pools can be built into the ground (in-ground pools) or built above ground (as a freestanding construction or as part of a building or other larger structure), and are also a common feature aboard ocean-liners and cruise ships. In-ground pools are most commonly constructed from materials such as concrete, natural stone, metal, plastic or fiberglass, and can be of a custom size and shape or built to a standardized size, the largest of which is the Olympic-size swimming pool.		Many health clubs, fitness centers and private clubs, such as the YMCA, have pools used mostly for exercise or recreation. Many towns and cities provide public pools. Many hotels have pools available for their guests to use at their leisure. Educational facilities such as universities typically have pools for physical education classes, recreational activities, leisure or competitive athletics such as swimming teams. Hot tubs and spas are pools filled with hot water, used for relaxation or hydrotherapy, and are common in homes, hotels, and health clubs. Special swimming pools are also used for diving, specialized water sports, physical therapy as well as for the training of lifeguards and astronauts. Swimming pools may be heated or unheated.		The "Great Bath" at the site of Mohenjo-Daro in modern-day Pakistan was most likely the first swimming pool, dug during the 3rd millennium BC. This pool is 12 by 7 metres (39 by 23 feet), is lined with bricks, and was covered with a tar-based sealant.[1]		Ancient Greeks and Romans built artificial pools for athletic training in the palaestras, for nautical games and for military exercises. Roman emperors had private swimming pools in which fish were also kept, hence one of the Latin words for a pool was piscina. The first heated swimming pool was built by Gaius Maecenas of Rome in the 1st century BC. Gaius Maecenas was a rich Roman lord and considered one of the first patrons of arts.[2]		Ancient Sinhalese built pairs of pools called "Kuttam Pokuna" in the kingdom of Anuradhapura, Sri Lanka in the 4th century BC. They were decorated with flights of steps, punkalas or pots of abundance, and scroll design.[3]		Swimming pools became popular in Britain in the mid-19th century. As early as 1837, six indoor pools with diving boards existed in London, England.[4] The Maidstone Swimming Club in Maidstone, Kent is believed to be the oldest surviving swimming club in Britain. It was formed in 1844, in response to concerns over drownings in the River Medway, especially since would-be rescuers would often drown because they themselves could not swim to safety. The club used to swim in the River Medway, and would hold races, diving competitions and water polo matches. The South East Gazette July 1844 reported an aquatic breakfast party: coffee and biscuits were served on a floating raft in the river. The coffee was kept hot over a fire; club members had to tread water and drink coffee at the same time. The last swimmers managed to overturn the raft, to the amusement of 150 spectators.[5]		The Amateur Swimming Association was founded in 1869 in England,[6] and the Oxford Swimming Club in 1909.[7] The presence of indoor baths in the cobbled area of Merton Street might have persuaded the less hardy of the aquatic brigade to join. So, bathers gradually became swimmers, and bathing pools became swimming pools.[citation needed]. In 1939, Oxford created its first major public indoor pool at Temple Cowley.		The modern Olympic Games started in 1896 and included swimming races, after which the popularity of swimming pools began to spread. In the US, the Racquet Club of Philadelphia clubhouse (1907) boasts one of the world's first modern above-ground swimming pools. The first swimming pool to go to sea on an ocean liner was installed on the White Star Line's Adriatic in 1907.[8] The oldest known public swimming pool in America, Underwood Pool, is located in Belmont, Massachusetts.[9]		Interest in competitive swimming grew following World War I. Standards improved and training became essential. Home swimming pools became popular in the United States after World War II and the publicity given to swimming sports by Hollywood films such as Esther Williams' Million Dollar Mermaid made a home pool a desirable status symbol. More than 50 years later, the home or residential swimming pool is a common sight. Some small nations enjoy a thriving swimming pool industry (e.g., New Zealand pop. 4,116,900 [Source NZ Census 7 March 2006] – holds the record in pools per capita with 65,000 home swimming pools and 125,000 spa pools).[citation needed]		A two-storey, white concrete swimming pool building composed of horizontal cubic volumes built in 1959 at the Royal Roads Military College is on the Registry of Historic Places of Canada.[10]		According to the Guinness World Records, the largest swimming pool in the world is San Alfonso del Mar Seawater pool in Algarrobo, Chile. It is 1,013 m (3,323 ft) long and has an area of 8 ha (20 acres). At its deepest, it is 3.5 m (11 ft) deep.[11] It was completed in December 2006.[12]		The largest indoor wave pool in North America is at the West Edmonton Mall and the largest indoor pool is at the Neutral Buoyancy Lab in the Sonny Carter Training Facility at NASA JSC in Houston.[13][14]		In 2014, the Y-40 swimming pool at the Hotel Terme Millepini in Padua, Italy became the deepest indoor pool, certified by the Guinness Book of World Records[15] The recreational diving center Nemo 33 near Brussels, Belgium previously held the record until the Y-40 was completed.[16]		The Fleishhacker Pool in San Francisco was the largest heated outdoor swimming pool in the United States. Opened on 23 April 1925, it measured 1,000 by 150 ft (300 by 50 m) and was so large that the lifeguards required kayaks for patrol. It was closed in 1971 due to low patronage.[17]		In Europe, the largest swimming pool opened in 1934 in Elbląg (Poland), providing a water area of 33,500 square metres (361,000 sq ft).[18]		One of the largest swimming pools ever built was reputedly created in Moscow after the Palace of Soviets remained uncompleted. The foundations of the palace were converted into the Moskva Pool open-air swimming pool after the process of de-Stalinisation.[19] However, after the fall of communism, Christ the Saviour Cathedral was re-built on the site between 1995 and 2000; the cathedral had originally been located there.[citation needed]		The highest swimming pool is believed to be in Yangbajain (Tibet, China). This resort is located at 4200 m AMSL and has two indoor swimming pools and one outdoor swimming pool, all filled with water from hot springs.[20]		Length: Most pools in the world are measured in metres, but in the United States pools are often measured in feet and yards. In the UK most pools are calibrated in metres, but older pools measured in yards still exist. In the US, pools tend to either be 25 yards (SCY-short course yards), 25 metres (SCM-short course metres) or 50 metres (long course). US high schools and the NCAA conduct short course (25 yards) competition. There are also many pools 33⅓ m long, so that 3 lengths = 100 m. This pool dimension is commonly used to accommodate water polo.[citation needed]		USA Swimming (USA-S) swims in both metric and non-metric pools. However, the international standard is metres, and world records are only recognized when swum in 50 m pools (or 25 m for short course) but 25-yard pools are very common in the US. In general, the shorter the pool, the faster the time for the same distance, since the swimmer gains speed from pushing off the wall after each turn at the end of the pool.		Width: Most European pools are between 10 m and 50 m wide.[citation needed]		Depth: The depth of a swimming pool depends on the purpose of the pool, and whether it is open to the public or strictly for private use. If it is a private casual, relaxing pool, it may go from 1.0 to 2.0 m (3.3 to 6.6 ft) deep. If it is a public pool designed for diving, it may slope from 3.0 to 5.5 m (10 to 18 ft) in the deep end. A children's play pool may be from 0.3 to 1.2 m (1 to 4 ft) deep. Most public pools have differing depths to accommodate different swimmer requirements. In many jurisdictions, it is a requirement to show the water depth with clearly marked depths affixed to the pool walls.[citation needed]		Pools can be either indoors or outdoors. They can be of any size and shape, and inground or above ground. Most pools are permanent fixtures, while others are temporary, collapsible structures.		Private pools are usually smaller than public pools, on average 3.7 m × 7.3 m (12 ft × 24 ft) to 6.1 m × 12.2 m (20 ft × 40 ft) whereas public pools usually start at 24 m (80 ft).[citation needed] Home pools can be permanently built-in, or be assembled above ground and disassembled after summer.[21] Privately owned outdoor pools in backyards or gardens started to proliferate in the 1950s in regions with warm summer climates, particularly in the United States with desegregation.[22]		Construction methods for private pools vary greatly. The main types of in-ground pools are gunite shotcrete, concrete, vinyl-lined, and one-piece fiberglass shells.		Many countries now have strict pool fencing requirements for private swimming pools, which require pool areas to be isolated so that unauthorized children younger than six years cannot enter. Many countries require a similar level of protection for the children residing in or visiting the house, although many pool owners prefer the visual aspect of the pool in close proximity to their living areas, and will not provide this level of protection. There is no consensus between states or countries on the requirements to fence private swimming pools, and in many places they are not required at all, particularly in rural settings.[23]		Inexpensive temporary polyvinyl chloride pools can be bought in supermarkets and taken down after summer. They are used mostly outdoors in yards, are typically shallow, and often their sides are inflated with air to stay rigid. When finished, the water and air can be let out and this type of pool can be folded up for convenient storage. They are regarded in the swimming pool industry as "splasher" pools intended for cooling off and amusing toddlers and children, not for swimming, hence the alternate name of "kiddie" pools.[citation needed]		Toys are available for children and other people to play with in pool water. They are often blown up with air so they are soft but still reasonably rugged, and can float in water.		Public pools are often part of a larger leisure centre or recreational complex. These centres often have more than one pool, such as an indoor heated pool, an outdoor (chlorinated, saltwater or ozonated) pool which may be heated or unheated, a shallower children's pool, and a paddling pool for toddlers and infants. There may also be a sauna and one or more hot tubs or spa pools ("jacuzzis").		Many upscale hotels and holiday resorts have a swimming pool for use by their guests. If a pool is in a separate building, the building may be called a natatorium. The building may sometimes also have facilities for related activities, such as a diving tank. Larger pools sometimes have a diving board affixed at one edge above the water.		Many public swimming pools are rectangles 25 m or 50 m long, but they can be any size and shape. There are also elaborate pools with artificial waterfalls, fountains, splash pads, wave machines, varying depths of water, bridges, and island bars.		Some swimming facilities have lockers for clothing and other belongings. The lockers can require a coin to be inserted in a slot, either as deposit or payment. There are usually showers - sometimes mandatory - before and/or after swimming. There are often also lifeguards to ensure the safety of users.		Wading or paddling pools are shallow bodies of water intended for use by small children, usually in parks. Concrete wading pools come in many shapes, traditionally rectangle, square or circle. Some are filled and drained daily due to lack of a filter system. Staff chlorinate the water to ensure health and safety standards.[citation needed]		The Fédération Internationale de la Natation (FINA, International Swimming Federation) sets standards for competition pools: 25 or 50 m (82 or 164 ft) long and at least 1.35 m (4.4 ft) deep. Competition pools are generally indoors and heated to enable their use all year round, and to more easily comply with the regulations regarding temperature, lighting, and automatic officiating equipment.		An Olympic-size swimming pool (first used at the 1924 Olympics) is a pool that meets FINA's additional standards for the Olympic Games and for world championship events. It must be 50 by 25 m (164 by 82 ft) wide, divided into eight lanes of 2.5 m (8.2 ft) each plus two areas of 2.5 m (8.2 ft) at each side of the pool.[24] The water must be kept at 25–28 °C (77–82 °F) and the lighting level at greater than 1500 lux. Depth must be at least 2 m (6.6 ft), and there are also regulations for color of lane rope, positioning of backstroke flags (5 metres from each wall), and so on. Pools claimed to be "Olympic pools" do not always meet these regulations, as FINA cannot police use of the term. Touchpads are mounted on both walls for long course meets and each end for short course.		A pool may be referred to as fast or slow, depending on its physical layout.[25] Some design considerations allow the reduction of swimming resistance making the pool faster: namely, proper pool depth, elimination of currents, increased lane width, energy absorbing racing lane lines and gutters, and the use of other innovative hydraulic, acoustic and illumination designs.		In the last two decades, a new style of pool has gained popularity. These consist of a small vessel (usually about 2.5 × 5 m) in which the swimmer swims in place, either against the push of an artificially generated water current or against the pull of restraining devices. These pools have several names, such as swim spas, swimming machines, or swim systems. They are all examples of different modes of resistance swimming.		Hot tubs and spa pools are common heated pools used for relaxation and sometimes for therapy. Commercial spas are common in the swimming pool area or sauna area of a health club or fitness centre, in men's clubs, women's clubs, motels and exclusive five-star hotel suites. Spa clubs may have very large pools, some segmented into increasing temperatures. In Japan, men's clubs with many spas of different size and temperature are common. Commercial spas are generally made of concrete, with a mosaic tiled interior. More recently with the innovation of the pre-form composite method where mosaic tiles are bonded to the shell this enables commercial spas to be completely factory manufactured to specification and delivered in one piece. Hot tubs are typically made somewhat like a wine barrel with straight sides, from wood such as Californian redwood held in place by metal hoops. Immersion of the head is not recommended in spas or hot tubs due to a potential risk of underwater entrapment from the pump suction forces. However, commercial installations in many countries must comply with various safety standards which reduce this risk considerably.		Home spas are a worldwide retail item in western countries since the 1980s, and are sold in dedicated spa stores, pool shops, department stores, the Internet, and catalog sales books. They are almost always made from heat-extruded acrylic sheet Perspex, often colored in marble look-alike patterns. They rarely exceed 6 m2 (65 sq ft) and are typically 1 m (3 ft 3 in) deep, restricted by the availability of the raw sheet sizes (typically manufactured in Japan). There is often a mid-depth seating or lounging system, and contoured lounger style reclining seats are common. Upmarket spas include various jet nozzles (massage, pulsating, etc.), a drinks tray, lights, LCD flat-screen TV sets and other features that make the pool a recreation center. Due to their family-oriented nature, home spas are normally operated from 36 to 39 °C (97 to 102 °F). Many pools are incorporated in a redwood or simulated wood surround, and are termed "portable" as they may be placed on a patio rather than sunken into a permanent location. Some portable spas are shallow and narrow enough to fit sideways through a standard door and be used inside a room. Low power electric immersion heaters are common with home spas.		Whirlpool tubs first became popular in America during the 1960s and 1970s. A spa is also called a "jacuzzi" in USA since the word became a generic after plumbing component manufacturer Jacuzzi introduced the "spa whirlpool" in 1968. Air bubbles may be introduced into the nozzles via an air-bleed venturi pump that combines cooler air with the incoming heated water to cool the pool if the temperature rises uncomfortably high. Some spas have a constant stream of bubbles fed via the seating area of the pool, or a footwell area. This is more common as a temperature control device where the heated water comes from a natural (uncontrolled heat) geothermal source, rather than artificially heated. Water temperature is usually very warm to hot — 38 to 42 °C (100 to 108 °F), so bathers usually stay in for only 20 to 30 minutes. Bromine or mineral sanitizers are often recommended as sanitizers for spas because chlorine dissipates at a high temperature thereby heightening its strong chemical smell. Ozone is an effective bactericide and is commonly included in the circulation system with cartridge filtration, but not with sand media filtration due to clogging problems with turbid body fats.		In the early 20th century, especially in Australia, ocean pools were built, typically on headlands by enclosing part of the rock shelf, with water circulated through the pools by flooding from tidal tanks or by regular flooding over the side of the pools at high tide. This continued a pre-European tradition of bathing in rockpools with many of the current sites being expanded from sites used by Aboriginal Australians or early European settlers. Bathing in these pools provided security against both rough surf and sea life. There were often separate pools for women and men, or the pool was open to the sexes at different times with a break for bathers to climb in without fear of observation by the other sex.[26] These were the forerunners of modern "Olympic" pools. A variation was the later development of sea- or harbour-side pools that circulated sea water using pumps. A pool of this type was the training ground for Australian Olympian Dawn Fraser.		There are currently about 100 ocean baths in New South Wales, which can range from small pools roughly 25 metres long and "Olympic Sized" (50m) to the very large, such as the 50 × 100 m baths in Newcastle. While most are free, a number charge fees, such as the Bondi Icebergs Club pool at Bondi Beach. Despite the development of chlorinated and heated pools, ocean baths remain a popular form of recreation in New South Wales.		A semi-natural ocean pool exists on the central coast of New South Wales; it is called The Bogey Hole.		An infinity edge pool (also named negative edge or vanishing edge pool) is a swimming pool which produces a visual effect of water extending to the horizon, vanishing, or extending to "infinity". Often, the water appears to fall into an ocean, lake, bay, or other similar body of water. The illusion is most effective whenever there is a significant change in elevation, though having a natural body of water on the horizon is not a limiting factor.[citation needed]		Natural pools were developed in central and western Europe in the early and mid-1980s by designers and landscape architects with environmental concerns. They have recently been growing in popularity as an alternative to traditional swimming pools.[27] Natural pools are constructed bodies of water in which no chemicals or devices that disinfect or sterilize water are used, and all the cleaning of the pool is achieved purely with the motion of the water through biological filters and plants rooted hydroponically in the system. In essence, natural pools seek to recreate swimming holes and swimmable lakes, the environment where people feel safe swimming in a non-polluted, healthy, and ecologically balanced body of water.		Water in natural pools has many desirable characteristics. For example, red eyes, dried-out skin and hair, and bleached bathing suits associated with overly chlorinated water are naturally absent in natural pools.[citation needed] Natural pools, by requiring a water garden to be a part of the system, offer different aesthetic options and can support amphibious wildlife such as snails, frogs, and salamanders, and even small fish if desired.		A zero-entry swimming pool, also called a beach entry swimming pool, is a swimming pool having an edge or entry that gradually slopes from the deck into the water, becoming deeper with each step, in the manner of a natural beach. As there are no stairs or ladders to navigate, this type of entry assists older people, young children and people with accessibility problems (e.g., people with a physical disability) where gradual entry is useful.		Swimming pools are also used for events such as synchronized swimming, water polo, canoe polo and underwater sports such as underwater hockey, underwater rugby, finswimming and sport diving as well as for teaching diving, lifesaving and scuba diving techniques. They have also been used for specialist tasks such as teaching water-ditching survival techniques for aircraft and submarine crews and astronaut training. Round-cornered, irregular swimming pools, such as the Nude Bowl, were drained of water and used for vertical skateboarding.		Levels of bacteria and viruses in swimming pool water must be kept low to prevent the spread of diseases and pathogens. Bacteria, algae and insect larvae can enter the pool if water is not properly sanitized. Pumps, mechanical sand filters, and disinfectants are often used to sanitise the water.		Chemical disinfectants, such as chlorine (usually as a hypochlorite salt, such as calcium hypochlorite) and bromine, are commonly used to kill pathogens. If not properly maintained, chemical sanitation can produce high levels of disinfection byproducts. Sanitized swimming pool water can theoretically appear green if a certain amount of iron salts or copper chloride are present in the water.[28]		Acesulfame potassium has been used to estimate how much urine is discharged by swimmers into a pool.[29] In a Canadian study it was estimated that swimmers had released 75 litres of urine into a large pool that had about 830,000 litres of water and was a third of the size of an olympic pool. Hot tubs were found to have higher readings of the marker. While urine itself is sterile, its degradation products may lead to asthma.[29]		Swimming pool heating costs can be significantly reduced by using a pool cover. Use of a pool cover also can help reduce the amount of chemicals (chlorine, etc.) required by the pool. Outdoor pools gain heat from the sun, absorbing 75–85% of the solar energy striking the pool surface. Though a cover decreases the total amount of solar heat absorbed by the pool, the cover eliminates heat loss due to evaporation and reduces heat loss at night through its insulating properties. Most swimming pool heat loss is through evaporation.[30]		The heating effectiveness of a cover depends on type. A transparent bubble cover is the most effective, as it allows the largest amount of solar flux into the pool itself. Thermal bubble covers are lightweight UV-stabilized floating covers designed to minimize heat loss on heated swimming pools. Typically they are only fitted in spring and fall (autumn) when the temperature difference between pool water and air temperature is greatest. They raise temperature of a pool by around 20 °Fahrenheit, or 11 °Celsius, after being on the pool for a week. Bubble covers are typically applied and removed by being rolled up on a device fitted to one side of the pool (see illustration). Covers fall apart after four or five years due to sun exposure, overheating in the sun while off the pool, and chlorine attacking the plastic. Bubble covers should be removed during super chlorination.		A vinyl cover absorbs more sunlight directly, allowing temperature to rise faster, but ultimately prevents the pool from reaching as high a temperature as a clear cover.[31] Vinyl covers consist of a heavier material and have a longer life expectancy than bubble covers. Insulated vinyl covers are also available with a thin layer of flexible insulation sandwiched between two layers of vinyl.[31] These covers are mandatory[citation needed] to be fitted to all pools in areas of Australia that have experienced drought since 2006. This is an effort to conserve water, as much water evaporates and transpires.		An alternative to a continuous sheet of pool covering is multiple floating disks which are deployed and removed disk by disk. They cover most of the surface of the pool and offer evaporation reduction similar to continuous covers. Various types are available, for example opaque (for UV resistance and possible reduced algal growth), transparent (for esthetics), heavy and solid (for wind resistance), light and inflatable (for ease of handling).		These covers are typically attached all winter, by hooked bungee cords or hooked springs connected to the pool deck, and are usually made in a variety of materials including coated or laminated vinyl or polypropylene mesh. They are custom designed to stop leaf debris from entering the pool but more importantly they also provide safety for animals and small children when designed and installed properly. The custom safety cover was invented in 1957 by Fred Meyer Jr. of Meyco Pool Covers when he found a dead animal in his pool. Today covers are made to meet ASTM safety barrier standards and have kept animals, people and even large vehicles out of the pool. They are not popular in warmer climates, due to the five to ten minutes it takes to fit/remove them, making them inconvenient for repeated application and removal.		A pool cover can be either manually, semi-automatically, or automatically operated. Manual covers can be folded and stored in an off site location. Pool cover reels can also be used to help manually roll up the pool cover. The reel, usually on wheels, can be rolled in or out of place.		Semi-automatic covers use a motor-driven reel system. They use electrical power to roll and unroll the cover, but usually require someone to pull on the cover when unrolling, or guide the cover onto the reel when rolling up the cover. Semi-automatic covers can be built into the pool deck surrounding the pool, or can use reels on carts.		Automatic covers have permanently mounted reels that automatically cover and uncover the pool at the push of a button. They are the most expensive option, but are also the most convenient. These reels can be run from either an external motor requiring a pit to be dug beside the pool or using an internal motor that spins the reel.		Some pool covers fit into tracks along the sides of the pool. This prevents anything or anybody from getting into the pool. They even support the weight of several people. They can be run manually, semi-automatically, or automatically. Safety covers may be required by inspectors for public pools.[31]		In areas which reach freezing temperature, it is important to close a pool properly. This varies greatly between in-ground and above-ground pools. By taking steps to properly secure the pool, it lessens the likelihood that the superstructure will be damaged or compromised by freezing water.[32]		In preparation for freezing temperatures, an in-ground swimming pool's pipes must be emptied. An above-ground pool should also be closed, so that ice does not drag down the pool wall, collapsing its structure. The plumbing is sealed with air, typically with rubber plugs, to prevent cracking from freezing water. The pool is typically covered to prevent leaves and other debris from falling in. The cover is attached to the pool typically using a stretch cord, similar to a bungee cord and hooks fitted into the pool surround. The skimmer is closed off or a floating device is placed into it to prevent it from completely freezing and cracking. Floating objects such as life rings or basketballs can be placed in the pool to avoid its freezing under the cover. Sand or DE filters must be backwashed, with the main drain plug removed and all water drained out. Drain plugs on the pool filter are removed after the filter has been cleaned. The pool pump motor is taken under cover. Winter chemicals are added to keep the pool clean.[33] The innovation of a composite construction of fibreglass, with an epoxy coating and porcelain ceramic tiles has led to the Pre-form, Composite-type with significant advantages over older methods; however, it also has increased sensitivity to metal staining.		In climates where there is no risk of freezing, closing down the pool for winter is not so important. Typically, the thermal cover is removed and stored. Winter sunlight can create an algae mess when a cover that has been left on all winter is removed. The pool is correctly pH-balanced and super-chlorinated. One part algaecide for every 50,000 parts of pool water should be added, and topped up each month. The pool should be filtered for one to two hours daily to keep the automated chlorination system active.[citation needed]		Pools pose a risk of drowning, which may be significant for swimmers who are inexperienced, suffer from seizures, or are susceptible to a heart or respiratory condition. Lifeguards are employed at most pools to execute water rescues and administer first aid as needed in order to reduce this risk.		Diving in shallow areas of a pool may also lead to significant head and neck injuries; diving, especially head-first diving, should be done in the deepest point of the pool, minimally 2.4 m (7 ft 10 in), but desirably 3.7 m (12 ft), deeper if the distance between the water and the board is great.		Pools also present a significant risk of infant and toddler death due to drowning. In regions where residential pools are common, drowning is a major cause of childhood fatalities. As a precaution, many jurisdictions require that residential pools be enclosed with fencing to restrict unauthorized access. Many products exist, such as removable baby fences, floating alarms and window/door alarms to reduce the risk of drowning for infants. Some pools are equipped with computer-aided drowning prevention or other forms of electronic safety and security systems.		Suspended ceilings in indoor swimming pools are safety-relevant components. The selection of materials under tension should be done with care. Especially the selection of unsuitable stainless steels can cause problems with stress corrosion cracking.[34]		In public swimming pools, dress code may be stricter than on public beaches, and in indoor pools stricter than outdoor pools. For example, in countries where women can be topless on the beach, this is often not allowed in a swimming pool, and a swimsuit must be worn. For men, wearing ordinary shorts and a tee shirt to go in the water at a beach may be considered acceptable, but pools usually require real swim suits or other dedicated water wear. Swimming with regular clothes on is not only unhygienic,[citation needed] but can potentially weigh a swimmer down should he or she need to be rescued. In France and some other European countries, board shorts are usually not allowed for hygienic reasons. In Nordic countries and in particular Iceland, rules about clothing and hygiene are especially strict.[35] When diving from a high board, swim suits are sometimes worn doubled up (one brief inside another) in case the outer suit tears on impact with the water.		
Beachrock is a friable to well-cemented sedimentary rock that consists of a variable mixture of gravel-, sand-, and silt-sized sediment that is cemented with carbonate minerals and has formed along a shoreline. Depending on location, the sediment that is cemented to form beachrock can consist of a variable mixture of shells, coral fragments, rock fragments of different types, and other materials. It can contain scattered artifacts, pieces of wood, and coconuts. Beachrock typically forms within the intertidal zone within tropical or semitropical regions. However, Quaternary beachrock is also found as far north and south as 60' latitude.[1][2]						Beachrock units form under a thin cover of sediment and generally overlie unconsolidated sand. They typically consist of multiple units, representing multiple episodes of cementation and exposure. The mineralogy of beachrocks is mainly high-magnesium calcite or aragonite. The main processes involved in the cementation are : supersaturation with CaCO3 through direct evaporation of seawater,[3] groundwater CO2 degassing in the vadose zone,[4] mixing of marine and meteoric water fluxes[5] and precipitation of micritic calcium carbonate as a byproduct of microbiological activity.[6]		On retreating coasts, outcrops of beachrock may be evident offshore where they may act as a barrier against coastal erosion. Beachrock presence can also induce sediment deficiency in a beach and out-synch its wave regime. Because beachrock is lithified within the intertidal zone and because it commonly forms in a few years, its potential as an indicator of past sea level is important.		Beachrocks are located along the coastline in a parallel term and they are usually a few meters offshore. They are generally separated in several levels which may correspond to different generations of beachrock cementation. Thus, the older zones are located in the outer part of the formation when the younger ones are on the side of the beach, possibly under the unconsolidated sand. They also seem to have a general inclination to the sea (50 – 150). There are several appearances of beachrock formations which are characterized by multiple cracks and gaps. The result from this fact is an interruptible formation of separated blocks of beachrock, which may be of the same formation.		The length of beachrocks varies from meters to kilometers, its width can reach up to 300 meters and its height starts from 30 cm and reaches 3 meters.		Following the process of coastal erosion, beachrock formation may be uncovered. Coastal erosion may be the result of sea level rise or deficit in sedimentary equilibrium. One way or another, unconsolidated sand that covers the beachrock draws away and the formation is revealed. If the process of cementation continues, new beachrock would be formed in a new position in the intertidal zone. Successive phases of sea level change may result in sequential zones of beachrock.		
Particle size, also called grain size, refers to the diameter of individual grains of sediment, or the lithified particles in clastic rocks. The term may also be applied to other granular materials. This is different from the crystallite size, which refers to the size of a single crystal inside a particle or grain. A single grain can be composed of several crystals. Granular material can range from very small colloidal particles, through clay, silt, sand, gravel, and cobbles, to boulders.						Size ranges define limits of classes that are given names in the Wentworth scale (or Udden–Wentworth scale) used in the United States. The Krumbein phi (φ) scale, a modification of the Wentworth scale created by W. C. Krumbein[1] in 1937, is a logarithmic scale computed by the equation		where		This equation can be rearranged to find diameter using φ:		In some schemes, gravel is anything larger than sand (comprising granule, pebble, cobble, and boulder in the table above).		ISO 14688-1:2002, establishes the basic principles for the identification and classification of soils on the basis of those material and mass characteristics most commonly used for soils for engineering purposes. ISO 14688-1 is applicable to natural soils in situ, similar man-made materials in situ and soils redeposited by people.[2]		An accumulation of sediment can also be characterized by the grain size distribution. A sediment deposit can undergo sorting when a particle size range is removed by an agency such as a river or the wind. The sorting can be quantified using the Inclusive Graphic Standard Deviation:[3]		where		The result of this can be described using the following terms:		
A nude beach, sometimes called a clothing-optional or free beach, is a beach where users are legally at liberty to be nude. Nude beaches usually have mixed bathing. Such beaches are usually on public lands, and any member of the public is entitled to use the facilities without membership in any movement or subscription to any personal belief. The use of the beach facilities is normally anonymous. Unlike a naturist resort or facility, there is normally no membership or vetting requirement for the use of a nude beach. The use of nude beach facilities is usually casual, not requiring pre-booking. Nude beaches may be official (legally sanctioned), unofficial (tolerated by residents and law enforcement), or illegal. However, nude beaches are relatively few and are usually at some distance from cities, and access is at times more difficult than at a regular beach and the facilities at these beaches tend to be very basic with a few notable exceptions. Nude bathing is one of the most common forms of nudity in public. A nude beach should not be confused with a topless beach (or top-free beach), where upper body clothing is not required for women or men, although a swimming costume covering the genital area is required for both men and women. A nude beach should be considered as a clothes-free beach.		Nude beaches tend to be separate or isolated physically from non-nude bathing areas. In other instances people maintain a comfortable space between beach users. Signage is often used to warn unfamiliar beach users about the specially designated areas on the beach. This accommodates people who are not comfortable with nudity, as well as nude beach users who do not like to be watched by clothed individuals (see voyeurism).						Most nude beaches become accepted after many years of use as nude beaches. Many are "unmanaged" beach areas that have been adopted by the local users in an effort to maintain the beach's "quality". Others' right to existence has been recognized as such by the appropriate local authority, and are termed "official" (although not necessarily legitimate).		There are several categories of nude beaches:		Most beaches around the world, including nude beaches, are on public lands. That means that although private resorts and hotels that adjoin a beach may enclose their property behind fences with controlled access, most countries do not allow private ownership of the actual beach area. Thus, while a resort can control access and set clothing standards on its property, these standards would not necessarily apply to the beach itself, which remains subject to local laws or customs, and public access to the beach itself usually remains unrestricted. This applies, for example, to the islands in the Caribbean, Mexico, and Florida. On the Seven Mile Beach in Negril, Jamaica, for example, though the beach is lined with private resorts with fences down to the sand/waterline, the beach itself is open to the public. Though actual clothing standards vary from resort to resort, the beach area is officially designated as "topfree", and public access is unrestricted.		The International Naturist Federation has developed a code of conduct, or etiquette, for use by member organizations. The INF nude beach etiquette requires the avoidance of all forms of sexual harassment and sexual activity, such as masturbation or sexual intercourse. Predatory behavior is not permitted, nor is unauthorized photography.[2] In general, the standards call for the respecting of the privacy of other visitors. Staring is frowned upon by rule and social pressure.[3]		However, unlike nudist resorts and hotels, which can enforce standards of conduct on their properties promptly and effectively, most nude beaches are on public lands, making the enforcement of standards of nude beach etiquette a more personal matter, subject to the deterrence of local laws. The standards of conduct take different forms in different countries. Other than the fact that people using a nude beach expect to find naked people on the beach, most other local laws and customs continue to apply.		Nude beaches became popular in the 1950s along the French coast[4] and have since spread around the world, though they are still few and far between. Some nude beaches are part of a larger nude area, such as the Cap d'Agde area. Most beaches in Denmark[5][6] and some beaches in Norway[7] are clothing-optional. In Germany there are clothes optional sunbathing areas in public parks, e.g., Munich[8] and Berlin.[9] Beaches in some holiday destinations, such as Crete, are also clothing-optional, except some central urban beaches.[10] There are two centrally located clothes-optional beaches in Barcelona.[11]		Though free beaches developed separately from national naturist bodies, some of these bodies have taken an interest and helped to protect them legally, and through the publication of guidelines of acceptable behaviour.[12] In North America, the Free Beach Movement was the name of a group that was opposed to the direction of the official nudist organisation, the American Association for Nude Recreation, and set up the rival body The Naturist Society. Clothes free organizations and free beach associations, such as the Naturist Action Committee, lobby for the removal of laws which prohibit nude swimming and sunbathing or the increase in the number of nude beaches and sometimes to improve the amenities at nude beaches.		
Llandudno (Welsh pronunciation: [ɬanˈdɪdnɔ]) is a seaside resort, town and community in Conwy County Borough, Wales, located on the Creuddyn peninsula, which protrudes into the Irish Sea. In the 2011 UK census, the community, which includes Penrhyn Bay and Penrhynside, had a population of 20,701.[1] The town's name is derived from its patron saint, Saint Tudno.		Llandudno, "Queen of the Welsh Resorts", a title first applied as early as 1864,[2] is now the largest seaside resort in Wales. Historically a part of Caernarfonshire, Llandudno was formerly in the district of Aberconwy within Gwynedd.						The town of Llandudno developed from Stone Age, Bronze Age and Iron Age settlements over many hundreds of years on the slopes of the limestone headland, known to seafarers as the Great Orme and to landsmen as the Creuddyn Peninsula. The origins in recorded history are with the Manor of Gogarth conveyed by King Edward I to Annan, Bishop of Bangor in 1284.[citation needed] The manor comprised three townships, Y Gogarth in the south-west, Y Cyngreawdr in the north (with the parish church of St Tudno) and Yr Wyddfid in the south-east.		Mostly owned by Mostyn Estates, Great Orme is home to several large herds of wild Kashmiri goats originally descended from several goats given by Queen Victoria to Lord Mostyn. The summit of the Great Orme stands at 679 feet (207 m). The Summit Hotel, now a tourist attraction, was once the home of world middleweight champion boxer Randolph Turpin.		A haven for flora and fauna with some rare species such as peregrine falcons and a species of wild cotoneaster (cambricus) which can only be found on the Great Orme. The sheer limestone cliffs of the Great Orme provide ideal nesting conditions for a wide variety of sea birds, including cormorants, shags, guillemots, razorbills, puffins, kittiwakes, fulmars and numerous gulls.		This great limestone headland has many attractions including the Great Orme Tramway and the Llandudno Cable Car that takes tourists effortlessly to the summit.		By 1847 the town had grown to a thousand people, served by the new church of St George, built in 1840. The great majority of the men worked in the copper mines, with others employed in fishing and subsistence agriculture.		In 1848, Owen Williams, an architect and surveyor from Liverpool, presented Lord Mostyn with plans to develop the marshlands behind Llandudno Bay as a holiday resort. These were enthusiastically pursued by Lord Mostyn. The influence of the Mostyn Estate and its agents over the years was paramount in the development of Llandudno, especially after the appointment of George Felton as surveyor and architect in 1857. Between 1857 and 1877 much of central Llandudno was developed under Felton's supervision.[citation needed] Felton also undertook architectural design work, including the design and execution of Holy Trinity Church in Mostyn Street.		The town is just off the North Wales Coast railway line which was opened as the Chester and Holyhead Railway in 1848. It became part of the London and North Western Railway in 1859, and part of the London, Midland and Scottish Railway in 1923. Llandudno was specifically built as a mid-Victorian era holiday destination and is served by a branch railway line opened in 1858 from Llandudno Junction with stations at Deganwy and Llandudno.		The Llandudno and Colwyn Bay Electric Railway operated an electric tramway service between Llandudno and Rhos-on-Sea from 1907 and extended to Colwyn Bay in 1908. The service closed in 1956.[3]		Modern Llandudno takes its name from the ancient parish of Saint Tudno but also encompasses several neighbouring townships and districts including Craig-y-Don, Llanrhos and Penrhyn Bay. Also nearby is the small town and marina of Deganwy and these last four are in the traditional parish of Llanrhos. The ancient geographical boundaries of the Llandudno area are complex. Although they are on the eastern side of the River Conwy (the natural boundary between north-west and north-east Wales), the ancient parishes of Llandudno, Llanrhos and Llangystennin (which includes Llandudno Junction) were in the medieval commote of Creuddyn in the Kingdom of Gwynedd, and afterwards part of Caernarfonshire. Today, Deganwy and Llandudno Junction are part of the town community of Conwy even though they are across the river and only linked to Conwy by a causeway and bridge.		A beach of sand, shingle and rock curves two miles between the headlands of the Great Orme and the Little Orme.		For most of the length of Llandudno's North Shore there is a wide curving Victorian promenade. The road, collectively known as The Parade, has a different name for each block and it is on these parades and crescents that many of Llandudno's hotels are built. Near the centre of the bay is the Venue Cymru. The Llandudno Sailing Club and a roundabout mark the end of this section of The Parade and beyond are more hotels and guest houses but they are in the township of Craig-y-Don.		At Nant-y-Gamar Road, the Parade becomes Colwyn Road with the fields of Bodafon Hall Farm on the landward side but with the promenade continuing until it ends in a large paddling pool for children and finally at Craigside on the lower slopes of the Little Orme.		The award-winning pier is on the North Shore. Built in 1878, it is a Grade II listed building.		The pier was extended in 1884 in a landward direction along the side of what was the Baths Hotel (where the Grand Hotel now stands) to provide a new entrance with the Llandudno Pier Pavilion Theatre, thus increasing the pier's length to 2,295 feet (700 m): it is the longest pier in Wales. Attractions on the pier include a bar, a cafe, amusement arcades, children's fairground rides and an assortment of shops & kiosks.		In the summer, Professor Codman's Punch and Judy show (established in 1860) can be found on the promenade near the entrance to the pier.		The Happy Valley, a former quarry, was the gift of Lord Mostyn to the town in celebration of the Golden Jubilee of Queen Victoria in 1887. The area was landscaped and developed as gardens, two miniature golf courses, a putting green, a popular open-air theatre and extensive lawns. The ceremonies connected with the Welsh National Eisteddfod were held there in 1896 and again in 1963. In June 1969, the Great Orme Cabin Lift, a modern alternative to the tramway, was opened with its base station adjacent to the open-air theatre. The distance to the summit is just over one mile (1.6 km) and the four-seater cabins travel at 6 mph on a continuous steel cable over two miles (3 km) long. It is the longest single-stage cabin lift in Britain, and the longest span between pylons is over 1,000 feet (300 m). The popularity of the 'Happy Valley Entertainers' open-air theatre having declined, the theatre closed in 1985 and likewise the two miniature golf courses closed and were converted in 1987 to create a 280-metre (920 ft) artificial ski slope and toboggan run. The gardens were extensively restored as part of the resort's millennium celebrations and remain a major attraction.		The first route round the perimeter of the Great Orme was a footpath constructed in 1858 by Reginald Cust, a trustee of the Mostyn Estate. In 1872 the Great Ormes Head Marine Drive Co. Ltd. was formed to turn the path into a carriage road. Following bankruptcy, a second company completed the road in 1878. The contractors for the scheme were Messrs Hughes, Morris, Davies, a consortium led by Richard Hughes of Madoc Street, Llandudno.[4] The road was bought by Llandudno Urban District Council in 1897.[5] The 4 miles (6.4 km) one way drive starts at the foot of the Happy Valley. After about 1.5 miles (2.4 km) a side road leads to St. Tudno's Church, the Great Orme Bronze Age Copper Mine and the summit of the Great Orme. Continuing on the Marine Drive one passes the Great Orme Lighthouse (now a small hotel) and, shortly afterwards on the right, the Rest and Be Thankful Cafe and information centre. Below the Marine Drive at its western end is the site of the wartime Coast Artillery School (1940–1945) now a scheduled ancient monument.[6]		The West Shore is the quiet beach on the estuary of the River Conwy. It was here at Pen Morfa that Alice Liddell (of Alice in Wonderland fame) spent the long summer holidays of her childhood from 1862 to 1871. There are a few hotels and quiet residential streets. The West Shore is linked to the North Shore by Gloddaeth Avenue and Gloddaeth Street, a wide dual carriageway.		Running behind the promenade is Mostyn Street leading to Mostyn Broadway and then Mostyn Avenue. These are the main shopping streets of Llandudno and Craig-y-Don. Mostyn Street accommodates the high street shops, the major high street banks and building societies, two churches, amusement arcades and the town's public library. The last is the starting point for the Town Trail,[7] a carefully planned walk that facilitates viewing Llandudno in a historical perspective.		Every year in May bank holiday weekend, Llandudno has a three-day Victorian Carnival[8] and Mostyn Street becomes a funfair. Madoc Street and Gloddaeth Street and the Promenade become part of the route each day of a mid-day carnival parade. The Bodafon Farm fields become the location of a Festival of Transport[9] for the weekend.		The North Wales Theatre, Arena and Conference Centre, built in 1994, extended in 2006 and renamed "Venue Cymru" is located near the centre of the promenade on Penrhyn Crescent. It is noted for its productions of opera, orchestral concerts, ballet, musical theatre, drama, circus, ice shows and pantomimes.		Llandudno is unique within the United Kingdom in that its lifeboat station is located inland, allowing it to launch with equal facility from either the West Shore or the North Shore as needed. Llandudno's active volunteer crews are called out more than ever with the rapidly increasing numbers of small pleasure craft sailing in coastal waters. The Llandudno Lifeboat is normally on display on the promenade every Sunday and bank holiday Monday from May until October. In 2014 a planning application was submitted for a new Lifeboat station, with a larger boat, to be built close to the paddling pool on North Shore.		The ancient parish church dedicated to Saint Tudno stands in a hollow near the northern point of the Great Orme and two miles (3 km) from the present town. It was established as an oratory by Tudno, a 6th-century monk, but the present church dates from the 12th century and it is still used on summer Sunday mornings. It was the Anglican parish church of Llandudno until that status was transferred first to St George’s (now closed) and later to Holy Trinity Church in Mostyn Street.		The principal Christian Churches of Llandudno are members of Cytûn (churches together) and include the Church in Wales (Holy Trinity and also Saint Paul's at Craig-y-Don), the Roman Catholic Church of Our Lady Star of the Sea, Saint John's Methodist Church, Gloddaeth United Church (Presbyterian), Assemblies of God (Pentecostal), Llandudno Baptist Church, St. David's Methodist Church at Craig-y-Don, the Coptic Orthodox Church of Saint Mary and Saint Abasikhiron, and Eglwys Unedig Gymraeg Llandudno (the United Welsh Church of Llandudno).		A member of the local Methodist community is the Revd Roger Roberts, now Lord Roberts of Llandudno, Liberal Democrat Spokesman for International Development in the House of Lords.		Llandudno is home to a Jewish centre in Church Walks, which serves the local Jewish population – one of few in North Wales. There is also a Buddhist centre, Kalpa Bhadra, on Mostyn Avenue in Craig-y-Don.		Llandudno is twinned with the Flemish town of Wormhout 10 miles (16 km) from Dunkirk. It was there that many members of the Llandudno-based 69th Territorial Regiment were ambushed and taken prisoner. Later, at nearby Esquelbecq on 28 May 1940, the prisoners were shot.[10]		The 1st (North Wales) Brigade was headquartered in Llandudno in December 1914 and included a battalion of the Royal Welch Fusiliers, which had been raised and trained in Llandudno. During the 1914–18 war this Brigade, a major part of the 38th Welsh Division, took part in the Battle of the Somme and the Brigade was ordered to take Mametz Wood. Two days of fighting brought about the total destruction of Mametz village by shelling. After the war, the people of Llandudno (including returning survivors from the 38th Welsh Division) contributed generously to the fund for the reconstruction of the village of Mametz.[11]		Llandudno hosted the Welsh National Eisteddfod in 1864, 1896 and 1963, and in 2008 welcomed the Urdd National Eisteddfod to Gloddaeth Isaf Farm, Penrhyn Bay. The town also hosted the Liverpool Olympic Festival in 1865 and 1866.		Matthew Arnold gives a vivid and lengthy description of 1860s Llandudno – and of the ancient tales of Taliesin and Maelgwn Gwynedd that are associated with the local landscape — in the first sections of the preface[12] to On the Study of Celtic Literature (1867).		Elisabeth of Wied, the Queen Consort of Romania and also known as writer Carmen Sylva, stayed in Llandudno for five weeks in 1890. On leaving, she described Wales as "a beautiful haven of peace".[13] Translated into Welsh as "hardd, hafan, hedd", it became the town's official motto.		Other famous people with links to Llandudno include the Victorian statesman John Bright and multi-capped Welsh international footballers Neville Southall, Neil Eardley , Chris Maxwell and Joey Jones. Australian ex-Prime Minister Billy Hughes attended school in Llandudno. Gordon Borrie QC (Baron Borrie), Director General of the Office of Fair Trading from 1976 to 1992, was educated at the town's John Bright Grammar School when he lived there as a wartime evacuee.		The international art gallery, Oriel Mostyn, is in Vaughan Street next to the post office. It was built in 1901 to house the art collection of Lady Augusta Mostyn. It was requisitioned in 1914 for use as an army drill hall and later became a warehouse, before being returned to use as an art gallery in 1979. Following a major revamp the gallery was renamed simply 'Mostyn' in 2010.		Llandudno has its own mini arts festival 'LLAWN' (Llandudno Arts Weekend) which has been running for the past three years (LLAWN01 −2013, LLAWN02 – 2014, LLAWN03 – 2015). LLAWN is a mini festival that rediscovers and celebrates Llandudno’s past in rather a unique way; via art, architecture, artefact, sound, performance, and participation. The festival takes place over three days of the weekend in late September,originally conceived as a way to promote what those in the hospitality sector refer to as the ‘shoulder season’, which means a lull in the tourist calendar. The festival is supported by Arts Council Wales, Mostyn Estates, Conwy County Borough Council, MOSTYN and Llandudno Town Council.[14]		In January 1984 Brookside character Petra Taylor (Alexandra Pigg) committed suicide in Llandudno.		In 1997, the English cookery programme "Two Fat Ladies" with Jennifer Patterson and Clarissa Dickson Wright shot an episode in Llandudno.		
A beach advisory is a warning given by a local government to avoid swimming in a body of water.[1] Beach advisories do not automatically close bodies of water to swimmers but instead function as a warning to swimmers against swimmining at a particular site.[2]		Beach advisories are issued after unsafe levels of Enterococcus are detected at sample sites along a body of water, often resulting from high levels of fecal matter in the water.[1] One source of waste pollution and subsequent increase in enteroccus concentration may come from migrating birds.[3] Enterococcus bacteria is not harmful by itself, but it indicates harmful bacteria is in the water. These types of bacteria can cause gastrointestinal illnesses, resulting in vomiting and diarrhea.[1][3] They may also cause upper respiratory illness as well as skin infections at an open wound.[3]		Beach advisories are also issued after chemical spills.[4] Beach advisories are often issued after rain advisories because high amounts of rain can cause contaminated streamflow from flooding to enter a body of water and contaminate the swimming area.[4][5]						1. Overview		2. Reasons for Beach Advisories		2.1 Enterococcus		2.2 Escherichia coli (E. coli)		2.3 Illnesses		2.4 Swimmer’s Itch		Enterococcus		Enterococcus is a large genus of lactic acid phylum Firmicutes[1] Fecal enterococci inhabit gastrointestinal tract of animals. Therefore, having abnormally high indicators of fecal enterococcus in bodies of water correlates directly to fecal contamination (Domingo et al., 2003). Domingo also suggests that using the TaqMan-based approach[2] can detect Enterococcus in environmental waters. This method may be performed in the span of a few hours, making it an efficient system that local governments may rely on, while issuing a beach advisory. Another method to detect large numbers of enterococcus in water is an agar-based growth media incubated under standard aerobic conditions. While conducting various tests involving selective as well as non-selective methods, cultures of enterococcus are isolated in brass and earthen vessels for up to 48 hours (Chhibber et al., 2007). Enterococcus may cause an array of illnesses, varying from cellulitis, prostatitis, diverticulitis, urinary tract infections (UTI), endocarditis as well intra-abdominal infections (Bush, 2013).		Cellulitis		The Mayo Clinic defines cellulitis as a common but potentially serious bacterial skin infection (2015). Symptoms of cellulitis include skin swelling, tenderness, redness and skin feeling hot. Cellulitis does not usually spread from person to person, but may enter the body by cracks or breaks in the skin. Cellulitis usually appears on the lower parts of the legs but may spread anywhere on the body. Cellulitis begins by affecting merely the surface of the skin, but may migrate to the tissues, affecting lymph nodes and eventually the bloodstream. If left untreated, the spreading infection may become life-threatening. It is crucial that one seeks medical treatment if the previously mentioned symptoms occur.		Prostatitis		Enterococcus may also cause prostatitis. Prostatitis is the swelling and inflammation of the prostate gland that is located below men’s bladders. Prostatitis can cause painful or difficult urination. Other symptoms may also include pain in the groin, pelvic area and flu-like symptoms. It is important to seek medical attention immediately once experiencing one or more of the symptoms. Prostatitis may be treated by taking antibiotics, but left untreated may cause medical complications concerning the prostate.		Diverticula are small pouches that form in the lining of the digestive system, generally in the lower part of the large intestine. Although there are a small number of implications, there may be swelling of one or more of the pouches. This may lead to infections and can cause extreme abdominal pain, fever, nausea and irregular bowel movements (Mayo Clinic, 2015). Simply resting and taking antibiotics can treat diverticulitis, although serious cases may require surgery.		Escherichia coli (E. coli)		Escherichia coli, or E. coli is a bacterium that can be found in many warm-blooded animals, which includes, humans, livestock, wildlife and birds (government of Manitoba). Escherichia coli does not usually cause illness by itself, but when it contaminates large numbers, the level of illness raises. E. coli is expelled into the environment via fecal matter. According to the Public Health Agency of Canada (2015), drinking contaminated water or drinking contaminated food may contract E. coli infections. E. coli may also be spread from one person to another. Symptoms may include nausea, diarrhea, vomiting and severe stomach cramps. Symptoms may appear anywhere from 3 to 10 days after ingestion of the bacteria.		There has been a study in Manitoba concerning the elevated E. coli numbers in Lake Winnipeg. The Interim Report of the Manitoba Water Stewardship, 2009 explains reasons for elevated Escherichia coli in Lake Winnipeg Beaches (Williamson et al., 2009). The Interim Report shows the correlation of high counts of Escherichia coli in the Lake with large discharge of sewage from the City of Winnipeg, run-offs from livestock operations into Lake Winnipeg. The lake had issued countless amounts of beach advisories to the public once it was noticed that irregular amounts of E. coli was found in the water. Studies had proved that the high number of E. coli in bathing water was partially due to wind-induced water level changes and that the majority of it originated from animal sources as opposed to human activity.		Urinary Tract Infection (UTI)		A Urinary Tract Infection is an infection that involves any part of the urinary system, being the kidneys, urethra, bladder, or ureters. Although women are more susceptible to getting UTI’s, men may also develop them. The infection causes pain while urinating, the urge to urinate often, and pelvic pain. UTIs may be caused by Escherichia coli, which as mentioned above, may be found in bodies of water at the time of beach advisories. Generally, UTIs can be treated with antibiotics that are prescribed by a doctor.		[1] Firmicutes are a phylum of bacteria, in which most have Gram-positive cell wall structure. Many firmicutes are resistant to desiccation and are able to survive extreme conditions.		[2] Taq-man is a chemistry formulation that is used to test the presence of certain bacteria, including enterococcus in large bodies of water.		Swimmer’s Itch		Swimmer’s Itch is a skin condition that occurs to people who partake in open-water activities. Swimmer’s itch may happen in any body of water in the world and is not exclusive to one specific region. The condition involves the cercarial dermatitis to penetrate the skin, while dying in the epidermis, causing the itching sensation (Blankespoor et al., 2004). Beach advisories may be put in place if there is an outbreak of swimmer’s itch, but its importance in the public health sector is still unknown. Outbreaks and reoccurring beach advisories may influence vacationers to travel elsewhere although its severity is still in question.		Bush, M. Larry, & Perez, T. Maria. (2013). Enterococcus Infections. Merck Manual, Professional Version. Retrieved from http://www.merckmanuals.com/professional/infectious-diseases/gram-positive-cocci/enterococcal-infections		Mayo Clinic Staff. (2015, February 11). Diseases and Conditions. [Website]. Retrieved from http://www.mayoclinic.org/diseases-conditions/cellulitis/basics/definition/con-20023471		Public Health Agency of Canada. (2015). E. Coli. Retrieved from http://www.phac-aspc.gc.ca/fs-sa/fs-fi/ecoli-eng.php		Santo, D. J. W., Siefring, S. C., & Haugland, R. A. (January 1, 2003). Real-time PCR method to detect Enterococcus faecalis in water. Biotechnology Letters, 25, 3, 261-5.		S J Corbett, G L Rubin, G K Curry, and D G Kleinbaum. The health effects of swimming at Sydney beaches. The Sydney Beach Users Study Advisory Group. American Journal of Public Health December 1993: Vol. 83, No. 12, pp. 1701-1706.		doi: 10.2105/AJPH.83.12.170		Tandon, P., Chhibber, S., & Reed, R. H. (January 1, 2007). Survival & detection of the faecal indicator bacterium Enterococcus faecalis in water stored in traditional vessels. The Indian Journal of Medical Research, 125, 4, 557-566.		Verbrugge, L. M., Rainey, J. J., Reimink, R. L., & Blankespoor, H. D. (January 1, 2004). Prospective study of swimmer's itch incidence and severity. The Journal of Parasitology, 90, 4, 697-704.		Williamson, D. A., & Manitoba. (2004). Principal factors affecting Escherichia coli at Lake Winnipeg beaches, Manitoba, Canada: Interim report. Winnipeg: Manitoba Water Stewardship.		
Blackpool /ˈblækpuːl/ ( listen) is a seaside resort on the Lancashire coast in North West England. The town is on the Irish Sea, between the Ribble and Wyre estuaries, 15 miles (24 km) northwest of Preston, 27 miles (43 km) north of Liverpool, 28 miles (45 km) northwest of Bolton and 40 miles (64 km) northwest of Manchester. It had an estimated population of 142,065 at the 2011 Census.[2][3]		Throughout the Middle Ages and Early Modern period, Blackpool was a coastal hamlet in Lancashire's Hundred of Amounderness, and remained such until the mid-18th century when it became fashionable in England to travel to the coast in the summer to improve well-being. In 1781, visitors attracted to Blackpool's 7-mile (11 km)[4] sandy beach were able to use a new private road, built by Thomas Clifton and Sir Henry Hoghton. Stagecoaches began running to Blackpool from Manchester in the same year, and from Halifax in 1782. In the early 19th century, Henry Banks and his son-in-law John Cocker erected new buildings in Blackpool such that its population grew from less than 500 in 1801 to over 2,500 in 1851. St John's Church in Blackpool was consecrated in 1821.		Blackpool rose to prominence as a major centre of tourism in England when a railway was built in the 1840s connecting it to the industrialised regions of Northern England. The railway made it much easier and cheaper for visitors to reach Blackpool, triggering an influx of settlers, such that in 1876 Blackpool was incorporated as a borough, governed by its own town council and aldermen. In 1881, Blackpool was a booming resort with a population of 14,000 and a promenade complete with piers, fortune-tellers, public houses, trams, donkey rides, fish-and-chip shops and theatres.[4] By 1901 the population of Blackpool was 47,000, by which time its place was cemented as "the archetypal British seaside resort".[4] By 1951 it had grown to 147,000.		Shifts in tastes, combined with opportunities for Britons to travel overseas, affected Blackpool's status as a leading resort in the late 20th century. Nevertheless, Blackpool's urban fabric and economy remains relatively undiversified, and firmly rooted in the tourism sector, and the borough's seafront continues to attract millions of visitors every year.[4] In addition to its sandy beaches, Blackpool's major attractions and landmarks include Blackpool Tower, Blackpool Illuminations, the Pleasure Beach, Blackpool Zoo, Sandcastle Water Park, the Winter Gardens, and the UK's only surviving first-generation tramway.						Blackpool gets its name from a historic drainage channel (possibly Spen Dyke) that ran over a peat bog, discharging discoloured water into the Irish Sea, which formed a black pool (on the other side of the sea, "Dublin" (Dubh Linn) is derived from the Irish for "black pool"). Another explanation is that the local dialect for stream was "pul" or "poole", hence "Black poole".		People originating from Blackpool are called Blackpudlians although Sandgrownians or Sandgrown'uns is sometimes used[citation needed] (as too for persons originating from Morecambe and Southport) or Seasiders (although this is more commonly associated with Blackpool F.C.).		A 13,500-year-old elk skeleton was found with man-made barbed bone points (probably from spears) on Blackpool Old Road in Carleton in 1970. Now displayed in the Harris Museum this provided the first evidence of humans living on the Fylde as far back as the Palaeolithic era.[5] The Fylde was also home to a British tribe, the Setantii (the "dwellers in the water") a sub-tribe of the Brigantes, who from about AD80 were controlled by Romans from their fort at Dowbridge, Kirkham. During the Roman occupation the area was covered by oak forests and bog land.		Some of the earliest villages on the Fylde, which were later to become part of Blackpool town, were named in the Domesday Book in 1086. Many of them were Anglo-Saxon settlements. Some though had 9th and 10th century Viking place names. The Vikings and Anglo-Saxons seem to have co-existed peacefully, with some Anglo-Saxon and Viking placenames later being joined together – such as Layton-with-Warbreck and Bispham-with-Norbreck. Layton was controlled by the Butlers, Barons of Warrington from the 12th century.		In medieval times Blackpool emerged as a few farmsteads on the coast within Layton-with-Warbreck, the name coming from "le pull", a stream that drained Marton Mere and Marton Moss into the sea close to what is now Manchester Square. The stream ran through peatlands that discoloured the water, so the name for the area became "Black Poole". In the 15th century the area was just called Pul, and a 1532 map calls the area "the pole howsys alias the north howsys".		In 1602, entries in Bispham Parish Church baptismal register include both Poole and for the first time blackpoole. The first house of any substance, Foxhall, was built toward the end of the 17th century by Edward Tyldesley, the Squire of Myerscough and son of the Royalist Sir Thomas Tyldesley. An Act of Parliament in 1767 enclosed a common, mostly sand hills on the coast, that stretched from Spen Dyke southwards. Plots of the land were allocated to landowners in Bispham, Layton, Great Marton and Little Marton. The same act also provided for the layout of a number of long straight roads that would be built in the areas south of the town centre, such as Lytham Road, St. Annes Road, Watson Road and Highfield Road.[6]		By the middle of the 18th century, the practice of sea bathing to cure diseases was becoming fashionable among the wealthier classes, and visitors began making the arduous trek to Blackpool for that purpose. In 1781, Thomas Clifton and Sir Henry Hoghton built a private road to Blackpool, and a regular stagecoach service from Manchester and Halifax was established. A few amenities, including four hotels, an archery stall and bowling greens, were developed, and the town grew slowly. The 1801 census records the town's population at 473. The growth was accelerated by the actions of Henry Banks, often considered to be the "Father of Blackpool". In 1819 he purchased the Lane Ends estate, including the Lane Ends Hotel, and built the first holiday cottages. In 1837, his son-in-law Dr. John Cocker built Blackpool's first assembly rooms, which still stand on the corner of Victoria Street and Bank Hey street.		The most significant event in the early growth of the town occurred in 1846, with the completion of a branch line to Blackpool from Poulton on the main Preston and Wyre Joint Railway line from Preston to Fleetwood. Fleetwood declined as a resort, as its founder and principal financial backer, Peter Hesketh-Fleetwood, went bankrupt. In contrast, Blackpool boomed. A sudden influx of visitors, arriving by rail, provided the motivation for entrepreneurs to build accommodation and create new attractions, leading to more visitors and a rapid cycle of growth throughout the 1850s and 1860s. In 1851 a Board of Health was formed. Gas lighting was introduced in 1852, and piped water in 1864. By 1851, the town's population was over 2,500.		The growth was intensified by the practice among the Lancashire cotton mill owners of closing the factories for a week every year to service and repair machinery. These became known as wakes weeks. Each town's mills would close for a different week, allowing Blackpool to manage a steady and reliable stream of visitors over a prolonged period in the summer.		In 1863, the North Pier was completed, rapidly becoming a centre of attraction for elite visitors. Central Pier was completed in 1868, with a theatre and a large open-air dance floor. The town expanded southward beyond what is today known as the Golden Mile, towards South Shore, and South Pier was completed in 1893, making Blackpool the only town in the United Kingdom with three piers. In 1878, the Winter Gardens complex opened, incorporating ten years later the Opera House, said to be the largest in Britain outside London.		From the 1880s until the First World War, Blackpool was one of the regular destinations for the Bass Excursions, when fifteen trains would take 8-9000 employees of Bass's Burton brewery on an annual trip to the seaside.		The town was granted a Charter of Incorporation as a municipal borough in 1876. W.H. Cocker, son of Dr John Cocker, and therefore grandson of Henry Banks, was its first mayor. The town would become a county borough in 1904.		Much of Blackpool's growth and character from the 1870s on was predicated on the town's pioneering use of electrical power. In 1879, it became the first municipality in the world to have electric street lighting, as large parts of the promenade were wired. The lighting and its accompanying pageants reinforced Blackpool's status as the North of England's most prominent holiday resort, and its specifically working class character. It was the forerunner of the present-day Blackpool Illuminations. In 1885 one of the world's first electric tramways was laid down as a conduit line running from Cocker Street to Dean Street on the Promenade. The line was operated by the Blackpool Electric Tramway Company until 1892 when their lease expired and Blackpool Corporation took over running the line. A further line was added in 1895 from Manchester Square along Lytham Road to South Shore, and the line was extended north, first to Gynn Square in 1899, and then to Fleetwood. In 1899 the conduit system was replaced by overhead wires. The tramway has remained in continuous service to this day.		By the 1890s, the town had a population of 35,000, and could accommodate 250,000 holidaymakers. The number of annual visitors, many staying for a week, was estimated at three million. 1894 saw the opening of two of the town's most prominent buildings, the Grand Theatre on Church Street, and Blackpool Tower on the Promenade. The Grand Theatre was one of Britain's first all-electric theatres.		The first decade of the new century saw the development of the Promenade as we know it today, and further development southwards beyond South Shore towards Harrowside and Squires Gate. The Pleasure Beach was first established about this time. Seasonal static illuminations were first set up in 1912, although due to World War I and its aftermath they only enjoyed two seasons until they were re-introduced in 1925. The illuminations extended the holiday season into September and early October.		The inter-war period saw Blackpool attain pre-eminence as a holiday destination. By 1920, Blackpool claimed around eight million visitors per year, three times as many as its nearest British rivals, still drawn largely from the mill towns of East Lancashire and the West Riding of Yorkshire. Stanley Park was laid out in 1920 and opened in 1926. The area round the park has become renowned for some of the most desirable residences in the area.		In 1937, Littlewoods opened its first department store in the town.[7]		Documents have been found to suggest that the reason Blackpool escaped heavy damage in World War II was that Adolf Hitler had earmarked the town to remain a place of leisure after his planned invasion.[8] Despite this, on 11 September 1940, German bombs fell near Blackpool North railway station and eight people were killed in nearby houses in Seed Street This site today is occupied by the new Town Hall offices and Sainsbury's Supermarket. No plaque is erected to remember the injured or dead.		In the same war, the Free Polish Air Force made its headquarters in exile at Blackpool in Talbot Square, after the force evacuated to Britain from France. The nearby Layton Cemetery contains the war graves of 26 Polish airmen.[9] The famous No. 303 Polish Fighter Squadron[10] was formed in Blackpool, and became the most successful Fighter Command unit shooting down 126 German machines in only 42 days during the Battle of Britain.[11]		Blackpool's population boom was complete by 1951, by which time some 147,000 people were living in the town – compared to 47,000 in 1901 and a mere 14,000 in 1881.[12] In the decade after the war, the town continued to attract more visitors, reaching a zenith of 17 million per year. However, several factors combined to make this growth untenable. The decline of the textile industry led to a de-emphasis of the traditional week-long break, known as wakes week. The rise of package holidays took many of Blackpool's traditional visitors abroad, where the weather was more reliably warm and dry, and improved road communications, epitomised by the construction of the M55 motorway in 1975, made Blackpool more feasible as a day trip rather than an overnight stay. The economy, however, remains relatively undiversified, and firmly rooted in the tourism sector.		The Blackpool Co-operative Society Emporium, a flagship store built in 1938, which incorporated the Jubilee Theatre, stood on Coronation Street, until 1988 when it was demolished for a planned shopping centre. The site remained empty until eventually becoming a car park and then was re developed when the Hounds Hill Centre was expanded to include the Debenham's Store.[13]		Though the Blackpool Urban Area extends beyond the statutory boundaries of Blackpool to encompass Fleetwood, Cleveleys, Thornton, Poulton-le-Fylde and Lytham St Annes, Blackpool remains administratively separate.		Between 1904 and 1974, Blackpool formed a county borough independent of the administrative county of Lancashire. With the passage of the Local Government Act 1972, Blackpool's county borough status was abolished and it was made part of the shire county of Lancashire. On 1 April 1998, however, Blackpool was made a unitary authority and re-formed as an autonomous local government unit. It remains part of Lancashire for ceremonial purposes, however.		As of the 2015 election Blackpool Council is currently controlled by the Labour Party, who took control from the Conservatives in 2011. They are the largest party represented with 29 councillors followed by the Conservative Party with 13 councillors.		This is a chart of the trend of regional gross value added (GVA) of Blackpool at current basic prices by the Office for National Statistics with figures in millions of British Pounds Sterling.[14]		While Blackpool hosts a large number of small businesses and self-employed people, there are some large employers. The government-owned National Savings and Investments is based at Marton, together with their Hardware random number generator, ERNIE ( "Electronic Random Number Indicator Equipment"), which picks the Premium Bond numbers, while other government agencies are based at Warbreck and Norcross further up the Fylde coast. Burton's Biscuit Company Tangerine Confectionery produce biscuits and other confectionery products, Klarius UK manufactures automotive components, Victrex manufactures high performance polymers and the Glasdon Group is a plastics manufacturer making litter bins, park benches and reflective road signs.		TVR formerly produced sports cars at its Bispham factory.[15] Blackpool was also the original site of Swallow Sidecar Company, forerunner of Jaguar Cars.		The 2015 HSBC research on rental yields ranks Blackpool in the top three cities with the best rental returns.[16] The numerous urban regeneration projects, the property prices which are among the most affordable in the UK, and the high rental yields create a very favourable environment for real estate investors.[17]		Retail is also becoming a major contributor to Blackpool's economy;[citation needed] many Blackpool residents work in the retail sector, either in the town centre or the retail parks on the edge of town.		Blackpool's main shopping streets are Church Street, Victoria Street, Birley Street, Market Street, Corporation Street, Bank Hey Street, Abingdon Street and Talbot Road. There is currently one shopping centre within the town, Houndshill Shopping Centre. This has recently been redeveloped with the opening of a new Debenhams department store along with other major high street names.		Blackpool has, like all of the UK, a temperate maritime climate according to the Köppen climate classification system. Thus the same cool summer, frequent overcast skies, and small annual temperature range is typical.		The absolute minimum temperature stands at −15.1 °C (4.8 °F),[18] recorded during December 1981. The lowest temperature to occur in recent years is −11.9 °C (10.6 °F)[19] during December 2010. In a more normal winter, the coldest night averages −7.6 °C (18.3 °F).[20]		The absolute maximum temperature recorded at Blackpool was 33.7 °C (92.7 °F)[21] during July 1976. The highest temperature to occur in recent years is 33.5 °C (92.3 °F) during July 2015.[22] In a more normal summer, the warmest day will likely average 28.1 °C (82.6 °F),[23] with slightly fewer than 5 days[24] a year attaining a temperature of 25.1 °C (77.2 °F) or above.		Rainfall averages slightly less than 900 mm (35 in), with over 1 mm of precipitation occurring on 143 days of the year.		Blackpool is heavily dependent on tourism. In what is often regarded as its heyday (1900–1950), Blackpool thrived as the factory workers of Northern England took their annual holidays there en masse. Any photograph from that era shows crowds of tourists on the beach and promenade. Blackpool was also a preferred destination of visitors from Glasgow and remains so to this day.[27] The town went into decline when cheap air travel arrived in the 1960s and the same workers decamped to the Mediterranean coastal resorts due to competitive prices and the more reliable weather.[28] Today Blackpool remains the most popular seaside resort in the UK; however, the town has suffered a serious drop in numbers of visitors which have fallen from 17 million in 1992 to 10 million today.[29] Similarly Pleasure Beach Blackpool was the country's most popular free attraction with 6 million visitors a year but has lost over a million visitors since 1998 and has recently introduced a £5 entrance fee.[30] Today, many visitors stay for the weekend rather than for a week at a time.		In July 2010, an independent survey of 4,500 members of the general public by consumer magazine Which? Holiday (now Which? Travel) found that Blackpool was the UK's favourite seaside resort, followed by Brighton, Whitby, Bournemouth and Scarborough. Blackpool has now improved the seawall and promenade, and Blackpool Tower has been revamped.		In February 2012, a number of tourist attractions in Blackpool collaborated to produce the Blackpool Resort Pass which allows for discounted access in one ticket. The original pass included visits to Merlin Entertainments attractions and Blackpool Pleasure Beach. In February 2013, Marketing Blackpool, formerly the Tourism division of Blackpool Council, led the relaunch of the Blackpool Resort Pass which includes additional attractions including Blackpool Zoo, Sandcastle Waterpark and Blackpool Model Village and Gardens.		Blackpool has a pioneering publicly owned Municipal wireless network Wi-Fi, which covers the entire town centre, promenade and beach front. Visitors can take a virtual tour of Blackpool, and full internet access is available.		Outside the main holiday season, Blackpool's Winter Gardens routinely hosts major political and trade union conferences, ranging from that of the Conservative Party and the Transport and General Workers Union with thousands of delegates and visitors, to substantially smaller gatherings such as the Communication Workers Union conference. The Labour Party, though, now uses facilities in Manchester when, every alternate year, its annual conference is in the North of England.		The National Union of Students last held its Annual Conference in Blackpool in 2009; they will now be hosted by the Sage Gateshead. In January 2011, Blackpool hosted the NEEC Conference (formerly the North of England Education Conference), a key date in the education calendar. The Winter Gardens also hold the National Pensioners' Parliament.[31]		The 'Young Farmers' convention has been held regularly in Blackpool since the late 1960s.[32]		Blackpool remains a summer through to the end of the illuminations in November and all holiday periods entertainment venue, specialising in variety shows featuring entertainers catering to a broad range of tastes, from family friendly Ken Dodd to the 'adults only' humour of Roy 'Chubby' Brown. Ken Dodd can regularly be seen throughout late summer at the Grand Theatre.		The Grand Theatre (locally known as 'The Grand') was designed by Victorian theatre architect Frank Matcham and was opened in 1894 after a construction period of seven months, at a cost of £20,000 between December 1893 and July 1894. The project was conceived and financed by local theatre manager Thomas Sergenson who had been using the site of the Grand for several years to stage a circus. He had also transformed the fortunes of other local theatres.		Matcham's brief was to build Sergenson the "prettiest theatre in the land". The Grand was Matcham's first theatre to use an innovative 'cantilever' design to support the tiers, thereby reducing the need for the usual pillars and so allowing clear views of the stage from all parts of the auditorium.		Sergenson's successful directorship of the theatre ended in 1909 when he sold the operation to the Blackpool Tower Company for a considerable profit.		The success of the Grand continued through World War I and on until the 1930s. The theatre now faced stiff competition from the newly introduced talking films and the building was operated as a cinema outside the summer tourist season. This practice continued until 1938 when the nearby Winter Gardens Opera House was constructed.		The theatre was able to stay open during World War II but the post-war rise in the popularity of television was probably the cause of the theatre's dwindling popularity toward the 1960s.[citation needed] Plans were filed for the demolition of the historic site in 1972 but the Grand's status as a Grade II* listed building was sought and obtained by a group of friends, thereby preventing this from taking place. An agreement was reached with the Grand's owners, EMI, that a refurbishment of the then unused building would take place if it could be used as a bingo hall. After three years of bingo use, the group of friends, now called the Friends of the Grand, with the support of Blackpool Borough Council, negotiated to lease and eventually buy the theatre back from EMI over a period of a few years. The purchase was complete by 1 October 1980 and a refurbishment, achieved partly through voluntary effort, was begun. Finally, on 23 March 1981 the Grand re-opened as a theatre once again to stage an Old Vic performance of William Shakespeare's The Merchant of Venice featuring Timothy West and Prunella Scales. The theatre's return was further confirmed in May of the same year when a Royal Variety Performance was staged in the presence of Prince Charles.		The town also plays host to the longest running seaside show in Britain, Legends, which features multiple tribute artistes with a live band and dance troupe, first appearing at the North Pier in 1999, then at the Central Pier from 2000 to 2012 and now at the Sands Venue, located in the Palatine buildings (formerly the Palace nightclub) on the promenade near Blackpool Tower. Current tribute artistes include "Neil Diamond", "Adele", "Elton John" and "Robbie Williams".		Blackpool plays host to several major events each year. From music festivals and dance competitions, to the greatest free light show on earth.		Blackpool is often described as the "gay capital of the North" (with Brighton often being described as "the gay capital of the South").[35][36] Blackpool had its first gay pride celebration in 2006.[37] Historically, seaside resorts have been able to provide niches for minority groups.[38] Blackpool, like other English resorts, has had a reputation for being a safe community for gay people.[38] During World War II, there was a proliferation of cafés, pubs and clubs where homosexual men could meet in Blackpool.[39] In the 1990s, the town began to be promoted as a gay tourist destination.[38] Blackpool contains several bars, pubs and nightclubs aimed at the LGBT community. These include Funny Girls (a burlesque cabaret showbar), Buzz, Flamingo, the Flying Handbag, Roxy's, Mardi Gras, KAOS and Taboo/Lucys @ tabago.[40] The local gay community is now also catered for by an online radio station – Blackpool Gay Radio – featuring a mix of music, local news, features and celebrity interviews.		In the late 20th century and early 21st century, pollution in the seawater at Blackpool caused considerable concern. In particular it was found that bacteria counts frequently exceeded the standards of the Environment Agency.[41][42][43][44][45] However, sea water quality has improved significantly in recent years, with the resort's south beach winning a Blue Flag award in 2016, and three other beaches achieving Seaside Award Status.[46][47]		Blackpool is continually striving to improve its position within today's tourist industry. One controversial proposal, which had the involvement of the local council, was to transform Blackpool into a casino resort along the lines of the Las Vegas Strip and Atlantic City, making it the centre point of gambling in the UK. During all the seven-year campaign the Council did not allow a single public meeting, where the public could hear the case for, and the case against the proposals.[citation needed] Early in the campaign a survey indicated 95% of Blackpool residents would prefer non-gambling related regeneration.[citation needed] For over five years the Gazette refused to publish any of the concerns of those critical of the slot machine proposals.[citation needed] Ultimately, Manchester was selected for the initial trial by the Government's Casinos Advisory Panel.[48] Since this decision, Blackpool's council and MPs have lobbied Parliament extensively, claiming their bid was misunderstood. The local newspaper, the Blackpool Gazette, sent a petition signed by over 11,500 local residents and visitors demanding the decision be reconsidered. On 29 March 2007, the Advisory Panel's recommendations were approved by the House of Commons, but rejected by the House of Lords, meaning the bill would be reconsidered by parliament.[49] However, in early 2008 the House of Lords voted against the super-casino proposal, and the Government proceeded no further with the idea.[citation needed]				The Talbot Gateway is a planned £285m civic quarter, for which international project management specialist AMEC has been chosen to transform a currently rundown area around Blackpool North railway station into what Blackpool Council hope will be a world-class gateway with new office and retail space as well as a public square, dubbed the Talbot Plaza. The development would be 'wrapped' around Blackpool North railway station so that rail passengers arrive at street level into the new plaza with views down onto the seafront, making their arrival into Blackpool a much more pleasant experience than at present. The regeneration company behind much of the towns current and future development, ReBlackpool, are working with Blackpool Council and AMEC to prepare a planning application.[50]		Regeneration work was completed in July 2009 on Waterloo Road in South Shore that transformed the area into a modern shopping centre. £1 million of public investment is helping to improve the public realm and act as a catalyst for the regeneration of South Shore.[51]		In March 2010 it was confirmed that a deal had been made between Blackpool Council and Leisure Parcs to purchase some of Blackpool's most notable landmarks.[52] The deal, totalling £38.9m, had national and local government backing and included the purchase of:		It was also announced that the Tower would be run by Merlin Entertainments Group (who run the London Eye) as well as it seeing a programme of repairs totalling £10m, the first phase was scheduled to be complete for the 2011 season. Merlin Entertainments Group also took over the running of Louis Tussauds Wax Works, converting it into their bigger and better-known brand, Madame Tussauds Wax Works.[53] The Winter Gardens were purchased by Blackpool Council; the complex is operated by Crown Entertainment Centres Ltd.[54]		Both the Northwest Development Agency (NWDA) and Blackpool's regeneration company ReBlackpool were crucial players in securing the deal.		Blackpool boasts some important landmarks, most of which appeared originally as part of the flourishing tourist industry.		Blackpool International Airport operated regular charter and scheduled flights throughout the UK and Europe. The airport is actually just over the borough boundary into Fylde Borough, although a proposal to reorganise Blackpool's borders would see the airport incorporated into Blackpool Borough. This airport, formerly known as Blackpool Squires Gate Airport, is one of the oldest in the UK having hosted public flying meetings in 1909 and 1910. After a gap, it has been active from the 1930s to mid 2014 and from December 2014 to date. Airlines that served Blackpool before its temporary closure in late 2014 included Jet2.com and Aer Arran. The Airport was reopened to small aircraft after failing to find a buyer in December 2014.[55]		Consumer champion Which? Holiday found that Blackpool Airport was the favourite among its members in a major independent survey. The airport, which flies to about 20 destinations, received an overall customer score of 80 per cent. It received five stars for the efficiency of check-in, the time it takes to clear security and distance from check-in to the gate, and the overall airport experience, including signage, design of the airport and attitude of staff.		Other than Blackpool's current services to Belfast and the Isle Of Man, access to the town by air is via Liverpool John Lennon Airport or Manchester Airport, both approximately 60 miles away by road.		In 1927 the local council announced that an airfield would be built near Stanley Park, which would become Stanley Park Aerodrome offering flights to the Isle of Man for £1-16s–0d (£1.80).[56] The airport opened in 1929 and was officially opened by then British Prime Minister Ramsay MacDonald in 1931.[57] However, with the opening of Squires Gate Airport a decision was announced in 1936 by the Ministry of Transport to close the Stanley Park airfield. In fact, civil operations continued until the outbreak of war with scheduled services to the Isle of Man and elsewhere.[58] During the war, Stanley Park was used as a Royal Air Force training station, known as No. 3 School of Technical Training. Vickers assembled many Wellington bombers here and Beaufighters were repaired for the RAF. The airfield closed in 1947. The land on which the airport stood now covers Blackpool Zoo and a hotel and golf course. The hangars from the old airport are still in use as the elephant enclosure for the zoo.[57]		Facilities include:		Train operators that serve Blackpool are:		Stations in the town are, or were:		Blackpool once had two railway termini with a total of over 30 platforms, mainly used by excursion traffic in the summer. Blackpool Central, close to Blackpool Tower, was closed in 1964, while Blackpool North was largely demolished and rebuilt as a smaller facility. The route of the former excursion line into Blackpool Central is now used as a link road from the M55 motorway to the town centre. The line into Blackpool via Lytham St Annes now has a station serving Blackpool Pleasure Beach but terminates at Blackpool South station. The line into North station is now the more important.		The M55 motorway links the town to the national motorway network. Other major roads in the town are the A583 to Kirkham and Preston, the A587 to Fleetwood, the A586 to Poulton-le-Fylde, Garstang and Lancaster and the A584 and B5261 which both lead to Lytham St Annes		Blackpool tramway runs from Starr Gate in Blackpool to Fleetwood and is the only surviving first-generation tramway in the United Kingdom.[60] The tramway dates back to 1885 and is one of the oldest electric tramways in the world. It is run by Blackpool Transport, owned by Blackpool Council. The tramway runs for 11 miles (18 km) and carries 6,500,000 passengers each year.[61]		The tramway was for a long time the only working tramway in the United Kingdom outside of museums. It was also the UK's first electric system. However, there are now a number of other tramways, including Manchester Metrolink, South London Tramlink, Nottingham Express Transit and Sheffield Supertram.		On 1 February 2008 it was announced that the Government had agreed to a joint Blackpool Transport and Blackpool Council bid for funding toward the total upgrade of the track. The government contributed £60.3m of the total £85.3m cost. Blackpool Council and Lancashire County Council each provided about £12.5m. The Government's decision meant that the entire length of the tramway from Starr Gate to Fleetwood was upgraded and also sixteen state-of-the-art trams joined the fleet.[62]		In April 2012, the tramway reopened after the major reconstruction. Day to day services are run by the 16 Flexity 2 trams. Several double deck 'Balloon' trams from the older fleet have been widened to work alongside the new trams to provide additional capacity in the summer months. Several non-modified older trams also operate a 'heritage' service from Pleasure Beach to Little Bispham on weekends and holidays.[63]		An extension of the new service to Blackpool North Railway Station is planned to open by April 2019.		The resort is featured in the 1934 film Sing as We Go, starring Gracie Fields, as well as other cinema and TV productions, including Forbidden (1949), Hindle Wakes (1952), Holiday (1957),[64] Coasting (1990),[65] Funny Bones (1995) starring Lee Evans and Oliver Platt and directed by St. Annes born Peter Chelsom, and The Parole Officer (2001) starring Steve Coogan.		The Japanese film Shall We Dance? (1996) closes with a scene at the World Ballroom Dancing Championships in Blackpool. All the hair styling for the film was completed by Blackpool-born-and-bred hairstylist Eileen Clough, who has been in the trade since the 1960s. In the Hollywood remake of the film (2004), directed by Peter Chelsom, Blackpool is mentioned but not shown.		Blackpool is the setting for Bhaji on the Beach (1993) directed by Gurinder Chadha. The film Like It Is (1998) directed by Paul Oremland was also partly filmed in Blackpool. The opening scenes were filmed in the Flamingo. The 2005 television comedy/thriller series Funland revolved around the fictionalised, seedier aspects of Blackpool.		The town also features heavily in the BBC television serial Blackpool, starring David Morrissey, Sarah Parish and David Tennant and first broadcast in 2004, and the one-off follow-up Viva Blackpool, broadcast in June 2006.		In 2006 Lion Television filmed The Great British Summer, which featured many iconic buildings in Blackpool. The Royal Windsor Hotel was featured, with the owner talking all about the hotel seasons and industry. Bernard Manning was also shown at the hotel doing his spot through the season hosted by a local DJ (BMD) and other local acts. The Great British Summer was narrated by Alan Titchmarsh.		Between 10 September 2012 and 19 November 2012 the resort was featured in Channel 4's 999: What's Your Emergency?.		The resort was also featured in the three-part reality television series, Blackpool Lights on Channel 5 in December 2013.[66][67]		As well as this, the 2016 Tim Burton film Miss Peregrine's Home for Peculiar Children also features Blackpool and its key tourist attraction, The Blackpool Tower.		Reginald Dixon, MBE, ARCM, who held the position as organist at the Tower Ballroom, Blackpool from March 1930 until March 1970 made and sold more recordings than any other organist.[68]		Blackpool Symphony Orchestra was founded by Percy Dayman in 1920. It presents an annual series of concerts and organises educational and community outreach projects.[69]		The Beatles had a long and varied association with Blackpool, including a significant event in John Lennon's early childhood[70] and multiple gigs in the town between 1963 and 1965.[71]		Formed in Blackpool in 1963, The Rockin' Vickers were a rock and roll beat combo most notable for featuring Ian "Lemmy" Kilmister, then known as Ian Frasier, later of Hawkwind and more famously Motörhead, as a guitarist. The band recorded four singles before splitting in 1967. The other Rockin' Vickers guitarist, Nick Gribbon, continues to perform in pubs in and around Blackpool as Nick Unlimited, with an open door policy that has given many talented younger Blackpool musicians their first opportunity to play live.[72]		The Executives were a Blackpool band who recorded a handful of singles in the 1960s including the original 1964 version of March of the Mods, which became a top 40 hit for Joe Loss and His Orchestra in the same year. The tune was written by Tony Carr, the father of Executives' frontman Roy Carr,[73] who later became a well-known music journalist with New Musical Express and the author of several books on popular music and executive editor of music magazines including New Musical Express, Melody Maker and Vox.[74] Executives bass player Glenn Cornick became a founding member of Jethro Tull, later forming Wild Turkey. Tony Williams, The Executives' guitarist, joined Stealers Wheel soon after its formation in 1967 and also briefly joined Jethro Tull in 1978 as a touring bassist.		Blackpool was notorious for having imposed an indefinite ban on the Rolling Stones from performing in the town in 1964 after a riot broke out among the audience who had found their performance "suggestive" during their concert at the Empress Ballroom. The ban was lifted forty-four years later in March 2008.[75][76]		The Jimi Hendrix – Experience video and DVD features concert footage of Hendrix's performance at Blackpool's Opera House in 1967.[77]		Complex were formed in Blackpool in 1970 and self-released 2 albums in 1971. Only 99 copies of their self-titled debut were pressed and this extremely rare vinyl album has since been described as "one of the "Holy Trinity" items of rare British Psychedelia".[78] The band continued to play until 1978 when they disbanded with the onset of punk.[79] Limited edition remastered versions of both Complex albums were released by Guersson in 2012.[80][81]		A number of bands from Blackpool achieved a level of success during the punk and post-punk era. Factory Records' Section 25[82] were formed in 1977 in Poulton-Le-Fylde, a small market town on the outskirts of Blackpool, as were the 1976–79 version of punk band Skrewdriver, who recorded several singles and an album for the Chiswick record label[83] (the skinhead "white power" rock act of the same name that gained notoriety later, contained only one member of the original band). Both bands claimed Blackpool as their place of origin.		Another Blackpool band signed to Factory was Tunnelvision,[84][85] who recorded just one single for the label in 1981.		When Barry Lights relocated his Lightbeat record label from Leeds to Blackpool in 1981, the label's first Blackpool signing was electronic rock band Zoo Boutique.[86] After releasing the debut single by Fleetwood punk band One Way System, Lights set up specialist hardcore punk Beat the System label. Blackpool punk band The Fits were amongst the first to benefit, eventually releasing four indie chart hit singles in 1982–85.[87]		The Membranes who featured John Robb initially set up their own Vinyl Drip record label in 1981 before achieving three indie top 20 hits from 1984–86,[87] reaching number 6 in John Peel's Festive Fifty in 1984[88] and making a pre-recorded appearance on Channel 4 rock show The Tube.		The Ceramic Hobs formed in 1985 and to date have "made more than 30 uncategorisable releases on vinyl, CD and cassette for many different worldwide record labels".[89][90]		Blackpool musician Lucifer's "Cyber Punk Rock" EPs of 1994 contained the first full vocal songs intended for playback on a computer.[91][92]		21st century musical exports from Blackpool include Karima Francis, The Locals, who first appeared on BBC Introducing when they were just 15,[93] Goonies Never Say Die, Litterbug, Aiden Grimshaw who came ninth on the 2010 series of X Factor, The Senton Bombs, UFX/Uncle Fester and Little Boots, who topped the BBC Sound of... poll in 2009.		The White Stripes recorded their first official DVD, Under Blackpool Lights, at the Empress Ballroom in the Winter Gardens on 27 and 28 January 2004. Get Up Kids guitarist Jim Suptic's Kansas City, Missouri indie rock band Blackpool Lights is named after the DVD title.		In 2005, a compilation album, The Ugly Truth About Blackpool Volume One, chronologically documenting the best of Blackpool indie rock music from 1977 to 2005, was released by Andy Higgins' JSNTGM Records in conjunction with the Arts Council, Blackpool Evening Gazette and Blackpool Council.[94][95] Volume 2, showcasing the best Blackpool indie bands active in 2005/6 was released the following year.[96][97] Other Blackpool recording artists on JSNTGM include Sick 56, Erase Today and Litterbug.[98]		Each August since 2006, Blackpool has been the venue for the largest festival of punk rock in the world, the annual Rebellion Festival, which is held in the Winter Gardens over four days and features over 200 punk bands.[99]		In early 2013, Grime music in Blackpool increased dramatically with the invention of BGMedia. They now have over 28 million views as they were made famous after becoming viral on YouTube.[100]		In 1937 George Formby's song "With My Little Stick of Blackpool Rock", was banned by BBC radio for having suggestive lyrics.[101]		The Kinks' song "Autumn Almanac" contains the following lines: "... I go to Blackpool for my holidays/Sit in the open sunlight ..."		"She Sold Blackpool Rock" was a minor success in 1969 for Honeybus as the follow up to their 1968 top ten hit single "I Can't Let Maggie Go".		Graham Nash's semi-autobiographical song "Military Madness" begins "In an upstairs room in Blackpool / By the side of a northern sea / The army had my father / And my mother was having me".		Paul McCartney recorded a song entitled "Blackpool" amongst a number of demo home recordings in the years 1971 and 1972.[102]		The Jethro Tull song "Up the 'Pool" from the 1972 Living in the Past album is about Blackpool, singer Ian Anderson and other members of the band's childhood home. Another Tull track about the beach attractions of Blackpool is "Big Dipper", from the 1976 album Too Old to Rock 'n' Roll: Too Young to Die!.		In the early 1980s the then Blackpool based band The Membranes used the town as the subject matter for their Tatty Seaside Town 1988 single, which was later covered by Therapy?		Other songs written about Blackpool include Oh Blackpool by Beautiful South and several different songs called Blackpool, by Sham 69, Macc Lads, Roy Harper and The Delgados. "Blackpool" is also the title song from a production co-written with author Irvine Welsh and Vic Godard (Subway Sect) in 2002, later released as a four-song EP called "Blackpool". A song called "Blackpool Fool" appears on the Frank Sidebottom album A,B,C & D(1997).[103]		Songs that mention Blackpool in the lyrics include "Elvis Impersonator: Blackpool Pier", the opening track of the Manic Street Preachers album Everything Must Go, which contains the lyrics "20ft high off Blackpool Promenade" amongst other references to Blackpool. The opening line of Soft Cell's 1982 "Say Hello, Wave Goodbye" hit (later a hit for David Gray in 1998) "Standing at the door of the Pink Flamingo, Crying in the rain" is believed to be a reference to Blackpool's famous gay nightclub The Flamingo. Låpsley's chillout song "Painter (Valentine)" includes the lines "you can paint these wings and make me fly/ crush coming over like the R.E.M kind/ orange in the colour like Blackpool on the sunrise".		Franz Ferdinand's 2013 "Love Illumination" single was originally called "Blackpool Illuminati".[104]		Folk songs written about the town include The Houghton Weavers anthem "The Blackpool Belle" ("Oh the Blackpool Belle was a getaway train that went from Northern stations. What a beautiful sight on a Saturday night bound for the illuminations"), Jasper Carrot's "Day Trip To Blackpool" ("Didn't we have a miserable time the day we went to Blackpool? An 'orrible day, we got drunk on the way And spent our money on chips and bingo...")[105] and Mike Harding's single "Talking Blackpool Blues" ("Well my Mam and Dad and Gran and me / We went to Blackpool by the sea / It rained and rained for most of the day / But we all got tanned in a funny sort of way").[106]		John Evan, Keyboard player of Jethro Tull (1969-1980), leader of The Blades, John Evan Band and John Evan Smash; Jeffrey Hammond-Hammond, bass guitarist of Jethro Tull, (1970_1975), David Ball (of Soft Cell), singer-songwriter Roy Harper, Chris Lowe (of Pet Shop Boys), Nick McCarthy (of Franz Ferdinand), Larry Cassidy (of Section 25), Gary Miller (who had a hit with The Yellow Rose of Texas), Graham Nash (of The Hollies / Crosby, Stills, Nash & Young), Robert Smith (of The Cure) and folk singer Maddy Prior. Victoria Christina Hesketh, better known as her stage name Little Boots, was also born in Blackpool. The conductor David Atherton, co-founder of the London Sinfonietta, was born in Blackpool.		Newspapers that cover the Blackpool area include the Blackpool Gazette, the daily newspaper covering the Fylde Coast area, known locally as The Gazette. They also publish a free weekly newspaper, the Blackpool Reporter, which is delivered to householders in Blackpool. The Gazette also publishes a daily online version in Polish, Witryna Polska (Polish Gazette) to cater for the local Polish community.[107] The Lancashire Evening Post is a daily evening newspaper covering the county of Lancashire.		Blackpool has a pioneering publicly owned Municipal wireless network, Wi-Fi which covers the entire town centre & promenade & beach front. Visitors can take a virtual tour of Blackpool, to discover all they need to know to enjoy their time in Blackpool. Full internet access is available via the publicly owned Municipal wireless network, The vouchers are available from the Tourist information office, Council offices & a selection of town centre businesses and conference venues as well as at a selection of Blackpool libraries displaying the Wireless Blackpool logo. Using a WiFi enabled laptop or mobile device simply connect to the Wireless network to gain instant access to a selection of local sites. To access the World Wide Web you will then need to use a Wireless Blackpool voucher. Simply scratch off the silver panel on the voucher and enter the individual Username and Password into the relevant boxes on the Wireless Blackpool landing page.[108][109]		Local radio is provided by Radio Wave, a commercial radio station based on Mowbray Drive in Blackpool which covers the Fylde Coast area. The radio station broadcasts on 96.5FM and is owned by media company UTV. Blackpool also falls in the coverage area of BBC Radio Lancashire, Rock FM, Magic 999, Smooth FM 100.4 and 105.4 Real Radio.		Blackpool Gay Radio provides a part-time radio service catering for the local gay community featuring a mix of music, local features, news and celebrity interviews.		Blackpool also has four music related internet radio stations:		Radio Victoria, based in Victoria Hospital broadcasts throughout the hospital and is aiming for an FM licence for 2013		Each supplies a variety of music broadcast throughout the world 24-hours a day.		National television with local opt outs is provided by ITV Granada, the ITV franchise holder for the North West, BBC North West, the regional BBC station for the North West region.		Blackpool also has a dedicated local TV news service, That's Lancashire, organised by the That's TV network. This is broadcast from their studio in Preston.[113]		Blackpool has 2 main venues for boxing fight nights, they are the Tower Circus Arena and the Winter Gardens which both hold regular fight nights throughout the year. Events at these venues have been screened on Sky Sports, British Eurosport and Channel M. Current promotions stables who host events in Blackpool are Matchroom Boxing and VIP Boxing Promotions.		Blackpool is home to many current and former professional boxers including Brian Rose (born in Birmingham), Jack Arnfield, Jeff Thomas (born in Dordrecht), Mathew Ellis (born in Oldham), Matty Askin (born in Barnsley), RP Davies and Scott Cardle. Not forgetting the late Neville Rowe		MMA fighters Leeroy Barnes who fights out of Cage Warriors, Shak Khan who is also a Pro wrestler/Street (Shoot) fighter and Karl Etherington the son of Judo champ Bill Etherington are also from Blackpool.		Blackpool Cricket Club are Blackpool's major cricketing team; they won the League Cup in 2013, and were National Champions in 1990. They won the Lancashire Cup on eight occasions between 1973 and 1996 and were League Champions fourteen times.[citation needed] Their home is in the grounds of Stanley Park, which also hosts Lancashire County Cricket Club.		The town's professional football club is Blackpool F.C., who have spent 31 seasons in the top division and won the 1953 FA Cup Final. There are other, smaller football clubs located within Blackpool, including A.F.C. Blackpool, Blackpool Wren Rovers and Squires Gate.		Blackpool Borough were the first professional rugby league club in the town. However, they eventually folded after leaving the town in 1987. Blackpool Panthers were formed in 2004 and played in Co-operative Championship One. They ground-shared at Woodlands Memorial Ground, the home of Fylde Rugby Club in the neighbouring town of Lytham St Annes. The club ceased to exist after the 2010 season due to lack of finance.[114] Blackpool also has a rugby union club, called Blackpool RUFC. Their home ground is Norbreck Rugby Ground. The resort formerly held the now discontinued Northern Rail Cup Final at Bloomfield Road, a Rugby League knockout competition for all clubs outside of the Super League attracting many thousands of visitors.		The annual Blackpool Marathon is staged on the Promenade each April. Thousands of competitors run on the closed Promenade, organised by Fylde Coast Runners.		The Pleasure Beach's Horseshoe Show Bar was home to professional wrestling events throughout the season. These were promoted by Bobby Baron. The bar shows were home to a "Wrestling Booth", where members of the public could challenge the wrestlers for cash prizes for each round they survived. These challenges would be taken by shooters: wrestlers skilled in the brutal submission holds of Catch Wrestling, which they could deploy to defend the prize money even against skilled amateur wrestlers. Booths such as these had been a foundation stone of the professional wrestling industry since the 19th century – Barron's booth is reputed to have been the last of its kind in the world.[115]		Numerous renowned professional wrestlers worked as carnival shooters at the booth, including future WWE star William Regal (then known as Steve Regal), his then tag team partner Robbie Brookside, promoter, trainer and champion Shak Khan (who runs a school for teaching Catch Wrestling in Blackpool), future British Ladies' Wrestling champion Klondyke Kate, and others including Dave Duran, (John Palin) The booth ended with Baron's death in 1994, although other promoters have since held shows in the bar.[115]		Additionally, the Tower Circus was a frequent venue for wrestling shows. A photograph of noted heel Jack Pye in action at the circus was, for some time in the late 2000s, displayed by the entrance to the circus. The tradition was revived by All Star Wrestling when they promoted a summer season at the venue in 2008, and a similar summer season in 2012 at the Winter Gardens.		WWE held a tournament at the Empress Ballroom on 14-15 January 2017 to crown the inaugural WWE United Kingdom Champion. In attendance were Regal and WWE legend Triple H, who commented to local journalists, "Blackpool has this reputation. It’s easy to get to, a lot of people come here and when they come here they lose it and that’s what we wanted. I almost feel like there wasn’t really another choice.." [116] Tyler Bate won the inaugural tournament to become the first WWE United Kingdom Champion.[117]		Blackpool has a number of Christian churches including eighteen Anglican and ten Roman Catholic churches.[118] Other Christian groups in the town include Blackpool Baptist Tabernacle, Blackpool Christian Centre, Blackpool Community Church, Kings Christian Centre, Liberty Church, (Metropolitan Community Church) and New Life Community Church.[118] The Shrine of Our Lady of Lourdes in Whinney Heys Road, built in 1955–57, is now redundant and is being converted into a community centre by the Historic Chapels Trust.[119]		There is a residential Buddhist Centre in North Shore, Keajra Kadampa Buddhist Centre, a member of the New Kadampa Tradition – International Kadampa Buddhist Union.[118] There are two mosques: the purpose-built Blackpool Central Mosque & Islamic Community Centre is located on Revoe Street and provides prayer facilities for local Muslims, and the Blackpool Islamic Community Centre (BICC) which offers Islamic education.[120]		There are two synagogues in Blackpool for its Jewish population. The Blackpool Reform Jewish Congregation is located on Raikes Parade with a synagogue hall and classroom facilities, a purpose-built sanctuary hall and an assembly room. Blackpool United Hebrew Congregation (closed) is located on Leamington Road with a synagogue hall and community centre.[118] The synagogue closed in May 2012 due to a declining orthodox Jewish population, the last minister Rabbi David Braunold having retired in 2011. As of January 2016 the synagogue building was awaiting new use.		Blackpool also has small communities of Bahá'í, Hindus, Jains, Mormons and Sikhs.[121]		The Blackpool Faith Forum was established in 2001 in conjunction with Blackpool Council to provide interfaith dialogue between the various faith groups in the town, to raise awareness of the various faiths in the town and to promote a multifaith community. It is linked to the Interfaith Network of UK.[122][123] In February 2007 a youth forum was established, Blackpool Faith Forum for Youth (BIFFY).[124]		As well as 29 state primary schools and 8 state secondary schools, there is also a range of activities for children and young people in the town. Some of these are delivered by Blackpool Young People Services (a part of Blackpool Council).[125]		A number of shipwrecks have occurred on the coastline of Blackpool. The most recent occurrence has been the grounding of the MS Riverdance in January 2008. Famously, in 1897, HMS Foudroyant, Nelson's flagship before HMS Victory, was grounded close to North Pier in a storm.		In 1913, the Brides in the bath serial killer George Joseph Smith drowned his second wife Alice in their rented room of a boarding house on Regent Road. He was due to be the beneficiary of a sizeable life insurance policy upon his wife's death.[126]		In 1971 Supt Gerry Richardson, 38, was shot dead while chasing a gang of London thugs who had robbed a resort jewellers. The five-man group bungled the raid on Preston's Jewellers in the Strand. They arrived late and failed to check a back room where the shop manager had already raised a silent alarm connected to Blackpool Police Station. As the gang made their getaway they became involved in a high-speed chase through the streets of North Shore which ended with Supt Richardson's tragic murder at the hands of "Fat" Freddie Sewell. Supt Richardson was posthumously awarded the George Cross in 1972. Wounded Inspector Carl Walker also received the George Cross.[127][128]		In 1972, Dr Ahmad Alami (the son of the Grand Mufti of Jerusalem) murdered 3 sleeping children at Blackpool Victoria Hospital, he also stabbed two nurses, and other children asleep on the ward.[129] Alami was diagnosed as a 'Paranoid schizophrenic' and judged unfit to stand trial, and was detained at Broadmoor high security hospital for several years before being released and deported back to his native Jordan		In 1999, Stuart Michael Diamond was convicted of the brutal murder of a homeless 17-year-old heroin addict, Christopher Hartley. Diamond murdered Hartley and dismembered his body before 'dumping' the remains in a hotel 'swill bin'; Hartley's head was never recovered.[130]		In 2007, the jury in the case of the alleged rape and murder of Blackpool schoolgirl Charlene Downes, 14, heard a police surveillance tape of Jordanian Iyad Albattikhi, 29, and Iranian Mohammed Reveshi, 50, allegedly detailing her stabbing, and her later alleged disposal in their "Funny Boyz" kebab shop's mincing machine by the prosecution. Albattikhi allegedly boasted that he had sold her remains in kebabs.[131] Both men were acquitted of the alleged offence. John Bromley-Davenport, for the defence, said: "We have uncovered within the Blackpool Police force an astonishing catalogue of incompetence, failure to disclose, manipulation and lies, some of which were uttered on oath during the trial last year. If the jury at that trial had swallowed the lies and been duped by the manipulation then a grave miscarriage of justice would have occurred."[132]		On 25 July 2010, a nurse named Jane Clough was stabbed to death in Victoria Hospital's car park. Her ex-boyfriend Jonathan Vass, a paramedic, was later found guilty of her murder.[133]		Blackpool has been the birthplace and/or home to a number of notable people, including:		Josh Tate (b. 2002) - Grime artist		Blackpool is twinned with:		Coordinates: 53°48′51″N 3°03′1″W﻿ / ﻿53.81417°N 3.05028°W﻿ / 53.81417; -3.05028		
An estuary is a partially enclosed coastal body of brackish water with one or more rivers or streams flowing into it, and with a free connection to the open sea.[1]		Estuaries form a transition zone between river environments and maritime environments. They are subject both to marine influences—such as tides, waves, and the influx of saline water—and to riverine influences—such as flows of fresh water and sediment. The inflows of both sea water and fresh water provide high levels of nutrients both in the water column and in sediment, making estuaries among the most productive natural habitats in the world.[2]		Most existing estuaries formed during the Holocene epoch with the flooding of river-eroded or glacially scoured valleys when the sea level began to rise about 10,000–12,000 years ago.[3] Estuaries are typically classified according to their geomorphological features or to water-circulation patterns. They can have many different names, such as bays, harbors, lagoons, inlets, or sounds, although some of these water bodies do not strictly meet the above definition of an estuary and may be fully saline.		The banks of many estuaries are amongst the most heavily populated areas of the world, with about 60% of the world's population living along estuaries and the coast.[citation needed] As a result, many estuaries suffer degradation by many factors, including sedimentation from soil erosion from deforestation, overgrazing, and other poor farming practices; overfishing; drainage and filling of wetlands; eutrophication due to excessive nutrients from sewage and animal wastes; pollutants including heavy metals, polychlorinated biphenyls, radionuclides and hydrocarbons from sewage inputs; and diking or damming for flood control or water diversion.[3][4]						The word "estuary" is derived from the Latin word aestuarium meaning tidal inlet of the sea, which in itself is derived from the term aestus, meaning tide. There have been many definitions proposed to describe an estuary. The most widely accepted definition is: "a semi-enclosed coastal body of water, which has a free connection with the open sea, and within which sea water is measurably diluted with freshwater derived from land drainage".[1] However, this definition excludes a number of coastal water bodies such as coastal lagoons and brackish seas. A more comprehensive definition of an estuary is "a semi-enclosed body of water connected to the sea as far as the tidal limit or the salt intrusion limit and receiving freshwater runoff; however the freshwater inflow may not be perennial, the connection to the sea may be closed for part of the year and tidal influence may be negligible".[3] This broad definition also includes fjords, lagoons, river mouths, and tidal creeks. An estuary is a dynamic ecosystem having a connection to the open sea through which the sea water enters with the rhythm of the tides. The sea water entering the estuary is diluted by the fresh water flowing from rivers and streams. The pattern of dilution varies between different estuaries and depends on the volume of fresh water, the tidal range, and the extent of evaporation of the water in the estuary.[2]		Drowned river valleys are also known as coastal plain estuaries. In places where the sea level is rising relative to the land, sea water progressively penetrates into river valleys and the topography of the estuary remains similar to that of a river valley. This is the most common type of estuary in temperate climates. Well-studied estuaries include the Severn Estuary in the United Kingdom and the Ems Dollard along the Dutch-German border.		The width-to-depth ratio of these estuaries is typically large, appearing wedge-shaped (in cross-section) in the inner part and broadening and deepening seaward. Water depths rarely exceed 30 m (100 ft). Examples of this type of estuary in the U.S. are the Hudson River, Chesapeake Bay, and Delaware Bay along the Mid-Atlantic coast, and Galveston Bay and Tampa Bay along the Gulf Coast.[5]		Bar-built estuaries are found in place where the deposition of sediment has kept pace with rising sea level so that the estuaries are shallow and separated from the sea by sand spits or barrier islands. They are relatively common in tropical and subtropical locations.		These estuaries are semi-isolated from ocean waters by barrier beaches (barrier islands and barrier spits). Formation of barrier beaches partially encloses the estuary, with only narrow inlets allowing contact with the ocean waters. Bar-built estuaries typically develop on gently sloping plains located along tectonically stable edges of continents and marginal sea coasts. They are extensive along the Atlantic and Gulf coasts of the U.S. in areas with active coastal deposition of sediments and where tidal ranges are less than 4 m (13 ft). The barrier beaches that enclose bar-built estuaries have been developed in several ways:		Barrier beaches form in shallow water and are generally parallel to the shoreline, resulting in long, narrow estuaries. The average water depth is usually less than 5 m (16 ft), and rarely exceeds 10 m (33 ft). Examples of bar-built estuaries are Barnegat Bay, New Jersey; Laguna Madre,[6] Texas; and Pamlico Sound, North Carolina.		Fjords were formed where pleistocene glaciers deepened and widened existing river valleys so that they become U-shaped in cross sections. At their mouths there are typically rocks bars or sills of glacial deposits, which have the effects of modifying the estuarine circulation.		Fjord-type estuaries are formed in deeply eroded valleys formed by glaciers. These U-shaped estuaries typically have steep sides, rock bottoms, and underwater sills contoured by glacial movement. The estuary is shallowest at its mouth, where terminal glacial moraines or rock bars form sills that restrict water flow. In the upper reaches of the estuary, the depth can exceed 300 m (1,000 ft). The width-to-depth ratio is generally small. In estuaries with very shallow sills, tidal oscillations only affect the water down to the depth of the sill, and the waters deeper than that may remain stagnant for a very long time, so there is only an occasional exchange of the deep water of the estuary with the ocean. If the sill depth is deep, water circulation is less restricted, and there is a slow but steady exchange of water between the estuary and the ocean. Fjord-type estuaries can be found along the coasts of Alaska, the Puget Sound region of western Washington state, British Columbia, eastern Canada, Greenland, Iceland, New Zealand, and Norway.		These estuaries are formed by subsidence or land cut off from the ocean by land movement associated with faulting, volcanoes, and landslides. Inundation from eustatic sea level rise during the Holocene Epoch has also contributed to the formation of these estuaries. There are only a small number of tectonically produced estuaries; one example is the San Francisco Bay, which was formed by the crustal movements of the San Andreas fault system causing the inundation of the lower reaches of the Sacramento and San Joaquin rivers.[7]		In this type of estuary, river output greatly exceeds marine input and tidal effects have a minor importance. Fresh water floats on top of the seawater in a layer that gradually thins as it moves seaward. The denser seawater moves landward along the bottom of the estuary, forming a wedge-shaped layer that is thinner as it approaches land. As a velocity difference develops between the two layers, shear forces generate internal waves at the interface, mixing the seawater upward with the freshwater. An example of a salt wedge estuary is the Mississippi River.[7]		As tidal forcing increases, river output becomes less than the marine input. Here, current induced turbulence causes mixing of the whole water column such that salinity varies more longitudinally rather than vertically, leading to a moderately stratified condition. Examples include the Chesapeake Bay and Narragansett Bay.[7]		Tidal mixing forces exceed river output, resulting in a well mixed water column and the disappearance of the vertical salinity gradient. The freshwater-seawater boundary is eliminated due to the intense turbulent mixing and eddy effects. The lower reaches of Delaware Bay and the Raritan River in New Jersey are examples of vertically homogenous estuaries.[7]		Inverse estuaries occur in dry climates where evaporation greatly exceeds the inflow of fresh water. A salinity maximum zone is formed, and both riverine and oceanic water flow close to the surface towards this zone.[8] This water is pushed downward and spreads along the bottom in both the seaward and landward direction.[3] An example of an inverse estuary is Spencer Gulf, South Australia.		Estuary type varies dramatically depending on freshwater input, and is capable of changing from a wholly marine embayment to any of the other estuary types.[9][10]		The most important variable characteristics of estuary water are the concentration of dissolved oxygen, salinity and sediment load. There is extreme spatial variability in salinity, with a range of near zero at the tidal limit of tributary rivers to 3.4% at the estuary mouth. At any one point the salinity will vary considerably over time and seasons, making it a harsh environment for organisms. Sediment often settles in intertidal mudflats which are extremely difficult to colonize. No points of attachment exist for algae, so vegetation based habitat is not established.[clarification needed] Sediment can also clog feeding and respiratory structures of species, and special adaptations exist within mudflat species to cope with this problem. Lastly, dissolved oxygen variation can cause problems for life forms. Nutrient-rich sediment from man-made sources can promote primary production life cycles, perhaps leading to eventual decay removing the dissolved oxygen from the water; thus hypoxic or anoxic zones can develop.[11]		Estuaries provide habitats for a large number of organisms and support very high productivity. Estuaries provide habitats for many fish nurseries, depending upon their locations in the world, such as salmon and sea trout.[12] Also, migratory bird populations, such as the black-tailed godwit,[13] make essential use of estuaries.		Two of the main challenges of estuarine life are the variability in salinity and sedimentation. Many species of fish and invertebrates have various methods to control or conform to the shifts in salt concentrations and are termed osmoconformers and osmoregulators. Many animals also burrow to avoid predation and to live in the more stable sedimental environment. However, large numbers of bacteria are found within the sediment which have a very high oxygen demand. This reduces the levels of oxygen within the sediment often resulting in partially anoxic conditions, which can be further exacerbated by limited water flux.		Phytoplankton are key primary producers in estuaries. They move with the water bodies and can be flushed in and out with the tides. Their productivity is largely dependent upon the turbidity of the water. The main phytoplankton present are diatoms and dinoflagellates which are abundant in the sediment.		It is important to remember that a primary source of food for many organisms on estuaries, including bacteria, is detritus from the settlement of the sedimentation.		Of the thirty-two largest cities in the world, twenty-two are located on estuaries.[14] For example, New York City is located at the mouth of the Hudson River estuary.[15]		As ecosystems, estuaries are under threat from human activities such as pollution and overfishing. They are also threatened by sewage, coastal settlement, land clearance and much more. Estuaries are affected by events far upstream, and concentrate materials such as pollutants and sediments.[16] Land run-off and industrial, agricultural, and domestic waste enter rivers and are discharged into estuaries. Contaminants can be introduced which do not disintegrate rapidly in the marine environment, such as plastics, pesticides, furans, dioxins, phenols and heavy metals.		Such toxins can accumulate in the tissues of many species of aquatic life in a process called bioaccumulation. They also accumulate in benthic environments, such as estuaries and bay muds: a geological record of human activities of the last century. The elemental composition of biofilm reflect areas of the estuary impacted by human activities, and over time may shift the basic composition of the ecosystem, and the reversible or irreversible changes in the abiotic and biotic parts of the systems from the bottom up.[17]		For example, Chinese and Russian industrial pollution, such as phenols and heavy metals, has devastated fish stocks in the Amur River and damaged its estuary soil.[18]		Estuaries tend to be naturally eutrophic because land runoff discharges nutrients into estuaries. With human activities, land run-off also now includes the many chemicals used as fertilizers in agriculture as well as waste from livestock and humans. Excess oxygen-depleting chemicals in the water can lead to hypoxia and the creation of dead zones.[19] This can result in reductions in water quality, fish, and other animal populations. Overfishing also occurs. Chesapeake Bay once had a flourishing oyster population that has been almost wiped out by overfishing. Oysters filter these pollutants, and either eat them or shape them into small packets that are deposited on the bottom where they are harmless. Historically the oysters filtered the estuary's entire water volume of excess nutrients every three or four days. Today that process takes almost a year,[20] and sediment, nutrients, and algae can cause problems in local waters.		
A surge channel is a narrow inlet on a rocky shoreline. As waves strike the shore, water fills the channel, and drains out again as the waves retreat. The narrow confines of the channel create powerful currents that reverse themselves rapidly as the water level rises and falls.		Surge channels can range from a few inches across to 10 feet or more. They may create tide pools if the conditions are correct, but the rapid water movement almost always creates a dangerous situation for people or animals that are caught in it. The West Coast Trail on the coast of Vancouver Island, B.C., is famous for its large number of surge channels, some of which are impassable even at low tide and must be crossed inland.		
Physical oceanography is the study of physical conditions and physical processes within the ocean, especially the motions and physical properties of ocean waters.		Physical oceanography is one of several sub-domains into which oceanography is divided. Others include biological, chemical and geological oceanography.		Physical oceanography may be subdivided into descriptive and dynamical physical oceanography.[1]		Descriptive physical oceanography seeks to research the ocean through observations and complex numerical models, which describe the fluid motions as precise as possible.		Dynamical physical oceanography focuses primarily upon the processes that govern the motion of fluids with emphasis upon theoretical research and numerical models. These are part of the large field of Geophysical Fluid Dynamics (GFD) that is shared together with meteorology.						Roughly 97% of the planet's water is in its oceans, and the oceans are the source of the vast majority of water vapor that condenses in the atmosphere and falls as rain or snow on the continents.[3][4] The tremendous heat capacity of the oceans moderates the planet's climate, and its absorption of various gases affects the composition of the atmosphere.[4] The ocean's influence extends even to the composition of volcanic rocks through seafloor metamorphism, as well as to that of volcanic gases and magmas created at subduction zones.[4]		The oceans are far deeper than the continents are tall; examination of the Earth's hypsographic curve shows that the average elevation of Earth's landmasses is only 840 metres (2,760 ft), while the ocean's average depth is 3,800 metres (12,500 ft). Though this apparent discrepancy is great, for both land and sea, the respective extremes such as mountains and trenches are rare.[3]		Because the vast majority of the world ocean's volume is deep water, the mean temperature of seawater is low; roughly 75% of the ocean's volume has a temperature from 0° – 5 °C (Pinet 1996). The same percentage falls in a salinity range between 34–35 ppt (3.4–3.5%) (Pinet 1996). There is still quite a bit of variation, however. Surface temperatures can range from below freezing near the poles to 35 °C in restricted tropical seas, while salinity can vary from 10 to 41 ppt (1.0–4.1%).[5]		The vertical structure of the temperature can be divided into three basic layers, a surface mixed layer, where gradients are low, a thermocline where gradients are high, and a poorly stratified abyss.		In terms of temperature, the ocean's layers are highly latitude-dependent; the thermocline is pronounced in the tropics, but nonexistent in polar waters (Marshak 2001). The halocline usually lies near the surface, where evaporation raises salinity in the tropics, or meltwater dilutes it in polar regions.[5] These variations of salinity and temperature with depth change the density of the seawater, creating the pycnocline.[3]		Energy for the ocean circulation (and for the atmospheric circulation) comes from solar radiation and gravitational energy from the sun and moon.[6] The amount of sunlight absorbed at the surface varies strongly with latitude, being greater at the equator than at the poles, and this engenders fluid motion in both the atmosphere and ocean that acts to redistribute heat from the equator towards the poles, thereby reducing the temperature gradients that would exist in the absence of fluid motion. Perhaps three quarters of this heat is carried in the atmosphere; the rest is carried in the ocean.		The atmosphere is heated from below, which leads to convection, the largest expression of which is the Hadley circulation. By contrast the ocean is heated from above, which tends to suppress convection. Instead ocean deep water is formed in polar regions where cold salty waters sink in fairly restricted areas. This is the beginning of the thermohaline circulation.		Oceanic currents are largely driven by the surface wind stress; hence the large-scale atmospheric circulation is important to understanding the ocean circulation. The Hadley circulation leads to Easterly winds in the tropics and Westerlies in mid-latitudes. This leads to slow equatorward flow throughout most of a subtropical ocean basin (the Sverdrup balance). The return flow occurs in an intense, narrow, poleward western boundary current. Like the atmosphere, the ocean is far wider than it is deep, and hence horizontal motion is in general much faster than vertical motion. In the southern hemisphere there is a continuous belt of ocean, and hence the mid-latitude westerlies force the strong Antarctic Circumpolar Current. In the northern hemisphere the land masses prevent this and the ocean circulation is broken into smaller gyres in the Atlantic and Pacific basins.		The Coriolis effect results in a deflection of fluid flows (to the right in the Northern Hemisphere and left in the Southern Hemisphere). This has profound effects on the flow of the oceans. In particular it means the flow goes around high and low pressure systems, permitting them to persist for long periods of time. As a result, tiny variations in pressure can produce measurable currents. A slope of one part in one million in sea surface height, for example, will result in a current of 10 cm/s at mid-latitudes. The fact that the Coriolis effect is largest at the poles and weak at the equator results in sharp, relatively steady western boundary currents which are absent on eastern boundaries. Also see secondary circulation effects.		Ekman transport results in the net transport of surface water 90 degrees to the right of the wind in the Northern Hemisphere, and 90 degrees to the left of the wind in the Southern Hemisphere. As the wind blows across the surface of the ocean, it "grabs" onto a thin layer of the surface water. In turn, that thin sheet of water transfers motion energy to the thin layer of water under it, and so on. However, because of the Coriolis Effect, the direction of travel of the layers of water slowly move farther and farther to the right as they get deeper in the Northern Hemisphere, and to the left in the Southern Hemisphere. In most cases, the very bottom layer of water affected by the wind is at a depth of 100 m – 150 m and is traveling about 180 degrees, completely opposite of the direction that the wind is blowing. Overall, the net transport of water would be 90 degrees from the original direction of the wind.		Langmuir circulation results in the occurrence of thin, visible stripes, called windrows on the surface of the ocean parallel to the direction that the wind is blowing. If the wind is blowing with more than 3 m s−1, it can create parallel windrows alternating upwelling and downwelling about 5–300 m apart. These windrows are created by adjacent ovular water cells (extending to about 6 m (20 ft) deep) alternating rotating clockwise and counterclockwise. In the convergence zones debris, foam and seaweed accumulates, while at the divergence zones plankton are caught and carried to the surface. If there are many plankton in the divergence zone fish are often attracted to feed on them.		At the ocean-atmosphere interface, the ocean and atmosphere exchange fluxes of heat, moisture and momentum.		The important heat terms at the surface are the sensible heat flux, the latent heat flux, the incoming solar radiation and the balance of long-wave (infrared) radiation. In general, the tropical oceans will tend to show a net gain of heat, and the polar oceans a net loss, the result of a net transfer of energy polewards in the oceans.		The oceans' large heat capacity moderates the climate of areas adjacent to the oceans, leading to a maritime climate at such locations. This can be a result of heat storage in summer and release in winter; or of transport of heat from warmer locations: a particularly notable example of this is Western Europe, which is heated at least in part by the north atlantic drift.		Surface winds tend to be of order meters per second; ocean currents of order centimeters per second. Hence from the point of view of the atmosphere, the ocean can be considered effectively stationary; from the point of view of the ocean, the atmosphere imposes a significant wind stress on its surface, and this forces large-scale currents in the ocean.		Through the wind stress, the wind generates ocean surface waves; the longer waves have a phase velocity tending towards the wind speed. Momentum of the surface winds is transferred into the energy flux by the ocean surface waves. The increased roughness of the ocean surface, by the presence of the waves, changes the wind near the surface.		The ocean can gain moisture from rainfall, or lose it through evaporation. Evaporative loss leaves the ocean saltier; the Mediterranean and Persian Gulf for example have strong evaporative loss; the resulting plume of dense salty water may be traced through the Straits of Gibraltar into the Atlantic Ocean. At one time, it was believed that evaporation/precipitation was a major driver of ocean currents; it is now known to be only a very minor factor.		A Kelvin wave is any progressive wave that is channeled between two boundaries or opposing forces (usually between the Coriolis force and a coastline or the equator). There are two types, coastal and equatorial. Kelvin waves are gravity driven and non-dispersive. This means that Kelvin waves can retain their shape and direction over long periods of time. They are usually created by a sudden shift in the wind, such as the change of the trade winds at the beginning of the El Niño-Southern Oscillation.		Coastal Kelvin waves follow shorelines and will always propagate in a counterclockwise direction in the Northern hemisphere (with the shoreline to the right of the direction of travel) and clockwise in the Southern hemisphere.		Equatorial Kelvin waves propagate to the east in the Northern and Southern hemispheres, using the equator as a guide.		Kelvin waves are known to have very high speeds, typically around 2–3 meters per second. They have wavelengths of thousands of kilometers and amplitudes in the tens of meters.		Rossby waves, or planetary waves are huge, slow waves generated in the troposphere by temperature differences between the ocean and the continents. Their major restoring force is the change in Coriolis force with latitude. Their wave amplitudes are usually in the tens of meters and very large wavelengths. They are usually found at low or mid latitudes.		There are two types of Rossby waves, barotropic and baroclinic. Barotropic Rossby waves have the highest speeds and do not vary vertically. Baroclinic Rossby waves are much slower.		The special identifying feature of Rossby waves is that the phase velocity of each individual wave always has a westward component, but the group velocity can be in any direction. Usually the shorter Rossby waves have an eastward group velocity and the longer ones have a westward group velocity.		The interaction of ocean circulation, which serves as a type of heat pump, and biological effects such as the concentration of carbon dioxide can result in global climate changes on a time scale of decades. Known climate oscillations resulting from these interactions, include the Pacific decadal oscillation, North Atlantic oscillation, and Arctic oscillation. The oceanic process of thermohaline circulation is a significant component of heat redistribution across the globe, and changes in this circulation can have major impacts upon the climate.		and		This is a coupled ocean/atmosphere wave that circles the Southern Ocean about every eight years. Since it is a wave-2 phenomenon (there are two peaks and two troughs in a latitude circle) at each fixed point in space a signal with a period of four years is seen. The wave moves eastward in the direction of the Antarctic Circumpolar Current.		Among the most important ocean currents are the:		The ocean body surrounding the Antarctic is currently the only continuous body of water where there is a wide latitude band of open water. It interconnects the Atlantic, Pacific and Indian oceans, and provide an uninterrupted stretch for the prevailing westerly winds to significantly increase wave amplitudes. It is generally accepted that these prevailing winds are primarily responsible for the circumpolar current transport. This current is now thought to vary with time, possibly in an oscillatory manner.		In the Norwegian Sea evaporative cooling is predominant, and the sinking water mass, the North Atlantic Deep Water (NADW), fills the basin and spills southwards through crevasses in the submarine sills that connect Greenland, Iceland and Britain. It then flows along the western boundary of the Atlantic with some part of the flow moving eastward along the equator and then poleward into the ocean basins. The NADW is entrained into the Circumpolar Current, and can be traced into the Indian and Pacific basins. Flow from the Arctic Ocean Basin into the Pacific, however, is blocked by the narrow shallows of the Bering Strait.		Also see marine geology about that explores the geology of the ocean floor including plate tectonics that create deep ocean trenches.		An idealised subtropical ocean basin forced by winds circling around a high pressure (anticyclonic) systems such as the Azores-Bermuda high develops a gyre circulation with slow steady flows towards the equator in the interior. As discussed by Henry Stommel, these flows are balanced in the region of the western boundary, where a thin fast polewards flow called a western boundary current develops. Flow in the real ocean is more complex, but the Gulf stream, Agulhas and Kuroshio are examples of such currents. They are narrow (approximately 100 km across) and fast (approximately 1.5 m/s).		Equatorwards western boundary currents occur in tropical and polar locations, e.g. the East Greenland and Labrador currents, in the Atlantic and the Oyashio. They are forced by winds circulation around low pressure (cyclonic).		The Gulf Stream, together with its northern extension, North Atlantic Current, is a powerful, warm, and swift Atlantic Ocean current that originates in the Gulf of Mexico, exits through the Strait of Florida, and follows the eastern coastlines of the United States and Newfoundland to the northeast before crossing the Atlantic Ocean.		The Kuroshio Current is an ocean current found in the western Pacific Ocean off the east coast of Taiwan and flowing northeastward past Japan, where it merges with the easterly drift of the North Pacific Current. It is analogous to the Gulf Stream in the Atlantic Ocean, transporting warm, tropical water northward towards the polar region.		Ocean heat flux is a turbulent and complex system[7] which utilizes atmospheric measurement techniques such as eddy covariance to measure the rate of heat transfer expressed in the unit of joules or watts per second. Heat flux is the difference in temperature between two points through which the heat passes. Most of the Earth's heat storage is within its seas with smaller fractions of the heat transfer in processes such as evaporation, radiation, diffusion, or absorption into the sea floor. The majority of the ocean heat flux is through advection or the movement of the ocean's currents. For example, the majority of the warm water movement in the south Atlantic is thought to have originated in the Indian Ocean.[8] Another example of advection is the nonequatorial Pacific heating which results from subsurface processes related to atmospheric anticlines.[9] Recent warming observations of Antarctic Bottom Water in the Southern Ocean is of concern to ocean scientists because bottom water changes will effect currents, nutrients, and biota elsewhere.[10] The international awareness of global warming has focused scientific research on this topic since the 1988 creation of the Intergovernmental Panel on Climate Change. Improved ocean observation, instrumentation, theory, and funding has increased scientific reporting on regional and global issues related to heat.[11]		Tide gauges and satellite altimetry suggest an increase in sea level of 1.5–3 mm/yr over the past 100 years.		The IPCC predicts that by 2081-2100, global warming will lead to a sea level rise of 260 to 820 mm.[12]		The rise and fall of the oceans due to tidal effects is a key influence upon the coastal areas. Ocean tides on the planet Earth are created by the gravitational effects of the Sun and Moon. The tides produced by these two bodies are roughly comparable in magnitude, but the orbital motion of the Moon results in tidal patterns that vary over the course of a month.		The ebb and flow of the tides produce a cyclical current along the coast, and the strength of this current can be quite dramatic along narrow estuaries. Incoming tides can also produce a tidal bore along a river or narrow bay as the water flow against the current results in a wave on the surface.		Tide and Current (Wyban 1992) clearly illustrates the impact of these natural cycles on the lifestyle and livelihood of Native Hawaiians tending coastal fishponds. Aia ke ola ka hana meaning . . . Life is in labor.		Tidal resonance occurs in the Bay of Fundy since the time it takes for a large wave to travel from the mouth of the bay to the opposite end, then reflect and travel back to the mouth of the bay coincides with the tidal rhythm producing the world's highest tides.		As the surface tide oscillates over topography, such as submerged seamounts or ridges, it generates internal waves at the tidal frequency, which are known as internal tides.		A series of surface waves can be generated due to large-scale displacement of the ocean water. These can be caused by sub-marine landslides, seafloor deformations due to earthquakes, or the impact of a large meteorite.		The waves can travel with a velocity of up to several hundred km/hour across the ocean surface, but in mid-ocean they are barely detectable with wavelengths spanning hundreds of kilometers.		Tsunamis, originally called tidal waves, were renamed because they are not related to the tides. They are regarded as shallow-water waves, or waves in water with a depth less than 1/20 their wavelength. Tsunamis have very large periods, high speeds, and great wave heights.		The primary impact of these waves is along the coastal shoreline, as large amounts of ocean water are cyclically propelled inland and then drawn out to sea. This can result in significant modifications to the coastline regions where the waves strike with sufficient energy.		The tsunami that occurred in Lituya Bay, Alaska on July 9, 1958 was 520 m (1,710 ft) high and is the biggest tsunami ever measured, almost 90 m (300 ft) taller than the Sears Tower in Chicago and about 110 m (360 ft) taller than the former World Trade Center in New York.[13]		The wind generates ocean surface waves, which have a large impact on offshore structures, ships, coastal erosion and sedimentation, as well as harbours. After their generation by the wind, ocean surface waves can travel (as swell) over long distances.		
Yorkshire (/ˈjɔːrkʃər/ or /ˈjɔːrkʃɪər/; abbreviated Yorks), formally known as the County of York, is a historic county of Northern England and the largest in the United Kingdom.[3] Due to its great size in comparison to other English counties, functions have been undertaken over time by its subdivisions, which have also been subject to periodic reform. Throughout these changes, Yorkshire has continued to be recognised as a geographical territory and cultural region.[4][5] The name is familiar and well understood across the United Kingdom and is in common use in the media and the military,[6] and also features in the titles of current areas of civil administration such as North Yorkshire, South Yorkshire, West Yorkshire and East Riding of Yorkshire.		Within the borders of the historic county of Yorkshire are areas which are widely considered to be among the greenest in England, due to the vast stretches of unspoilt countryside in the Yorkshire Dales and North York Moors and to the open aspect of some of the major cities.[7][8] Yorkshire has sometimes been nicknamed "God's Own County" or "God's Own Country".[5][9][10]		The emblem of Yorkshire is the White Rose of the English royal House of York, and the most commonly used flag representative of Yorkshire is the White Rose on a blue background,[11] which after nearly fifty years of use, was recognised by the Flag Institute on 29 July 2008.[12] Yorkshire Day, held annually on 1 August, is a celebration of the general culture of Yorkshire, ranging from its history to its own dialect.[13]		Yorkshire is now divided between different official regions. Most of the county falls within Yorkshire and the Humber. The extreme northern part of the county falls within North East England. Following boundary changes in 1974, small areas in the west of the historic county now form part of North West England.						Yorkshire or the County of York was so named as it is the shire (administrative area or county) of the city of York locally /ˈjɔːk/ ( listen) or York's Shire. "York" comes from the Viking name for the city, Jórvík. "Shire" is from Old English, scir meaning care or official charge.[14] The "shire" suffix is locally pronounced /-ʃə/ "shuh", or occasionally /-ʃiə/, a homophone of "sheer".[15]		Early inhabitants of Yorkshire were Celts, who formed two separate tribes, the Brigantes and the Parisi. The Brigantes controlled territory which later became all of the North Riding of Yorkshire and the West Riding of Yorkshire. The tribe controlled most of Northern England and more territory than any other Celtic tribe in England. That they had the Yorkshire area as their heartland is evident in that Isurium Brigantum (now known as Aldborough) was the capital town of their civitas under Roman rule. Six of the nine Brigantian poleis described by Claudius Ptolemaeus in the Geographia fall within the historic county.[16][17] The Parisi, who controlled the area that would become the East Riding of Yorkshire, might have been related to the Parisii of Lutetia Parisiorum, Gaul (known today as Paris, France).[18] Their capital was at Petuaria, close to the Humber estuary. Although the Roman conquest of Britain began in 43 AD, the Brigantes remained in control of their kingdom as a client state of Rome for an extended period, reigned over by the Brigantian monarchs Cartimandua and her husband Venutius. Initially, this situation suited both the Romans and the Brigantes, who were known as the most militant tribe in Britain.[19]		Queen Cartimandua left her husband Venutius for his armour bearer, Vellocatus, setting off a chain of events which changed control of the Yorkshire area. Cartimandua, due to her good relationship with the Romans, was able to keep control of the kingdom; however her former husband staged rebellions against her and her Roman allies.[20] At the second attempt, Venutius seized the kingdom, but the Romans, under general Petillius Cerialis, conquered the Brigantes in 71 AD.[21]		The fortified city of Eboracum (now known as York) was named as capital of Britannia Inferior and joint-capital of all Roman Britain.[22] During the two years before the death of Emperor Septimius Severus, the Roman Empire was run from Eboracum by him.[23]		Another emperor, Constantius Chlorus, died in Yorkshire during a visit in 306 AD. This saw his son Constantine the Great proclaimed emperor in the city, who would become renowned due to his contributions to Christianity.[24] In the early 5th century, the Roman rule ceased with the withdrawal of the last active Roman troops. By this stage, the Western Empire was in intermittent decline.[23]		After the Romans left, small Celtic kingdoms arose in Yorkshire; the Kingdom of Ebrauc around York and more notably the Kingdom of Elmet in West Yorkshire.[25][26] Elmet remained independent from the Germanic Northumbrian Angles until some time in the early 7th century, when King Edwin of Northumbria expelled its last king, Certic, and annexed the region. At its greatest extent, Northumbria stretched from the Irish Sea to the North Sea and from Edinburgh down to Hallamshire in South Yorkshire.[27]		An army of Danish Vikings, the Great Heathen Army[28] as its enemies often referred to it, invaded Northumbrian territory in 866 AD. The Danes conquered and assumed what is now York and renamed it Jórvík, making it the capital city of a new Danish kingdom under the same name. The area which this kingdom covered included most of Southern Northumbria, roughly equivalent to the borders of Yorkshire extending further West.[29]		The Danes went on to conquer an even larger area of England that afterwards became known as the Danelaw; but whereas most of the Danelaw was still English land, albeit in submission to Viking overlords, it was in the Kingdom of Jórvík that the only truly Viking territory on mainland Britain was ever established. The Kingdom prospered, taking advantage of the vast trading network of the Viking nations, and established commercial ties with the British Isles, North-West Europe, the Mediterranean and the Middle East.[30]		Founded by the Dane Halfdan Ragnarsson in 875,[31] ruled for the great part by Danish kings, and populated by the families and subsequent descendants of Danish Vikings, the leadership of the kingdom nonetheless passed into Norwegian hands during its twilight years.[31] Eric Bloodaxe, an ex-king of Norway who was the last independent Viking king of Jórvík, is a particularly noted figure in history,[32] and his bloodthirsty approach towards leadership may have been at least partly responsible for convincing the Danish inhabitants of the region to accept English sovereignty so readily in the years that followed.		After around 100 years of its volatile existence, the Kingdom of Jorvik finally came to an end. The Kingdom of Wessex was now in its ascendant and established its dominance over the North in general, placing Yorkshire again within Northumbria, which retained a certain amount of autonomy as an almost-independent earldom rather than a separate kingdom. The Wessex Kings of England were reputed to have respected the Norse customs in Yorkshire and left law-making in the hands of the local aristocracy.[33]		In the weeks immediately leading up to the Battle of Hastings in 1066 AD, Harold II of England was distracted by events in Yorkshire. His brother Tostig and Harold Hardrada, King of Norway, attempted a takeover in the north, having won the Battle of Fulford. The King of England marched North where the two armies met at the Battle of Stamford Bridge. Tostig and Hardrada were both killed and their army was defeated decisively. However, Harold Godwinson was forced immediately to march his army back down to the South where William the Conqueror was landing. The King was defeated at Hastings, which led to the Norman conquest of England.		The people of the North rebelled against the Normans in September 1069 AD, enlisting Sweyn II of Denmark. They tried to take back York, but the Normans burnt it before they could.[34] What followed was the Harrying of the North ordered by William. From York to Durham, crops, domestic animals, and farming tools were scorched. Many villages between the towns were burnt and local northerners were indiscriminately murdered.[35] During the winter that followed, families starved to death and thousands of peasants died of cold and hunger. Orderic Vitalis put the estimation at "more than 100,000" people from the North died from hunger.[36]		In the centuries following, many abbeys and priories were built in Yorkshire. Norman landowners were keen to increase their revenues and established new towns such as Barnsley, Doncaster, Hull, Leeds, Scarborough, Sheffield, among others. Of towns founded before the conquest, only Bridlington, Pocklington, and York continued at a prominent level.[37] The population of Yorkshire boomed until hit by the Great Famine in the years between 1315 and 1322.[37]		In the early 12th century, people of Yorkshire had to contend with the Battle of the Standard at Northallerton with the Scots. Representing the Kingdom of England led by Archbishop Thurstan of York, soldiers from Yorkshire defeated the more numerous Scots.[38]		The Black Death reached Yorkshire by 1349, killing around a third of the population.[37]		When King Richard II was overthrown in 1399, antagonism between the House of York and the House of Lancaster, both branches of the royal House of Plantagenet, began to emerge. Eventually the two houses fought for the throne of England in a series of civil wars, commonly known as the Wars of the Roses. Some of the battles took place in Yorkshire, such as those at Wakefield and Towton, the latter of which is known as the bloodiest battle ever fought on English soil.[40] Richard III was the last Yorkist king.		Henry Tudor, sympathiser to the House of Lancaster, defeated and killed Richard at the Battle of Bosworth Field. He then became King Henry VII and married Elizabeth of York, daughter of Yorkist Edward IV, ending the wars.[41] The two roses of white and red, emblems of the Houses of York and Lancaster respectively, were combined to form the Tudor Rose of England.[a][42] This rivalry between the royal houses of York and Lancaster has passed into popular culture as a rivalry between the counties of Yorkshire and Lancashire, particularly in sport (for example the Roses Match played in County Cricket), although the House of Lancaster was based in York and the House of York in London. In football, matches between Manchester United and Leeds United are usually described as "War of the Roses" games, the teams' home kits being the colour of the respective rose.		The wool textile industry which had previously been a cottage industry centred on the old market towns moved to the West Riding where entrepreneurs were building mills that took advantage of water power gained by harnessing the rivers and streams flowing from the Pennines. The developing textile industry helped Wakefield and Halifax grow.[43]		The English Reformation began under Henry VIII and the Dissolution of the Monasteries in 1536 led to a popular uprising known as Pilgrimage of Grace, started in Yorkshire as a protest. Some Catholics in Yorkshire continued to practise their religion and those caught were executed during the reign of Elizabeth I. One such person was a York woman named Margaret Clitherow who was later canonised.[44]		During the English Civil War, which started in 1642, Yorkshire had divided loyalties; Hull famously shut the gates of the city on the king when he came to enter a few months before fighting began, while the North Riding of Yorkshire in particular was strongly royalist.[45][46] York was the base for Royalists, and from there they captured Leeds and Wakefield only to have them recaptured a few months later. The royalists won the Battle of Adwalton Moor meaning they controlled Yorkshire (with the exception of Hull). From their base in Hull the Parliamentarians ("Roundheads") fought back, re-taking Yorkshire town by town, until they won the Battle of Marston Moor and with it control of all of the North of England.[47]		In the 16th and 17th centuries Leeds and other wool industry centred towns continued to grow, along with Huddersfield, Hull and Sheffield, while coal mining first came into prominence in the West Riding of Yorkshire.[48] Canals and turnpike roads were introduced in the late 18th century. In the following century the spa towns of Harrogate and Scarborough flourished, due to people believing mineral water had curative properties.[49]		The 19th century saw Yorkshire's continued growth, with the population growing and the Industrial Revolution continuing with prominent industries in coal, textile and steel (especially in Sheffield and Rotherham). However, despite the booming industry, living conditions declined in the industrial towns due to overcrowding, this saw bouts of cholera in both 1832 and 1848.[50] Fortunately for the county, advances were made by the end of the century with the introduction of modern sewers and water supplies. Several Yorkshire railway networks were introduced as railways spread across the country to reach remote areas.[51] County councils were created for the three ridings in 1889, but their area of control did not include the large towns, which became county boroughs, and included an increasingly large part of the population.[52]		During the Second World War, Yorkshire became an important base for RAF Bomber Command and brought the county into the cutting edge of the war.[53]		In the 1970s there were major reforms of local government throughout the United Kingdom. Some of the changes were unpopular,[54] and controversially Yorkshire and its ridings lost status in 1974[55] as part of the Local Government Act 1972.[56] The East Riding was resurrected with reduced boundaries in 1996 with the abolition of Humberside. With slightly different borders, the government office entity which currently contains most of Yorkshire is the Yorkshire and the Humber region of England.[55] This region includes a northern slice of Lincolnshire, but does not include the northern part of the ceremonial county of North Yorkshire (Middlesbrough and Redcar and Cleveland), which is in the North East England region. Other parts of the historic county of Yorkshire are also in other official regions. Saddleworth (now in Greater Manchester); the Forest of Bowland (Lancashire); Sedbergh and Dent (Cumbria) are in the North West England region, and Upper Teesdale (County Durham) is in North East England.[54]		Historically, the northern boundary of Yorkshire was the River Tees, the eastern boundary was the North Sea coast and the southern boundary was the Humber Estuary and Rivers Don and Sheaf. The western boundary meandered along the western slopes of the Pennine Hills to again meet the River Tees.[57] It is bordered by several other historic counties in the form of County Durham, Lincolnshire, Nottinghamshire, Derbyshire, Cheshire, Lancashire and Westmorland.[58] In Yorkshire there is a very close relationship between the major topographical areas and the geological period in which they were formed.[57] The Pennine chain of hills in the west is of Carboniferous origin. The central vale is Permo-Triassic. The North York Moors in the north-east of the county are Jurassic in age while the Yorkshire Wolds to the south east are Cretaceous chalk uplands.[57]		Yorkshire is drained by several rivers. In western and central Yorkshire the many rivers empty their waters into the River Ouse which reaches the North Sea via the Humber Estuary.[59] The most northerly of the rivers in the Ouse system is the River Swale, which drains Swaledale before passing through Richmond and meandering across the Vale of Mowbray. Next, draining Wensleydale, is the River Ure, which the Swale joins east of Boroughbridge. Near Great Ouseburn the Ure is joined by the small Ouse Gill Beck, and below the confluence the river is known as the Ouse. The River Nidd rises on the edge of the Yorkshire Dales National Park and flows along Nidderdale before reaching the Vale of York and the Ouse.[59] The River Wharfe, which drains Wharfedale, joins the Ouse upstream of Cawood.[59] The Rivers Aire and Calder are more southerly contributors to the River Ouse and the most southerly Yorkshire tributary is the River Don, which flows northwards to join the main river at Goole. Further north and east the River Derwent rises on the North York Moors, flows south then westwards through the Vale of Pickering then turns south again to drain the eastern part of the Vale of York. It empties into the River Ouse at Barmby on the Marsh.[59]		In the far north of the county the River Tees flows eastwards through Teesdale and empties its waters into the North Sea downstream of Middlesbrough. The smaller River Esk flows from west to east at the northern foot of the North York Moors to reach the sea at Whitby.[59] To the east of the Yorkshire Wolds the River Hull flows southwards to join the Humber Estuary at Kingston upon Hull.		The western Pennines are served by the River Ribble which drains westwards into the Irish Sea close to Lytham St Annes.[59]		The countryside of Yorkshire has acquired the common nickname of "God's Own County".[5][9] Yorkshire includes the North York Moors and Yorkshire Dales National Parks, and part of the Peak District National Park. Nidderdale and the Howardian Hills are designated Areas of Outstanding Natural Beauty.[60] Spurn Point, Flamborough Head and the coastal North York Moors are designated Heritage Coast areas,[61] and are noted for their scenic views with rugged cliffs[62] such as the jet cliffs at Whitby,[62] the limestone cliffs at Filey and the chalk cliffs at Flamborough Head.[63][64] Moor House – Upper Teesdale, most of which is part of the former North Riding of Yorkshire, is one of England's largest national nature reserves.[65]		The Royal Society for the Protection of Birds runs nature reserves such as the one at Bempton Cliffs with coastal wildlife such as the northern gannet, Atlantic puffin and razorbill.[66] Spurn Point is a narrow, 3 miles (4.8 km) long sand spit. It is a national nature reserve owned by the Yorkshire Wildlife Trust and is noted for its cyclical nature whereby the spit is destroyed and re-created approximately once every 250 years.[67] There are seaside resorts in Yorkshire with sandy beaches; Scarborough is Britain's oldest seaside resort dating back to the spa town-era in the 17th century,[68] while Whitby has been voted as the United Kingdom's best beach, with a "postcard-perfect harbour".[69]		Historically, Yorkshire was divided into three ridings and the Ainsty of York. The term 'riding' is of Viking origin and derives from Threthingr meaning a third part. The three ridings in Yorkshire were named the East Riding, West Riding and North Riding.[70] The East and North Ridings of Yorkshire were separated by the River Derwent and the West and North Ridings were separated by the Ouse and the Ure/Nidd watershed. In 1974 the three ridings of Yorkshire were abolished and York, which had been independent of the three ridings, was incorporated into the new county called North Yorkshire. It later became part of York Unitary Authority.[71]		Yorkshire has a mixed economy. The City of Leeds is Yorkshire's largest city and is the main centre of trade and commerce. Leeds is one of the UK's larger financial centres. Leeds' traditional industries were mixed; service-based industries, textile manufacturing and coal mining being examples.		Sheffield once had heavy industries, such as coal mining and the steel industry. Since the decline of such industries Sheffield has attracted tertiary and administrative businesses including more retail trade; Meadowhall being an example. However, while Sheffield's heavy industry has declined, the region has reinvented itself as a centre for specialist engineering. A cluster of hi-tech facilities including The Welding Institute and the Boeing partnered Advanced Materials Research Centre[73] have all helped to raise the region's profile and to bring significant investment into Yorkshire.[citation needed]		Bradford, Halifax, Keighley and Huddersfield once were centres of wool milling. Areas such as Bradford, Dewsbury and Keighley have suffered a decline in their economy since.		North Yorkshire has an established tourist industry with two national parks (Yorkshire Dales National Park, North York Moors National Park), Harrogate, York and Scarborough and such an industry is growing in Leeds. Kingston upon Hull is Yorkshire's largest port and has a large manufacturing base, its fishing industry has however declined somewhat in recent years. Harrogate and Knaresborough both have small legal and financial sectors. Harrogate is a European conference and exhibition destination with both the Great Yorkshire Showground and Harrogate International Centre in the town.		Coal mining was prolific in the south of the county during the 19th century and for most of the 20th century, particularly around Barnsley and Wakefield. As late as the 1970s, the number of miners working in the area was still in six figures.[74] The industry was placed under threat on 6 March 1984 when the National Coal Board announced the closure of 20 pits nationwide (some of them in South Yorkshire). By March 2004, a mere three coalpits remained open in the area.[75] Three years later, the only remaining coal pit in the region was Maltby Colliery near Rotherham.[76]		Many large British companies are based in Yorkshire or were founded there. These include; Morrisons (Bradford), Asda (Leeds), Jet2.com (Leeds), Ronseal (Sheffield), Optare (Leeds), Aunt Bessie's (Hull), Birds Eye (Hull), Wharfedale (Leeds), Plaxton (Scarborough), Seven Seas (Hull), Little Chef (Sheffield), Plusnet (Sheffield), Quidco (Sheffield), Fenner plc (Hull), Halifax Bank (Halifax), Rank Organisation (Hull), Yorkshire Bank (Leeds), William Jackson Food Group (Hull), Yorkshire Building Society (Bradford), Victoria Plumb (Hull), Ebuyer (Howden), GHD (Leeds), Marks and Spencer (Leeds), Burtons (Leeds), Jaeger Ilkley, Magnet Kitchens (Keighley), Reckitt and Sons (Hull), McCains (Scarborough), First Direct (Leeds), KCOM Group (Hull), Tetley's Brewery (Leeds), Timothy Taylor Brewery (Keighley), Bradford and Bingley (Bingley), Skipton Building Society (Skipton), Bettys and Taylors of Harrogate, SGS Europe (Hull) and Provident Financial (Bradford.)		The most prominent road in Yorkshire, historically called the Great North Road, is known as the A1.[77] This trunk road passes through the centre of the county and is the prime route from London to Edinburgh.[78] Another important road is the more easterly A19 road which starts in Doncaster and ends just north of Newcastle-upon-Tyne at Seaton Burn. The M62 motorway crosses the county from east to west from Hull towards Greater Manchester and Merseyside.[79] The M1 carries traffic from London and the south of England to Yorkshire. In 1999 about 8 miles (13 km) was added to make it swing east of Leeds and connect to the A1.[80] The East Coast Main Line rail link between Scotland and London runs roughly parallel with the A1 through Yorkshire and the Trans Pennine rail link runs east to west from Hull to Liverpool via Leeds.[81]		Before the advent of rail transport, the seaports of Hull and Whitby played an important role in transporting goods. Historically canals were used, including the Leeds and Liverpool Canal, which is the longest canal in England. Mainland Europe (the Netherlands and Belgium) can be reached from Hull via regular ferry services from P&O Ferries.[82] Yorkshire also has air transport services from Leeds Bradford International Airport. This airport has experienced significant and rapid growth in both terminal size and passenger facilities since 1996, when improvements began, until the present day.[83] South Yorkshire is served by the Robin Hood Airport Doncaster Sheffield, based in Finningley.[84] Sheffield City Airport opened in 1997 after years of Sheffield having no airport, due to a council decision in the 1960s not to develop one because of the city's good rail links with London and the development of airports in other nearby areas. The newly opened airport never managed to compete with larger airports such as Leeds Bradford International Airport and East Midlands Airport and attracted only a few scheduled flights, while the runway was too short to support low cost carriers. The opening of Doncaster Sheffield Airport effectively made the airport redundant and it officially closed in April 2008.		The culture of the people of Yorkshire is an accumulated product of a number of different civilisations who have influenced its history, including; the Celts (Brigantes and Parisii), Romans, Angles, Norse Vikings, Normans and amongst others.[85] The western part of the historic North Riding had an additional infusion of Breton culture due to the Honour of Richmond being occupied by Alain Le Roux, grandson of Geoffrey I, Duke of Brittany.[86] The people of Yorkshire are immensely proud of their county and local culture and it is sometimes suggested they identify more strongly with their county than they do with their country.[87] Yorkshire people have their own Yorkshire dialects and accents and are, or rather were, known as Broad Yorkshire or Tykes, with its roots in Old English and Old Norse.[88][89]		Though distinct accents remain, dialects are no longer in everyday use. Some have argued the dialect was a fully fledged language in its own right.[90] The county has also produced a set of Yorkshire colloquialisms,[91] which are in use in the county. Among Yorkshire's traditions is the Long Sword dance. The most famous traditional song of Yorkshire is On Ilkla Moor Baht 'at ("On Ilkley Moor without a hat"), it is considered the unofficial anthem of the county.[92]		Throughout Yorkshire many castles were built during the Norman-Breton period, particularly after the Harrying of the North. These included Bowes Castle, Pickering Castle, Richmond Castle, Skipton Castle, York Castle and others.[93] Later medieval castles at Helmsley, Middleham and Scarborough were built as a means of defence against the invading Scots.[94] Middleham is notable because Richard III of England spent his childhood there.[94] The remains of these castles, some being English Heritage sites, are popular tourist destinations.[94] There are several stately homes in Yorkshire which carry the name "castle" in their title, even though they are more akin to a palace.[95] The most notable examples are Allerton Castle and Castle Howard,[96] both linked to the Howard family.[97] Castle Howard and the Earl of Harewood's residence, Harewood House, are included amongst the Treasure Houses of England, a group of nine English stately homes.[98]		There are numerous other Grade I listed buildings within the historic county including public buildings such as Leeds Town Hall, Sheffield Town Hall, Ormesby Hall, the Yorkshire Museum and Guildhall at York, and the Piece Hall in Halifax.[99] Large estates with significant buildings were constructed at Brodsworth Hall, Temple Newsam and Wentworth Castle. In addition to this there are properties which are conserved and managed by the National Trust, such as Nunnington Hall, the Rievaulx Terrace & Temples and Studley Royal Park.[100] Religious architecture includes extant cathedrals as well as the ruins of monasteries and abbeys. Many of these prominent buildings suffered from the Dissolution of the Monasteries under Henry VIII; these include Bolton Abbey, Fountains Abbey, Gisborough Priory, Rievaulx Abbey, St Mary's Abbey and Whitby Abbey among others.[101] Notable religious buildings of historic origin still in use include York Minster, the largest Gothic cathedral in northern Europe,[101] Beverley Minster, Bradford Cathedral and Ripon Cathedral.[101]		Although the first Professor of English Literature at Leeds University, F.W. Moorman, claimed the first extant work of English literature, Beowulf, was written in Yorkshire,[102] this view does not have common acceptance today. However, when Yorkshire formed the southern part of the kingdom of Northumbria there were several notable poets, scholars and ecclesiastics, including Alcuin, Cædmon and Wilfrid.[103] The most esteemed literary family from the county are the three Brontë sisters, with part of the county around Haworth being nicknamed Brontë Country in their honour.[104] Their novels, written in the mid-19th century, caused a sensation when they were first published, yet were subsequently accepted into the canon of great English literature.[105] Among the most celebrated novels written by the sisters are Anne Brontë's The Tenant of Wildfell Hall, Charlotte Brontë's Jane Eyre and Emily Brontë's Wuthering Heights.[104] Wuthering Heights was almost a source used to depict life in Yorkshire, illustrating the type of people that reside there in its characters, and emphasising the use of the stormy Yorkshire moors. Nowadays, the parsonage which was their former home is now a museum in their honour.[106] Bram Stoker authored Dracula while living in Whitby[107] and it includes several elements of local folklore including the beaching of the Russian ship Dmitri, which became the basis of Demeter in the book.[108]		The novelist tradition in Yorkshire continued into the 20th century, with authors such as J. B. Priestley, Alan Bennett, Stan Barstow, Dame Margaret Drabble, A S Byatt, and Barbara Taylor Bradford being prominent examples.[109][110] Taylor Bradford is noted for A Woman of Substance which was one of the top-ten best selling novels in history.[111] Another well-known author was children's writer Arthur Ransome, who penned the Swallows and Amazons series.[110] James Herriot, the best selling author of over 60 million copies of books about his experiences of some 50 years as a veterinarian in Thirsk, North Yorkshire, the town which he refers to as Darrowby in his books[112] (although born in Sunderland), has been admired for his easy reading style and interesting characters.[113] Poets include Ted Hughes, W. H. Auden, William Empson, Simon Armitage and Andrew Marvell.[110][114][115][116] Three well known sculptors emerged in the 20th century; contemporaries Henry Moore and Barbara Hepworth, and Leeds-raised eco artist Andy Goldsworthy. Some of their works are available for public viewing at the Yorkshire Sculpture Park.[117] There are several art galleries in Yorkshire featuring extensive collections, such as Ferens Art Gallery, Leeds Art Gallery, Millennium Galleries and York Art Gallery.[118][119][120] Some of the better known local painters are William Etty and David Hockney;[121] many works by the latter are housed at Salts Mill 1853 Gallery in Saltaire.[122]		Yorkshire has a long tradition in the field of sports, with participation in cricket, football, rugby league and horse racing being the most established sporting ventures.[123][124][125][126] Yorkshire County Cricket Club represents the historic county in the domestic first class cricket County Championship; with a total of 32 championship titles, 14 more than any other county, Yorkshire is the most decorated county cricket club.[125] Some of the most highly regarded figures in the game were born in the county[127] amongst them Geoffrey Boycott, Brian Close, George Hirst, Len Hutton, Stanley Jackson, Ray Illingworth, Wilfred Rhodes, Joe Root, Herbert Sutcliffe, Fred Trueman and Hedley Verity.[127] England's oldest horse race, which began in 1519, is run each year at Kiplingcotes near Market Weighton.[126] Continuing this tradition in the field of horse racing, there are currently nine established racecourses in the county.[128] Britain's oldest organised fox hunt is the Bilsdale, founded in 1668.[129][130]		Yorkshire is officially recognised by FIFA as the birthplace of club football,[131][132] as Sheffield FC founded in 1857 are certified as the oldest association football club in the world.[133] The world's first inter-club match and local derby was competed in the county, at the world's oldest ground Sandygate Road.[134] The Laws of the Game which are now used worldwide were drafted by Ebenezer Cobb Morley from Hull.[135] Football clubs founded in Yorkshire include Barnsley, Bradford City, Doncaster Rovers, Huddersfield Town, Hull City, Leeds United, Middlesbrough, Rotherham United, Sheffield United, Sheffield Wednesday and York City, four of which have been the league champions. Huddersfield were the first club to win three consecutive league titles.[136] Middlesbrough F.C. recently came to prominence by reaching the 2006 UEFA Cup Final[137] and winning the 2004 League Cup.[138] Leeds United are arguably the biggest team in Yorkshire, reaching the semi finals of the UEFA Champions League in 2001 and having a period of dominance in the 1970s; this position is often paralleled with Sheffield Wednesday who have had similar spells of dominance, most recently in the early 1990s, and also house a comparably large fan-base and prestigious history.[citation needed] Noted players from Yorkshire who have influenced the game include World Cup-winning goalkeeper Gordon Banks[139] and two time European Footballer of the Year award winner Kevin Keegan,[140] as well as prominent managers Herbert Chapman, Brian Clough, Bill Nicholson, George Raynor and Don Revie.[141]		The Rugby Football League and with it the sport of rugby league was founded in 1895 at the George Hotel, Huddersfield, after a North-South schism within the Rugby Football Union.[142] The top league is the Super League and the most decorated Yorkshire clubs are Huddersfield Giants, Hull FC, Bradford Bulls, Hull Kingston Rovers, Wakefield Trinity Wildcats, Castleford Tigers and Leeds Rhinos.[143] In total six Yorkshiremen have been inducted into the Rugby Football League Hall of Fame amongst them is Roger Millward, Jonty Parkin and Harold Wagstaff.[144] In the area of boxing "Prince" Naseem Hamed from Sheffield achieved title success and widespread fame,[145] in what the BBC describes as "one of British boxing's most illustrious careers".[145] Along with Leeds-born Nicola Adams who in 2012 became the first female athlete to win a boxing gold medal at the olympics.[146] Yorkshire also has an array of racecourses, in North Yorkshire, there are Catterick, Redcar, Ripon, Thirsk and York in the East Riding of Yorkshire there is Beverley, in West Yorkshire there are Pontefract and Wetherby, while in South Yorkshire there is Doncaster.		The sport of Knurr and Spell was unique to the region, being one of the most popular sports in the area during the 18th and 19th centuries, before a decline in the 20th century to virtual obscurity.[147][148][149]		A number of athletes from or associated with Yorkshire took part in the 2012 Summer Olympics as members of Team GB; the Yorkshire Post stated that Yorkshire's athletes alone secured more gold medals than those of Spain.[150] Notable Yorkshire athletes include Jessica Ennis-Hill and the Brownlee brothers Jonathan and Alastair. Jessica Ennis-Hill is from Sheffield and won gold at the 2012 Olympics in London and silver at the 2016 Olympics in Rio. Triathletes Alastair and Jonny Brownlee have won two golds and a silver and bronze respectively.		In 2014 the County hosted the Grande Depart of the Tour de France. Spectator crowds over the two days were estimated to be of the order of 2.5 million people.[151] The inaugural Tour de Yorkshire was held from 1–3 May 2015,[152] with start and finishes in Bridlington, Leeds, Scarborough, Selby, Wakefield and York,[153] watched by 1.2 million.[154]		The traditional cuisine of Yorkshire, in common with the North of England in general, is known for using rich tasting ingredients, especially with regard to sweet dishes, which were affordable for the majority of people.[155] There are several dishes which originated in Yorkshire or are heavily associated with it.[155] Yorkshire pudding, a savoury batter dish, is by far the best known of Yorkshire foods, and is eaten throughout England. It is commonly served with roast beef and vegetables to form part of the Sunday roast[155] but is traditionally served as a starter dish filled with onion gravy within Yorkshire.[156] Yorkshire pudding is the base for toad in the hole, a dish containing sausage.[157]		Other foods associated with the county include: Yorkshire curd tart, a curd tart recipe with rosewater;[158] Parkin, a sweet ginger cake which is different from standard ginger cakes in that it includes oatmeal and treacle;[159] and Wensleydale cheese, a cheese made with milk from Wensleydale and often eaten as an accompaniment to sweet foods.[160] The beverage ginger beer, flavoured with ginger, came from Yorkshire and has existed since the mid 18th century. Liquorice sweet was first created by George Dunhill from Pontefract, who in the 1760s thought to mix the liquorice plant with sugar.[161] Yorkshire and in particular the city of York played a prominent role in the confectionery industry, with chocolate factories owned by companies such as Rowntree's, Terry's and Thorntons inventing many of Britain's most popular sweets.[162][163] Another traditional Yorkshire food is pikelets which are similar to crumpets but much thinner.[164] The Rhubarb Triangle is a location within Yorkshire which supplies most of the rhubarb to locals.		In recent years curries have become popular in the county largely due to the immigration and successful integration of Asian families. There are many famous curry empires with their origins in Yorkshire including the 850-seater Aakash restaurant in Cleckheaton which has been described as "the world's largest curry house".[165]		Yorkshire has a number of breweries including Black Sheep, Copper Dragon, Cropton Brewery, John Smith's, Sam Smith's, Kelham Island Brewery, Theakstons, Timothy Taylor, Wharfedale Brewery and Leeds Brewery.[166][167] The beer style most associated with the county is bitter.[168] As elsewhere in the North of England, when served through a handpump, a sparkler is used giving a tighter, more solid head.[169]		Brewing has taken place on a large scale since at least the 12th century, for example at the now derelict Fountains Abbey which at its height produced 60 barrels of strong ale every ten days.[170] Most current Yorkshire breweries date from the Industrial Revolution of the late 18th and early 19th century.[166]		Yorkshire has a heritage of folk music and folk dance including the Long Sword dance.[171] Yorkshire folk song was distinguished by the use of dialect, particularly in the West Riding and exemplified by the song 'On Ilkla Moor Baht 'at', probably written in the late 19th century, using a Kent folk tune (almost certainly borrowed via a Methodist hymnal),[citation needed] seen as an unofficial Yorkshire anthem.[172] Famous folk performers from the county include the Watersons from Hull, who began recording Yorkshire versions of folk songs from 1965;[173] Heather Wood (born 1945) of the Young Tradition; the short-lived electric folk group Mr Fox (1970–72), The Deighton Family; Julie Matthews; Kathryn Roberts; and Kate Rusby.[173] Yorkshire has a flourishing folk music culture, with over forty folk clubs and thirty annual folk music festivals.[174] The 1982 Eurovision Song Contest was held in the Harrogate International Centre. In 2007 the Yorkshire Garland Group was formed to make Yorkshire folk songs accessible online and in schools.[175]		In the field of classical music, Yorkshire has produced some major and minor composers, including Frederick Delius, George Dyson, Edward Bairstow, William Baines, Kenneth Leighton, Eric Fenby, Haydn Wood, Arthur Wood, Arnold Cooke, Gavin Bryars, and in the area of TV, film and radio music, John Barry and Wally Stott.		The county is home to successful brass bands such as Black Dyke, Brighouse & Rastrick, Carlton Main Frickley, Hammonds Saltaire, and Yorkshire Imperial.		During the 1970s David Bowie, himself of a father from Tadcaster in North Yorkshire,[176] hired three musicians from Hull, Mick Ronson, Trevor Bolder and Mick Woodmansey; together they recorded Ziggy Stardust and the Spiders from Mars, an album considered by a magazine article as one of a 100 greatest and most influential of all time.[177] In the following decade, Def Leppard, from Sheffield, achieved worldwide fame, particularly in America. Their 1983 album Pyromania and 1987 album Hysteria are among the most successful albums of all time.[citation needed] Yorkshire had a very strong post-punk scene which went on to achieve widespread acclaim and success, including; The Sisters of Mercy, The Cult, Vardis, Gang of Four, ABC, The Human League, New Model Army, Soft Cell, Chumbawamba, The Wedding Present and The Mission.[178] Pulp from Sheffield had a massive hit in "Common People" during 1995; the song focuses on working-class northern life.[179] In 21st century, indie rock and post-punk revival bands from the area gained popularity, including the Kaiser Chiefs, The Cribs and the Arctic Monkeys, the last-named holding the record for the fastest-selling debut album in British music history with Whatever People Say I Am, That's What I'm Not.[180]		Among prominent British television shows filmed in (and based on) Yorkshire are the sitcom Last of the Summer Wine, the drama series Heartbeat, and the soap operas Emmerdale and Downton Abbey. Last of the Summer Wine in particular is noted for holding the record of longest-running comedy series in the world, from 1973 until 2010.[181] Other notable television series set in Yorkshire include All Creatures Great and Small, The Beiderbecke Trilogy, Rising Damp, Fat Friends and The Royal. Several noted films are set in Yorkshire, including Kes, This Sporting Life, Room at the Top, Brassed Off, Mischief Night, Rita, Sue and Bob Too and Calendar Girls. The Full Monty, a comedy film set in Sheffield, won an Academy Award and was voted the second best British film of all time by ANI.[182]		Yorkshire has remained a popular location for filming in more recent times.[183][184] For example, much of ITV's highly-acclaimed Victoria was filmed in the region, at locations such as Harewood House in Leeds and Beverly Minster; the latter was used to depict Westminster Abbey and St James’ Palace.[185][186]		West Yorkshire has particularly benefited from a great deal of production activity.[187][188] For example, portions of the BBC television series Happy Valley and Last Tango in Halifax were filmed in the area, in Huddersfield and other cities; in addition to exteriors, some of the studio filming for Happy Valley was done at North Light Film Studios at Brookes Mill, Huddersfield. As well, the BBC's Jamaica Inn, for the BBC's Remember Me and for ITV series Black Work, were also filmed at the studios and in nearby West Yorkshire locations.[189][190][191][192] More recently, many of the exteriors of the BBC series Jericho were filmed at the nearby Rockingstone Quarry and some interior work was done at North Light Film Studios.[193]		From 1290, Yorkshire was represented by two Members of Parliament of the House of Commons of the Parliament of England. After the union with Scotland two members represented the county in the Parliament of Great Britain from 1707 to 1800 and of the Parliament of the United Kingdom from 1801 to 1832. In 1832 the county benefited from the disfranchisement of Grampound by taking an additional two members.[194] Yorkshire was represented at this time as one single, large, county constituency.[194] Like other counties, there were also some county boroughs within Yorkshire, the oldest of which was the City of York, which had existed since the ancient Montfort's Parliament of 1265. After the Reform Act 1832, Yorkshire's political representation in parliament was drawn from its subdivisions, with Members of Parliament representing each of the three historic Ridings of Yorkshire; East Riding, North Riding, and West Riding constituencies.[194]		For the 1865 general elections and onwards, the West Riding was further divided into Northern, Eastern and Southern parliamentary constituencies, though these only lasted until the major Redistribution of Seats Act 1885.[195] This act saw more localisation of government in the United Kingdom, with the introduction of 26 new parliamentary constituencies within Yorkshire, while the Local Government Act 1888 introduced some reforms for the county boroughs, of which there were eight in Yorkshire by the end of the 19th century.[196]		With the Representation of the People Act 1918 there was some reshuffling on a local level for the 1918 general election, revised again during the 1950s.[197] The most controversial reorganisation of local government in Yorkshire was the Local Government Act 1972,[198] put into practice in 1974. Under the act, the Ridings lost their lieutenancies, shrievalties, and administrative counties. County boroughs and their councils were abolished, to be replaced by metropolitan and non-metropolitan counties with vastly changed borders.[56] Although some government officials[199] and Prince Charles[200] have asserted such reform is not meant to alter the ancient boundaries or cultural loyalties, there are pressure groups such as the Yorkshire Ridings Society who want greater recognition for the historic boundaries.[201] In 1996 the East Riding of Yorkshire was reformed as a unitary authority area and a ceremonial county. The Yorkshire and the Humber region of government office covers most, but not all of the historic county. Yorkshire and the Humber is a constituency for European elections, returning six MEPs to the European Parliament.		A number of claims have been made for the distinctiveness of Yorkshire, as a geographical, cultural and political entity, and these have been used to demand increased political autonomy. In the early twentieth century, F. W. Moorman, the first professor of English Language at Leeds University, claimed Yorkshire was not settled by Angles or Saxons following the end of rule Roman in Britain, but by a different Germanic tribe, the Geats. As a consequence, he claimed, it is possible the first work of English literature, Beowulf, believed to have been composed by Geats, was written in Yorkshire, and this distinctive ethnic and cultural origin is the root of the unique status of Yorkshire today.[102] One of Moorman's students at Leeds University, Herbert Read, was greatly influenced by Moorman's ideas on Yorkshire identity, and claimed that until recent times Yorkshire was effectively an island, cut off from the rest of England by rivers, fens, moors and mountains. This distancing of Yorkshire from England led Read to question whether Yorkshire people were really English at all.[202] Combined with the suggested ethnic difference to the rest of England, Read quoted Frederic Pearson, who wrote:		There is something characteristic about the very physiognomy of the Yorkshireman. He is much more of a Dane or a Viking than a Saxon. He is usually a big upstanding man, who looks as if he could take care of himself and those who depend upon him in an emergency. This is indeed the character that his neighbours give him; the southerner may think him a little hard: but if ever our country is let down by its inhabitants, we may be sure that it will not be the fault of Yorkshire.[202]		During the premiership of William Pitt the Younger the hypothetical idea of Yorkshire becoming independent was raised in the British parliament in relation to the question whether Ireland should become part of the United Kingdom. This resulted in an anonymous pamphlet being published in London in 1799 arguing at length that Yorkshire could never be an independent state as it would always be reliant on the rest of the United Kingdom to provide it with essential resources.[203]		Although in the devolution debates in the House of Commons of the late 1960s, which paved the way for the 1979 referenda on the creation of a Scottish parliament and Welsh assembly, parallel devolution for Yorkshire was suggested, this was opposed by the Scottish Nationalist Party Member of Parliament for Hamilton, Winifred Ewing. Ewing argued that it was offensive to Scots to argue that an English region had the same status as an 'ancient nation' such as Scotland.[204]		The relationship between Yorkshire and Scottish devolution was again made in 1975 by Richard Wainwright, MP for Colne Valley, who claimed in a speech in the House of Commons:		The nationalist movement in Scotland is associated with flags, strange costumes, weird music and extravagant ceremonial. When... people go to Yorkshire and find that we have no time for dressing up, waving flags and playing strange instruments—in other words, we are not a lot of Presbyterians in Yorkshire—they should not assume that we do not have the same feelings underneath the skin. Independence in Yorkshire expresses itself in a markedly increasing determination to establish self-reliance.[205]		In more recent years, in 1998 the Campaign for Yorkshire was established to push for the creation of a Yorkshire regional assembly,[206] sometimes dubbed the Yorkshire Parliament.[207] In its defining statement, the Campaign for Yorkshire made reference to the historical notions that Yorkshire had a distinctive identity:		Yorkshire and the Humber has distinctive characteristics which make it an ideal test bed for further reform. It has a strong popular identity. The region follows closely the historic boundaries of the three Ridings, and there is no serious debate about boundaries. It possesses strong existing regional partnerships including universities, voluntary and church associations. All this makes it realistic to regard Yorkshire and the Humber as the standard bearer for representative regional government.[208]		The Campaign for Yorkshire was led by Jane Thomas as Director[209] and Paul Jagger as chairman. Jagger claimed in 1999 that Yorkshire had as much right to a regional parliament or assembly as Scotland and Wales because Yorkshire 'has as clear a sense of identity as Scotland or Wales.'[210] One of those brought into the Campaign for Yorkshire by Jane Thomas was Herbert Read scholar Michael Paraskos, who organised a series of events in 2000 to highlight the distinctiveness of Yorkshire culture. This included a major exhibition of Yorkshire artists.[211] Paraskos also founded a Yorkshire Studies degree course at Hull University.[212] Interviewed by The Guardian newspaper, Paraskos linked the start of this course to the contemporary devolution debates in Yorkshire, Scotland and Wales, claiming:		If Yorkshire is arguing for a parliament, there needs to be a cultural argument as well, otherwise why not have a parliament of the north? There is a rediscovery of political and social culture going on in a very similar way to the early assertions of a Scottish identity.[213]		In 2014, two other former members of the Campaign for Yorkshire, Stewart Arnold and Richard Carter, founded Yorkshire First, a political party campaigning for the creation of a Yorkshire parliament by 2050 based on the Scottish Parliament. It was later renamed the Yorkshire Party.[214]		When the territory of Yorkshire began to take shape as a result of the invasion of the Danish vikings, they instituted a monarchy based at the settlement of Jórvík, York.[215] The reign of the Viking kings came to an end with the last king Eric Bloodaxe dying in battle in 954 after the invasion and conquest by the Kingdom of England from the south. Jórvík was the last of the independent kingdoms to be taken to form part of the Kingdom of England and thus the local monarchal title became defunct.[216]		Though the monarchal title became defunct, it was succeeded by the creation of the Earl of York title of nobility[217] by king of England Edgar the Peaceful in 960. (The earldom covered the general area of Yorkshire and is sometimes referred to as the Earl of Yorkshire.)[217] The title passed through the hands of various nobles, decided upon by the king of England. The last man to hold the title was William le Gros, however the earldom was abolished by Henry II as a result of a troubled period known as The Anarchy.[218]		The peerage was recreated by Edward III in 1385, this time in the form of the prestigious title of Duke of York which he gave to his son Edmund of Langley. Edmund founded the House of York; later the title was merged with that of the King of England. Much of the modern-day symbolism of Yorkshire, such as the White Rose of York, is derived from the Yorkists,[219] giving the house a special affinity within the culture of Yorkshire. Especially celebrated is the Yorkist king Richard III who spent much of his life at Middleham Castle in Yorkshire.[39][220] Since that time the title has passed through the hands of many, being merged with the crown and then recreated several times. The title of Duke of York is given to the second son of the British monarch.[221]		Coordinates: 54°N 2°W﻿ / ﻿54°N 2°W﻿ / 54; -2		
Tide pools, or rock pools, are rocky pools on the sea shore which are filled with seawater. Many of these pools exist as separate pools only at low tide.		Many tide pools are habitats of especially adaptable animals that have engaged the attention of naturalists and marine biologists, as well as philosophical essayists: John Steinbeck wrote in The Log from the Sea of Cortez, "It is advisable to look from the tide pool to the stars and then back to the tide pool."[1]						Tidal pools exist in the intertidal zones. These zones are submerged by the sea at high tides and during storms, and may receive spray from wave action. At other times the rocks may undergo other extreme conditions, baking in the sun or exposed to cold winds. Few organisms can survive such harsh conditions. Lichens and barnacles live in this region.[1] In this zone, different barnacle species live at very tightly constrained elevations. Tidal conditions precisely determine the exact height of an assemblage relative to sea level.		The intertidal zone is periodically exposed to sun and wind, which desiccate barnacles, which need to be well adapted to water loss. Their calcite shells are impermeable, and they possess two plates which they slide across their mouth opening when not feeding. These plates also protect against predation.[verification needed]		The high tide zone is flooded during each high tide. Organisms must survive wave action, currents, and exposure to the sun. This zone is predominantly inhabited by seaweed and invertebrates, such as sea anemones, starfish, chitons, crabs, green algae, and mussels. Marine algae provide shelter for nudibranches and hermit crabs. The same waves and currents that make life in the high tide zone difficult bring food to filter feeders and other intertidal organisms.		Also called the Lower Littoral Zone. This area is usually under water - it is only exposed when the tide is unusually low. This sub region is mostly submerged, but it is exposed only during low tide. Often it teems with life and has much more marine vegetation, especially seaweeds. There is also greater biodiversity. Organisms in this zone do not have to be as well adapted to drying out and temperature extremes. Low tide zone organisms include abalone, anemones, brown seaweed, chitons, crabs, green algae, hydroids, isopods, limpets, mussels, and sometimes even small vertebrates such as fish. These creatures can grow to larger sizes because there is more available energy and better water coverage: the water is shallow enough to allow more sunlight for photosynthetic activity, and the salinity is at almost normal levels. This area is also relatively protected from large predators because of the wave action and shallow water.		Tide pools provide a home for hardy organisms such as starfish, mussels and clams. Inhabitants must be able to deal with a frequently changing environment — fluctuations in water temperature, salinity, and oxygen content. Hazards include waves, strong currents, exposure to midday sun and predators.		Waves can dislodge mussels and draw them out to sea. Gulls pick up and drop sea urchins to break them open. Starfish prey on mussels and are eaten by gulls themselves. Even black bears sometimes feast on intertidal creatures at low tide.[2] Although tide pool organisms must avoid getting washed away into the ocean, drying up in the sun, or getting eaten, they depend on the tide pool's constant changes for food.[1]		The sea anemone Anthopleura elegantissima reproduces clones of itself through a process called longitudinal fission, in which the animal splits into two parts along its length.[3] The sea anemone Anthopleura sola often engages in territorial fights. The white tentacles (acrorhagi), which contain stinging cells, are for fighting. The sea anemones sting each other repeatedly until one moves.[4]		Some species of starfish can regenerate lost arms. Most species must retain an intact central part of the body to be able to regenerate, but a few can regrow from a single ray. The regeneration of these stars is possible because the vital organs are in the arms.[5]		Sea palms look similar to palm trees. They live in the middle to upper intertidal zones in areas with greater wave action. High wave action may increase nutrient availability and moves the blades of the thallus, allowing more sunlight to reach the organism so that it can photosynthesize. In addition, the constant wave action removes competitors, such as the mussel species Mytilus californianus.		Recent studies have shown that Postelsia grows in greater numbers when such competition exists — a control group with no competition produced fewer offspring than an experimental group with mussels; from this it is thought that the mussels provide protection for the developing gametophytes.[6] Alternatively, the mussels may prevent the growth of competing algae such as Corallina or Halosaccion, allowing Postelsia to grow freely after wave action removes the mussels.[7]		A large sea anemone Anthopleura sola consuming a "by-the-wind-sailor" Velella velella a blue hydrozoan		Postelsia palmaeformis at low tide in a tide pool		Sea star, Pisaster ochraceus consuming a mussel in tide pools		Sea anemones, Anthopleura sola engaged in a battle for territory		
Coordinates: 21°18′41″N 157°47′47″W﻿ / ﻿21.31139°N 157.79639°W﻿ / 21.31139; -157.79639		Hawaii (English: /həˈwaɪ.i, -ji, -ʔi/ ( listen) hə-WY-(y)ee; Hawaiian: Hawaiʻi [həˈvɐjʔi]) is the 50th and most recent state to have joined the United States of America, having received statehood on August 21, 1959.[10] Hawaii is the only U.S. state located in Oceania and the only one composed entirely of islands. It is the northernmost island group in Polynesia, occupying most of an archipelago in the central Pacific Ocean.[11] Hawaii is the only U.S. state located outside North America.		The state encompasses nearly the entire volcanic Hawaiian archipelago, which comprises hundreds of islands spread over 1,500 miles (2,400 km). At the southeastern end of the archipelago, the eight main islands are—in order from northwest to southeast: Niʻihau, Kauaʻi, Oʻahu, Molokaʻi, Lānaʻi, Kahoʻolawe, Maui, and the Island of Hawaiʻi. The last is the largest island in the group; it is often called the "Big Island" or "Hawaiʻi Island" to avoid confusion with the state or archipelago. The archipelago is physiographically and ethnologically part of the Polynesian subregion of Oceania.		Hawaii's diverse natural scenery, warm tropical climate, abundance of public beaches, oceanic surroundings, and active volcanoes make it a popular destination for tourists, surfers, biologists, and volcanologists. Because of its central location in the Pacific and 19th-century labor migration, Hawaii's culture is strongly influenced by North American and Asian cultures, in addition to its indigenous Hawaiian culture. Hawaii has over a million permanent residents, along with many visitors and U.S. military personnel. Its capital is Honolulu on the island of Oʻahu.		Hawaii is the 8th-smallest and the 11th-least populous, but the 13th-most densely populated of the fifty U.S. states. It is the only state with an Asian plurality. The state's coastline is about 750 miles (1,210 km) long, the fourth longest in the U.S. after the coastlines of Alaska, Florida, and California.		The state of Hawaii derives its name from the name of its largest island, Hawaiʻi. A common Hawaiian explanation of the name of Hawaiʻi is that was named for Hawaiʻiloa, a legendary figure from Hawaiian myth. He is said to have discovered the islands when they were first settled.[12][13]		The Hawaiian language word Hawaiʻi is very similar to Proto-Polynesian *Sawaiki, with the reconstructed meaning "homeland".[14] Cognates of Hawaiʻi are found in other Polynesian languages, including Māori (Hawaiki), Rarotongan (ʻAvaiki) and Samoan (Savaiʻi) . According to linguists Pukui and Elbert,[15] "[e]lsewhere in Polynesia, Hawaiʻi or a cognate is the name of the underworld or of the ancestral home, but in Hawaii, the name has no meaning".[16]		A somewhat divisive political issue arose in 1978 when the Constitution of the State of Hawaii added Hawaiian as a second official state language.[17] The title of the state constitution is The Constitution of the State of Hawaii. Article XV, Section 1 of the Constitution uses The State of Hawaii.[18] Diacritics were not used because the document, drafted in 1949,[19] predates the use of the okina (ʻ) and the kahakō in modern Hawaiian orthography. The exact spelling of the state's name in the Hawaiian language is Hawaiʻi.[b] In the Hawaii Admission Act that granted Hawaiian statehood, the federal government recognized Hawaii as the official state name. Official government publications, department and office titles, and the Seal of Hawaii use the traditional spelling with no symbols for glottal stops or vowel length.[20] In contrast, the National and State Parks Services, the University of Hawaiʻi and some private enterprises implement these symbols. No precedent for changes to U.S. state names exists since the adoption of the United States Constitution in 1789. However, the Constitution of Massachusetts formally changed the Province of Massachusetts Bay to the Commonwealth of Massachusetts in 1780, and in 1819 the Territory of Arkansaw was created but was later admitted to statehood as State of Arkansas.		There are eight main Hawaiian islands, seven of which are permanently inhabited. The island of Niʻihau is privately managed by brothers Bruce and Keith Robinson; access is restricted to those who have permission from the island's owners.		Hawaii from space, January 26, 2014[21]		Nā Pali Coast State Park, Kauaʻi		The main islands and undersea terrain of Hawaii		The Hawaiian archipelago is located 2,000 mi (3,200 km) southwest of the contiguous United States.[31] Hawaii is the southernmost U.S. state and the second westernmost after Alaska. Hawaii, along with Alaska, does not border any other U.S. state. It is the only U.S. state that is not geographically located in North America, the only state completely surrounded by water and that is entirely an archipelago, and the only state in which coffee is commercially cultivable.		In addition to the eight main islands, the state has many smaller islands and islets. Kaʻula is a small island near Niʻihau. The Northwest Hawaiian Islands is a group of nine small, older islands to the northwest of Kauaʻi that extend from Nihoa to Kure Atoll; these are remnants of once much larger volcanic mountains. Across the archipelago are around 130 small rocks and islets, such as Molokini, which are either volcanic, marine sedimentary or erosional in origin.[32]		Hawaii's tallest mountain Mauna Kea is 13,796 ft (4,205 m) above mean sea level;[33] it is taller than Mount Everest if measured from the base of the mountain, which lies on the floor of the Pacific Ocean and rises about 33,500 feet (10,200 m).[34]		The Hawaiian islands were formed by volcanic activity initiated at an undersea magma source called the Hawaii hotspot. The process is continuing to build islands; the tectonic plate beneath much of the Pacific Ocean continually moves northwest and the hot spot remains stationary, slowly creating new volcanoes. Because of the hotspot's location, all currently active land volcanoes are located on the southern half of Hawaii Island. The newest volcano, Lōʻihi Seamount, is located south of the coast of Hawaii Island.		The last volcanic eruption outside Hawaii Island occurred at Haleakalā on Maui before the late 18th century, possibly hundreds of years earlier.[35] In 1790, Kīlauea exploded; it was the deadliest eruption known to have occurred in the modern era in what is now the United States.[36] Up to 5,405 warriors and their families marching on Kīlauea were killed by the eruption.[37] Volcanic activity and subsequent erosion have created impressive geological features. Hawaii Island has the third-highest point among the world's islands.[38]		On the flanks of the volcanoes, slope instability has generated damaging earthquakes and related tsunamis, particularly in 1868 and 1975.[39] Steep cliffs have been created by catastrophic debris avalanches on the submerged flanks of ocean island volcanoes.[40][41]		Because the islands of Hawaii are distant from other land habitats, life is thought to have arrived there by wind, waves (i.e. by ocean currents) and wings (i.e. birds, insects, and any seeds they may have carried on their feathers). This isolation, in combination with the diverse environment (including extreme altitudes, tropical climates, and arid shorelines), produced an array of endemic flora and fauna. Hawaii has more endangered species and has lost a higher percentage of its endemic species than any other U.S. state.[42] One endemic plant, Brighamia, now requires hand-pollination because its natural pollinator is presumed to be extinct.[43] The two species of Brighamia—B. rockii and B. insignis—are represented in the wild by around 120 individual plants. To ensure these plants set seed, biologists rappel down 3,000-foot (910 m) cliffs to brush pollen onto their stigmas.[44]		The extant main islands of the archipelago have been above the surface of the ocean for fewer than 10 million years; a fraction of the time biological colonization and evolution have occurred there. The islands are well known for the environmental diversity that occurs on high mountains within a trade winds field. On a single island, the climate around the coasts can range from dry tropical (less than 20 inches or 510 millimeters annual rainfall) to wet tropical; on the slopes, environments range from tropical rainforest (more than 200 inches or 5,100 millimeters per year), through a temperate climate, to alpine conditions with a cold, dry climate. The rainy climate impacts soil development, which largely determines ground permeability, affecting the distribution of streams and wetlands.[citation needed]		Several areas in Hawaii are under the protection of the National Park Service.[45] Hawaii has two national parks: Haleakalā National Park located near Kula on the island of Maui, which features the dormant volcano Haleakalā that formed east Maui, and Hawaii Volcanoes National Park in the southeast region of the Hawaiʻi Island, which includes the active volcano Kīlauea and its rift zones.		There are three national historical parks; Kalaupapa National Historical Park in Kalaupapa, Molokaʻi, the site of a former leper colony; Kaloko-Honokōhau National Historical Park in Kailua-Kona on Hawaiʻi Island; and Puʻuhonua o Hōnaunau National Historical Park, an ancient place of refuge on Hawaiʻi Island's west coast. Other areas under the control of the National Park Service include Ala Kahakai National Historic Trail on Hawaiʻi Island and the USS Arizona Memorial at Pearl Harbor on Oʻahu.		The Papahānaumokuākea Marine National Monument was proclaimed by President George W. Bush on June 15, 2006. The monument covers roughly 140,000 square miles (360,000 km2) of reefs, atolls, and shallow and deep sea out to 50 miles (80 km) offshore in the Pacific Ocean—an area larger than all of the national parks in the U.S. combined.[46]		Hawaii's climate is typical for the tropics, although temperatures and humidity tend to be less extreme because of near-constant trade winds from the east. Summer highs usually reach around 88 °F (31 °C) during the day, with the temperature reaching a low of 75 °F (24 °C) at night. Winter day temperatures are usually around 83 °F (28 °C); at low elevation they seldom dip below 65 °F (18 °C) at night. Snow, not usually associated with the tropics, falls at 13,800 feet (4,200 m) on Mauna Kea and Mauna Loa on Hawaii Island in some winter months. Snow rarely falls on Haleakalā. Mount Waiʻaleʻale on Kauaʻi has the second-highest average annual rainfall on Earth, about 460 inches (12,000 mm) per year. Most of Hawaii experiences only two seasons; the dry season runs from May to October and the wet season is from October to April.[48]		The warmest temperature recorded in the state, in Pahala on April 27, 1931, is 100 °F (38 °C), making it tied with Alaska as the lowest record high temperature observed in a U.S. state.[49] Hawaii's record low temperature is 12 °F (−11 °C) observed in May 1979 on the summit of Mauna Kea. Hawaii is the only state to have never recorded sub-zero Fahrenheit temperatures.[49]		Climates vary considerably on each island; they can be divided into windward and leeward (koʻolau and kona, respectively) areas based upon location relative to the higher mountains. Windward sides face cloud cover.[citation needed]		Hawaii is one of four U.S. states—apart from the original thirteen, along with the Vermont Republic (1791), the Republic of Texas (1845), and the California Republic (1846)—that were independent nations prior to statehood. Along with Texas, Hawaii had formal, international diplomatic recognition as a nation.[50]		The Kingdom of Hawaiʻi was sovereign from 1810 until 1893 when the monarchy was overthrown by resident American and European capitalists and landholders. Hawaii was an independent republic from 1894 until August 12, 1898, when it officially became a territory of the United States. Hawaii was admitted as a U.S. state on August 21, 1959.[51]		Based on archaeological evidence, the earliest habitation of the Hawaiian Islands dates to around 300 CE, probably by Polynesian settlers from the Marquesas Islands. A second wave of migration from Raiatea and Bora Bora took place in the 11th century. The date of the human discovery and habitation of the Hawaiian Islands is the subject of academic debate.[52] Some archaeologists and historians think it was a later wave of immigrants from Tahiti around 1000 CE who introduced a new line of high chiefs, the kapu system, the practice of human sacrifice, and the building of heiau.[citation needed] This later immigration is detailed in Hawaiian mythology (moʻolelo) about Paʻao. Other authors say there is no archaeological or linguistic evidence for a later influx of Tahitian settlers and that Paʻao must be regarded as a myth.[citation needed]		The history of the islands is marked by a slow, steady growth in population and the size of the chiefdoms, which grew to encompass whole islands. Local chiefs, called aliʻi, ruled their settlements, and launched wars to extend their influence and defend their communities from predatory rivals. Ancient Hawaii was a caste-based society, much like that of Hindus in India.[53]		It is possible that Spanish explorers arrived in the Hawaiian Islands in the 16th century—200 years before Captain James Cook's first documented visit in 1778. Ruy López de Villalobos commanded a fleet of six ships that left Acapulco in 1542 bound for the Philippines with a Spanish sailor named Juan Gaetano aboard as pilot. Depending on the interpretation, Gaetano's reports describe an encounter with either Hawaiʻi or the Marshall Islands.[54][55][better source needed] If de Villalobos' crew spotted Hawaiʻi, Gaetano would be considered the first European to see the islands. Some scholars have dismissed these claims due to a lack of credibility.[56][57]		Spanish archives contain a chart that depicts islands at the same latitude as Hawaiʻi but with a longitude ten degrees east of the islands. In this manuscript, the island of Maui is named La Desgraciada (The Unfortunate Island), and what appears to be Hawaiʻi Island is named La Mesa (The Table). Islands resembling Kahoolawe, Lanai, and Molokai are named Los Monjes (The Monks).[58] For two-and-a-half centuries, Spanish galleons crossed the Pacific from Mexico along a route that passed south of Hawaiʻi on their way to Manila. The exact route was kept secret to protect the Spanish trade monopoly against competing powers.		The 1778 arrival of British explorer James Cook was the first documented contact by a European explorer with Hawaii. Cook named the archipelago as the Sandwich Islands in honor of his sponsor John Montagu, 4th Earl of Sandwich. Cook published the islands' location and rendered the native name as Owyhee. This spelling lives on in Owyhee County, Idaho. It was named after three native Hawaiian members of a trapping party who went missing in that area. The Owyhee Mountains were also named for them.[59]		Cook visited the Hawaiian Islands twice. As he prepared for departure after his second visit in 1779, a quarrel ensued as Cook took temple idols and fencing as "firewood",[60] and a minor chief and his men took a ship's boat. Cook abducted the King of Hawaiʻi Island, Kalaniʻōpuʻu, and held him for ransom aboard his ship in order to gain return of Cook's boat. This tactic had worked in Tahiti and other islands.[61] Instead, Kalaniʻōpuʻu's supporters fought back, killing Cook and four marines as Cook's party retreated along the beach to their ship. They departed without the ship's boat.		After Cook's visit and the publication of several books relating his voyages, the Hawaiian islands attracted many European visitors: explorers, traders, and eventually whalers, who found the islands to be a convenient harbor and source of supplies. Early British influence can be seen in the design of the flag of Hawaiʻi, which bears the Union Jack in the top-left corner. These visitors introduced diseases to the once-isolated islands, causing the Hawaiian population to drop precipitously.[62] Native Hawaiians had no resistance to Eurasian diseases, such as influenza, smallpox and measles. By 1820, disease, famine and wars between the chiefs killed more than half of the Native Hawaiian population.[63] During the 1850s, measles killed a fifth of Hawaii's people.[64]		Historical records indicated the earliest Chinese immigrants to Hawaii originated from Guangdong Province; a few sailors arrived in 1778 with Captain Cook's journey and more arrived in 1789 with an American trader, who settled in Hawaii in the late 18th century. It appears that leprosy was introduced by Chinese workers by 1830; as with the other new infectious diseases, it proved damaging to the Hawaiians.[citation needed]		During the 1780s and 1790s, chiefs often fought for power. After a series of battles that ended in 1795, all inhabited islands were subjugated under a single ruler, who became known as King Kamehameha the Great. He established the House of Kamehameha, a dynasty that ruled the kingdom until 1872.[65]		After Kamehameha II inherited the throne in 1819, American Protestant missionaries to Hawaii converted many Hawaiians to Christianity. They used their influence to end many traditional practices of the people.[66][67] During the reign of King Kamehameha III, Hawai'i turned into a Christian monarchy with the signing of the 1840 Constitution.[68] Hiram Bingham I, a prominent Protestant missionary, was a trusted adviser to the monarchy during this period. Other missionaries and their descendants became active in commercial and political affairs, leading to conflicts between the monarchy and its restive American subjects.[69] Catholic and Mormon missionaries were also active in the kingdom, but they converted a minority of the Native Hawaiian population.[70][71][72] Missionaries from each major group administered to the leper colony at Kalaupapa on Molokaʻi, which was established in 1866 and operated well into the 20th century. The best known were Father Damien and Mother Marianne Cope, both of whom were canonized in the early 21st century as Roman Catholic saints.		The death of the bachelor King Kamehameha V—who did not name an heir—resulted in the popular election of Lunalilo over Kalākaua. Lunalilo died the next year, also without naming an heir. In 1874, the election was contested within the legislature between Kalākaua and Emma, Queen Consort of Kamehameha IV. After riots broke out, the United States and Britain landed troops on the islands to restore order. King Kalākaua was chosen as monarch by the Legislative Assembly by a vote of 39 to 6 on February 12, 1874.[73]		In 1887, Kalākaua was forced to sign the 1887 Constitution of the Kingdom of Hawaii. Drafted by white businessmen and lawyers, the document stripped the king of much of his authority. It established a property qualification for voting that effectively disenfranchised most Hawaiians and immigrant laborers and favored the wealthier, white elite. Resident whites were allowed to vote but resident Asians were not. Because the 1887 Constitution was signed under threat of violence, it is known as the Bayonet Constitution. King Kalākaua, reduced to a figurehead, reigned until his death in 1891. His sister, Queen Liliʻuokalani, succeeded him; she was the last monarch of Hawaiʻi.[74]		In 1893, Queen Liliʻuokalani announced plans for a new constitution. On January 14, 1893, a group of mostly Euro-American business leaders and residents formed the Committee of Safety to stage a coup d'état against the kingdom and seek annexation by the United States. United States Government Minister John L. Stevens, responding to a request from the Committee of Safety, summoned a company of U.S. Marines. According to historian William Russ, these troops effectively rendered the monarchy unable to protect itself.[75]		In January 1893, Queen Liliʻuokalani was overthrown and replaced by a provisional government composed of members of the American Committee of Safety. American lawyer Sanford B. Dole became President of the Republic when the Provisional Government of Hawaii ended on July 4, 1894. Controversy ensued in the following years as the Queen tried to regain her throne. The administration of President Grover Cleveland commissioned the Blount Report, which concluded that the removal of Liliʻuokalani had been illegal. The U.S. government first demanded that Queen Liliʻuokalani be reinstated, but the Provisional Government refused.		Congress conducted an independent investigation, and on February 26, 1894, submitted the Morgan Report, which found all parties, including Minister Stevens—with the exception of the Queen—"not guilty" and not responsible for the coup.[76] Partisans on both sides of the debate questioned the accuracy and impartiality of both the Blount and Morgan reports over the events of 1893.[75][77][78][79]		In 1993, the US Congress passed a joint Apology Resolution regarding the overthrow; it was signed by President Bill Clinton. The resolution apologized for the overthrow of the Hawaiian Kingdom and acknowledged that the United States had annexed Hawaii unlawfully.[79]		After William McKinley won the 1896 U.S. presidential election, advocates pressed to annex the Republic of Hawaii. The previous president, Grover Cleveland, was a friend of Queen Liliʻuokalani. McKinley was open to persuasion by U.S. expansionists and by annexationists from Hawaiʻi. He met with three annexationists: Lorrin A. Thurston, Francis March Hatch and William Ansel Kinney. After negotiations in June 1897, Secretary of State John Sherman agreed to a treaty of annexation with these representatives of the Republic of Hawaii.[80] The U.S. Senate never ratified the treaty. Despite the opposition of most native Hawaiians,[81] the Newlands Resolution was used to annex the Republic to the U.S.; it became the Territory of Hawaii. The Newlands Resolution was passed by the House on June 15, 1898, by 209 votes in favor to 91 against, and by the Senate on July 6, 1898, by a vote of 42 to 21.[82][83][84]		In 1900, Hawaii was granted self-governance and retained ʻIolani Palace as the territorial capitol building. Despite several attempts to become a state, Hawaii remained a territory for sixty years. Plantation owners and capitalists, who maintained control through financial institutions such as the Big Five, found territorial status convenient because they remained able to import cheap, foreign labor. Such immigration and labor practices were prohibited in many states.[85][86]		Puerto Rican immigration to Hawaii began in 1899 when Puerto Rico's sugar industry was devastated by two hurricanes, causing a worldwide shortage of sugar and a huge demand for sugar from Hawaii. Hawaiian sugarcane plantation owners began to recruit experienced, unemployed laborers in Puerto Rico. Two waves of Korean immigration to Hawaii occurred in the 20th century. The first wave arrived between 1903 and 1924; the second wave began in 1965 after President Lyndon B. Johnson signed the Immigration and Nationality Act of 1965 which removed racial and national barriers and resulted in significantly altering the demographic mix in the U.S.[87]		Oʻahu was the target of a surprise attack on Pearl Harbor by Imperial Japan on December 7, 1941. The attack on Pearl Harbor and other military and naval installations, carried out by aircraft and by midget submarines, brought the United States into World War II.		In the 1950s, the power of the plantation owners was broken by the descendants of immigrant laborers, who were born in Hawaii and were U.S. citizens. They voted against the Hawaii Republican Party, strongly supported by plantation owners. The new majority voted for the Democratic Party of Hawaii, which dominated territorial and state politics for more than 40 years. Eager to gain full representation in Congress and the Electoral College, residents actively campaigned for statehood. In Washington there was talk that Hawaii would be a Republican Party stronghold so it was matched with the admission of Alaska, seen as a Democratic Party stronghold. These predictions turned out to be inaccurate; today, Hawaii votes Democratic predominately, and Alaska votes Republican.[88][89][90][91]		In March 1959, Congress passed the Hawaii Admission Act, which U.S. President Dwight D. Eisenhower signed into law.[92] The act excluded Palmyra Atoll from statehood; it had been part of the Kingdom and Territory of Hawaii. On June 27, 1959, a referendum asked residents of Hawaii to vote on the statehood bill; 94.3% voted in favor of statehood and 5.7% opposed it.[93] The referendum asked voters to choose between accepting the Act and remaining a U.S. territory. The United Nations' Special Committee on Decolonization later removed Hawaii from its list of non-self-governing territories.		After attaining statehood, Hawaii quickly modernized through construction and a rapidly growing tourism economy. Later, state programs promoted Hawaiian culture.[which?] The Hawaii State Constitutional Convention of 1978 created institutions such as the Office of Hawaiian Affairs to promote indigenous language and culture.[citation needed]		After Europeans and mainland Americans first arrived during the Kingdom of Hawaii period, the overall population of Hawaii, until that time composed solely of indigenous Hawaiians, fell dramatically. The indigenous Hawaiian population succumbed to foreign diseases, declining from 300,000 in the 1770s, to 60,000 in the 1850s, to 24,000 in 1920. The population of Hawaii began to finally increase after an influx of primarily Asian settlers that arrived as migrant laborers at the end of the 19th century.[94]		The unmixed indigenous Hawaiian population has still not restored itself to its 300,000 pre-contact level. As of 2010, only 156,000 persons declared themselves to be of Native Hawaiian only ancestry, just over half of the pre-contact level Native Hawaiian population, although an additional 371,000 persons declared themselves to possess Native Hawaiian ancestry in combination with one or more other races (including other Polynesian groups, but mostly Asian and/or Caucasian).		The United States Census Bureau estimates the population of Hawaii was 1,431,603 on July 1, 2015; an increase of 5.2% since the 2010 United States Census.[95]		As of 2014[update], Hawaii had an estimated population of 1,431,603; an increase of 12,042 from the previous year and an increase of 71,302 (5.2%) since 2010. This includes a natural increase of 48,111 (96,028 births minus 47,917 deaths) and an increase due to net migration of 16,956 people into the state. Immigration from outside the United States resulted in a net increase of 30,068; migration within the country produced a net loss of 13,112 people.		The center of population of Hawaii is located between the two islands of O'ahu and Moloka'i. Large numbers of Native Hawaiians have moved to Las Vegas, which has been called the "ninth island" of Hawaii.[96][97]		Hawaii has a de facto population of over 1.4 million, due in part to a large number of military personnel and tourist residents. O'ahu is the most populous island; it has the highest population density with a resident population of just under one million in 597 square miles (1,546 km2), approximately 1,650 people per square mile.[c][citation needed] Hawaii's 1.4 million residents, spread across 6,000 square miles (15,500 km2) of land, result in an average population density of 188.6 persons per square mile.[98] The state has a lower population density than Ohio and Illinois.[99]		The average projected lifespan of people born in Hawaii in 2000 is 79.8 years; 77.1 years if male, 82.5 if female—longer than the average lifespan of any other U.S. state.[100] As of 2011[update] the U.S. military reported it had 42,371 personnel on the islands.[101]		According to the 2010 United States Census, Hawaii had a population of 1,360,301. The state's population identified as 38.6% Asian; 24.7% White (22.7% Non-Hispanic White Alone); 23.6% from two or more races; 10.0% Native Hawaiians and other Pacific Islanders; 8.9% Hispanics and Latinos of any race; 1.6% Black or African American; 1.2% from some other race; and 0.3% Native American and Alaska Native.[104]		Hawaii has the highest percentage of Asian Americans and multiracial Americans and the lowest percentage of White Americans of any state. It is the only state where Asian Americans identify as the largest ethnic group. In 2011, 14.5% of births were to white, non-Hispanic parents.[109] Hawaii's Asian population consists mainly of 198,000 (14.6%) Filipino Americans, 185,000 (13.6%) Japanese Americans, roughly 55,000 (4.0%) Chinese Americans, and 24,000 (1.8%) Korean Americans.[citation needed] There are over 80,000 Indigenous Hawaiians—5.9% of the population.[110] Including those with partial ancestry, Samoan Americans constitute 2.8% of Hawaii's population, and Tongan Americans constitute 0.6%.[111]		Over 120,000 (8.8%) of Hispanic and Latino Americans live in Hawaii. Mexican Americans number over 35,000 (2.6%); Puerto Ricans exceed 44,000 (3.2%). Multiracial Americans constitute almost 25% of Hawaii's population, exceeding 320,000 people. Eurasian Americans are a prominent mixed-race group, numbering about 66,000 (4.9%). The Non-Hispanic White population numbers around 310,000—just over 20% of the population. The multi-racial population outnumbers the non-Hispanic white population by about 10,000 people.[110] In 1970, the Census Bureau reported Hawaii's population was 38.8% white and 57.7% Asian and Pacific Islander.[112]		The five largest European ancestries in Hawaii are German (7.4%), Irish (5.2%), English (4.6%), Portuguese (4.3%) and Italian (2.7%). About 82.2% of the state's residents were born in the United States. Roughly 75% of foreign-born residents originate in Asia. Hawaii is a majority-minority state. It was expected to be one of three states that will not have a non-Hispanic white plurality in 2014; the other two are California and New Mexico.[113]		The third group of foreigners to arrive in Hawaii were from China. Chinese workers on Western trading ships settled in Hawaii starting in 1789. In 1820, the first American missionaries arrived to preach Christianity and teach the Hawaiians Western ways.[115] As of 2015[update], a large proportion of Hawaii's population have Asian ancestry—especially Filipino, Japanese and Chinese. Many are descendants of immigrants brought to work on the sugarcane plantations in the mid-to-late 19th century. The first 153 Japanese immigrants arrived in Hawaii on June 19, 1868. They were not approved by the then-current Japanese government because the contract was between a broker and the Tokugawa shogunate—by then replaced by the Meiji Restoration. The first Japanese current-government-approved immigrants arrived on February 9, 1885, after Kalākaua's petition to Emperor Meiji when Kalākaua visited Japan in 1881.[116][117]		Almost 13,000 Portuguese migrants had arrived by 1899; they also worked on the sugarcane plantations.[118] By 1901, over 5,000 Puerto Ricans were living in Hawaii.[119]		English (General American) and Hawaiian are listed as Hawaii's "official languages" in the state's 1978 constitution. Article XV, Section 4 specifies that "Hawaiian shall be required for public acts and transactions only as provided by law". Hawaiʻi Creole English, locally referred to as "Pidgin", is the native language of many native residents and is a second language for many others.[citation needed]		As of the 2000 Census, 73.4% of Hawaii residents aged five and older exclusively speak English at home.[120] According to the 2008 American Community Survey, 74.6% of Hawaii's residents over the age of five speak only English at home.[114] In their homes, 21.0% of state residents speak an additional Asian language, 2.6% speak Spanish, 1.6% speak other Indo-European languages and 0.2% speak another language.[114]		After English, other languages popularly spoken in the state are Tagalog, Japanese and Ilokano. Significant numbers of European immigrants and their descendants also speak their native languages; the most numerous are German, Portuguese, Italian and French.[citation needed] 5.4% of residents speak Tagalog—which includes non-native speakers of Filipino language, the national, co-official, Tagalog-based language; 5.0% speak Japanese and 4.0% speak Ilokano; 1.2% speak Chinese, 1.7% speak Hawaiian; 1.7% speak Spanish; 1.6% speak Korean; and 1.0% speak Samoan.[120]		The keyboard layout used for Hawaiian is QWERTY.[121]		The Hawaiian language has about 2,000 native speakers, about 0.15% of the total population.[122] According to the United States Census, there were over 24,000 total speakers of the language in Hawaii in 2006–2008.[123] Hawaiian is a Polynesian member of the Austronesian language family.[122] It is closely related to other Polynesian languages, such as Marquesan, Tahitian, Māori, Rapa Nui (the language of Easter Island), and less closely to Samoan and Tongan.[citation needed]		According to Schütz, the Marquesans colonized the archipelago in roughly 300 CE[124] and were later followed by waves of seafarers from the Society Islands, Samoa and Tonga.[citation needed]		These Polynesians remained in the islands; they eventually became the Hawaiian people and their languages evolved into the Hawaiian language.[125] Kimura and Wilson say, "[l]inguists agree that Hawaiian is closely related to Eastern Polynesian, with a particularly strong link in the Southern Marquesas, and a secondary link in Tahiti, which may be explained by voyaging between the Hawaiian and Society Islands".[126] Before the arrival of Captain James Cook, the Hawaiian language had no written form. That form was developed mainly by American Protestant missionaries between 1820 and 1826. They assigned to the Hawaiian phonemes letters from the Latin alphabet.[citation needed]		Interest in Hawaiian increased significantly in the late 20th century. With the help of the Office of Hawaiian Affairs, specially designated immersion schools in which all subjects would be taught in Hawaiian were established. The University of Hawaii developed a Hawaiian language graduate studies program. Municipal codes were altered to favor Hawaiian place and street names for new civic developments.[citation needed] Hawai'i Sign Language, a sign language for the deaf based on the Hawaiian language, has been in use in the islands since the early 1800s. It is dwindling in numbers due to American Sign Language supplanting HSL through schooling and various other domains.[citation needed]		Hawaiian distinguishes between long and short vowel sounds. In modern practice, vowel length is indicated with a macron (kahakō). Hawaiian-language newspapers (nūpepa) published from 1834 to 1948 and traditional native speakers of Hawaiian generally omit the marks in their own writing. The ʻokina and kahakō are intended to help non-native speakers.[citation needed] The Hawaiian language uses the glottal stop (ʻokina) as a consonant. It is written as a symbol similar to the apostrophe or left-hanging (opening) single quotation mark.[citation needed]		Some residents of Hawaii speak Hawaiʻi Creole English (HCE), endonymically called pidgin or pidgin English. The lexicon of HCE derives mainly from English but also uses words that have derived from Hawaiian, Chinese, Japanese, Portuguese, Ilocano and Tagalog. During the 19th century, the increase in immigration—mainly from China, Japan, Portugal—especially from the Azores and Madeira, and Spain—catalyzed the development of a hybrid variant of English known to its speakers as pidgin. By the early 20th century, pidgin speakers had children who acquired it as their first language. HCE speakers use some Hawaiian words without those words being considered archaic.[clarification needed] Most place names are retained from Hawaiian, as are some names for plants and animals. For example, tuna fish is often called by its Hawaiian name, ahi.[citation needed]		HCE speakers have modified the meanings of some English words. For example, "aunty" and "uncle" may either refer to any adult who is a friend or be used to show respect to an elder. Syntax and grammar follow distinctive rules different from those of General American English. For example, instead of "it is hot today, isn't it?", an HCE speaker would say simply "stay hot, eh?"[d] The term da kine is used as a filler; a substitute for virtually any word or phrase. During the surfing boom in Hawaii, HCE was influenced by surfer slang. Some HCE expressions, such as brah and da kine, have found their ways elsewhere through surfing communities.[citation needed]		Christianity is the most widespread religion in Hawaii. It is mainly represented by various Protestants, Catholics and Mormons. Buddhism is the second most popular religion, especially among the archipelago's Japanese community. Unaffilliated account for one-quarter of the population.		The largest denominations by number of adherents were the Catholic Church with 249,619 adherents in 2010[127] and the Church of Jesus Christ of Latter-day Saints with 68,128 adherents in 2009.[128] The third-largest religious group includes all non-denominational churches, with 128 congregations and 32,000 members. The third-largest denominational group is the United Church of Christ, with 115 congregations and 20,000 members. The Southern Baptist Convention has 108 congregations and 18,000 members in Hawaii.[129]		According to data provided by religious establishments, religion in Hawaii in 2000 was distributed as follows:[130][131]		A Pew poll found that the religious composition was as follows:		Note: Births in table don't add up, because Hispanics are counted both by their ethnicity and by their race, giving a higher overall number.		Hawaii has had a long history of queer identities. Māhū people, who often traversed gender as defined by Western standards, were a respected group of pre-colonization people who were widely known in society as healers. Another Hawaiian word, aikāne, referred to same-sex relationships. According to journals written by Captain Cook's crew, it is widely believed that many aliʻi engaged in aikāne relationships. Hawaiian scholar Lilikalā Kameʻeleihiwa said, "If you didn't sleep with a man, how could you trust him when you went into battle? How would you know if he was going to be the warrior that would protect you at all costs, if he wasn't your lover?"[136]		A 2012 poll by Gallup found that Hawaii had the largest proportion of lesbian, gay, bisexual and transgender (LGBT) adults in the U.S., at 5.1%, comprising an estimated adult LGBT population of 53,966 individuals. The number of same-sex couple households in 2010 was 3,239; a 35.5% increase of figures from a decade earlier.[137][138] In 2013, Hawaii became the fifteenth U.S. state to legalize same-sex marriage; a University of Hawaii researcher said the law may boost tourism by $217 million.[139]		The history of Hawaii's economy can be traced through a succession of dominant industries; sandalwood,[140] whaling,[141] sugarcane, pineapple, the military, tourism and education. Since statehood in 1959, tourism has been the largest industry, contributing 24.3% of the gross state product (GSP) in 1997, despite efforts to diversify. The state's gross output for 2003 was US$47 billion; per capita income for Hawaii residents in 2014 was US$54,516.[142] Hawaiian exports include food and clothing. These industries play a small role in the Hawaiian economy, due to the shipping distance to viable markets, such as the West Coast of the contiguous U.S. The state's food exports include coffee, macadamia nuts, pineapple, livestock, sugarcane and honey.[143]		By weight, honey bees may be the state's most valuable export.[144] According to the Hawaii Agricultural Statistics Service, agricultural sales were US$370.9 million from diversified agriculture, US$100.6 million from pineapple, and US$64.3 million from sugarcane. Hawaii's relatively consistent climate has attracted the seed industry, which is able to test three generations of crops per year on the islands, compared with one or two on the mainland.[145] Seeds yielded US$264 million in 2012, supporting 1,400 workers.[146]		As of December 2015, the state's unemployment rate was 3.2%.[147] In 2009, the United States military spent US$12.2 billion in Hawaii, accounting for 18% of spending in the state for that year. 75,000 United States Department of Defense personnel live in Hawaii.[148] According to a 2013 study by Phoenix Marketing International, Hawaii had the fourth-largest number of millionaires per capita in the United States, with a ratio of 7.2%.[149]		Hawaii residents pay the most per person in state taxes in the United States.[150] Millions of tourists pay general excise tax and hotel room tax.[150]		The Hawaii Tax Foundation considers the state's tax burden too high, which it says contributes to higher prices and the perception of an unfriendly business climate.[150]		State Senator Sam Slom says state taxes are comparatively higher than other states because the state government handles education, health care, and social services that are usually handled at a county or municipal level in most other states.[150]		The cost of living in Hawaii, specifically Honolulu, is high compared to that of most major U.S. cities. However, the cost of living in Honolulu is 6.7% lower than in New York City and 3.6% lower than in San Francisco.[151] These numbers may not take into account some costs, such as increased travel costs for flights, additional shipping fees, and the loss of promotional participation opportunities for customers outside the contiguous U.S. While some online stores offer free shipping on orders to Hawaii,[152] many merchants exclude Hawaii, Alaska, Puerto Rico and certain other U.S. territories.[citation needed]		Hawaiian Electric Industries, a privately owned company, provides 95% of the state's population with electricity, mostly from fossil-fuel power stations. Average electricity prices in October 2014 (36.41 cents per kilowatt-hour) were nearly three times the national average (12.58 cents per kilowatt-hour) and 80% higher than the second-highest state, Connecticut.[153]		The median home value in Hawaii in the 2000 U.S. Census was US$272,700, while the national median home value was US$119,600. Hawaii home values were the highest of all states, including California with a median home value of US$211,500.[154] Research from the National Association of Realtors places the 2010 median sale price of a single family home in Honolulu, Hawaii, at US$607,600 and the U.S. median sales price at US$173,200. The sale price of single family homes in Hawaii was the highest of any U.S. city in 2010, just above that of the Silicon Valley area of California (US$602,000).[155]		Hawaii's very high cost of living is the result of several interwoven factors of the global economy in addition to domestic U.S. government trade policy. Like other regions with desirable weather throughout the year, such as areas of California, Arizona and Florida, Hawaii's residents can be considered to be subject to a "Sunshine tax". This situation is further exacerbated by the natural factors of geography and world distribution that lead to higher prices for goods due to increased shipping costs, a problem which many island states and territories suffer from as well. The situation is compounded even further by what could possibly be the single largest contributor to the high costs of living in Hawaii, a U.S. trade law known as the Jones Act, or the Merchant Marine Act of 1920. This trade regulation prohibits any foreign-flagged ships from carrying cargo between two American ports—a practice known as cabotage. Most consumer goods in the United States are manufactured by outsourced labor in East Asia, then transported by container ships to ports on the U.S. mainland, and Hawaii also receives the same goods. Being located in the central Pacific Ocean, right between major Pacific shipping lanes, it would be very economical to unload Hawaiian-bound goods in Honolulu, before continuing on to the mainland. However, this would effectively make the second leg of the voyage between Hawaii and the mainland a domestic route between two American ports. Because most large cargo ships operate under foreign "flags of convenience" such as Liberia, Vanuatu or Papua New Guinea, allowing them to avoid the more stringent, and thus more costly, regulations of developed nations' ports, the domestic leg of the voyage would be disallowed by the Jones Act. Instead, those cargo ships must proceed directly to the West Coast, where distributors break bulk and transport the Hawaiian-bound, Asian-manufactured goods back across the ocean by U.S.-flagged ships and increasing the length of the voyage by more than 50%. This highly inefficient system of shipping Hawaii's consumer cargo comes at a very hefty price for the average Hawaiian citizen, and makes the cost of living in Hawaii much, much higher than it would otherwise be.[156][157]		Hawaiian consumers ultimately bear the expense of transporting goods imposed by the Jones Act. This law makes Hawaii less competitive than West Coast ports as a shopping destination for tourists from countries with much higher taxes like Japan, even though prices for Asian-manufactured goods should be cheaper because Hawaii is much closer than mainland states to Asia.[158][159]		The aboriginal culture of Hawaii is Polynesian. Hawaii represents the northernmost extension of the vast Polynesian Triangle of the south and central Pacific Ocean. While traditional Hawaiian culture remains as vestiges in modern Hawaiian society, there are re-enactments of the ceremonies and traditions throughout the islands. Some of these cultural influences, including the popularity (in greatly modified form) of lūʻau and hula, are strong enough to affect the wider United States.		The cuisine of Hawaii is a fusion of many foods brought by immigrants to the Hawaiian Islands, including the earliest Polynesians and Native Hawaiian cuisine, and American, Chinese, Filipino, Japanese, Korean, Polynesian and Portuguese origins. Plant and animal food sources are imported from around the world for agricultural use in Hawaii. Poi, a starch made by pounding taro, is one of the traditional foods of the islands. Many local restaurants serve the ubiquitous plate lunch, which features two scoops of rice, a simplified version of American macaroni salad and a variety of toppings including hamburger patties, a fried egg, and gravy of a loco moco, Japanese style tonkatsu or the traditional lūʻau favorites, including kālua pork and laulau. Spam musubi is an example of the fusion of ethnic cuisine that developed on the islands among the mix of immigrant groups and military personnel. In the 1990s, a group of chefs developed Hawaii regional cuisine as a contemporary fusion cuisine.		Some key customs and etiquette in Hawaii are as follows: when visiting a home, it is considered good manners to bring a small gift for one's host (for example, a dessert). Thus, parties are usually in the form of potlucks. Most locals take their shoes off before entering a home. It is customary for Hawaiian families, regardless of ethnicity, to hold a luau to celebrate a child's first birthday. It is also customary at Hawaiian weddings, especially at Filipino weddings, for the bride and groom to do a money dance (also called the pandanggo). Print media and local residents recommend that one refer to non-Hawaiians as "locals of Hawaii" or "people of Hawaii".		Hawaiian mythology comprises the legends, historical tales, and sayings of the ancient Hawaiian people. It is considered a variant of a more general Polynesian mythology that developed a unique character for several centuries before circa 1800. It is associated with the Hawaiian religion, which was officially suppressed in the 19th century but was kept alive by some practitioners to the modern day.[citation needed] Prominent figures and terms include Aumakua, the spirit of an ancestor or family god and Kāne, the highest of the four major Hawaiian deities.[citation needed]		Polynesian mythology is the oral traditions of the people of Polynesia, a grouping of Central and South Pacific Ocean island archipelagos in the Polynesian triangle together with the scattered cultures known as the Polynesian outliers. Polynesians speak languages that descend from a language reconstructed as Proto-Polynesian that was probably spoken in the area around Tonga and Samoa in around 1000 BCE.[citation needed]		Prior to the 15th century, Polynesian people migrated east to the Cook Islands, and from there to other island groups such as Tahiti and the Marquesas. Their descendants later discovered the islands Tahiti, Rapa Nui and later the Hawaiian Islands and New Zealand.[citation needed]		The Polynesian languages are part of the Austronesian language family. Many are close enough in terms of vocabulary and grammar to be mutually intelligible. There are also substantial cultural similarities between the various groups, especially in terms of social organization, childrearing, horticulture, building and textile technologies. Their mythologies in particular demonstrate local reworkings of commonly shared tales. The Polynesian cultures each have distinct but related oral traditions; legends or myths are traditionally considered to recount ancient history (the time of "pō") and the adventures of gods ("atua") and deified ancestors.[citation needed]		There are many Hawaiian state parks.		The literature of Hawaii is diverse and includes authors Kiana Davenport, Lois-Ann Yamanaka, and Kaui Hart Hemmings. Hawaiian magazines include Hana Hou!, Hawaii Business Magazine and Honolulu, among others.		The music of Hawaii includes traditional and popular styles, ranging from native Hawaiian folk music to modern rock and hip hop. Hawaii's musical contributions to the music of the United States are out of proportion to the state's small size. Styles such as slack-key guitar are well-known worldwide, while Hawaiian-tinged music is a frequent part of Hollywood soundtracks. Hawaii also made a major contribution to country music with the introduction of the steel guitar.[160]		Traditional Hawaiian folk music is a major part of the state's musical heritage. The Hawaiian people have inhabited the islands for centuries and have retained much of their traditional musical knowledge. Their music is largely religious in nature, and includes chanting and dance music. Hawaiian music has had an enormous impact on the music of other Polynesian islands; according to Peter Manuel, the influence of Hawaiian music a "unifying factor in the development of modern Pacific musics".[161] Native Hawaiian musician and Hawaiian sovereignty activist Israel Kamakawiwoʻole, famous for his medley of "Somewhere Over the Rainbow/What a Wonderful World", was named "The Voice of Hawaii" by NPR in 2010 in its 50 great voices series.[162]		Tourism is an important part of the Hawaiian economy. In 2003, according to state government data, there were over 6.4 million visitors, with expenditures of over $10 billion, to the Hawaiian Islands.[163] Due to the mild year-round weather, tourist travel is popular throughout the year. The major holidays are the most popular times for outsiders to visit, especially in the winter months. Substantial numbers of Japanese tourists still visit the islands but have now been surpassed by Chinese and Koreans due to the collapse of the value of the Yen and the weak Japanese economy. The average Japanese stays only 5 days while other Asians spend over 9.5 days and spend 25% more.[164][citation needed]		Hawaii hosts numerous cultural events. The annual Merrie Monarch Festival is an international Hula competition.[165] The Hawaii International Film Festival is the premier film festival for Pacific rim cinema.[166] Honolulu hosts the state's long-running LGBT film festival, the Rainbow Film Festival.[167][168]		As of 2009[update], Hawaii's health care system insures 92% of residents. Under the state's plan, businesses are required to provide insurance to employees who work more than twenty hours per week. Heavy regulation of insurance companies helps reduce the cost to employers. Due in part to heavy emphasis on preventive care, Hawaiians require hospital treatment less frequently than the rest of the United States, while total health care expenses measured as a percentage of state GDP are substantially lower.[citation needed] Proponents of universal health care elsewhere in the U.S. sometimes use Hawaii as a model for proposed federal and state health care plans.[citation needed]		Hawaii has the only school system within the U.S. that is unified statewide. Policy decisions are made by the fourteen-member state Board of Education, which sets policy and hires the superintendent of schools, who oversees the state Department of Education. The Department of Education is divided into seven districts; four on Oʻahu and one for each of the other three counties. The main rationale for centralization is to combat inequalities between highly populated Oʻahu and the more rural Neighbor Islands, and between lower-income and more affluent areas.[citation needed]		Public elementary, middle and high school test scores in Hawaii are below national averages on tests mandated under the No Child Left Behind Act. The Hawaii Board of Education requires all eligible students to take these tests and report all student test scores. This may have unbalanced the results that reported in August 2005 that of 282 schools across the state, 185 failed to reach federal minimum performance standards in mathematics and reading.[169] The ACT college placement tests show that in 2005, seniors scored slightly above the national average (21.9 compared with 20.9),[170] but in the widely accepted SAT examinations, Hawaii's college-bound seniors tend to score below the national average in all categories except mathematics.		Hawaii has the highest rates of private school attendance in the nation.[11] During the 2011–2012 school year, Hawaii public and charter schools had an enrollment of 181,213,[171] while private schools had 37,695.[172] Private schools educated over 17% of students in Hawaii that school year, nearly three times the approximate national average of 6%.[173] It has four of the largest independent schools; ʻIolani School, Kamehameha Schools, Mid-Pacific Institute and Punahou School. Pacific Buddhist Academy, the second Buddhist high school in the U.S. and first such school in Hawaii, was founded in 2003. The first native controlled public charter school was the Kanu O Ka Aina New Century Charter School.[citation needed]		Independent and charter schools can select their students, while the public schools are open to all students in their district. The Kamehameha Schools are the only schools in the U.S. that openly grant admission to students based on ancestry; collectively, they are one of the wealthiest schools in the United States, if not the world, having over eleven billion US dollars in estate assets.[174] In 2005, Kamehameha enrolled 5,398 students, 8.4% of the Native Hawaiian children in the state.[175]		Graduates of secondary schools in Hawaii often enter directly into the workforce. Some attend colleges and universities on the mainland or other countries, and the rest attend an institution of higher learning in Hawaii. The largest is the University of Hawaii System, which consists of: the research university at Mānoa, two comprehensive campuses at Hilo and West Oʻahu, and seven community colleges. Private universities include Brigham Young University–Hawaii, Chaminade University of Honolulu, Hawaii Pacific University, and Wayland Baptist University. Saint Stephen Diocesan Center is a seminary of the Roman Catholic Diocese of Honolulu. Kona hosts the University of the Nations, which is not an accredited university.		First opened in 1984 illegally in Kekaha, Kaua'i, the Pūnana Leo or "Language Nest" (lit. "Nest of Voices") were the first indigenous language immersion schools in the United States. Modelled after the Māori language Kōhanga reo of New Zealand, they provide preschool aged children the opportunity to engage in early education through a Hawaiian language medium, generally taught by elders. Graduates from the Pūnana Leo schools have achieved several measures of academic success in later life. As of 2006, there were a total of eleven Pūnana Leo preschools, with locations on five of the islands.		A system of state highways encircles each main island. Only Oʻahu has federal highways, and is the only area outside the contiguous 48 states to have signed Interstate highways. Narrow, winding roads and congestion in populated places can slow traffic. Each major island has a public bus system.		Honolulu International Airport (IATA: HNL), which shares runways with the adjacent Hickam Field (IATA: HIK), is the major commercial aviation hub of Hawaii. The commercial aviation airport offers intercontinental service to North America, Asia, Australia and Oceania. Hawaiian Airlines, Mokulele Airlines and go! use jets to provide services between the large airports in Honolulu, Līhuʻe, Kahului, Kona and Hilo. Island Air and Pacific Wings serve smaller airports. These airlines also provide air freight services between the islands. On May 30, 2017, the airport was officially renamed as the Daniel K. Inouye International Airport (HNL), after U.S. Senator Daniel K. Inouye.[176]		Until air passenger services began in the 1920s,[177] private boats were the sole means of traveling between the islands. Seaflite operated hydrofoils between the major islands in the mid-1970s.[178]		The Hawaii Superferry operated between Oʻahu and Maui between December 2007 and March 2009, with additional routes planned for other islands. Protests and legal problems over environmental impact statements ended the service, though the company operating Superferry has expressed a wish to recommence ferry services in the future.[179] Currently there are passenger ferry services in Maui County between Molokaʻi and Maui,[180] and between Lanaʻi and Maui,[181] though neither of these take vehicles. Currently Norwegian Cruise Lines and Princess Cruises provide passenger cruise ship services between the larger islands.[182][183]		At one time Hawaii had a network of railroads on each of the larger islands that transported farm commodities and passengers. Most were 3 ft (914 mm) narrow gauge systems but there were some 2 ft 6 in (762 mm) gauge on some of the smaller islands. The standard gauge in the U.S. is 4 ft 8 1⁄2 in (1,435 mm). By far the largest railroad was the Oahu Railway and Land Company (OR&L) that ran lines from Honolulu across the western and northern part of Oahu.[184]		The OR&L was important for moving troops and goods during World War II. Traffic on this line was busy enough for signals to be used to facilitate movement of trains and to require wigwag signals at some railroad crossings for the protection of motorists. The main line was officially abandoned in 1947, although part of it was bought by the U.S. Navy and operated until 1970. Thirteen miles (21 km) of track remain; preservationists occasionally run trains over a portion of this line.[184] The Honolulu High-Capacity Transit Corridor Project aims to add elevated passenger rail on Oahu to relieve highway congestion.[11]		The movement of the Hawaiian royal family from Hawaiʻi Island to Maui, and subsequently to Oʻahu, explains the modern-day distribution of population centers. Kamehameha III chose the largest city, Honolulu, as his capital because of its natural harbor—the present-day Honolulu Harbor. Now the state capital, Honolulu is located along the southeast coast of Oʻahu. The previous capital was Lahaina, Maui, and before that Kailua-Kona, Hawaiʻi. Some major towns are Hilo; Kāneʻohe; Kailua; Pearl City; Waipahu; Kahului; Kailua-Kona. Kīhei; and Līhuʻe.		Hawaii comprises five counties: the City and County of Honolulu, Hawaii County, Maui County, Kauai County, and Kalawao County.		Hawaii has the fewest local governments among U.S. states.[185][186] Unique to this state is the lack of municipal governments. All local governments are generally administered at the county level. The only incorporated area in the state is Honolulu County, a consolidated city–county that governs the entire island of Oahu. County executives are referred to as mayors; these are the Mayor of Hawaii County, Mayor of Honolulu, Mayor of Kauaʻi, and the Mayor of Maui. The mayors are all elected in nonpartisan elections. Kalawao County has no elected government,[187] and as mentioned above there are no local school districts and instead all local public education is administered at the state level by the Hawaii Department of Education. The remaining local governments are special districts.[185][186]		The state government of Hawaii is modeled after the federal government with adaptations originating from the kingdom era of Hawaiian history. As codified in the Constitution of Hawaii, there are three branches of government: executive, legislative and judicial. The executive branch is led by the Governor of Hawaii, who is assisted by the Lieutenant Governor of Hawaii, both of whom are elected on the same ticket. The governor is the only state public official elected statewide; all others are appointed by the governor. The lieutenant governor acts as the Secretary of State. The governor and lieutenant governor oversee twenty agencies and departments from offices in the State Capitol. The official residence of the governor is Washington Place.		The legislative branch consists of the bicameral Hawaii State Legislature, which is composed of the 51-member Hawaii House of Representatives led by the Speaker of the House, and the 25-member Hawaii Senate led by the President of the Senate. The Legislature meets at the State Capitol. The unified judicial branch of Hawaii is the Hawaii State Judiciary. The state's highest court is the Supreme Court of Hawaii, which uses Aliʻiōlani Hale as its chambers.		Hawaii is represented in the United States Congress by two senators and two representatives. As of 2016[update], all four seats are held by Democrats. Colleen Hanabusa won a special election for the 1st congressional district representing southeastern Oahu, including central Honolulu, on November 8, 2016 to finish the term of Rep. Mark Takai who died July 20, 2016. Tulsi Gabbard represents the 2nd congressional district, representing the rest of the state, which is largely rural and semi-rural.[188]		Brian Schatz is the senior United States Senator from Hawaii. He was appointed to the office on December 26, 2012, by Governor Neil Abercrombie, following the death of former senator Daniel Inouye. The state's junior senator is Mazie Hirono, the former representative from the second congressional district. Hirono is the first female Asian American senator and the first Buddhist senator. Hawaii incurred the biggest seniority shift between the 112th and 113th Congresses. The state went from a delegation consisting of senators who were first and twenty-first in seniority[e] to their respective replacements, relative newcomers Schatz and Hirono.[189]		Federal officials in Hawaii are based at the Prince Kūhiō Federal Building near the Aloha Tower and Honolulu Harbor. The Federal Bureau of Investigation, Internal Revenue Service and the Secret Service maintain their offices there; the building is also the site of the federal District Court for the District of Hawaii and the United States Attorney for the District of Hawaii.		Since gaining statehood and participating in its first election in 1960, Hawaii has supported Democrats in all but two presidential elections; 1972 and 1984, both of which were landslide victories for Republicans Richard Nixon and Ronald Reagan respectively. In Hawaii's statehood tenure, only Minnesota has supported Republican candidates fewer times in presidential elections.		Hawaii hasn't elected a Republican to represent the state in the U.S. Senate since Hiram Fong in 1970; since 1977, both of the state's U.S. Senators have been Democrats.[191][192]		In 2004, John Kerry won the state's four electoral votes by a margin of nine percentage points with 54% of the vote. Every county supported the Democratic candidate. In 1964, favorite son candidate senator Hiram Fong of Hawaii sought the Republican presidential nomination, while Patsy Mink ran in the Oregon primary in 1972.		Honolulu-born Barack Obama, then serving as United States Senator from Illinois, was elected the 44th President of the United States on November 4, 2008 and was re-elected for a second term on November 6, 2012. Obama had won the Hawaii Democratic caucus on February 19, 2008, with 76% of the vote. He was the third Hawaii-born candidate to seek the nomination of a major party and the first presidential nominee from Hawaii.[193][194]		While Hawaii is internationally recognized as a state of the United States while also being broadly accepted as such in mainstream understanding, the legality of this status has been raised in U.S. District Court,[195] the U.N., and other international forums.[196] Domestically, the debate is a topic covered in the Kamehameha Schools curriculum.[197] On September 29, 2015 the Department of the Interior announced a procedure to recognize a Native Hawaiian government.[198][199]		Political organizations seeking some form of sovereignty for Hawaii have been active since the 1880s. Generally, their focus is on self-determination and self-governance, either for Hawaii as a new relationship akin to tribal sovereignty with US federal recognition of Native Hawaiians. A 2005 Grassroot Institute poll found the large majority of Hawaiian residents opposed the Akaka Bill.[200]		The Hawaiian sovereignty movement, which generally views the overthrow of Kingdom of Hawaii in 1893 and its subsequent annexation by the United States as illegal, seeks some form of greater autonomy for Hawaii, such as free association or independence from the United States.[201][202][203][204]		Some groups also advocate some form of redress from the United States for the 1893 overthrow of Queen Liliʻuokalani, and for what is described as a prolonged military occupation beginning with the 1898 annexation. The movement generally views both the overthrow and annexation as illegal, with the Apology Resolution passed by US Congress in 1993 cited as a major impetus by the movement for Hawaiian sovereignty.[201]		
In physical geography, a channel is a type of landform consisting of the outline of a path of relatively shallow and narrow body of fluid, most commonly the confine of a river, river delta or strait. The word is cognate to canal, and sometimes shows in this form, e.g. the Hood Canal. Most examples of this are fjords in the Pacific Northwest; a notable exception is the Casiquiare canal. All likely share borrowing from Spanish, Portuguese or French.		Channels can be either natural or human-made. A channel is typically outlined in terms of its bed and banks.						Channel initiation refers to the site on a mountain slope where water begins to flow between identifiable banks.[1] This site is referred to as the channel head and it marks an important boundary between hillslope processes and fluvial processes.[1] The channel head is the most upslope part of a channel network and is defined by flowing water between defined identifiable banks.[1] A channel head forms as overland flow and/or subsurface flow accumulate to a point where shear stress can overcome erosion resistance of the ground surface.[1] Channel heads are often associated with colluvium, hollows and landslides.[1]		Overland flow is a primary factor in channel initiation where saturation overland flow deepens to increase shear stress and begin channel incision.[1] Overland flows converge in topographical depressions where channel initiation begins. Soil composition, vegetation, precipitation, and topography dictate the amount and rate of overland flow. The composition of a soil determines how quickly saturation occurs and cohesive strength retards the entrainment of material from overland flows.[1] Vegetation slows infiltration rates during precipitation events and plant roots anchor soil on hillslopes.[1]		Subsurface flow destabilizes soil and resurfaces on hillslopes where channel heads are often formed. This often results in abrupt channel heads and landslides. Hollows form due to concentrated subsurface flows where concentrations of colluvium are in a constant flux.[1]Channel heads associated with hollows in steep terrain frequently migrate up and down hillslopes depending on sediment supply and precipitation.		Natural channels are formed by fluvial process and are found across the Earth. These are mostly formed by flowing water from the hydrological cycle, though can also be formed by other fluids such as flowing lava. Channels also describe the deeper course through a reef, sand bar, bay, or any shallow body of water. One example is the Columbia River, a river located in the US states of Washington and Oregon, and which empties into the Pacific Ocean in Astoria, Oregon.		A stream channel is the physical confine of a stream (river) consisting of a bed and stream banks. Stream channels exist in a variety of geometries. Stream channel development is controlled by both water and sediment movement. There is a difference between low gradient streams (less than a couple of percent in gradient or slightly sloped) and high gradient streams (steeply sloped). A wide variety of stream channel types can be distinguished (e.g. braided rivers, wandering rivers, single-thread sinuous rivers etc.). During floods, water flow may exceed the capacity of the channel and flood waters will spill out of the channel and across the valley bottom, floodplain or drainage area.		The channel form is described in terms of geometry (plan, cross-sections, profile) enclosed by the materials of its bed and banks. This form is under influence of two major forces: water discharge and sediment supply. For erodible channels the mutual dependence of its parameters may be qualitatively described by the Lane's Principle (also known as the Lane's relationship):[2] the product of the sediment load and bed grain size is proportional to the product of discharge and channel slope.[3]		It is especially used as a nautical term to mean the dredged and marked lane of safe travel which a cognizant governmental entity guarantees to have a minimum depth across its specified minimum width to all vessels transiting a body of water (see Buoy). The term not only includes the deep-dredged ship-navigable parts of an estuary or river leading to port facilities, but also to lesser channels accessing boat port-facilities such as marinas. When dredged channels traverse bay mud or sandy bottoms, repeated dredging is often necessary because of the unstable subsequent movement of benthic soils.[4]		Responsibility for monitoring navigability conditions of navigation channels to various port facilities varies, and the actual maintenance work is frequently performed by a third party. Storms, sea-states, flooding, and seasonal sedimentation adversely affect navigability. In the U.S., navigation channels are monitored and maintained by the United States Army Corps of Engineers (USACE), although dredging operations are often carried out by private contractors (under USACE supervision). USACE also monitors water quality and some remediation. This was first established under the Rivers and Harbors Act of 1899 and modified under acts of 1913, 1935, and 1938. For example, the USACE developed the Intracoastal Waterway, and has the Mississippi Valley Division responsible for the Mississippi River from the Gulf to Cairo, Illinois, the North Atlantic Division for New York Harbor and Port of Boston, and the South Pacific Division for Port of Los Angeles and Port of Long Beach. Waterways policing as well as some emergency spill response falls under United States Coast Guard jurisdiction, including inland channels serving ports like Saint Louis hundreds of miles from any coast. The various state or local governments maintain lesser channels, for example former Erie Canal.		In a larger nautical context, as a geographical place name, the term channel is another word for strait, which is defined as a relatively narrow body of water that connects two larger bodies of water. In this nautical context, the terms strait, channel, sound, and passage are synonymous and usually interchangeable. For example, in an archipelago, the water between islands is typically called a channel or passage. The English Channel is the strait between England and France.		Extraterrestrial natural channels are found elsewhere in the Solar System than the Earth and the longest and widest of which are the outflow channels on Mars and the channels of Venus many of which are tens of kilometres wide (the network of channels flowing from Argyre Planitia on Mars for example is 8000 km in length and the Baltis Vallis Venus is 7000 km compared to the 6,650 km Nile, the largest active channel on Earth). The exact formation of these large ancient channels is unknown although it is theorised that those on Mars may have been formed due to catastrophic flooding and on Venus by lava flow. In planetary science the term "rille" is sometimes used for similar formations found on The Moon and Mercury that are of inconclusive origin. Channels have also been recently discovered on Titan. The Saturnian moon has the only known permanently active channels in the Solar System other than Earth, the largest known of which is 400 km in length.[5] These are believed to be formed from flowing hydrocarbons in the hypothesized methanological cycle.[6]		
The Isle of Wight /ˈaɪl əv ˈwaɪt/ is a county and the largest and second-most populous island in England. It is in the English Channel, about 4 miles (6 km) off the coast of Hampshire, separated by the Solent. The island has resorts that have been holiday destinations since Victorian times, and is known for its mild climate, coastal scenery, and verdant landscape of fields, downland and chines.		The island has been home to the poets Swinburne and Tennyson and to Queen Victoria, who built her much-loved summer residence and final home Osborne House at East Cowes. It has a maritime and industrial tradition including boat building, sail making, the manufacture of flying boats, the hovercraft, and Britain's space rockets. The island hosts annual music festivals including the Isle of Wight Festival, which, in 1970, was the largest rock music event ever held.[4] It has well-conserved wildlife and some of the richest cliffs and quarries for dinosaur fossils in Europe.		The Isle was owned by a Norman family until 1293[5] and was earlier a kingdom in its own right. The island has played an important part in the defence of the ports of Southampton and Portsmouth, and been near the front-line of conflicts through the ages, including the Spanish Armada and the Battle of Britain. Rural for most of its history, its Victorian fashionability and the growing affordability of holidays led to significant urban development during the late 19th and early 20th centuries. The island was part of Hampshire until 1890 when it became its own administrative county, but continued to share the Lord Lieutenant until 1974 when it became a ceremonial county. Apart from a shared police force, there is now no administrative link with Hampshire, although a combined local authority with Portsmouth and Southampton is being considered.[6] Until 1995 the island had a governor.[n 1]		The quickest public transport link to the mainland is the hovercraft from Ryde to Southsea, while three ferry and two catamaran services cross the Solent to Southampton, Lymington and Portsmouth.						During the Ice Age, sea levels were lower and the Solent was part of a river flowing south east from current day Poole Harbour towards mid-Channel. As sea levels rose, the river valley became flooded, and the chalk ridge line west of the Needles breached to form the island.[7]		The first inhabitants are assumed to have been hunter-gatherers migrating by land during the Paleolithic or Old Stone Age period, as the ice age began to recede. From the Neolithic era onwards, there are indications that the island had wide trading links, with a port at Bouldnor,[8][9][10] evidence of Bronze Age tin trading,[11] and finds of Late Iron Age coins.[12]		Caesar reported that the Belgae took the Isle of Wight in about 85 BC and gave its name as Vectis.[13] The Roman historian Suetonius mentions that the island was captured by the commander Vespasian. The Romans built no towns or roads on the island, but the remains of at least seven Roman villas have been found, indicating the prosperity of local agriculture.[14]		During the Dark Ages the island was settled by Jutes as the pagan kingdom of Wihtwara under King Arwald. In 685 it was invaded by Caedwalla, who tried to replace the inhabitants with his own followers. In 686 Arwald was defeated and the island became the last part of English lands to be converted to Christianity,[15][16][17] added to Wessex and then becoming part of England under Alfred the Great, included within the shire of Hampshire.		It suffered especially from Viking raids,[18] and was often used as a winter base by Viking raiders when they were unable to reach Normandy.[19] Later, both Earl Tostig and his brother Harold Godwinson (who became King Harold II) held manors on the island.[20][21]		The Norman Conquest of 1066 created the position of Lord of the Isle of Wight, the island being given by William the Conqueror to his kinsman William FitzOsbern. Carisbrooke Priory and the fort of Carisbrooke Castle were then founded. Allegiance was sworn to FitzOsbern rather than the king; the Lordship was subsequently granted to the de Redvers family by Henry I, after his succession in 1100.		For nearly 200 years the island was a semi-independent feudal fiefdom, with the de Redvers family ruling from Carisbrooke. The final private owner was the Countess Isabella de Fortibus, who, on her deathbed in 1293, was persuaded to sell it to Edward I. Thereafter the island was under control of the English crown[22] and its Lordship a royal appointment.		The island continued to be attacked from the continent, raided in 1374 by the fleet of Castile,[23] and in 1377 by French raiders who burned several towns, including Newtown, and laid siege to Carisbrooke Castle before they were defeated.		Under Henry VIII, who developed the Royal Navy and its Portsmouth base, the island was fortified at Yarmouth, Cowes, East Cowes, and Sandown.		The French invasion on 21 July 1545 (famous for the sinking of the Mary Rose on the 19th) was repulsed by local militia.[24]		During the English Civil War, King Charles fled to the Isle of Wight, believing he would receive sympathy from the governor Robert Hammond. But Hammond imprisoned the king in Carisbrooke Castle.[25]		During the Seven Years' War, the island was used as a staging post for British troops departing on expeditions against the French coast, such as the Raid on Rochefort. During 1759, with a planned French invasion imminent, a large force of soldiers was stationed there. The French called off their invasion following the Battle of Quiberon Bay.[26]		In the 1860s, what remains in real terms the most expensive ever government spending project saw fortifications built on the island and in the Solent, as well as elsewhere along the south coast, including the Palmerston Forts, The Needles Battery and Fort Victoria, because of fears about possible French invasion.[27]		Queen Victoria spent childhood holidays on the island and became fond of it. When queen she made Osborne House her winter home, and so the island became a fashionable holiday resort, including for Alfred, Lord Tennyson, Julia Margaret Cameron, and Charles Dickens (who wrote much of David Copperfield there), as well as the French painter Berthe Morisot and members of European royalty.[28] Until then, the island had been rural, with most people employed in farming, fishing or boat-building. The boom in tourism, spurred by growing wealth and leisure time, and by Victoria's example, led to significant urban development of the island's coastal resorts.		Queen Victoria died at Osborne House on 22 January 1901, aged 81.		During her reign, the world's first radio station was set up by Marconi in 1897 at the Needles Battery, at the western tip of the island.[29][30] In 1898 the first paid wireless telegram (called a 'Marconigram' at the time) was sent from this station, and the island is now the home of the National Wireless Museum, near Ryde.[31]		During the Second World War the island was frequently bombed. With its proximity to German-occupied France, the island hosted observation stations and transmitters, as well as the RAF radar station at Ventnor. It was the starting-point for one of the earlier Operation Pluto pipelines to feed fuel to Europe after the Normandy landings.[32]		The Needles Battery was used to develop and test the Black Arrow and Black Knight space rockets, which were subsequently launched from Woomera, Australia.[33]		The Isle of Wight Festival was a very large rock festival that took place near Afton Down, West Wight in 1970, following two smaller concerts in 1968 and 1969. The 1970 show was notable both as one of the last public performances by Jimi Hendrix and for the number of attendees, reaching by some estimates 600,000.[34] The festival was revived in 2002 in a different format, and is now an annual event.[35]		The Isle of Wight is situated between the Solent and the English Channel, is roughly rhomboid in shape, and covers an area of 150 sq mi (380 km2). Slightly more than half, mainly in the west, is designated as the Isle of Wight Area of Outstanding Natural Beauty. The island has 100 sq mi (258 km2) of farmland, 20 sq mi (52 km2) of developed areas, and 57 miles (92 km) of coastline. Its landscapes are diverse, leading to its oft-quoted description as "England in miniature".		West Wight is predominantly rural, with dramatic coastlines dominated by the chalk downland ridge, running across the whole island and ending in the Needles stacks. The southwestern quarter is commonly referred to as the Back of the Wight, and has a unique character. The highest point on the island is St Boniface Down in the south east, which at 791 feet (241 m) is a marilyn.[36] The most notable habitats on the rest of the island are probably the soft cliffs and sea ledges, which are scenic features, important for wildlife, and internationally protected.		The island has three principal rivers. The River Medina flows north into the Solent, the Eastern Yar flows roughly northeast to Bembridge Harbour, and the Western Yar flows the short distance from Freshwater Bay to a relatively large estuary at Yarmouth. Without human intervention the sea might well have split the island into three: at the west end where a bank of pebbles separates Freshwater Bay from the marshy backwaters of the Western Yar east of Freshwater, and at the east end where a thin strip of land separates Sandown Bay from the marshy Eastern Yar basin.		The Undercliff between St Catherine's Point and Bonchurch is the largest area of landslip morphology in western Europe.		The north coast is unusual in having four high tides each day, with a double high tide every twelve and a half hours. This arises because the western Solent is narrower than the eastern; the initial tide of water flowing from the west starts to ebb before the stronger flow around the south of the island returns through the eastern Solent to create a second high water.[37]		The Isle of Wight is made up of a variety of rock types dating from early Cretaceous (around 127 million years ago) to the middle of the Palaeogene (around 30 million years ago). The geological structure is dominated by a large monocline which causes a marked change in age of strata from the northern younger Tertiary beds to the older Cretaceous beds of the south. This gives rise to a dip of almost 90 degrees in the chalk beds, seen best at the Needles.		The northern half of the island is mainly composed of clays, with the southern half formed of the chalk of the central east–west downs, as well as Upper and Lower Greensands and Wealden strata.[38] These strata continue west from the island across the Solent into Dorset, forming the basin of Poole Harbour (Tertiary) and the Isle of Purbeck (Cretaceous) respectively. The chalky ridges of Wight and Purbeck were a single formation before they were breached by waters from the River Frome during the last ice age, forming the Solent and turning Wight into an island. The Needles, along with Old Harry Rocks on Purbeck, represent the edges of this breach.		All the rocks found on the island are sedimentary, such as limestones, mudstones and sandstones. They are rich in fossils; many can be seen exposed on beaches as the cliffs erode. Lignitic coal is present in small quantities within seams, and can be seen on the cliffs and shore at Whitecliff Bay. Fossilised molluscs have been found there, and also on the northern coast along with fossilised crocodiles, turtles and mammal bones; the youngest date back to around 30 million years ago.		The island is one of the most important areas in Europe for dinosaur fossils. The eroding cliffs often reveal previously hidden remains, particularly along the Back of the Wight.[39] Dinosaur bones and fossilised footprints can be seen in and on the rocks exposed around the island's beaches, especially at Yaverland and Compton Bay. As a result, the island has been nicknamed "Dinosaur Island".		The area was affected by sea level changes during the repeated Quaternary glaciations. The island probably became separated from the mainland about 125,000 years ago, during the Ipswichian interglacial.[40]		Ordnance Survey map of the island.		Geological map of the island.		Blackgang Chine, circa 1910.		A view of the Needles and Alum Bay.		Like the rest of the UK, the island has an oceanic climate, but is somewhat milder and sunnier, which makes it a holiday destination. It also has a longer growing season. Lower Ventnor and the neighbouring Undercliff have a particular microclimate, because of their sheltered position south of the downs. The island enjoys 1,800–2,100 hours of sunshine a year.[41] Some years have almost no snow in winter, and only a few days of hard frost.[42] The island is in Hardiness zone 9.[43]		The Isle of Wight is one of the few places in England where the red squirrel is still flourishing; no grey squirrels are to be found.[44] There are occasional sightings of wild deer, and there is a colony of wild goats on Ventnor's downs.[45][46][47][48] Protected species such as the dormouse and rare bats can be found. The Glanville fritillary butterfly's distribution in the United Kingdom is largely restricted to the edges of the island's crumbling cliffs.[49]		A competition in 2002 named the pyramidal orchid as the Isle of Wight's county flower.[50]		The island has a single Member of Parliament and 138,300 permanent residents in 2011, being one of the most populated constituencies in the United Kingdom (more than 50% above the English average).[51] However, in 2011 the Parliamentary Voting System and Constituencies Act was to have changed this, as part of the Sixth Periodic Review of Westminster constituencies,[52] but this was deferred to no earlier than October 2018 by the Electoral Registration and Administration Act 2013. Thus the single constituency remained for the 2015 general election. However, two separate East and West constituencies are proposed for the island under the 2018 review now underway.		The Isle of Wight is a ceremonial and non-metropolitan county. Since the abolition of its two borough councils and restructuring of the county council as Isle of Wight Council in 1995, it has been a unitary authority.		Elections in the constituency have traditionally been a battle between the Conservatives and the Liberal Democrats. The Member of Parliament since 2001, Andrew Turner, is a Conservative, and while predecessor Dr Peter Brand was a Liberal Democrat. In recent years Turner has been embroiled in controversy over his expenses, health, and relationships with colleagues, with local Conservatives having tried but failed to remove him in the runup to the 2015 election.[53]		The Isle of Wight Council election of 2013 saw the Conservatives lose the majority which they had held since 2005 to the Island Independents. Island Independent councillors currently hold 16 of the 40 seats, with a further five sitting as independents outside the group.[54]		There have been small regionalist movements: the Vectis National Party and the Isle of Wight Party; but they have attracted little support in elections.[55]		The local accent is similar to the traditional dialect of Hampshire, featuring the dropping of some consonants and an emphasis on longer vowels. It is similar to the West Country dialects heard in South West England, but less pronounced.[57][58]		The island has its own local and regional words. Some, such as nipper/nips (a young male person), are still commonly used and are shared with neighbouring areas of the mainland. A few are unique to the island, for example overner and caulkhead (see below). Others are more obscure and now used mainly for comic emphasis, such as mallishag (meaning "caterpillar"), gurt meaning "large", nammit (a mid-morning snack) and gallybagger ("scarecrow", and now the name of a local cheese).[59]		There remains occasional confusion between the Isle of Wight as a county and its former position within Hampshire.[60] The island was regarded and administered as a part of Hampshire until 1890, when its distinct identity was recognised with the formation of Isle of Wight County Council (see also Politics of the Isle of Wight). However, it remained a part of Hampshire until the local government reforms of 1974 when it became a full ceremonial county with its own Lord Lieutenant.[61]		In January 2009, the first general flag for the county was accepted by the Flag Institute.[62]		Island residents are sometimes referred to as 'Vectensians', 'Vectians' or, if born on the island, "caulkheads".[63] One theory is that this last comes from the once prevalent local industry of caulking or sealing wooden boats; the term became attached to islanders either because they were so employed, or as a derisory term for perceived unintelligent labourers from elsewhere. The term 'overner' is used for island residents originating from the mainland (an abbreviated form of 'overlander', which is an archaic term for 'outsider' still found in parts of Australia).[64]		Residents refer to the island as "The Island", as did Jane Austen in Mansfield Park, and sometimes to the UK mainland as "North Island".[65]		To promote the island's identity and culture, the High Sheriff Robin Courage founded an Isle of Wight Day; the first was held on Saturday 24 September 2016.		The island is said to be the most haunted in the world, sometimes referred to as 'Ghost Island'. Notable claimed hauntings include God's Providence House in Newport (now a tea room), Appuldurcombe House, and the remains of Knighton Gorges.[31]		The island is well known for its cycling, and it was included within Lonely Planet's Best in Travel Guide (2010) top ten cycling locations. The island also hosts events such as the Isle of Wight Randonnée and the Isle of Wight Cycling Festival each year.		There are rowing clubs at Newport, Ryde and Shanklin, all members of the Hants and Dorset rowing association.		There is a long tradition of rowing around the island dating back to the 1880s.		In May 1999 a group of local women made history by becoming the first ladies crew to row around the island, in ten hours and twenty minutes. Rowers from Ryde Rowing Club have rowed around the island several times since 1880. The fours record was set 16 August 1995 at 7 hours 54 minutes.[66]		Two rowers from Southampton ARC (Chris Bennett and Roger Slaymaker) set the two-man record in July 2003 at 8 hours 34 minutes, and in 2005 Gus McKechnie of Coalporters Rowing Club became the first adaptive rower to row around, completing a clockwise row.[67]		The route around the island is about 60 miles (97 km) and usually rowed anticlockwise. Even in good conditions, it includes a number of significant obstacles such as the Needles and the overfalls at St Catherine's Point. The traditional start and finish were at Ryde Rowing Club; however other starts have been chosen in recent years to give a tidal advantage.		Cowes is a centre for sailing, hosting several racing regattas. Cowes Week is the longest-running regular regatta in the world, with over 1,000 yachts and 8,500 competitors taking part in over 50 classes of racing.[68] In 1851 the first America's Cup race was around the island. Other major sailing events hosted in Cowes include the Fastnet race, the Round the Island Race,[69] the Admiral's Cup, and the Commodore's Cup.[70]		There are two main trampoline clubs on the island, in Freshwater and Newport, competing at regional, national and international grades.[71][72]		The Isle of Wight Marathon is the United Kingdom's oldest continuously held marathon, having been run every year since 1957.[73] Since 2013 the course has started and finished in Cowes, heading out to the west of the island and passing through Gurnard, Rew Street, Porchfield, Shalfleet, Yarmouth, Afton, Willmingham, Thorley, Wellow, Shalfleet, Porchfield, and Northwood. It is an undulating course with a total climb of 1,043 feet (318 m).		The island is home to the Wightlink Warriors speedway team, who compete in the sport's third division, the National League.		Following an amalgamation of local hockey clubs in 2011, the Isle of Wight Hockey Club now runs two men's senior and two ladies' senior teams. These compete at a range of levels in the Hampshire open leagues.[74]		The now-disbanded Ryde Sports F.C., founded in 1888, was one of the eight founder members of the Hampshire League in 1896. There are several non-league clubs such as Newport (IW) F.C. There is an Isle of Wight Saturday Football League with three divisions, and a rugby union club.[75][76]		The Isle of Wight is the 39th official county in English cricket, and the Isle of Wight Cricket Board organises a league of local clubs. Ventnor Cricket Club competes in the Southern Premier League, and has won the Second Division several times. Newclose County Cricket Ground near Newport[77][78][79] opened officially in 2009 but with its first match held on 6 September 2008.[80] The island has produced some notable cricketers, such as Danny Briggs, who plays county cricket for Hampshire.		The Isle of Wight competes in the biennial Island Games, which it hosted in 1993 and again in 2011.		The annual Isle of Wight International Scooter Rally has since 1980 met on the August Bank Holiday. This is now one of the biggest scooter rallies in the world, attracting between four and seven thousand participants.[81]		The island is home to the Isle of Wight Festival and, up to 2016, Bestival. In 1970, the festival headlined by Jimi Hendrix attracted an audience of 600,000, some six times the local population at the time.[82] It is the home of the band The Bees, which performs at smaller local concerts. Trixie's Big Red Motorbike[83] as well as three of the founding members of Level 42 (Mark King, Boon Gould and Phil Gould) came from the island. It has also hosted a one-day festival called 'Summer Madness', which started in 2009 headlined by Madness; in 2010 Paul Weller headlined. In January 2011 it was reported that the promoter of Summer Madness was insolvent.		The table below shows the regional gross value (in millions of pounds) added by the Isle of Wight economy, at current prices, compiled by the Office for National Statistics:[84][85]		According to the 2011 census,[90] the island's population of 138,625 lives in 61,085 households, giving an average household size of 2.27 people.		41% of households own their home outright and a further 29% own with a mortgage, so in total 70% of households are owned (compared to 68% for South East England).		Compared to South East England, the island has fewer children (19% aged 0–17 against 22% for the South East) and more elderly (24% aged 65+ against 16%), giving an average age of 44 years for an island resident compared to 40 in South East England.		The largest industry is tourism, but the island also has a strong agricultural heritage, including sheep and dairy farming and arable crops. Traditional agricultural commodities are more difficult to market off the island because of transport costs, but local farmers have managed successfully to exploit some specialist markets, with the higher price of such products being able to absorb the transport costs. One of the most successful agricultural sectors is now the growing of crops under cover, particularly salad crops including tomatoes and cucumbers. The island has a warmer climate and longer growing season than much of the United Kingdom. Garlic has been successfully grown in Newchurch for many years, and is even exported to France. This has led to the establishment of an annual Garlic Festival at Newchurch, which is one of the largest events of the local calendar. A favourable climate supports two vineyards, including one of the oldest in the British Isles at Adgestone.[91] Lavender is grown for its oil.[92] The largest agricultural sector has been dairying, but due to low milk prices and strict legislation for UK milk producers, the dairy industry has been in decline: there were nearly 150 producers in the mid-1980s, but now just 24.		Maritime industries, especially the making of sailcloth and boat building, has long been associated with the island, although this has diminished somewhat in recent years. GKN operates what began as the British Hovercraft Corporation, a subsidiary of (and known latterly as) Westland Aircraft, although they have reduced the extent of plant and workforce and sold the main site. Previously it had been the independent company Saunders-Roe, one of the island's most notable historic firms that produced many flying boats and the world's first hovercraft.[93]		Another manufacturing activity is in composite materials, used by boat-builders and the wind turbine manufacturer Vestas, which has a wind turbine blade factory and testing facilities in West Medina Mills and East Cowes.[94]		Bembridge Airfield is the home of Britten-Norman, manufacturers of the Islander and Trislander aircraft. This is shortly to become the site of the European assembly line for Cirrus light aircraft. The Norman Aeroplane Company is a smaller aircraft manufacturing company operating in Sandown. There have been three other firms that built planes on the island.[95]		In 2005, Northern Petroleum began exploratory drilling for oil at its Sandhills-2 borehole at Porchfield, but ceased operations in October that year after failing to find significant reserves.[96]		There are three breweries on the island. Goddards Brewery in Ryde opened in 1993.[97] David Yates, who was head brewer of the Island Brewery, started brewing as Yates Brewery at the Inn at St Lawrence in 2000.[98]		Ventnor Brewery, which closed in 2009, was the last incarnation of Burt's Brewery, brewing since the 1840s in Ventnor.[99] Until the 1960s most pubs were owned by Mews Brewery, situated in Newport near the old railway station, but it closed and the pubs were taken over by Strong's, and then by Whitbread. By some accounts Mews beer was apt to be rather cloudy and dark. In the 19th century they pioneered the use of screw top cans for export to British India.[100]		Its heritage is a major asset that has for many years supported the island's tourist economy. Holidays focused on natural heritage, including wildlife and geology, are becoming an alternative to the traditional British seaside holiday, which went into decline in the second half of the 20th century due to the increased affordability of foreign holidays.[101] The island is still an important destination for coach tours from other parts of the United Kingdom.		Tourism is still the largest industry, and most island towns and villages offer hotels, hostels and camping sites. In 1999, it hosted 2.7 million visitors, with 1.5 million staying overnight, and 1.2 million visits day visits; only 150,000 of these were from abroad. Between 1993 and 2000, visits increased at an average rate of 3% per year.[102]		At the turn of the 19th century the island had ten pleasure piers including two at Ryde and a "chain pier" at Seaview. The Victoria Pier in Cowes succeeded the earlier Royal Pier but was itself removed in 1960. The piers at Ryde, Seaview, Sandown, Shanklin and Ventnor originally served a coastal steamer service that operated from Southsea on the mainland. The piers at Seaview, Shanklin, Ventnor and Alum Bay were all destroyed by various storms during the 20th century; only the railway pier at Ryde and the piers at Sandown, Totland Bay (currently closed to the public) and Yarmouth survive.		Blackgang Chine is the oldest theme park in Britain, opened in 1843.[103] The skeleton of a dead whale that its founder Alexander Dabell found in 1844 is still on display.[31]		As well as its more traditional attractions, the island is often host to walking[104] or cycling holidays through the attractive scenery. An annual walking festival[105] has attracted considerable interest. The 70 miles (113 km) Isle of Wight Coastal Path follows the coastline as far as possible, deviating onto roads where the route along the coast is impassable.[106]		A major contributor to the local economy is sailing and marine-related tourism.[107]		Summer Camp at Camp Beaumont is an attraction at the old Bembridge School site.[108]		The Isle of Wight has 489 miles (787 km) of roadway. It does not have a motorway, although there is a short stretch of dual carriageway towards the north of Newport near the hospital and prison.		A comprehensive bus network operated by Southern Vectis links most settlements, with Newport as its central hub.[109]		Journeys away from the island involve a ferry journey. Car ferry and passenger catamaran services are run by Wightlink and Red Funnel, and a hovercraft passenger service (the only such remaining in the world[110]) by Hovertravel.		The island formerly had its own railway network of over 55 miles (89 km), but only one line remains in regular use. The Island Line is part of the United Kingdom's National Rail network, running a little under 9 miles (14 km) from Shanklin to Ryde Pier Head, where there is a connecting ferry service to Portsmouth Harbour station on the mainland network. The line was opened by the Isle of Wight Railway in 1864, and from 1996 to 2007 was run by the smallest train operating company on the network, Island Line Trains. It is notable for utilising old ex-London Underground rolling stock, due to the small size of its tunnels and unmodernised signalling. Branching off the Island Line at Smallbrook Junction is the heritage Isle of Wight Steam Railway, which runs for 5 1⁄2 miles (8.9 km) to the outskirts of Wootton on the former line to Newport.[111]		There are two airfields for general aviation, Isle of Wight Airport at Sandown and Bembridge Airport.		The island has over 200 miles (322 km) of cycleways, many of which can be enjoyed off-road. Major Trails are:[112]		The main local newspaper is the Isle of Wight County Press, published most Fridays.		The island has one local commercial radio station: Isle of Wight Radio has broadcast in the medium-wave band since 1990 and on 107.0 MHz (with three smaller transmitters on 102.0 MHz) FM since 1998, as well as streaming on the Internet.[113] The island is also covered by a number of local stations on the mainland, including the BBC station BBC Radio Solent broadcast from Southampton.		The island's not-for-profit community radio station Angel Radio opened in 2007. Angel Radio began broadcasting on 91.5 MHz from studios in Cowes and a transmitter near Newport.[114][115]		Local online radio station Vectis Radio has broadcast since 2010, broadcasting from the Riverside Centre in Newport.[116]		Online news sources for the Isle of Wight include On the Wight[117] and The Isle of Wight Chronicle.[118] The Chronicle was originally an island local paper during the later 19th and early 20th century.		The island has an online 24/7 breaking news source Island Echo,[119] which was founded in May 2012.		The island has had community television stations in the past, first TV12 and then Solent TV from 2002 until its closure on 24 May 2007. iWight.tv is a local internet video news channel.		The Isle of Wight is part of the BBC South region and the ITV Meridian region.		Important broadcasting infrastructure includes Chillerton Down transmitting station with a mast that is the tallest structure on the island, and Rowridge transmitting station, which broadcasts the main television signal both locally and for most of Hampshire and parts of Dorset and West Sussex.[120]		Its separation from the mainland yet being near the densely populated south of England led to it hosting three prisons: Albany, Camp Hill and Parkhurst, all located outside Newport near the main road to Cowes. Albany and Parkhurst were among the few Category A prisons in the UK until they were downgraded in the 1990s.[121] The downgrading of Parkhurst was precipitated by a major escape: three prisoners (two murderers and a blackmailer) escaped from the prison on 3 January 1995 for four days, before being recaptured.[122] Parkhurst enjoyed notoriety as one of the toughest jails in the United Kingdom, and housed many notable inmates including the Yorkshire Ripper Peter Sutcliffe, New Zealand drug lord Terry Clark and the Kray twins.		Camp Hill is located adjacent but to the west of Albany and Parkhurst, on the very edge of Parkhurst Forest, having been converted first to a borstal and later to a Category C prison. It was built on the site of an army camp (both Albany and Parkhurst were barracks); there is a small estate of tree-lined roads with the former officers' quarters (now privately owned) to the south and east. Camp Hill closed as a prison in March 2013.		The management of all three prisons was merged into a single administration, under HMP Isle of Wight in April 2009.		There are sixty-nine Local Education Authority-maintained schools on the Isle of Wight, and two independent schools.[123] As a rural community, many of these are small and with fewer pupils than in urban areas. The Isle of Wight College is located on the outskirts of Newport.		From September 2010, there was a transition period from the three-tier system of primary, middle and high schools to the two-tier system that is usual in England.[124] Some schools have now closed, such as Chale C.E. Primary. Others have become "federated", such as Brading C.E. Primary and St Helen's Primary. Christ the King College started as a "middle school" but has now been converted into a secondary school and sixth form.		As of September 2011, there are five new secondary schools, with an age range of 11 to 18 years, which have replaced the island's high schools (as a part of the previous three-tier system).		Notable residents have included:		The Isle of Wight has given names to many parts of former colonies, most notably Isle of Wight County in Virginia founded by settlers from the island in the 17th century. Its county seat is a town named Isle of Wight.		Other notable examples include:		[126]		The Isle of Wight was:[128]		
An intertidal wetland is an area along a shoreline that is exposed to air at low tide and submerged at high tide. This type of wetland is defined by an intertidal zone and includes its own intertidal ecosystems.		The main types of intertidal wetlands are mudflats (e.g., mangrove swamps) and salt marshes. The mangrove swamps are encountered along tropical shores and are characterized by tree vegetation, while salt marshes are mostly found in temperate zones and are mostly grass ecosystems.[1]		Intertidal wetlands are commonly encountered in most estuaries. Intertidal wetland ecosystems are amongst the most productive plant communities and often constitute a large part of the estuary areas.[1]				
The Mediterranean Sea is a sea connected to the Atlantic Ocean, surrounded by the Mediterranean Basin and almost completely enclosed by land: on the north by Southern Europe and Anatolia, on the south by North Africa, and on the east by the Levant. Although the sea is sometimes considered a part of the Atlantic Ocean, it is usually identified as a separate body of water. Geological evidence indicates that around 5.9 million years ago, the Mediterranean was cut off from the Atlantic and was partly or completely desiccated over a period of some 600,000 years before being refilled by the Zanclean flood about 5.3 million years ago.		The name Mediterranean is derived from the Latin mediterraneus, meaning "inland" or "in the middle of land" (from medius, "middle" and terra, "land"). It covers an approximate area of 2.5 million km2 (965,000 sq mi), but its connection to the Atlantic (the Strait of Gibraltar) is only 14 km (8.7 mi) wide. The Strait of Gibraltar is a narrow strait that connects the Atlantic Ocean to the Mediterranean Sea and separates Gibraltar and Spain in Europe from Morocco in Africa. In oceanography, it is sometimes called the Eurafrican Mediterranean Sea or the European Mediterranean Sea to distinguish it from mediterranean seas elsewhere.[3][4]		The Mediterranean Sea has an average depth of 1,500 m (4,900 ft) and the deepest recorded point is 5,267 m (17,280 ft) in the Calypso Deep in the Ionian Sea. The sea is bordered on the north by Europe, the east by Asia, and in the south by Africa. It is located between latitudes 30° and 46° N and longitudes 6° W and 36° E. Its west-east length, from the Strait of Gibraltar to the Gulf of Iskenderun, on the southwestern coast of Turkey, is approximately 4,000 km (2,500 miles). The sea's average north-south length, from Croatia’s southern shore to Libya, is approximately 800 km (500 miles). The Mediterranean Sea, including the Sea of Marmara (connected by the Dardanelles to the Aegean Sea), has a surface area of approximately 2,510,000 square km (970,000 square miles).[5]		The sea was an important route for merchants and travellers of ancient times that allowed for trade and cultural exchange between emergent peoples of the region. The history of the Mediterranean region is crucial to understanding the origins and development of many modern societies.		The countries with coastlines on the Mediterranean Sea are Albania, Algeria, Bosnia and Herzegovina, Croatia, Cyprus, Egypt, France, Greece, Israel, Italy, Lebanon, Libya, Malta, Morocco, Monaco, Montenegro, Slovenia, Spain, Syria, Tunisia and Turkey. In addition, the Gaza Strip and the British Overseas Territories of Gibraltar and Akrotiri and Dhekelia have coastlines on the sea.						The term Mediterranean derives from the Latin word mediterraneus, meaning "amid the earth (note: earth in the sense "soil", not Planet Earth)" or "between land" (medi-; adj. medius, -um -a "middle, between" + terra f., "land, earth"): as it is between the continents of Africa, Asia and Europe. The Ancient Greek name Mesogeios (Μεσόγειος), is similarly from μέσο, "between" + γη, "land, earth").[6] It can be compared with the Ancient Greek name Mesopotamia (Μεσοποταμία), meaning "between rivers".		The Mediterranean Sea has historically had several names. For example, the Carthaginians called it the "Syrian Sea" and latter Romans commonly called it Mare Nostrum ("Our Sea"), and occasionally Mare Internum[7] and in Greek as the "Mare Magnum", meaning "Great Sea".[8]		In ancient Syrian texts, Phoenician epics and in the Hebrew Bible, it was primarily known as the "Great Sea" (הַיָּם הַגָּדוֹל, HaYam HaGadol, Numbers 34:6,7; Joshua 1:4, 9:1, 15:47; Ezekiel 47:10,15,20), or simply "The Sea" (1 Kings 5:9; comp. 1 Macc. 14:34, 15:11); however, it has also been called the "Hinder Sea" (הַיָּם הָאַחֲרוֹן), due to its location on the west coast of Greater Syria or the Holy Land, and therefore behind a person facing the east, sometimes translated as "Western Sea", (Deut. 11:24; Joel 2:20). Another name was the "Sea of the Philistines" (יָם פְּלִשְׁתִּים, Exod. 23:31), from the people inhabiting a large portion of its shores near the Israelites.		In Modern Hebrew, it has been called HaYam HaTikhon (הַיָּם הַתִּיכוֹן), "the Middle Sea", reflecting the Sea's name in ancient Greek (Mesogeios), Latin Mare internum (Inner Sea) or Mare Nostrum (Our Sea), and modern languages in both Europe and the Middle East (Mediterranean, etc.).[8]		Similarly, in Modern Arabic, it is known as al-Baḥr [al-Abyaḍ] al-Mutawassiṭ (البحر [الأبيض] المتوسط), "the [White] Middle Sea", while in Islamic and older Arabic literature, it was referenced as Baḥr al-Rūm (بحر الروم), or "the Roman/Byzantine Sea."[8]		In Ottoman Turkish, it has also been called Bahr-i Sefid, meaning the "Pure White Sea".		In Turkish, it is known as Akdeniz,[9] meaning "the White Sea", to distinguish it from the Black Sea.[8]		Several ancient civilisations were located around the Mediterranean shores, and were greatly influenced by their proximity to the sea. It provided routes for trade, colonisation, and war, as well as food (from fishing and the gathering of other seafood) for numerous communities throughout the ages.[10]		Due to the shared climate, geology, and access to the sea, cultures centered on the Mediterranean tended to have some extent of intertwined culture and history.		Two of the most notable Mediterranean civilisations in classical antiquity were the Greek city states and the Phoenicians, both of which extensively colonised the coastlines of the Mediterranean. Later, when Augustus founded the Roman Empire, the Romans referred to the Mediterranean as Mare Nostrum ("Our Sea").		Darius I of Persia, who conquered Ancient Egypt, built a canal linking the Mediterranean to the Red Sea. Darius's canal was wide enough for two triremes to pass each other with oars extended, and required four days to traverse.[11]		The Western Roman Empire collapsed around AD 476. Temporarily the east was again dominant as the Byzantine Empire formed from the eastern half of the Roman empire. Another power arose in the 7th century, and with it the religion of Islam, which soon swept across from the east; at its greatest extent, the Arab Empire controlled 75% of the Mediterranean region and left a lasting footprint on its eastern and southern shores.		Europe was reviving, however, as more organised and centralised states began to form in the later Middle Ages after the Renaissance of the 12th century.		Ottoman power continued to grow, and in 1453, the Byzantine Empire was extinguished with the Conquest of Constantinople. Ottomans gained control of much of the sea in the 16th century and maintained naval bases in southern France, Algeria and Tunisia. Barbarossa, the famous Ottoman captain is a symbol of this domination with the victory of the Battle of Preveza (1538). The Battle of Djerba (1560) marked the apex of Ottoman naval domination in the Mediterranean. As the naval prowess of the European powers increased, they confronted Ottoman expansion in the region when the Battle of Lepanto (1571) checked the power of the Ottoman Navy. This was the last naval battle to be fought primarily between galleys.		The Barbary pirates of North Africa preyed on Christian shipping in the Western Mediterranean Sea.[12] According to Robert Davis, from the 16th to 19th centuries, pirates captured 1 million to 1.25 million Europeans as slaves.[13]		The development of oceanic shipping began to affect the entire Mediterranean. Once, all trade from the east had passed through the region, but now the circumnavigation of Africa allowed spices and other goods to be imported through the Atlantic ports of western Europe.[14][15][16]		In 2013 the Maltese president described the Mediterranean sea as a "cemetery" due to the large amounts of migrants who drowned there after their boats capsized.[17] European Parliament president Martin Schulz said in 2014 that Europe's migration policy "turned the Mediterranean into a graveyard", referring to the number of drowned refugees in the region as a direct result of the policies.[18] An Azerbaijani official described the sea as "a burial ground ... where people die".[19]		Following the 2013 Lampedusa migrant shipwreck, the Italian government decided to strengthen the national system for the patrolling of the Mediterranean Sea by authorising "Operation Mare Nostrum", a military and humanitarian mission in order to rescue the migrants and arrest the traffickers of immigrants. In 2015, more than one million migrants crossed the Mediterranean sea into Europe.[20]		The Mediterranean Sea is connected to the Atlantic Ocean by the Strait of Gibraltar (known in Homer's writings as the "Pillars of Hercules") in the west and to the Sea of Marmara and the Black Sea, by the Dardanelles and the Bosporus respectively, in the east. The Sea of Marmara (Dardanelles) is often considered a part of the Mediterranean Sea, whereas the Black Sea is generally not. The 163 km (101 mi) long artificial Suez Canal in the southeast connects the Mediterranean Sea to the Red Sea.[8]		Large islands in the Mediterranean include Cyprus, Crete, Euboea, Rhodes, Lesbos, Chios, Kefalonia, Corfu, Limnos, Samos, Naxos and Andros in the Eastern Mediterranean; Sicily, Cres, Krk, Brač, Hvar, Pag, Korčula and Malta in the central Mediterranean; and Sardinia, Corsica, Ibiza, Majorca and Minorca (the Balearic Islands) in the Western Mediterranean.		The typical Mediterranean climate has hot, humid, and dry summers and mild, rainy winters. Crops of the region include olives, grapes, oranges, tangerines, and cork.		The International Hydrographic Organization defines the limits of the Mediterranean Sea as follows:[21]		Stretching from the Strait of Gibraltar in the west to the entrances to the Dardanelles and the Suez Canal in the east, the Mediterranean Sea is bounded by the coasts of Europe, Africa and Asia, and is divided into two deep basins:		Being nearly landlocked affects conditions in the Mediterranean Sea: for instance, tides are very limited as a result of the narrow connection with the Atlantic Ocean. The Mediterranean is characterised and immediately recognised by its deep blue colour.		Evaporation greatly exceeds precipitation and river runoff in the Mediterranean, a fact that is central to the water circulation within the basin.[22] Evaporation is especially high in its eastern half, causing the water level to decrease and salinity to increase eastward.[23] The salinity at 5 m depth is 3.8%.[24]		The pressure gradient pushes relatively cool, low-salinity water from the Atlantic across the basin; it warms and becomes saltier as it travels east, then sinks in the region of the Levant and circulates westward, to spill over the Strait of Gibraltar.[25] Thus, seawater flow is eastward in the Strait's surface waters, and westward below; once in the Atlantic, this chemically distinct Mediterranean Intermediate Water can persist thousands of kilometres away from its source.[26]		The temperature of the water in the deepest part of the Mediterranean Sea is 13.2 °C (55.8 °F).[24]		The following countries have a coastline on the Mediterranean Sea:		Several other territories also border the Mediterranean Sea (from west to east): The British overseas territory of Gibraltar, the Spanish autonomous cities of Ceuta and Melilla and nearby islands, the Sovereign Base Areas on Cyprus, and the Gaza Strip.		Major cities (municipalities) with populations larger than 200,000 people bordering the Mediterranean Sea are:		According to the International Hydrographic Organization (IHO), the Mediterranean Sea is subdivided into a number of smaller waterbodies, each with their own designation (from west to east):[21]		Although not recognised by the IHO treaties, there are some other seas whose names have been in common use from the ancient times, or in the present:		Many of these smaller seas feature in local myth and folklore and derive their names from these associations.		In addition to the seas, a number of gulfs and straits are also recognised:		The geologic history of the Mediterranean Sea is complex. Underlain by oceanic crust, the sea basin was once thought to be a tectonic remnant of the ancient Tethys Ocean; it is now known to be a structurally younger basin, called the Neotethys, which was first formed by the convergence of the African and Eurasian plates during the Late Triassic and Early Jurassic. Because it is a near-landlocked body of water in a normally dry climate, the Mediterranean is subject to intensive evaporation and the precipitation of evaporites. The Messinian salinity crisis started about six million years ago (mya) when the Mediterranean became landlocked, and then essentially dried up. There are salt deposits accumulated on the bottom of the basin of more than a million cubic kilometres—in some places more than three kilometres thick.[42][43]		Scientists estimate that the sea was last filled about 5.3 million years ago (mya) in less than two years by the Zanclean flood. Water poured in from the Atlantic Ocean through a newly breached gateway now called the Strait of Gibraltar at an estimated rate of about three orders of magnitude (one thousand times) larger than the current flow of the Amazon River.[44]		The Mediterranean Sea has an average depth of 1,500 m (4,900 ft) and the deepest recorded point is 5,267 m (17,280 ft) in the Calypso Deep in the Ionian Sea. The coastline extends for 46,000 km (29,000 mi). A shallow submarine ridge (the Strait of Sicily) between the island of Sicily and the coast of Tunisia divides the sea in two main subregions: the Western Mediterranean, with an area of about 850 thousand km2 (330 thousand mi2); and the Eastern Mediterranean, of about 1.65 million km2 (640 thousand mi2). A characteristic of the coastal Mediterranean are submarine karst springs or vruljas, which discharge pressurised groundwater into the coastal seawater from below the surface; the discharge water is usually fresh, and sometimes may be thermal.[45][46]		The Mediterranean basin and sea system was established by the ancient African-Arabian continent colliding with the Eurasian continent. As Africa-Arabia drifted northward, it closed over the ancient Tethys Ocean which had earlier separated the two supercontinents Laurasia and Gondwana. At about that time in the middle Jurassic period a much smaller sea basin, dubbed the Neotethys, was formed shortly before the Tethys Ocean closed at its western (Arabian) end. The broad line of collisions pushed up a very long system of mountains from the Pyrenees in Spain to the Zagros Mountains in Iran in an episode of mountain-building tectonics known as the Alpine orogeny. The Neotethys grew larger during the episodes of collisions (and associated foldings and subductions) that occurred during the Oligocene and Miocene epochs (34 to 5.33 mya); see animation: Africa-Arabia colliding with Eurasia. Accordingly, the Mediterranean basin consists of several stretched tectonic plates in subduction which are the foundation of the Eastern part of the Mediterranean Sea. Various zones of subduction harbour and form the deepest and most majestic oceanic ridges, east of the Ionian Sea and south of the Aegean. The Central Indian Ridge runs East of the Mediterranean Sea South-East across the in-between of Africa and the Arabian Peninsula into the Indian Ocean. Nevertheless, while man-made geopolitical turmoil and chaos have governed the coastlines of many various Mediterranean nations throughout the courses of ancient, modern, present and foreseeable history, the Plate tectonic status of nations bordering the Mediterranean Sea will find sharing the same geological concerns and fate.		During Mesozoic and Cenozoic times, as the northwest corner of Africa converged on Iberia, it lifted the Betic-Rif mountain belts across southern Iberia and northwest Africa. There the development of the intramontane Betic and Rif basins led to creating two roughly-parallel marine gateways between the Atlantic Ocean and the Mediterranean Sea. Dubbed the Betic and Rifian corridors, they progressively closed during middle and late Miocene times; perhaps several times.[47] During late Miocene times the closure of the Betic Corridor triggered the so-called "Messinian salinity crisis" (MSC), when the Mediterranean almost entirely dried out. The time of beginning of the MSC was recently estimated astronomically at 5.96 mya, and it persisted for some 630,000 years until about 5.3 mya;[48] see Animation: Messinian salinity crisis, at right.		After the initial drawdown and re-flooding there followed more episodes—the total number is debated—of sea drawdowns and re-floodings for the duration of the MSC. It ended when the Atlantic Ocean last re-flooded the basin—creating the Strait of Gibraltar and causing the Zanclean flood—at the end of the Miocene (5.33 mya). Some research has suggested that a desiccation-flooding-desiccation cycle may have repeated several times, which could explain several events of large amounts of salt deposition.[49][50] Recent studies, however, show that repeated desiccation and re-flooding is unlikely from a geodynamic point of view. [51][52]		The present-day Atlantic gateway, i.e. the Strait of Gibraltar, originated in the early Pliocene via the Zanclean Flood. As mentioned, two other gateways preceded Gibraltar: the Betic Corridor across southern Spain and the Rifian Corridor across northern Morocco. The former gateway closed about six (6) mya, causing the Messinian salinity crisis (MSC); the latter or possibly both gateways closed during the earlier Tortonian times, causing a "Tortonian salinity crisis" (from 11.6 to 7.2 mya), which occurred well before the MSC and lasted much longer. Both "crises" resulted in broad connections of the mainlands of Africa and Europe, which thereby normalised migrations of flora and fauna—especially large mammals including primates—between the two continents. The Vallesian crisis indicates a typical extinction and replacement of mammal species in Europe during Tortonian times following climatic upheaval and overland migrations of new species;[53] see Animation: Messinian salinity crisis (and mammal migrations), at right.		The near-completely enclosed configuration of the Mediterranean basin has enabled the oceanic gateways to dominate seawater circulation and the environmental evolution of the sea and basin. Circulation patterns are also affected by several other factors—including climate, bathymetry, and water chemistry and temperature—which are interactive and can induce precipitation of evaporites. Deposits of evaporites accumulated earlier in the nearby Carpathian foredeep during the Middle Miocene, and the adjacent Red Sea Basin (during the Late Miocene), and in the whole Mediterranean basin (during the MSC and the Messinian age). Diatomites are regularly found underneath the evaporite deposits, suggesting a connection between their geneses.		Today, evaporation of surface seawater (output) is more than the supply (input) of fresh water by precipitation and coastal drainage systems, causing the salinity of the Mediterranean to be much higher than that of the Atlantic—so much so that the saltier Mediterranean waters sink below the waters incoming from the Atlantic, causing a two-layer flow across the Gibraltar strait: that is, an outflow submarine current of warm saline Mediterranean water, counterbalanced by an inflow surface current of less saline cold oceanic water from the Atlantic. Herman Sörgel's Atlantropa project proposal in the 1920s proposed a hydroelectric dam to be built across the Strait of Gibraltar, using the inflow current to provide a large amount of hydroelectric energy. The underlying energy grid was as well intended to support a political union between Europe and, at least, the Marghreb part of Africa (compare Eurafrika for the later impact and Desertec for a later project with some parallels in the planned grid).[54]		The end of the Miocene also marked a change in the climate of the Mediterranean basin. Fossil evidence from that period reveals that the larger basin had a humid subtropical climate with rainfall in the summer supporting laurel forests. The shift to a "Mediterranean climate" occurred largely within the last three million years (the late Pliocene epoch) as summer rainfall decreased. The subtropical laurel forests retreated; and even as they persisted on the islands of Macaronesia off the Atlantic coast of Iberia and North Africa, the present Mediterranean vegetation evolved, dominated by coniferous trees and sclerophyllous trees and shrubs with small, hard, waxy leaves that prevent moisture loss in the dry summers. Much of these forests and shrublands have been altered beyond recognition by thousands of years of human habitation. There are now very few relatively intact natural areas in what was once a heavily wooded region.		Because of its latitudinal position and its land-locked configuration, the Mediterranean is especially sensitive to astronomically induced climatic variations, which are well documented in its sedimentary record. Since the Mediterranean is involved in the deposition of eolian dust from the Sahara during dry periods, whereas riverine detrital input prevails during wet ones, the Mediterranean marine sapropel-bearing sequences provide high-resolution climatic information. These data have been employed in reconstructing astronomically calibrated time scales for the last 9 Ma of the Earth's history, helping to constrain the time of past geomagnetic reversals.[55] Furthermore, the exceptional accuracy of these paleoclimatic records has improved our knowledge of the Earth's orbital variations in the past.		As a result of the drying of the sea during the Messinian salinity crisis,[56] the marine biota of the Mediterranean are derived primarily from the Atlantic Ocean. The North Atlantic is considerably colder and more nutrient-rich than the Mediterranean, and the marine life of the Mediterranean has had to adapt to its differing conditions in the five million years since the basin was reflooded.		The Alboran Sea is a transition zone between the two seas, containing a mix of Mediterranean and Atlantic species. The Alboran Sea has the largest population of bottlenose dolphins in the Western Mediterranean, is home to the last population of harbour porpoises in the Mediterranean, and is the most important feeding grounds for loggerhead sea turtles in Europe. The Alboran sea also hosts important commercial fisheries, including sardines and swordfish. The Mediterranean monk seals live in the Aegean Sea in Greece. In 2003, the World Wildlife Fund raised concerns about the widespread drift net fishing endangering populations of dolphins, turtles, and other marine animals such as the ogre cancer.		For 4,000 years, human activity has transformed most parts of Mediterranean Europe, and the "humanisation of the landscape" overlapped with the appearance of the present Mediterranean climate.[57] The image of a simplistic, environmental determinist notion of a Mediterranean Paradise on Earth in antiquity, which was destroyed by later civilisations dates back to at least the 18th century and was for centuries fashionable in archaeological and historical circles. Based on a broad variety of methods, e.g. historical documents, analysis of trade relations, floodplain sediments, pollen, tree-ring and further archaeometric analyses and population studies, Alfred Thomas Grove and Oliver Rackham's work on "The Nature of Mediterranean Europe" challenges this common wisdom of a Mediterranean Europe as a "Lost Eden", a formerly fertile and forested region, that had been progressively degraded and desertified by human mismanagement.[57] The belief stems more from the failure of the recent landscape to measure up to the imaginary past of the classics as idealised by artists, poets and scientists of the early modern Enlightenment.[57]		The historical evolution of climate, vegetation and landscape in southern Europe from prehistoric times to the present is much more complex and underwent various changes. For example, some of the deforestation had already taken place before the Roman age. While in the Roman age large enterprises as the Latifundiums took effective care of forests and agriculture, the largest depopulation effects came with the end of the empire. Some[who?] assume that the major deforestation took place in modern times — the later usage patterns were also quite different e.g. in southern and northern Italy. Also, the climate has usually been unstable and showing various ancient and modern "Little Ice Ages",[58] and plant cover accommodated to various extremes and became resilient with regard to various patterns of human activity.[57]		Humanisation was therefore not the cause of climate change but followed it.[57] The wide ecological diversity typical of Mediterranean Europe is predominantly based on human behavior, as it is and has been closely related human usage patterns.[57] The diversity range was enhanced by the widespread exchange and interaction of the longstanding and highly diverse local agriculture, intense transport and trade relations, and the interaction with settlements, pasture and other land use. The greatest human-induced changes, however, came after World War II, respectively in line with the '1950s-syndrome'[59] as rural populations throughout the region abandoned traditional subsistence economies. Grove and Rackham suggest that the locals left the traditional agricultural patterns towards taking a role as scenery-setting agents for the then much more important (tourism) travellers. This resulted in more monotonous, large-scale formations.[57] Among further current important threats to Mediterranean landscapes are overdevelopment of coastal areas, abandonment of mountains and, as mentioned, the loss of variety via the reduction of traditional agricultural occupations.[57]		The region has a variety of geological hazards which have closely interacted with human activity and land use patterns. Among others, in the eastern Mediterranean, the Thera eruption, dated to the 17th or 16th century BC, caused a large tsunami that some experts hypothesise devastated the Minoan civilisation on the nearby island of Crete, further leading some to believe that this may have been the catastrophe that inspired the Atlantis legend.[60] Mount Vesuvius is the only active volcano on the European mainland, while others as Mount Etna and Stromboli are to be found on neighbouring islands. The region around Vesuvius including the Phlegraean Fields Caldera west of Naples are quite active[61] and constitute the most densely populated volcanic region in the world and eruptive event may occur within decades.[62]		Vesuvius itself is regarded as quite dangerous due to a tendency towards explosive (Plinian) eruptions.[63] It is best known for its eruption in AD 79 that led to the burying and destruction of the Roman cities of Pompeii and Herculaneum.		The large experience of member states and regional authorities has led to exchange on the international level with cooperation of NGOs, states, regional and municipality authorities and private persons.[64] The Greek–Turkish earthquake diplomacy is a quite positive example of natural hazards leading to improved relations of traditional rivals in the region after earthquakes in İzmir and Athens 1999. The European Union Solidarity Fund (EUSF) was set up to respond to major natural disasters and express European solidarity to disaster-stricken regions within all of Europe.[65] The largest amount of fund requests in the EU is being directed to forest fires, followed by floodings and earthquakes. Forest fires are, whether man made or natural, an often recurring and dangerous hazard in the Mediterranean region.[64] Also, tsunamis are an often underestimated hazard in the region. For example, the 1908 Messina earthquake and tsunami took more than 123,000 lives in Sicily and Calabria and is among the most deadly natural disasters in modern Europe.		Unlike the vast multidirectional Ocean currents in open Oceans within their respective Oceanic zones; biodiversity in the Mediterranean Sea is that of a stable one due to the subtle but strong locked nature of currents which affects favorably, even the smallest macroscopic type of Volcanic Life Form. The stable Marine ecosystem of the Mediterranean Sea and sea temperature provides a nourishing environment for life in the deep sea to flourish while assuring a balanced Aquatic ecosystem excluded from any external deep oceanic factors.		The opening of the Suez Canal in 1869 created the first salt-water passage between the Mediterranean and Red Sea. The Red Sea is higher than the Eastern Mediterranean, so the canal serves as a tidal strait that pours Red Sea water into the Mediterranean. The Bitter Lakes, which are hyper-saline natural lakes that form part of the canal, blocked the migration of Red Sea species into the Mediterranean for many decades, but as the salinity of the lakes gradually equalised with that of the Red Sea, the barrier to migration was removed, and plants and animals from the Red Sea have begun to colonise the Eastern Mediterranean. The Red Sea is generally saltier and more nutrient-poor than the Atlantic, so the Red Sea species have advantages over Atlantic species in the salty and nutrient-poor Eastern Mediterranean. Accordingly, Red Sea species invade the Mediterranean biota, and not vice versa; this phenomenon is known as the Lessepsian migration (after Ferdinand de Lesseps, the French engineer) or Erythrean invasion. The construction of the Aswan High Dam across the Nile River in the 1960s reduced the inflow of freshwater and nutrient-rich silt from the Nile into the Eastern Mediterranean, making conditions there even more like the Red Sea and worsening the impact of the invasive species.		Invasive species have become a major component of the Mediterranean ecosystem and have serious impacts on the Mediterranean ecology, endangering many local and endemic Mediterranean species. A first look at some groups of exotic species show that more than 70% of the non-indigenous decapods and about 63% of the exotic fishes occurring in the Mediterranean are of Indo Pacific origin,[66] introduced into the Mediterranean through the Suez Canal. This makes the Canal as the first pathway of arrival of "alien" species into the Mediterranean. The impacts of some lessepsian species have proven to be considerable mainly in the Levantine basin of the Mediterranean, where they are replacing native species and becoming a "familiar sight".		According to the International Union for Conservation of Nature definition, as well as Convention on Biological Diversity (CBD) and Ramsar Convention terminologies, they are alien species, as they are non-native (non-indigenous) to the Mediterranean Sea, and they are outside their normal area of distribution which is the Indo-Pacific region. When these species succeed in establishing populations in the Mediterranean sea, compete with and begin to replace native species they are "Alien Invasive Species", as they are an agent of change and a threat to the native biodiversity. In the context of CBD, "introduction" refers to the movement by human agency, indirect or direct, of an alien species outside of its natural range (past or present). The Suez Canal, being an artificial (man made) canal, is a human agency. Lessepsian migrants are therefore "introduced" species (indirect, and unintentional). Whatever wording is chosen, they represent a threat to the native Mediterranean biodiversity, because they are non-indigenous to this sea. In recent years, the Egyptian government's announcement of its intentions to deepen and widen the canal have raised concerns from marine biologists, fearing that such an act will only worsen the invasion of Red Sea species into the Mediterranean, facilitating the crossing of the canal for yet additional species.[67]		In recent decades, the arrival of exotic species from the tropical Atlantic has become a noticeable feature. Whether this reflects an expansion of the natural area of these species that now enter the Mediterranean through the Gibraltar strait, because of a warming trend of the water caused by global warming; or an extension of the maritime traffic; or is simply the result of a more intense scientific investigation, is still an open question. While not as intense as the "lessepsian" movement, the process may be scientific interest and may therefore warrant increased levels of monitoring.[citation needed]		By 2100 the overall level of the Mediterranean could rise between 3 to 61 cm (1.2 to 24.0 in) as a result of the effects of climate change.[68] This could have adverse effects on populations across the Mediterranean:		Coastal ecosystems also appear to be threatened by sea level rise, especially enclosed seas such as the Baltic, the Mediterranean and the Black Sea. These seas have only small and primarily east-west movement corridors, which may restrict northward displacement of organisms in these areas.[71] Sea level rise for the next century (2100) could be between 30 cm (12 in) and 100 cm (39 in) and temperature shifts of a mere 0.05–0.1 °C in the deep sea are sufficient to induce significant changes in species richness and functional diversity.[72]		Pollution in this region has been extremely high in recent years.[when?] The United Nations Environment Programme has estimated that 650,000,000 t (720,000,000 short tons) of sewage, 129,000 t (142,000 short tons) of mineral oil, 60,000 t (66,000 short tons) of mercury, 3,800 t (4,200 short tons) of lead and 36,000 t (40,000 short tons) of phosphates are dumped into the Mediterranean each year.[73] The Barcelona Convention aims to 'reduce pollution in the Mediterranean Sea and protect and improve the marine environment in the area, thereby contributing to its sustainable development.'[74] Many marine species have been almost wiped out because of the sea's pollution. One of them is the Mediterranean monk seal which is considered to be among the world's most endangered marine mammals.[75]		The Mediterranean is also plagued by marine debris. A 1994 study of the seabed using trawl nets around the coasts of Spain, France and Italy reported a particularly high mean concentration of debris; an average of 1,935 items per km2. Plastic debris accounted for 76%, of which 94% was plastic bags.[76]		Some of the world's busiest shipping routes are in the Mediterranean Sea. It is estimated that approximately 220,000 merchant vessels of more than 100 tonnes cross the Mediterranean Sea each year—about one third of the world's total merchant shipping. These ships often carry hazardous cargo, which if lost would result in severe damage to the marine environment.		The discharge of chemical tank washings and oily wastes also represent a significant source of marine pollution. The Mediterranean Sea constitutes 0.7% of the global water surface and yet receives 17% of global marine oil pollution. It is estimated that every year between 100,000 t (98,000 long tons) and 150,000 t (150,000 long tons) of crude oil are deliberately released into the sea from shipping activities.		Approximately 370,000,000 t (360,000,000 long tons) of oil are transported annually in the Mediterranean Sea (more than 20% of the world total), with around 250–300 oil tankers crossing the sea every day. Accidental oil spills happen frequently with an average of 10 spills per year. A major oil spill could occur at any time in any part of the Mediterranean.[72]		The Mediterranean Sea is arguably among the most culturally diverse block basin sea regions in the world, with a unique combination of pleasant climate, beautiful coastline, rich history and various cultures. The Mediterranean region is the most popular tourist destination in the world—attracting approximately one third of the world's international tourists.[citation needed]		Tourism is one of the most important sources of income for many Mediterranean countries regardless of the man-made geopolitical conflicts that harbour coastal nations. In that regard, authorities around the Mediterranean have made it a point to extinguish rising man-made chaotic zones that would affect the economies, societies in neighboring coastal countries, let alone shipping routes. Naval and rescue components in the Mediterranean Sea are considered one of the very best due to the quick intercooperation of various Naval Fleets within proximity of each other. Unlike the vast open Oceans, the closed nature of the Mediterranean Sea provides a much more adaptable naval initiative among the coastal countries to provide effective naval and rescue missions, considered the safest and regardless of any man-made or natural disaster.		Tourism also supports small communities in coastal areas and islands by providing alternative sources of income far from urban centers. However, tourism has also played major role in the degradation of the coastal and marine environment. Rapid development has been encouraged by Mediterranean governments to support the large numbers of tourists visiting the region each year. But this has caused serious disturbance to marine habitats such as erosion and pollution in many places along the Mediterranean coasts.		Tourism often concentrates in areas of high natural wealth, causing a serious threat to the habitats of endangered Mediterranean species such as sea turtles and monk seals. Reductions in natural wealth may reduce incentives for tourists to visit.[72]		Fish stock levels in the Mediterranean Sea are alarmingly low. The European Environment Agency says that more than 65% of all fish stocks in the region are outside safe biological limits and the United Nations Food and Agriculture Organisation, that some of the most important fisheries—such as albacore and bluefin tuna, hake, marlin, swordfish, red mullet and sea bream—are threatened.[date missing]		There are clear indications that catch size and quality have declined, often dramatically, and in many areas larger and longer-lived species have disappeared entirely from commercial catches.		Large open water fish like tuna have been a shared fisheries resource for thousands of years but the stocks are now dangerously low. In 1999, Greenpeace published a report revealing that the amount of bluefin tuna in the Mediterranean had decreased by over 80% in the previous 20 years and government scientists warn that without immediate action the stock will collapse.		Aquaculture is expanding rapidly—often without proper environmental assessment—and currently accounts for 30% of the fish protein consumed worldwide. The industry claims that farmed seafood lessens the pressure on wild fish stocks, yet many of the farmed species are carnivorous, consuming up to five times their weight in wild fish.		Mediterranean coastal areas are already over exposed to human influence, with pristine areas becoming ever scarcer. The aquaculture sector adds to this pressure, requiring areas of high water quality to set up farms. The installation of fish farms close to vulnerable and important habitats such as seagrass meadows is particularly concerning.		Beach of Hammamet, Tunisia		The beach of la Courtade in the Îles d'Hyères, France		Sardinia's south coast, Italy		Pretty Bay, Malta		Panoramic view of Piran, Slovenia		Panoramic view of Cavtat, Croatia		View of Neum, Bosnia and Herzegovina		A view of Sveti Stefan, Montenegro		Ksamil Islands, Albania		Navagio, Greece		Marmaris, Turquoise Coast, Turkey		Paphos, Cyprus		Burj Islam Beach, Latakia, Syria		A view of Raouché off the coast of Beirut, Lebanon		A view of Haifa, Israel		Coast of Alexandria, view From Bibliotheca Alexandrina, Egypt		Old city of Ibiza Town, Spain		Les Aiguades near Béjaïa, Algeria		El Jebha, a port town in Morocco		Europa Point, Gibraltar		Panoramic view of La Condamine, Monaco		Sunset at the Deir al-Balah beach, Gaza Strip		
A windwatt is a mudflat exposed as a result of wind action on water. They occur especially in the Western Pomerania Lagoon Area National Park on Germany's Baltic Sea coast. The term is German.[1]		Unlike the Wadden Sea along Europe's North Sea coast, the shallow water zones of the Western Pomerania Lagoon Area National Park are largely unaffected by oceanic tides. When there are strong winds in a certain direction, however, water is driven out of the lagoons (the so-called bodden) into the Baltic Sea, so that several particularly shallow areas of mud become exposed and dry out. The water flows back when the wind turns again.[1] These windwatts are a major source of food for migrating birds in the autumn. For the Crane, which cross Western Pomeranian bodden country during migration, the windwatts are one of the most important resting areas in Western Europe.		
Copenhagen[note 1] (Danish: København [købm̩ˈhɑwˀn] ( listen); Latin: Hafnia) is the capital and most populous city of Denmark. The city has a population of 763,908 (as of December 2016[update]), of whom 601,448 live in the Municipality of Copenhagen.[7][8] The larger urban area has a population of 1,280,371 (as of 1 January 2016[update]),[4] while the Copenhagen metropolitan area has just over 2 million inhabitants.[9] Copenhagen is situated on the eastern coast of the island of Zealand; another small portion of the city is located on Amager, and is separated from Malmö, Sweden, by the strait of Øresund. The Øresund Bridge connects the two cities by rail and road.		Originally a Viking fishing village founded in the 10th century, Copenhagen became the capital of Denmark in the early 15th century. Beginning in the 17th century it consolidated its position as a regional centre of power with its institutions, defences and armed forces. After suffering from the effects of plague and fire in the 18th century, the city underwent a period of redevelopment. This included construction of the prestigious district of Frederiksstaden and founding of such cultural institutions as the Royal Theatre and the Royal Academy of Fine Arts. After further disasters in the early 19th century when Nelson attacked the Dano-Norwegian fleet and bombarded the city, rebuilding during the Danish Golden Age brought a Neoclassical look to Copenhagen's architecture. Later, following the Second World War, the Finger Plan fostered the development of housing and businesses along the five urban railway routes stretching out from the city centre.		Since the turn of the 21st century, Copenhagen has seen strong urban and cultural development, facilitated by investment in its institutions and infrastructure. The city is the cultural, economic and governmental centre of Denmark; it is one of the major financial centres of Northern Europe with the Copenhagen Stock Exchange. Copenhagen's economy has seen rapid developments in the service sector, especially through initiatives in information technology, pharmaceuticals and clean technology. Since the completion of the Øresund Bridge, Copenhagen has become increasingly integrated with the Swedish province of Scania and its largest city, Malmö, forming the Øresund Region. With a number of bridges connecting the various districts, the cityscape is characterized by parks, promenades and waterfronts. Copenhagen's landmarks such as Tivoli Gardens, The Little Mermaid statue, the Amalienborg and Christiansborg palaces, Rosenborg Castle Gardens, Frederik's Church, and many museums, restaurants and nightclubs are significant tourist attractions.		Copenhagen is home to the University of Copenhagen, the Technical University of Denmark and Copenhagen Business School. The University of Copenhagen, founded in 1479, is the oldest university in Denmark. Copenhagen is home to the FC København and Brøndby football clubs. The annual Copenhagen Marathon was established in 1980. Copenhagen is one of the most bicycle-friendly cities in the world. The Copenhagen Metro launched in 2002 serves central Copenhagen while the Copenhagen S-train network connects central Copenhagen to its outlying boroughs. Serving roughly two million passengers a month, Copenhagen Airport, Kastrup, is the largest airport in the Nordic countries.		The name of the city reflects its origin as a harbour and a place of commerce. The original designation, from which the contemporary Danish name derives, was Køpmannæhafn, meaning "merchants' harbour", often simply Hafn or Havn ("harbour"). The literal English translation would be "Chapman's haven".[10] The English name for the city was adapted from its Low German name, Kopenhagen. The abbreviations Kbh. or Kbhvn are often used in Danish for København, and kbh. for københavnsk (of Copenhagen).[11]		The chemical element hafnium is named for Copenhagen (Latin name Hafnia), where it was discovered.[12][13] The bacterium Hafnia is also named after Copenhagen: Vagn Møller of the State Serum Institute in Copenhagen named it in 1954.[14]		Although the earliest historical records of Copenhagen are from the end of the 12th century, recent archaeological finds in connection with work on the city's metropolitan rail system revealed the remains of a large merchant's mansion near today's Kongens Nytorv from c. 1020. Excavations in Pilestræde have also led to the discovery of a well from the late 12th century. The remains of an ancient church, with graves dating to the 11th century, have been unearthed near where Strøget meets Rådhuspladsen.		These finds indicate that Copenhagen's origins as a city go back at least to the 11th century. Substantial discoveries of flint tools in the area provide evidence of human settlements dating to the Stone Age.[15] Many historians believe the town dates to the late Viking Age, and was possibly founded by Sweyn I Forkbeard.[16] The natural harbour and good herring stocks seem to have attracted fishermen and merchants to the area on a seasonal basis from the 11th century and more permanently in the 13th century.[17] The first habitations were probably centred on Gammel Strand (literally "old shore") in the 11th century or even earlier.[18]		The earliest written mention of the town was in the 12th century when Saxo Grammaticus in Gesta Danorum referred to it as Portus Mercatorum, meaning Merchants' Harbour or, in the Danish of the time, Købmannahavn.[19] Traditionally, Copenhagen's founding has been dated to Bishop Absalon's construction of a modest fortress on the little island of Slotsholmen in 1167 where Christiansborg Palace stands today.[20] The construction of the fortress was in response to attacks by Wendish pirates who plagued the coastline during the 12th century.[21] Defensive ramparts and moats were completed and by 1177 St. Clemens Church had been built. Attacks by the Germans continued, and after the original fortress was eventually destroyed by the marauders, islanders replaced it with Copenhagen Castle.[22]		In 1186, a letter from Pope Urban III states that the castle of Hafn (Copenhagen) and its surrounding lands, including the town of Hafn, were given to Absalon, Bishop of Roskilde 1158–1191 and Archbishop of Lund 1177–1201, by King Valdemar I. On Absalon's death, the property was to come into the ownership of the Bishopric of Roskilde.[17] Around 1200, the Church of Our Lady was constructed on higher ground to the northeast of the town, which began to develop around it.[17]		As the town became more prominent, it was repeatedly attacked by the Hanseatic League. As the fishing industry thrived in Copenhagen, particularly in the trade of herring, the city began expanding to the north of Slotsholmen.[21] In 1254, it received a charter as a city under Bishop Jakob Erlandsen[23] who garnered support from the local fishing merchants against the king by granting them special privileges.[24] In the mid 1330s, the first land assessment of the city was published.[24]		With the establishment of the Kalmar Union (1397–1523) between Denmark, Norway and Sweden, by about 1416 Copenhagen had emerged as the capital of Denmark when Eric of Pomerania moved his seat to Copenhagen Castle.[25][22] The University of Copenhagen was inaugurated on 1 June 1479 by King Christian I, following approval from Pope Sixtus IV.[26] This makes it the oldest university in Denmark and one of the oldest in Europe. Originally controlled by the Catholic Church, the university's role in society was forced to change during the Reformation in Denmark in the late 1530s.[26]		In disputes prior to the Reformation of 1536, the city which had been faithful to Christian II, who was Catholic, was successfully besieged in 1523 by the forces of Frederik I, who supported Lutheranism. Copenhagen's defences were reinforced with a series of towers along the city wall. After an extended siege from July 1535 to July 1536, during which the city supported Christian II's alliance with Malmö and Lübeck, it was finally forced to capitulate to Christian III. During the second half of the century, the city prospered from increased trade across the Baltic supported by Dutch shipping. Christoffer Valkendorff, a high-ranking statesman, defended the city's interests and contributed to its development.[17] The Netherlands had also become primarily Protestant, as were northern German states.		During the reign of Christian IV between 1588 and 1648, Copenhagen had dramatic growth as a city. On his initiative at the beginning of the 17th century, two important buildings were completed on Slotsholmen: the Tøjhus Arsenal and Børsen, the stock exchange. To foster international trade, the East India Company was founded in 1616. To the east of the city, inspired by Dutch planning, the king developed the district of Christianshavn with canals and ramparts. It was initially intended to be a fortified trading centre but ultimately became part of Copenhagen.[27] Christian IV also sponsored an array of ambitious building projects including Rosenborg Slot and the Rundetårn.[21] In 1658–59, the city withstood a siege by the Swedes under Charles X and successfully repelled a major assault.[27]		By 1661, Copenhagen had asserted its position as capital of Denmark and Norway. All the major institutions were located there, as was the fleet and most of the army. The defences were further enhanced with the completion of the Citadel in 1664 and the extension of Christianshavns Vold with its bastions in 1692, leading to the creation of a new base for the fleet at Nyholm.[27][28]		Copenhagen lost around 22,000 of its population of 65,000 to the plague in 1711.[29] The city was also struck by two major fires which destroyed much of its infrastructure.[22] The Copenhagen Fire of 1728 was the largest in the history of Copenhagen. It began on the evening of 20 October, and continued to burn until the morning of 23 October, destroying approximately 28% of the city, leaving some 20% of the population homeless. No less than 47% of the medieval section of the city was completely lost. Along with the 1795 fire, it is the main reason that few traces of the old town can be found in the modern city.[30][31]		A substantial amount of rebuilding followed. In 1733, work began on the royal residence of Christiansborg Palace which was completed in 1745. In 1749, development of the prestigious district of Frederiksstaden was initiated. Designed by Nicolai Eigtved in the Rococo style, its centre contained the mansions which now form Amalienborg Palace.[32] Major extensions to the naval base of Holmen were undertaken while the city's cultural importance was enhanced with the Royal Theatre and the Royal Academy of Fine Arts.[33]		In the second half of the 18th century, Copenhagen benefitted from Denmark's neutrality during the wars between Europe's main powers, allowing it to play an important role in trade between the states around the Baltic Sea. After Christiansborg was destroyed by fire in 1794 and another fire caused serious damage to the city in 1795, work began on the classical Copenhagen landmark of Højbro Plads while Nytorv and Gammel Torv were converged.[33]		On 2 April 1801, a British fleet under the command of Admiral Sir Hyde Parker defeated a Danish-Norwegian fleet anchored near Copenhagen. Vice-Admiral Horatio Nelson led the main attack.[34] He famously disobeyed Parker's order to withdraw, destroying many of the Dano-Norwegian ships before a truce was agreed.[35] Copenhagen is often considered to be Nelson's hardest-fought battle, surpassing even the heavy fighting at Trafalgar.[36] It was during this battle that Lord Nelson was said to have "put the telescope to the blind eye" in order not to see Admiral Parker's signal to cease fire.[37]		The Second Battle of Copenhagen (or the Bombardment of Copenhagen) (16 August – 5 September 1807) was from a British point of view a preemptive attack on Copenhagen, targeting the civilian population in order to seize the Dano-Norwegian fleet.[38] But from a Danish point of view the battle was a terror bombardment on their capital. Particularly notable was the use of incendiary Congreve rockets (containing phosphorus, which cannot be extinguished with water) that randomly hit the city. Few houses with straw roofs remained after the bombardment. The largest church, Vor frue kirke, was destroyed by the sea artillery. Several historians consider this battle the first terror attack against a major European city in modern times.[39][40]		The British landed 30,000 men, they surrounded Copenhagen and the attack continued for the next three days, killing some 2,000 civilians and destroying most of the city.[citation needed] The devastation was so great because Copenhagen relied on an old defence-line whose limited range could not reach the British ships and their longer-range artillery.[41]		Despite the disasters of the early 19th century, Copenhagen experienced a period of intense cultural creativity known as the Danish Golden Age. Painting prospered under C.W. Eckersberg and his students while C.F. Hansen and Gottlieb Bindesbøll brought a Neoclassical look to the city's architecture.[42] In the early 1850s, the ramparts of the city were opened to allow new housing to be built around The Lakes (Danish: Søerne) that bordered the old defences to the west. By the 1880s, the districts of Nørrebro and Vesterbro developed to accommodate those who came from the provinces to participate in the city's industrialization. This dramatic increase of space was long overdue, as not only were the old ramparts out of date as a defence system but bad sanitation in the old city had to be overcome. From 1886, the west rampart (Vestvolden) was flattened, allowing major extensions to the harbour leading to the establishment of the Freeport of Copenhagen 1892–94.[43] Electricity came in 1892 with electric trams in 1897. The spread of housing to areas outside the old ramparts brought about a huge increase in the population. In 1840, Copenhagen was inhabited by approximately 120,000 people. By 1901, it had some 400,000 inhabitants.[33]		By the beginning of the 20th century, Copenhagen had become a thriving industrial and administrative city. With its new city hall and railway station, its centre was drawn towards the west.[33] New housing developments grew up in Brønshøj and Valby while Frederiksberg became an enclave within the city of Copenhagen.[44] The northern part of Amager and Valby were also incorporated into the City of Copenhagen in 1901–02.[45]		As a result of Denmark's neutrality in the First World War, Copenhagen prospered from trade with both Britain and Germany while the city's defences were kept fully manned by some 40,000 soldiers for the duration of the war.[46]		In the 1920s there were serious shortages of goods and housing. Plans were drawn up to demolish the old part of Christianshavn and to get rid of the worst of the city's slum areas.[47] However, it was not until the 1930s that substantial housing developments ensued,[48] with the demolishment of one side of Christianhavn's Torvegade in order to build five large blocks of flats.[47]		During World War II in Denmark, Copenhagen was occupied by German troops along with the rest of the country from 9 April 1940 until 4 May 1945. German leader Adolf Hitler hoped that Denmark would be "a model protectorate"[49] and initially the Nazi authorities sought to arrive at an understanding with the Danish government. The 1943 Danish parliamentary election was also allowed to take place, with only the Communist Party excluded. But in August 1943, after the government's collaboration with the occupation forces collapsed, several ships were sunk in Copenhagen Harbor by the Royal Danish Navy to prevent their use by the Germans. Around that time the Nazis started to arrest Jews, although most managed to escape to Sweden.[50]		In 1945 Ole Lippman, leader of the Danish section of the Special Operations Executive, invited the British Royal Air Force to assist their operations by attacking Nazi headquarters in Copenhagen. Accordingly, Air Vice-Marshal Sir Basil Embry drew up plans for a spectacular precision attack on the Sicherheitsdienst and Gestapo building, the former offices of the Shell Oil Company. Political prisoners were kept in the attic to prevent an air raid, so the RAF had to bomb the lower levels of the building.[51]		The attack, known as "Operation Carthage", came on 22 March 1945, in three small waves. In the first wave, all six planes (carrying one bomb each) hit their target, but one of the aircraft crashed near Frederiksberg Girls School. Because of this crash four of the planes in the two following waves assumed the school was the military target, and aimed their bombs at the school leading to the death of 123 civilians (of which 87 were schoolchildren).[51] However, 18 of the 26 political prisoners in the Shell Building managed to escape while the Gestapo archives were completely destroyed.[51]		On 8 May 1945 Copenhagen was officially liberated by British troops commanded by Field Marshal Bernard Montgomery who supervised the surrender of 30,000 Germans situated around the capital.[52]		Shortly after the end of the war, an innovative urban development project known as the Finger Plan was introduced in 1947, encouraging the creation of new housing and businesses interspersed with large green areas along five "fingers" stretching out from the city centre along the S-train routes.[53][54] With the expansion of the welfare state and women entering the work force, schools, nurseries, sports facilities and hospitals were established across the city. As a result of student unrest in the late 1960s, the former Bådsmandsstræde Barracks in Christianshavn was occupied, leading to the establishment of Freetown Christiania in September 1971.[55]		Motor traffic in the city grew significantly and in 1972 the trams were replaced by buses. From the 1960s, on the initiative of the young architect Jan Gehl, pedestrian streets and cycle tracks were created in the city centre.[56] Activity in the port of Copenhagen declined with the closure of the Holmen naval base. Copenhagen Airport underwent considerable expansion, becoming a hub for the Nordic countries. In the 1990s, large-scale housing developments were realized in the harbour area and in the west of Amager.[48] The national library's Black Diamond building on the waterfront was completed in 1999.[57]		Since the summer of 2000, Copenhagen and the Swedish city of Malmö have been connected by the Øresund Bridge, which carries rail and road traffic. As a result, Copenhagen has become the centre of a larger metropolitan area spanning both nations. The bridge has brought about considerable changes in the public transport system and has led to the extensive redevelopment of Amager.[55] The city's service and trade sectors have developed while a number of banking and financial institutions have been established. Educational institutions have also gained importance, especially the University of Copenhagen with its 35,000 students.[58] Another important development for the city has been the Copenhagen Metro, the underground railway system which opened in 2000 with additions until 2007, transporting some 54 million passengers by 2011.[59]		On the cultural front, the lavish Copenhagen Opera House, a gift to the city from the shipping magnate Mærsk Mc-Kinney Møller on behalf of the A.P. Møller foundation, was completed in 2004.[60] In December 2009 Copenhagen gained international prominence when it hosted the worldwide climate meeting COP15.[61]		Copenhagen is part of the Øresund Region, which consists of Zealand, Lolland-Falster and Bornholm in Denmark and Scania in Sweden.[62] It is located on the eastern shore of the island of Zealand, partly on the island of Amager and on a number of natural and artificial islets between the two. Copenhagen faces the Øresund to the east, the strait of water that separates Denmark from Sweden, and which connects the North Sea with the Baltic Sea. The Swedish towns of Malmö and Landskrona lie on the Swedish side of the sound directly across from Copenhagen.[63] By road, Copenhagen is 42 kilometres (26 mi) northwest of Malmö, Sweden, 85 kilometres (53 mi) northeast of Næstved, 164 kilometres (102 mi) northeast of Odense, 295 kilometres (183 mi) east of Esbjerg and 188 kilometres (117 mi) southeast of Aarhus by sea and road via Sjællands Odde.[64]		The city centre lies in the area originally defined by the old ramparts, which are still referred to as the Fortification Ring (Fæstningsringen) and kept as a partial green band around it.[65] Then come the late 19th and early 20th century residential neighbourhoods of Østerbro, Nørrebro, Vesterbro and Amagerbro. The outlying areas of Kongens Enghave, Valby, Vigerslev, Vanløse, Brønshøj, Utterslev and Sundby followed from 1920 to 1960. They consist mainly of residential housing and apartments often enhanced with parks and greenery.[66]		The central area of the city consists of relatively low-lying flat ground formed by moraines from the last ice age while the hilly areas to the north and west frequently rise to 50 m (160 ft) above sea level. The slopes of Valby and Brønshøj reach heights of over 30 m (98 ft), divided by valleys running from the northeast to the southwest. Close to the centre are the Copenhagen lakes of Sortedams Sø, Peblinge Sø and Sankt Jørgens Sø.[66]		Copenhagen rests on a subsoil of flint-layered limestone deposited in the Danian period some 60 to 66 million years ago. Some greensand from the Selandian is also present. There are a few faults in the area, the most important of which is the Carlsberg fault which runs northwest to southeast through the centre of the city.[67] During the last ice age, glaciers eroded the surface leaving a layer of moraines up to 15 m (49 ft) thick.[68]		Amager Strandpark, which opened in 2005, is a 2 km (1 mi) long artificial island, with a total of 4.6 km (2.9 mi) of beaches. It is located just 15 minutes by bicycle or a few minutes by metro from the city centre.[69] In Klampenborg, about 10 kilometers from downtown Copenhagen, is Bellevue Beach. It is 700 metres (2,300 ft) long and has both lifeguards and freshwater showers on the beach.[70]		The beaches are supplemented by a system of Harbour Baths along the Copenhagen waterfront. The first and most popular of these is located at Islands Brygge and has won international acclaim for its design.[71]		Copenhagen is in the oceanic climate zone (Köppen: Cfb ).[72] Its weather is subject to low-pressure systems from the Atlantic which result in unstable conditions throughout the year. Apart from slightly higher rainfall from July to September, precipitation is moderate. While snowfall occurs mainly from late December to early March, there can also be rain, with average temperatures around the freezing point.[73]		June is the sunniest month of the year with an average of about eight hours of sunshine a day. July is the warmest month with an average daytime high of 21 °C. By contrast, the average hours of sunshine are less than two per day in November and only one and a half per day from December to February. In the spring, it gets warmer again with from four to six hours of sunshine per day from March to May. February is the driest month of the year.[74] Exceptional weather conditions can bring as much as 50 cm of snow to Copenhagen in a 24-hour period during the winter months[75] while summer temperatures have been known to rise to heights of 33 °C (91 °F).[76]		Because of Copenhagen's northern latitude, the number of daylight hours varies considerably between summer and winter. On the summer solstice, the sun rises at 04:26 and sets at 21:58, providing 17 hours 32 minutes of daylight. On the winter solstice, it rises at 08:37 and sets at 15:39 with 7 hours and 1 minute of daylight. There is therefore a difference of 10 hours and 31 minutes in the length of days and nights between the summer and winter solstices.[77]		According to Statistics Denmark, the urban area of Copenhagen (Hovedstadsområdet) consists of the municipalities of Copenhagen, Frederiksberg, Albertslund, Brøndby, Gentofte, Gladsaxe, Glostrup, Herlev, Hvidovre, Lyngby-Taarbæk, Rødovre, Tårnby and Vallensbæk as well as parts of Ballerup, Rudersdal and Furesø municipalities, along with the cities of Ishøj and Greve Strand.[4][80] They are located in the Capital Region (Region Hovedstaden). Municipalities are responsible for a wide variety of public services, which include land-use planning, environmental planning, public housing, management and maintenance of local roads, and social security. Municipal administration is also conducted by a mayor, a council, and an executive.[81]		Copenhagen Municipality is by far the largest municipality, with the historic city at its core. The seat of Copenhagen's municipal council is the Copenhagen City Hall (Rådhus), which is situated on City Hall Square. The second largest municipality is Frederiksberg, an enclave within Copenhagen Municipality.		Copenhagen Municipality is divided into ten districts (bydele):[82] Indre By, Østerbro, Nørrebro, Vesterbro/Kongens Enghave, Valby, Vanløse, Brønshøj-Husum, Bispebjerg, Amager Øst, and Amager Vest. Neighbourhoods of Copenhagen include Slotsholmen, Frederiksstaden, Islands Brygge, Holmen, Christiania, Carlsberg, Sluseholmen, Amagerbro, Ørestad, Nordhavnen, Bellahøj, Brønshøj, Ryparken, and Vigerslev.		Most of Denmark's top legal courts and institutions are based in Copenhagen. A modern style court of justice, Hof- og Stadsretten, was introduced in Denmark, specifically for Copenhagen, by Johann Friedrich Struensee in 1771.[83] Now known as the City Court of Copenhagen (Københavns Byret), it is the largest of the 24 city courts in Denmark with jurisdiction over the municipalities of Copenhagen, Dragør and Tårnby. With its 42 judges, it has a Probate Division, an Enforcement Division and a Registration and Notorial Acts Division while bankruptcy is handled by the Maritime and Commercial Court of Copenhagen.[84] Established in 1862, the Maritime and Commercial Court (Sø- og Handelsretten) also hears commercial cases including those relating to trade marks, marketing practices and competition for the whole of Denmark.[85] Denmark's Supreme Court (Højesteret), located in Christiansborg Palace on Prins Jørgens Gård in the centre of Copenhagen, is the country's final court of appeal. Handling civil and criminal cases from the subordinate courts, it has two chambers which each hear all types of cases.[86]		The Danish National Police and Copenhagen Police headquarters is situated in the Neoclassical-inspired Politigården building built in 1918–24 under architects Hack Kampmann and Holger Alfred Jacobsen. The building also contains administration, management, emergency department and radio service offices.[87] In their efforts to deal with drugs, the police have noted considerable success in the two special drug consumption rooms opened by the city where addicts can use sterile needles and receive help from nurses if necessary. Use of these rooms does not lead to prosecution; the city treats drug use as a public health issue, not a criminal one.[88]		The Copenhagen Fire Department forms the largest municipal fire brigade in Denmark with some 500 fire and ambulance personnel, 150 administration and service workers, and 35 workers in prevention.[89] The brigade began as the Copenhagen Royal Fire Brigade on 9 July 1687 under King Christian V. After the passing of the Copenhagen Fire Act on 18 May 1868, on 1 August 1870 the Copenhagen Fire Brigade became a municipal institution in its own right.[90] The fire department has its headquarters in the Copenhagen Central Fire Station which was designed by Ludvig Fenger in the Historicist style and inaugurated in 1892.[91]		Copenhagen is recognized as one of the most environmentally friendly cities in the world.[92] As a result of its commitment to high environmental standards, Copenhagen has been praised for its green economy, ranked as the top green city for the second time in the 2014 Global Green Economy Index (GGEI).[93][94] In 2001 a large offshore wind farm was built just off the coast of Copenhagen at Middelgrunden. It produces about 4% of the city's energy.[95] Years of substantial investment in sewage treatment have improved water quality in the harbour to an extent that the inner harbour can be used for swimming with facilities at a number of locations.[96]		Copenhagen aims to be carbon-neutral by 2025. Commercial and residential buildings are to reduce electricity consumption by 20 percent and 10 percent respectively, and total heat consumption is to fall by 20 percent by 2025. Renewable energy features such as solar panels are becoming increasingly common in the newest buildings in Copenhagen. District heating will be carbon-neutral by 2025, by waste incineration and biomass. New buildings must now be constructed according to Low Energy Class ratings and in 2020 near net-zero energy buildings. By 2025, 75% of trips should be made on foot, by bike, or by using public transit. The city plans that 20–30% of cars will run on electricity or biofuel by 2025. The investment is estimated at $472 million public funds and $4.78 billion private funds.[97]		The city's architectural planning authorities continue to take full account of these priorities. Special attention is given both to climate issues and efforts to ensure maximum application of low-energy standards. Priorities include sustainable drainage systems,[98] recycling rainwater, green roofs and efficient waste management solutions. In city planning, streets and squares are to be designed to encourage cycling and walking rather than driving.[99]		Copenhagen is the most populous city in Denmark and one of the most populous in the Nordic countries. For statistical purposes, Statistics Denmark considers the City of Copenhagen (Byen København) to consist of the Municipality of Copenhagen plus three adjacent municipalities, viz. Dragør, Frederiksberg, and Tårnby.[7] Their combined population stands at 763,908 (as of December 2016[update]).[8]		The Municipality of Copenhagen is by far the most populous in the country and one of the one of the most populous Nordic municipalities with 601,448 inhabitants (as of December 2016[update]).[4] There was a demographic boom in the 1990s and first decade of the 21st century, largely due to immigration to Denmark. According to figures from the first quarter of 2016, approximately 76% of the municipality's population was of Danish descent,[3] defined as having at least one parent who was born in Denmark and has Danish citizenship. Much of the remaining 24% were of a foreign background, defined as immigrants (18%) or descendants of recent immigrants (6%).[3] There are no official statistics on ethnic groups. The table to the right shows the most common countries of birth of Copenhagen residents.		According to Statistics Denmark, Copenhagen's urban area has a larger population of 1,280,371 (as of 1 January 2016[update]).[4] The urban area consists of the municipalities of Copenhagen and Frederiksberg plus 16 of the 20 municipalities of the former counties Copenhagen and Roskilde, though five of them only partially.[80] Metropolitan Copenhagen has a total of 2,016,285 inhabitants (as of 2016[update]).[4][9] The area of Metropolitan Copenhagen is defined by the Finger Plan.[100] Since the opening of the Øresund Bridge in 2000, commuting between Zealand and Scania in Sweden has increased rapidly, leading to a wider, integrated area. Known as the Øresund Region, it has 3.8 million inhabitants (of whom 2.5 million live in the Danish part of the region).[101]		With 58.1% a majority of those living in Copenhagen are members of the Lutheran Church of Denmark which is 1.2% lower than one year earlier according to 2017 figures.[102] The National Cathedral, the Church of Our Lady, is one of the dozens of churches in Copenhagen. There are also several other Christian communities in the city, of which the largest is Roman Catholic.[103]		Foreign migration to Copenhagen, rising over the last three decades, has contributed to increasing religious diversity; the Grand Mosque of Copenhagen, the first in Denmark, opened in 2014.[104] Islam is the second largest religion in Copenhagen, accounting for approximately 10% of the population.[105][106][107] While there are no official statistics, a significant portion of the estimated 175,000–200,000 Muslims in the country live in the Copenhagen urban area, with the highest concentration in Nørrebro and the Vestegnen.[108] There are also some 7,000 Jews in Denmark, most of them in the Copenhagen area where there are several synagogues.[109]		For a number of years, Copenhagen has ranked high in international surveys for its quality of life. Its stable economy together with its education services and level of social safety make it attractive for locals and visitors alike. Although it is one of the world's most expensive cities, it is also one of the most liveable with its public transport, facilities for cyclists and its environmental policies.[110] In elevating Copenhagen to "most liveable city" in 2013, Monocle pointed to its open spaces, increasing activity on the streets, city planning in favour of cyclists and pedestrians, and features to encourage inhabitants to enjoy city life with an emphasis on community, culture and cuisine.[111] Other sources have ranked Copenhagen high for its business environment, accessibility, restaurants and environmental planning.[112] However, Copenhagen ranks only 39th for student friendliness in 2012. Despite a top score for quality of living, its scores were low for employer activity and affordability.[113]		Copenhagen is the major economic and financial centre of Denmark. The city's economy is based largely on services and commerce. Statistics for 2010 show that the vast majority of the 350,000 workers in Copenhagen are employed in the service sector, especially transport and communications, trade, and finance, while less than 10,000 work in the manufacturing industries. The public sector workforce is around 110,000, including education and healthcare.[114] From 2006 to 2011, the economy grew by 2.5% in Copenhagen, while it fell by some 4% in the rest of Denmark.[115] In 2010, the wider Capital Region of Denmark had a gross domestic product (GDP) of €88,366 million, and the 15th largest GDP per capita of regions in the European Union.[116]		Several financial institutions and banks have headquarters in Copenhagen, including Alm. Brand, Danske Bank, Nykredit and Nordea Bank Danmark. The Copenhagen Stock Exchange (CSE) was founded in 1620 and is now owned by Nasdaq, Inc.. Copenhagen is also home to a number of international companies including A.P. Møller-Mærsk, Novo Nordisk, Carlsberg and Novozymes.[117] City authorities have encouraged the development of business clusters in several innovative sectors, which include information technology, biotechnology, pharmaceuticals, clean technology and smart city solutions.[118][119]		Life science is a key sector with extensive research and development activities. Medicon Valley is a leading bi-national life sciences cluster in Europe, spanning the Øresund Region. Copenhagen is rich in companies and institutions with a focus on research and development within the field of biotechnology,[120] and the Medicon Valley initiative aims to strengthen this position and to promote cooperation between companies and academia. Many major Danish companies like Novo Nordisk and Lundbeck, both of which are among the 50 largest pharmaceutical and biotech companies in the world, are located in this business cluster.[121]		Shipping is another import sector with Maersk, the world's largest shipping company, having their world headquarters in Copenhagen. The city has an industrial harbour, Copenhagen Port. Following decades of stagnation, it has experienced a resurgence since 1990 following a merger with Malmö harbour. Both ports are operated by Copenhagen Malmö Port (CMP). The central location in the Øresund Region allows the ports to act as a hub for freight that is transported onward to the Baltic countries. CMP annually receives about 8,000 ships and handled some 148,000 TEU in 2012.[122]		Copenhagen has some of the highest gross wages in the world.[123] High taxes mean that wages are reduced after mandatory deduction. A beneficial researcher scheme with low taxation of foreign specialists has made Denmark an attractive location for foreign labour. It is however also among the most expensive cities in Europe.[124][125]		Denmark's Flexicurity model features some of the most flexible hiring and firing legislation in Europe, providing attractive conditions for foreign investment and international companies looking to locate in Copenhagen.[126] In Dansk Industri's 2013 survey of employment factors in the ninety-six municipalities of Denmark, Copenhagen came in first place for educational qualifications and for the development of private companies in recent years, but fell to 86th place in local companies' assessment of the employment climate. The survey revealed considerable dissatisfaction in the level of dialogue companies enjoyed with the municipal authorities.[127]		Tourism is a major contributor to Copenhagen's economy, attracting visitors due to the city's harbour, cultural attractions and award-winning restaurants. Since 2009, Copenhagen has been one of the fastest growing metropolitan destinations in Europe.[128] Hotel capacity in the city is growing significantly. From 2009 to 2013, it experienced a 42% growth in international bed nights (total number of nights spent by tourists), tallying a rise of nearly 70% for Chinese visitors.[128] The total number of bed nights in the Capital Region surpassed 9 million in 2013, while international bed nights reached 5 million.[128]		In 2010, it is estimated that city break tourism contributed to DKK 2 billion in turnover. However, 2010 was an exceptional year for city break tourism and turnover increased with 29% in that one year.[129] 680,000 cruise passengers visited the port in 2015.[130]		The city's appearance today is shaped by the key role it has played as a regional centre for centuries. Copenhagen has a multitude of districts, each with its distinctive character and representing its own period. Other distinctive features of Copenhagen include the abundance of water, its many parks, and the bicycle paths that line most streets.[131]		The oldest section of Copenhagen's inner city is often referred to as Middelalderbyen (the medieval city).[132] However, the city's most distinctive district is Frederiksstaden, developed during the reign of Frederick V. It has the Amalienborg Palace at its centre and is dominated by the dome of Frederik's Church (or the Marble Church) and several elegant 18th-century Rococo mansions.[133] The inner city includes Slotsholmen, a little island on which Christiansborg Palace stands and Christianshavn with its canals.[134] Børsen on Slotsholmen and Frederiksborg Palace in Hillerød are prominent examples of the Dutch Renaissance style in Copenhagen. Around the historical city centre lies a band of congenial residential boroughs (Vesterbro, Inner Nørrebro, Inner Østerbro) dating mainly from late 19th century. They were built outside the old ramparts when the city was finally allowed to expand beyond its fortifications.[135]		Sometimes referred to as "the City of Spires", Copenhagen is known for its horizontal skyline, broken only by the spires and towers of its churches and castles. Most characteristic of all is the Baroque spire of the Church of Our Saviour with its narrowing external spiral stairway that visitors can climb to the top.[136] Other important spires are those of Christiansborg Palace, the City Hall and the former Church of St. Nikolaj that now houses a modern art venue. Not quite so high are the Renaissance spires of Rosenborg Castle and the "dragon spire" of Christian IV's former stock exchange, so named because it resembles the intertwined tails of four dragons.[137]		Copenhagen is recognised globally as an exemplar of best practice urban planning.[138] Its thriving mixed use city centre is defined by striking contemporary architecture, engaging public spaces and an abundance of human activity. These design outcomes have been deliberately achieved through careful replanning in the second half of the 20th century.		Recent years have seen a boom in modern architecture in Copenhagen[139] both for Danish architecture and for works by international architects. For a few hundred years, virtually no foreign architects had worked in Copenhagen, but since the turn of the millennium the city and its immediate surroundings have seen buildings and projects designed by top international architects. British design magazine Monocle named Copenhagen the World's best design city 2008.[140]		Copenhagen's urban development in the first half of the 20th century was heavily influenced by industrialisation. After World War II, Copenhagen Municipality adopted Fordism and repurposed its medieval centre to facilitate private automobile infrastructure in response to innovations in transport, trade and communication.[141] Copenhagen’s spacial planning in this time frame was characterised by the separation of land uses: an approach which requires residents to travel by car to access facilities of different uses.[142]		The boom in urban development and modern architecture has brought some changes to the city's skyline. A political majority has decided to keep the historical centre free of high-rise buildings, but several areas will see or have already seen massive urban development. Ørestad now has seen most of the recent development. Located near Copenhagen Airport, it currently boasts one of the largest malls in Scandinavia and a variety of office and residential buildings as well as the IT University and a high school.[143]		Copenhagen is a green city with many parks, both large and small. King's Garden (Kongens Have), the garden of Rosenborg Castle, is the oldest and most frequented of them all.[144] It was Christian IV who first developed its landscaping in 1606. Every year it sees more than 2.5 million visitors[145] and in the summer months it is packed with sunbathers, picnickers and ballplayers. It serves as a sculpture garden with both a permanent display and temporary exhibits during the summer months.[144] Also located in the city centre are the Botanical Gardens noted for their large complex of 19th-century greenhouses donated by Carlsberg founder J. C. Jacobsen.[146] Fælledparken at 58 ha (140 acres) is the largest park in Copenhagen.[147]		It is popular for sports fixtures and hosts several annual events including a free opera concert at the opening of the opera season, other open-air concerts, carnival and Labour Day celebrations, and the Copenhagen Historic Grand Prix, a race for antique cars. A historical green space in the northeastern part of the city is Kastellet, a well-preserved Renaissance citadel that now serves mainly as a park.[148] Another popular park is the Frederiksberg Gardens, a 32-hectare romantic landscape park. It houses a colony of tame grey herons and other waterfowl.[149] The park offers views of the elephants and the elephant house designed by world-famous British architect Norman Foster of the adjacent Copenhagen Zoo, the largest zoo in Denmark.[150] Langelinie, a park and promenade along the inner Øresund coast, is home to one of Copenhagen's most-visited tourist attractions, the Little Mermaid statue.[151]		In Copenhagen, many cemeteries double as parks, though only for the more quiet activities such as sunbathing, reading and meditation. Assistens Cemetery, the burial place of Hans Christian Andersen, is an important green space for the district of Inner Nørrebro and a Copenhagen institution. The lesser known Vestre Kirkegaard is the largest cemetery in Denmark (54 ha (130 acres)) and offers a maze of dense groves, open lawns, winding paths, hedges, overgrown tombs, monuments, tree-lined avenues, lakes and other garden features.[152]		It is official municipal policy in Copenhagen that by 2015 all citizens must be able to reach a park or beach on foot in less than 15 minutes.[153] In line with this policy, several new parks, including the innovative Superkilen in the Nørrebro district, have been completed or are under development in areas lacking green spaces.[154]		The historic centre of the city, Indre By or the Inner City, features many of Copenhagen's most popular monuments and attractions. The area known as Frederiksstaden, developed by Frederik V in the second half of the 18th century in the Rococo style, has the four mansions of Amalienborg, the royal residence, and the wide-domed Marble Church at its centre.[155] Directly across the water from Amalienborg, the recently completed Copenhagen Opera stands on the island of Holmen.[156] To the south of Frederiksstaden, the Nyhavn canal is lined with colourful houses from the 17th and 18th centuries, many now with lively restaurants and bars.[157] The canal runs from the harbour front to the spacious square of Kongens Nytorv which was laid out by Christian V in 1670. Important buildings include Charlottenborg Palace, famous for its art exhibitions, the Thott Palace (now the French embassy), the Royal Danish Theatre and the Hotel D'Angleterre, dated to 1755.[158] Other landmarks in Indre By include the parliament building of Christiansborg, the City Hall and Rundetårn, originally an observatory. There are also several museums in the area including Thorvaldsen Museum dedicated to the 18th-century sculptor Bertel Thorvaldsen.[159] Closed to traffic since 1964, Strøget, the world's oldest and longest pedestrian street, runs the 3.2 km (2.0 mi) from Rådhuspladsen to Kongens Nytorv. With its speciality shops, cafés, restaurants, and buskers, it is always full of life and includes the old squares of Gammel Torv and Amagertorv, each with a fountain.[160] Rosenborg Castle on Øster Voldgade was built by Christian IV in 1606 as a summer residence in the Renaissance style. It houses the Danish crown jewels and crown regalia, the coronation throne and tapestries illustrating Christian V's victories in the Scanian War.[161]		Christianshavn lies to the southeast of Indre By on the other side of the harbour. The area was developed by Christian IV in the early 17th century. Impressed by the city of Amsterdam, he employed Dutch architects to create canals within its ramparts which are still well preserved today.[27] The canals themselves, branching off the central Christianshavn Canal and lined with house boats and pleasure craft are one of the area's attractions. Another interesting feature is Freetown Christiania, a fairly large area which was initially occupied by squatters during student unrest in 1971. Today it still maintains a measure of autonomy. The inhabitants openly sell drugs on "Pusher Street" as well as their arts and crafts. Other buildings of interest in Christianshavn include the Church of Our Saviour with its spiralling steeple and the magnificent Rococo Christian's Church. Once a warehouse, the North Atlantic House now displays culture from Iceland and Greenland and houses the Noma restaurant, known for its Nordic cuisine.[162][163]		Vesterbro, to the southwest of Indre By, begins with the Tivoli Gardens, the city's top tourist attraction with its fairground atmosphere, its Pantomime Theatre, its Concert Hall and its many rides and restaurants.[164] The Carlsberg neighbourhood has some interesting vestiges of the old brewery of the same name including the Elephant Gate and the Ny Carlsberg Brewhouse.[165] The Tycho Brahe Planetarium is located on the edge of Skt. Jørgens Sø, one of the Copenhagen lakes.[166] Halmtorvet, the old haymarket behind the Central Station, is an increasingly popular area with its cafés and restaurants. The former cattle market Øksnehallen has been converted into a modern exhibition centre for art and photography.[167] Radisson Blu Royal Hotel, built by Danish architect and designer Arne Jacobsen for the airline Scandinavian Airlines System (SAS) between 1956 and 1960 was once the tallest hotel in Denmark with a height of 69.60 m (228.3 ft) and the city's only skyscraper until 1969.[168] Completed in 1908, Det Ny Teater (the New Theatre) located in a passage between Vesterbrogade and Gammel Kongevej has become a popular venue for musicals since its reopening in 1994, attracting the largest audiences in the country.[169]		Nørrebro to the northwest of the city centre has recently developed from a working-class district into a colourful cosmopolitan area with antique shops, ethnic food stores and restaurants. Much of the activity is centred on Sankt Hans Torv.[170] Copenhagen's historic cemetery, Assistens Kirkegård halfway up Nørrebrogade, is the resting place of many famous figures including Søren Kierkegaard, Niels Bohr, and Hans Christian Andersen but is also used by locals as a park and recreation area.[171]		Just north of the city centre, Østerbro is an upper middle-class district with a number of fine mansions, some now serving as embassies.[172] The district stretches from Nørrebro to the waterfront where The Little Mermaid statue can be seen from the promenade known as Langelinie. Inspired by Hans Christian Andersen's fairy tale, it was created by Edvard Eriksen and unveiled in 1913.[173] Not far from the Little Mermaid, the old Citadel (Kastellet) can be seen. Built by Christian IV, it is one of northern Europe's best preserved fortifications. There is also a windmill in the area.[174] The large Gefion Fountain (Gefionspringvandet) designed by Anders Bundgaard and completed in 1908 stands close to the southeast corner of Kastellet. Its figures illustrate a Nordic legend.[175]		Frederiksberg, a separate municipality within the urban area of Copenhagen, lies to the west of Nørrebro and Indre By and north of Vesterbro. Its landmarks include Copenhagen Zoo founded in 1869 with over 250 species from all over the world and Frederiksberg Palace built as a summer residence by Charles IV who was inspired by Italian architecture. Now a military academy, it overlooks the extensive landscaped Frederiksberg Gardens with its follies, waterfalls, lakes and decorative buildings.[176] The wide tree-lined avenue of Frederiksberg Allé connecting Vesterbrogade with the Frederiksberg Gardens has long been associated with theatres and entertainment. While a number of the earlier theatres are now closed, the Betty Nansen Theatre and Aveny-T are still active.[177]		Not far from Copenhagen Airport on the Kastrup coast, The Blue Planet completed in March 2013 now houses the national aquarium. With its 53 aquariums, it is the largest facility of its kind in Scandinavia.[178] Grundtvig's Church, located in the northern suburb of Bispebjerg, was designed by P.V. Jensen Klint and completed in 1940. A rare example of Expressionist church architecture, its striking west façade is reminiscent of a church organ.[179]		Apart from being the national capital, Copenhagen also serves as the cultural hub of Denmark and wider Scandinavia. Since the late 1990s, it has undergone a transformation from a modest Scandinavian capital into a metropolitan city of international appeal in the same league as Barcelona and Amsterdam.[180] This is a result of huge investments in infrastructure and culture as well as the work of successful new Danish architects, designers and chefs.[139][181] Copenhagen Fashion Week, the largest fashion event in Northern Europe, takes place every year in February and August.[182][183]		Copenhagen has a wide array of museums of international standing. The National Museum, Nationalmuseet, is Denmark's largest museum of archaeology and cultural history, comprising the histories of Danish and foreign cultures alike.[184] Denmark's National Gallery (Statens Museum for Kunst) is the national art museum with collections dating from the 12th century to the present. In addition to Danish painters, artists represented in the collections include Rubens, Rembrandt, Picasso, Braque, Léger, Matisse, Emil Nolde, Olafur Eliasson, Elmgreen and Dragset, Superflex and Jens Haaning.[185]		Another important Copenhagen art museum is the Ny Carlsberg Glyptotek founded by second generation Carlsberg philanthropist Carl Jacobsen and built around his personal collections. Its main focus is classical Egyptian, Roman and Greek sculptures and antiquities and a collection of Rodin sculptures, the largest outside France. Besides its sculpture collections, the museum also holds a comprehensive collection of paintings of Impressionist and Post-Impressionist painters such as Monet, Renoir, Cézanne, van Gogh and Toulouse-Lautrec as well as works by the Danish Golden Age painters.[186]		Louisiana is a museum of modern art situated on the coast just north of Copenhagen. It is located in the middle of a sculpture garden on a cliff overlooking Øresund. Its collection of over 3,000 items includes works by Picasso, Giacometti and Dubuffet.[187] The Danish Design Museum is housed in the 18th-century former Frederiks Hospital and displays Danish design as well as international design and crafts.[188]		Other museums include: the Thorvaldsens Museum, dedicated to the oeuvre of romantic Danish sculptor Bertel Thorvaldsen who lived and worked in Rome;[189] the Cisternerne museum dedicated to modern glass art, located in former cisterns that come complete with stalactites formed by the changing water levels;[190] and the Ordrupgaard Museum, located just north of Copenhagen, which features 19th-century French and Danish art and is noted for its works by Paul Gauguin.[191]		The new Copenhagen Concert Hall opened in January 2009. Designed by Jean Nouvel, it has four halls with the main auditorium seating 1,800 people. It serves as the home of the Danish National Symphony Orchestra and along with the Walt Disney Concert Hall in Los Angeles is the most expensive concert hall ever built.[192] Another important venue for classical music is the Tivoli Concert Hall located in the Tivoli Gardens.[193] Designed by Henning Larsen, the Copenhagen Opera House (Operaen) opened in 2005. It is among the most modern opera houses in the world.[194] The Royal Danish Theatre also stages opera in addition to its drama productions. It is also home to the Royal Danish Ballet. Founded in 1748 along with the theatre, it is one of the oldest ballet troupes in Europe, and is noted for its Bournonville style of ballet.[195]		Copenhagen has a significant jazz scene that has existed for many years. It developed when a number of American jazz musicians such as Ben Webster, Thad Jones, Richard Boone, Ernie Wilkins, Kenny Drew, Ed Thigpen, Bob Rockwell, Dexter Gordon, and others such as rock guitarist Link Wray came to live in Copenhagen during the 1960s. Every year in early July, Copenhagen's streets, squares, parks as well as cafés and concert halls fill up with big and small jazz concerts during the Copenhagen Jazz Festival. One of Europe's top jazz festivals, the annual event features around 900 concerts at 100 venues with over 200,000 guests from Denmark and around the world.[196]		The largest venue for popular music in Copenhagen is Vega in the Vesterbro district. It was chosen as "best concert venue in Europe" by international music magazine Live. The venue has three concert halls: the great hall, Store Vega, accommodates audiences of 1,550, the middle hall, Lille Vega, has space for 500 and Ideal Bar Live has a capacity of 250.[197] Every September since 2006, the Festival of Endless Gratitude (FOEG) has taken place in Copenhagen. This festival focuses on indie counterculture, experimental pop music and left field music combined with visual arts exhibitions.[198]		Copenhagen is home to the "K-Town" punk and hardcore music community. This community developed around the underground scene venue Ungdomshuset in the late 90's punk scene, with punk- and hardcore acts such as Snipers, Amdi Petersens Armé, Gorilla Angreb, Young Wasteners, and No Hope For The Kids emerging as significant bands.[199] The term "K-town" got international recognition within the punk-scene with the emergence of "K-Town" festivals. In 2001, the first of these was held in Ungdomshuset, on Jagtvej 69, Nørrebro, Copenhagen.[200] The festival temporarily moved to Freetown Christiania after Ungdomshuset was evicted from its original location until a new Ungdomshuset location was opened on Dortheavej 61.[201]		For free entertainment one can stroll along Strøget, especially between Nytorv and Højbro Plads, which in the late afternoon and evening is a bit like an impromptu three-ring circus with musicians, magicians, jugglers and other street performers.[202]		Most of Denmarks's major publishing houses are based in Copenhagen.[203] These include the book publishers Gyldendal and Akademisk Forlag and newspaper publishers Berlingske and Politiken (the latter also publishing books).[204][205] Many of the most important contributors to Danish literature such as Hans Christian Andersen (1805–1875) with his fairy tales, the philosopher Søren Kierkegaard (1813–1855) and playwright Ludvig Holberg (1684–1754) spent much of their lives in Copenhagen. Novels set in Copenhagen include Baby (1973) by Kirsten Thorup, The Copenhagen Connection (1982) by Barbara Mertz, Number the Stars (1989) by Lois Lowry, Miss Smilla's Feeling for Snow (1992) and Borderliners (1993) by Peter Høeg, Music and Silence (1999) by Rose Tremain, The Danish Girl (2000) by David Ebershoff, and Sharpe's Prey (2001) by Bernard Cornwell. Michael Frayn's 1998 play Copenhagen about the meeting between the physicists Niels Bohr and Werner Heisenberg in 1941 is also set in the city. On 15–18 August 1973, an oral literature conference took place in Copenhagen as part of the 9th International Congress of Anthropological and Ethnological Sciences.[206]		The Royal Library, belonging to the University of Copenhagen, is the largest library in the Nordic countries with an almost complete collection of all printed Danish books since 1482. Founded in 1648, the Royal Library is located at four sites in the city, the main one being on the Slotsholmen waterfront.[207] Copenhagen's public library network has over 20 outlets, the largest being the Central Library (Københavns Hovedbibliotek) on Krystalgade in the inner city.[208]		Copenhagen has a wide selection of art museums and galleries displaying both historic works and more modern contributions. They include Statens Museum for Kunst, i.e. the Danish national art gallery, in the Østre Anlæg park, and the adjacent Hirschsprung Collection specialising in the 19th and early 20th century. Kunsthal Charlottenborg in the city centre exhibits national and international contemporary art. Den Frie Udstilling near the Østerport Station exhibits paintings created and selected by contemporary artists themselves rather than by the official authorities. The Arken Museum of Modern Art is located in southwestern Ishøj.[209] Among artists who have painted scenes of Copenhagen are Martinus Rørbye (1803–1848),[210] Christen Købke (1810–1848)[211] and the prolific Paul Gustav Fischer (1860–1934).[212]		A number of notable sculptures can be seen in the city. In addition to The Little Mermaid on the waterfront, there are two historic equestrian statues in the city centre: Jacques Saly's Frederik V on Horseback (1771) in Amalienborg Square[213] and the statue of Christian V on Kongens Nytorv created by Abraham-César Lamoureux in 1688 who was inspired by the statue of Louis XIII in Paris.[214] Rosenborg Castle Gardens contains several sculptures and monuments including August Saabye's Hans Christian Andersen, Aksel Hansen's Echo, and Vilhelm Bissen's Dowager Queen Caroline Amalie.[215]		Copenhagen is believed to have invented the photomarathon photography competition, which has been held in the City each year since 1989.[216][217]		As of 2014[update], Copenhagen has 15 Michelin-starred restaurants, the most of any Scandinavian city.[218] The city is increasingly recognized internationally as a gourmet destination.[219] These include Den Røde Cottage, Formel B Restaurant, Grønbech & Churchill, Søllerød Kro, Kadeau, Kiin Kiin (Denmark's first Michelin-starred Asian gourmet restaurant), the French restaurant Kong Hans Kælder, Relæ, Restaurant AOC, Noma (short for Danish: nordisk mad, English: Nordic food) with two Stars and Geranium with three. Noma, was ranked as the Best Restaurant in the World by Restaurant in 2010, 2011, 2012, and again in 2014,[220] sparking interest in the New Nordic Cuisine.[221]		Apart from the selection of upmarket restaurants, Copenhagen offers a great variety of Danish, ethnic and experimental restaurants. It is possible to find modest eateries serving open sandwiches, known as smørrebrød – a traditional, Danish lunch dish; however, most restaurants serve international dishes.[222] Danish pastry can be sampled from any of numerous bakeries found in all parts of the city. The Copenhagen Baker's Association dates back to the 1290s and Denmark's oldest confectioner's shop still operating, Conditori La Glace, was founded in 1870 in Skoubogade by Nicolaus Henningsen, a trained master baker from Flensburg.[223]		Copenhagen has long been associated with beer. Carlsberg beer has been brewed at the brewery's premises on the border between the Vesterbro and Valby districts since 1847 and has long been almost synonymous with Danish beer production. However, recent years have seen an explosive growth in the number of microbreweries so that Denmark today has more than 100 breweries, many of which are located in Copenhagen. Some like Nørrebro Bryghus also act as brewpubs where it is also possible to eat on the premises.[224][225]		Copenhagen has one of the highest number of restaurants and bars per capita in the world.[226] The nightclubs and bars stay open until 5 or 6 in the morning, some even longer. Denmark has a very liberal alcohol culture and a strong tradition for beer breweries, although binge drinking is frowned upon and the Danish Police take driving under the influence very seriously.[227] Inner city areas such as Istedgade and Enghave Plads in Vesterbro, Sankt Hans Torv in Nørrebro and certain places in Frederiksberg are especially noted for their nightlife. Notable nightclubs include Bakken Kbh, ARCH (previously ZEN), Jolene, The Jane, Chateau Motel, KB3, At Dolores (previously Sunday Club), Rust, Vega Nightclub, Culture Box and Gefährlich, which also serves as a bar, café, restaurant, and art gallery.[228][229]		Copenhagen has several recurring community festivals, mainly in the summer. Copenhagen Carnival has taken place every year since 1982 during the Whitsun Holiday in Fælledparken and around the city with the participation of 120 bands, 2,000 dancers and 100,000 spectators.[230] Since 2010, the old B&W Shipyard at Refshaleøen in the harbour has been the location for Copenhell, a heavy metal rock music festival. Copenhagen Pride is a gay pride festival taking place every year in August. The Pride has a series of different activities all over Copenhagen, but it is at the City Hall Square that most of the celebration takes place. During the Pride the square is renamed Pride Square.[231] Copenhagen Distortion has emerged to be one of the biggest street festivals in Europe with 100.000 people joining to parties in the beginning of June every year.		Copenhagen has the two oldest amusement parks in the world.[232][233]		Dyrehavsbakken, a fair-ground and pleasure-park established in 1583, is located in Klampenborg just north of Copenhagen in a forested area known as Dyrehaven. Created as an amusement park complete with rides, games and restaurants by Christian IV, it is the oldest surviving amusement park in the world.[232] Pierrot (Danish: Pjerrot), a nitwit dressed in white with a scarlet grin wearing a boat-like hat while entertaining children, remains one of the park's key attractions. In Danish, Dyrehavsbakken is often abbreviated as Bakken. There is no entrance fee to pay and Klampenborg Station on the C-line, is situated nearby.[234]		The Tivoli Gardens is an amusement park and pleasure garden located in central Copenhagen between the City Hall Square and the Central Station. It opened in 1843, making it the second oldest amusement park in the world. Among its rides are the oldest still operating rollercoaster Rutschebanen from 1915 and the oldest ferris wheel still in use, opened in 1943.[235] Tivoli Gardens also serves as a venue for various performing arts and as an active part of the cultural scene in Copenhagen.[236]		Copenhagen has over 94,000 students enrolled in its largest universities and institutions: University of Copenhagen (38,867 students),[237] Copenhagen Business School (19,999 students),[238] Metropolitan University College and University College Capital (10,000 students each),[239] Technical University of Denmark (7,000 students),[240] KEA (c. 4,500 students),[241] IT University of Copenhagen (2,000 students) and Aalborg University – Copenhagen (2,300 students).[242]		The University of Copenhagen is Denmark's oldest university founded in 1479. It attracts some 1,500 international and exchange students every year. The Academic Ranking of World Universities placed it 30th in the world in 2016.[243]		The Technical University of Denmark is located in Lyngby in the northern outskirts of Copenhagen. In 2013, it was ranked as one of the leading technical universities in Northern Europe.[244] The IT University is Denmark's youngest university, a mono-faculty institution focusing on technical, societal and business aspects of information technology.[245]		The Danish Academy of Fine Arts has provided education in the arts for more than 250 years. It includes the historic School of Visual Arts, and has in later years come to include a School of Architecture, a School of Design and a School of Conservation.[246] Copenhagen Business School (CBS) is an EQUIS-accredited business school located in Frederiksberg.[247] There are also branches of both University College Capital and Metropolitan University College inside and outside Copenhagen.[248][249]		The city has a variety of sporting teams. The major football teams are the historically successful FC København[250] and Brøndby. FC København plays at Parken in Østerbro. Formed in 1992, it is a merger of two older Copenhagen clubs, B 1903 (from the inner suburb Gentofte) and KB (from Frederiksberg).[251] Brøndby plays at Brøndby Stadion in the inner suburb of Brøndbyvester. BK Frem is based in the southern part of Copenhagen (Sydhavnen, Valby). Other teams are FC Nordsjælland (from suburban Farum), Fremad Amager, B93, AB, Lyngby and Hvidovre IF.[252]		Copenhagen has several handball teams—a sport which is particularly popular in Denmark. Of clubs playing in the "highest" leagues, there are Ajax, Ydun, and HIK (Hellerup).[252] The København Håndbold women's club has recently been established.[253] Copenhagen also has ice hockey teams, of which three play in the top league, Rødovre Mighty Bulls, Herlev Eagles and Hvidovre Ligahockey all inner suburban clubs. Copenhagen Ice Skating Club founded in 1869 is the oldest ice hockey team in Denmark but is no longer in the top league.[254]		Rugby union is also played in the Danish capital with teams such as CSR-Nanok, Copenhagen Business School Sport Rugby, Frederiksberg RK, Exiles RUFC and Rugbyklubben Speed. Rugby league is now played in Copenhagen, with the national team playing out of Gentofte Stadion. The Danish Australian Football League, based in Copenhagen is the largest Australian rules football competition outside of the English-speaking world.[252][255]		Copenhagen Marathon, Copenhagen's annual marathon event, was established in 1980.[256] Round Christiansborg Open Water Swim Race is a 2-kilometre (1.2-mile) open water swimming competition taking place each year in late August.[257] This amateur event is combined with a 10-kilometre (6-mile) Danish championship.[258] In 2009 the event included a 10-kilometre (6-mile) FINA World Cup competition in the morning. Copenhagen hosted the 2011 UCI Road World Championships in September 2011, taking advantage of its bicycle-friendly infrastructure. It was the first time that Denmark had hosted the event since 1956, when it was also held in Copenhagen.[259]		The greater Copenhagen area has a very well established transportation infrastructure making it a hub in Northern Europe. Copenhagen Airport, opened in 1925, is Scandinavia's largest airport, located in Kastrup on the island of Amager. It is connected to the city centre by metro and main line railway services.[260] October 2013 was a record month with 2.2 million passengers, and November 2013 figures reveal that the number of passengers is increasing by some 3% annually, about 50% more than the European average.[261]		Copenhagen has an extensive road network including motorways connecting the city to other parts of Denmark and to Sweden over the Øresund Bridge.[262] The car is still the most popular form of transport within the city itself, representing two-thirds of all distances travelled. This can however lead to serious congestion in rush hour traffic.[263] Copenhagen is also served by a daily ferry connection to Oslo in Norway.[264] In 2012, Copenhagen Harbour handled 372 cruise ships and 840,000 passengers.[264]		The Copenhagen S-Train, Copenhagen Metro and the regional train networks are used by about half of the city's passengers, the remainder using bus services. Nørreport Station near the city centre serves passengers travelling by main-line rail, S-train, regional train, metro and bus. Some 750,000 passengers make use of public transport facilities every day.[262] Copenhagen Central Station is the hub of the DSB railway network serving Denmark and international destinations.[265]		The Danish capital is known as one of the most bicycle-friendly cities in the world, with bicycles actually outnumbering its inhabitants.[266][267] In 2012 some 36% of all working or studying city-dwellers cycled to work, school, or university. With 1.27 million km covered every working day by Copenhagen's cyclists (including both residents and commuters), and 75% of Copenhageners cycling throughout the year.[268] The city's bicycle paths are extensive and well used, boasting 400 kilometres (250 miles) of cycle lanes not shared with cars or pedestrians, and sometimes have their own signal systems – giving the cyclists a lead of a couple of seconds to accelerate.[267][269]		Promoting health is an extremely important issue for Copenhagen's municipal authorities. Central to its sustainability mission is its "Long Live Copenhagen" (Længe Leve København) scheme in which it has the goal of increasing the life expectancy of citizens, improving quality of life through better standards of health, and encouraging more productive lives and equal opportunities.[270] The city has targets to encourage people to exercise regularly and to reduce the number who smoke and consume alcohol.[270]		Copenhagen University Hospital forms a conglomerate of several hospitals in Region Hovedstaden and Region Sjælland, together with the faculty of health sciences at the University of Copenhagen; Rigshospitalet and Bispebjerg Hospital in Copenhagen belong to this group of university hospitals.[271] Rigshospitalet began operating in March 1757 as Frederiks Hospital,[272] and became state-owned in 1903. With 1,120 beds, Rigshospitalet has responsibility for 65,000 inpatients and approximately 420,000 outpatients annually. It seeks to be the number one specialist hospital in the country, with an extensive team of researchers into cancer treatment, surgery and radiotherapy.[273] In addition to its 8,000 personnel, the hospital has training and hosting functions. It benefits from the presence of in-service students of medicine and other healthcare sciences, as well as scientists working under a variety of research grants. The hospital became internationally famous as the location of Lars von Trier's television horror mini-series The Kingdom. Bispebjerg Hospital was built in 1913, and serves about 400,000 people in the Greater Copenhagen area, with some 3,000 employees.[274] Other large hospitals in the city include Amager Hospital (1997),[275] Herlev Hospital (1976),[276] Hvidovre Hospital (1970),[277] and Gentofte Hospital (1927).[278]		Many Danish media corporations are located in Copenhagen. DR, the major Danish public service broadcasting corporation collected their activities in a new headquarters, DR Byen, in 2006 and 2007. Similarly TV2 which is based in Odense has concentrated its Copenhagen activities in a modern media house in Teglholmen.[279] The two national daily newspapers Politiken and Berlingske Tidende and the two tabloids Ekstra Bladet and B.T. are based in Copenhagen.[280] Kristeligt Dagblad is based in Copenhagen and is published six days a week.[281] Other important media corporations include Aller Media which is the largest publisher of weekly and monthly magazines in Scandinavia,[282] the Egmont media group[283] and Gyldendal, the largest Danish publisher of books.[284]		Copenhagen also has a sizable film and television industry. Nordisk Film, established in Valby, Copenhagen in 1906 is the oldest continuously operating film production company in the world.[230] In 1992 it merged with the Egmont media group and currently runs the 17-screen Palads Cinema in Copenhagen. Filmbyen (movie city), located in a former military camp in the suburb of Hvidovre, houses several movie companies and studios. Among the movie companies is Zentropa, co-owned by Danish movie director Lars von Trier who is behind several international movie productions as well as a founding force behind the Dogme Movement.[285] CPH:PIX is Copenhagen's international feature film festival, established in 2009 as a fusion of the 20-year-old Natfilm festival and the four-year-old CIFF. The CPH:PIX festival takes place in mid-April. CPH:DOX is Copenhagen's international documentary film festival, every year in November. On top of its documentary film programme of over 100 films, CPH:DOX includes a wide event programme with dozens of events, concerts, exhibitions and parties all over town.[286]		Copenhagen is twinned or cooperating with several cities, including:		
Firth is a word in the Scots and English languages used to denote various coastal waters in Scotland and England. In mainland Scotland, it is used to refer to a large sea bay, or even a strait. In the Northern Isles, it more usually refers to a smaller inlet. It is linguistically cognate to fjord (both from Proto-Germanic *ferþuz) which has a more constrained sense in English. Bodies of water named "firths" tend to be more common on the east coast, or in the southwest of the country, although the Firth of Lorn is an exception to this. The Highland coast contains numerous estuaries, straits, and inlets of a similar kind, but not called "firth" (e.g. the Minch and Loch Torridon); instead, these are often called sea lochs. Before about 1850, the spelling "Frith" was more common.		A firth is generally the result of ice age glaciation and is very often associated with a large river, where erosion caused by the tidal effects of incoming sea water passing upriver has widened the riverbed into an estuary. Demarcation can be rather vague. The Firth of Clyde is sometimes thought to include the estuary as far upriver as Dumbarton, but the Ordnance Survey map shows the change from river to firth occurring off Port Glasgow, while locally the change is held to be at the Tail of the Bank where the river crosses a sandbar off Greenock at the junction to the Gare Loch, or even further west at Gourock point.		However, some firths are exceptions. The Cromarty Firth on the east coast of Scotland, for example, resembles a large loch with only a relatively small outlet to the sea and the Solway Firth and the Moray Firth are more like extremely large bays. The Pentland Firth is a strait rather than a bay or an inlet.						These are connected to, or form part of, the North Sea.		The Northern Isles were part of Norway until the 15th century, and retain many Norse names. In Shetland in particular, "firth" can refer to smaller inlets, although geo, voe and wick are as common. In Orkney, "wick" is common.		In the Scottish Gaelic language, linne is used to refer to most of the firths above; it is also applied to the Sound of Sleat, Crowlin Sound, Cuillin Sound, Sound of Jura, Sound of Raasay, and part of Loch Linnhe.		The following is a selection of other bodies of water in Scotland which are similar to various firths, but which are not termed such –		Likewise, in the Northern Isles, the words "firth" and "sound" are often used arbitrarily or interchangeably. Bluemull Sound for example, is very similar to some of the firths in the Shetland Islands.		
Eighty Mile Beach, also spelled Eighty-mile Beach or 80-mile Beach, lies along the north-west coast of Western Australia about half-way between the towns of Broome and Port Hedland. It is a beach some 220 kilometres (140 mi) in length,[1] forming the coastline where the Great Sandy Desert approaches the Indian Ocean. It is one of the most important sites for migratory shorebirds, or waders, in Australia, and is recognised as a wetland of international importance under the Ramsar Convention on Wetlands.[1]						The southern section of Eighty Mile Beach is part of the traditional territory of the Nyangumarta people, who maintain a strong connection to the area with many songs, stories and ceremonies associated with sites along and in the vicinity of the beach. In June 2009 the Federal Court of Australia determined that the Nyangumarta People were the valid native title holders of that section of the beach.[2] The judgement of the Court was delivered on country at Nyiyamarri Pukurl, a site adjacent to the Eighty Mile Beach Caravan Park.		Traditional ownership of the northern part of Eighty Mile Beach, within the vicinity of the Anna Plains pastoral lease, is shared between the Nyangumarta People and the Karajarri (or Garadjari) People. The two groups filed overlapping native title determination applications over the area, which were determined together on 25 May 2012.[3] The judgement of the Court was delivered on country at Talgarno, a former military site within the Anna Plains pastoral lease.		In the Karajarri language, Eighty Mile Beach is called Wender, meaning "a creaking noise", with reference to the sound of walking through dry sand. Many Aboriginal people with connections to the area now live at the Bidyadanga Community (formerly the La Grange Mission) and nearby at Frazier Downs. Several soaks, known as lirri, lie behind the beach and were traditionally important as sources of fresh water. Many of the soaks became Water Reserves on the Kimberley-De Grey Stock Route, which was used until the 1960s for long distance cattle-droving.[1]		The Talgarno military base, east of Anna Plains homestead, was important in the post-Second World War period for the monitoring and recovery of British Blue Streak rockets, test-fired from Woomera, South Australia. A gravel airstrip, artesian bores and concrete blockhouses remain. In 1999 the Department of Defence test-fired a missile from a site on Anna Plains, in connection with the development of the Jindalee over-the-horizon radar project.[1]		Because of its importance for shorebirds, Eighty Mile Beach is classified as an Important Bird Area (IBA) and is one of the principal shorebird study sites in north-western Australia. It regularly supports over 400,000 shorebirds, including over 1% of the global populations of bar-tailed godwits, eastern curlews, great knots, red knots, red-necked stints, grey-tailed tattlers, Terek sandpipers, pied oystercatchers, greater sand plovers, Oriental plovers, red-capped plovers and Oriental pratincoles, with irregular high counts of other species.[4] Since 1981 almost yearly expeditions by the Australasian Wader Studies Group have been banding and counting shorebirds there as part of a long-term program of monitoring the populations using the East Asian – Australasian Flyway. Since 1992 most birds caught have also been leg-flagged in order to discover their precise migration routes and staging sites.[5]		Eighty Mile Beach lies in the Shire of Broome in the Kimberley region of Western Australia, in the Dampierland bioregion. It extends south-west from Cape Missiessy 19°03′S 121°31′E﻿ / ﻿19.050°S 121.517°E﻿ / -19.050; 121.517 in a shallow curve to Cape Keraudren 19°58′S 119°46′E﻿ / ﻿19.967°S 119.767°E﻿ / -19.967; 119.767, with its midpoint at 19°37′S 120°59′E﻿ / ﻿19.617°S 120.983°E﻿ / -19.617; 120.983. The beach is about 100 m wide and has a gentle gradient. It consists of sand with a high proportion of shelly material, and experiences a very large tidal range with an amplitude of up to 9 m. The adjoining tidal mudflats vary from 1 to 5 km in width. On the landward side it is bordered by dunes, a narrow floodplain and, further inland, by a strip of pindan woodland or shrubland. Most of the land along the coast is covered by four large pastoral leases: Anna Plains, Mandora, Wallal and Pardoo, which are operated principally as cattle stations.[1]		The climate is semi-arid monsoonal with a hot wet summer and a warm dry winter. Median and mean annual rainfall are 327 mm and 341 mm respectively, with annual evaporation about 3500 mm. There is much variability in rainfall, with significant variation between years as well as the period when the bulk of the rain falls; much is contributed by tropical cyclones, especially from January to March.[1]		Some 1,750 square kilometres (680 sq mi) of the beach and adjoining land, as well as the Mandora Marsh, was designated Ramsar Site 480 on 7 June 1990.[1][6]		Mandora Marsh, also known as the Mandora Salt Marsh, is a diverse wetland complex based on a palaeo-river system. It lies on Mandora Station, with the western end some 30 km from Eighty Mile Beach, beginning on the inland side of the Great Northern Highway, at the western edge of the Great Sandy Desert, in which bioregion it lies. Although it is included in the Eighty Mile Beach Ramsar Site, its environmental values are somewhat different.		Along the beach, the primary dunes are stabilised by green birdflower and beach spinifex. Secondary parallel, calcareous dune ridges and swales commonly feature scattered dune wattle. Significant grasses include Whiteochloa airoides and the local endemic Triodia epactia, a resinous hummock-forming species. Inland grasslands have been strongly modified by intensive cattle grazing and are dominated by introduced buffel grass and birdwood grass.[1]		The principal conservation value of Eighty Mile Beach lies in the presence of very large numbers of shorebirds, for which it is one of the most important non-breeding and migratory stop-over areas in the East Asian – Australasian Flyway, regularly supporting more than 400,000 birds and especially important as a landfall for birds migrating southwards from their high latitude breeding grounds in northern Asia and Alaska to spend the austral summer in Australia. It is one of the most important sites in the world for the migration of great knot and it supports at least 1% of the flyway population (or 1% of the national population for non-migratory species) of 17 waders and the Caspian tern. The most abundant shorebird species at the beach are the great knot (up to 169,000 counted), bar-tailed godwit (110,000), and red knot (80,000). Other notable species include curlew sandpiper (60,000), red-necked stint (60,000), large sand plover (64,000) and Oriental plover (57,000) on the beach, sharp-tailed sandpiper (25,000) at both the beach and floodplain swamps, and little curlew (12,000) on the floodplain.[1]		Flatback turtles nest along Eighty-mile Beach at scattered locations between October and April. Coastal plains in the southern part of Anna Plains Station are a stronghold for Australian bustards and support high densities of red kangaroos. The western part of Wallal Downs has a dense population of euros.		Eighty Mile Beach is subject to a relatively low but increasing amount of tourism. A caravan park has been established on Wallal Downs at one of the access points to the beach, 250 km north of Port Hedland and 365 km south of Broome. It is used for fishing, seashell collecting and other beach-based recreation.[1]		Media related to Eighty Mile Beach at Wikimedia Commons		
Nottingham (/ˈnɒtɪŋəm/ ( listen) NOT-ing-əm) is a city and unitary authority area located in Nottinghamshire, England, located 128 miles (206 km) north of London, in the East Midlands.		Nottingham has links to the legend of Robin Hood and to the lace-making, bicycle (notably Raleigh bikes) and tobacco industries. It was granted its city charter in 1897 as part of Queen Victoria's Diamond Jubilee celebrations. Nottingham is a tourist destination; in 2011, visitors spent over £1.5 billion – the thirteenth highest amount in England's 111 statistical territories.[6]		In 2015, Nottingham had an estimated population of 321,550[7] with the wider urban area, which includes many of the city's suburbs, having a population of 915,977. Its urban area is the largest in the east Midlands and the second largest in the Midlands.[8] The population of the Nottingham/Derby metropolitan area is estimated to be 1,610,000.[4] Its metropolitan economy is the seventh largest in the United Kingdom with a GDP of $50.9bn (2014).[9] The city is also ranked as a sufficiency-level world city by the Globalization and World Cities Research Network.[10]		Nottingham has an award-winning public transport system,[11] including the largest publicly owned bus network in England[12] and is also served by Nottingham railway station and the modern Nottingham Express Transit tram system.		It is also a major sporting centre, and in October 2015 was named 'Home of English Sport'.[13] The National Ice Centre, Holme Pierrepont National Watersports Centre, and Trent Bridge international cricket ground are all based in or around the city, which is also the home of two professional league football teams; the world's oldest professional league club Notts County, and Nottingham Forest, famously two-time winners of the UEFA European Cup under Brian Clough in 1979 and 1980. The city also has professional rugby, ice hockey and cricket teams, and the Aegon Nottingham Open, an international tennis tournament on the ATP and WTA tours. This accolade came just over a year after Nottingham was named as the UK's first City of Football.[14]		On 11 December 2015, Nottingham was named a "City of Literature" by UNESCO, joining Norwich, Melbourne, Prague and Barcelona as one of only a handful in the world.[15] The title reflects Nottingham's literary heritage, with Lord Byron, D. H. Lawrence and Alan Sillitoe having links to the city, as well as a strong contemporary literary community, a thriving publishing industry and a vibrant poetry scene.[16]		It has two universities, the University of Nottingham and Nottingham Trent University, which are attended by over 70,610 students—with 43,765 at the University of Nottingham, and Nottingham Trent University having 26,845, according to the respective University websites.[17] [18]						The city predates Anglo-Saxon times and was known in Brythonic as Tigguo Cobauc, meaning Place of Caves (known also as "City of Caves"). In modern Welsh it is known poetically as Y Ty Ogofog and Irish as Na Tithe Uaimh "The Cavey Dwelling".[19] When it fell under the rule of a Saxon chieftain named Snot it became known as "Snotingaham"; the homestead of Snot's people (-inga = the people of; -ham = homestead).[20] Some authors derive "Nottingham" from Snottenga, caves, and ham, but "this has nothing to do with the English form".[21]		Nottingham Castle was constructed in 1068 on a sandstone outcrop by the River Leen. The Anglo-Saxon settlement was originally confined to the area today known as the Lace Market and was surrounded by a substantial defensive ditch and rampart, which fell out of use following the Norman Conquest and was filled by the time of the Domesday Survey (1086).[22] Following the Norman Conquest the Saxon settlement developed into the English Borough of Nottingham and housed a Town Hall and Law Courts. A settlement also developed around the castle on the hill opposite and was the French borough supporting the Normans in the castle. Eventually, the space between was built on as the town grew and the Old Market Square became the focus of Nottingham several centuries later.[22] Defences, consisted initially of a ditch and bank in the early 12th century. The ditch was later widened, in the mid 13th century, and a stone wall built around much of the perimeter of the town. A short length of the wall survives, and is visible at the northern end of Maid Marian Way, and is protected as a Scheduled Monument.[22]		On the return of Richard the Lionheart from the Crusades, the Castle was occupied by supporters of Prince John, including the Sheriff of Nottingham. It was besieged by Richard and, after a sharp conflict, was captured.[23] In the legends of Robin Hood, Nottingham Castle is the scene of the final showdown between the Sheriff and the hero outlaw.[24]		By the 15th century Nottingham had established itself as a centre of a thriving export trade in religious sculpture made from Nottingham Alabaster.[25] The town became a county corporate in 1449[26] giving it effective self-government, in the words of the charter, "for eternity". The Castle and Shire Hall were expressly excluded and remained as detached Parishes of Nottinghamshire.		One of those highly impressed by Nottingham in the late 18th century was the German traveller C. P. Moritz, who wrote in 1782, "Of all the towns I have seen outside London, Nottingham is the loveliest and neatest. Everything had a modern look, and a large space in the centre was hardly less handsome than a London square. A charming footpath leads over the fields to the highway, where a bridge spans the Trent. ... Nottingham ... with its high houses, red roofs and church steeples, looks excellent from a distance."[27]		During the Industrial Revolution, much of Nottingham's prosperity was founded on the textile industry; in particular, the city became an internationally important centre of lace manufacture. In 1831 citizens rioted in protest against the Duke of Newcastle's opposition to the Reform Act 1832, setting fire to his residence, Nottingham Castle.		In common with the UK textile industry, Nottingham's textile sector fell into decline in the decades following World War II.[citation needed] Little textile manufacture now takes place in Nottingham; however, many of the former industrial buildings in the Lace Market district have been restored and put to new uses.		Nottingham was one of the boroughs reformed by the Municipal Corporations Act 1835, and at that time consisted of the parishes of St Mary, St Nicholas and St Peter. It was expanded in 1877 by adding the parishes of Basford, Brewhouse Yard, Bulwell, Radford, Sneinton, Standard Hill, and parts of the parishes of West Bridgford, Carlton, Wilford (North Wilford). In 1889 Nottingham became a county borough under the Local Government Act 1888. City status was awarded as part of the Diamond Jubilee celebrations of Queen Victoria, being signified in a letter from the prime minister, the Marquess of Salisbury to the mayor, dated 18 June 1897. Nottingham was extended in 1933 by adding Bilborough and Wollaton, parts of the parishes of Bestwood Park and Colwick, and a recently developed part of the Beeston Urban District. A further boundary extension was granted in 1951 when Clifton and Wilford (south of the River Trent) were incorporated into the city.[28][29]		Electric trams were introduced to the city in 1901; they served the city for 35 years until the trolleybus network was begun in 1927. Trams were reintroduced after 68 years when a new network opened in 2004.[30]		In the sporting world, Nottingham is home to the world's oldest professional football club, Notts County, which was formed in 1862. The town's other football club, Nottingham Forest, had a period of success between 1977 and 1993 under manager Brian Clough, winning the First Division, four League Cups, a UEFA Super Cup and two European Cups.[31] During this time Forest signed Trevor Francis, Britain's first £1 million footballer, who joined the club in February 1979 from Birmingham City.[32]		The city was the site of race riots in 1958, centred on the St Ann's neighbourhood.[33]		During the second half of the 20th century Nottingham saw urban growth with the development of new public and private housing estates and new urban centres, which have engulfed former rural villages such as Bilborough, Wollaton, Gedling and Bramcote. South of the river there has also been expansion with new areas such as Edwalton and West Bridgford, adding to Nottingham's urban sprawl. Although this growth slowed towards the end of the century, the modern pressures for more affordable and council housing is back on the political agenda and there is now pressure on the Green Belt which surrounds the city.[citation needed]		Nottingham City Council is a unitary authority based at Nottingham Council House in Old Market Square. It consists of 55 councillors, representing 20 wards, who are elected every four years; the last elections being held on 7 May 2015.		The city also has a Lord Mayor who is selected by city councillors from among themselves. The position is ceremonial and has no formal power or authority.		The City of Nottingham's boundaries are tightly drawn and exclude several suburbs and satellite towns that are usually considered part of Greater Nottingham. The western suburbs of Beeston, Stapleford and Eastwood are administered by Broxtowe borough council. Further west still, the Nottingham urban district extends into Derbyshire where Ilkeston and Long Eaton are administered by Erewash borough council, and Ripley by Amber Valley. To the north, Hucknall is controlled by Ashfield district council, while in the east Arnold and Carlton form part of the borough of Gedling. South of the river, the suburb of West Bridgford lies in Rushcliffe, as do the outlying villages of Ruddington and Tollerton and the town of Bingham. In December 2011, Rushcliffe, was named one of the 20 most desirable places to live in the UK by the Halifax Building Society. It was one of only four places outside the south of the country to appear in the top 50.[34]		Nottingham has three UK parliamentary constituency seats within its boundaries. Nottingham North has been represented since 2017 by Labour MP Alex Norris, Nottingham East since 2010 by Labour MP Chris Leslie and Nottingham South since 2010 by Labour MP Lilian Greenwood.		Nottingham lies within the East Midlands European parliamentary constituency. In 2014, it elected five MEPs: Margot Parker (UKIP), Roger Helmer (UKIP), Andrew Lewer (Conservative), Emma McClarkin (Conservative) and Glenis Willmott (Labour).[35]		Emergency services are provided by Nottinghamshire Police, Nottinghamshire Fire and Rescue Service and East Midlands Ambulance Service.		Nottingham is situated on an area of low hills[36] along the lower valley of the River Trent, and is surrounded by the Sherwood Forest in the north, the Nottinghamshire, Derbyshire and Yorkshire Coalfield in the west, and the Trent and Belvoir Vales in the east and south.		There are weather-reporting stations close to Nottingham – the former "Nottingham Weather Centre", at Watnall, about 6 miles (10 km) north-west of the city centre; and the University of Nottingham's agricultural campus at Sutton Bonington, about 10 miles (16 km) to the south-west of the city centre. The highest temperature recorded in Nottingham (Watnall) stands at 34.6 °C (94.3 °F),[37] whilst at Sutton Bonington stands at 34.8 °C (94.6 °F)[38] both recorded on 3 August 1990, and the record high minimum temperature is 19.9 °C (67.8 °F)[39] recorded in August 2004. On average, a temperature of 25 °C (77 °F) or above is recorded on 11.0 days per year[40] at Watnall (1981–2010), and the warmest day of the year reaches an average of 29.4 °C (84.9 °F).[41]		For the period 1981–2010 Nottingham (Watnall) recorded on average 42.9 days of air frost per year,[42] and Sutton Bonington 47.1.[43] The lowest recorded temperature in Nottingham (Watnall) is −13.3 °C (8.1 °F) recorded in January 1963[44] and January 1987.[45] The record low maximum temperature is −6.3 °C (20.7 °F)[46] recorded in January 1963. For the period of 1981–2010, the coldest temperature of the year reaches an average of −6.6 °C (20.1 °F)[47] in Nottingham (Watnall).		The geographical centre of Nottingham is usually defined as the Old Market Square.[citation needed] The square is dominated by the Council House, which replaced the Nottingham Exchange Building, built in 1726. The Council House was built in the 1920s to display civic pride, ostentatiously using baroque columns and placing stone statues of two lions at the front to stand watch over the square. The Exchange Arcade, on the ground floor, is an upmarket shopping centre containing boutiques.		Tall office buildings line Maid Marian Way. The Georgian area around Oxford and Regent Streets is dominated by small professional firms. The Albert Hall faces the Gothic revival St Barnabas' Roman Catholic Cathedral by Pugin. Nottingham Castle and its grounds are located further south in the western third of the city. The central third descends from the University district in the north, past Nottingham Trent University's Gothic revival Arkwright Building. The University also owns many other buildings in this area. The Theatre Royal on Theatre Square, with its pillared façade, was built in 1865. King and Queen Streets are home to striking Victorian buildings designed by such architects as Alfred Waterhouse and Watson Fothergill.[citation needed]		To the south, is Broadmarsh Shopping Centre. The Canal-side further south of this is adjacent to Nottingham railway station and home to numerous redeveloped 19th-century industrial buildings, reused as bars and restaurants.[citation needed]		The eastern third of the city centre contains the Victoria Shopping Centre, built in the 1970s on the site of the demolished Victoria Railway Station. All that remains of the old station is the clock tower and the station hotel, now the Nottingham Hilton Hotel. The 250-foot-high Victoria Centre flats stand above the shopping centre and are the tallest buildings in the city. The eastern third contains Hockley Village. Hockley is where many of Nottingham's unique, independent shops are to be found. It is also home to two alternative cinemas.		The Lace Market area just south of Hockley has streets with four to seven-storey red brick warehouses, iron railings and red phone boxes.		Buildings have been converted into apartments, bars and restaurants. Adams Building, built by Thomas Chambers Hine for Thomas Adams (1817–1873), is currently used by New College Nottingham. The Georgian-built Shire Hall is home to the Galleries of Justice and was Nottingham's main court and prison building.		Ye Olde Trip To Jerusalem (the Trip), partially built into the cave system beneath Nottingham Castle, is a contender for the title of England's Oldest Pub, as it is supposed to have been established in 1189.[52] The Bell Inn in the Old Market Square, and Ye Olde Salutation Inn (the Salutation) in Maid Marian Way have both disputed this claim. The Trip's current timber building probably dates back to the 17th or 18th century, but the caves are certainly older and may have been used to store beer and water for the castle during medieval times. There are also caves beneath the Salutation that date back to the medieval period, although they are no longer used as beer cellars. The Bell Inn is probably the oldest of the three pub buildings still standing, according to dendrochronology, and has medieval cellars that are still used to store beer.[53]		Over 61,000 students attend the city's two universities, Nottingham Trent University and the University of Nottingham, both of which have several campuses in the city. In 2011/12, Nottingham Trent University had 27,930 students, and the University of Nottingham had 35,630.[54] The University of Nottingham Medical School is part of the Queen's Medical Centre.[55]		Four further education colleges are located in Nottingham. Bilborough College is solely a sixth form college. Central College was formed from the merger of South Nottingham College and Castle College. New College was formed from a merger of four smaller further education colleges.[citation needed]. The Confetti Institute of Creative Technologies is a further education college that specialises in media, and is owned by Nottingham Trent University[56]. Nottingham also has dozens of sixth-form colleges and academies that provide education and training for adults aged over 16.[57]		Nottingham also has a number of independent schools, with Nottingham High School – which was founded in 1513[58][59] –being the city's oldest educational establishment.[citation needed]		In 2010, Nottingham City Council announced that as part of their economic development strategy for the city, their target sectors would include low-carbon technologies, digital media, life sciences, financial and business services and retail and leisure.[60]		Nottingham is home to the headquarters of several companies. One is Boots the Chemists (now Alliance Boots). Other large companies include Chinook Sciences, GM (cricket bats), Pedigree pet food company, American clothing VF Cooperation, Chinese-made automobiles Changan Automobile, the credit reference agency Experian, the energy company E.ON UK, the betting company Gala Group, the amusement and gambling-machine manufacturer Bell-Fruit-Games, the engineering company Siemens, the sportswear manufacturers Speedo, the high-street opticians Vision Express and Specsavers, the games and publishing company Games Workshop, the PC software developer Serif Europe (publisher of PagePlus and other titles), the Web hosting provider Heart Internet, the American credit card company Capital One, and the national law firm Browne Jacobson. Nottingham is also the home of the Nottingham Building Society (set up in 1849), the offices of HM Revenue and Customs, the Driving Standards Agency, BBC East Midlands offices, and formerly, the Government Office for the east Midlands.		Nottingham was made one of the UK's six science cities in 2005 by the then chancellor of the Exchequer (and later prime minister), Gordon Brown. Among the science-based industries within the city is BioCity. Founded as a joint venture between Nottingham Trent University and the University of Nottingham, it is the UK's biggest bioscience innovation and incubation centre, housing around 80 science-based companies.[61]		Until recently cycle manufacturing was a major industry, the city being the birthplace of Raleigh Cycles in 1886, later joined by Sturmey-Archer, the developer of three-speed hub gears. However, Raleigh's factory on Triumph Road, famous as the location for the filming of Saturday Night and Sunday Morning, was demolished in Summer 2003 to make way for the University of Nottingham's expansion of its Jubilee Campus. The schools and aerial photographers, H Tempest Ltd were Nottingham-based for many years, until relocating to St. Ives (Cornwall) around 1960.		Nottingham is also host to the UK's first and only local authority-owned and not-for-profit energy company; Robin Hood Energy.[62][63]		In 2015, Nottingham was also ranked as being in the top 10 UK cities for job growth (2004–13), in the public and private sectors.[64] And in the same year, it was revealed more new companies were started in Nottingham in 2014/15 than any other UK city, with a 68% year-on-year increase.[65]		In 2014, Nottingham came seventh in CACI's Retail Footprint rankings of retail expenditure in the UK, behind the West End of London, Glasgow, Birmingham, Manchester and Liverpool.[66] This is a slip of four places since 2010, primarily due to major developments in other parts of the UK and a relative lack of investment in Nottingham. However, this is likely to change as the owners of the two main shopping centres, Intu, have plans to upgrade and extend them both.[67]		There are two main shopping centres in Nottingham: the Victoria Centre and the Broadmarsh Centre. The Victoria Centre was established on the site of the former Nottingham Victoria railway station, and was the first to be built in the city, with parking for up to 2,400 cars on several levels, and a bus station.		Nottingham City Council, owners of the Broadmarsh Centre, have been attempting to redevelop it for "almost two decades".[68] Work on redeveloping Broadmarsh, at a cost of £400 million (creating 400 stores, 136,000 m2 of shopping space), was due to start in 2008.[citation needed] However, the downturn in the economy meant that redevelopment was delayed throughout from 2008 to 2010. In the light of the Victoria Centre's redevelopment plans, Westfield announced in 2011 that it was once again planning a £500 million development of Broadmarsh, which would start in 2012. This, however, did not take place either. Broadmarsh was finally sold to Capital Shopping Centres, the owners of the Victoria Centre. The purchase prompted an investigation by the Office of Fair Trading and the Competition Commission, who were concerned that the company's monopoly over the city's shopping centres could have a negative impact on competition.[69] CSC subsequently rebranded itself and the centres use the "Intu" name. Although the new owners wished to start the planned development of the Victoria Centre, Nottingham City Council insisted that Broadmarsh must have priority, with the Council offering £50 million towards its redevelopment.[70] The deputy leader of Nottingham City Council said the Council would withhold planning permission for the development of the Victoria Centre until they saw "bulldozers going into the Broadmarsh Centre."[68]		Smaller shopping centres in the city are The Exchange Arcade, the Flying Horse Walk and newer developments in Trinity Square and The Pod. The Bridlesmith Gate area has numerous designer shops, and is the home of the original Paul Smith boutique. There are various side streets and alleys that hide some interesting and often overlooked buildings and shops – such as Poultry Walk, West End Arcade and Hurts Yard. These are home to many specialist shops, as is Derby Road, near the Roman Catholic Cathedral and once the antiques area.		Nottingham has a number of department stores including the House of Fraser, John Lewis, and Debenhams.		In March 2011 the government announced the creation of Nottingham Enterprise Zone, an enterprise zone sited on part of the Boots Estate.[71] In March 2012 Nottingham Science Park, Beeston Business Park and Nottingham Medipark were added to the zone.[72] In December 2014 the government announced that the zone would be expanded again, to include Infinity Park Derby, a planned business park for aerospace, rail and automotive technology adjacent to the Rolls-Royce site in Sinfin, Derby.[73]		The Creative Quarter is a project started by Nottingham City Council as part of the Nottingham City Deal. Centred on the east of the city (including the Lace Market, Hockley, Broadmarsh East, the Island site and BioCity), the project aims at creating growth and jobs. In July 2012, the government contributed £25 million towards a £45 million venture capital fund, mainly targeted at the Creative Quarter.[74]		Nottingham has two large-capacity theatres, the Nottingham Playhouse and the Theatre Royal, which together with the neighbouring Royal Concert Hall forms the Royal Centre. The city also contains smaller theatre venues such as the Nottingham Arts Theatre, the Lace Market Theatre and New Theatre.		The city contains several notable museums and art galleries including:		There is a Cineworld and a Showcase in the city. Independent cinemas include the Arthouse Broadway Cinema in Hockley,[75] and the four-screen Art Deco Savoy Cinema[76] .		Nottingham has several large music and entertainment venues including the Royal Concert Hall, Rock City, Nottingham Royal Concert Hall (2,500-capacity) and the Nottingham Arena (Social centre). Nottingham's City Ground played host to rock band R.E.M. in 2005, the first time a concert had been staged at the football stadium.[77]		Nottingham also has a selection of smaller venues, including the Albert Hall (800-capacity), Ye Olde Salutation Inn, Malt Cross, Rescue Rooms, the Bodega, the Old Angel, the Central, the Maze, the Chameleon and the Corner. '60s Blues-rock band Ten Years After formed in Nottingham, as did the '70s pop act Paper Lace and the critically acclaimed Tindersticks. Since the beginning of the 2010s, the city has produced a number of artists to gain media attention, including; Jake Bugg, London Grammar, Indiana, Sleaford Mods, Natalie Duncan, Ady Suleiman, Dog Is Dead, Saint Raymond, Childhood, Rue Royale, Spotlight Kid and Amber Run.		The city has an active classical music scene, with long-established ensembles such as the city's Symphony Orchestra, Philharmonic Orchestra, Nottingham Harmonic Society, Bach Choir, Early Music Group Musica Donum Dei and the Symphonic Wind Orchestra giving regular performances in the city.[citation needed] The Sumac Centre is a social centre in Forest Fields.		Wollaton Park in Nottingham hosts an annual family-friendly music event called Splendour. In 2009 it was headlined by Madness and the Pogues. The following year it was headlined by the Pet Shop Boys and featured, among others, Calvin Harris, Noisettes, Athlete and OK Go.[78] In 2011 it featured headline acts Scissor Sisters, Blondie, Eliza Doolittle and Feeder. In 2012, performers included Dizzee Rascal, Razorlight, Katy B and Hard-Fi. In 2014, Wollaton Park hosted the first ever No Tomorrow Festival, featuring the likes of Sam Smith, London Grammar and Clean Bandit.[79]		Nottingham is known for hip hop.[80] Rofl Audio Recording Studios opened in 2013.[81]		The Hockley Arts Market runs alongside Sneinton Market.		There are several hundred restaurants in Nottingham, with there being several AA rosette winning restaurants in 2010[82] Iberico World Tapas, located in the city centre, was awarded a Bib Gourmand in the 2013 Michelin Guide.[83] Sat Bains, on the edge of the city, near Clifton Bridge, is a two-star Michelin restaurant.		In 2010, the city was named as one of the "Top 10 Cities to Visit in 2010" by DK Travel.[84] In 2013 it was estimated the city received 247,000 overseas visitors.[85]		There is a Robin Hood Pageant in Nottingham in October. The city is home to the Nottingham Robin Hood Society, founded in 1972 by Jim Lees and Steve and Ewa Theresa West.[86]		In February 2008, a Ferris wheel was put up in the Old Market Square and was an attraction of Nottingham City Council's "Light Night" on 8 February. The wheel returned to Nottingham in February 2009 to mark another night of lights, activities, illuminations and entertainment. Initially marketed as the Nottingham Eye, it was later redubbed as the Nottingham Wheel, to avoid any association with the London Eye.[87] It was seen again in 2010 and 2015.		Many local businesses and organisations use the worldwide fame of Robin Hood to represent or promote their brands. Many residents converse in the East Midlands dialect. The friendly term of greeting "Ay-up midduk" is a humorous example of the local dialect.[88] but with an unclear origin.		In 2015 the National Videogame Arcade was opened in the Hockley area of the city; being "the UK's first cultural centre for videogames".[89]		In 2013, Nottingham was named the most haunted city in England, reflecting its historical past.[90]		Nottingham has hosted an annual Asian Mela every summer since about 1989.[91] Nottingham also hosts a parade on St Patrick's Day,[92] Fireworks at the Chinese New Year, Holi in the Park celebrating Hinduism,[citation needed] a West Indian-style Carnival, and several Sikh events.[93]		Nottingham has featured in a number of fictional works.		Nottingham is home to two professional football clubs: Notts County and Nottingham Forest. Their two football grounds, on opposite sides of the River Trent, are noted for geographically being the closest in English league football. Notts County, formed in 1862, is the oldest professional football club in the world.[94] They were also among the Football League's founder members in 1888. For most of their history they have played their home games at Meadow Lane, which currently holds some 20,000 spectators, all seated. They currently play in Football League Two – the Fourth tier of English league football – and most recently played top division football in May 1992.[95] Nottingham Forest, who currently play in the Football League Championship, were English league champions in 1978 and won the European Cup twice over the next two seasons under the management of Brian Clough, who was the club's manager from January 1975 to May 1993, leading them to four Football League Cup triumphs in that time. They have played at the City Ground, on the south bank of the River Trent, since 1898. Nottingham Forest joined the Football League in 1892, four years after its inception when it merged with the rival Football Alliance, and 100 years later, they were among the FA Premier League's founder members in 1992 – though they have not played top division football since May 1999.[96] The City Ground played host to group stage games in the 1996 European Football Championships.[97]		Nottingham won the title of 2015 City of Football after five months of campaigning, which resulted in £1.6m in funding for local football ventures and to encourage more people to play the sport.[98] Nottingham was selected to be a host city for the England 2018 FIFA World Cup bid.[99] It was proposed that if the bid were successful, the city would have received a new Nottingham Forest Stadium.[100]		Nottinghamshire County Cricket Club play at Trent Bridge – an international cricket venue. The club were 2010 Cricket County Champions. Trent Bridge cricket ground is a host of Test Cricket, and was one of the venues for the 2009 ICC World Twenty20.		The Rugby team, Nottingham R.F.C., have played their home games at League One, Notts County's Meadow Lane stadium since 2006. In January 2015 they will play home matches at their training base, Lady Bay Sports Ground. Currently in the RFU Championship, if Nottingham are promoted to the Rugby Premiership they will return to Meadow Lane for home matches.[101] Nottingham Outlaws are an amateur Rugby League club who play in the Rugby League Conference National Division. The Nottingham Caesars who were formed in 1984 play in the British American Football League at the Harvey Hadden Stadium.		The city was the birthplace and training location for ice dancers Torvill and Dean, who won Gold at the 1984 Sarajevo Olympics. The National Ice Centre, opened by Bob the Builder, is a national centre for ice sports. The square in-front of the centre is named "Bolero Square" after Torvill and Dean's perfect 6.0 performance. Nottingham is home to the Nottingham Panthers ice hockey team.		Other sporting events in the city include the annual tennis Aegon Trophy (which is staged at the City of Nottingham Tennis Centre), the Robin Hood Marathon, Milk Race, the Great Nottinghamshire Bike Ride[102] and the Outlaw Triathlon.[103] Nottingham also has three Roller derby teams: Nottingham Roller Girls,[104] the Hellfire Harlots (women's teams)[105]		In October 2015, Nottingham was named as the official Home of Sport by VisitEngland for its contributions and recognition of the developments of the games of Football, Cricket, Ice Hockey in Britain, Boxing, Tennis and general Athletics, Gymnastics and Water sports.		Nottingham is served by East Midlands Airport (formerly known as Nottingham East Midlands Airport until it reverted to its original name), near Castle Donington in North West Leicestershire, just under 15 miles (24 km) south-west of the city centre.		Nottingham Station, the second busiest railway station in the Midlands for passenger entries and exits,[106] provides rail services for the city; with connections operated by CrossCountry, East Midlands Trains and Northern.		The reintroduction of trams in 2004 made Nottingham the newest of only six English cities to have a light rail system.[107] The trams run from the city centre to Hucknall in the north, with a spur to the Phoenix Park Park and Ride close to Junction 26 of the M1. Two new lines opened in 2015 extending the network to the southern suburbs of Wilford and Clifton and the western suburbs of Beeston and Chilwell.[108]		The city has the largest public bus network in the UK,[12] In September 2010, Nottingham was named "England's least car-dependent city" by the Campaign for Better Transport with London and Manchester in second and fourth place respectively.[109] In November 2010, Nottingham City Council won Transport Authority of the Year by the UK Bus Awards, for services for providing safer and sustainable public transport.[110][111]		Nottingham's waterways, now primarily used for leisure, have been extensively used for transport in the past.		Nottingham is served by Nottinghamshire Police and has a Crown Court and Magistrates' Court.		Laurie Macdonald of Inside One magazine observes that the city's former high crime rate earned it the nickname "Shottingham", but that by 2013 this image was outdated. The article was written in response to a uSwitch survey that had found south Nottinghamshire to be the fourth best place to live in the UK in terms of living standards. Crime in Nottingham had also fallen by three-quarters since 2007.[112]		Historically, the requirement for city status was the presence of a (Church of England) cathedral. Nottingham, however, does not have one, having only been designated a city in 1897, in celebration of Queen Victoria's Diamond Jubilee. From around AD 1100 Nottingham was part of the Diocese of Lichfield, controlled as an archdeaconry from Lichfield Cathedral in Staffordshire. However, in 1837 the archdeaconry was placed under the control of the Diocese of Lincoln. In 1884 it became part of the newly created Diocese of Southwell, which it, and the city, are still part of today. The bishop is based at Southwell Minster, 14 miles (23 km) north-east of the city.		Despite not having a cathedral, Nottingham has three notable historic Anglican parish churches, all of which date back to the Middle Ages. St. Mary the Virgin, in the Lace Market, is the oldest and largest. The church dates from the eighth or ninth centuries, but the present building is at least the third on the site, dating primarily from 1377 to 1485. St. Mary's is considered the mother church of the city and civic services are held here, including the welcome to the new Lord Mayor of Nottingham each year. It is a member of the Greater Churches Group. St. Peter's in the heart of the city is the oldest building in continuous use in Nottingham, with traces of building starting in 1180. St. Nicholas' is the third.		A variety of chapels and meeting rooms are in the town. Many of these grand buildings have been demolished, including Halifax Place Wesleyan Chapel, but some have been re-used, notably High Pavement Chapel which is now a public house. The national headquarters of the Congregational Federation is in Nottingham.		Nottingham is one of 18 British cities that do not have an Anglican cathedral.[113][114] It is, however, home to the Roman Catholic Cathedral of St. Barnabas, which was designed by Augustus Pugin and consecrated in 1844. It is the cathedral church for the Roman Catholic Diocese of Nottingham.		Today there are places of worship for all major religions, including Christianity and Islam with 32 Mosques in Nottingham.[115]		Nottingham has 30,000 Muslims, 15,000 Sikhs, 8,000 Hindus and 2,000 Jews.[116]		The ONS 2014 basis population projections indicate that the city is once again in a phase of steady population growth and that the 350,000 mark should be reached around 2030.		The city of Nottingham has a population at 312,900 with the Greater Nottingham population at 729,977 and the Metro population at 1,543,000. The city of Nottingham has a density of 4,073/km2.		65.4% are White British, 6.1% are European/North American, 13.1% Asian, 4.3% African, 1.6% Middle Eastern, 1.1% South/Central American and 8.2% of West Indian origins. Nottingham is a very multi-cultural city with people from 93 different countries and 101 spoken languages with cuisines, religious institutions/places of worship, businesses and supermarkets all over Nottingham especially situated in Hyson Green, Forest Fields, Carrington, Radford, Lenton, Meadows, Dunkirk, Rylands, St Ann's, Sneinton, Aspley, Broxtowe, City, Basford, Bakersfield, Carlton and Arnold.		The BBC has its East Midlands headquarters in Nottingham on London Road. BBC East Midlands Today is broadcast from the city every weeknight at 6.30 pm.		From 1983 to 2005 Central Television (the ITV region for the east Midlands) had a studio complex on Lenton Lane, producing programmes for various networks and broadcasting regional news.		The city was recently granted permission by Ofcom to set up its own local television station. After a tender process, Confetti College was awarded the licence. The station was declared open by Prince Harry in April 2013 and Notts TV began broadcast in spring 2014.[120]		In addition to the national commercial and BBC radio stations, the Nottingham area is served by licensed commercial radio stations (though all broadcast to a wider area than the city).		Radio stations include:		The city's two universities both broadcast their own student radio stations. Nottingham Trent University's FlyFM is based at the university's city campus and is broadcast online.[121] Nottingham University's University Radio Nottingham is broadcast around the main and Sutton Bonnington campuses on medium wave (AM), as well as over the internet.[122]		Nottingham's main local newspaper, the Nottingham Post, is owned by Northcliffe Media and is published daily from Monday to Saturday each week.		LeftLion magazine (established 2003) is distributed for free across the city. Covering Nottingham culture including music, art, theatre, comedy, food and drink.		Student tabloid The Tab also publishes online content and has teams at both universities.[123][124]		Nottingham has been used as a location in many locally, nationally, and internationally produced films. Movies that have been filmed (partly or entirely) in Nottingham include:[125]		Nottingham is twinned with the following cities:[126]		
Rotterdam (/ˈrɒtərdæm/ or /ˌrɒtərˈdæm/;[8][9] Dutch: [ˌrɔtərˈdɑm] ( listen)) is a city in the Netherlands, in South Holland within the Rhine–Meuse–Scheldt river delta at the North Sea. Its history goes back to 1270 when a dam was constructed in the Rotte river by people settled around it for safety. In 1340, Rotterdam was granted city rights by the Count of Holland.[10]		A major logistic and economic centre, Rotterdam is Europe's largest port and has a population of 633,471 (2017), the second-largest in the Netherlands, just behind Amsterdam.[11]		Rotterdam is known for the Erasmus University, its riverside setting, lively cultural life and maritime heritage. The near-complete destruction of the city centre in the World War II Rotterdam Blitz has resulted in a varied architectural landscape, including sky-scrapers, an uncommon sight in other Dutch cities, designed by renowned architects like Rem Koolhaas, Piet Blom and Ben van Berkel.[12][13]		Rotterdam's logistic success is based on its strategic location on the North Sea, at the mouth of the Nieuwe Maas channel leading into the Rhine–Meuse–Scheldt delta. The rivers Rhine, Meuse, and Scheldt give waterway access into the heart of Western Europe, including the highly industrialized Ruhr. The extensive distribution system including rail, roads, and waterways have earned Rotterdam the nicknames "Gateway to Europe" and "Gateway to the World".[14][15][16]						The settlement at the lower end of the fen stream Rotte (or Rotta, as it was then known, from rot, "muddy" and a, "water", thus "muddy water") dates from at least 900 CE. Around 1150, large floods in the area ended development, leading to the construction of protective dikes and dams, including Schielands Hoge Zeedijk ("Schieland’s High Sea Dike") along the northern banks of the present-day Nieuwe Maas. A dam on the Rotte was built in the 1260s and was located at the present-day Hoogstraat ("High Street").		On 7 July 1340, Count Willem IV of Holland granted city rights to Rotterdam, which then had approximately 2,000 inhabitants. Around the year 1350[citation needed], a shipping canal, the Rotterdamse Schie was completed, which provided Rotterdam access to the larger towns in the north, allowing it to become a local trans-shipment centre between the Netherlands, England and Germany, and to urbanize.		The port of Rotterdam grew slowly but steadily into a port of importance, becoming the seat of one of the six "chambers" of the Vereenigde Oostindische Compagnie (VOC), the Dutch East India Company.		The greatest spurt of growth, both in port activity and population, followed the completion of the Nieuwe Waterweg in 1872. The city and harbor started to expand on the south bank of the river. The Witte Huis or White House skyscraper,[17] inspired by American office buildings and built in 1898 in the French Château-style, is evidence of Rotterdam's rapid growth and success. When completed, it was the tallest office building in Europe, with a height of 45 m (147.64 ft).		During World War I the city was the world's largest spy centre because of Dutch neutrality and its strategic location in between Great-Britain, Germany and German-occupied Belgium. Many spies who were arrested and executed in Britain were led by German secret agents operating from Rotterdam. MI6 had its main European office on de Boompjes. From there the British coordinated espionage in Germany and occupied Belgium. During World War I, an average of 25,000 Belgian refugees lived in the city, as well as hundreds of German deserters and escaped Allied prisoners of war.[18]		During World War II, the German army invaded the Netherlands on 10 May 1940.[19] Adolf Hitler had hoped to conquer the country in just one day, but his forces met unexpectedly fierce resistance. The Dutch army was forced to capitulate on 15 May 1940, following the bombing of Rotterdam on 14 May and threatening to bomb other Dutch cities.[20][21][22] The heart of Rotterdam was almost completely destroyed by the Luftwaffe. Some 80,000 civilians were made homeless and 900 were killed; a relatively low number due to the fact that many had fled the city because of the warfare and bombing going on in Rotterdam since the start of the invasion three days earlier. The City Hall survived the bombing. Ossip Zadkine later attempted to capture the event with his statue De Verwoeste Stad ('The Destroyed City'). The statue stands near the Leuvehaven, not far from the Erasmusbrug in the centre of the city, on the north shore of the river Nieuwe Maas.		Rotterdam was gradually rebuilt from the 1950s through to the 1970s. It remained quite windy and open until the city councils from the 1980s on began developing an active architectural policy. Daring and new styles of apartments, office buildings and recreation facilities resulted in a more 'livable' city centre with a new skyline. In the 1990s, the Kop van Zuid was built on the south bank of the river as a new business centre. Rotterdam was voted 2015 European City of the Year by the Academy of Urbanism.[13]		'Rotterdam' is divided into a northern and a southern part by the river Nieuwe Maas, connected by (from west to east): the Beneluxtunnel; the Maastunnel; the Erasmusbrug ('Erasmus Bridge'); a subway tunnel; the Willemsspoortunnel ('Willems railway tunnel'); the Willemsbrug ('Willems Bridge'); the Koninginnebrug ('Queen's Bridge'); and the Van Brienenoordbrug ('Van Brienenoord Bridge'). The former railway lift bridge De Hef ('the Lift') is preserved as a monument in lifted position between the Noordereiland ('North Island') and the south of Rotterdam.		The city centre is located on the northern bank of the Nieuwe Maas, although recent urban development has extended the centre to parts of southern Rotterdam known as De Kop van Zuid ('the Head of South', i.e. the northern part of southern Rotterdam). From its inland core, Rotterdam reaches the North Sea by a swathe of predominantly harbour area.		Built mostly behind dikes, large parts of the Rotterdam are below sea level. For instance, the Prins Alexander Polder in the northeast of Rotterdam extends 6 metres (20 ft) below sea level, or rather below Normaal Amsterdams Peil (NAP) or 'Amsterdam Ordnance Datum'. The lowest point in the Netherlands (6.76 metres (22.2 ft) below NAP) is situated just to the east of Rotterdam, in the municipality of Nieuwerkerk aan den IJssel.		The Rotte river no longer joins the Nieuwe Maas directly. Since the early 1980s, when the construction of Rotterdam’s second subway line interfered with the Rotte’s course, its waters have been pumped through a pipe into the Nieuwe Maas via the Boerengat.		Between the summers of 2003 and 2008, an artificial beach was created at the Boompjeskade along the Nieuwe Maas, between the Erasmus Bridge and the Willems Bridge. Swimming was not possible, digging pits was limited to the height of the layer of sand, about 50 cm (20 in). Alternatively people go the beach of Hoek van Holland (which is a Rotterdam district) or one of the beaches in Zeeland: Renesse or the Zuid Hollandse Eilanden: Ouddorp, Oostvoorne.		Rotterdam forms the centre of the Rijnmond conurbation, bordering the conurbation surrounding The Hague to the north-west. The two conurbations are close enough to be a single conurbation. They share the Rotterdam The Hague Airport and a light rail system called RandstadRail. Consideration is being given to creating an official Metropolitan region Rotterdam The Hague (Metropoolregio Rotterdam Den Haag), which would have a combined population approaching 2.5 million.		On its turn, the Rijnmond conurbation is part of the southern wing (the Zuidvleugel) of the Randstad, which is one of the most important economic and densely populated areas in the north-west of Europe. Having a population of 7.1 million, the Randstad is the sixth-largest urban area in Europe (after Moscow, London, Paris, Istanbul, and the Rhein-Ruhr Area). The Zuidvleugel, situated in the province of South Holland, has a population of around 3 million.		Rotterdam experiences a temperate oceanic climate (Köppen climate classification Cfb) similar to all of the Netherlands. Located near to the coast, its climate is slightly milder than locations further inland.		Overall the demographics differ per city area. According to a recent area analysis, the city centre has a singles population of 70%, between the ages of 20 and 40,[citation needed] considerably more than other city areas. Also the city centre has a much larger population of people with higher education and higher income. Nonetheless, 80% of the homes are rented, not owned. The city centre also has a higher percentage (51% vs 45%) of foreign-born citizens. The majority (70%) of shops are also run by foreign-born citizens.[26]		On 1 January 2015 (source: Statistics Netherlands), the municipality covered an area of 319 km2 (206.44 km2 of which is land) with a population of 623,956. It is part of the Rotterdam The Hague Metropolitan Area with a total population of approximately 2.3 million. In 1965, the municipal population of Rotterdam reached its peak of 731,000, but by 1984 it had decreased to 555,000 as a result of suburbanization.[citation needed]		Rotterdam consists of 14 submunicipalities: Centrum, Charlois (including Heijplaat), Delfshaven, Feijenoord, Hillegersberg-Schiebroek, Hoek van Holland, Hoogvliet, IJsselmonde, Kralingen-Crooswijk, Noord, Overschie, Prins Alexander (the most populous submunicipality with around 85,000 inhabitants), and Rozenburg. One other area, Pernis, does have an official submunicipality status since 3 March 2010.		The current size of the municipality of Rotterdam is the result of the amalgamation of the following former municipalities,[27] some of which now are a submunicipality:		In the Netherlands, Rotterdam has the highest percentage of foreigners from non-industrialised nations. They form a large part of Rotterdam's multi ethnic and multicultural diversity. 50.3% of the population are of non Dutch origins or have at least one parent born outside the country. There are 80,000 Muslims, constituting 13% of the population.[28] The mayor of Rotterdam, Ahmed Aboutaleb, is of Moroccan descent and is a practicing Muslim. The city is home to the largest Dutch Antillean community. The city also has its own China Town at the West-Kruiskade, close to Rotterdam Centraal.		Religions in Rotterdam (2013)[29]		Christianity is the largest religion in Rotterdam, with 31.1% of the population identifying. The second and third largest religions are Islam (13.3%) and Hinduism (3.3%), while about half of the population has no religious affiliation.		Since 1795 Rotterdam has hosted the chief congregation of the liberal Protestant brotherhood of Remonstrants. From 1955 it has been the see of the bishop of Rotterdam when the Rotterdam diocese was split from the Haarlem diocese. Since 2010 the city is home to the largest mosque in the Netherlands, the Essalam mosque, (capacity 1,500).		Rotterdam has always been one of the main centres of the shipping industry in the Netherlands. From the Rotterdam Chamber of the VOC, the world's first multinational, established in 1602, to the merchant shipping leader Royal Nedlloyd established in 1970, with its corporate headquarters located in the landmark building the 'Willemswerf' in 1988.[citation needed] In 1997, Nedlloyd merged with the British shipping industry leader P&O forming the third largest merchant shipping company in the world. The Anglo-Dutch P&O Nedlloyd was bought by the Danish giant corporation 'AP Moller Maersk' in 2005 and its Dutch operations are still headquartered in the 'Willemswerf'.		Nowadays, well-known companies with headquarters in Rotterdam are consumers goods company Unilever, asset management firm Robeco, energy company Eneco, dredging company Van Oord, oil company Shell Downstream, terminal operator Vopak, commodity trading company Vitol and architecture firm Office for Metropolitan Architecture. It is also home to the regional headquarters of chemical company LyondellBasell, commodities trading company Glencore, pharmaceutical company Pfizer, logistics companies Stolt-Nielsen, electrical equipment company ABB Group and consumer goods company Procter & Gamble. Furthermore, Rotterdam has the Dutch headquarters of Allianz, Maersk, Petrobras, Samskip, Louis Dreyfus Group and Aon.		The City of Rotterdam makes use of the services of semi-government companies Roteb (to take care of sanitation, waste management and assorted services) and the Port of Rotterdam Authority (to maintain the Port of Rotterdam). Both these companies were once municipal bodies, now they are autonomous entities, owned by the City.		Being the largest port and one of the largest cities of the country, Rotterdam attracts many people seeking jobs, especially in the cheap labour segment. The city's unemployment rate is 12%, almost twice the national average.[30]		Together with Eindhoven (Brainport) and Amsterdam (Airport), Rotterdam (Seaport) forms the foundation of the Dutch economy.[31]		Rotterdam is the largest port in Europe, with the rivers Meuse and Rhine providing excellent access to the hinterland upstream reaching to Basel, Switzerland and into France. In 2004 Shanghai took over as the world's busiest port. In 2006, Rotterdam was the world's seventh largest container port in terms of twenty-foot equivalent units (TEU) handled.[32]		The port's main activities are petrochemical industries and general cargo handling and transshipment. The harbour functions as an important transit point for bulk materials and between the European continent and overseas. From Rotterdam goods are transported by ship, river barge, train or road. In 2007, the Betuweroute, a new fast freight railway from Rotterdam to Germany, was completed.		Well-known streets in Rotterdam are the Lijnbaan (the first set of pedestrian streets of the country, opened in 1953), the Hoogstraat, the Coolsingel with the city hall, and the Weena, which runs from the Central Station to the Hofplein (square). A modern shopping venue is the Beurstraverse ("Stock Exchange Traverse"), better known by its informal name 'Koopgoot' ('Buying/Shopping Gutter', after its subterranean position), which crosses the Coolsingel below street level). The Kruiskade is a more upscale shopping street, with retailers like Michael Kors, 7 For All Mankind, Calvin Klein, Hugo Boss, Tommy Hilfiger and the Dutch well known men's clothier Oger. Another upscale shopping venue is a flagship store of department store De Bijenkorf. Located a little more to the east is the Markthal, with lots of small retailers inside. This hall is also one of Rotterdam's famous architectural landmarks.		The main shopping venue in the south of Rotterdam is Zuidplein, which lies close to Rotterdam Ahoy, an accommodation center for shows, exhibitions, sporting events, concerts and congresses. Another prominent shopping center, called Alexandrium, lies in the east of Rotterdam. It includes a large kitchen and furniture center.		Rotterdam has one major university, the Erasmus University Rotterdam (EUR), named after one of the city's famous former inhabitants, Desiderius Erasmus. The Woudestein campus houses (among others) Rotterdam School of Management, Erasmus University. In Financial Times' 2005 rankings it placed 29th globally and 7th in Europe. In the 2009 rankings of Masters of Management, the school reached first place with the CEMS Master in Management and a tenth place with its RSM Master in Management.[33] The university is also home to Europe's largest student association, STAR Study Association Rotterdam School of Management, Erasmus University and the world's largest student association, AIESEC, has its international office in the city.		The Willem de Kooning Academy Rotterdam's main art school, which is part of the Hogeschool Rotterdam. It is regarded as one of the most prestigious art schools in the Netherlands and the number 1 in Advertising and Copywriting. Part of the Willem de Kooning Academy is the Piet Zwart Institute for postgraduate studies and research in Fine Art, Media Design and Retail Design. The Piet Zwart Institute boasts a selective roster of emerging international artists.		The Hoboken campus of EUR houses the Dijkzigt (general) hospital, the Sophia Hospital (for children) and the Medical Department of the University. These are known collectively as the Erasmus Medical Center. This is ranked third in Europe by CSIC [34] as a hospital, and is also ranked within top 50 universities of the world in the field of medicine (clinical, pre-clinical & health, 2017).[35]		There are also three Hogescholen (Universities of applied sciences) in Rotterdam. These schools award their students a professional Bachelor's degree and postgraduate or Master's degree. The three Hogescholen are Hogeschool Rotterdam, Hogeschool Inholland and Hogeschool voor Muziek en Dans (uni for music and dance) which is also known as CodArts.		As there are many international and American schools scattered across Europe such as ASH (American International School of the Hague) Rotterdam also has its own international/American school by the name AISR (American International School of Rotterdam). At AISR children receive a multicultural education in a culturally diverse community and it offers the International Baccalaureate (IB) Diploma Program.		Unique to the city is the Shipping & Transport College which offers masters, bachelors and vocational diplomas on all levels.		Alongside Porto, Rotterdam was European Capital of Culture in 2001. The city has its own orchestra, the Rotterdam Philharmonic, with its well-regarded young music director Yannick Nézet-Séguin; a large congress and concert building called De Doelen; several theaters (including the new Luxor) and movie theatres; and the Ahoy Rotterdam complex in the south of the city, which is used for pop concerts, exhibitions, tennis tournaments, and other activities. A major zoo called Diergaarde Blijdorp is situated at the northwest side of Rotterdam, complete with a walkthrough sea aquarium called the Oceanium. The city is home to the Willem de Kooning Academy and Piet Zwart Institute.		Rotterdam features some urban architecture projects, nightlife, and many summer festivals celebrating the city's multicultural population and identity, such as the Caribbean-inspired "Summer Carnival", the Dance Parade, Rotterdam 666, the Metropolis pop festival and the World Port days. In the years 2005–2011 the city struggled with venues for popmusic.[citation needed] Many of the venues suffered severe financial problems. This resulted in the disappearance of the major music venues Nighttown and WATT and smaller stages such as Waterfront, Exit, and Heidegger. Currently the city has a few venues for pop music like Rotown, Poortgebouw and Annabel. The venue WORM focuses on experimental music and related cutting edge subcultural music. There are also the International Film Festival in January, the Poetry International Festival in June, the North Sea Jazz Festival in July, the Valery Gergiev Festival in September, September in Rotterdam and the World of the Witte de With. In June 1970, The Holland Pop Festival (which featured Jefferson Airplane, The Byrds, Canned Heat, It's a Beautiful Day, and Santana) was held and filmed at the Stamping Grounds in Rotterdam.		There is a healthy competition with Amsterdam, which is often viewed as the cultural capital of the Netherlands. There is a saying: "Amsterdam to party, Den Haag (The Hague) to live, Rotterdam to work". Another one, more popular by Rotterdammers, is "Money is earned in Rotterdam, distributed in The Hague and spent in Amsterdam". Another saying that reflects both the rivalry between Rotterdam and Amsterdam is "Amsterdam has it, Rotterdam doesn't need it".[citation needed]		It is also the home of Gabber, a type of hardcore electronic music popular in the mid-1990s, with hard beats and samples. Groups like Neophyte and Rotterdam Terror Corps (RTC) started in Rotterdam.		The main cultural organisations in Amsterdam, such as the Concertgebouw and Holland Festival, have joint forces with similar organisations in Rotterdam, via A'R'dam. In 2007 these organisations published with plans for co-operation.[36] One of the goals is to strengthen the international position of culture and art in the Netherlands in the international context.		Rotterdam has many museums. Well known museums are the Museum Boijmans Van Beuningen, the Netherlands Architecture Institute, the Wereldmuseum, the Kunsthal, Witte de With Center for Contemporary Art[37] and the Maritime Museum Rotterdam.[38] The Historical Museum Rotterdam has changed into Museum Rotterdam which aims to exhibit Rotterdam as a contemporary transnational city, and not a past city.[39]		Other museums include the tax museum and the natural history museum. At the historical shipyard and museum Scheepswerf 'De Delft', the reconstruction of ship of the line Delft can be visited.[40]		In 1898, the 45-metre (148-foot) high-rise office building the White House (in Dutch Witte Huis) was completed, at that time the tallest office building in Europe. In the first decades of the 20th century, some influential architecture in the modern style was built in Rotterdam. Notable are the Van Nelle fabriek (1929) a monument of modern factory design by Brinkman en Van der Vlugt, the Jugendstil clubhouse of the Royal Maas Yacht Club designed by Hooijkaas jr. en Brinkman (1909), and Feyenoord's football stadium De Kuip (1936) also by Brinkman en Van der Vlugt. The architect J. J. P. Oud was a famous Rotterdammer in those days. The Van Nelle Factory obtained the status of UNESCO World Heritage Site in 2014. During the early stages of World War II the center of Rotterdam was bombed by the Germans, destroying many of the older buildings in the center of the city. After initial crisis re-construction the center of Rotterdam has become the site of ambitious new architecture.		Rotterdam is also famous for its Lijnbaan 1952 by architects Broek en Bakema, Peperklip by architect Carel Weeber, Kubuswoningen or cube houses designed by architect Piet Blom 1984.		The newest landmark in Rotterdam is the Markthal, designed by architect firm MVRDV. In addition to that there are many international well known architects based in Rotterdam like O.M.A (Rem Koolhaas), Neutelings & Riedijk and Erick van Egeraat to name a few. Two architectural landmarks are located in the Lloydkwartier: the STC college building and the Schiecentrale 4b.		Rotterdam also houses several of the tallest structures in the Netherlands.		Rotterdam has a reputation in being a platform for architectural development and education through the Berlage Institute, a postgraduate laboratory of architecture, and the NAi (Netherlands Architecture Institute), which is open to the public and has a variety of good exhibitions on architecture and urban planning issues.		Rotterdam has one of the best European Skylines together with Frankfurt, London, Madrid, Paris, Warsaw and Moscow. Over 30 new highrise projects are being developed at the moment.		Highrise buildings that are currently being built:		Rotterdam calls itself Sportstad (City of Sports). The city annually organises several world-renowned sporting events. Some examples are the Rotterdam Marathon, the World Port Tournament, and the Rotterdam World Tennis Tournament. Rotterdam also organises one race of the Red Bull Air Race World Championship and the car racing event Monaco aan de Maas (Monaco at the Meuse).		The city is also the home of many sports clubs and some historic and iconic athletes.		Rotterdam is the home of three professional football clubs, being first tier clubs Feyenoord, Excelsior and Sparta.		Feyenoord, founded in 1908 and the dominant of the three professional clubs, has won fifteen national titles since the introduction of professional football in the Netherlands. It won the European Cup (current Champions league) as the first Dutch club in 1970, and won the World Cup for club teams in the same year. In 1974, they were the first Dutch club to win the UEFA Cup and in 2002, Feyenoord won the UEFA Cup again. In 2008, the year of their 100-year-anniversary, Feyenoord won the KNVB-cup.		Seating 51,480, its 1931 stadium, called Stadion Feijenoord but popularly known as De Kuip ('the Tub'), is the second largest in the country, after the Amsterdam Arena. De Kuip, located in the southeast of the city, has hosted many international football games, including the final of Euro 2000 and has been awarded a FIFA 5 star ranking. There are concrete plans to build a new stadium with a capacity of at least 63,000 seats.		Sparta, founded in 1888 and situated in the northwest of Rotterdam, won the national title six times; Excelsior (founded 1902), in the northeast, has never won any.		Rotterdam also has three fourth tier clubs, SC Feijenoord (Feyenoord Amateurs), PVV DOTO and TOGR. Rotterdam is and has been the home to many great football players and coaches, among whom:		Rotterdam has its own annual international marathon, which offers one of the fastest courses in the world. From 1985 until 1998, the world record was set in Rotterdam, first by Carlos Lopes and later in 1988 by Belayneh Densamo.		In 1998, the world record for women was set by Tegla Loroupe, in a time of 2:20.47. Loroupe won the Rotterdam Marathon three consecutive times, from 1997 to 1999.		The current track record for men is held by Duncan Kibet, who ran a time of 2:04.27 in 2009. The female record was set in 2012, when Tiki Gelana finished the race in 2:18.58. Gelana went on to become the 2012 Olympic champion in London, a few months later.		The marathon starts and ends on the Coolsingel in the heart of Rotterdam. It attracts a total of 900.000 visitors.		Since 1972, Rotterdam hosts the indoor hard court ABN AMRO World Tennis Tournament, part of the ATP Tour. The event was first organised in 1972, when it was won by Arthur Ashe. Ashe went on to win the tournament two more times, making him the singles title record holder.		Former Wimbledon winner Richard Krajicek became the tournament director after his retirement in 2000. The latest edition of the tournament attracted a total of 116.354 visitors.[44]		In November 2008 Rotterdam was chosen as the host of the Grand Départ of the 2010 Tour de France. Rotterdam won the selection over the Dutch city of Utrecht. Germany's Düsseldorf had previously also expressed interest in hosting. The Amaury Sport Organization (ASO), organizer of the Tour de France, said in a statement on its web site that it chose Rotterdam because, in addition to it being another big city, like London, to showcase the use of bikes for urban transportation, it provided a location well positioned considering the rest of the route envisioned for the 2010 event.		The start in Rotterdam was the fifth in the Netherlands. The prologue was a 7 km (4.35 mi) individual time trial crossing the centre of the city. The first regular stage left the Erasmusbrug and went south, towards Brussels.		Members of the student rowing club Skadi were part of the 'Holland Acht', winning a gold medal at the Olympics in 1996.[citation needed]. Since the opening in April 2013, Rotterdam hosts the rowing venue Willem-Alexander Baan that hosted the 2016 World Rowing Championships for Seniors, U23 and Juniors.		In field hockey, Rotterdam has the largest hockey club in the Netherlands, HC Rotterdam, with its own stadium in the north of the city and nearly 2,400 members. The first men's and women's teams both play on the highest level in the Dutch Hoofdklasse.		Rotterdam is home to the most successful European baseball team, Neptunus Rotterdam, winning the most European Cups.		Rotterdam has a long boxing tradition starting with Bep van Klaveren (1907–1992), aka 'The Dutch Windmill', Gold medal winner of the 1928 Amsterdam Olympics, followed by professional boxers like Regilio Tuur and Don Diego Poeder.		Rotterdam's swimming tradition started with Marie Braun aka Zus (sister) Braun, who was coached to a Gold medal at the 1928 Amsterdam Olympics by her mother Ma Braun, and 3 European titles 3 years later in Paris. In her career as 14 time national champ, she broke 6 world records. Ma Braun later also coached the Rotterdam born, three-times Olympic champion Rie Mastenbroek during the Berlin Olympics in 1936. In later years Inge de Bruijn became a Rotterdam sport icon as triple Olympic Gold medal winner in 2000 and triple European Gold medal winner in 2001.		Motor cycle speedway was staged in the Feyenoord Stadium after the second world war. The team which raced in a Dutch league was known as the Feyenoord Tigers. The team included Dutch riders and some English and Australian riders.		Since 1986, the city has selected its best sportsman, woman and team at the Rotterdam Sports Awards Election, held in December.		Rotterdam hosts several annual events unique to the city. It hosts the Zomercarnaval (Summercarnaval), the second largest Caribbean carnival in Europe, originally called the Antillean carnival. Other events include: North Sea Jazz Festival, the largest Jazz festival in Europe, Bavaria City Race, a Formula 1 race inside the city center and a 3 day long maritime extravaganza called the World Port Days celebrating the Port of Rotterdam.		Rotterdam is well connected by international, national, regional and local public transport systems, as well as by the Dutch motorway network.		Motorways There are several motorways to/from Rotterdam. The following four are part of its 'Ring' (ring road):		The following two other motorways also serve Rotterdam:		Airport Much smaller than the international hub Schiphol Airport, Rotterdam The Hague Airport (formerly known as Zestienhoven) is the third largest airport in the country, behind Schiphol Airport and Eindhoven Airport. Located north of the city, it has shown a very strong growth over the past five years, mostly caused by the growth of the low-cost carrier market. For business travelers, Rotterdam The Hague Airport offers advantages in terms of rapid handling of passengers and baggage. Environmental regulations make further growth uncertain.		Train		Rotterdam is well connected to the Dutch railway network, and has several international connections:		Railway stations		The main connections:		In Rotterdam, public transport services are provided by the following companies:		Metro		In 1968, Rotterdam was the first Dutch city to open a metro system. Currently the metro system consists of three main lines, each of which has its own variants. The metro network has 78.3 km (48.7 mi) of railtracks and there are 62 stations, which makes it the biggest of the Benelux. The system is operated by 5 lines; 3 lines (A, B and C) on the east-west line, and two (D and E) on the north-south line. Line E (Randstadrail) connects Rotterdam with The Hague as of December 2011.		Tram		The Rotterdam tramway network offers 9 regular tram lines and 4 special tram lines with a total length of 93.4 km (58.0 mi). Service Tramlines in Rotterdam as of 2016[update]:		Special tram lines:		Bus Rotterdam offers 55 city bus lines with a total length of 432.7 km (268.9 mi).		RET runs buses in the city of Rotterdam and surrounding places like Spijkenisse, Barendrecht, Ridderkerk, Rhoon, Poortugaal, Schiedam, Vlaardingen, Delft and Capelle aan den IJssel. .		Arriva Netherlands, Connexxion and Veolia run buses from other cities to Rotterdam.		Waterbus The Waterbus network consists of seven lines. The main line (Line 20) stretches from Rotterdam to Dordrecht. The ferry carries about 130 passengers and there is space for 60 bicycles. The stops between Rotterdam and Dordrecht are:		Rotterdam has city and port connections throughout the world. In 2008, the city had 13 sister cities, 12 partner cities, and 4 sister ports.[52] Since 2008, the City of Rotterdam doesn't forge new sister or partner connections. Sister and partner cities are not a priority in international relations.[53]		On March 15, 2017 the Turkish president expressed his wish that Istanbul should no longer be the twin town of Rotterdam. A speaker of the Rotterdam municipality then explained that the two cities have no official partnership. Both authorities do cooperate often.[54]		Rotterdam is twinned with:		Rotterdam features in Edgar Allan Poe's short story ‘The Unparalleled Adventure of One Hans Pfaall’ (1835), as well as J.T. Sheridan Le Fanu's 'Strange Event in the Life of Schalken the Painter' (1839).[56]		Part of Jackie Chan's 1998 film 'Who am I?' is set in Rotterdam.		Ender's Shadow, part of the series Ender's Game is partially set in Rotterdam.		In season 1, episode 2 of The Golden Girls ("Guess Who's Coming to the Wedding?"), Dorothy reminisces how her ex-husband, Stan, would buy her tulips after they had a fight. "Towards the end, our house looked like Easter in Rotterdam."		In 1996, the British band The Beautiful South recorded a song named after this region titled Rotterdam (or Anywhere).,[57]		The 2017 Olivier award winning play, Rotterdam, written by Jon Brittain, is set in the city.		
A bay is a recessed, coastal body of water that directly connects to a larger main body of water, such as an ocean, lake, or another bay.[1][2][3] A large bay may be called a gulf, sea, sound, or bight. A cove is a type of smaller bay with a circular inlet and narrow entrance. A fjord is a particularly steep bay shaped by glacial activity.		Bays can be the estuary of a river, such as the Chesapeake Bay, an estuary of the Susquehanna River.[2] Bays may also be nested within each other; for example, James Bay is an arm of Hudson Bay in northeastern Canada. Some large bays, such as the Bay of Bengal and the Hudson Bay, have varied marine geology.		The land surrounding a bay often reduces the strength of winds and blocks waves. Bays were significant in the history of human settlement because they provided a safe place for fishing. Later they were important in the development of sea trade as the safe anchorage they provide encouraged their selection as ports.[4]		The United Nations Convention on the Law of the Sea (UNCLOS), also called the Law of the Sea defines a bay as a well-marked indentation whose penetration is in such proportion to the width of its mouth as to contain land-locked waters and constitute more than a mere curvature of the coast. An indentation shall not, however, be regarded as a bay unless its area is as large as, or larger than, that of the semi-circle whose diameter is a line drawn across the mouth of that indentation.		There are various ways from which bays can be created. The largest bays have developed as a result of plate tectonics.[4] As the super-continent Pangaea broke up along curved and indented fault lines, the continents moved apart and the world's largest bays formed. These include the Gulf of Guinea, Gulf of Mexico and the Bay of Bengal, which is the largest bay in the world.[4]		Another way bays form is via glacial and river erosion.[4] A bay formed by a glacier is a fjord. Rias are created by rivers and are characterised by more gradual slopes. Currents can make waves more constant, and soft rocks speed erosion. Hard rock eroded less quickly, leaving headlands. The Gulf of California is an example of a bay created by plate tectonics as Baja California peninsula moves away from the Mexican mainland.		
Coastal erosion is the wearing away of land and the removal of beach or dune sediments by wave action, tidal currents, wave currents, drainage or high winds (see also beach evolution). Waves, generated by storms, wind, or fast moving motor craft, can cause coastal erosion, which may take the form of long-term losses of sediment and rocks, or merely the temporary redistribution of coastal sediments; erosion in one location may result in accretion nearby. The study of erosion and sediment redistribution is called 'coastal morphodynamics'. It may be caused by hydraulic action, abrasion, impact and corrosion.		On non-rocky coasts, coastal erosion results in dramatic (or non-dramatic) rock formations in areas where the coastline contains rock layers or fracture zones with varying resistance to erosion. Softer areas become eroded much faster than harder ones, which typically result in landforms such as tunnels, bridges, columns, and pillars. Over time the coast generally evens out. The softer areas fill up with sediment eroded from hard areas, and rock formations are eroded away.[1] Also abrasion commonly happens in areas where there are strong winds, loose sand, and soft rocks. The blowing of millions of sharp sand grains creates a sandblasting effect. This effect helps to erode, smooth and polish rocks. The definition of abrasion is grinding and wearing away of rock surfaces through the mechanical action of other rock or sand particles.						A place where erosion of a cliffed coast has occurred is at Wamberal in the Central Coast region of New South Wales where houses built on top of the cliffs began to collapse into the sea. This is due to waves causing erosion of the primarily sedimentary material on which the buildings foundations sit.[2]		Dunwich, the capital of the English medieval wool trade, disappeared over the period of a few centuries due to redistribution of sediment by waves. Human interference can also increase coastal erosion: Hallsands in Devon, England, was a coastal village that washed away over the course of a year, an event directly caused by dredging of shingle in the bay in front of it.		The California coast, which has soft cliffs of sedimentary rock and is heavily populated, regularly has incidents of housing damage as cliffs erodes . Devil's Slide, Santa Barbara, the coast just north of Ensenada, and Malibu are regularly affected.		The Holderness coastline on the east coast of England, just north of the Humber Estuary, is one of the fastest eroding coastline in Europe due to its soft clay cliffs and powerful waves. Groynes and other artificial measures to keep it under control has only accelerated the process further down the coast, because longshore drift starves the beaches of sand, leaving them more exposed. The White Cliffs of Dover have also been affected.		Fort Ricasoli, a historic 17th century fortress in Malta is being threatened by coastal erosion, as it was built on a fault in the headland which is prone to erosion. A small part of one of the bastion walls has already collapsed since the land under it has eroded, and there are cracks in other walls as well.		Hydraulic action occurs when waves striking a cliff face compress air in cracks on the cliff face. This exerts pressure on the surrounding rock, and can progressively splinter and remove pieces. Over time, the cracks can grow, sometimes forming a cave. The splinters fall to the sea bed where they are subjected to further wave action.		Attrition occurs when waves cause loose pieces of rock debris (scree) to collide with each other, grinding and chipping each other, progressively becoming smaller, smoother and rounder. Scree also collides with the base of the cliff face, chipping small pieces of rock from the cliff or have a corrasion (abrasion) effect, similar to sandpapering.		Solution is the process in which acids contained in sea water will dissolve some types of rock such as chalk or limestone.[3]		Corrasion or otherwise known as abrasion occurs when waves break on cliff faces and slowly erode it. As the sea pounds cliff faces it also uses the scree from other wave actions to batter and break off pieces of rock from higher up the cliff face which can be used for this same wave action and attrition.		Corrosion or solution/chemical weathering occurs when the sea's pH (anything below pH 7.0) corrodes rocks on a cliff face. Limestone cliff faces, which have a moderately high pH, are particularly affected in this way. Wave action also increases the rate of reaction by removing the reacted material.		The ability of waves to cause erosion of the cliff face depends on many factors.		The hardness (or inversely, the erodibility) of sea-facing rocks is controlled by the rock strength and the presence of fissures, fractures, and beds of non-cohesive materials such as silt and fine sand.		The rate at which cliff fall debris is removed from the foreshore depends on the power of the waves crossing the beach. This energy must reach a critical level to remove material from the debris lobe. Debris lobes can be very persistent and can take many years to completely disappear.		Beaches dissipate wave energy on the foreshore and provide a measure of protection to the adjoining land.		The stability of the foreshore, or its resistance to lowering. Once stable, the foreshore should widen and become more effective at dissipating the wave energy, so that fewer and less powerful waves reach beyond it. The provision of updrift material coming onto the foreshore beneath the cliff helps to ensure a stable beach.		The adjacent bathymetry, or configuration of the seafloor, controls the wave energy arriving at the coast, and can have an important influence on the rate of cliff erosion. Shoals and bars offer protection from wave erosion by causing storm waves to break and dissipate their energy before reaching the shore. Given the dynamic nature of the seafloor, changes in the location of shoals and bars may cause the locus of beach or cliff erosion to change position along the shore.[4]		Coastal erosion has been greatly affected by the rising sea levels globally. There has been great measures of increased coastal erosion on the Eastern seaboard of the United States. Locations such as Florida have noticed increased coastal erosion. In reaction to these increases Florida and its individual counties have increased budgets to replenish the eroded sands that attract visitors to Florida and help support its multibillion-dollar tourism industries.		Pacifica, California coast after major storms in 1997 (resulting from the strongest El Niño on record) destroyed the houses shown above.		Beach erosion at Cabrillo National Monument, California.		Large-scale coastal erosion at Torrey Pines State Reserve, California.		Coastal erosion at Torrey Pines State Reserve, California, resulted in the necessary relocation of a scenic overlook.		There are three common forms of coastal erosion control methods. These three include: soft-erosion controls, hard-erosion controls, and relocation.		Hard-erosion control methods provide a more permanent solution than soft-erosion control methods. Seawalls and groynes serve as semi-permanent infrastructure. These structures are not immune from normal wear-and-tear and will have to be refurbished or rebuilt. It is estimated the average life span of a seawall is 50–100 years and the average for a groyne is 30–40 years.[5] Because of their relative permanence, it is assumed that these structures can be a final solution to erosion. Seawalls can also deprive public access to the beach and drastically alter the natural state of the beach. Groynes also drastically alter the natural state of the beach. Some claim that groynes could reduce the interval between beach nourishment projects though they are not seen as a solution to beach nourishment.[6] Other criticisms of seawalls are that they can be expensive, difficult to maintain, and can sometimes cause further damage to the beach if built improperly.[7]		Natural forms of hard-erosion control include planting or maintaining native vegetation, such as mangrove forests and coral reefs.		Soft erosion strategies refer to temporary options of slowing the effects of erosion. These options, including Sandbag and beach nourishment, are not intended to be long term solutions or permanent solutions.[5] Another method, beach scraping or beach bulldozing allows for the creation of an artificial dune in front of a building or as means of preserving a building foundation. However, there is a U.S. federal moratorium on beach bulldozing during turtle nesting season, 1 May – 15 November.[8] One of the most common methods of soft erosion control is beach nourishment projects. These projects involve dredging sand and moving it to the beaches as a means of reestablishing the sand lost due to erosion.[5] In some situations, beach nourishment is not a suitable measure to take for erosion control, such as in areas with sand sinks or frequent and large storms.[7]		Under this response, humans move from the coast and surrender the coast to the natural processes of both absolute and relative sea level rise and erosion. This solution is eco-centric meaning that the focus is on forcing humans to adapt to the natural processes rather than the opposite. By removing structures along the oceanfront, the beach is surrendered to the natural forces of the ocean. In this case, property owners and coastal communities are essentially “retreating” from the sea. Depending on factors such as the severity of the erosion, as well as the natural landscape of the property, relocation could simply mean moving inland by a number of yards, or in more severe cases, relocation can be to completely desert an area.[7] Typically, there has been low public support for “retreating.”[9] However, this would be most effective in reducing the impacts of erosion on human society.		Storms can cause erosion hundreds of times faster than normal weather. Before-and-after comparisons can be made using data gathered by manual surveying, laser altimeter, or even a GPS unit mounted on an ATV.[10] Remote sensing data such as Landsat scenes can be used for large scale and multi year assessments of coastal erosion.[11]		Images:		
Sand is a naturally occurring granular material composed of finely divided rock and mineral particles. It is defined by size, being finer than gravel and coarser than silt. Sand can also refer to a textural class of soil or soil type; i.e. a soil containing more than 85% sand-sized particles by mass.[1]		The composition of sand varies, depending on the local rock sources and conditions, but the most common constituent of sand in inland continental settings and non-tropical coastal settings is silica (silicon dioxide, or SiO2), usually in the form of quartz. The second most common type of sand is calcium carbonate, for example aragonite, which has mostly been created, over the past half billion years, by various forms of life, like coral and shellfish. For example, it is the primary form of sand apparent in areas where reefs have dominated the ecosystem for millions of years like the Caribbean.		Sand is a non renewable resource over human timescales, and sand suitable for making concrete is in high demand.						In terms of particle size as used by geologists, sand particles range in diameter from 0.0625 mm (or  1⁄16 mm) to 2 mm. An individual particle in this range size is termed a sand grain. Sand grains are between gravel (with particles ranging from 2 mm up to 64 mm) and silt (particles smaller than 0.0625 mm down to 0.004 mm). The size specification between sand and gravel has remained constant for more than a century, but particle diameters as small as 0.02 mm were considered sand under the Albert Atterberg standard in use during the early 20th century. A 1953 engineering standard published by the American Association of State Highway and Transportation Officials set the minimum sand size at 0.074 mm. A 1938 specification of the United States Department of Agriculture was 0.05 mm.[2] Sand feels gritty when rubbed between the fingers (silt, by comparison, feels like flour).		ISO 14688 grades sands as fine, medium and coarse with ranges 0.063 mm to 0.2 mm to 0.63 mm to 2.0 mm. In the United States, sand is commonly divided into five sub-categories based on size: very fine sand ( 1⁄16 –  1⁄8 mm diameter), fine sand ( 1⁄8 mm –  1⁄4 mm), medium sand ( 1⁄4 mm –  1⁄2 mm), coarse sand ( 1⁄2 mm – 1 mm), and very coarse sand (1 mm – 2 mm). These sizes are based on the Krumbein phi scale, where size in Φ = -log2D; D being the particle size in mm. On this scale, for sand the value of Φ varies from −1 to +4, with the divisions between sub-categories at whole numbers.		The most common constituent of sand, in inland continental settings and non-tropical coastal settings, is silica (silicon dioxide, or SiO2), usually in the form of quartz, which, because of its chemical inertness and considerable hardness, is the most common mineral resistant to weathering.		The composition of mineral sand is highly variable, depending on the local rock sources and conditions. The bright white sands found in tropical and subtropical coastal settings are eroded limestone and may contain coral and shell fragments in addition to other organic or organically derived fragmental material, suggesting sand formation depends on living organisms, too.[3] The gypsum sand dunes of the White Sands National Monument in New Mexico are famous for their bright, white color. Arkose is a sand or sandstone with considerable feldspar content, derived from weathering and erosion of a (usually nearby) granitic rock outcrop. Some sands contain magnetite, chlorite, glauconite or gypsum. Sands rich in magnetite are dark to black in color, as are sands derived from volcanic basalts and obsidian. Chlorite-glauconite bearing sands are typically green in color, as are sands derived from basaltic (lava) with a high olivine content. Many sands, especially those found extensively in Southern Europe, have iron impurities within the quartz crystals of the sand, giving a deep yellow color. Sand deposits in some areas contain garnets and other resistant minerals, including some small gemstones.		The study of individual grains can reveal much historical information as to the origin and kind of transport of the grain.[4] Quartz sand that is recently weathered from granite or gneiss quartz crystals will be angular. It is called grus in geology or sharp sand in the building trade where it is preferred for concrete, and in gardening where it is used as a soil amendment to loosen clay soils. Sand that is transported long distances by water or wind will be rounded, with characteristic abrasion patterns on the grain surface. Desert sand is typically rounded.		People who collect sand as a hobby are known as arenophiles. Organisms that thrive in sandy environments are psammophiles.[5]		Only some sands are suitable for the construction industry, for example for making concrete. Because of the growth of population and of cities and the consequent construction activity there is a huge demand for these special kinds of sand, and natural sources are running low. In 2012 French director Denis Delestrac made a documentary called "Sand Wars" about the impact of the lack of construction sand. It shows the ecological and economic effects of both legal and illegal trade in construction sand.[7][8][9]		Sand's many uses require a significant dredging industry, raising environmental concerns over fish depletion, landslides, and flooding. Countries such as China, Indonesia, Malaysia and Cambodia ban sand exports, citing these issues as a major factor.[10] It is estimated that the annual consumption of sand and gravel is 40 billion tons and sand is a $70 billion global industry.[11]		While sand is generally non-toxic, sand-using activities such as sandblasting require precautions. Bags of silica sand used for sandblasting now carry labels warning the user to wear respiratory protection to avoid breathing the resulting fine silica dust. Safety data sheets for silica sand state that "excessive inhalation of crystalline silica is a serious health concern".[12]		In areas of high pore water pressure, sand and salt water can form quicksand, which is a colloid hydrogel that behaves like a liquid. Quicksand produces a considerable barrier to escape for creatures caught within, who often die from exposure (not from submersion) as a result.		Media related to Sand at Wikimedia Commons		
The shoreline is where the land meets the sea and it is continually changing. Over the long term, the water is eroding the land. Beaches represent a special case, in that they exist where sand accumulated from the same processes that strip away rocky and sedimentary material. That is, they can grow as well as erode. River deltas are another exception, in that silt that erodes up river can accrete at the river's outlet and extend ocean shorelines. Catastrophic events such as tsunamis, hurricanes and storm surges accelerate beach erosion, potentially carrying away the entire sand load. Human activities can be as catastrophic as hurricanes, albeit usually over a longer time interval.[citation needed]						Tsunamis, potentially enormous waves often caused by earthquakes, have great erosional and sediment-reworking potential. They may strip beaches of sand that may have taken years to accumulate and may destroy trees and other coastal vegetation. Tsunamis are also capable of flooding hundreds of meters inland past the typical high-water level and fast-moving water, associated with the inundating tsunami, can crush homes and other coastal structures.		A storm surge is an onshore gush of water associated with a low pressure weather system—storms. Storm surges can cause beach accretion and erosion.[1] Historically notable storm surges occurred during the North Sea Flood of 1953, Hurricane Katrina, and the 1970 Bhola cyclone.		The gradual evolution of beaches often comes from the interaction of longshore drift, a wave-driven process by which sediments move along a beach shore, and other sources of erosion or accretion, such as nearby rivers.		Deltas are nourished by alluvial systems and accumulate sand and silt, growing where the sediment flux from land is large enough to avoid complete removal by coastal currents, tides, or waves.		Most modern deltas formed during the last five thousand years, after the present sea-level high stand was attained. However, not all sediment remains permanently in place: in the short term (decades to centuries), exceptional river floods, storms or other energetic events may remove significant portions of delta sediment or change its lobe distribution and, on longer geological time scales, sea-level fluctuations lead to destruction of deltaic features.		In the Mediterranean sea, deltas have been continuously growing for the last several thousand years. Six to seven thousand years ago, the sea level stabilized, and continuous river systems, ephemeral torrents, and other factors began this steady accretion. Since intense human use of coastal areas is a relatively recent phenomenon (except in the Nile delta), beach contours were primarily shaped by natural forces until the last centuries.		In Barcelona, for example, the accretion of the coast was a natural process until the late Middle Ages, when harbor-building increased the rate of accretion.		The port of Ephesus, one of the great cities of the Ionian Greeks in Asia Minor, was filled with sediment due to accretion from a nearby river; it is now 5 kilometers (3.1 mi) from the sea. Likewise, Ostia, the once-important port near ancient Rome, is now several kilometers inland, the coastline having moved slowly seaward.		Bruges became a port during the early Middle Ages and was accessible by sea until around 1050. At that time, however, the natural link between Bruges and the sea silted up. In 1134, a storm flood opened a deep channel, the Zwin, linking the city to the sea until the fifteenth century via a canal from the Zwin to Bruges. Bruges had to use a number of outports, such as Damme and Sluis, for this purpose. In 1907, a new seaport was inaugurated in Zeebrugge.		At the present time important segments of low coasts are in recession, losing sand and reducing beach dimensions. This loss can occur very rapidly. There are various reasons for beach recession, some more natural than others (degree of anthropization). Examples of this are occurring at Sète, in California, in Poland, in Aveiro (Portugal), and in the Netherlands and elsewhere along the North Sea. In Europe, coastal erosion is widespread (at least 70%) and distributed very irregularly.		Some of the coastal defence bunkers of the Atlantic Wall, built by the German soldiers during the Second World War at the top of the dunes are now underwater 2/3 of the times. It shows 200 meters of recession of the beach in 65 years.		The coast recession near Sète is related with coastal drift sand supply interruption due to growth of the Rhone delta, which (like most deltas) is becoming independent of the rest of the coast. The present lido shoreline is 210 meters away from the Roman lido.		California's beaches and other shoreline features change according to the availability of beach sand, the wave and current energy impinging on the coast, and other physical processes that affect the movement of sand. A constant supply of sand is necessary for beaches to form and be maintained along this shoreline. Many human activities, including dam construction and river channelization, have reduced the supply of sand that reaches the ocean. This, in turn, has prevented beaches from being replenished and has thus created greater vulnerability for shorelines that have always been subject to varying levels of erosion. There are few practical solutions to improving sand supply from inland sources, so management of shoreline erosion will likely continue to focus at the land/sea interface along the California coastline.		Construction of breakwaters, jetties, or groyne fields to protect harbor entrances, maintain beaches, or protect coastal structures have both helped and harmed the movement of sand along the shoreline. Protective armoring formations trap sand and allow beaches to expand up-coast from the device, but can interrupt the flow of sand to beaches located down-coast.		During the last glaciation, the Baltic Polish area was covered in ice and associated morainal sediments. Deglaciation left a substantial amount of unconsolidated sediment. Currently, these unconsolidated sediments are strongly eroded and reworked by the sea.		The North Portuguese coast and its beaches were fed by large Iberian rivers. The massive building of dams in the Douro River basin has cut the sediment supply to the Aveiro coast, resulting in its recession. Hard protective works have been done all along.		The Dutch coast consists of sandy, multi-barred beaches and can be characterised as a wave-dominated coast. Approximately 290 km of the coast consists of dunes and 60 km is protected by structures such as dikes and dams. With the melting of the ice at the end of the last ice age the coastline shifted eastward until about 5000 years ago the present position of the Dutch coastline was reached.		As the sea level rise stagnated, the sand supply decreased and the formation of the beach ridges stopped, after which when the sea broke through the lines of dunes during storms, men started to defend the land by building primitive dikes and walls. The dunes, together with the beach and the shoreline, offer a natural, sandy defence to the sea. About 30% of the Netherlands lies below sea level.		Over the last 30 years, approximately 1 million m³ sand per year has been lost from the Dutch coast to deep water. In most northern coastal sections, erosion occurs in deep water and also in the nearshore zone. In most southern sections, sedimentation occurs in the nearshore zone and erosion in deep water.		Structural erosion is due to sea level rise relative to the land and, in some spots, it is caused by harbour dams. The Dutch coast looked at as a single unit shows erosive behaviour. Approximately 12 million m³ of sand is transferred annually from the North Sea to the Wadden Sea as a result of relative rising sea level and coastal erosion.		Several geological events and the climate can change (progressively or suddenly) the relative height of the Earth's surface to the sea-level. These events or processes continuously change coastlines.		Volcanic activity can create new islands. The 800 meters (2,600 ft) in diameter Surtsey Island, Iceland, for example, was created between November 1963 and June 1967. The island has since partially eroded, but it is expected to last another 100 years.		Some earthquakes can create sudden variations of relative ground level and change the coastline dramatically. Structurally controlled coasts include the San Andreas fault zone in California and the seismic Mediterranean belt (from Gibraltar to Greece).		The Bay of Pozzuoli, in Pozzuoli, Italy experienced hundreds of tremors between August 1982 and December 1984. The tremors, which reached a peak on October 4, 1983, damaged 8,000 buildings in the city center and raised the sea bottom by almost 2 meters (6.6 ft). This rendered the Bay of Pozzuoli too shallow for large craft and required the reconstruction of the harbour with new quays. The photo at the upper right shows the harbor before the uplift while the one on the bottom right shows the new quay.		Subsidence is the motion of the Earth's surface downward relative to the sea level due to internal geodynamic causes. The opposite of subsidence is uplift, which increases elevation.		Venice is probably the best-known example of a subsiding location. It experiences periodic flooding when extreme high tides or surges arrive. This phenomenon is caused by the compaction of young sediments in the Po River delta area, magnified by subsurface water and gas exploitation. Man-made works to solve this progressive sinking have been unsuccessful.		Mälaren, the third-largest lake in Sweden, is an example of deglacial uplift. It was once a bay on which seagoing vessels were once able to sail far into the country's interior, but it ultimately became a lake. Its uplift was caused by deglaciation: the removal of the weight of ice-age glaciers caused rapid uplift of the depressed land. For 2,000 years as the ice was unloaded, uplift proceeded at about 7.5 centimeters (3.0 in)/year. Once deglaciation was complete, uplift slowed to about 2.5 centimeters (0.98 in) annually, and it decreased exponentially after that. Today, annual uplift rates are 1 centimeter (0.39 in) or less, and studies suggest that rebound will continue for about another 10,000 years. The total uplift from the end of deglaciation may be up to 400 meters (1,300 ft).		
Ghost crabs are semiterrestrial crabs of the subfamily Ocypodinae. They are common shore crabs in tropical and subtropical regions throughout the world, inhabiting deep burrows in the intertidal zone. They are generalist scavengers and predators of small animals. The name "ghost crab" derives from their nocturnality and their generally pale coloration.[1][2] They are also sometimes called sand crabs, though the name refers to various other crabs that do not belong to the subfamily.		Characteristics of the subfamily include one claw being larger than the other, thick and elongated eyestalks, and a box-like body. The differences in claw sizes, however, are not as marked as in male fiddler crabs. The subfamily includes 22 species in two genera.						Ocypodinae is one of two subfamilies in the family Ocypodidae, the other being the fiddler crab subfamily, Ucinae. Both subfamilies have members in which one of the claw-bearing legs (the chelipeds) is much larger than the other. However, only male fiddler crabs exhibit this, while both male and female ghost crabs have unequally sized claws. The difference is also much more pronounced among fiddler crab males. The fiddler crabs' carapaces are broadened at the front, while the carapaces of ghost crabs are more or less box-like. Lastly, the eyes of ghost crabs have large and elongated eyestalks, with the corneas occupying the entire lower part, while in fiddler crabs the eyestalks are long and thin, with the corneas small and located at the tip.[3][4]		Ocypodinae was previously regarded as monotypic, with only one genus, Ocypode, classified under it. In 2013, though, Katsushi Sakai and Michael Türkay reclassified the gulf ghost crab into a separate genus, Hoplocypode based on the differences of their gonopods (appendages modified into copulatory organs) from that of the rest of the members of the genus Ocypode.[5]		The subfamily Ocypodinae currently contains 22 species in these two genera:[5]		Most ghost crabs have pale-colored bodies that blend in well with the sand,[3] though they are capable of gradually changing body coloration to match their environments and the time of day.[6][7] Some species are brightly colored, such as Ocypode gaudichaudii and Ocypode ryderi.[2][5]		Ghost crabs have elongated and swollen eyestalks with very large corneas on the bottom half. Their carapaces are deep and box-like, squarish when viewed from the top with straight or slightly curving sides. The regions of the carapace are usually not clearly defined. The "whip" of their antennules (antennular flagella) are small or rudimentary. They fold back into the body diagonally or almost vertically. The plate between them (the interantennular septum) is broad. The third pair of mouth appendages (maxillipeds) completely cover the mouth opening. A small orifice with edges thickly fringed with hair is found between the bases of the second and third pairs of walking legs.[8]		Ghost crab species can be most reliably identified by means of the area where they were recovered, the presence of "horns" (styles) on their eyestalks (exophthalmy), the pattern of stridulating (sound-producing) ridges on the inside surface of the palms of their larger claws, and the shape of the gonopods in males.[5]		Exophthalmy is exhibited by seven species in the subfamily: Ocypode brevicornis, Ocypode ceratophthalma, Ocypode gaudichaudii, Ocypode macrocera, Ocypode mortoni, Ocypode rotundata, and Ocypode saratan. All of them are found in the Indo-Pacific region with more or less limited ranges, with the exception of Ocypode ceratophthalma, which is found widely. Ocypode cursor, found in the Atlantic and the Mediterranean Sea, also possesses a tuft of bristles at the end of its eyestalks.[5]		Stridulating ridges also differ from species to species, with some displaying rows of tubercles, others displaying rows of smaller ridges (striae), or a combination of both. These are very important in identifying species as they are displayed by both adults and juveniles (though they may be absent in newly regenerated claws). They are used by ghost crabs for communication.[5]		Both exophthalmy and stridulating ridges, however, can not be reliably used to determine phylogenetic relationships between different species of ghost crabs. Sakai & Türkay (2013) regarded the shape of the gonopods as more suited for this. As gonopods are important in sexual reproduction, they are less likely to evolve randomly in response to the environment. Ghost crabs of the genus Hoplocypode can be distinguished from those in Ocypode by examining their gonopods. In the former, the first gonopod has a complex, hoof-shaped tip, while in the latter they are simple and curved.[5]		Ghost crabs dig deep burrows near the intertidal zone of open sandy beaches. The burrows are usually composed of a long shaft with a chamber at the end, occasionally with a second entrance shaft.[1] They are semi-terrestrial and breathe oxygen from the air through moistened gills. They must periodically wet their gills with seawater,[1][9] usually by taking water from moist sand or by running into the surf and letting the waves wash over them. However, they can only remain under water for a limited amount of time, as they will drown.[10][11]		Ghost crabs are generalists, scavenging carrion and debris, as well as preying on small animals, including sea turtle eggs and hatchlings, clams, and other crabs.[12] They are predominantly nocturnal. They remain in their burrows during the hottest part of the day, and throughout the coldest part of the winter.[1]		Ghost crabs are swift runners, darting away at the slightest sign of danger. They either head back to their burrows or plunge into the sea to escape intruders.[10][11][13] The gaits of ghost crabs alter as their speed increases. Observations on O. ceratophthalma show it can walk indefinitely using all four pairs of walking legs, occasionally alternating which side leads. At higher speeds, the fourth pair of legs is raised off the ground, and at the highest speeds, the crab runs, using only the first and second pairs of walking legs.[14]		Ghost crabs also have the ability to change colors to match their surroundings by adjusting the concentration and dispersal of pigments within their chromatophores.[6] They can even match the specific colors of the grains of sand in their habitats.[15] However, unlike metachrosis (which is a rapid change of colors), ghost crabs are only capable of morphological color change, which occurs over a longer span of time.[6]		Atlantic ghost crab (Ocypode quadrata) emerging from its burrow in Cahuita, Costa Rica		Horned ghost crab (Ocypode ceratophthalma) from a black sand beach in Kauai		White sand beach in Kahoolawe, Hawaii		In a study in 1964, individuals of O. ceratophthalma in Hawaii from two populations (one from a black-sand beach and the other from a white-sand beach) were observed to markedly differ in pigmentation although they remain morphologically indistinguishable. Specimens taken from the black-sand beach were much darker than the specimens taken from the white-sand beach, exhibiting nearly 12 times as many black chromatophores. When the black-sand specimens were subsequently exposed to a white background, they were observed to gradually become lighter over the course of about a month. The opposite happened to white-sand specimens when placed in black backgrounds.[6]		In a 2013 study in Singapore, Ocypode ceratophthalma was also discovered to change color in response to the time of day. In a span of 24 hours, they were observed to alternate between lighter and darker coloration, being lightest at midday and darkest at night. However, when placed in a dark background, the crabs showed no significant changes in coloration. This suggests, at least for short-term color changes, they follow a day-night cycle to determine body coloration; basing it on their biological clocks rather than on the brightness or darkness of their environments. The researchers believe relying on the time of day rather than ambient light is more advantageous for survival in ghost crabs. It lets ghost crabs avoid changing color when in temporary shadow (for example within their burrows) and thus still remain inconspicuous when they are once again illuminated by daylight. However, this behavior is only exhibited by juveniles.[7][15]		Ghost crabs lay their eggs in the sea, which develop into planktonic marine larvae.[1]		Ghost crabs dominate sandy shores in tropical and subtropical regions of the world, replacing the sandhoppers that predominate in cooler areas.[1] Three species are found in the Atlantic Ocean and the Mediterranean Sea, and two occur in the eastern Pacific coast of the Americas. The rest of the species are found in the western Pacific and the Indian Ocean to the tip of southern Africa.[5]		Ghost crabs are negatively affected by human activity on sandy beaches, such as sand trampling by foot traffic, the building of seawalls, or the presence of inorganic pollutants. Due to their worldwide distribution and the ease by which their burrows can be surveyed, ghost crab burrows are regarded as valuable ecological indicators for quickly assessing the impact of human disturbance on beach habitats.[19][20][21]		
Miami Beach is a coastal resort city in Miami-Dade County, Florida, United States. It was incorporated on March 26, 1915.[6] The municipality is located on natural and man-made barrier islands between the Atlantic Ocean and Biscayne Bay, the latter of which separates the Beach from Miami. The neighborhood of South Beach, comprising the southernmost 2.5 square miles (6.5 km2) of Miami Beach, along with downtown Miami and the Port of Miami, collectively form the commercial center of South Florida.[7] As of the 2010 census, Miami Beach had a total population of 87,779.[8] It has been one of America's pre-eminent beach resorts since the early 20th century.		In 1979, Miami Beach's Art Deco Historic District was listed on the National Register of Historic Places. The Art Deco District is the largest collection of Art Deco architecture in the world[9] and comprises hundreds of hotels, apartments and other structures erected between 1923 and 1943. Mediterranean, Streamline Moderne and Art Deco are all represented in the District. The Historic District is bounded by the Atlantic Ocean on the East, Lenox Court on the West, 6th Street on the South and Dade Boulevard along the Collins Canal to the North. The movement to preserve the Art Deco District's architectural heritage was led by former interior designer Barbara Capitman, who now has a street in the District named in her honor.						Miami Beach is governed by a ceremonial mayor and six commissioners. Although the mayor runs commission meetings, the mayor and all commissioners have equal voting power and are elected by popular election. The mayor serves for terms of two years with a term limit of three terms and commissioners serve for terms of four years and are limited to two terms. Commissioners are voted for citywide and every two years three commission seats are voted upon.		A city manager is responsible for administering governmental operations. An appointed city manager is responsible for administration of the city.[10] The City Clerk and the City Attorney are also appointed officials.		In 1870, a father and son, Henry and Charles Lum, purchased the land for 75 cents an acre. The first structure to be built on this uninhabited oceanfront was the Biscayne House of Refuge, constructed in 1876 by the United States Life-Saving Service at approximately 72nd Street. Its purpose was to provide food, water, and a return to civilization for people who were shipwrecked. The next step in the development of the future Miami Beach was the planting of a coconut plantation along the shore in the 1880s by New Jersey entrepreneurs Ezra Osborn and Elnathan Field, but this was a failed venture. One of the investors in the project was agriculturist John S. Collins, who achieved success by buying out other partners and planting different crops, notably avocados, on the land that would later become Miami Beach. Meanwhile, across Biscayne Bay, the City of Miami was established in 1896 with the arrival of the railroad, and developed further as a port when the shipping channel of Government Cut was created in 1905, cutting off Fisher Island from the south end of the Miami Beach peninsula.		Collins' family members saw the potential in developing the beach as a resort. This effort got underway in the early years of the 20th century by the Collins/Pancoast family, the Lummus brothers (bankers from Miami), and Indianapolis entrepreneur Carl G. Fisher. Until then, the beach here was only the destination for day-trips by ferry from Miami, across the bay. By 1912, Collins and Pancoast were working together to clear the land, plant crops, supervise the construction of canals to get their avocado crop to market, and set up the Miami Beach Improvement Company.[11] There were bath houses and food stands, but no hotel until Brown's Hotel was built in 1915 (still standing, at 112 Ocean Drive). Much of the interior land mass at that time was a tangled jungle of mangroves. Clearing it, deepening the channels and water bodies, and eliminating native growth almost everywhere in favor of landfill for development, was expensive.		With loans from the Lummus brothers, Collins had begun work on a 2½-mile-long wooden bridge, the world's longest wooden bridge at the time, to connect the island to the mainland. When funds ran dry and construction work stalled, Indianapolis millionaire and recent Miami transplant Fisher intervened, providing the financing needed to complete the bridge the following year in return for a land swap deal.[11] That transaction kicked off the island's first real estate boom. Fisher helped by organizing an annual speed boat regatta, and by promoting Miami Beach as an Atlantic City-style playground and winter retreat for the wealthy. By 1915, Lummus, Collins, Pancoast, and Fisher were all living in mansions on the island, three hotels and two bath houses had been erected, an aquarium built, and an 18-hole golf course landscaped.		The Town of Miami Beach was chartered on March 26, 1915; it grew to become a City in 1917. Even after the town was incorporated in 1915 under the name of Miami Beach, many visitors thought of the beach strip as Alton Beach, indicating just how well Fisher had advertised his interests there. The Lummus property was called Ocean Beach, with only the Collins interests previously referred to as Miami Beach.[12]		Carl Fisher was the main promoter of Miami Beach's development in the 1920s as the site for wealthy industrialists from the north and Midwest to and build their winter homes here. Many other Northerners were targeted to vacation on the island. To accommodate the wealthy tourists, several grand hotels were built, among them: The Flamingo Hotel, The Fleetwood Hotel, The Floridian, The Nautilus, and the Roney Plaza Hotel. In the 1920s, Fisher and others created much of Miami Beach as landfill by dredging Biscayne Bay; this man-made territory includes Star, Palm, and Hibiscus Islands, the Sunset Islands, much of Normandy Isle, and all of the Venetian Islands except Belle Isle. The Miami Beach peninsula became an island in April 1925 when Haulover Cut was opened, connecting the ocean to the bay, north of present-day Bal Harbour. The great 1926 Miami hurricane put an end to this prosperous era of the Florida Boom, but in the 1930s Miami Beach still attracted tourists, and investors constructed the mostly small-scale, stucco hotels and rooming houses, for seasonal rental, that comprise much of the present "Art Deco" historic district.		Carl Fisher brought Steve Hannagan to Miami Beach in 1925 as his chief publicist.[13] Upon arrival, Hannagan set-up the Miami Beach News Bureau and notified news eidtors that they could "Print anything you want about Miami Beach; just make sure you get our name right."[14] The News Bureau sent thousands of pictures of bathing beauties and press releases to columnists like Walter Winchell and Ed Sullivan. [14] One of Hannagan's favorite venues was the massive billboard overhangin Time Square, where he ran two taglines: "'It's always June in Miami Beach' and 'Miami Beach, Where Summer Spends the Winter.'"[15] Forbes magazine gave a testimonial of Hannagan and his impact on Miami Beach; "And with Hannagan’s arrival, publicity suddenly became an art and a big business at Miami Beach."[16]		Post–World War II economic expansion brought a wave of immigrants to South Florida from the Northern United States, which significantly increased the population in Miami Beach within a few decades. After Fidel Castro's rise to power in 1959, a wave of Cuban refugees entered South Florida and dramatically changed the demographic make-up of the area. In 2017, one study named zipcode 33109 in Miami Beach as having the 4th most expensive home sales in the United States.[17]		South Beach (also known as SoBe, or simply the Beach), the area from Biscayne Street (also known as South Pointe Drive) one block south of 1st Street to about 23rd Street, is one of the more popular areas of Miami Beach. Topless sunbathing by women is illegal, but is officially tolerated on South Beach.[18] Before the TV show Miami Vice helped make the area popular, SoBe was under urban blight, with vacant buildings and a high crime rate. Today, it is considered one of the richest commercial areas on the beach, yet poverty and crime still remain in some places near the area.[19]		Miami Beach, particularly Ocean Drive of what is now the Art Deco District, was also featured prominently in the 1983 feature film Scarface and the 1996 comedy The Birdcage.		The New World Symphony Orchestra is based in Miami Beach, under the direction of Michael Tilson Thomas.		Lincoln Road, running east-west parallel between 16th and 17th Streets, is a nationally known spot for outdoor dining, bicycling, rollerblading and shopping and features and galleries of well known designers, artists and photographers such as Romero Britto, Peter Lik, and Jonathan Adler.[citation needed]		Miami Beach is home to a number of Orthodox Jewish communities with a network of well-established synagogues and yeshivas, the first of which being the Landow Yeshiva, a Chabad institution in operation for over 30 years. There is also a liberal Jewish community containing such famous synagogues as Temple Emanu-El and Cuban Hebrew Congregation. It is also a magnet for Jewish families, retirees, and particularly snowbirds when the cold winter sets in to the north. They range from the Modern Orthodox to the Haredi and Hasidic – including many rebbes who vacation there during the North American winter. Till his death in 1991, the Nobel laureate writer Isaac Bashevis Singer lived in the northern end of Miami Beach and breakfasted often at Sheldon's drugstore on Harding Avenue.		There are a number of kosher restaurants and even kollels for post-graduate Talmudic scholars, such as the Miami Beach Community Kollel. Miami Beach had roughly 60,000 people in Jewish households, 62 percent of the total population, in 1982, but only 16,500, or 19 percent of the population, in 2004, said Ira Sheskin, a demographer at the University of Miami who conducts surveys once a decade.[citation needed] The Miami Beach Jewish community had decreased in size by 1994 due to migration to wealthier areas and an aging of the population.[20]		Miami Beach is home to the Holocaust Memorial on Miami Beach.		On December 3, 2013, several buildings in Miami Beach including a Jewish Women's prayer center were found vandalized with hate messages such as "kkk". [21]		After decades of economic and social decline, an influx of gays and lesbians moving to South Beach in the late-1980s to mid-1990s helped contribute to Miami Beach's revitalization. The newcomers purchased and restored dilapidated Art Deco hotels and clubs, started numerous businesses, and built political power in city and county government.[22] As South Beach became more popular as a national and international tourist destination, there have been occasional clashes between cultures and disputes about whether South Beach is as "gay-friendly" as it once was.[23]		Miami Beach is home to numerous gay bars and gay-specific events, and five service and resource organizations. The passage of progressive civil rights laws,[22] election of outspokenly pro-gay Miami Beach Mayor Matti Bower, and the introduction of Miami Beach's Gay Pride Celebration, have reinvigorated the local LGBT community in recent years, which some argued had experienced a decline in the late 2000s.[24] Some instances of Miami Beach Police brutality against gay men[25] have been at odds with Miami Beach's longstanding image as a welcoming place for gay people.[26]		Miami Beach is home to some of the country's largest fundraisers that benefit both local and national LGBT nonprofits. As of 2011[update], some of the largest LGBT events in Miami Beach are:		In 2008, the new Miami Beach Mayor Matti Bower created a Gay Business Development Ad Hoc Committee, with a mission to bring recommendations to the Mayor and City Commission on initiatives to be implemented and supported by the city regarding a variety of issues to ensure the welfare and future of the Miami Beach LGBT community.		While being a gay mecca of the 1980s and 1990s, Miami Beach never had a city sanctioned Gay Pride Parade until April 2009.[27] With strong support from the newly elected mayor Matti Bower,[28] Miami Beach had its first Gay Pride Festival in April 2009.[29] It is now an annual event. The 2010 Pride drew tens of thousands of people.[30]		In 2009, the American Civil Liberties Union (ACLU) began looking into instances of Miami Beach Police Department (MBPD) targeting gay men for harassment.[31] In February 2010, the ACLU announced that it will sue the City of Miami Beach for an ongoing targeting and arrests of gay men in public.[32] According to the ACLU, Miami Beach police have a history of arresting gay men for simply looking "too gay".[33]		The incidents between gay men and MBPD resulted in negative publicity for the city.[34] At the meeting with the local gay leaders, Miami Beach Police Chief Carlos Noriega claimed that the incidents were isolated, and promised increased diversity training for police officers. He also announced that captain, who is a lesbian, would soon be reassigned to internal affairs to handle complaints about cops accused of harassing gays. Some members of the committee were skeptical of Noriega's assertion that the recent case wasn't indicative of a larger problem in the MBPD, and provided examples of other cases.[35]		In January 2010, Miami Beach passed a revised Human Rights Ordinance that strengthens enforcement of already existing human rights laws and adds protections for transgender people,[36] making Miami Beach's human rights laws some of the most progressive in the state.[22] Both residents of, and visitors to, Miami Beach have been able to register as domestic partners since 2004;[37] in 2008 this benefit was extended to all of Miami-Dade County.[38]		In 2010, the Miami-Dade Gay & Lesbian Chamber of Commerce, with support from the City of Miami Beach, opened an LGBT Visitor Center[39] at Miami Beach's Old City Hall.		Each December, the City of Miami Beach hosts Art Basel Miami Beach, one of the largest art shows in the United States. Art Basel Miami Beach, the sister event to the Art Basel event held each June in Basel, Switzerland, combines an international selection of top galleries with a program of special exhibitions, parties and crossover events featuring music, film, architecture and design. Exhibition sites are located in the city's Art Deco District, and ancillary events are scattered throughout the greater Miami metropolitan area.		Miami Beach is home to the New World Symphony, established in 1987 under the artistic direction of Michael Tilson Thomas. In January 2011, the New World Symphony made a highly publicized move into the New World Center building designed by Canadian American Pritzker Prize-winning architect Frank Gehry. Gehry is famous for his design of the Guggenheim Museum in Bilbao, Spain, and the Walt Disney Concert Hall in Los Angeles, California. The new Gehry building offers Live Wallcasts™,[40] which allow visitors to experience select events throughout the season at the half-acre, outdoor Miami Beach SoundScape through the use of visual and audio technology on a 7,000-square-foot (650 m2) projection wall.		The Miami City Ballet, a ballet company founded in 1985, is housed in a 63,000-square-foot (5,900 m2) building near Miami Beach's Bass Museum of Art.		The Miami Beach Festival of the Arts is an annual outdoor art festival that was begun in 1974.		According to the United States Census Bureau, the city has a total area of 18.7 sq mi (48.5 km2), of which 7.0 sq mi (18.2 km2) is land and 11.7 sq mi (30.2 km2) (62.37%) is water.		Miami Beach sees sunny day flooding of certain roads during the annual king tides,[41] though some argue this has been the case for decades,[42] as the parts of the western side of South Beach[43] are at virtually 0 feet (0 m) above normal high tide,[44] with the entire city averaging only 4.4 feet (1.3 m) above mean sea level (AMSL).[45] However, a recent study by the University of Miami showed that tidal flooding became much more common from the mid 2000s.[46] The fall 2015 king tides exceeded expectations in longevity and height.[47] Traditional sea level rise and storm mitigation measures including sea walls and dykes, such as those in the Netherlands and New Orleans, may not work in South Florida due to the porous nature of the ground and limestone beneath the surface.[43]		In addition to present difficulty with below-grade development, some areas of southern Florida, especially Miami Beach, are beginning to engineer specifically for sea level rise and other potential effects of climate change. This includes a five-year, US$500 million project for the installation of 60 to 80 pumps, building of taller sea walls, and the physical raising of road tarmac levels,[48] as well as possible zoning and building code changes, which could eventually lead to retrofitting of existing and historic properties. Some streets and sidewalks were raised about 2.5 feet (0.76 m) over previous levels;[42] the four initial pumps installed in 2014 are capable of pumping 4,000 US gallons per minute.[49] However, this plan is not without criticism. Some residents worry that the efforts will not be sufficient to successfully adapt to rising sea levels and wish the city had pursued a more aggressive plan. On the other hand, some worry that the city is moving too quickly with untested solutions. Others yet have voiced concerns that the plan protects big-money interests in Miami Beach. [50]		Like much of Florida, there is a marked wet and dry season in Miami Beach. The tropical rainy season runs from May through September, when showers and late day thunderstorms are common. The dry season is from November through April, when few showers, sunshine, and low humidity prevail. The island location of Miami Beach however, creates fewer convective thunderstorms, so Miami Beach receives less rainfall in a given year than neighboring areas such as Miami and Fort Lauderdale. Proximity to the moderating influence of the Atlantic gives Miami Beach lower high temperatures and higher lows than inland areas of Florida. Other than the Florida Keys (and Key West), Miami Beach is the only U.S. city (mainland) to never report snow flurries in its weather history.[51]		Miami Beach's location on the Atlantic Ocean, near its confluence with the Gulf of Mexico, make it extraordinarily vulnerable to hurricanes and tropical storms. Though direct strikes from hurricanes are rare (Miami has experienced only two direct hits from major hurricanes in recorded weather history – the 1926 Miami hurricane and Hurricane Cleo in 1964), the area has seen indirect contact from hurricanes Betsy (1965), Inez (1966), Andrew (1992), Irene (1999), Michelle (2001), Katrina (2005), and Wilma (2005).		This chart shows the average coastal water temperature for the Atlantic Ocean by month in degrees Fahrenheit for Miami Beach based on historical measurements.[53]		As of 2010[update], those of Hispanic or Latino ancestry accounted for 53.0% of Miami Beach's population. Out of the 53.0%, 20.0% were Cuban, 4.9% Colombian, 4.6% Argentinean, 3.7% Puerto Rican, 2.4% Peruvian, 2.1% Venezuelan, 1.8% Mexican, 1.7% Honduran, 1.6% Guatemalan, 1.4% Dominican, 1.1% Uruguayan, 1.1% Spaniard, 1.0% Nicaraguan, 0.9% Ecuadorian, and 0.8% were Chilean.[55]		As of 2010[update], those of African ancestry accounted for 4.4% of Miami Beach's population, which includes African Americans. Out of the 4.4%, 1.3% were Black Hispanics, 0.8% were Subsaharan African, and 0.8% were West Indian or Afro-Caribbean American (0.3% Jamaican, 0.3% Haitian, 0.1% Other or Unspecified West Indian, 0.1% Trinidadian and Tobagonian.)[55][56][57][58]		As of 2010[update], those of (non-Hispanic white) European ancestry accounted for 40.5% of Miami Beach's population. Out of the 40.5%, 9.0% Italian, 6.0% German, 3.8% were Irish, 3.8% Russian, 3.7% French, 3.4% Polish, 3.0% English, 1.2% Hungarian, 0.7% Swedish, 0.6% Scottish, 0.5% Portuguese, 0.5% Dutch, 0.5% Scotch-Irish, and 0.5% were Norwegian.[56][57]		As of 2010[update], those of Asian ancestry accounted for 1.9% of Miami Beach's population. Out of the 1.9%, 0.6% were Indian, 0.4% Filipino, 0.3% Other Asian, 0.3% Chinese, 0.1% Japanese, 0.1% Korean, and 0.1% were Vietnamese.[56]		In 2010, 2.8% of the population considered themselves to be of only American ancestry (regardless of race or ethnicity.)[56][57] And 1.5% were of Arab ancestry, as of 2010[update].[56]		As of 2010[update], there were 67,499 households, while 30.1% were vacant. 13.8% had children under the age of 18 living with them, 26.3% were married couples living together, 8.4% have a female householder with no husband present, and 61.1% were non-families. 49.0% of all households were made up of individuals and 12.0% had someone living alone who was 65 years of age or older (4.0% male and 8.0% female.) The average household size was 1.84 and the average family size was 2.70.[56][59]		In 2010, the city population was spread out with 12.8% under the age of 18, 7.4% from 18 to 24, 38.0% from 25 to 44, 25.7% from 45 to 64, and 16.2% who were 65 years of age or older. The median age was 40.3 years. For every 100 females there were 109.9 males. For every 100 females age 18 and over, there were 111.0 males.[56][59]		As of 2010[update], the median income for a household in the city was $43,538, and the median income for a family was $52,104. Males had a median income of $42,605 versus $36,269 for females. The per capita income for the city was $40,515. About 10.9% of families and 15.6% of the population were below the poverty line, including 13.0% of those under age 18 and 27.5% of those aged 65 or over.[60]		In 2010, 51.7% of the city's population was foreign-born. Of foreign-born residents, 76.9% were born in Latin America and 13.6% were born in Europe, with smaller percentages from North America, Africa, Asia, and Oceania.[57]		As of 2000, speakers of Spanish at home accounted for 54.90% of residents, while those who spoke exclusively English made up 32.76%. Speakers of Portuguese were 3.38%, French 1.66%, German 1.12%, Italian 1.00%, and Russian 0.85% of the population. Due to the large Jewish community, Yiddish was spoken at the home of 0.81% of the population, and Hebrew was the mother tongue of 0.75%.[61]		As of 2000, Miami Beach had the 22nd highest concentration of Cuban residents in the United States, at 20.51% of the population.[62] It had the 28th highest percentage of Colombian residents, at 4.40% of the city's population,[63] and the 14th highest percentage of Brazilian residents, at 2.20% of the its population (tied with Hillside, New Jersey and Hudson, Massachusetts.)[64] It also had the 27th largest concentration of Peruvian ancestry, at 1.85%,[65] and the 27th highest percentage of people of Venezuelan heritage, at 1.79%.[66] Miami Beach also has the 33rd highest concentration of Honduran ancestry at 1.21%[67] and the 41st highest percentage of Nicaraguan residents, which made up 1.03% of the population.[68]		Public Transportation in Miami Beach is operated by Miami-Dade Transit (MDT). Along with neighborhoods such as Downtown and Brickell, public transit is heavily used in Miami Beach, and is a vital part of city life. Although Miami Beach has no direct Metrorail stations, numerous Metrobus lines connect to Downtown Miami and Metrorail (i.e., the 'S' bus line). The South Beach Local (SBL) is one of the most heavily used lines in Miami, and connects all major points of South Beach to other major bus lines in the city. Metrobus ridership in Miami Beach is high, with some of the routes such as the L and S being the busiest Metrobus routes.[69]		The Airport-Beach Express (Route 150), operated by MDT, is a direct-service bus line that connects Miami International Airport to major points in South Beach. The ride costs $2.65, and runs every 30 minutes from 6:00 a.m. to 11:00 p.m. seven days a week.[70]		Since the late 20th century, cycling has grown in popularity in Miami Beach. Due to its dense, urban nature, and pedestrian-friendly streets, many Miami Beach residents get around by bicycle.		In March 2011 a public bicycle sharing system named Decobike was launched, one of only a handful of such programs in the United States. The program is operated by a private corporation, Decobike, LLC, but is partnered with the City of Miami Beach in a revenue sharing model.[71] Once fully implemented, the program hopes to have around 1000 bikes accessible from 100 stations throughout Miami Beach, from around 85th Street on the north side of Miami Beach all the way south to South Pointe Park.[72]		Miami-Dade County Public Schools serves Miami Beach.		Private schools include Rabbi Alexander S. Gross Hebrew Academy, St. Patrick Catholic School, Landow Yeshiva – Lubavitch Educational Center (Klurman Mesivta High School for Boys and Beis Chana Middle and High School for Girls), and Mechina High School.		In the early history of Miami Beach there was one elementary school and the Ida M. Fisher junior-senior high school.[73] The building of Miami Beach High was constructed in 1926, and classes began in 1928.[74]		The Florida International University School of Architecture has a sister campus at 420 Lincoln Road in South Beach, with classroom spaces for FIU architecture, art, music and theater graduate students.[75]		Miami Beach has 12 sister cities[76]		The historical Art Deco District at South Beach at night.		The Art Deco District at South Beach during the day.		Miami Beach Police HQ		A street of Miami Beach with royal palms		
A coastal waterfall is a waterfall that plunges directly into the sea. Another common name for this feature is a tidefall.		Coastal waterfalls include:		
Romanticism (also the Romantic era or the Romantic period) was an artistic, literary, musical and intellectual movement that originated in Europe toward the end of the 18th century, and in most areas was at its peak in the approximate period from 1800 to 1850. Romanticism was characterized by its emphasis on emotion and individualism as well as glorification of all the past and nature, preferring the medieval rather than the classical. It was partly a reaction to the Industrial Revolution,[1] the aristocratic social and political norms of the Age of Enlightenment, and the scientific rationalization of nature—all components of modernity.[2] It was embodied most strongly in the visual arts, music, and literature, but had a major impact on historiography,[3] education,[4] and the natural sciences.[5] It had a significant and complex effect on politics, and while for much of the Romantic period it was associated with liberalism and radicalism, its long-term effect on the growth of nationalism was perhaps more significant.		The movement emphasized intense emotion as an authentic source of aesthetic experience, placing new emphasis on such emotions as apprehension, horror and terror, and awe—especially that experienced in confronting the new aesthetic categories of the sublimity and beauty of nature. It elevated folk art and ancient custom to something noble, but also spontaneity as a desirable characteristic (as in the musical impromptu). In contrast to the Rationalism and Classicism of the Enlightenment, Romanticism revived medievalism[6] and elements of art and narrative perceived as authentically medieval in an attempt to escape population growth, early urban sprawl, and industrialism.		Although the movement was rooted in the German Sturm und Drang movement, which preferred intuition and emotion to the rationalism of the Enlightenment, the events and ideologies of the French Revolution were also proximate factors. Romanticism assigned a high value to the achievements of "heroic" individualists and artists, whose examples, it maintained, would raise the quality of society. It also promoted the individual imagination as a critical authority allowed of freedom from classical notions of form in art. There was a strong recourse to historical and natural inevitability, a Zeitgeist, in the representation of its ideas. In the second half of the 19th century, Realism was offered as a polar opposite to Romanticism.[7] The decline of Romanticism during this time was associated with multiple processes, including social and political changes and the spread of nationalism.[8]						Defining the nature of Romanticism may be approached from the starting point of the primary importance of the free expression of the feelings of the artist. The importance the Romantics placed on emotion is summed up in the remark of the German painter Caspar David Friedrich that "the artist's feeling is his law".[9] To William Wordsworth, poetry should begin as "the spontaneous overflow of powerful feelings," which the poet then "recollect[s] in tranquility," evoking a new but corresponding emotion the poet can then mould into art.[10] To express these feelings, it was considered that the content of the art had to come from the imagination of the artist, with as little interference as possible from "artificial" rules that dictated what a work should consist of. Samuel Taylor Coleridge and others believed there were natural laws that the imagination—at least of a good creative artist—would unconsciously follow through artistic inspiration if left alone.[11] As well as rules, the influence of models from other works was considered to impede the creator's own imagination, so that originality was essential. The concept of the genius, or artist who was able to produce his own original work through this process of creation from nothingness, is key to Romanticism, and to be derivative was the worst sin.[12][13][14] This idea is often called "romantic originality."[15]		Not essential to Romanticism, but so widespread as to be normative, was a strong belief and interest in the importance of nature. However, this is particularly in the effect of nature upon the artist when he is surrounded by it, preferably alone. In contrast to the usually very social art of the Enlightenment, Romantics were distrustful of the human world, and tended to believe that a close connection with nature was mentally and morally healthy. Romantic art addressed its audiences with what was intended to be felt as the personal voice of the artist. So, in literature, "much of romantic poetry invited the reader to identify the protagonists with the poets themselves".[16]		According to Isaiah Berlin, Romanticism embodied "a new and restless spirit, seeking violently to burst through old and cramping forms, a nervous preoccupation with perpetually changing inner states of consciousness, a longing for the unbounded and the indefinable, for perpetual movement and change, an effort to return to the forgotten sources of life, a passionate effort at self-assertion both individual and collective, a search after means of expressing an unappeasable yearning for unattainable goals."[17]		The group of words with the root "Roman" in the various European languages, such as "romance" and "Romanesque", has a complicated history, but by the middle of the 18th century "romantic" in English and romantique in French were both in common use as adjectives of praise for natural phenomena such as views and sunsets, in a sense close to modern English usage but without the sexual connotation. The application of the term to literature first became common in Germany, where the circle around the Schlegel brothers, critics August and Friedrich, began to speak of romantische Poesie ("romantic poetry") in the 1790s, contrasting it with "classic" but in terms of spirit rather than merely dating. Friedrich Schlegel wrote in his Dialogue on Poetry (1800), "I seek and find the romantic among the older moderns, in Shakespeare, in Cervantes, in Italian poetry, in that age of chivalry, love and fable, from which the phenomenon and the word itself are derived."[18]		In both French and German the closeness of the adjective to roman, meaning the fairly new literary form of the novel, had some effect on the sense of the word in those languages. The use of the word did not become general very quickly, and was probably spread more widely in France by its persistent use by Madame de Staël in her De l'Allemagne (1813), recounting her travels in Germany.[19] In England Wordsworth wrote in a preface to his poems of 1815 of the "romantic harp" and "classic lyre",[19] but in 1820 Byron could still write, perhaps slightly disingenuously, "I perceive that in Germany, as well as in Italy, there is a great struggle about what they call 'Classical' and 'Romantic', terms which were not subjects of classification in England, at least when I left it four or five years ago".[20] It is only from the 1820s that Romanticism certainly knew itself by its name, and in 1824 the Académie française took the wholly ineffective step of issuing a decree condemning it in literature.[21]		The period typically called Romantic varies greatly between different countries and different artistic media or areas of thought. Margaret Drabble described it in literature as taking place "roughly between 1770 and 1848",[22] and few dates much earlier than 1770 will be found. In English literature, M. H. Abrams placed it between 1789, or 1798, this latter a very typical view, and about 1830, perhaps a little later than some other critics.[23] Others have proposed 1780–1830.[24] In other fields and other countries the period denominated as Romantic can be considerably different; musical Romanticism, for example, is generally regarded as only having ceased as a major artistic force as late as 1910, but in an extreme extension the Four Last Songs of Richard Strauss are described stylistically as "Late Romantic" and were composed in 1946–48.[25] However, in most fields the Romantic Period is said to be over by about 1850, or earlier.		The early period of the Romantic Era was a time of war, with the French Revolution (1789–1799) followed by the Napoleonic Wars until 1815. These wars, along with the political and social turmoil that went along with them, served as the background for Romanticism.[26] The key generation of French Romantics born between 1795–1805 had, in the words of one of their number, Alfred de Vigny, been "conceived between battles, attended school to the rolling of drums".[27] According to Jacques Barzun, there were three generations of Romantic artists. The first emerged in the 1790s and 1800s, the second in the 1820s, and the third later in the century.[28]		The more precise characterization and specific definition of Romanticism has been the subject of debate in the fields of intellectual history and literary history throughout the 20th century, without any great measure of consensus emerging. That it was part of the Counter-Enlightenment, a reaction against the Age of Enlightenment, is generally accepted in current scholarship. Its relationship to the French Revolution, which began in 1789 in the very early stages of the period, is clearly important, but highly variable depending on geography and individual reactions. Most Romantics can be said to be broadly progressive in their views, but a considerable number always had, or developed, a wide range of conservative views,[29] and nationalism was in many countries strongly associated with Romanticism, as discussed in detail below.		In philosophy and the history of ideas, Romanticism was seen by Isaiah Berlin as disrupting for over a century the classic Western traditions of rationality and the idea of moral absolutes and agreed values, leading "to something like the melting away of the very notion of objective truth",[30] and hence not only to nationalism, but also fascism and totalitarianism, with a gradual recovery coming only after World War II.[31] For the Romantics, Berlin says,		in the realm of ethics, politics, aesthetics it was the authenticity and sincerity of the pursuit of inner goals that mattered; this applied equally to individuals and groups – states, nations, movements. This is most evident in the aesthetics of romanticism, where the notion of eternal models, a Platonic vision of ideal beauty, which the artist seeks to convey, however imperfectly, on canvas or in sound, is replaced by a passionate belief in spiritual freedom, individual creativity. The painter, the poet, the composer do not hold up a mirror to nature, however ideal, but invent; they do not imitate (the doctrine of mimesis), but create not merely the means but the goals that they pursue; these goals represent the self-expression of the artist's own unique, inner vision, to set aside which in response to the demands of some "external" voice – church, state, public opinion, family friends, arbiters of taste – is an act of betrayal of what alone justifies their existence for those who are in any sense creative.[32]		Arthur Lovejoy attempted to demonstrate the difficulty of defining Romanticism in his seminal article "On The Discrimination of Romanticisms" in his Essays in the History of Ideas (1948); some scholars see Romanticism as essentially continuous with the present, some like Robert Hughes see in it the inaugural moment of modernity,[33] and some like Chateaubriand, Novalis and Samuel Taylor Coleridge see it as the beginning of a tradition of resistance to Enlightenment rationalism—a "Counter-Enlightenment"— [34][35] to be associated most closely with German Romanticism. An earlier definition comes from Charles Baudelaire: "Romanticism is precisely situated neither in choice of subject nor exact truth, but in the way of feeling."[36]		The end of the Romantic era is marked in some areas by a new style of Realism, which affected literature, especially the novel and drama, painting, and even music, through Verismo opera. This movement was led by France, with Balzac and Flaubert in literature and Courbet in painting; Stendhal and Goya were important precursors of Realism in their respective media. However, Romantic styles, now often representing the established and safe style against which Realists rebelled, continued to flourish in many fields for the rest of the century and beyond. In music such works from after about 1850 are referred to by some writers as "Late Romantic" and by others as "Neoromantic" or "Postromantic", but other fields do not usually use these terms; in English literature and painting the convenient term "Victorian" avoids having to characterise the period further.		In northern Europe, the Early Romantic visionary optimism and belief that the world was in the process of great change and improvement had largely vanished, and some art became more conventionally political and polemical as its creators engaged polemically with the world as it was. Elsewhere, including in very different ways the United States and Russia, feelings that great change was underway or just about to come were still possible. Displays of intense emotion in art remained prominent, as did the exotic and historical settings pioneered by the Romantics, but experimentation with form and technique was generally reduced, often replaced with meticulous technique, as in the poems of Tennyson or many paintings. If not realist, late 19th-century art was often extremely detailed, and pride was taken in adding authentic details in a way that earlier Romantics did not trouble with. Many Romantic ideas about the nature and purpose of art, above all the pre-eminent importance of originality, remained important for later generations, and often underlie modern views, despite opposition from theorists.		In literature, Romanticism found recurrent themes in the evocation or criticism of the past, the cult of "sensibility" with its emphasis on women and children, the isolation of the artist or narrator, and respect for nature. Furthermore, several romantic authors, such as Edgar Allan Poe and Nathaniel Hawthorne, based their writings on the supernatural/occult and human psychology. Romanticism tended to regard satire as something unworthy of serious attention, a prejudice still influential today.[37]		The precursors of Romanticism in English poetry go back to the middle of the 18th century, including figures such as Joseph Warton (headmaster at Winchester College) and his brother Thomas Warton, Professor of Poetry at Oxford University.[38] Joseph maintained that invention and imagination were the chief qualities of a poet. Thomas Chatterton is generally considered the first Romantic poet in English.[39] The Scottish poet James Macpherson influenced the early development of Romanticism with the international success of his Ossian cycle of poems published in 1762, inspiring both Goethe and the young Walter Scott. Both Chatterton and Macpherson's work involved elements of fraud, as what they claimed was earlier literature that they had discovered or compiled was, in fact, entirely their own work. The Gothic novel, beginning with Horace Walpole's The Castle of Otranto (1764), was an important precursor of one strain of Romanticism, with a delight in horror and threat, and exotic picturesque settings, matched in Walpole's case by his role in the early revival of Gothic architecture. Tristram Shandy, a novel by Laurence Sterne (1759–67) introduced a whimsical version of the anti-rational sentimental novel to the English literary public.		An early German influence came from Johann Wolfgang von Goethe, whose 1774 novel The Sorrows of Young Werther had young men throughout Europe emulating its protagonist, a young artist with a very sensitive and passionate temperament. At that time Germany was a multitude of small separate states, and Goethe's works would have a seminal influence in developing a unifying sense of nationalism. Another philosophic influence came from the German idealism of Johann Gottlieb Fichte and Friedrich Schelling, making Jena (where Fichte lived, as well as Schelling, Hegel, Schiller and the brothers Schlegel) a center for early German Romanticism (see Jena Romanticism). Important writers were Ludwig Tieck, Novalis (Heinrich von Ofterdingen, 1799), Heinrich von Kleist and Friedrich Hölderlin. Heidelberg later became a center of German Romanticism, where writers and poets such as Clemens Brentano, Achim von Arnim, and Joseph Freiherr von Eichendorff met regularly in literary circles.		Important motifs in German Romanticism are travelling, nature, for example the German Forest, and Germanic myths. The later German Romanticism of, for example E. T. A. Hoffmann's Der Sandmann (The Sandman), 1817, and Joseph Freiherr von Eichendorff's Das Marmorbild (The Marble Statue), 1819, was darker in its motifs and has gothic elements. The significance to Romanticism of childhood innocence, the importance of imagination, and racial theories all combined to give an unprecedented importance to folk literature, non-classical mythology and children's literature, above all in Germany. Brentano and von Arnim were significant literary figures who together published Des Knaben Wunderhorn ("The Boy's Magic Horn" or cornucopia), a collection of versified folk tales, in 1806–08. The first collection of Grimms' Fairy Tales by the Brothers Grimm was published in 1812.[40] Unlike the much later work of Hans Christian Andersen, who was publishing his invented tales in Danish from 1835, these German works were at least mainly based on collected folk tales, and the Grimms remained true to the style of the telling in their early editions, though later rewriting some parts. One of the brothers, Jacob, published in 1835 Deutsche Mythologie, a long academic work on Germanic mythology.[41] Another strain is exemplified by Schiller's highly emotional language and the depiction of physical violence in his play The Robbers of 1781.		In English literature, the key figures of the Romantic movement are considered to be the group of poets including William Wordsworth, Samuel Taylor Coleridge, John Keats, Lord Byron, Percy Bysshe Shelley, and the much older William Blake, followed later by the isolated figure of John Clare. Also such novelists as Walter Scott from Scotland and Mary Shelley, and the essayists William Hazlitt and Charles Lamb. The publication in 1798 of Lyrical Ballads, with many of the finest poems by Wordsworth and Coleridge, is often held to mark the start of the movement. The majority of the poems were by Wordsworth, and many dealt with the lives of the poor in his native Lake District, or his feelings about nature—which he more fully developed in his long poem The Prelude, never published in his lifetime. The longest poem in the volume was Coleridge's The Rime of the Ancient Mariner, which showed the Gothic side of English Romanticism, and the exotic settings that many works featured. In the period when they were writing, the Lake Poets were widely regarded as a marginal group of radicals, though they were supported by the critic and writer William Hazlitt and others.		In contrast Lord Byron and Walter Scott achieved enormous fame and influence throughout Europe with works exploiting the violence and drama of their exotic and historical settings; Goethe called Byron "undoubtedly the greatest genius of our century".[42] Scott achieved immediate success with his long narrative poem The Lay of the Last Minstrel in 1805, followed by the full epic poem Marmion in 1808. Both were set in the distant Scottish past, already evoked in Ossian; Romanticism and Scotland were to have a long and fruitful partnership. Byron had equal success with the first part of Childe Harold's Pilgrimage in 1812, followed by four "Turkish tales", all in the form of long poems, starting with The Giaour in 1813, drawing from his Grand Tour, which had reached Ottoman Europe, and orientalizing the themes of the Gothic novel in verse. These featured different variations of the "Byronic hero", and his own life contributed a further version. Scott meanwhile was effectively inventing the historical novel, beginning in 1814 with Waverley, set in the 1745 Jacobite Rising, which was an enormous and highly profitable success, followed by over 20 further Waverley Novels over the next 17 years, with settings going back to the Crusades that he had researched to a degree that was new in literature.[43]		In contrast to Germany, Romanticism in English literature had little connection with nationalism, and the Romantics were often regarded with suspicion for the sympathy many felt for the ideals of the French Revolution, whose collapse and replacement with the dictatorship of Napoleon was, as elsewhere in Europe, a shock to the movement. Though his novels celebrated Scottish identity and history, Scott was politically a firm Unionist. Several spent much time abroad, and a famous stay on Lake Geneva with Byron and Shelley in 1816 produced the hugely influential novel Frankenstein by Shelley's wife-to-be Mary Shelley and the novella The Vampyre by Byron's doctor John William Polidori. The lyrics of Robert Burns in Scotland and Thomas Moore, from Ireland reflected in different ways their countries and the Romantic interest in folk literature, but neither had a fully Romantic approach to life or their work.		Though they have modern critical champions such as György Lukács, Scott's novels are today more likely to be experienced in the form of the many operas that composers continued to base on them over the following decades, such as Donizetti's Lucia di Lammermoor and Vincenzo Bellini's I puritani (both 1835). Byron is now most highly regarded for his short lyrics and his generally unromantic prose writings, especially his letters, and his unfinished satire Don Juan.[44] Unlike many Romantics, Byron's widely publicised personal life appeared to match his work, and his death at 36 in 1824 from disease when helping the Greek War of Independence appeared from a distance to be a suitably Romantic end, entrenching his legend.[45] Keats in 1821 and Shelley in 1822 both died in Italy, Blake (at almost 70) in 1827, and Coleridge largely ceased to write in the 1820s. Wordsworth was by 1820 respectable and highly regarded, holding a government sinecure, but wrote relatively little. In the discussion of English literature, the Romantic period is often regarded as finishing around the 1820s, or sometimes even earlier, although many authors of the succeeding decades were no less committed to Romantic values.		The most significant novelist in English during the peak Romantic period, other than Walter Scott, was Jane Austen, whose essentially conservative world-view had little in common with her Romantic contemporaries, retaining a strong belief in decorum and social rules, though critics[who?] have detected tremors under the surface of some works, especially Mansfield Park (1814) and Persuasion (1817).[46] But around the mid-century the undoubtedly Romantic novels of the Yorkshire-based Brontë family appeared, in particular Charlotte's Jane Eyre and Emily's Wuthering Heights, which were both published in 1847.		Byron, Keats and Shelley all wrote for the stage, but with little success in England, with Shelley's The Cenci perhaps the best work produced, though that was not played in a public theatre in England until a century after his death. Byron's plays, along with dramatizations of his poems and Scott's novels, were much more popular on the Continent, and especially in France, and through these versions several were turned into operas, many still performed today. If contemporary poets had little success on the stage, the period was a legendary one for performances of Shakespeare, and went some way to restoring his original texts and removing the Augustan "improvements" to them. The greatest actor of the period, Edmund Kean, restored the tragic ending to King Lear;[47] Coleridge said that, “Seeing him act was like reading Shakespeare by flashes of lightning.”[48]		Although after union with England in 1707 Scotland increasingly adopted English language and wider cultural norms, its literature developed a distinct national identity and began to enjoy an international reputation. Allan Ramsay (1686–1758) laid the foundations of a reawakening of interest in older Scottish literature, as well as leading the trend for pastoral poetry, helping to develop the Habbie stanza as a poetic form.[49] James Macpherson (1736–96) was the first Scottish poet to gain an international reputation. Claiming to have found poetry written by the ancient bard Ossian, he published translations that acquired international popularity, being proclaimed as a Celtic equivalent of the Classical epics. Fingal, written in 1762, was speedily translated into many European languages, and its appreciation of natural beauty and treatment of the ancient legend has been credited more than any single work with bringing about the Romantic movement in European, and especially in German literature, through its influence on Johann Gottfried von Herder and Johann Wolfgang von Goethe.[50] It was also popularised in France by figures that included Napoleon.[51] Eventually it became clear that the poems were not direct translations from the Gaelic, but flowery adaptations made to suit the aesthetic expectations of his audience.[52]		Robert Burns (1759–96) and Walter Scott (1771–1832) were highly influenced by the Ossian cycle. Burns, an Ayrshire poet and lyricist, is widely regarded as the national poet of Scotland and a major influence on the Romantic movement. His poem (and song) "Auld Lang Syne" is often sung at Hogmanay (the last day of the year), and "Scots Wha Hae" served for a long time as an unofficial national anthem of the country.[53] Scott began as a poet and also collected and published Scottish ballads. His first prose work, Waverley in 1814, is often called the first historical novel.[54] It launched a highly successful career, with other historical novels such as Rob Roy (1817), The Heart of Midlothian (1818) and Ivanhoe (1820). Scott probably did more than any other figure to define and popularise Scottish cultural identity in the nineteenth century.[55] Other major literary figures connected with Romanticism include the poets and novelists James Hogg (1770–1835), Allan Cunningham (1784–1842) and John Galt (1779–1839).[56] One of the most significant figures of the Romantic movement, Lord Byron, was brought up in Scotland until he inherited his family's English peerage.[57]		Scotland was also the location of two of the most important literary magazines of the era, The Edinburgh Review (founded in 1802) and Blackwood's Magazine (founded in 1817), which had a major impact on the development of British literature and drama in the era of Romanticism.[58][59] Ian Duncan and Alex Benchimol suggest that publications like the novels of Scott and these magazines were part of a highly dynamic Scottish Romanticism that by the early nineteenth century, caused Edinburgh to emerge as the cultural capital of Britain and become central to a wider formation of a "British Isles nationalism."[60]		Scottish "national drama" emerged in the early 1800s, as plays with specifically Scottish themes began to dominate the Scottish stage. Theatres had been discouraged by the Church of Scotland and fears of Jacobite assemblies. In the later eighteenth century, many plays were written for and performed by small amateur companies and were not published and so most have been lost. Towards the end of the century there were "closet dramas", primarily designed to be read, rather than performed, including work by Scott, Hogg, Galt and Joanna Baillie (1762–1851), often influenced by the ballad tradition and Gothic Romanticism.[61]		Romanticism was relatively late in developing in French literature, even more so than in the visual arts. The 18th-century precursor to Romanticism, the cult of sensibility, had become associated with the Ancien regime, and the French Revolution had been more of an inspiration to foreign writers than those experiencing it at first hand. The first major figure was François-René de Chateaubriand, a minor aristocrat who had remained a royalist throughout the Revolution, and returned to France from exile in England and America under Napoleon, with whose regime he had an uneasy relationship. His writings, all in prose, included some fiction, such as his influential novella of exile René (1802), which anticipated Byron in its alienated hero, but mostly contemporary history and politics, his travels, a defence of religion and the medieval spirit (Génie du christianisme 1802), and finally in the 1830s and 1840s his enormous autobiography Mémoires d'Outre-Tombe ("Memoirs from beyond the grave").[62]		After the Bourbon Restoration, French Romanticism developed in the lively world of Parisian theatre, with productions of Shakespeare, Schiller (in France a key Romantic author), and adaptations of Scott and Byron alongside French authors, several of whom began to write in the late 1820s. Cliques of pro- and anti-Romantics developed, and productions were often accompanied by raucous vocalizing by the two sides, including the shouted assertion by one theatregoer in 1822 that "Shakespeare, c'est l'aide-de-camp de Wellington" ("Shakespeare is Wellington's aide-de-camp").[63] Alexandre Dumas began as a dramatist, with a series of successes beginning with Henri III et sa cour (1829) before turning to novels that were mostly historical adventures somewhat in the manner of Scott, most famously The Three Musketeers and The Count of Monte Cristo, both of 1844. Victor Hugo published as a poet in the 1820s before achieving success on the stage with Hernani—a historical drama in a quasi-Shakespearian style that had famously riotous performances, themselves as much a spectacle as the play, on its first run in 1830.[64] Like Dumas, he is best known for his novels, and was already writing The Hunchback of Notre-Dame (1831), one of the best known works of his long career. The preface to his unperformed play "Cromwell" gives an important manifesto of French Romanticism, stating that "there are no rules, or models". The career of Prosper Mérimée followed a similar pattern; he is now best known as the originator of the story of Carmen, with his novella of 1845. Alfred de Vigny remains best known as a dramatist, with his play on the life of the English poet Chatterton (1835) perhaps his best work.		French Romantic poets of the 1830s to 1850s include Alfred de Musset, Gérard de Nerval, Alphonse de Lamartine and the flamboyant Théophile Gautier, whose prolific output in various forms continued until his death in 1872. George Sand took over from Germaine de Staël as the leading female writer, and was a central figure of the Parisian literary scene, famous both for her novels and criticism and her affairs with Chopin and several others.[65]		Stendhal is today probably the most highly regarded French novelist of the period, but he stands in a complex relation with Romanticism, and is notable for his penetrating psychological insight into his characters and his realism, qualities rarely prominent in Romantic fiction. As a survivor of the French retreat from Moscow in 1812, fantasies of heroism and adventure had little appeal for him, and like Goya he is often seen as a forerunner of Realism. His most important works are Le Rouge et le Noir (The Red and the Black, 1830) and La Chartreuse de Parme (The Charterhouse of Parma, 1839).		Romanticism in Poland is often taken to begin with the publication of Adam Mickiewicz's first poems in 1822, and end with the crushing of the January Uprising of 1863 against the Russians. It was strongly marked by interest in Polish history.[66] Polish Romanticism revived the old "Sarmatism" traditions of the szlachta or Polish nobility. Old traditions and customs were revived and portrayed in a positive light in the Polish messianic movement and in works of great Polish poets such as Adam Mickiewicz (Pan Tadeusz), Juliusz Słowacki and Zygmunt Krasiński, as well as prose writers such as Henryk Sienkiewicz. This close connection between Polish Romanticism and Polish history became one of the defining qualities of the literature of Polish Romanticism period, differentiating it from that of other countries. They had not suffered the loss of national statehood as was the case with Poland.[67] Influenced by the general spirit and main ideas of European Romanticism, the literature of Polish Romanticism is unique, as many scholars have pointed out, in having developed largely outside of Poland and in its emphatic focus upon the issue of Polish nationalism. The Polish intelligentsia, along with leading members of its government, left Poland in the early 1830s, during what is referred to as the "Great Emigration," resettling in France, Germany, Great Britain, Turkey, and the United States.		Their art featured emotionalism and irrationality, fantasy and imagination, personality cults, folklore and country life, and the propagation of ideals of freedom. In the second period, many of the Polish Romantics worked abroad, often banished from Poland by the occupying powers due to their politically subversive ideas. Their work became increasingly dominated by the ideals of political struggle for freedom and their country's sovereignty. Elements of mysticism became more prominent. There developed the idea of the poeta wieszcz (the prophet). The wieszcz (bard) functioned as spiritual leader to the nation fighting for its independence. The most notable poet so recognized was Adam Mickiewicz.		Zygmunt Krasinski also wrote to inspire political and religious hope in his countrymen. Unlike his predecessors, who called for victory at whatever price in Poland's struggle against Russia, Krasinski emphasized Poland's spiritual role in its fight for independence, advocating an intellectual rather than a military superiority. His works best exemplify the Messianic movement in Poland: in two early dramas, Nie-boska komedyia[68] (1835; The Undivine Comedy) and Irydion (1836; Iridion), as well as in the later Psalmy przyszłości (1845), he asserted that Poland was the Christ of Europe: specifically chosen by God to carry the world's burdens, to suffer, and eventually be resurrected.		Early Russian Romanticism is associated with the writers Konstantin Batyushkov (A Vision on the Shores of the Lethe, 1809), Vasily Zhukovsky (The Bard, 1811; Svetlana, 1813) and Nikolay Karamzin (Poor Liza, 1792; Julia, 1796; Martha the Mayoress, 1802; The Sensitive and the Cold, 1803). However the principal exponent of Romanticism in Russia is Alexander Pushkin (The Prisoner of the Caucasus, 1820–1821; The Robber Brothers, 1822; Ruslan and Ludmila, 1820; Eugene Onegin, 1825–1832). Pushkin's work influenced many writers in the 19th century and led to his eventual recognition as Russia's greatest poet.[69] Other Russian Romantic poets include Mikhail Lermontov (A Hero of Our Time, 1839), Fyodor Tyutchev (Silentium!, 1830), Yevgeny Baratynsky (Eda, 1826), Anton Delvig, and Wilhelm Küchelbecker.		Influenced heavily by Lord Byron, Lermontov sought to explore the Romantic emphasis on metaphysical discontent with society and self, while Tyutchev's poems often described scenes of nature or passions of love. Tyutchev commonly operated with such categories as night and day, north and south, dream and reality, cosmos and chaos, and the still world of winter and spring teeming with life. Baratynsky's style was fairly classical in nature, dwelling on the models of the previous century.		Romanticism in Spanish literature developed a well-known literature with a huge variety of poets and playwrights. The most important Spanish poet during this movement was José de Espronceda. After him there were other poets like Gustavo Adolfo Bécquer, Mariano José de Larra and the dramatist José Zorrilla, author of Don Juan Tenorio. Before them may be mentioned the pre-romantics José Cadalso and Manuel José Quintana.[70] The plays of Antonio García Gutiérrez were adapted to produce Giuseppe Verdi's operas Il trovatore and Simon Boccanegra. Spanish Romanticism also influenced regional literatures. For example, in Catalonia and in Galicia there was a national boom of writers in the local languages, like the Catalan Jacint Verdaguer and the Galician Rosalía de Castro, the main figures of the national revivalist movements Renaixença and Rexurdimento, respectively.[71]		Modern Portuguese poetry develops its character from the work of its Romantic epitome, Almeida Garrett, a very prolific writer who helped shape the genre with the masterpiece Folhas Caídas (1853). This late arrival of a truly personal Romantic style would linger on to the beginning of the 20th century, notably through the works of poets such as Alexandre Herculano, Cesário Verde and António Nobre. However, an early Portuguese expression of Romanticism is found already in Manuel Maria Barbosa du Bocage, especially in his sonnets dated at the end of the 18th century.		Romanticism in Italian literature was a minor movement, yet still important; it began officially in 1816 when Mme de Staël wrote an article in the journal Biblioteca italiana called "Sulla maniera e l'utilità delle traduzioni", inviting Italian people to reject Neoclassicism and to study new authors from other countries. Before that date, Ugo Foscolo had already published poems anticipating Romantic themes. The most important Romantic writers were Ludovico di Breme, Pietro Borsieri and Giovanni Berchet. Better known authors such as Alessandro Manzoni and Giacomo Leopardi were influenced by Enlightenment as well as by Romanticism and Classicism.[72]		Spanish-speaking South American Romanticism was influenced heavily by Esteban Echeverría, who wrote in the 1830 and 1840s. His writings were influenced by his hatred for the Argentine dictator Juan Manuel de Rosas, and filled with themes of blood and terror, using the metaphor of a slaughterhouse to portray the violence of Rosas' dictatorship.		Brazilian Romanticism is characterized and divided in three different periods. The first one is basically focused on the creation of a sense of national identity, using the ideal of the heroic Indian. Some examples include José de Alencar, who wrote Iracema and O Guarani, and Gonçalves Dias, renowned by the poem "Canção do Exílio" (Song of the Exile). The second period, sometimes called Ultra-Romanticism, is marked by a profound influence of European themes and traditions, involving the melancholy, sadness and despair related to unobtainable love. Goethe and Lord Byron are commonly quoted in these works. The third cycle is marked by social poetry, especially the abolitionist movement, and it includes Álvares de Azevedo and Castro Alves.[73]		In the United States, at least by 1818 with William Cullen Bryant's "To a Waterfowl", Romantic poetry was being published. American Romantic Gothic literature made an early appearance with Washington Irving's The Legend of Sleepy Hollow (1820) and Rip Van Winkle (1819), followed from 1823 onwards by the Leatherstocking Tales of James Fenimore Cooper, with their emphasis on heroic simplicity and their fervent landscape descriptions of an already-exotic mythicized frontier peopled by "noble savages", similar to the philosophical theory of Rousseau, exemplified by Uncas, from The Last of the Mohicans. There are picturesque "local color" elements in Washington Irving's essays and especially his travel books. Edgar Allan Poe's tales of the macabre and his balladic poetry were more influential in France than at home, but the romantic American novel developed fully with the atmosphere and melodrama of Nathaniel Hawthorne's The Scarlet Letter (1850). Later Transcendentalist writers such as Henry David Thoreau and Ralph Waldo Emerson still show elements of its influence and imagination, as does the romantic realism of Walt Whitman. The poetry of Emily Dickinson—nearly unread in her own time—and Herman Melville's novel Moby-Dick can be taken as epitomes of American Romantic literature. By the 1880s, however, psychological and social realism were competing with Romanticism in the novel.		The European Romantic movement reached America in the early 19th century. American Romanticism was just as multifaceted and individualistic as it was in Europe. Like the Europeans, the American Romantics demonstrated a high level of moral enthusiasm, commitment to individualism and the unfolding of the self, an emphasis on intuitive perception, and the assumption that the natural world was inherently good, while human society was filled with corruption.[74]		Romanticism became popular in American politics, philosophy and art. The movement appealed to the revolutionary spirit of America as well as to those longing to break free of the strict religious traditions of early settlement. The Romantics rejected rationalism and religious intellect. It appealed to those in opposition of Calvinism, which includes the belief that the destiny of each individual is preordained. The Romantic movement gave rise to New England Transcendentalism, which portrayed a less restrictive relationship between God and Universe. The new philosophy presented the individual with a more personal relationship with God. Transcendentalism and Romanticism appealed to Americans in a similar fashion, for both privileged feeling over reason, individual freedom of expression over the restraints of tradition and custom. It often involved a rapturous response to nature. It encouraged the rejection of harsh, rigid Calvinism, and promised a new blossoming of American culture.[74][75]		American Romanticism embraced the individual and rebelled against the confinement of neoclassicism and religious tradition. The Romantic movement in America created a new literary genre that continues to influence American writers. Novels, short stories, and poems replaced the sermons and manifestos of yore. Romantic literature was personal, intense, and portrayed more emotion than ever seen in neoclassical literature. America's preoccupation with freedom became a great source of motivation for Romantic writers as many were delighted in free expression and emotion without so much fear of ridicule and controversy. They also put more effort into the psychological development of their characters, and the main characters typically displayed extremes of sensitivity and excitement.[76]		The works of the Romantic Era also differed from preceding works in that they spoke to a wider audience, partly reflecting the greater distribution of books as costs came down during the period.[26]		In the visual arts, Romanticism first showed itself in landscape painting, where from as early as the 1760s British artists began to turn to wilder landscapes and storms, and Gothic architecture, even if they had to make do with Wales as a setting. Caspar David Friedrich and J. M. W. Turner were born less than a year apart in 1774 and 1775 respectively and were to take German and English landscape painting to their extremes of Romanticism, but both their artistic sensibilities were formed when forms of Romanticism was already strongly present in art. John Constable, born in 1776, stayed closer to the English landscape tradition, but in his largest "six-footers" insisted on the heroic status of a patch of the working countryside where he had grown up—challenging the traditional hierarchy of genres, which relegated landscape painting to a low status. Turner also painted very large landscapes, and above all, seascapes. Some of these large paintings had contemporary settings and staffage, but others had small figures that turned the work into history painting in the manner of Claude Lorrain, like Salvator Rosa a late Baroque artist whose landscapes had elements that Romantic painters repeatedly turned to. Friedrich often used single figures, or features like crosses, set alone amidst a huge landscape, "making them images of the transitoriness of human life and the premonition of death."[77]		Other groups of artists expressed feelings that verged on the mystical, many largely abandoning classical drawing and proportions. These included William Blake and Samuel Palmer and the other members of the Ancients in England, and in Germany Philipp Otto Runge. Like Friedrich, none of these artists had significant influence after their deaths for the rest of the 19th century, and were 20th century rediscoveries from obscurity, though Blake was always known as a poet, and Norway's leading painter Johan Christian Dahl was heavily influenced by Friedrich. The Rome-based Nazarene movement of German artists, active from 1810, took a very different path, concentrating on medievalizing history paintings with religious and nationalist themes.[78]		The arrival of Romanticism in French art was delayed by the strong hold of Neoclassicism on the academies, but from the Napoleonic period it became increasingly popular, initially in the form of history paintings propagandising for the new regime, of which Girodet's Ossian receiving the Ghosts of the French Heroes, for Napoleon's Château de Malmaison, was one of the earliest. Girodet's old teacher David was puzzled and disappointed by his pupil's direction, saying: "Either Girodet is mad or I no longer know anything of the art of painting".[79] A new generation of the French school,[80] developed personal Romantic styles, though still concentrating on history painting with a political message. Théodore Géricault (1791–1824) had his first success with The Charging Chasseur, a heroic military figure derived from Rubens, at the Paris Salon of 1812 in the years of the Empire, but his next major completed work, The Raft of the Medusa of 1821, remains the greatest achievement of the Romantic history painting, which in its day had a powerful anti-government message.		Eugène Delacroix (1798–1863) made his first Salon hits with The Barque of Dante (1822), The Massacre at Chios (1824) and Death of Sardanapalus (1827). The second was a scene from the Greek War of Independence, completed the year Byron died there, and the last was a scene from one of Byron's plays. With Shakespeare, Byron was to provide the subject matter for many other works of Delacroix, who also spent long periods in North Africa, painting colourful scenes of mounted Arab warriors. His Liberty Leading the People (1830) remains, with the Medusa, one of the best-known works of French Romantic painting. Both reflected current events, and increasingly "history painting", literally "story painting", a phrase dating back to the Italian Renaissance meaning the painting of subjects with groups of figures, long considered the highest and most difficult form of art, did indeed become the painting of historical scenes, rather than those from religion or mythology.[81]		Francisco Goya was called "the last great painter in whose art thought and observation were balanced and combined to form a faultless unity".[82] But the extent to which he was a Romantic is a complex question. In Spain, there was still a struggle to introduce the values of the Enlightenment, in which Goya saw himself as a participant. The demonic and anti-rational monsters thrown up by his imagination are only superficially similar to those of the Gothic fantasies of northern Europe, and in many ways he remained wedded to the classicism and realism of his training, as well as looking forward to the Realism of the later 19th century.[83] But he, more than any other artist of the period, exemplified the Romantic values of the expression of the artist's feelings and his personal imaginative world.[84] He also shared with many of the Romantic painters a more free handling of paint, emphasized in the new prominence of the brushstroke and impasto, which tended to be repressed in neoclassicism under a self-effacing finish.		Sculpture remained largely impervious to Romanticism, probably partly for technical reasons, as the most prestigious material of the day, marble, does not lend itself to expansive gestures. The leading sculptors in Europe, Antonio Canova and Bertel Thorvaldsen, were both based in Rome and firm Neoclassicists, not at all tempted to allow influence from medieval sculpture, which would have been one possible approach to Romantic sculpture. When it did develop, true Romantic sculpture—with the exception of a few artists such as Rudolf Maison—[85] rather oddly was missing in Germany, and mainly found in France, with François Rude, best known from his group of the 1830s from the Arc de Triomphe in Paris, David d'Angers, and Auguste Préault. Préault's plaster relief entitled Slaughter, which represented the horrors of wars with exacerbated passion, caused so much scandal at the 1834 Salon that Préault was banned from this official annual exhibition for nearly twenty years.[86] In Italy, the most important Romantic sculptor was Lorenzo Bartolini.[87]		Francisco Goya, The Third of May 1808, 1814		Théodore Géricault, The Raft of the Medusa, 1819		Eugène Delacroix, Liberty Leading the People 1830		J.M.W. Turner, The Fighting Téméraire tugged to her last Berth to be broken up, 1839		In France, historical painting on idealized medieval and Renaissance themes is known as the style Troubadour, a term with no equivalent for other countries, though the same trends occurred there. Delacroix, Ingres and Richard Parkes Bonington all worked in this style, as did lesser specialists such as Pierre-Henri Révoil (1776–1842) and Fleury-François Richard (1777–1852). Their pictures are often small, and feature intimate private and anecdotal moments, as well as those of high drama. The lives of great artists such as Raphael were commemorated on equal terms with those of rulers, and fictional characters were also depicted. Fleury-Richard's Valentine of Milan weeping for the death of her husband, shown in the Paris Salon of 1802, marked the arrival of the style, which lasted until the mid-century, before being subsumed into the increasingly academic history painting of artists like Paul Delaroche.[88]		Another trend was for very large apocalyptic history paintings, often combining extreme natural events, or divine wrath, with human disaster, attempting to outdo The Raft of the Medusa, and now often drawing comparisons with effects from Hollywood. The leading English artist in the style was John Martin, whose tiny figures were dwarfed by enormous earthquakes and storms, and worked his way through the biblical disasters, and those to come in the final days. Other works such as Delacroix's Death of Sardanapalus included larger figures, and these often drew heavily on earlier artists, especially Poussin and Rubens, with extra emotionalism and special effects.		Elsewhere in Europe, leading artists adopted Romantic styles: in Russia there were the portraitists Orest Kiprensky and Vasily Tropinin, with Ivan Aivazovsky specializing in marine painting, and in Norway Hans Gude painted scenes of fjords. In Italy Francesco Hayez (1791–1882) was the leading artist of Romanticism in mid-19th-century Milan. His long, prolific and extremely successful career saw him begin as a Neoclassical painter, pass right through the Romantic period, and emerge at the other end as a sentimental painter of young women. His Romantic period included many historical pieces of "Troubadour" tendencies, but on a very large scale, that are heavily influenced by Gian Battista Tiepolo and other late Baroque Italian masters.		Literary Romanticism had its counterpart in the American visual arts, most especially in the exaltation of an untamed American landscape found in the paintings of the Hudson River School. Painters like Thomas Cole, Albert Bierstadt and Frederic Edwin Church and others often expressed Romantic themes in their paintings. They sometimes depicted ancient ruins of the old world, such as in Fredric Edwin Church’s piece Sunrise in Syria. These works reflected the Gothic feelings of death and decay. They also show the Romantic ideal that Nature is powerful and will eventually overcome the transient creations of men. More often, they worked to distinguish themselves from their European counterparts by depicting uniquely American scenes and landscapes. This idea of an American identity in the art world is reflected in W. C. Bryant’s poem, To Cole, the Painter, Departing for Europe, where Bryant encourages Cole to remember the powerful scenes that can only be found in America.		Some American paintings (such as Albert Bierstadt’s The Rocky Mountains, Lander's Peak) promote the literary idea of the “noble savage” by portraying idealized Native Americans living in harmony with the natural world. Thomas Cole's paintings tend towards allegory, explicit in The Voyage of Life series painted in the early 1840s, showing the stages of life set amidst an awesome and immense nature.		Thomas Cole, Childhood, one of the 4 scenes in The Voyage of Life, 1842		William Blake, Albion Rose, 1794-5		Louis Janmot, from his series "The Poem of the Soul", before 1854		Thomas Cole, 1842, The Voyage of Life Old Age		Musical Romanticism is predominantly a German phenomenon—so much so that one respected French reference work defines it entirely in terms of "The role of music in the aesthetics of German romanticism".[89] Another French encyclopedia holds that the German temperament generally "can be described as the deep and diverse action of romanticism on German musicians", and that there is only one true representative of Romanticism in French music, Hector Berlioz, while in Italy, the sole great name of musical Romanticism is Giuseppe Verdi, "a sort of [Victor] Hugo of opera, gifted with a real genius for dramatic effect". Nevertheless, the huge popularity of German Romantic music led, "whether by imitation or by reaction", to an often nationalistically inspired vogue amongst Polish, Hungarian, Russian, Czech, and Scandinavian musicians, successful "perhaps more because of its extra-musical traits than for the actual value of musical works by its masters".[90]		Although the term "Romanticism" when applied to music has come to imply the period roughly from 1800 until 1850, or else until around 1900, the contemporary application of "romantic" to music did not coincide with this modern interpretation. Indeed, one of the earliest sustained applications of the term to music occurs in 1789, in the Mémoires of André Grétry.[91] This is of particular interest because it is a French source on a subject mainly dominated by Germans, but also because it explicitly acknowledges its debt to Jean-Jacques Rousseau (himself a composer, amongst other things) and, by so doing, establishes a link to one of the major influences on the Romantic movement generally.[92] In 1810 E.T.A. Hoffmann named Mozart, Haydn and Beethoven as "the three masters of instrumental compositions" who "breathe one and the same romantic spirit". He justified his view on the basis of these composers' depth of evocative expression and their marked individuality. In Haydn's music, according to Hoffmann, "a child-like, serene disposition prevails", while Mozart (in the late E-flat major Symphony, for example) "leads us into the depths of the spiritual world," with elements of fear, love, and sorrow, "a presentiment of the infinite ... in the eternal dance of the spheres". Beethoven's music, on the other hand, conveys a sense of "the monstrous and immeasurable," with the pain of an endless longing that "will burst our breasts in a fully coherent concord of all the passions."[93] This elevation in the valuation of pure emotion resulted in the promotion of music from the subordinate position it had held in relation to the verbal and plastic arts during the Enlightenment. Because music was considered to be free of the constraints of reason, imagery, or any other precise concept, it came to be regarded, first in the writings of Wackenroder and Tieck and later by writers such as Schelling and Wagner, as preeminent among the arts, the one best able to express the secrets of the universe, to evoke the spirit world, infinity, and the absolute.[94]		This chronologic agreement of musical and literary Romanticism continued as far as the middle of the 19th century, when Richard Wagner denigrated the music of Meyerbeer and Berlioz as "neoromantic": "The Opera, to which we shall now return, has swallowed down the Neoromanticism of Berlioz, too, as a plump, fine-flavoured oyster, whose digestion has conferred on it anew a brisk and well-to-do appearance."[95]		It was only toward the end of the 19th century that the newly emergent discipline of Musikwissenschaft (musicology)—itself a product of the historicizing proclivity of the age—attempted a more scientific periodization of music history, and a distinction between Viennese Classical and Romantic periods was proposed. The key figure in this trend was Guido Adler, who viewed Beethoven and Franz Schubert as transitional but essentially Classical composers, with Romanticism achieving full maturity only in the post-Beethoven generation of Frédéric Chopin, Robert Schumann, Berlioz, and Franz Liszt. From Adler's viewpoint, found in books like Der Stil in der Musik (1911), composers of the New German School and various late-19th-century nationalist composers were not Romantics but "moderns" or "realists" (by analogy with the fields of painting and literature), and this schema remained prevalent through the first decades of the 20th century.[92]		By the second quarter of the 20th century, an awareness that radical changes in musical syntax had occurred during the early 1900s caused another shift in historical viewpoint, and the change of century came to be seen as marking a decisive break with the musical past. This in turn led historians such as Alfred Einstein[96] to extend the musical "Romantic Era" throughout the 19th century and into the first decade of the 20th. It has continued to be referred to as such in some of the standard music references such as The Oxford Companion to Music[97] and Grout's History of Western Music[98] but was not unchallenged. For example, the prominent German musicologist Friedrich Blume, the chief editor of the first edition of Die Musik in Geschichte und Gegenwart (1949–86), accepted the earlier position that Classicism and Romanticism together constitute a single period beginning in the middle of the 18th century, but at the same time held that it continued into the 20th century, including such pre–World War II developments as expressionism and neoclassicism.[99] This is reflected in some notable recent reference works such as the New Grove Dictionary of Music and Musicians[92] and the new edition of Musik in Geschichte und Gegenwart.[100]		Franz Liszt, 1847		Daniel Auber, c.1868		Giovanni Boldini, Portrait of Giuseppe Verdi, 1886		Robert Schumann, 1839		Hector Berlioz, 1850		Richard Wagner, c. 1870s		Giacomo Meyerbeer, 1847		Felix Mendelssohn, 1839		In the contemporary music culture, the romantic musician followed a public career depending on sensitive middle-class audiences rather than on a courtly patron, as had been the case with earlier musicians and composers. Public persona characterized a new generation of virtuosi who made their way as soloists, epitomized in the concert tours of Paganini and Liszt, and the conductor began to emerge as an important figure, on whose skill the interpretation of the increasingly complex music depended.[101]		The Romantic movement affected most aspects of intellectual life, and Romanticism and science had a powerful connection, especially in the period 1800–40. Many scientists were influenced by versions of the Naturphilosophie of Johann Gottlieb Fichte, Friedrich Wilhelm Joseph von Schelling and Georg Wilhelm Friedrich Hegel and others, and without abandoning empiricism, sought in their work to uncover what they tended to believe was a unified and organic Nature. The English scientist Sir Humphry Davy, a prominent Romantic thinker, said that understanding nature required “an attitude of admiration, love and worship, [...] a personal response.”[102] He believed that knowledge was only attainable by those who truly appreciated and respected nature. Self-understanding was an important aspect of Romanticism. It had less to do with proving that man was capable of understanding nature (through his budding intellect) and therefore controlling it, and more to do with the emotional appeal of connecting himself with nature and understanding it through a harmonious co-existence.[103]		History writing was very strongly, and many would say harmfully, influenced by Romanticism.[104] In England Thomas Carlyle was a highly influential essayist who turned historian; he both invented and exemplified the phrase "hero-worship",[105] lavishing largely uncritical praise on strong leaders such as Oliver Cromwell, Frederick the Great and Napoleon. Romantic nationalism had a largely negative effect on the writing of history in the 19th century, as each nation tended to produce its own version of history, and the critical attitude, even cynicism, of earlier historians was often replaced by a tendency to create romantic stories with clearly distinguished heroes and villains.[106] Nationalist ideology of the period placed great emphasis on racial coherence, and the antiquity of peoples, and tended to vastly over-emphasize the continuity between past periods and the present, leading to national mysticism. Much historical effort in the 20th century was devoted to combating the romantic historical myths created in the 19th century.		To insulate theology from reductionism in science, 19th-century post-Enlightenment German theologians moved in a new direction, led by Friedrich Schleiermacher and Albrecht Ritschl. They took the Romantic approach of rooting religion in the inner world of the human spirit, so that it is a person's feeling or sensibility about spiritual matters that comprises religion.[107]		One of Romanticism's key ideas and most enduring legacies is the assertion of nationalism, which became a central theme of Romantic art and political philosophy. From the earliest parts of the movement, with their focus on development of national languages and folklore, and the importance of local customs and traditions, to the movements that would redraw the map of Europe and lead to calls for self-determination of nationalities, nationalism was one of the key vehicles of Romanticism, its role, expression and meaning. One of the most important functions of medieval references in the 19th century was nationalist. Popular and epic poetry were its workhorses. This is visible in Germany and Ireland, where underlying Germanic or Celtic linguistic substrates dating from before the Romanization-Latinization were sought out. And, in Catalonia, nationalists reclaimed Catalanism from before the Hispanicization of the Catholic Monarchs in the 15th century, when the Crown of Aragon was unified with the Castilian nobility.[citation needed]		Early Romantic nationalism was strongly inspired by Rousseau, and by the ideas of Johann Gottfried von Herder, who in 1784 argued that the geography formed the natural economy of a people, and shaped their customs and society.[citation needed]		The nature of nationalism changed dramatically, however, after the French Revolution with the rise of Napoleon, and the reactions in other nations. Napoleonic nationalism and republicanism were, at first, inspirational to movements in other nations: self-determination and a consciousness of national unity were held to be two of the reasons why France was able to defeat other countries in battle. But as the French Republic became Napoleon's Empire, Napoleon became not the inspiration for nationalism, but the object of its struggle. In Prussia, the development of spiritual renewal as a means to engage in the struggle against Napoleon was argued by, among others, Johann Gottlieb Fichte, a disciple of Kant. The word Volkstum, or nationality, was coined in German as part of this resistance to the now conquering emperor. Fichte expressed the unity of language and nation in his address "To the German Nation" in 1806:		Those who speak the same language are joined to each other by a multitude of invisible bonds by nature herself, long before any human art begins; they understand each other and have the power of continuing to make themselves understood more and more clearly; they belong together and are by nature one and an inseparable whole. ...Only when each people, left to itself, develops and forms itself in accordance with its own peculiar quality, and only when in every people each individual develops himself in accordance with that common quality, as well as in accordance with his own peculiar quality—then, and then only, does the manifestation of divinity appear in its true mirror as it ought to be.[108]		This view of nationalism inspired the collection of folklore by such people as the Brothers Grimm, the revival of old epics as national, and the construction of new epics as if they were old, as in the Kalevala, compiled from Finnish tales and folklore, or Ossian, where the claimed ancient roots were invented. The view that fairy tales, unless contaminated from outside literary sources, were preserved in the same form over thousands of years, was not exclusive to Romantic Nationalists, but fit in well with their views that such tales expressed the primordial nature of a people. For instance, the Brothers Grimm rejected many tales they collected because of their similarity to tales by Charles Perrault, which they thought proved they were not truly German tales;[109] Sleeping Beauty survived in their collection because the tale of Brynhildr convinced them that the figure of the sleeping princess was authentically German. Vuk Karadžić contributed to Serbian folk literature, using peasant culture as the foundation. He regarded the oral literature of the peasants as an integral part of Serbian culture, compiling it to use in his collections of folk songs, tales, and proverbs, as well as the first dictionary of vernacular Serbian.[110] Similar projects were undertaken by the Russian Alexander Afanasyev, the Norwegians Peter Christen Asbjørnsen and Jørgen Moe, and the Englishman Joseph Jacobs.[111]		Romanticism played an essential role in the national awakening of many Central European peoples lacking their own national states, not least in Poland, which had recently lost its independence when Russia's army crushed the Polish Uprising under Nicholas I. Revival and reinterpretation of ancient myths, customs and traditions by Romantic poets and painters helped to distinguish their indigenous cultures from those of the dominant nations and crystallise the mythography of Romantic nationalism. Patriotism, nationalism, revolution and armed struggle for independence also became popular themes in the arts of this period. Arguably, the most distinguished Romantic poet of this part of Europe was Adam Mickiewicz, who developed an idea that Poland was the Messiah of Nations, predestined to suffer just as Jesus had suffered to save all the people. The Polish self-image as a "Christ among nations" or the martyr of Europe can be traced back to its history of Christendom and suffering under invasions. During the periods of foreign occupation, the Catholic Church served as bastion of Poland's national identity and language, and the major promoter of Polish culture. The partitions came to be seen in Poland as a Polish sacrifice for the security for Western civilization. Adam Mickiewicz wrote the patriotic drama Dziady (directed against the Russians) where he depicts Poland as the Christ of Nations. He also wrote "Verily I say unto you, it is not for you to learn civilization from foreigners, but it is you who are to teach them civilization ... You are among the foreigners like the Apostles among the idolaters". In "Books of the Polish nation and Polish pilgrimage" Mickiewicz detailed his vision of Poland as a Messias and a Christ of Nations, that would save mankind. Dziady is known for various interpretation. The most known ones are the moral aspect of part II, individualist and romantic message of part IV, as well as deeply patriotic,messianistic and Christian vision in part III of poem. Zdzisław Kępiński, however, focuses his interpretation on Slavic pagan and occult elements found in the drama. In his book Mickiewicz hermetyczny he writes about hermetic, theosophic and alchemical philosophy on the book as well as Masonic symbols.		Joseph Vernet, 1759, Shipwreck; the 18th century "sublime"		Joseph Wright, 1774, Cave at evening, Smith College Museum of Art, Northampton, Massachusetts		Henry Fuseli, 1781, The Nightmare, a classical artist whose themes often anticipate the Romantic		Philip James de Loutherbourg, Coalbrookdale by Night, 1801, a key location of the English Industrial Revolution		Théodore Géricault, The Charging Chasseur, c. 1812		Ingres, Death of Leornardo da Vinci, 1818, one of his Troubadour style works		Eugène Delacroix, Collision of Moorish Horsemen, 1843–44		Eugène Delacroix, The Bride of Abydos, 1857, after the poem by Byron		Joseph Anton Koch, Waterfalls at Subiaco 1812–1813, a "classical" landscape to art historians		James Ward, 1814–1815, Gordale Scar		John Constable, 1821, The Hay Wain, one of Constable's large "six footers"		J. C. Dahl, 1826, Eruption of Vesuvius, by Friedrich's closest follower		William Blake, c. 1824–27, The Wood of the Self-Murderers: The Harpies and the Suicides, Tate		Karl Bryullov, The Last Day of Pompeii, 1833, The State Russian Museum, St. Petersburg, Russia		J. M. W. Turner, The Burning of the Houses of Lords and Commons (1835), Philadelphia Museum of Art		Hans Gude, Winter Afternoon, 1847, National Gallery of Norway, Oslo		Ivan Aivazovsky, 1850, The Ninth Wave, Russian Museum, St. Petersburg		John Martin, 1852, The Destruction of Sodom and Gomorrah, Laing Art Gallery		Frederic Edwin Church, 1860, Twilight in the Wilderness, Cleveland Museum of Art		Albert Bierstadt, 1863, The Rocky Mountains, Lander's Peak		
A sand beach is a beach consisting primarily of sand.		Sand Beach may also refer to:		
1 French Land Register data, which excludes lakes, ponds, glaciers > 1 km² (0.386 sq mi or 247 acres) and river estuaries.		Paris (locally [pɑʁi] ( listen)) is the capital and most populous city of France. It has an area of 105 square kilometres (41 square miles) and a population of 2,229,621 in 2015 within its administrative limits.[2] The city is both a commune and department and forms the centre and headquarters of the Île-de-France, or Paris Region, which has an area of 12,012 square kilometres (4,638 square miles) and a population in 2016 of 12,142,802, comprising roughly 18 percent of the population of France.[5] By the 17th century, Paris was one of Europe's major centres of finance, commerce, fashion, science, and the arts, and it retains that position still today. The Paris Region had a GDP of €649.6 billion (US $763.4 billion) in 2014, accounting for 30.4 percent of the GDP of France.[6] According to official estimates, the Paris Region has the fourth-highest GDP in the world and the largest regional GDP in the EU.		Around its historical heart, the small Île de la Cité, the City of Paris stretches on both sides of the Seine River, which divides it into two parts: the Rive Gauche (Left Bank, south) and Rive Droite (Right Bank, north). The city proper is but the core of a built-up area that extends well beyond its administrative limits. Commonly referred to as the agglomération Parisienne, and statistically as a unité urbaine (a measure of urban area), the agglomeration has a 2013 population of 10,601,122, which makes it the largest in the European Union.[3] City-influenced commuter activity reaches well beyond even this in a statistical aire urbaine de Paris (a measure of metropolitan area), that had a 2013 population of 12,405,426,[7] a number one-fifth the population of France,[8] and one that makes it, after London, the second largest metropolitan area in the European Union.		In 2016 a new entity was created, the Metropole of Grand Paris, to improve cooperation between the City of Paris and the suburbs. It includes the City of Paris and all the communes in the departments that surround the city. [9] Grand Paris covers 814 square kilometers and has a population of 7 million.[10][11]		The city is also a major rail, highway, and air-transport hub served by two international airports: Paris-Charles de Gaulle (the second busiest airport in Europe after London Heathrow Airport with 63.8 million passengers in 2014) and Paris-Orly. Opened in 1900, the city's subway system, the Paris Métro, serves 5.23 million passengers daily.[12] It is the second busiest metro system in Europe after Moscow Metro. Notably, Paris Gare du Nord is the busiest railway station in the world outside of Japan, with 262 million passengers in 2015.[13]		Paris is known especially for its museums and architectural landmarks. The Louvre is the most visited art museum in the world outside of China.[14] The Musée d'Orsay is noted for its collection of French Impressionist art, and its Pompidou-center Musée National d'Art Moderne has the largest collection of modern and contemporary art in Europe. In 2017, the European Commission ranked it as the most "Culturally Vibrant City" in the EU.[15] The central area of the city along the Seine River is classified as a UNESCO Heritage Site and includes many notable monuments, including Notre Dame Cathedral and Sainte-Chapelle on Île de la Cité, the Grand Palais, Petit Palais and Eiffel Tower (remnants of Universal Expositions held in Paris) and the Louvre and the adjacent Tuileries Garden. Other notable monuments include the Arc de Triomphe just to the west of the centre and the Basilica of Sacré-Cœur in Montmartre. In 2015, Paris received 22.2 million visitors, making it one of the world's top tourist destinations. However, in 2016, after a series of terrorist attacks, the number of foreign tourists in Greater Paris dropped by 11.5 percent. [16]		The association football club Paris Saint-Germain and the rugby union club Stade Français are based in Paris. The 80,000-seat Stade de France, built for the 1998 FIFA World Cup, is located just north of Paris in the neighbouring commune of Saint-Denis. Paris hosts the annual French Open Grand Slam tennis tournament on the red clay of Roland Garros. Paris hosted the Olympic Games in 1900, 1924 and will host the 2024 Summer Olympics. The 1938 and 1998 FIFA World Cups, the 2007 Rugby World Cup, and the 1960, 1984, and 2016 UEFA European Championships were also held in the city, and every July, the Tour de France bicycle race finishes in the city.						The name "Paris" is derived from its early inhabitants, the Celtic Parisii tribe[17] but the city's name is not related to the Paris of Greek mythology.		Paris is often referred to as "The City of Light" (La Ville Lumière),[18] both because of its leading role during the Age of Enlightenment, and more literally because Paris was one of the first European cities to adopt gas street lighting. In the 1860s, the boulevards and streets of Paris were illuminated by 56,000 gas lamps.[19] Since the late 19th century, Paris has also been known as Panam(e) (pronounced [panam]) in French slang.[20]		Inhabitants are known in English as "Parisians" and in French as Parisiens ([paʁizjɛ̃] ( listen)). They are also pejoratively called Parigots ([paʁiɡo] ( listen)).[note 1][21]		The Parisii, a sub-tribe of the Celtic Senones, inhabited the Paris area from around the middle of the 3rd century BC.[22][23] One of the area's major north-south trade routes crossed the Seine on the île de la Cité; this meeting place of land and water trade routes gradually became a town and an important trading centre.[24] The Parisii traded with many river towns as far away as the Iberian Peninsula, and minted their own coins for that purpose.[25]		The Romans conquered the Paris Basin in 52 BC and,[26] after making the island a garrison camp, began extending their settlement in a more permanent way to Paris's Left Bank. The Gallo-Roman town was originally called Lutetia (more fully, Lutetia Parisiorum, "Lutetia of the Parisii"). It became a prosperous city with a forum, baths, temples, theatres, and an amphitheatre.[27]		By the end of the Western Roman Empire, the town was known as Parisius, a Latin name that would later become Paris in French.[28] Christianity was introduced in the middle of the 3rd century AD by Saint Denis, the first Bishop of Paris: according to legend, when he refused to renounce his faith before the Roman occupiers, he was beheaded on the hill which became known as Mons Martyrum (Latin "Hill of Martyrs"), later "Montmartre", from where he walked headless to the north of the city; the place where he fell and was buried became an important religious shrine, the Basilica of Saint-Denis, and many French Kings are buried there.[29]		Clovis the Frank, the first king of the Merovingian dynasty, made the city his capital from 508. A gradual immigration by the Franks also occurred in Paris in the beginning of the Frankish domination of Gaul which created the Parisian Francien dialects. Fortification of the Île-de-France failed to prevent sacking by Vikings in 845 but Paris's strategic importance—with its bridges preventing ships from passing—was established by successful defence in the Siege of Paris (885–86). In 987 Hugh Capet, Count of Paris (comte de Paris), Duke of the Franks (duc des Francs) was elected King of the Franks (roi des Francs). Under the rule of the Capetian kings, Paris gradually became the largest and most prosperous city in France.[29]		By the end of the 12th century, Paris had become the political, economic, religious, and cultural capital of France.[30] The Palais de la Cité, the royal residence, was located at the western end of the Île de la Cité. In 1163, during the reign of Louis VII, Maurice de Sully, bishop of Paris, undertook the construction of the Notre Dame Cathedral at its eastern extremity.		Paris' cultural centre had begun to move to the right bank, after the draining of its former swampland made the land habitable and fit for crops. In 1137, a new city marketplace (where Les Halles is today) replaced the two smaller ones on the Île de la Cité and Place de la Grève (Hotel de Ville).[31] The latter location housed the headquarters of Paris' river trade corporation, an organisation that later became, unofficially (although formally in later years), Paris' first municipal government.		In the late 12th century, Philip Augustus extended the Louvre fortress to defend the city against river invasions from the west, gave the city its first walls between 1190 and 1215, rebuilt its bridges to either side of its central island, and paved its main thoroughfares.[32] In 1190, he transformed Paris' former cathedral school into a student-teacher corporation that would become the University of Paris and would draw students from all of Europe.[33][30]		During the Hundred Years' War, Paris was occupied by England-friendly Burgundian forces from 1418, before being occupied outright by the English when Henry V of England entered the French capital in 1420;[34] in spite of a 1429 effort by Joan of Arc to liberate the city,[35] it would remain under English occupation until 1436.		In the late 16th-century French Wars of Religion, Paris was a Catholic League stronghold, the organisers of the 24 August 1572 St. Bartholomew's Day massacre that killed thousands of French Protestants.[36][37] The conflicts ended when crown-pretendant Henry IV, after converting to Catholicism to gain entry to the capital, entered the city in 1594 to claim the crown of France. This king made several improvements to the capital during his reign: he completed the construction of Paris' first uncovered, sidewalk-doted bridge, the Pont Neuf, built a Louvre extension that connected it the Tuileries Palace, and created the first Paris residential square, the Place Royale, now Place des Vosges. The king would end his life in the capital, assassinated in a narrow street by Les Halles marketplace in 1610.[38]		During the 17th century, Cardinal Richelieu, chief minister of Louis XIII, was determined to make Paris the most beautiful city in Europe. He built five new bridges, a new chapel for the College of Sorbonne, and a palace for himself, the Palais Cardinal, which he bequeathed to Louis XIII. After Richelieu's death in 1642, it was the renamed as the Palais-Royal.[39]		Due to the Parisian uprisings during the Fronde civil war, Louis XIV moved his court to a new palace, Versailles, in 1682. Although no longer the capital of France, arts and sciences in the city flourished with the Comédie-Française, the Academy of Painting, and the French Academy of Sciences. To demonstrate that the city was safe from attack, the king had the city walls demolished and replaced with tree-lined boulevards that would become the Grands Boulevards of today.[40] Other marks of his reign were the Collège des Quatre-Nations, the Place Vendôme, the Place des Victoires, and Les Invalides.[41]		Paris grew in population from about 400,000 in 1640 to 650,000 in 1780.[42] A new boulevard, the Champs-Élysées, extended the city west to Étoile,[43] while the working-class neighbourhood of the Faubourg Saint-Antoine on the eastern site of the city grew more and more crowded with poor migrant workers from other regions of France.[44]		Paris was the centre of an explosion of philosophic and scientific activity known as the Age of Enlightenment. Diderot and d'Alembert published their Encyclopédie in 1751–52, and the Montgolfier Brothers launched the first manned flight in a hot-air balloon on 21 November 1783, from the gardens of the Château de la Muette. Paris was the financial capital of continental Europe, the primary European centre of book publishing, fashion and the manufacture of fine furniture and luxury goods.[45]		In the summer of 1789, Paris became the centre stage of the French Revolution. On 14 July, a mob seized the arsenal at the Invalides, acquiring thousands of guns, and stormed the Bastille, a symbol of royal authority.		The first independent Paris Commune, or city council, met in the Hôtel de Ville and, on 15 July, elected a Mayor, the astronomer Jean Sylvain Bailly.[46]		Louis XVI and the royal family were brought to Paris and made prisoners within the Tuileries Palace. In 1793, as the revolution turned more and more radical, the king, queen, and the mayor were guillotined, along with more than 16,000 others (throughout France), during the Reign of Terror.[47] The property of the aristocracy and the church was nationalised, and the city's churches were closed, sold or demolished.[48] A succession of revolutionary factions ruled Paris until 9 November 1799 (coup d'état du 18 brumaire), when Napoléon Bonaparte seized power as First Consul.[49]		The population of Paris had dropped by 100,000 during the Revolution, but between 1799 and 1815, it surged with 160,000 new residents, reaching 660,000.[50] Napoleon Bonaparte replaced the elected government of Paris with a prefect reporting only to him. He began erecting monuments to military glory, including the Arc de Triomphe, and improved the neglected infrastructure of the city with new fountains, the Canal de l'Ourcq, Père Lachaise Cemetery and the city's first metal bridge, the Pont des Arts.[50]		During the Restoration, the bridges and squares of Paris were returned to their pre-Revolution names, but the July Revolution of 1830 in Paris, (commemorated by the July Column on Place de la Bastille), brought a constitutional monarch, Louis Philippe I, to power. The first railway line to Paris opened in 1837, beginning a new period of massive migration from the provinces to the city.[50]		Louis-Philippe was overthrown by a popular uprising in the streets of Paris in 1848. His successor, Napoleon III, and the newly appointed prefect of the Seine, Georges-Eugène Haussmann, launched a gigantic public works project to build wide new boulevards, a new opera house, a central market, new aqueducts, sewers, and parks, including the Bois de Boulogne and Bois de Vincennes.[51] In 1860, Napoleon III also annexed the surrounding towns and created eight new arrondissements, expanding Paris to its current limits.[51]		During the Franco-Prussian War (1870–1871), Paris was besieged by the Prussian army. After months of blockade, hunger, and then bombardment by the Prussians, the city was forced to surrender on 28 January 1871. On 28 March, a revolutionary government called the Paris Commune seized power in Paris. The Commune held power for two months, until it was harshly suppressed by the French army during the "Bloody Week" at the end of May 1871.[52]		Late in the 19th century, Paris hosted two major international expositions: the 1889 Universal Exposition, was held to mark the centennial of the French Revolution and featured the new Eiffel Tower; and the 1900 Universal Exposition, which gave Paris the Pont Alexandre III, the Grand Palais, the Petit Palais and the first Paris Métro line.[53] Paris became the laboratory of Naturalism (Émile Zola) and Symbolism (Charles Baudelaire and Paul Verlaine), and of Impressionism in art (Courbet, Manet, Monet, Renoir).[54]		By 1901, the population of Paris had grown to 2,715,000.[55] At the beginning of the century, artists from around the world, including Picasso, Modigliani, and Matisse made Paris their home. It was the birthplace of Fauvism, Cubism and abstract art,[56][57] and authors such as Marcel Proust were exploring new approaches to literature.[58]		During the First World War, Paris sometimes found itself on the front line; 600 to 1,000 Paris taxis played a small but highly important symbolic role in transporting 6,000 soldiers to the front line at the First Battle of the Marne. The city was also bombed by Zeppelins and shelled by German long-range guns.[59] In the years after the war, known as Les Années Folles, Paris continued to be a mecca for writers, musicians and artists from around the world, including Ernest Hemingway, Igor Stravinsky, James Joyce, Josephine Baker, Sidney Bechet[60] and the surrealist Salvador Dalí.[61]		In the years after the peace conference, the city was also home to growing numbers of students and activists from French colonies and other Asian and African countries, who later became leaders of their countries, such as Ho Chi Minh, Zhou Enlai and Léopold Sédar Senghor.[62]		On 14 June 1940, the German army marched into Paris, which had been declared an "open city".[63] On 16–17 July 1942, following German orders, the French police and gendarmes arrested 12,884 Jews, including 4,115 children, and confined them during five days at the Vel d'Hiv (Vélodrome d'Hiver), from which they were transported by train to the extermination camp at Auschwitz. None of the children came back.[64][65] On 25 August 1944, the city was liberated by the French 2nd Armoured Division and the 4th Infantry Division of the United States Army. General Charles de Gaulle led a huge and emotional crowd down the Champs Élysées towards Notre Dame de Paris, and made a rousing speech from the Hôtel de Ville.[66]		In the 1950s and the 1960s, Paris became one front of the Algerian War for independence; in August 1961, the pro-independence FLN targeted and killed 11 Paris policemen, leading to the imposition of a curfew on Muslims of Algeria (who, at that time, were French citizens). On 17 October 1961, an unauthorised but peaceful protest demonstration of Algerians against the curfew led to violent confrontations between the police and demonstrators, in which at least 40 people were killed, including some thrown into the Seine. The anti-independence Organisation armée secrète (OAS), for their part, carried out a series of bombings in Paris throughout 1961 and 1962.[67][68]		In May 1968, protesting students occupied the Sorbonne and put up barricades in the Latin Quarter. Thousands of Parisian blue-collar workers joined the students, and the movement grew into a two-week general strike. Supporters of the government won the June elections by a large majority. The May 1968 events in France resulted in the break-up of the University of Paris into 13 independent campuses.[69]		In 1975, the National Assembly changed the status of Paris to that of other French cities and, on 25 March 1977, Jacques Chirac became the first elected mayor of Paris since 1793.[70] The Tour Maine-Montparnasse, the tallest building in the city at 57 storeys and 210 metres (689 feet) high, was built between 1969 and 1973. It was highly controversial, and it remains the only building in the centre of the city over 32 storeys high.[71]		The population of Paris dropped from 2,850,000 in 1954 to 2,152,000 in 1990, as middle-class families moved to the suburbs.[72] A suburban railway network, the RER (Réseau Express Régional), was built to complement the Métro, and the Périphérique expressway encircling the city, was completed in 1973.[73]		Most of the postwar's presidents of the Fifth Republic wanted to leave their own monuments in Paris; President Georges Pompidou started the Centre Georges Pompidou (1977), Valéry Giscard d'Estaing began the Musée d'Orsay (1986); President François Mitterrand, in power for 14 years, built the Opéra Bastille (1985–1989), the Bibliothèque nationale de France (1996), the Arche de la Défense (1985–1989), and the Louvre Pyramid with its underground courtyard (1983–1989); Jacques Chirac (2006), the Musée du quai Branly.[74]		In the early 21st century, the population of Paris began to increase slowly again, as more young people moved into the city. It reached 2.25 million in 2011. In March 2001, Bertrand Delanoë became the first socialist mayor of Paris. In 2007, in an effort to reduce car traffic in the city, he introduced the Vélib', a system which rents bicycles for the use of local residents and visitors. Bertrand Delanoë also transformed a section of the highway along the left bank of the Seine into an urban promenade and park, the Promenade des Berges de la Seine, which he inaugurated in June 2013.[75]		In 2007, President Nicolas Sarkozy launched the Grand Paris project, to integrate Paris more closely with the towns in the region around it. After many modifications, the new area, named the Metropolis of Grand Paris, with a population of 6.7 million, was created on 1 January 2016.[76]		In 2011, the City of Paris and the national government approved the plans for the Grand Paris Express, totalling 205 kilometres (127 miles) of automated metro lines to connect Paris, the innermost three departments around Paris, airports and high-speed rail (TGV) stations, at an estimated cost of €35 billion.[77] The system is scheduled to be completed by 2030.[78]		On 5 April 2014, Anne Hidalgo, a socialist, was elected the first female mayor of Paris.[79]		On 7 January 2015, two French Muslim extremists attacked the Paris headquarters of Charlie Hebdo and killed thirteen people, in an attack claimed by Al-Qaeda in the Arabian Peninsula,[80] and on 9 January, a third terrorist, who claimed he was part of ISIS (also called ISIL or 'Daesh'), killed four hostages during an attack at a Jewish grocery store at Porte de Vincennes.[81] On 11 January an estimated 1.5 million people marched in Paris–along with international political leaders–to show solidarity against terrorism and in defence of freedom of speech.[82] Ten months later, 13 November 2015, came a series of coordinated terrorist attacks in Paris and Saint-Denis claimed by the 'Islamic state' organisation ISIL ('Daesh', ISIS);[83] 130 people were killed by gunfire and bombs, and more than 350 were injured.[84]		On 3 February 2017, an attacker tried to stab soldiers guarding the Louvre after he was refused admission with the two bags he was carrying, reportedly saying 'Allahu Akbar', and was shot. Later searches found no explosives in the bags (see Louvre machete attack).[85] On 18 March 2017, a man held up patrons of a bar in Vitry-sur-Seine, then held a gun to the head of a French soldier at Orly Airport, the second-largest airport in the Paris metro area, shouting "I am here to die in the name of Allah", and was shot dead by the soldier's comrades (see March 2017 Île-de-France attacks).[86] On 20 April 2017, a man shot dead French police officer Xavier Jugelé on the Champs-Élysées, and was later shot dead himself (see April 2017 Champs-Élysées attack).[87] On June 19, 2017, a man rammed his car into a police van on the Champs-Élysées, with a car containing weapons and explosives powerful enough to blow up the car.[88]		Paris is located in northern central France. By road, it is 450 kilometres (280 mi) southeast of London, 287 kilometres (178 mi) south of Calais, 305 kilometres (190 mi) southwest of Brussels, 774 kilometres (481 mi) north of Marseille, 385 kilometres (239 mi) northeast of Nantes, and 135 kilometres (84 mi) southeast of Rouen.[89] Paris is located in the north-bending arc of the river Seine and includes two islands, the Île Saint-Louis and the larger Île de la Cité, which form the oldest part of the city.		The river's mouth on the English Channel (La Manche) is about 233 mi (375 km) downstream from the city. The city is spread widely on both banks of the river.[90] Overall, the city is relatively flat, and the lowest point is 35 m (115 ft) above sea level. Paris has several prominent hills, the highest of which is Montmartre at 130 m (427 ft).[91] Montmartre gained its name from the martyrdom of Saint Denis, first bishop of Paris, atop the Mons Martyrum, "Martyr's mound", in 250.		Excluding the outlying parks of Bois de Boulogne and Bois de Vincennes, Paris covers an oval measuring about 87 km2 (34 sq mi) in area, enclosed by the 35 km (22 mi) ring road, the Boulevard Périphérique.[92] The city's last major annexation of outlying territories in 1860 not only gave it its modern form but also created the 20 clockwise-spiralling arrondissements (municipal boroughs). From the 1860 area of 78 km2 (30 sq mi), the city limits were expanded marginally to 86.9 km2 (33.6 sq mi) in the 1920s. In 1929, the Bois de Boulogne and Bois de Vincennes forest parks were officially annexed to the city, bringing its area to about 105 km2 (41 sq mi).[93] The metropolitan area of the city is 2,300 km2 (890 sq mi).[90]		Paris has a typical Western European oceanic climate (Köppen climate classification: Cfb ) which is affected by the North Atlantic Current. The overall climate throughout the year is mild and moderately wet.[94] Summer days are usually warm and pleasant with average temperatures between 15 and 25 °C (59 and 77 °F), and a fair amount of sunshine.[95] Each year, however, there are a few days when the temperature rises above 32 °C (90 °F). Longer periods of more intense heat sometimes occur, such as the heat wave of 2003 when temperatures exceeded 30 °C (86 °F) for weeks, reached 40 °C (104 °F) on some days and seldom cooled down at night.[96]		Spring and autumn have, on average, mild days and fresh nights but are changing and unstable. Surprisingly warm or cool weather occurs frequently in both seasons.[97] In winter, sunshine is scarce; days are cool, nights cold but generally above freezing with low temperatures around 3 °C (37 °F).[98] Light night frosts are however quite common, but the temperature will dip below −5 °C (23 °F) for only a few days a year. Snow falls every year, but rarely stays on the ground. The city sometimes sees light snow or flurries with or without accumulation.[99]		Paris has an average annual precipitation of 652 mm (25.7 in), and experiences light rainfall distributed evenly throughout the year. However the city is known for intermittent abrupt heavy showers. The highest recorded temperature is 40.4 °C (104.7 °F) on 28 July 1947, and the lowest is −23.9 °C (−11.0 °F) on 10 December 1879.[100]		For almost all of its long history, except for a few brief periods, Paris was governed directly by representatives of the king, emperor, or president of France. The city was not granted municipal autonomy by the National Assembly until 1974.[103] The first modern elected mayor of Paris was Jacques Chirac, elected 20 March 1977, becoming the city's first mayor since 1793. The current mayor is Anne Hidalgo, a socialist, elected 5 April 2014.[104]		The mayor of Paris is elected indirectly by Paris voters; the voters of each arrondissement elect the Conseil de Paris (Council of Paris), composed of 163 members. Each arrondissement has a number of members depending upon its population, from 10 members for each of the least-populated arrondissements (1st through 9th) to 36 members for the most populated (the 15th). The elected council members select the mayor. Sometimes the candidate who receives the most votes citywide is not selected if the other candidate has won the support of the majority of council members. Mayor Bertrand Delanoë (2001–2014) was elected by only a minority of city voters, but a majority of council members.		Once elected, the council plays a largely passive role in the city government; it meets only once a month. The current council is divided between a coalition of the left of 91 members, including the socialists, communists, greens, and extreme left; and 71 members for the centre right, plus a few members from smaller parties.[105]		Each of Paris's 20 arrondissements has its own town hall and a directly elected council (conseil d'arrondissement), which, in turn, elects an arrondissement mayor.[106] The council of each arrondissement is composed of members of the Conseil de Paris and also members who serve only on the council of the arrondissement. The number of deputy mayors in each arrondissement varies depending upon its population. There are a total of 20 arrondissement mayors and 120 deputy mayors.[103]		The budget of the city for 2013 was €7.6 billion, of which €5.4 billion went for city administration, while €2.2 billion went for investment. The largest part of the budget (38 percent) went for public housing and urbanism projects; 15 percent for roads and transport; 8 percent for schools (which are mostly financed by the state budget); 5 percent for parks and gardens; and 4 percent for culture. The main source of income for the city is direct taxes (35 percent), supplemented by a 13-percent real estate tax; 19 percent of the budget comes in a transfer from the national government.[107]		The number of city employees, or agents, grew from 40,000 in 2000 to 73,000 in 2013. The city debt grew from €1.6 billion in 2000 to 3.1 billion in 2012, with a debt of €3.65 billion expected for 2014.[108] As a result of the growing debt, the bond rating of the city was lowered from AAA to AA+ in both 2012 and 2013. In September 2014, Mayor Hidalgo announced that the city would have budget shortfall of €400 million, largely because of a cut in support from the national government.[109]		The Métropole du Grand Paris, or simply Grand Paris, formally came into existence on 1 January 2016.[110] It is an administrative structure for co-operation between the City of Paris and its nearest suburbs. It includes the City of Paris, plus the communes or towns of the three departments of the inner suburbs ( Hauts-de-Seine, Seine-Saint-Denis and Val-de-Marne), plus seven communes in the outer suburbs, including Argenteuil in Val d'Oise and Paray-Vieille-Poste in Essonne, which were added to include the major airports of Paris. The Metropole covers 814 square kilometres (314 square miles) and has a population of 6.945 million persons.[111][112]		The new structure is administered by a Metropolitan Council of 210 members, not directly elected, but chosen by the councils of the member Communes. By 2020 its basic competencies will include urban planning, housing and protection of the environment.[110][112] The first president of the metropolitan council, Patrick Ollier, a Republican and the mayor of the town of Rueil-Malmaison, was elected on 22 January 2016. Though the Metropole has a population of nearly seven million persons and accounts for 25 percent of the GDP of France, it has a very small budget; just 65 million Euros, compared with eight billion Euros for the City of Paris.[113]		The Region of Île de France, including Paris and its surrounding communities, is governed by the Regional Council, which has its headquarters in the 7th arrondissement of Paris. It is composed of 209 members representing the different communes within the region. On December 15, 2015, a list of candidates of the Union of the Right, a coalition of centrist and right-wing parties, led by Valérie Pécresse, narrowly won the regional election, defeating a coalition of Socialists and ecologists. The Socialists had governed the region for seventeen years. The regional council has 121 members from the Union of the Right, 66 from the Union of the Left and 22 from the extreme right National Front.[114]		As the capital of France, Paris is the seat of France's national government. For the executive, the two chief officers each have their own official residences, which also serve as their offices. The President of the French Republic resides at the Élysée Palace in the 8th arrondissement,[115] while the Prime Minister's seat is at the Hôtel Matignon in the 7th arrondissement.[116][117] Government ministries are located in various parts of the city; many are located in the 7th arrondissement, near the Matignon.[118]		The two houses of the French Parliament are located on the Left Bank. The upper house, the Senate, meets in the Palais du Luxembourg in the 6th arrondissement, while the more important lower house, the Assemblée Nationale, meets in the Palais Bourbon in the 7th arrondissement. The President of the Senate, the second-highest public official in France (the President of the Republic being the sole superior), resides in the "Petit Luxembourg", a smaller palace annexe to the Palais du Luxembourg.[119]		France's highest courts are located in Paris. The Court of Cassation, the highest court in the judicial order, which reviews criminal and civil cases, is located in the Palais de Justice on the Île de la Cité,[120] while the Conseil d'État, which provides legal advice to the executive and acts as the highest court in the administrative order, judging litigation against public bodies, is located in the Palais-Royal in the 1st arrondissement.[121] The Constitutional Council, an advisory body with ultimate authority on the constitutionality of laws and government decrees, also meets in the Montpensier wing of the Palais Royal.[122]		Paris and its region host the headquarters of several international organisations including UNESCO, the Organisation for Economic Co-operation and Development, the International Chamber of Commerce, the Paris Club, the European Space Agency, the International Energy Agency, the Organisation internationale de la Francophonie, the European Union Institute for Security Studies, the International Bureau of Weights and Measures, the International Exhibition Bureau, and the International Federation for Human Rights.		Following the motto "Only Paris is worthy of Rome; only Rome is worthy of Paris";[123][124] the only sister city of Paris is Rome, although Paris has partnership agreements with many other cities around the world.[123]		The security of Paris is mainly the responsibility of the Prefecture of Police of Paris, a subdivision of the Ministry of the Interior of France. It supervises the units of the National Police who patrol the city and the three neighbouring departments. It is also responsible for providing emergency services, including the Paris Fire Brigade. Its headquarters is on Place Louis Lépine on the Île de la Cité.[125]		There are 30,200 officers under the prefecture, and a fleet of more than 6,000 vehicles, including police cars, motorcycles, fire trucks, boats and helicopters. In addition to traditional police duties, the local police monitors the number of discount sales held by large stores (no more than two a year are allowed) and verify that, during summer holidays, at least one bakery is open in every neighbourhood.[125] The national police has its own special unit for riot control and crowd control and security of public buildings, called the Compagnies Républicaines de Sécurité (CRS), a unit formed in 1944 right after the liberation of France. Vans of CRS agents are frequently seen in the centre of the city when there are demonstrations and public events.		The police are supported by the National Gendarmerie, a branch of the French Armed Forces, though their police operations now are supervised by the Ministry of the Interior. The traditional kepis of the gendarmes were replaced in 2002 with caps, and the force modernised, though they still wear kepis for ceremonial occasions.[126]		Crime in Paris is similar to that in most large cities. Violent crime is relatively rare in the city centre.[127] Political violence is uncommon, though very large demonstrations may occur in Paris and other French cities simultaneously. These demonstrations, usually managed by a strong police presence, can turn confrontational and escalate into violence.[127]		Most French rulers since the Middle Ages made a point of leaving their mark on a city that, contrary to many other of the world's capitals, has never been destroyed by catastrophe or war. In modernising its infrastructure through the centuries, Paris has preserved even its earliest history in its street map.[128] At its origin, before the Middle Ages, the city was composed around several islands and sandbanks in a bend of the Seine; of those, two remain today: the île Saint-Louis, the île de la Cité; a third one is the 1827 artificially created île aux Cygnes.		Modern Paris owes much to its late 19th century Second Empire remodelling by the Baron Haussmann: many of modern Paris's busiest streets, avenues and boulevards today are a result of that city renovation. Paris also owes its style to its aligned street-fronts, distinctive cream-grey "Paris stone" building ornamentation, aligned top-floor balconies, and tree-lined boulevards. The high residential population of its city centre makes it much different from most other western global cities.[129]		Paris's urbanism laws have been under strict control since the early 17th century,[130] particularly where street-front alignment, building height and building distribution is concerned. In recent developments, a 1974–2010 building height limitation of 37 metres (121 ft) was raised to 50 m (160 ft) in central areas and 180 metres (590 ft) in some of Paris's peripheral quarters, yet for some of the city's more central quarters, even older building-height laws still remain in effect.[130] The 210 metres (690 ft) Montparnasse tower was both Paris and France's tallest building until 1973,[131] but this record has been held by the La Défense quarter Tour First tower in Courbevoie since its 2011 construction.		A new project for La Défense, called Hermitage Plaza, launched in 2009, proposes to build two towers, 85 and 86 stories or 320 metres (1,050 feet) high, which would be the tallest buildings in the European Union, just slightly shorter than the Eiffel Tower. They were scheduled for completion in 2019 or 2020, but as of January 2015 construction had not yet begun, and there were questions in the press about the future of the project.[132][133]		Parisian examples of European architecture date back more than a millennium; including the Romanesque church of the Abbey of Saint-Germain-des-Prés (1014–1163); the early Gothic Architecture of the Basilica of Saint-Denis (1144), the Notre Dame Cathedral (1163–1345), the Flamboyant Gothic of Saint Chapelle (1239–1248), the Baroque churches of Saint-Paul-Saint-Louis (1627–1641) and Les Invalides (1670–1708). The 19th century produced the neoclassical church of La Madeleine (1808–1842); the Palais Garnier Opera House (1875); the neo-Byzantine Basilica of Sacré-Cœur (1875–1919), and the exuberant Belle Époque modernism of the Eiffel Tower (1889). Striking examples of 20th-century architecture include the Centre Georges Pompidou by Richard Rogers and Renzo Piano (1977), and the Louvre Pyramid by I.M. Pei (1989). Contemporary architecture includes the Musée du Quai Branly by Jean Nouvel (2006) and the new contemporary art museum of the Louis Vuitton Foundation by Frank Gehry (2014).[134]		Paris is the fifth most expensive city in the world for luxury housing: €18,499 per square metre (€1,720/sq ft) in 2014.[135] According to a 2012 study for the La Tribune newspaper, the most expensive street is the quai des Orfèvres in the 1st arrondissement, with an average price of €20,665 per square metre (€1,920/sq ft), against €3,900 per square metre (€360/sq ft) for rue Pajol in the 18th arrondissement.[136]		The total number of residences in the city of Paris in 2011 was 1,356,074, up from a former high of 1,334,815 in 2006. Among these, 1,165,541 (85.9 percent) were main residences, 91,835 (6.8 percent) were secondary residences, and the remaining 7.3 percent were empty (down from 9.2 percent in 2006).[137]		Paris urban tissue began to fill and overflow its 1860 limits from around the 1920s, and because of its density, it has seen few modern constructions since then. Sixty-two percent of its buildings date from 1949 and before, 20 percent were built between 1949 and 1974, and only 18 percent of the buildings remaining were built after that date.[138]		Two-thirds of the city's 1.3 million residences are studio and two-room apartments. Paris averages 1.9 people per residence, a number that has remained constant since the 1980s, but it is much less than Île-de-France's 2.33 person-per-residence average. Only 33 percent of principal residence Parisians own their habitation (against 47 percent for the entire Île-de-France): the major part of the city's population is a rent-paying one.[138]		Social housing represents a little more than 17 percent of the city's total residences, but these are rather unevenly distributed throughout the capital: the vast majority of these are concentrated in a crescent formed by Paris's south-western to northern periphery arrondissements.[139]		In 2012 the Paris agglomeration (urban area) counted 28,800 people without a fixed residence, an increase of 84 percent since 2001; it represents 43 percent of the homeless in all of France. Forty-one percent were women, and 29 percent were accompanied by children. Fifty-six percent of the homeless were born outside France, the largest number coming from Africa and Eastern Europe.[140] The city of Paris has sixty homeless shelters, called Centres d'hébergement et de réinsertion sociale or CHRS, which are funded by the city and operated by private charities and associations.[141]		Aside from the 20th-century addition of the Bois de Boulogne, Bois de Vincennes and Paris heliport, Paris's administrative limits have remained unchanged since 1860. The Seine département had been governing Paris and its suburbs since its creation in 1790, but the rising suburban population had made it difficult to govern as a unique entity. This problem was 'resolved' when its parent "District de la région parisienne" (Paris region) was reorganised into several new departments from 1968: Paris became a department in itself, and the administration of its suburbs was divided between the three departments surrounding it. The Paris region was renamed "Île-de-France" in 1977, but the "Paris region" name is still commonly used today.[142] Long-intended measures to unite Paris with its suburbs began on January 1, 2016, when the Métropole du Grand Paris came into existence.[110]		Paris's disconnect with its suburbs, its lack of suburban transportation, in particular, became all too apparent with the Paris agglomeration's growth. Paul Delouvrier promised to resolve the Paris-suburbs mésentente when he became head of the Paris region in 1961:[143] two of his most ambitious projects for the Region were the construction of five suburban villes nouvelles ("new cities")[144] and the RER commuter train network.[145] Many other suburban residential districts (grands ensembles) were built between the 1960s and 1970s to provide a low-cost solution for a rapidly expanding population:[146] these districts were socially mixed at first,[147] but few residents actually owned their homes (the growing economy made these accessible to the middle classes only from the 1970s).[148] Their poor construction quality and their haphazard insertion into existing urban growth contributed to their desertion by those able to move elsewhere and their repopulation by those with more limited possibilities.[148]		These areas, quartiers sensibles ("sensitive quarters"), are in northern and eastern Paris, namely around its Goutte d'Or and Belleville neighbourhoods. To the north of the city, they are grouped mainly in the Seine-Saint-Denis department, and to a lesser extreme to the east in the Val-d'Oise department. Other difficult areas are located in the Seine valley, in Évry et Corbeil-Essonnes (Essonne), in Mureaux, Mantes-la-Jolie (Yvelines), and scattered among social housing districts created by Delouvrier's 1961 "ville nouvelle" political initiative.[149]		The Paris agglomeration's urban sociology is basically that of 19th century Paris: its fortuned classes are situated in its west and southwest, and its middle-to-lower classes are in its north and east. The remaining areas are mostly middle-class citizenry dotted with islands of fortuned populations located there due to reasons of historical importance, namely Saint-Maur-des-Fossés to the east and Enghien-les-Bains to the north of Paris.[150]		The population of Paris in its administrative city limits was 2,241,346 in January 2014.[153] This makes Paris the fifth largest municipality in the European Union, following London, Berlin, Madrid and Rome. Eurostat, the statistical agency of the EU, places Paris (6.5 million people) second behind London (8 million) and ahead of Berlin (3.5 million), based on the 2012 populations of what Eurostat calls "urban audit core cities".[154] The Paris Urban Area, or "unité urbaine", is a statistical area created by the French statistical agency INSEE to measure the population of built-up areas around the city. It is slightly smaller than the Paris Region. According to INSEE, the Paris Urban Area had a population of 10,550,350 at the January 2012 census,[3] the most populous in the European Union, and third most populous in Europe, behind Istanbul and Moscow.[155] The Paris Metropolitan Area is the second most populous in the European Union after London with a population of 12,341,418 at the Jan. 2012 census.[7]		The population of Paris today is lower than its historical peak of 2.9 million in 1921. The principal reasons were a significant decline in household size, and a dramatic migration of residents to the suburbs between 1962 and 1975. Factors in the migration included de-industrialisation, high rent, the gentrification of many inner quarters, the transformation of living space into offices, and greater affluence among working families. The city's population loss came to an end in the 21st century; the population estimate of July 2004 showed a population increase for the first time since 1954, and the population reached 2,234,000 by 2009.[156]		According to Eurostat, the EU statistical agency, in 2012 the Commune of Paris was the most densely populated city in the European Union, with 21,616 people per square kilometre within the city limits (the NUTS-3 statistical area), ahead of Inner London West, which had 10,374 people per square kilometre. According to the same census, three departments bordering Paris, Hauts-de-Seine, Seine-Saint-Denis and Val-de-Marne, had population densities of over ten thousand people per square kilometre, ranking among the ten most densely populated areas of the EU.[157]		According to the 2012 French census, 586,163 residents of the City of Paris, or 26.2 percent, and 2,782,834 residents of the Paris Region (Île-de-France), or 23.4 percent, were born outside of Metropolitan France (the last figure up from 22.4% at the 2007 census).[151]		26,700 of these in the City of Paris and 210,159 in the Paris Region were people born in Overseas France (more than two-thirds of whom in the French West Indies) and are therefore not counted as immigrants since there are legally French citizens at birth.[151]		A further 103,648 in the City of Paris and in 412,114 in the Paris Region were born in foreign countries with French citizenship at birth.[151] This concerns in particular the many Christians and Jews from North Africa who moved to France and Paris after the times of independence and are not counted as immigrants due to their being born French citizens.		The remaining group, people born in foreign countries with no French citizenship at birth, are those defined as immigrants under French law. According to the 2012 census, 135,853 residents of the city of Paris were immigrants from Europe, 112,369 were immigrants from the Maghreb, 70,852 from sub-Saharan Africa and Egypt, 5,059 from Turkey, 91,297 from Asia (outside Turkey), 38,858 from the Americas, and 1,365 from the South Pacific.[158] Note that the immigrants from the Americas and the South Pacific in Paris are vastly outnumbered by migrants from French overseas regions and territories located in these regions of the world.[151]		In the Paris Region, 590,504 residents were immigrants from Europe, 627,078 were immigrants from the Maghreb, 435,339 from sub-Saharan Africa and Egypt, 69,338 from Turkey, 322,330 from Asia (outside Turkey), 113,363 from the Americas, and 2,261 from the South Pacific.[159] These last two groups of immigrants are again vastly outnumbered by migrants from French overseas regions and territories located in the Americas and the South Pacific.[151]		In 2012, there were 8,810 British citizens and 10,019 US citizens living in the City of Paris (Ville de Paris), and 20,466 British citizens and 16,408 US citizens living in the entire Paris Region (Île-de-France).[160][161]		According to a 2011 survey by IFOP, a French public opinion research organisation, 61 percent of residents of the Paris Region (Île-de-France) identified themselves as Roman Catholic, though just 15 percent said they were practising Catholics, while 46 percent were non-practicing. In the same survey, 7 percent of residents identified themselves as Muslims, 4 percent as Protestants, two percent as Jewish, and 25 percent as without religion.[162]		According to INSEE, the French government statistical office, between 4 and 5 million French residents were born or had at least one parent born in a predominately Muslim country, particularly Algeria, Morocco, and Tunisia. An IFOP survey in 2008 reported that, of immigrants from these predominantly Muslim countries, 25 percent went to the mosque regularly; 41 percent practised the religion, and 34 percent were believers but did not practice the religion.[163][164]		In 2012, Dalil Boubakeur, the Rector of the Grand Mosque of Paris and former President of the French Council of the Muslim Faith, estimated that there were 500,000 Muslims in the city of Paris, 1.5 million Muslims in the Île-de-France region, and 4 to 5 million Muslims in France.[165]		The Jewish population of the Paris Region was estimated in 2014 to be 282,000, the largest concentration of Jews in the world outside of Israel and the United States.[166]		The economy of the City of Paris is today is based largely on services and commerce; of the 390,480 enterprises in the city, 80.6 percent are engaged in commerce, transportation, and diverse services, 6.5 percent in construction, and just 3.8 percent in industry.[168] The story is similar in the Paris Region, or Île-de-France. 76.7 percent of enterprises are engaged in commerce and services, and 3.4 percent in industry.[169]		At the 2012 census, 59.5% of jobs in the Paris Region were in market services (12.0% in wholesale and retail trade, 9.7% in professional, scientific, and technical services, 6.5% in information and communication, 6.5% in transportation and warehousing, 5.9% in finance and insurance, 5.8% in administrative and support services, 4.6% in accommodation and food services, and 8.5% in various other market services), 26.9% in non-market services (10.4% in human health and social work activities, 9.6% in public administration and defence, and 6.9% in education), 8.2% in manufacturing and utilities (6.6% in manufacturing and 1.5% in utilities), 5.2% in construction, and 0.2% in agriculture.[170][171]		The Paris Region had 5.4 million salaried employees in 2010, of whom 2.2 million were concentrated in 39 pôles d'emplois or business districts. The largest of these, in terms of number of employees, is known in French as the QCA, or quartier central des affaires; it is in the western part of the City of Paris, in the 2nd, 8th, 9th, 16th, and 18th arrondissements. In 2010, it was the workplace of 500,000 salaried employees, about thirty percent of the salaried employees in Paris and ten percent of those in the Île-de-France. The largest sectors of activity in the central business district were finance and insurance (16 percent of employees in the district) and business services (15 percent). The district also includes a large concentration of department stores, shopping areas, hotels and restaurants, as well a government offices and ministries.[172]		The second-largest business district in terms of employment is La Défense, just west of the city, where many companies installed their offices in the 1990s. In 2010, it was the workplace of 144,600 employees, of whom 38 percent worked in finance and insurance, 16 percent in business support services. Two other important districts, Neuilly-sur-Seine and Levallois-Perret, are extensions of the Paris business district and of La Défense. Another district, including Boulogne-Billancourt, Issy-les-Moulineaux and the southern part of the 15th arrondissement, is a centre of activity for the media and information technology.[172]		The top ten French companies listed in the Fortune Global 500 for 2015 all have their headquarters in the Paris Region; six in the central business district of the City of Paris; and four close to the city in the Hauts-de-Seine Department, three in La Défense and one in Boulogne-Billancourt. Some companies, like Société Générale, have offices in both Paris and La Défense.		The Paris Region is France's leading region for economic activity, with a 2014 GDP of € 649.6 billion (US$773.4 billion).[173] In 2011, its GDP ranked second among the regions of Europe and its per-capita GDP was the 4th highest in Europe.[174][175] While the Paris region's population accounted for 18.8 percent of metropolitan France in 2011,[176] the Paris region's GDP accounted for 30 percent of metropolitan France's GDP.[177] In 2015, it hosts the world headquarters of 29 of the 31 Fortune Global 500 companies located in France.[178]		The Paris Region economy has gradually shifted from industry to high-value-added service industries (finance, IT services, etc.) and high-tech manufacturing (electronics, optics, aerospace, etc.).[179] The Paris region's most intense economic activity through the central Hauts-de-Seine department and suburban La Défense business district places Paris's economic centre to the west of the city, in a triangle between the Opéra Garnier, La Défense and the Val de Seine.[179] While the Paris economy is dominated by services, and employment in manufacturing sector has declined sharply, the region remains an important manufacturing centre, particularly for aeronautics, automobiles, and "eco" industries.[179]		In the 2017 worldwide cost of living survey by the Economist Intelligence Unit, based on a survey made in September 2016, Paris ranked as the seventh most expensive city in the world, and the second most expensive in Europe, after Zurich. [180]		According to 2012 INSEE figures, 68 percent of employees in the City of Paris work in commerce, transportation, and services; 24.4 percent in public administration, health and social services; 4.4 percent in industry, and 0.1 percent in agriculture.[181]		The majority of Paris's salaried employees fill 370,000 businesses services jobs, concentrated in the north-western 8th, 16th and 17th arrondissements.[182] Paris's financial service companies are concentrated in the central-western 8th and 9th arrondissement banking and insurance district.[182] Paris's department store district in the 1st, 6th, 8th and 9th arrondissements employ 10 percent of mostly female Paris workers, with 100,000 of these registered in the retail trade.[182] Fourteen percent of Parisians work in hotels and restaurants and other services to individuals.[182] Nineteen percent of Paris employees work for the State in either in administration or education. The majority of Paris's healthcare and social workers work at the hospitals and social housing concentrated in the peripheral 13th, 14th, 18th, 19th and 20th arrondissements.[182] Outside Paris, the western Hauts-de-Seine department La Défense district specialising in finance, insurance and scientific research district, employs 144,600,[179] and the north-eastern Seine-Saint-Denis audiovisual sector has 200 media firms and 10 major film studios.[179]		Paris's manufacturing is mostly focused in its suburbs, and the city itself has only around 75,000 manufacturing workers, most of which are in the textile, clothing, leather goods, and shoe trades.[179] Paris region manufacturing specialises in transportation, mainly automobiles, aircraft and trains, but this is in a sharp decline: Paris proper manufacturing jobs dropped by 64 percent between 1990 and 2010, and the Paris region lost 48 percent during the same period. Most of this is due to companies relocating outside the Paris region. The Paris region's 800 aerospace companies employed 100,000.[179] Four hundred automobile industry companies employ another 100,000 workers: many of these are centred in the Yvelines department around the Renault and PSA-Citroen plants (this department alone employs 33,000),[179] but the industry as a whole suffered a major loss with the 2014 closing of a major Aulnay-sous-Bois Citroen assembly plant.[179]		The southern Essonne department specialises in science and technology,[179] and the south-eastern Val-de-Marne, with its wholesale Rungis food market, specialises in food processing and beverages.[179] The Paris region's manufacturing decline is quickly being replaced by eco-industries: these employ about 100,000 workers.[179] In 2011, while only 56,927 construction workers worked in Paris itself,[183] its metropolitan area employed 246,639,[181] in an activity centred largely around the Seine-Saint-Denis (41,378)[184] and Hauts-de-Seine (37,303)[185] departments and the new business-park centres appearing there.		The average net household income (after social, pension and health insurance contributions) in Paris was €36,085 for 2011.[186] It ranged from €22,095 in the 19th arrondissement[187] to €82,449 in the 7th arrondissement.[188] The median taxable income for 2011 was around €25,000 in Paris and €22,200 for Île-de-France.[189] Generally speaking, incomes are higher in the Western part of the city and in the western suburbs than in the northern and eastern parts of the urban area.[190] Unemployment was estimated at 8.2 percent in the city of Paris and 8.8 percent in the Île-de-France region in the first trimester of 2015. It ranged from 7.6 percent in the wealthy Essonne department to 13.1 percent in the Seine-Saint-Denis department, where many recent immigrants live.[191]		While Paris has some of the richest neighbourhoods in France, it also has some of the poorest, mostly on the eastern side of the city. In 2012, 14 percent of households in the city earned less than €977 per month, the official poverty line. Twenty-five percent of residents in the 19th arrondissement lived below the poverty line; 24 percent in the 18th, 22 percent in the 20th and 18 percent in the 10th. In the city's wealthiest neighbourhood, the 7th arrondissement, 7 percent lived below the poverty line; 8 percent in the 6th arrondissement; and 9 percent in the 16th arrondissement.[192]		Tourism in Paris continued to suffer in 2016, after two terrorist attacks in Paris in 2015 and an attack in Nice in 2016. The number of foreign visitors in Grand Paris (Paris plus the three surrounding departments) dropped by 11.5 percent percent in 2016. [193] The largest drops were in tourists from Japan (46.9 percent), Russia (35.5 percent), Italy (31.9 percent), and China (17.9 percent).[194] The drops were particularly noticeable in the city's museums, especially the Louvre, where 70 percent of the visitors are from abroad. Attendance at the Louvre dropped by 15 percent in 2016: 61 percent fewer Japanese visitors, 47 percent fewer Brazilian visitors, and 31 percent fewer Chinese visitors. Visitors from the United States were down by 5.7 percent. Similar drops were reported at the Musee d'Orsay (visitors down by 13 percent from 2015) and the Palace of Versailles (down by 15 percent).[195]		Greater Paris received 36.5 million visitors in 2016, measured by hotel stays. [196] The largest numbers of foreign tourists in 2015, measured by airport arrivals, came from the United States (1.8 million), the UK (1.08 million), Germany (725,000), Italy (622,000), and Spain (609,000). Arrivals from Russia numbered 211,000, while arrivals from the rest of Europe numbered 1 million. 746,000 visitors came from China, while 481,000 came from Japan. Arrivals from the Near and Middle East numbered 535,000. Arrivals from the Americas outside the US numbered 910,000, 395,000 arrived from Africa, and 1,065,000 arrived from Asia and Oceania excluding China and Japan.[197]		In 2016, measured by the MasterCard Global Cities Destination Index, Paris was the third busiest airline destination in the world, with 18.03 million visitors, behind Bangkok (21.47 million) and London (19.88 million).[198] According to the Paris Convention and Visitors Bureau, 393,008 workers in Greater Paris, or 12.4 percent of the total workforce, are engaged in tourism-related sectors such as hotels, catering, transport, and leisure.[197]		The city's top tourist attraction was the Notre Dame Cathedral, which welcomed 12million visitors in 2016 <re>Tourism in Paris, Key Figures 2016, Paris Convention and Visitors Bureau<.ref> The Louvre museum had 7.3 million visitors in 2016, making it the second most visited art museum in the world.[200] After the Louvre, the other top museums in Paris in 2016 were the Centre Pompidou (3,3 million visitors), Musée d'Orsay (3 million visitors), and the National Museum of Natural History (1.5 million visitors). [201] Other top sites in 2016 were the Basilique du Sacré-Cœur (10 million visitors), the Eiffel Tower (5.9 million visitors, visitors), and the Arc de Triomphe (1.3 million visitors [202] In the Paris region, Disneyland Paris, in Marne-la-Vallée, 32 kilometres (20 miles) east of the centre of Paris, was the most visited tourist attraction in France, with 13.4 million visitors in fiscal year 2016, though this was a drop of ten percent from visitors in fiscal year 2015.[203]		The centre of Paris contains the most visited monuments in the city, including the Notre Dame Cathedral and the Louvre as well as the Sainte-Chapelle; Les Invalides, where the tomb of Napoleon is located, and the Eiffel Tower are located on the Left Bank south-west of the centre. The banks of the Seine from the Pont de Sully to the Pont d'Iéna have been listed as a UNESCO World Heritage Site since 1991.[204] Other landmarks are laid out east to west along the historical axis of Paris, which runs from the Louvre through the Tuileries Garden, the Luxor Column in the Place de la Concorde, and the Arc de Triomphe, to the Grande Arche of La Défense.		Several other much-visited landmarks are located in the suburbs of the city; the Basilica of St Denis, in Seine-Saint-Denis, is the birthplace of the Gothic style of architecture and the royal necropolis of French kings and queens.[205] The Paris region hosts three other UNESCO Heritage sites: the Palace of Versailles in the west,[206] the Palace of Fontainebleau in the south,[207] and the medieval fairs site of Provins in the east.[208]		As of 2013[update] the City of Paris had 1,570 hotels with 70,034 rooms, of which 55 were rated five-star, mostly belonging to international chains and mostly located close to the centre and the Champs-Élysées. Paris has long been famous for its grand hotels. The Hotel Meurice, opened for British travellers in 1817, was one of the first luxury hotels in Paris.[209] The arrival of the railways and the Paris Exposition of 1855 brought the first flood of tourists and the first modern grand hotels; the Hôtel du Louvre (now an antiques marketplace) in 1855; the Grand Hotel (now the Intercontinental LeGrand) in 1862; and the Hôtel Continental in 1878. The Hôtel Ritz on Place Vendôme opened in 1898, followed by the Hôtel Crillon in an 18th-century building on the Place de la Concorde in 1909; the Hotel Bristol on the Rue du Faubourg Saint-Honoré in 1925; and the Hotel George V in 1928.[210]		In addition to hotels, in July 2017 Paris had 65,000 homes registered with Airbnb, the biggest single market for the company. Under French law, renters of these units must pay the Paris tourism tax. The company paid the city government 7.3 million Euros in 2016. [211]		For centuries, Paris has attracted artists from around the world, who arrive in the city to educate themselves and to seek inspiration from its vast pool of artistic resources and galleries. As a result, Paris has acquired a reputation as the "City of Art".[212] Italian artists were a profound influence on the development of art in Paris in the 16th and 17th centuries, particularly in sculpture and reliefs. Painting and sculpture became the pride of the French monarchy and the French royal family commissioned many Parisian artists to adorn their palaces during the French Baroque and Classicism era. Sculptors such as Girardon, Coysevox and Coustou acquired reputations as the finest artists in the royal court in 17th-century France. Pierre Mignard became the first painter to King Louis XIV during this period. In 1648, the Académie royale de peinture et de sculpture (Royal Academy of Painting and Sculpture) was established to accommodate for the dramatic interest in art in the capital. This served as France's top art school until 1793.[213]		Paris was in its artistic prime in the 19th century and early 20th century, when it had a colony of artists established in the city and in art schools associated with some of the finest painters of the times: Édouard Manet, Claude Monet, Berthe Morisot, Paul Gauguin, Pierre-Auguste Renoir and others. The French Revolution and political and social change in France had a profound influence on art in the capital. Paris was central to the development of Romanticism in art, with painters such as Gericault.[213] Impressionism, Art Nouveau, Symbolism, Fauvism, Cubism and Art Deco movements all evolved in Paris.[213] In the late 19th century, many artists in the French provinces and worldwide flocked to Paris to exhibit their works in the numerous salons and expositions and make a name for themselves.[214] Artists such as Pablo Picasso, Henri Matisse, Vincent van Gogh, Paul Cézanne, Jean Metzinger, Albert Gleizes, Henri Rousseau, Marc Chagall, Amedeo Modigliani and many others became associated with Paris. Picasso, living in Montmartre, painted his famous La Famille de Saltimbanques and Les Demoiselles d'Avignon between 1905 and 1907.[215] Montmartre and Montparnasse became centres for artistic production.		The most prestigious names of French and foreign sculptors, who made their reputation in Paris in the modern era, are Frédéric Auguste Bartholdi (Statue of Liberty - Liberty Enlightening the World), Auguste Rodin, Camille Claudel, Antoine Bourdelle, Paul Landowski (statue of Christ the Redeemer in Rio de Janeiro) and Aristide Maillol. The Golden Age of the School of Paris ended between the two world wars.		The inventor Nicéphore Niépce produced the first permanent photograph on a polished pewter plate in Paris in 1825, and then developed the process with Louis Daguerre.[213] The work of Étienne-Jules Marey in the 1880s contributed considerably to the development of modern photography. Photography came to occupy a central role in Parisian Surrealist activity, in the works of Man Ray and Maurice Tabard.[216][217] Numerous photographers achieved renown for their photography of Paris, including Eugène Atget, noted for his depictions of street scenes, Robert Doisneau, noted for his playful pictures of people and market scenes (among which Le baiser de l'hôtel de ville has become iconic of the romantic vision of Paris), Marcel Bovis, noted for his night scenes, and others such as Jacques-Henri Lartigue and Cartier-Bresson.[213] Poster art also became an important art form in Paris in the late nineteenth century, through the work of Henri de Toulouse-Lautrec, Jules Chéret, Eugène Grasset, Adolphe Willette, Pierre Bonnard, Georges de Feure, Henri-Gabriel Ibels, Gavarni, and Alphonse Mucha.[213]		The Louvre was the world's second-most visited art museum in 2016, with 7.3 million visitors.[218] Its treasures include the Mona Lisa (La Joconde) and the Venus de Milo statue. With 3.44 million visitors, the Musée d'Orsay, in the former Orsay railway station, was the second-most visited museum in the city in 2016 with 3 million visitors. It displays French art of the 19th century, including major collections of the Impressionists and Post-Impressionists. The original building – a railway station – was constructed for the Universal Exhibition of 1900. Starkly apparent with its service-pipe exterior, the Centre Georges Pompidou, the third-most visited art museum in Paris, attracted 3.3 million visitors in 2016. Also known as Beaubourg, it houses the Musée National d'Art Moderne.[197] The Musée national du Moyen Âge, or Cluny Museum, presents Medieval art, including the famous tapestry cycle of The Lady and the Unicorn. The Guimet Museum, or Musée national des arts asiatiques, has one of the largest collections of Asian art in Europe. There are also notable museums devoted to individual artists, including the Picasso Museum the Rodin Museum, and the Musée national Eugène Delacroix.		Paris hosts one of the largest science museums in Europe, the Cité des Sciences et de l'Industrie at La Villette, attracted 2 million visitors in 2015, making it the fourth most popular national museum in the city. The National Museum of Natural History, on the Left Bank, attracted 1.88 million visitors in 2015, making it the fifth most popular Parisian national museum.[197] It is famous for its dinosaur artefacts, mineral collections, and its Gallery of Evolution. The military history of France, from the Middle Ages to World War II, is vividly presented by displays at the Musée de l'Armée at Les Invalides, near the tomb of Napoleon. In addition to the national museums, run by the French Ministry of Culture, the City of Paris operates 14 museums, including the Carnavalet Museum on the history of Paris; Musée d'Art Moderne de la Ville de Paris; Palais de Tokyo; the House of Victor Hugo and House of Balzac, and the Catacombs of Paris.[219] There are also notable private museums; The Contemporary Art museum of the Louis Vuitton Foundation, designed by architect Frank Gehry, opened in October 2014 in the Bois de Boulogne.[220]		The largest opera houses of Paris are the 19th-century Opéra Garnier (historical Paris Opéra) and modern Opéra Bastille; the former tends toward the more classic ballets and operas, and the latter provides a mixed repertoire of classic and modern.[221] In middle of the 19th century, there were three other active and competing opera houses: the Opéra-Comique (which still exists), Théâtre-Italien, and Théâtre Lyrique (which in modern times changed its profile and name to Théâtre de la Ville).[222] Philharmonie de Paris, the modern symphonic concert hall of Paris, opened in January 2015. Another musical landmark is the Théâtre des Champs-Élysées, where the first performances of Diaghilev's Ballets Russes took place in 1913.		Theatre traditionally has occupied a large place in Parisian culture, and many of its most popular actors today are also stars of French television. The oldest and most famous Paris theatre is the Comédie-Française, founded in 1680. Run by the French government, it performs mostly French classics at the Salle Richelieu in the Palais-Royal at 2 rue de Richelieu, next to the Louvre.[223] of Other famous theatres include the Odéon-Théâtre de l'Europe, next to the Luxembourg Gardens, also a state institution and theatrical landmark; the Théâtre Mogador, and the Théâtre de la Gaîté-Montparnasse.[224]		The music hall and cabaret are famous Paris institutions. The Moulin Rouge was opened in 1889. It was highly visible because of its large red imitation windmill on its roof, and became the birthplace of the dance known as the French Cancan. It helped make famous the singers Mistinguett and Édith Piaf and the painter Toulouse-Lautrec, who made posters for the venue. In 1911, the dance hall Olympia Paris invented the grand staircase as a settling for its shows, competing with its great rival, the Folies Bergère. Its stars in the 1920s included the American singer and dancer Josephine Baker. Later, Olympia Paris presented Edith Piaf, Marlene Dietrich, Miles Davis, Judy Garland, and the Grateful Dead. The Casino de Paris presented many famous French singers, including Mistinguett, Maurice Chevalier, and Tino Rossi. Other famous Paris music halls include Le Lido, on the Champs-Élysées, opened in 1946; and the Crazy Horse Saloon, featuring strip-tease, dance and magic, opened in 1951. A half dozen music halls exist today in Paris, attended mostly visitors to the city.[225]		The first book printed in France, Epistolae ("Letters"), by Gasparinus de Bergamo (Gasparino da Barzizza), was published in Paris in 1470 by the press established by Johann Heynlin. Since then, Paris has been the centre of the French publishing industry, the home of some of the world's best-known writers and poets, and the setting for many classic works of French literature. Almost all the books published in Paris in the Middle Ages were in Latin, rather than French. Paris did not become the acknowledged capital of French literature until the 17th century, with authors such as Boileau, Corneille, La Fontaine, Molière, Racine, several coming from the provinces, and the foundation of the Académie française.[226] In the 18th century, the literary life of Paris revolved around the cafés and salons, and was dominated by Voltaire, Jean-Jacques Rousseau, Pierre de Marivaux, and Beaumarchais.		During the 19th century, Paris was the home and subject for some of France's greatest writers, including Charles Baudelaire, Stéphane Mallarmé, Mérimée, Alfred de Musset, Marcel Proust, Émile Zola, Alexandre Dumas, Gustave Flaubert, Guy de Maupassant and Honoré de Balzac. Victor Hugo's The Hunchback of Notre Dame inspired the renovation of its setting, the Notre-Dame de Paris.[227] Another of Victor Hugo's works, Les Misérables, written while he was in exile outside France during the Second Empire, described the social change and political turmoil in Paris in the early 1830s.[228] One of the most popular of all French writers, Jules Verne, worked at the Theatre Lyrique and the Paris stock exchange, while he did research for his stories at the National Library.[229][citation not found]		In the 20th century, the Paris literary community was dominated by Colette, André Gide, François Mauriac, André Malraux, Albert Camus, and, after World War II, by Simone de Beauvoir and Jean-Paul Sartre; Between the wars it was the home of many important expatriate writers, including Ernest Hemingway, Samuel Beckett, and, in the 1970s, Milan Kundera. The winner of the 2014 Nobel Prize in Literature, Patrick Modiano–who lives in Paris–, based most of his literary work on the depiction of the city during World War II and the 1960s–1970s.[230]		Paris is a city of books and bookstores. In the 1970s, 80 percent of French-language publishing houses were found in Paris, almost all on the Left Bank in the 5th, 6th and 7th arrondissements. Since that time, because of high prices, some publishers have moved out to the less expensive areas.[231] It is also a city of small bookstores; There are about 150 bookstores in the 5th arrondissement alone, plus another 250 book stalls along the Seine. Small Paris bookstores are protected against competition from discount booksellers by French law; books, even e-books, cannot be discounted more than five percent below their publisher's cover price.[232]		In the late 12th century, a school of polyphony was established at Notre-Dame. Among the Trouvères of northern France, a group of Parisian aristocrats became known for their poetry and songs. Troubadours, from the south of France, were also popular. During the reign of François I, in the Renaissance era, the lute became popular in the French court. The French royal family and courtiers "disported themselves in masques, ballets, allegorical dances, recitals, and opera and comedy", and a national musical printing house was established.[213] In the Baroque-era, noted composers included Jean-Baptiste Lully, Jean-Philippe Rameau, and François Couperin.[213] The Conservatoire de Musique de Paris was founded in 1795.[233] By 1870, Paris had become an important centre for symphony, ballet and operatic music. Romantic-era composers (in Paris) include Hector Berlioz (La Symphonie fantastique), Charles Gounod (Faust), Camille Saint-Saëns (Samson et Delilah), Léo Delibes (Lakmé) and Jules Massenet (Thaïs), among others.[213] Georges Bizet's Carmen premiered 3 March 1875. Carmen has since become one of the most popular and frequently-performed operas in the classical canon.[234][235] Among the Impressionist composers who created new works for piano, orchestra, opera, chamber music and other musical forms, stand in particular, Claude Debussy (Suite bergamasque, and its well-known third movement, Clair de lune, La Mer, Pelléas et Mélisande), Erik Satie (Gymnopédies, "Je te veux", Gnossiennes, Parade) and Maurice Ravel (Miroirs, Boléro, La valse, L'heure espagnole). Several foreign-born composers, such as Frédéric Chopin (Poland), Franz Liszt (Hungary), Jacques Offenbach (Germany), Niccolò Paganini (Italy), and Igor Stravinsky (Russia), established themselves or made significant contributions both with their works and their influence in Paris.		Bal-musette is a style of French music and dance that first became popular in Paris in the 1870s and 1880s; by 1880 Paris had some 150 dance halls in the working-class neighbourhoods of the city.[236] Patrons danced the bourrée to the accompaniment of the cabrette (a bellows-blown bagpipe locally called a "musette") and often the vielle à roue (hurdy-gurdy) in the cafés and bars of the city. Parisian and Italian musicians who played the accordion adopted the style and established themselves in Auvergnat bars especially in the 19th arrondissement,[237] and the romantic sounds of the accordion has since become one of the musical icons of the city. Paris became a major centre for jazz and still attracts jazz musicians from all around the world to its clubs and cafés.[238]		Paris is the spiritual home of gypsy jazz in particular, and many of the Parisian jazzmen who developed in the first half of the 20th century began by playing Bal-musette in the city.[237] Django Reinhardt rose to fame in Paris, having moved to the 18th arrondissement in a caravan as a young boy, and performed with violinist Stéphane Grappelli and their Quintette du Hot Club de France in the 1930s and 1940s.[239]		Immediately after the War The Saint-Germain-des-Pres quarter and the nearby Saint-Michel quarter became home to many small jazz clubs, mostly found in cellars because of a lack of space; these included the Caveau des Lorientais, the Club Saint-Germain, the Rose Rouge, the Vieux-Colombier, and the most famous, Le Tabou. They introduced Parisians to the music of Claude Luter, Boris Vian, Sydney Bechet, Mezz Mezzrow, and Henri Salvador. Most of the clubs closed by the early 1960s, as musical tastes shifted toward rock and roll.[240]		Some of the finest manouche musicians in the world are found here playing the cafés of the city at night.[239] Some of the more notable jazz venues include the New Morning, Le Sunset, La Chope des Puces and Bouquet du Nord.[238][239] Several yearly festivals take place in Paris, including the Paris Jazz Festival(fr) and the rock festival Rock en Seine.[241] The Orchestre de Paris was established in 1967.[242]		On December 19, 2015, Paris and other worldwide fans commemorated the 100th anniversary of the birth of Edith Piaf—a French cabaret singer, songwriter and actress who became widely regarded as France's national chanteuse, as well as being one of France's greatest international stars.[243] Other singers—of similar style—include Maurice Chevalier, Charles Aznavour, Yves Montand, and Charles Trenet.		Paris has a big hip hop scene. This music became popular during the 1980s.[244] The presence of a large African and Caribbean community helped to its development, it gave a voice, a political and social status for many minorities.[245]		The movie industry was born in Paris when Auguste and Louis Lumière projected the first motion picture for a paying audience at the Grand Café on 28 December 1895.[246] Many of Paris's concert/dance halls were transformed into cinemas when the media became popular beginning in the 1930s. Later, most of the largest cinemas were divided into multiple, smaller rooms. Paris's largest cinema room today is in the Grand Rex theatre with 2,700 seats.[247] Big multiplex cinemas have been built since the 1990s. UGC Ciné Cité Les Halles with 27 screens, MK2 Bibliothèque with 20 screens and UGC Ciné Cité Bercy with 18 screens are among the largest.[248]		Parisians tend to share the same movie-going trends as many of the world's global cities, with cinemas primarily dominated by Hollywood-generated film entertainment. French cinema comes a close second, with major directors (réalisateurs) such as Claude Lelouch, Jean-Luc Godard, and Luc Besson, and the more slapstick/popular genre with director Claude Zidi as an example. European and Asian films are also widely shown and appreciated.[249] On 2 February 2000, Philippe Binant realised the first digital cinema projection in Europe, with the DLP CINEMA technology developed by Texas Instruments, in Paris.[250]		Since the late 18th century, Paris has been famous for its restaurants and haute cuisine, food meticulously prepared and artfully presented. A luxury restaurant, La Taverne Anglaise, opened in 1786 in the arcades of the Palais-Royal by Antoine Beauvilliers; it featured an elegant dining room, an extensive menu, linen tablecloths, a large wine list and well-trained waiters; it became a model for future Paris restaurants. The restaurant Le Grand Véfour in the Palais-Royal dates from the same period.[251] The famous Paris restaurants of the 19th century, including the Café de Paris, the Rocher de Cancale, the Café Anglais, Maison Dorée and the Café Riche, were mostly located near the theatres on the Boulevard des Italiens; they were immortalised in the novels of Balzac and Émile Zola. Several of the best-known restaurants in Paris today appeared during the Belle Epoque, including Maxim's on Rue Royale, Ledoyen in the gardens of the Champs-Élysées, and the Tour d'Argent on the Quai de la Tournelle.[252]		Today, thanks to Paris's cosmopolitan population, every French regional cuisine and almost every national cuisine in the world can be found there; the city has more than 9,000 restaurants.[253] The Michelin Guide has been a standard guide to French restaurants since 1900, awarding its highest award, three stars, to the best restaurants in France. In 2015, of the 29 Michelin three-star restaurants in France, nine are located in Paris. These include both restaurants which serve classical French cuisine, such as L'Ambroisie in the Place des Vosges, and those which serve non-traditional menus, such as L'Astrance, which combines French and Asian cuisines. Several of France's most famous chefs, including Pierre Gagnaire, Alain Ducasse, Yannick Alléno and Alain Passard, have three-star restaurants in Paris.[254][255]		In addition to the classical restaurants, Paris has several other kinds of traditional eating places. The café arrived in Paris in the 17th century, when the beverage was first brought from Turkey, and by the 18th century Parisian cafés were centres of the city's political and cultural life. The Café Procope on the Left Bank dates from this period. In the 20th century, the cafés of the Left Bank, especially Café de la Rotonde and Le Dôme Café in Montparnasse and Café de Flore and Les Deux Magots on Boulevard Saint Germain, all still in business, were important meeting places for painters, writers and philosophers.[252] A bistro is a type of eating place loosely defined as a neighbourhood restaurant with a modest decor and prices and a regular clientele and a congenial atmosphere. Its name is said to have come in 1814 from the Russian soldiers who occupied the city; "bistro" means "quickly" in Russian, and they wanted their meals served rapidly so they could get back their encampment. Real bistros are increasingly rare in Paris, due to rising costs, competition from cheaper ethnic restaurants, and different eating habits of Parisian diners.[256] A brasserie originally was a tavern located next to a brewery, which served beer and food at any hour. Beginning with the Paris Exposition of 1867; it became a popular kind of restaurant which featured beer and other beverages served by young women in the national costume associated with the beverage, particular German costumes for beer. Now brasseries, like cafés, serve food and drinks throughout the day.[257]		Paris has been an international capital of high fashion since the 19th century, particularly in the domain of haute couture, clothing hand-made to order for private clients.[258] It is home of some of the largest fashion houses in the world, including Dior and Chanel, and of many well-known fashion designers, including Karl Lagerfeld, Jean-Paul Gaultier, Christophe Josse, and Christian Lacroix. Paris Fashion Week, held in January and July in the Carrousel du Louvre and other city locations, is among the top four events of the international fashion calendar, along with the fashion weeks in Milan, London and New York.[259][260] Paris is also the home of the world's largest cosmetics company, L'Oréal, and three of the five top global makers of luxury fashion accessories; Louis Vuitton, Hermés, and Cartier.[261]		Bastille Day, a celebration of the storming of the Bastille in 1789, the biggest festival in the city, is a military parade taking place every year on 14 July on the Champs-Élysées, from the Arc de Triomphe to Place de la Concorde. It includes a flypast over the Champs Élysées by the Patrouille de France, a parade of military units and equipment, and a display of fireworks in the evening, the most spectacular being the one at the Eiffel Tower.[262]		Other yearly festivals are Paris-Plages, a festive event that lasts from mid-July to mid-August when the Right Bank of the Seine is converted into a temporary beach with sand, deck chairs and palm trees;[262] Journées du Patrimoine, Fête de la Musique, Techno Parade, Nuit Blanche, Cinéma au clair de lune, Printemps des rues, Festival d'automne and Fête des jardins. Carnaval de Paris, one of the oldest festivals in Paris, dates back to the Middle Ages.		Paris is the département with the highest proportion of highly educated people. In 2009, around 40 percent of Parisians held a licence-level diploma or higher, the highest proportion in France,[263] while 13 percent have no diploma, the third lowest percentage in France.		Education in Paris and the Île-de-France region employs approximately 330,000 people, 170,000 of whom are teachers and professors teaching approximately 2.9 million children and students in around 9,000 primary, secondary, and higher education schools and institutions.[264]		The University of Paris, founded in the 12th century, is often called the Sorbonne after one of its original medieval colleges. It was broken up into thirteen autonomous universities in 1970, following the student demonstrations in 1968. Most of the campuses today are in the Latin Quarter where the old university was located, while others are scattered around the city and the suburbs.[265][citation not found]		The Paris region hosts France's highest concentration of the grandes écoles – 55 specialised centres of higher-education outside the public university structure. The prestigious public universities are usually considered grands établissements. Most of the grandes écoles were relocated to the suburbs of Paris in the 1960s and 1970s, in new campuses much larger than the old campuses within the crowded city of Paris, though the École Normale Supérieure has remained on rue d'Ulm in the 5th arrondissement.[266] There are a high number of engineering schools, led by the Paris Institute of Technology which comprises several colleges such as École Polytechnique, École des Mines, AgroParisTech, Télécom Paris, Arts et Métiers, and École des Ponts et Chaussées. There are also many business schools, including HEC, INSEAD, ESSEC, and ESCP Europe. The administrative school such as ENA has been relocated to Strasbourg, the political science school Sciences-Po is still located in Paris's 7th arrondissement and the most prestigious university of economics and finance, Paris-Dauphine, is located in Paris's 16th. The Parisian school of journalism CELSA department of the Paris-Sorbonne University is located in Neuilly-sur-Seine.[267] Paris is also home to several of France's most famous high-schools such as Lycée Louis-le-Grand, Lycée Henri-IV, Lycée Janson de Sailly and Lycée Condorcet. The National Institute of Sport and Physical Education, located in the 12th arrondissement, is both a physical education institute and high-level training centre for elite athletes.		The Bibliothèque nationale de France (BnF) operates public libraries in Paris, among them the François Mitterrand Library, Richelieu Library, Louvois, Opéra Library, and Arsenal Library.[268] There are three public libraries in the 4th arrondissement. The Forney Library, in the Marais district, is dedicated to the decorative arts; the Arsenal Library occupies a former military building, and has a large collection on French literature; and the Bibliothèque historique de la ville de Paris, also in Le Marais, contains the Paris historical research service. The Sainte-Geneviève Library is in 5th arrondissement; designed by Henri Labrouste and built in the mid-1800s, it contains a rare book and manuscript division.[269] Bibliothèque Mazarine, in the 6th arrondissement, is the oldest public library in France. The Médiathèque Musicale Mahler in the 8th arrondissement opened in 1986 and contains collections related to music. The François Mitterrand Library (nicknamed Très Grande Bibliothèque) in the 13th arrondissement was completed in 1994 to a design of Dominique Perrault and contains four glass towers.[269]		There are several academic libraries and archives in Paris. The Sorbonne Library in the 5th arrondissement is the largest university library in Paris. In addition to the Sorbonne location, there are branches in Malesherbes, Clignancourt-Championnet, Michelet-Institut d'Art et d'Archéologie, Serpente-Maison de la Recherche, and Institut des Etudes Ibériques.[270] Other academic libraries include Interuniversity Pharmaceutical Library, Leonardo da Vinci University Library, Paris School of Mines Library, and the René Descartes University Library.[271]		Like the rest of France, Paris has been predominantly Roman Catholic since the early Middle Ages, though religious attendance is now low. A majority of Parisians are still nominally Roman Catholic. According to 2011 statistics, there are 106 parishes and curates in the city, plus separate parishes for Spanish, Polish and Portuguese Catholics. There are an additional 10 Eastern Orthodox parishes, and bishops for the Armenian and Ukrainian Orthodox Churches. In addition there are eighty male religious orders and 140 female religious orders in the city, as well as 110 Catholic schools with 75,000 students.[272]		The principal Roman Catholic church in Paris is the Cathedral of Notre-Dame de Paris, the seat of the Archbishop of Paris.[273] There are two officially recognised pilgrimage sites in Paris: the Basilique du Sacré-Cœur de Montmartre and the Chapel of Our Lady of the Miraculous Medal. Cardinal André Vingt-Trois became the Archbishop of Paris in March 2005.[274]		Almost all Protestant denominations are represented in Paris, with 74 evangelical churches from various denominations,[275] including 21 parishes of the United Protestant Church of France and two parishes of the Church of Jesus Christ of the Latter-Day Saints. There are several important churches for the English-speaking community: the American Church in Paris, founded in 1814, was the first American church outside the United States; the current church was finished in 1931.[276] The Saint George's Anglican Church in the 16th arrondissement is the principal Anglican church in the city.[277]		The Grand Mosque of Paris, the oldest mosque in Paris, was dedicated in 1926. It was funded by the French government and built to honour the 38,000 soldiers from Algeria, Tunisia and Morocco who died fighting for France in the First World War.[278]		In 2011 there were nineteen large mosques within the city limits of Paris, all except the Grand Mosque located in the outer arrondissements of the city, as well as hundreds of small prayer rooms. The number of mosques doubled between 1991 and 2011.[279]		During the Middle Ages, Paris was a centre of Jewish learning with famous Talmudic scholars, such as Yechiel of Paris who took part in the Disputation of Paris between Christian and Jewish intellectuals. The Parisian Jewish community was victim of persecution, alternating expulsions and returns, until France became the first country in Europe to emancipate its Jewish population during the French Revolution. Although 75% of the Jewish population in France survived the Holocaust during World War II,[280][281] half the city's Jewish population perished in Nazi concentration camps, while some others fled abroad.[282] A large migration of North Africa Sephardic Jews settled Paris in the 1960s, and represent most of the Paris Jewish community today. There are currently 83 synagogues in the city;[283] The Marais-quarter Agoudas Hakehilos Synagogue, built in 1913 by architect Hector Guimard, is a Paris landmark.[284]		The Pagode de Vincennes Buddhist temple, near Lake Daumesnil in the Bois de Vincennes, is the former Cameroon pavilion from the 1931 Paris Colonial Exposition. It hosts several different schools of Buddhism, and does not have a single leader. It shelters the biggest Buddha statue in Europe, more than nine metres (30 feet) high. There are two other small temples located in the Asian community in the 13th arrondissement. A Hindu temple, dedicated to Ganesh, on Rue Pajol in the 18th arrondissement, opened in 1985.		Paris's most popular sport clubs are the association football club Paris Saint-Germain F.C. and the rugby union club Stade Français. The 80,000-seat Stade de France, built for the 1998 FIFA World Cup, is located just north of Paris in the commune of Saint-Denis.[285] It is used for football, rugby union and track and field athletics. It hosts the French national football team for friendlies and major tournaments qualifiers, annually hosts the French national rugby team's home matches of the Six Nations Championship, and hosts several important matches of the Stade Français rugby team.[285] In addition to Paris Saint-Germain FC, the city has a number of other professional and amateur football clubs: Paris FC, Red Star, RCF Paris and Stade Français Paris.		Paris hosted the 1900 and 1924 Summer Olympics and will host the 2024 Summer Olympics and Paralympic Games.		The city also hosted the finals of the 1938 FIFA World Cup (at the Stade Olympique de Colombes), as well as the 1998 FIFA World Cup and the 2007 Rugby World Cup Final (both at the Stade de France). Two UEFA Champions League Finals in the current century have also been played in the Stade de France: the 2000 and 2006 editions.[286] Paris has most recently been the host for UEFA Euro 2016 at the Parc des Princes.		The final stage of the most famous bicycle racing in the world, Tour de France, always finishes in Paris. Since 1975, the race has finished on the Champs-Elysées.[287]		Tennis is another popular sport in Paris and throughout France; the French Open, held every year on the red clay of the Roland Garros National Tennis Centre,[288] is one of the four Grand Slam events of the world professional tennis tour. The 17,000-seat Bercy Arena (officially named AccorHotels Arena and formerly known as the Palais Omnisports de Paris-Bercy) is the venue for the annual Paris Masters ATP Tour tennis tournament and has been a frequent site of national and international tournaments in basketball, boxing, cycling, handball, ice hockey, show jumping and other sports. The Bercy Arena also hosted the 2017 IIHF World Ice Hockey Championship, together with Cologne, Germany. The final stages of the FIBA EuroBasket 1999 were also played at the Palais Omnisports de Paris-Bercy.		The basketball team Paris-Levallois Basket play at the 4,000 capacity Stade Pierre de Coubertin.[289]		Paris is a major rail, highway, and air transport hub. The Syndicat des transports d'Île-de-France (STIF), formerly Syndicat des transports parisiens (STP), oversees the transit network in the region.[290] The syndicate coordinates public transport and contracts it out to the RATP (operating 347 bus lines, the Métro, eight tramway lines, and sections of the RER), the SNCF (operating suburban rails, one tramway line and the other sections of the RER) and the Optile consortium of private operators managing 1,176 bus lines.[291]		A central hub of the national rail network, Paris's six major railway stations (Gare du Nord, Gare de l'Est, Gare de Lyon, Gare d'Austerlitz, Gare Montparnasse, Gare Saint-Lazare) and a minor one (Gare de Bercy) are connected to three networks: the TGV serving four high-speed rail lines, the normal speed Corail trains, and the suburban rails (Transilien).		Since the inauguration of its first line in 1900, Paris's Métro subway network has grown to become the city's most widely used local transport system; today it carries about 5.23 million passengers daily[292] through 16 lines, 303 stations (385 stops) and 220 km (136.7 mi) of rails. Superimposed on this is a 'regional express network', the RER, whose five lines (A, B, C, D, and E), 257 stops and 587 km (365 mi) of rails connect Paris to more distant parts of the urban area.[293]		Over €26.5 billion will be invested over the next 15 years to extend the Métro network into the suburbs,[293] with notably the Grand Paris Express project.		In addition, the Paris region is served by a light rail network of nine lines, the tramway: Line T1 runs from Asnières-Gennevilliers to Noisy-le-Sec, line T2 runs from Pont de Bezons to Porte de Versailles, line T3a runs from Pont du Garigliano to Porte de Vincennes, line T3b runs from Porte de Vincennes to Porte de la Chapelle, line T5 runs from Saint-Denis to Garges-Sarcelles, line T6 runs from Châtillon to Viroflay, line T7 runs from Villejuif to Athis-Mons, line T8 runs from Saint-Denis to Épinay-sur-Seine and Villetaneuse, all of which are operated by the Régie Autonome des Transports Parisiens,[294] and line T4 runs from Bondy RER to Aulnay-sous-Bois, which is operated by the state rail carrier SNCF.[293] Five new light rail lines are currently in various stages of development.[295]		Paris is a major international air transport hub with the 5th busiest airport system in the world. The city is served by three commercial international airports: Paris-Charles de Gaulle, Paris-Orly and Beauvais-Tillé. Together these three airports recorded traffic of 96.5 million passengers in 2014.[297] There is also one general aviation airport, Paris-Le Bourget, historically the oldest Parisian airport and closest to the city centre, which is now used only for private business flights and air shows.		Orly Airport, located in the southern suburbs of Paris, replaced Le Bourget as the principal airport of Paris from the 1950s to the 1980s.[298] Charles de Gaulle Airport, located on the edge of the northern suburbs of Paris, opened to commercial traffic in 1974 and became the busiest Parisian airport in 1993.[299] Today it is the 4th busiest airport in the world by international traffic and is the hub for the nation's flag carrier Air France.[293] Beauvais-Tillé Airport, located 69 kilometres (43 miles) north of Paris's city centre, is used by charter airlines and low-cost carriers such as Ryanair.		In 2014 the main domestic and international destinations served by the three commercial airports of Paris were the following:		Domestically, air travel between Paris and some of France's largest cities such as Lyon, Marseille, or Strasbourg has been in a large measure replaced by high-speed rail due to the opening of several high-speed TGV rail lines from the 1980s. For example, after the LGV Méditerranée opened in 2001, air traffic between Paris and Marseille declined from 2,976,793 passengers in 2000 to 1,502,196 passengers in 2014.[300] After the LGV Est opened in 2007, air traffic between Paris and Strasbourg declined from 1,006,327 passengers in 2006 to 157,207 passengers in 2014.[300]		Internationally, air traffic has increased markedly in recent years between Paris and the Gulf airports, the emerging nations of Africa, Russia, Turkey, Portugal, Italy, and mainland China, whereas noticeable decline has been recorded between Paris and the British Isles, Egypt, Tunisia, and Japan.[301][302]		The city is also the most important hub of France's motorway network, and is surrounded by three orbital freeways: the Périphérique,[92] which follows the approximate path of 19th-century fortifications around Paris, the A86 motorway in the inner suburbs, and finally the Francilienne motorway in the outer suburbs. Paris has an extensive road network with over 2,000 km (1,243 mi) of highways and motorways.		The Paris region is the most active water transport area in France, with most of the cargo handled by Ports of Paris in facilities located around Paris. The Loire, Rhine, Rhone, Meuse, and Scheldt rivers can be reached by canals connecting with the Seine, which include the Canal Saint-Martin, Canal Saint-Denis, and the Canal de l'Ourcq.[303]		There are 440 km (270 mi) of cycle paths and routes in Paris. These include piste cyclable (bike lanes separated from other traffic by physical barriers such as a kerb) and bande cyclable (a bicycle lane denoted by a painted path on the road). Some 29 km (18 mi) of specially marked bus lanes are free to be used by cyclists, with a protective barrier protecting against encroachments from vehicles.[304] Cyclists have also been given the right to ride in both directions on certain one-way streets. Paris offers a bike sharing system called Vélib' with more than 20,000 public bicycles distributed at 1,800 parking stations,[305] which can be rented for short and medium distances including one way trips.		Paris is provided in electricity through a 'periphery' grid fed by multiple sources.As of 2012[update], around 50% of electricity generated in the Île-de-France comes from cogeneration energy plants located near the outer limits of the region; other energy sources include the Nogent nuclear power plant (35%), trash incineration (9% – with cogeneration plants, these provide the city in heat as well), methane gas (5%), hydraulics (1%), solar power (0.1%) and a negligible amount of wind power (0.034 GWh).[306] A quarter of Paris's district heating is to come from a plant in Saint-Ouen, burning a 50/50-mix of coal and 140,000 tonnes of wood pellets from USA per year.[307]		Paris in its early history had only the Seine and Bièvre rivers for water. From 1809, the Canal de l'Ourcq provided Paris with water from less-polluted rivers to the north-east of the capital.[308] From 1857, the civil engineer Eugène Belgrand, under Napoleon III, oversaw the construction of a series of new aqueducts that brought water from locations all around the city to several reservoirs built atop the Capital's highest points of elevation.[309] From then on, the new reservoir system became Paris's principal source of drinking water, and the remains of the old system, pumped into lower levels of the same reservoirs, were from then on used for the cleaning of Paris's streets. This system is still a major part of Paris's modern water-supply network. Today Paris has more than 2,400 km (1,491 mi) of underground passageways[310] dedicated to the evacuation of Paris's liquid wastes.		In 1982, Mayor Chirac introduced the motorcycle-mounted Motocrotte to remove dog faeces from Paris streets.[311] The project was abandoned in 2002 for a new and better enforced local law, under the terms of which dog owners can be fined up to €500 for not removing their dog faeces.[312] The air pollution in Paris, from the point of view of particulate matter (PM10), is the highest in France with 38 µg/m³.[313]		Paris today has more than 421 municipal parks and gardens, covering more than 3,000 hectares and containing more than 250,000 trees.[314] Two of Paris's oldest and most famous gardens are the Tuileries Garden, created in 1564 for the Tuileries Palace, and redone by André Le Nôtre between 1664 and 1672,[315] and the Luxembourg Garden, for the Luxembourg Palace, built for Marie de' Medici in 1612, which today houses the French Senate.[316] The Jardin des Plantes was the first botanical garden in Paris, created in 1626 by Louis XIII's doctor Guy de La Brosse for the cultivation of medicinal plants.[317]		Between 1853 and 1870, the Emperor Napoleon III and the city's first director of parks and gardens, Jean-Charles Alphand, created the Bois de Boulogne, the Bois de Vincennes, Parc Montsouris and the Parc des Buttes-Chaumont, located at the four points of the compass around the city, as well as many smaller parks, squares and gardens in the Paris's quarters.[318] Since 1977, the city has created 166 new parks, most notably the Parc de la Villette (1987), Parc André Citroën (1992), and Parc de Bercy (1997).[319] One of the newest parks, the Promenade des Berges de la Seine (2013), built on a former highway on the Left Bank of the Seine between the Pont de l'Alma and the Musée d'Orsay, has floating gardens and gives a view of the city's landmarks.		In Paris's Roman era, its main cemetery was located to the outskirts of the Left Bank settlement, but this changed with the rise of Catholicism, where most every inner-city church had adjoining burial grounds for use by their parishes. With Paris's growth many of these, particularly the city's largest cemetery, les Innocents, were filled to overflowing, creating quite unsanitary conditions for the capital. When inner-city burials were condemned from 1786, the contents of all Paris's parish cemeteries were transferred to a renovated section of Paris's stone mines outside the "Porte d'Enfer" city gate, today place Denfert-Rochereau in the 14th arrondissement.[320][321] The process of moving bones from Cimetière des Innocents to the catacombs took place between 1786 and 1814;[322] part of the network of tunnels and remains can be visited today on the official tour of the catacombs.		After a tentative creation of several smaller suburban cemeteries, the Prefect Nicholas Frochot under Napoleon Bonaparte provided a more definitive solution in the creation of three massive Parisian cemeteries outside the city limits.[323] Open from 1804, these were the cemeteries of Père Lachaise, Montmartre, Montparnasse, and later Passy; these cemeteries became inner-city once again when Paris annexed all neighbouring communes to the inside of its much larger ring of suburban fortifications in 1860. New suburban cemeteries were created in the early 20th century: The largest of these are the Cimetière parisien de Saint-Ouen, the Cimetière parisien de Pantin (also known as Cimetière parisien de Pantin-Bobigny), the Cimetière parisien d'Ivry, and the Cimetière parisien de Bagneux.[324] Some of the most famous people in the world are buried in Parisian cemeteries.		Health care and emergency medical service in the city of Paris and its suburbs are provided by the Assistance publique – Hôpitaux de Paris (AP-HP), a public hospital system that employs more than 90,000 people (including practitioners, support personnel, and administrators) in 44 hospitals.[325] It is the largest hospital system in Europe. It provides health care, teaching, research, prevention, education and emergency medical service in 52 branches of medicine. The hospitals receive more than 5.8 million annual patient visits.[325]		One of the most notable hospitals is the Hôtel-Dieu, founded in 651, the oldest hospital in the city.[326] Other hospitals include Pitié-Salpêtrière Hospital (one of the largest in Europe), Hôpital Cochin, Hôpital Bichat, Hôpital Européen Georges-Pompidou, Bicêtre Hospital, Beaujon Hospital, the Curie Institute, Lariboisière Hospital, Necker-Enfants Malades Hospital, Hôpital Saint-Louis, Hôpital de la Charité and the American Hospital of Paris.		Paris and its close suburbs is home to numerous newspapers, magazines and publications including Le Monde, Le Figaro, Libération, Le Nouvel Observateur, Le Canard enchaîné, La Croix, Pariscope, Le Parisien (in Saint-Ouen), Les Échos, Paris Match (Neuilly-sur-Seine), Réseaux & Télécoms, Reuters France, and L'Officiel des Spectacles.[327] France's two most prestigious newspapers, Le Monde and Le Figaro, are the centrepieces of the Parisian publishing industry.[328] Agence France-Presse is France's oldest, and one of the world's oldest, continually operating news agencies. AFP, as it is colloquially abbreviated, maintains its headquarters in Paris, as it has since 1835.[329] France 24 is a television news channel owned and operated by the French government, and is based in Paris.[330] Another news agency is France Diplomatie, owned and operated by the Ministry of Foreign and European Affairs, and pertains solely to diplomatic news and occurrences.[331]		The most-viewed network in France, TF1, is in nearby Boulogne-Billancourt. France 2, France 3, Canal+, France 5, M6 (Neuilly-sur-Seine), Arte, D8, W9, NT1, NRJ 12, La Chaîne parlementaire, France 4, BFM TV, and Gulli are other stations located in and around the capital.[332] Radio France, France's public radio broadcaster, and its various channels, is headquartered in Paris's 16th arrondissement. Radio France Internationale, another public broadcaster is also based in the city.[333] Paris also holds the headquarters of the La Poste, France's national postal carrier.[334]		Paris is since April 9, 1956 exclusively and reciprocally twinned only with:[335]		Paris has agreements of friendship and co-operation with:[335]		
A fjard (Swedish: fjärd, IPA: [ˈfjæːɖ]) is an inlet formed by the marine submergence of formerly glaciated valleys and depressions within a rocky glaciated terrain of low relief. Fjards are characterized by a profile that is shorter, shallower, and broader than the profile of a fjord.[1] A fjard lacks the steep walls that characterize a glacial trough that has been partially submerged to form a fjord. Examples of fjards are Bråviken on the coast of Sweden, Hjortsholm on the coast of Denmark, and Somes Sound in Acadia National Park, Maine.[2][3][4]		Although fjards and fjords are similar in that they are a glacially-formed topography, they still differ in some key ways. Fjords are characterized by steep high relief cliffs carved by glacial activity and often have split or branching channels. Fjards are a glacial depression or valley that has much lower relief than a fjord. Fjards fill with eroded local materials which assists "filling" along with rising sea level since the last ice age contributing as well. Other low relief landforms that are only associated with fjards such as mud flats, salt marshes, and flood plains[5] further characterize the difference between fjords and fjards.		The "Förden" of the German coast and the fjords of Danish eastern Jutland together form a third type of glacial inlets.		
Ninety Mile Beach (official name Te-Oneroa-a-Tōhē/Ninety Mile Beach)[1] is on the western coast of the far north of the North Island of New Zealand.[2] It stretches from just west of Kaitaia towards Cape Reinga along the Aupouri Peninsula. It begins close to the headland of Reef Point, to the west of Ahipara Bay, sweeping briefly northeast before turning northwest for the majority of its length. It ends at Scott Point, 5 kilometres (3 mi) south of Cape Maria van Diemen. The beach is actually just 88 kilometers (55 miles) long. In the days of sailing ships a number of vessels were wrecked on this beach.[3]		The beach and its northern dunes are a tourist destination. The dunes, looking much like a desert landscape, are often used for bodyboarding.		In 1932 the beach was used as the runway for some of the earliest airmail services between Australia and New Zealand. It is officially a public highway[4] and sometimes used as an alternative road to State Highway 1 north of Kaitaia, though mainly for tourist reasons, or when the main road is closed due to landslides or floods.[citation needed]		In a 2013 feature for TV show Top Gear, Jeremy Clarkson drove the length of the beach in a Toyota Corolla[5] as part of a race against an AC45 racing yacht with a crew that included James May.[6]		Coordinates: 34°43′S 172°56′E﻿ / ﻿34.717°S 172.933°E﻿ / -34.717; 172.933		
A wash margin[1] or wash fringe[1] (German: Spülsaum)[1] is an area of the shore on which material is deposited or washed up. It often runs along the margin of a waterbody and there can be several bands due to variations in water levels. As a result of the richness of nutrients that occur in such wash fringes, ruderal species frequently occur here, that, for example, on the Baltic Sea coast consist of grassleaf orache and sea kale.						
Coordinates: 40°N 100°W﻿ / ﻿40°N 100°W﻿ / 40; -100		The United States of America (/əˈmɛrɪkə/; USA), commonly known as the United States (U.S.) or America, is a federal republic[19][20] composed of 50 states, a federal district, five major self-governing territories, and various possessions.[fn 6] Forty-eight of the fifty states and the federal district are contiguous and located in North America between Canada and Mexico. The state of Alaska is in the northwest corner of North America, bordered by Canada to the east and across the Bering Strait from Russia to the west. The state of Hawaii is an archipelago in the mid-Pacific Ocean. The U.S. territories are scattered about the Pacific Ocean and the Caribbean Sea, stretching across nine time zones. The extremely diverse geography, climate and wildlife of the United States make it one of the world's 17 megadiverse countries.[22][23]		At 3.8 million square miles (9.8 million km2)[11] and with over 324 million people, the United States is the world's third- or fourth-largest country by total area,[fn 7] third-largest by land area, and the third-most populous. It is one of the world's most ethnically diverse and multicultural nations, and is home to the world's largest immigrant population.[28] The capital is Washington, D.C., and the largest city is New York City; nine other major metropolitan areas—each with at least 4.5 million inhabitants—are Los Angeles, Chicago, Dallas, Houston, Philadelphia, Miami, Atlanta, Boston, and San Francisco.		Paleo-Indians migrated from Asia to the North American mainland at least 15,000 years ago.[29] European colonization began in the 16th century. The United States emerged from 13 British colonies along the East Coast. Numerous disputes between Great Britain and the colonies following the Seven Years' War led to the American Revolution, which began in 1775. On July 4, 1776, during the course of the American Revolutionary War, the colonies unanimously adopted the Declaration of Independence. The war ended in 1783 with recognition of the independence of the United States by Great Britain, representing the first successful war of independence against a European power.[30] The current constitution was adopted in 1788, after the Articles of Confederation, adopted in 1781, were felt to have provided inadequate federal powers. The first ten amendments, collectively named the Bill of Rights, were ratified in 1791 and designed to guarantee many fundamental civil liberties.		The United States embarked on a vigorous expansion across North America throughout the 19th century,[31] displacing Native American tribes, acquiring new territories, and gradually admitting new states until it spanned the continent by 1848.[31] During the second half of the 19th century, the American Civil War led to the end of legal slavery in the country.[32][33] By the end of that century, the United States extended into the Pacific Ocean,[34] and its economy, driven in large part by the Industrial Revolution, began to soar.[35] The Spanish–American War and World War I confirmed the country's status as a global military power. The United States emerged from World War II as a global superpower, the first country to develop nuclear weapons, the only country to use them in warfare, and a permanent member of the United Nations Security Council. The end of the Cold War and the dissolution of the Soviet Union in 1991 left the United States as the world's sole superpower.[36] The U.S. is a founding member of the United Nations, World Bank, International Monetary Fund, Organization of American States (OAS), and other international organizations.		The United States is a highly developed country, with the world's largest economy by nominal GDP and second-largest economy by PPP. Though its population is only 4.3% of the world total,[37] Americans hold nearly 40% of the total wealth in the world.[38] The United States ranks among the highest in several measures of socioeconomic performance, including average wage,[39] human development, per capita GDP, and productivity per person.[40] While the U.S. economy is considered post-industrial, characterized by the dominance of services and knowledge economy, the manufacturing sector remains the second-largest in the world.[41] Accounting for approximately a quarter of global GDP[42] and a third of global military spending,[43] the United States is the world's foremost economic and military power. The United States is a prominent political and cultural force internationally, and a leader in scientific research and technological innovations.[44]						In 1507, the German cartographer Martin Waldseemüller produced a world map on which he named the lands of the Western Hemisphere "America" in honor of the Italian explorer and cartographer Amerigo Vespucci (Latin: Americus Vespucius).[45] The first documentary evidence of the phrase "United States of America" is from a letter dated January 2, 1776, written by Stephen Moylan, Esq., George Washington's aide-de-camp and Muster-Master General of the Continental Army. Addressed to Lt. Col. Joseph Reed, Moylan expressed his wish to carry the "full and ample powers of the United States of America" to Spain to assist in the revolutionary war effort.[47][48][49]		The first known publication of the phrase "United States of America" was in an anonymous essay in The Virginia Gazette newspaper in Williamsburg, Virginia, on April 6, 1776.[50][51] The second draft of the Articles of Confederation, prepared by John Dickinson and completed by June 17, 1776, at the latest, declared "The name of this Confederation shall be the 'United States of America.'"[52] The final version of the Articles sent to the states for ratification in late 1777 contains the sentence "The Stile of this Confederacy shall be 'The United States of America'".[53] In June 1776, Thomas Jefferson wrote the phrase "UNITED STATES OF AMERICA" in all capitalized letters in the headline of his "original Rough draught" of the Declaration of Independence.[54][55] This draft of the document did not surface until June 21, 1776, and it is unclear whether it was written before or after Dickinson used the term in his June 17 draft of the Articles of Confederation.[52] In the final Fourth of July version of the Declaration, the title was changed to read, "The unanimous Declaration of the thirteen united States of America".[56] The preamble of the Constitution states "...establish this Constitution for the United States of America."		The short form "United States" is also standard. Other common forms are the "U.S.", the "USA", and "America". Colloquial names are the "U.S. of A." and, internationally, the "States". "Columbia", a name popular in poetry and songs of the late 18th century, derives its origin from Christopher Columbus; it appears in the name "District of Columbia".[57] In non-English languages, the name is frequently the translation of either the "United States" or "United States of America", and colloquially as "America". In addition, an abbreviation (e.g. USA) is sometimes used.[58]		The phrase "United States" was originally plural, a description of a collection of independent states—e.g., "the United States are"—including in the Thirteenth Amendment to the United States Constitution, ratified in 1865. The singular form—e.g., "the United States is"—became popular after the end of the American Civil War. The singular form is now standard; the plural form is retained in the idiom "these United States".[59] The difference is more significant than usage; it is a difference between a collection of states and a unit.[60]		A citizen of the United States is an "American". "United States", "American" and "U.S." refer to the country adjectivally ("American values", "U.S. forces"). In English, the word "American" rarely refers to topics or subjects not connected with the United States.[61]		The first inhabitants of North America migrated from Siberia by way of the Bering land bridge and arrived at least 15,000 years ago, though increasing evidence suggests an even earlier arrival.[29] Some, such as the pre-Columbian Mississippian culture, developed advanced agriculture, grand architecture, and state-level societies.[62] The first Europeans to arrive in territory of the modern United States were Spanish conquistadors such as Juan Ponce de León, who made his first visit to Florida in 1513.		In the Hawaiian Islands, the earliest indigenous inhabitants arrived around 1 AD from Polynesia. Europeans under the British explorer Captain James Cook arrived in the Hawaiian Islands in 1778.		After Spain sent Columbus on his first voyage to the New World in 1492, other explorers followed. The Spanish set up the first settlements in Florida and New Mexico such as Saint Augustine[63] and Santa Fe. The French established their own as well along the Mississippi River. Successful English settlement on the eastern coast of North America began with the Virginia Colony in 1607 at Jamestown and the Pilgrims' Plymouth Colony in 1620. Many settlers were dissenting Christian groups who came seeking religious freedom. The continent's first elected legislative assembly, Virginia's House of Burgesses created in 1619, the Mayflower Compact, signed by the Pilgrims before disembarking, and the Fundamental Orders of Connecticut, established precedents for the pattern of representative self-government and constitutionalism that would develop throughout the American colonies.[64][65]		Most settlers in every colony were small farmers, but other industries developed within a few decades as varied as the settlements. Cash crops included tobacco, rice and wheat. Extraction industries grew up in furs, fishing and lumber. Manufacturers produced rum and ships, and by the late colonial period Americans were producing one-seventh of the world's iron supply.[66] Cities eventually dotted the coast to support local economies and serve as trade hubs. English colonists were supplemented by waves of Scotch-Irish and other groups. As coastal land grew more expensive freed indentured servants pushed further west.[67]		A large-scale slave trade with English privateers was begun.[68] The life expectancy of slaves was much higher in North America than further south, because of less disease and better food and treatment, leading to a rapid increase in the numbers of slaves.[69][70] Colonial society was largely divided over the religious and moral implications of slavery and colonies passed acts for and against the practice.[71][72] But by the turn of the 18th century, African slaves were replacing indentured servants for cash crop labor, especially in southern regions.[73]		With the British colonization of Georgia in 1732, the 13 colonies that would become the United States of America were established.[74] All had local governments with elections open to most free men, with a growing devotion to the ancient rights of Englishmen and a sense of self-government stimulating support for republicanism.[75] With extremely high birth rates, low death rates, and steady settlement, the colonial population grew rapidly. Relatively small Native American populations were eclipsed.[76] The Christian revivalist movement of the 1730s and 1740s known as the Great Awakening fueled interest in both religion and religious liberty.[77]		During the Seven Years' War (in America, known as the French and Indian War), British forces seized Canada from the French, but the francophone population remained politically isolated from the southern colonies. Excluding the Native Americans, who were being conquered and displaced, the 13 British colonies had a population of over 2.1 million in 1770, about one-third that of Britain. Despite continuing new arrivals, the rate of natural increase was such that by the 1770s only a small minority of Americans had been born overseas.[78] The colonies' distance from Britain had allowed the development of self-government, but their success motivated monarchs to periodically seek to reassert royal authority.[79]		With the progress of European colonization in the territories of the contemporary United States, the Native Americans were often conquered and displaced.[80] The native population of America declined after Europeans arrived, and for various reasons, primarily diseases such as smallpox and measles. Violence was not a significant factor in the overall decline among Native Americans, though conflict among themselves and with Europeans affected specific tribes and various colonial settlements.[81][82][83][84][85][86]		In the early days of colonization, many European settlers were subject to food shortages, disease, and attacks from Native Americans. Native Americans were also often at war with neighboring tribes and allied with Europeans in their colonial wars. At the same time, however, many natives and settlers came to depend on each other. Settlers traded for food and animal pelts, natives for guns, ammunition and other European wares.[87] Natives taught many settlers where, when and how to cultivate corn, beans and squash. European missionaries and others felt it was important to "civilize" the Native Americans and urged them to adopt European agricultural techniques and lifestyles.[88][89]		The American Revolutionary War was the first successful colonial war of independence against a European power. Americans had developed an ideology of "republicanism" asserting that government rested on the will of the people as expressed in their local legislatures. They demanded their rights as Englishmen and "no taxation without representation". The British insisted on administering the empire through Parliament, and the conflict escalated into war.[90]		Following the passage of the Lee Resolution, on July 2, 1776, which was the actual vote for independence, the Second Continental Congress adopted the Declaration of Independence on July 4, which proclaimed, in a long preamble, that humanity is created equal in their unalienable rights and that those rights were not being protected by Great Britain, and declared, in the words of the resolution, that the Thirteen Colonies were independent states and had no allegiance to the British crown in the United States. The fourth day of July is celebrated annually as Independence Day. In 1777, the Articles of Confederation established a weak government that operated until 1789.[91]		Britain recognized the independence of the United States following their defeat at Yorktown in 1781.[92] In the peace treaty of 1783, American sovereignty was recognized from the Atlantic coast west to the Mississippi River. Nationalists led the Philadelphia Convention of 1787 in writing the United States Constitution, ratified in state conventions in 1788. The federal government was reorganized into three branches, on the principle of creating salutary checks and balances, in 1789. George Washington, who had led the revolutionary army to victory, was the first president elected under the new constitution. The Bill of Rights, forbidding federal restriction of personal freedoms and guaranteeing a range of legal protections, was adopted in 1791.[93]		Although the federal government criminalized the international slave trade in 1808, after 1820, cultivation of the highly profitable cotton crop exploded in the Deep South, and along with it, the slave population.[94][95][96] The Second Great Awakening, especially 1800–1840, converted millions to evangelical Protestantism. In the North, it energized multiple social reform movements, including abolitionism;[97] in the South, Methodists and Baptists proselytized among slave populations.[98]		Americans' eagerness to expand westward prompted a long series of American Indian Wars.[99] The Louisiana Purchase of French-claimed territory in 1803 almost doubled the nation's area.[100] The War of 1812, declared against Britain over various grievances and fought to a draw, strengthened U.S. nationalism.[101] A series of military incursions into Florida led Spain to cede it and other Gulf Coast territory in 1819.[102] Expansion was aided by steam power, when steamboats began traveling along America's large water systems, which were connected by new canals, such as the Erie and the I&M; then, even faster railroads began their stretch across the nation's land.[103]		From 1820 to 1850, Jacksonian democracy began a set of reforms which included wider white male suffrage; it led to the rise of the Second Party System of Democrats and Whigs as the dominant parties from 1828 to 1854. The Trail of Tears in the 1830s exemplified the Indian removal policy that resettled Indians into the west on Indian reservations. The U.S. annexed the Republic of Texas in 1845 during a period of expansionist Manifest destiny.[104] The 1846 Oregon Treaty with Britain led to U.S. control of the present-day American Northwest.[105] Victory in the Mexican–American War resulted in the 1848 Mexican Cession of California and much of the present-day American Southwest.[106]		The California Gold Rush of 1848–49 spurred western migration and the creation of additional western states.[107] After the American Civil War, new transcontinental railways made relocation easier for settlers, expanded internal trade and increased conflicts with Native Americans.[108] Over a half-century, the loss of the American bison (sometimes called "buffalo") was an existential blow to many Plains Indians cultures.[109] In 1869, a new Peace Policy sought to protect Native-Americans from abuses, avoid further war, and secure their eventual U.S. citizenship, although conflicts, including several of the largest Indian Wars, continued throughout the West into the 1900s.[110]		Differences of opinion and social order between northern and southern states in early United States society, particularly regarding Black slavery, ultimately led to the American Civil War.[111] Initially, states entering the Union alternated between slave and free states, keeping a sectional balance in the Senate, while free states outstripped slave states in population and in the House of Representatives. But with additional western territory and more free-soil states, tensions between slave and free states mounted with arguments over federalism and disposition of the territories, whether and how to expand or restrict slavery.[112]		With the 1860 election of Abraham Lincoln, the first president from the largely anti-slavery Republican Party, conventions in thirteen slave states ultimately declared secession and formed the Confederate States of America, while the federal government maintained that secession was illegal.[112] The ensuing war was at first for Union, then after 1863 as casualties mounted and Lincoln delivered his Emancipation Proclamation, a second war aim became abolition of slavery. The war remains the deadliest military conflict in American history, resulting in the deaths of approximately 618,000 soldiers as well as many civilians.[113]		Following the Union victory in 1865, three amendments were added to the U.S. Constitution: the Thirteenth Amendment prohibited slavery, the Fourteenth Amendment provided citizenship to the nearly four million African Americans who had been slaves,[114] and the Fifteenth Amendment ensured that they had the right to vote. The war and its resolution led to a substantial increase in federal power[115] aimed at reintegrating and rebuilding the Southern states while ensuring the rights of the newly freed slaves.		Southern white conservatives, calling themselves "Redeemers" took control after the end of Reconstruction. By the 1890–1910 period Jim Crow laws disenfranchised most blacks and some poor whites. Blacks faced racial segregation, especially in the South.[116] Racial minorities occasionally experienced vigilante violence.[117]		In the North, urbanization and an unprecedented influx of immigrants from Southern and Eastern Europe supplied a surplus of labor for the country's industrialization and transformed its culture.[118] National infrastructure including telegraph and transcontinental railroads spurred economic growth and greater settlement and development of the American Old West. The later invention of electric light and the telephone would also affect communication and urban life.[119]		The end of the Indian Wars further expanded acreage under mechanical cultivation, increasing surpluses for international markets.[120] Mainland expansion was completed by the purchase of Alaska from Russia in 1867.[121] In 1893, pro-American elements in Hawaii overthrew the monarchy and formed the Republic of Hawaii, which the U.S. annexed in 1898. Puerto Rico, Guam, and the Philippines were ceded by Spain in the same year, following the Spanish–American War.[122]		Rapid economic development during the late 19th and early 20th centuries fostered the rise of many prominent industrialists. Tycoons like Cornelius Vanderbilt, John D. Rockefeller, and Andrew Carnegie led the nation's progress in railroad, petroleum, and steel industries. Banking became a major part of the economy, with J. P. Morgan playing a notable role. Edison and Tesla undertook the widespread distribution of electricity to industry, homes, and for street lighting. Henry Ford revolutionized the automotive industry. The American economy boomed, becoming the world's largest, and the United States achieved great power status.[123] These dramatic changes were accompanied by social unrest and the rise of populist, socialist, and anarchist movements.[124] This period eventually ended with the advent of the Progressive Era, which saw significant reforms in many societal areas, including women's suffrage, alcohol prohibition, regulation of consumer goods, greater antitrust measures to ensure competition and attention to worker conditions.[125][126][127][128]		The United States remained neutral from the outbreak of World War I, in 1914, until 1917 when it joined the war as an "associated power", alongside the formal Allies of World War I, helping to turn the tide against the Central Powers. In 1919, President Woodrow Wilson took a leading diplomatic role at the Paris Peace Conference and advocated strongly for the U.S. to join the League of Nations. However, the Senate refused to approve this, and did not ratify the Treaty of Versailles that established the League of Nations.[129]		In 1920, the women's rights movement won passage of a constitutional amendment granting women's suffrage.[130] The 1920s and 1930s saw the rise of radio for mass communication and the invention of early television.[131] The prosperity of the Roaring Twenties ended with the Wall Street Crash of 1929 and the onset of the Great Depression. After his election as president in 1932, Franklin D. Roosevelt responded with the New Deal, which included the establishment of the Social Security system.[132] The Great Migration of millions of African Americans out of the American South began before World War I and extended through the 1960s;[133] whereas the Dust Bowl of the mid-1930s impoverished many farming communities and spurred a new wave of western migration.[134]		At first effectively neutral during World War II while Germany conquered much of continental Europe, the United States began supplying material to the Allies in March 1941 through the Lend-Lease program. On December 7, 1941, the Empire of Japan launched a surprise attack on Pearl Harbor, prompting the United States to join the Allies against the Axis powers.[135] During the war, the United States was referred as one of the "Four Policemen"[136] of Allies power who met to plan the postwar world, along with Britain, the Soviet Union and China.[137][138] Though the nation lost more than 400,000 soldiers,[139] it emerged relatively undamaged from the war with even greater economic and military influence.[140]		The United States played a leading role in the Bretton Woods and Yalta conferences with the United Kingdom, the Soviet Union and other Allies, which signed agreements on new international financial institutions and Europe's postwar reorganization. As an Allied victory was won in Europe, a 1945 international conference held in San Francisco produced the United Nations Charter, which became active after the war.[141] The United States developed the first nuclear weapons and used them on Japan in the cities of Hiroshima and Nagasaki; causing the Japanese to surrender on September 2, ending World War II.[142][143] Parades and celebrations followed in what is known as Victory Day, or V-J Day.[144]		After World War II the United States and the Soviet Union jockeyed for power during what became known as the Cold War, driven by an ideological divide between capitalism and communism[145] and, according to the school of geopolitics, a divide between the maritime Atlantic and the continental Eurasian camps. They dominated the military affairs of Europe, with the U.S. and its NATO allies on one side and the USSR and its Warsaw Pact allies on the other. The U.S. developed a policy of containment towards the expansion of communist influence. While the U.S. and Soviet Union engaged in proxy wars and developed powerful nuclear arsenals, the two countries avoided direct military conflict.		The United States often opposed Third World movements that it viewed as Soviet-sponsored. American troops fought communist Chinese and North Korean forces in the Korean War of 1950–53.[146] The Soviet Union's 1957 launch of the first artificial satellite and its 1961 launch of the first manned spaceflight initiated a "Space Race" in which the United States became the first nation to land a man on the moon in 1969.[146] A proxy war in Southeast Asia eventually evolved into full American participation, as the Vietnam War.		At home, the U.S. experienced sustained economic expansion and a rapid growth of its population and middle class. Construction of an Interstate Highway System transformed the nation's infrastructure over the following decades. Millions moved from farms and inner cities to large suburban housing developments.[147][148] In 1959 Hawaii became the 50th and last U.S. state added to the country.[149] The growing Civil Rights Movement used nonviolence to confront segregation and discrimination, with Martin Luther King Jr. becoming a prominent leader and figurehead. A combination of court decisions and legislation, culminating in the Civil Rights Act of 1968, sought to end racial discrimination.[150][151][152] Meanwhile, a counterculture movement grew which was fueled by opposition to the Vietnam war, black nationalism, and the sexual revolution.		The launch of a "War on Poverty" expanded entitlements and welfare spending, including the creation of Medicare and Medicaid, two programs that provide health coverage to the elderly and poor, respectively, and the means-tested Food Stamp Program and Aid to Families with Dependent Children.[153]		The 1970s and early 1980s saw the onset of stagflation. After his election in 1980, President Ronald Reagan responded to economic stagnation with free-market oriented reforms. Following the collapse of détente, he abandoned "containment" and initiated the more aggressive "rollback" strategy towards the USSR.[154][155][156][157][158] After a surge in female labor participation over the previous decade, by 1985 the majority of women aged 16 and over were employed.[159]		The late 1980s brought a "thaw" in relations with the USSR, and its collapse in 1991 finally ended the Cold War.[160][161][162][163] This brought about unipolarity[164] with the U.S. unchallenged as the world's dominant superpower. The concept of Pax Americana, which had appeared in the post-World War II period, gained wide popularity as a term for the post-Cold War new world order.		After the Cold War, the conflict in the Middle East triggered a crisis in 1990, when Iraq under Sadaam Hussein invaded and attempted to annex Kuwait, an ally of the United States. Fearing that the instability would spread to other regions, President George H.W. Bush launched Operation Desert Shield, a defensive force buildup in Saudi Arabia, and Operation Desert Storm, in a staging titled the Gulf War; waged by coalition forces from 34 nations, led by the United States against Iraq ending in the successful expulsion of Iraqi forces from Kuwait, restoring the former monarchy.[165]		Originating in U.S. defense networks, the Internet spread to international academic networks, and then to the public in the 1990s, greatly affecting the global economy, society, and culture.[166]		Due to the dot-com boom, stable monetary policy under Alan Greenspan, and reduced social welfare spending, the 1990s saw the longest economic expansion in modern U.S. history, ending in 2001.[167] Beginning in 1994, the U.S. entered into the North American Free Trade Agreement (NAFTA), linking 450 million people producing $17 trillion worth of goods and services. The goal of the agreement was to eliminate trade and investment barriers among the U.S., Canada, and Mexico by January 1, 2008. Trade among the three partners has soared since NAFTA went into force.[168]		On September 11, 2001, Al-Qaeda terrorists struck the World Trade Center in New York City and the Pentagon near Washington, D.C., killing nearly 3,000 people.[169] In response, the United States launched the War on Terror, which included war in Afghanistan and the 2003–11 Iraq War.[170][171] In 2007, the Bush administration ordered a major troop surge in the Iraq War,[172] which successfully reduced violence and led to greater stability in the region.[173][174]		Government policy designed to promote affordable housing,[175] widespread failures in corporate and regulatory governance,[176] and historically low interest rates set by the Federal Reserve[177] led to the mid-2000s housing bubble, which culminated with the 2008 financial crisis, the largest economic contraction in the nation's history since the Great Depression.[178] Barack Obama, the first African American[179] and multiracial[180] president, was elected in 2008 amid the crisis,[181] and subsequently passed stimulus measures and the Dodd-Frank Wall Street Reform and Consumer Protection Act in an attempt to mitigate its negative effects. While the stimulus facilitated infrastructure improvements[182] and a relative decline in unemployment,[183] Dodd-Frank has had a negative impact on business investment and small banks.[184]		In 2010, the Obama administration passed the Affordable Care Act, which made the most sweeping reforms to the nation's healthcare system in nearly five decades, including mandates, subsidies and insurance exchanges. The law caused a significant reduction in the number and percentage of people without health insurance, with 24 million covered during 2016,[185] but remains controversial due to its impact on healthcare costs, insurance premiums, and economic performance.[186] Although the recession reached its trough in June 2009, voters remained frustrated with the slow pace of the economic recovery. The Republicans, who stood in opposition to Obama's policies, won control of the House of Representatives with a landslide in 2010 and control of the Senate in 2014.[187]		American forces in Iraq were withdrawn in large numbers in 2009 and 2010, and the war in the region was declared formally over in December 2011.[188] The withdrawal caused an escalation of sectarian insurgency,[189] leading to the rise of the Islamic State of Iraq and the Levant, the successor of al-Qaeda in the region.[190] In 2014, Obama announced a restoration of full diplomatic relations with Cuba for the first time since 1961.[needs update][191] The next year, the United States as a member of the P5+1 countries signed the Joint Comprehensive Plan of Action, an agreement aimed to slow the development of Iran's nuclear program.[192]		The land area of the contiguous United States is 2,959,064 square miles (7,663,940.6 km2). Alaska, separated from the contiguous United States by Canada, is the largest state at 663,268 square miles (1,717,856.2 km2). Hawaii, occupying an archipelago in the central Pacific, southwest of North America, is 10,931 square miles (28,311 km2) in area. The populated territories of Puerto Rico, American Samoa, Guam, Northern Mariana Islands, and U.S. Virgin Islands together cover 9,185 square miles (23,789 km2).[193]		The United States is the world's third- or fourth-largest nation by total area (land and water), ranking behind Russia and Canada and just above or below China. The ranking varies depending on how two territories disputed by China and India are counted and how the total size of the United States is measured: calculations range from 3,676,486 square miles (9,522,055.0 km2)[194] to 3,717,813 square miles (9,629,091.5 km2)[195] to 3,796,742 square miles (9,833,516.6 km2)[10] to 3,805,927 square miles (9,857,306 km2).[11] Measured by only land area, the United States is third in size behind Russia and China, just ahead of Canada.[196]		The coastal plain of the Atlantic seaboard gives way further inland to deciduous forests and the rolling hills of the Piedmont.[197] The Appalachian Mountains divide the eastern seaboard from the Great Lakes and the grasslands of the Midwest.[198] The Mississippi–Missouri River, the world's fourth longest river system, runs mainly north–south through the heart of the country. The flat, fertile prairie of the Great Plains stretches to the west, interrupted by a highland region in the southeast.[198]		The Rocky Mountains, at the western edge of the Great Plains, extend north to south across the country, reaching altitudes higher than 14,000 feet (4,300 m) in Colorado.[199] Farther west are the rocky Great Basin and deserts such as the Chihuahua and Mojave.[200] The Sierra Nevada and Cascade mountain ranges run close to the Pacific coast, both ranges reaching altitudes higher than 14,000 feet (4,300 m). The lowest and highest points in the contiguous United States are in the state of California,[201] and only about 84 miles (135 km) apart.[202] At an elevation of 20,310 feet (6,190.5 m), Alaska's Denali (Mount McKinley) is the highest peak in the country and North America.[203] Active volcanoes are common throughout Alaska's Alexander and Aleutian Islands, and Hawaii consists of volcanic islands. The supervolcano underlying Yellowstone National Park in the Rockies is the continent's largest volcanic feature.[204]		The United States, with its large size and geographic variety, includes most climate types. To the east of the 100th meridian, the climate ranges from humid continental in the north to humid subtropical in the south.[205] The Great Plains west of the 100th meridian are semi-arid. Much of the Western mountains have an alpine climate. The climate is arid in the Great Basin, desert in the Southwest, Mediterranean in coastal California, and oceanic in coastal Oregon and Washington and southern Alaska. Most of Alaska is subarctic or polar. Hawaii and the southern tip of Florida are tropical, as are the populated territories in the Caribbean and the Pacific.[206] Extreme weather is not uncommon—the states bordering the Gulf of Mexico are prone to hurricanes, and most of the world's tornadoes occur within the country, mainly in Tornado Alley areas in the Midwest and South.[207]		The U.S. ecology is megadiverse: about 17,000 species of vascular plants occur in the contiguous United States and Alaska, and over 1,800 species of flowering plants are found in Hawaii, few of which occur on the mainland.[209] The United States is home to 428 mammal species, 784 bird species, 311 reptile species, and 295 amphibian species.[210] About 91,000 insect species have been described.[211] The bald eagle is both the national bird and national animal of the United States, and is an enduring symbol of the country itself.[212]		There are 59 national parks and hundreds of other federally managed parks, forests, and wilderness areas.[213] Altogether, the government owns about 28% of the country's land area.[214] Most of this is protected, though some is leased for oil and gas drilling, mining, logging, or cattle ranching; about .86% is used for military purposes.[215][216]		Environmental issues have been on the national agenda since 1970. Environmental controversies include debates on oil and nuclear energy, dealing with air and water pollution, the economic costs of protecting wildlife, logging and deforestation,[217][218] and international responses to global warming.[219][220] Many federal and state agencies are involved. The most prominent is the Environmental Protection Agency (EPA), created by presidential order in 1970.[221] The idea of wilderness has shaped the management of public lands since 1964, with the Wilderness Act.[222] The Endangered Species Act of 1973 is intended to protect threatened and endangered species and their habitats, which are monitored by the United States Fish and Wildlife Service.[223]		The U.S. Census Bureau estimated the country's population to be 323,425,550 as of April 25, 2016, and to be adding 1 person (net gain) every 13 seconds, or about 6,646 people per day.[228] The U.S. population almost quadrupled during the 20th century, from about 76 million in 1900.[229] The third most populous nation in the world, after China and India, the United States is the only major industrialized nation in which large population increases are projected.[230] In the 1800s the average woman had 7.04 children, by the 1900s this number had decreased to 3.56.[231] Since the early 1970s the birth rate has been below the replacement rate of 2.1 with 1.86 children per woman in 2014. Foreign born immigration has caused the US population to continue its rapid increase with the foreign born population doubling from almost 20 million in 1990 to over 40 million in 2010, representing one third of the population increase.[232] The foreign born population reached 45 million in 2015.[233][fn 8]		The United States has a birth rate of 13 per 1,000, which is 5 births below the world average.[237] Its population growth rate is positive at 0.7%, higher than that of many developed nations.[238] In fiscal year 2012, over one million immigrants (most of whom entered through family reunification) were granted legal residence.[239] Mexico has been the leading source of new residents since the 1965 Immigration Act. China, India, and the Philippines have been in the top four sending countries every year since the 1990s.[240] As of 2012[update], approximately 11.4 million residents are illegal immigrants.[241] As of 2015, 47% of all immigrants are Hispanic, 26% are Asian, 18% are white and 8% are black. The percentage of immigrants who are Asian is increasing while the percentage who are Hispanic is decreasing.[233]		According to a survey conducted by the Williams Institute, nine million Americans, or roughly 3.4% of the adult population identify themselves as homosexual, bisexual, or transgender.[242][243] A 2016 Gallup poll also concluded that 4.1% of adult Americans identified as LGBT. The highest percentage came from the District of Columbia (10%), while the lowest state was North Dakota at 1.7%.[244] In a 2013 survey, the Centers for Disease Control and Prevention found that 96.6% of Americans identify as straight, while 1.6% identify as gay or lesbian, and 0.7% identify as being bisexual.[245]		In 2010, the U.S. population included an estimated 5.2 million people with some American Indian or Alaska Native ancestry (2.9 million exclusively of such ancestry) and 1.2 million with some native Hawaiian or Pacific island ancestry (0.5 million exclusively).[246] The census counted more than 19 million people of "Some Other Race" who were "unable to identify with any" of its five official race categories in 2010, over 18.5 million (97%) of whom are of Hispanic ethnicity.[246]		The population growth of Hispanic and Latino Americans (the terms are officially interchangeable) is a major demographic trend. The 50.5 million Americans of Hispanic descent[246] are identified as sharing a distinct "ethnicity" by the Census Bureau; 64% of Hispanic Americans are of Mexican descent.[247] Between 2000 and 2010, the country's Hispanic population increased 43% while the non-Hispanic population rose just 4.9%.[248] Much of this growth is from immigration; in 2007, 12.6% of the U.S. population was foreign-born, with 54% of that figure born in Latin America.[249][fn 9]		About 82% of Americans live in urban areas (including suburbs);[10] about half of those reside in cities with populations over 50,000.[255] The US has numerous clusters of cities known as megaregions, the largest being the Great Lakes Megalopolis followed by the Northeast Megalopolis and Southern California. In 2008, 273 incorporated municipalities had populations over 100,000, nine cities had more than one million residents, and four global cities had over two million (New York, Los Angeles, Chicago, and Houston).[256] There are 52 metropolitan areas with populations greater than one million.[257] Of the 50 fastest-growing metro areas, 47 are in the West or South.[258] The metro areas of San Bernardino, Dallas, Houston, Atlanta, and Phoenix all grew by more than a million people between 2000 and 2008.[257]				English (American English) is the de facto national language. Although there is no official language at the federal level, some laws—such as U.S. naturalization requirements—standardize English. In 2010, about 230 million, or 80% of the population aged five years and older, spoke only English at home. Spanish, spoken by 12% of the population at home, is the second most common language and the most widely taught second language.[261][262] Some Americans advocate making English the country's official language, as it is in 32 states.[263]		Both Hawaiian and English are official languages in Hawaii, by state law.[264] Alaska recognizes twenty Native languages as well as English.[265] While neither has an official language, New Mexico has laws providing for the use of both English and Spanish, as Louisiana does for English and French.[266] Other states, such as California, mandate the publication of Spanish versions of certain government documents including court forms.[267] Many jurisdictions with large numbers of non-English speakers produce government materials, especially voting information, in the most commonly spoken languages in those jurisdictions.		Several insular territories grant official recognition to their native languages, along with English: Samoan[268] and Chamorro[269] are recognized by American Samoa and Guam, respectively; Carolinian and Chamorro are recognized by the Northern Mariana Islands;[270] Cherokee is officially recognized by the Cherokee Nation within the Cherokee tribal jurisdiction area in eastern Oklahoma;[271] Spanish is an official language of Puerto Rico and is more widely spoken than English there.[272]		The most widely taught foreign languages in the United States, in terms of enrollment numbers from kindergarten through university undergraduate studies, are: Spanish (around 7.2 million students), French (1.5 million), and German (500,000). Other commonly taught languages (with 100,000 to 250,000 learners) include Latin, Japanese, ASL, Italian, and Chinese.[273][274] 18% of all Americans claim to speak at least one language in addition to English.[275]		The First Amendment of the U.S. Constitution guarantees the free exercise of religion and forbids Congress from passing laws respecting its establishment.		Christianity is by far the most common religion practiced in the U.S., but other religions are followed, too. In a 2013 survey, 56% of Americans said that religion played a "very important role in their lives", a far higher figure than that of any other wealthy nation.[278] In a 2009 Gallup poll, 42% of Americans said that they attended church weekly or almost weekly; the figures ranged from a low of 23% in Vermont to a high of 63% in Mississippi.[279] Experts, researchers and authors have referred to the United States as a "Protestant nation" or "founded on Protestant principles,"[280][281][282][283] specifically emphasizing its Calvinist heritage.[284][285][286]		As with other Western countries, the U.S. is becoming less religious. Irreligion is growing rapidly among Americans under 30.[287] Polls show that overall American confidence in organized religion has been declining since the mid to late 1980s,[288] and that younger Americans in particular are becoming increasingly irreligious.[9][289] According to a 2012 study, the Protestant share of the U.S. population had dropped to 48%, thus ending its status as religious category of the majority for the first time.[290][291] Americans with no religion have 1.7 children compared to 2.2 among Christians. The unaffiliated are less likely to get married with 37% marrying compared to 52% of Christians.[292]		According to a 2014 survey, 70.6% of adults identified themselves as Christian,[293] Protestant denominations accounted for 46.5%, while Roman Catholicism, at 20.8%, was the largest individual denomination.[294] The total reporting non-Christian religions in 2014 was 5.9%.[294] Other religions include Judaism (1.9%), Islam (0.9%), Buddhism (0.7%), Hinduism (0.7%).[294] The survey also reported that 22.8% of Americans described themselves as agnostic, atheist or simply having no religion, up from 8.2% in 1990.[294][295][296] There are also Unitarian Universalist, Baha'i, Sikh, Jain, Shinto, Confucian, Taoist, Druid, Native American, Wiccan, humanist and deist communities.[297]		Protestantism is the largest Christian religious grouping in the United States. Baptists collectively form the largest branch of Protestantism, and the Southern Baptist Convention is the largest individual Protestant denomination. About 26% of Americans identify as Evangelical Protestants, while 15% are Mainline and 7% belong to a traditionally Black church. Roman Catholicism in the United States has its origin in the Spanish and French colonization of the Americas, and later grew because of Irish, Italian, Polish, German and Hispanic immigration. Rhode Island has the highest percentage of Catholics with 40 percent of the total population.[298] Lutheranism in the U.S. has its origin in immigration from Northern Europe and Germany. North and South Dakota are the only states in which a plurality of the population is Lutheran. Presbyterianism was introduced in North America by Scottish and Ulster Scots immigrants. Although it has spread across the United States, it is heavily concentrated on the East Coast. Dutch Reformed congregations were founded first in New Amsterdam (New York City) before spreading westward. Utah is the only state where Mormonism is the religion of the majority of the population. The Mormon Corridor also extends to parts of Idaho, Nevada and Wyoming.[299]		The Bible Belt is an informal term for a region in the Southern United States in which socially conservative Evangelical Protestantism is a significant part of the culture and Christian church attendance across the denominations is generally higher than the nation's average. By contrast, religion plays the least important role in New England and in the Western United States.[279]		As of 2007[update], 58% of Americans age 18 and over were married, 6% were widowed, 10% were divorced, and 25% had never been married.[300] Women now work mostly outside the home and receive a majority of bachelor's degrees.[301]		The U.S. teenage pregnancy rate is 26.5 per 1,000 women. The rate has declined by 57% since 1991.[302] In 2013, the highest teenage birth rate was in Alabama, and the lowest in Wyoming.[302][303] Abortion is legal throughout the U.S., owing to Roe v. Wade, a 1973 landmark decision by the Supreme Court of the United States. While the abortion rate is falling, the abortion ratio of 241 per 1,000 live births and abortion rate of 15 per 1,000 women aged 15–44 remain higher than those of most Western nations.[304] In 2013, the average age at first birth was 26 and 40.6% of births were to unmarried women.[305]		The total fertility rate (TFR) was estimated for 2013 at 1.86 births per woman.[306] Adoption in the United States is common and relatively easy from a legal point of view (compared to other Western countries).[307] In 2001, with over 127,000 adoptions, the U.S. accounted for nearly half of the total number of adoptions worldwide.[308] Same-sex marriage is legal nationwide and it is legal for same-sex couples to adopt. Polygamy is illegal throughout the U.S.[309]		The United States is the world's oldest surviving federation. It is a representative democracy, "in which majority rule is tempered by minority rights protected by law".[310] The government is regulated by a system of checks and balances defined by the U.S. Constitution, which serves as the country's supreme legal document.[311] For 2016, the U.S. ranked 21st on the Democracy Index[312] (tied with Italy) and 18th on the Corruption Perceptions Index.[313]		In the American federalist system, citizens are usually subject to three levels of government: federal, state, and local. The local government's duties are commonly split between county and municipal governments. In almost all cases, executive and legislative officials are elected by a plurality vote of citizens by district. There is no proportional representation at the federal level, and it is rare at lower levels.[314]		The federal government is composed of three branches:		The House of Representatives has 435 voting members, each representing a congressional district for a two-year term. House seats are apportioned among the states by population every tenth year. At the 2010 census, seven states had the minimum of one representative, while California, the most populous state, had 53.[319]		The Senate has 100 members with each state having two senators, elected at-large to six-year terms; one third of Senate seats are up for election every other year. The President serves a four-year term and may be elected to the office no more than twice. The President is not elected by direct vote, but by an indirect electoral college system in which the determining votes are apportioned to the states and the District of Columbia.[320] The Supreme Court, led by the Chief Justice of the United States, has nine members, who serve for life.[321]		The state governments are structured in roughly similar fashion; Nebraska uniquely has a unicameral legislature.[323] The governor (chief executive) of each state is directly elected. Some state judges and cabinet officers are appointed by the governors of the respective states, while others are elected by popular vote.		The original text of the Constitution establishes the structure and responsibilities of the federal government and its relationship with the individual states. Article One protects the right to the "great writ" of habeas corpus. The Constitution has been amended 27 times;[324] the first ten amendments, which make up the Bill of Rights, and the Fourteenth Amendment form the central basis of Americans' individual rights. All laws and governmental procedures are subject to judicial review and any law ruled by the courts to be in violation of the Constitution is voided. The principle of judicial review, not explicitly mentioned in the Constitution, was established by the Supreme Court in Marbury v. Madison (1803)[325] in a decision handed down by Chief Justice John Marshall.[326]		The United States is a federal republic of 50 states, a federal district, five territories and eleven uninhabited island possessions.[328] The states and territories are the principal administrative districts in the country. These are divided into subdivisions of counties and independent cities. The District of Columbia is a federal district that contains the capital of the United States, Washington DC.[329] The states and the District of Columbia choose the President of the United States. Each state has presidential electors equal to the number of their Representatives and Senators in Congress; the District of Columbia has three.[330]		Congressional Districts are reapportioned among the states following each decennial Census of Population. Each state then draws single member districts to conform with the census apportionment. The total number of Representatives is 435, and delegate Members of Congress represent the District of Columbia and the five major U.S. territories.[331]		The United States also observes tribal sovereignty of the American Indian nations to a limited degree, as it does with the states' sovereignty. American Indians are U.S. citizens and tribal lands are subject to the jurisdiction of the U.S. Congress and the federal courts. Like the states they have a great deal of autonomy, but also like the states tribes are not allowed to make war, engage in their own foreign relations, or print and issue currency.[332]		The United States has operated under a two-party system for most of its history.[334] For elective offices at most levels, state-administered primary elections choose the major party nominees for subsequent general elections. Since the general election of 1856, the major parties have been the Democratic Party, founded in 1824, and the Republican Party, founded in 1854. Since the Civil War, only one third-party presidential candidate—former president Theodore Roosevelt, running as a Progressive in 1912—has won as much as 20% of the popular vote. The President and Vice-president are elected through the Electoral College system.[335]		Within American political culture, the center-right Republican Party is considered "conservative" and the center-left Democratic Party is considered "liberal".[336][337] The states of the Northeast and West Coast and some of the Great Lakes states, known as "blue states", are relatively liberal. The "red states" of the South and parts of the Great Plains and Rocky Mountains are relatively conservative.		Republican Donald Trump, the winner of the 2016 presidential election, is currently serving as the 45th President of the United States.[338] Current leadership in the Senate includes Republican Vice President Mike Pence, Republican President Pro Tempore Orrin Hatch, Majority Leader Mitch McConnell, and Minority Leader Chuck Schumer.[339] Leadership in the House includes Speaker of the House Paul Ryan, Majority Leader Kevin McCarthy, and Minority Leader Nancy Pelosi.[340]		In the 115th United States Congress, both the House of Representatives and the Senate are controlled by the Republican Party. The Senate currently consists of 52 Republicans, and 46 Democrats with 2 Independents who caucus with the Democrats; the House consists of 241 Republicans and 194 Democrats.[341] In state governorships, there are 33 Republicans, 16 Democrats, and 1 Independent.[342] Among the DC mayor and the 5 territorial governors, there are 2 Republicans, 1 Democrat, 1 New Progressive, and 2 Independents.[343]		The United States has an established structure of foreign relations. It is a permanent member of the United Nations Security Council, and New York City is home to the United Nations Headquarters. It is a member of the G7,[345] G20, and Organisation for Economic Co-operation and Development. Almost all countries have embassies in Washington, D.C., and many have consulates around the country. Likewise, nearly all nations host American diplomatic missions. However, Iran, North Korea, Bhutan, and the Republic of China (Taiwan) do not have formal diplomatic relations with the United States (although the U.S. still maintains relations with Taiwan and supplies it with military equipment).[346]		The United States has a "Special Relationship" with the United Kingdom[347] and strong ties with Canada,[348] Australia,[349] New Zealand,[350] the Philippines,[351] Japan,[352] South Korea,[353] Israel,[354] and several European Union countries, including France, Italy, Germany, and Spain. It works closely with fellow NATO members on military and security issues and with its neighbors through the Organization of American States and free trade agreements such as the trilateral North American Free Trade Agreement with Canada and Mexico. In 2008, the United States spent a net $25.4 billion on official development assistance, the most in the world. As a share of America's large gross national income (GNI), however, the U.S. contribution of 0.18% ranked last among 22 donor states. By contrast, private overseas giving by Americans is relatively generous.[355]		The U.S. exercises full international defense authority and responsibility for three sovereign nations through Compact of Free Association with Micronesia, the Marshall Islands and Palau. These are Pacific island nations, once part of the U.S.-administered Trust Territory of the Pacific Islands after World War II, which gained independence in subsequent years.[356]		Taxes in the United States are levied at the federal, state, and local government levels. These include taxes on income, payroll, property, sales, imports, estates and gifts, as well as various fees. In 2010 taxes collected by federal, state and municipal governments amounted to 24.8% of GDP.[358] During FY2012, the federal government collected approximately $2.45 trillion in tax revenue, up $147 billion or 6% versus FY2011 revenues of $2.30 trillion. Primary receipt categories included individual income taxes ($1,132B or 47%), Social Security/Social Insurance taxes ($845B or 35%), and corporate taxes ($242B or 10%).[359] Based on CBO estimates,[360] under 2013 tax law the top 1% will be paying the highest average tax rates since 1979, while other income groups will remain at historic lows.[361]		U.S. taxation is generally progressive, especially the federal income taxes, and is among the most progressive in the developed world.[362][363][364][365][366] The highest 10% of income earners pay a majority of federal taxes,[367] and about half of all taxes.[368] Payroll taxes for Social Security are a flat regressive tax, with no tax charged on income above $118,500 (for 2015 and 2016) and no tax at all paid on unearned income from things such as stocks and capital gains.[369][370] The historic reasoning for the regressive nature of the payroll tax is that entitlement programs have not been viewed as welfare transfers.[371][372] However, according to the Congressional Budget Office the net effect of Social Security is that the benefit to tax ratio ranges from roughly 70% for the top earnings quintile to about 170% for the lowest earning quintile, making the system progressive.[373]		The top 10% paid 51.8% of total federal taxes in 2009, and the top 1%, with 13.4% of pre-tax national income, paid 22.3% of federal taxes.[374] In 2013 the Tax Policy Center projected total federal effective tax rates of 35.5% for the top 1%, 27.2% for the top quintile, 13.8% for the middle quintile, and −2.7% for the bottom quintile.[375][376] The incidence of corporate income tax has been a matter of considerable ongoing controversy for decades.[365][377] State and local taxes vary widely, but are generally less progressive than federal taxes as they rely heavily on broadly borne regressive sales and property taxes that yield less volatile revenue streams, though their consideration does not eliminate the progressive nature of overall taxation.[365][378]		During FY 2012, the federal government spent $3.54 trillion on a budget or cash basis, down $60 billion or 1.7% vs. FY 2011 spending of $3.60 trillion. Major categories of FY 2012 spending included: Medicare & Medicaid ($802B or 23% of spending), Social Security ($768B or 22%), Defense Department ($670B or 19%), non-defense discretionary ($615B or 17%), other mandatory ($461B or 13%) and interest ($223B or 6%).[359]		The total national debt of the United States in the United States was $18.527 trillion (106% of the GDP) in 2014.[379][fn 11]		The President holds the title of commander-in-chief of the nation's armed forces and appoints its leaders, the Secretary of Defense and the Joint Chiefs of Staff. The United States Department of Defense administers the armed forces, including the Army, Marine Corps, Navy, and Air Force. The Coast Guard is run by the Department of Homeland Security in peacetime and by the Department of the Navy during times of war. In 2008, the armed forces had 1.4 million personnel on active duty. The Reserves and National Guard brought the total number of troops to 2.3 million. The Department of Defense also employed about 700,000 civilians, not including contractors.[384]		Military service is voluntary, though conscription may occur in wartime through the Selective Service System.[385] American forces can be rapidly deployed by the Air Force's large fleet of transport aircraft, the Navy's 10 active aircraft carriers, and Marine expeditionary units at sea with the Navy's Atlantic and Pacific fleets. The military operates 865 bases and facilities abroad,[386] and maintains deployments greater than 100 active duty personnel in 25 foreign countries.[387]		The military budget of the United States in 2011 was more than $700 billion, 41% of global military spending and equal to the next 14 largest national military expenditures combined. At 4.7% of GDP, the rate was the second-highest among the top 15 military spenders, after Saudi Arabia.[388] U.S. defense spending as a percentage of GDP ranked 23rd globally in 2012 according to the CIA.[389] Defense's share of U.S. spending has generally declined in recent decades, from Cold War peaks of 14.2% of GDP in 1953 and 69.5% of federal outlays in 1954 to 4.7% of GDP and 18.8% of federal outlays in 2011.[390]		The proposed base Department of Defense budget for 2012, $553 billion, was a 4.2% increase over 2011; an additional $118 billion was proposed for the military campaigns in Iraq and Afghanistan.[391] The last American troops serving in Iraq departed in December 2011;[392] 4,484 service members were killed during the Iraq War.[393] Approximately 90,000 U.S. troops were serving in Afghanistan in April 2012;[394] by November 8, 2013 2,285 had been killed during the War in Afghanistan.[395]		Law enforcement in the United States is primarily the responsibility of local police and sheriff's departments, with state police providing broader services. The New York City Police Department (NYPD) is the largest in the country. Federal agencies such as the Federal Bureau of Investigation (FBI) and the U.S. Marshals Service have specialized duties, including protecting civil rights, national security and enforcing U.S. federal courts' rulings and federal laws.[397] At the federal level and in almost every state, a legal system operates on a common law. State courts conduct most criminal trials; federal courts handle certain designated crimes as well as certain appeals from the state criminal courts. Plea bargaining in the United States is very common; the vast majority of criminal cases in the country are settled by plea bargain rather than jury trial.[398]		In 2015, there were 15,696 murders which was 1,532 more than in 2014, a 10.8 per cent increase, the largest since 1971.[399] The murder rate in 2015 was 4.9 per 100,000 people.[400] The national clearance rate for homicides in 2015 was 64.1%, compared to 90% in 1965.[401] In 2012 there were 4.7 murders per 100,000 persons in the United States, a 54% decline from the modern peak of 10.2 in 1980.[402] In 2001–2, the United States had above-average levels of violent crime and particularly high levels of gun violence compared to other developed nations.[403] A cross-sectional analysis of the World Health Organization Mortality Database from 2010 showed that United States "homicide rates were 7.0 times higher than in other high-income countries, driven by a gun homicide rate that was 25.2 times higher."[404] Gun ownership rights continue to be the subject of contentious political debate.		From 1980 through 2008 males represented 77% of homicide victims and 90% of offenders. Blacks committed 52.5% of all homicides during that span, at a rate almost eight times that of whites ("whites" includes most Hispanics), and were victimized at a rate six times that of whites. Most homicides were intraracial, with 93% of black victims killed by blacks and 84% of white victims killed by whites.[405] In 2012, Louisiana had the highest rate of murder and non-negligent manslaughter in the U.S., and New Hampshire the lowest.[406] The FBI's Uniform Crime Reports estimates that there were 3,246 violent and property crimes per 100,000 residents in 2012, for a total of over 9 million total crimes.[407]		Capital punishment is sanctioned in the United States for certain federal and military crimes, and used in 31 states.[408][409] No executions took place from 1967 to 1977, owing in part to a U.S. Supreme Court ruling striking down arbitrary imposition of the death penalty. In 1976, that Court ruled that, under appropriate circumstances, capital punishment may constitutionally be imposed. Since the decision there have been more than 1,300 executions, a majority of these taking place in three states: Texas, Virginia, and Oklahoma.[410] Meanwhile, several states have either abolished or struck down death penalty laws. In 2015, the country had the fifth-highest number of executions in the world, following China, Iran, Pakistan and Saudi Arabia.[411]		The United States has the highest documented incarceration rate and total prison population in the world.[412] At the start of 2008, more than 2.3 million people were incarcerated, more than one in every 100 adults.[413] In December 2012, the combined U.S. adult correctional systems supervised about 6,937,600 offenders. About 1 in every 35 adult residents in the United States was under some form of correctional supervision in December 2012, the lowest rate observed since 1997.[414] The prison population has quadrupled since 1980,[415] and state and local spending on prisons and jails has grown three times as much as that spent on public education during the same period.[416] However, the imprisonment rate for all prisoners sentenced to more than a year in state or federal facilities is 478 per 100,000 in 2013[417] and the rate for pre-trial/remand prisoners is 153 per 100,000 residents in 2012.[418] The country's high rate of incarceration is largely due to changes in sentencing guidelines and drug policies.[419] According to the Federal Bureau of Prisons, the majority of inmates held in federal prisons are convicted of drug offenses.[420] The privatization of prisons and prison services which began in the 1980s has been a subject of debate.[421][422] In 2008, Louisiana had the highest incarceration rate,[423] and Maine the lowest.[424]		The United States has a capitalist mixed economy[433] which is fueled by abundant natural resources and high productivity.[434] According to the International Monetary Fund, the U.S. GDP of $16.8 trillion constitutes 24% of the gross world product at market exchange rates and over 19% of the gross world product at purchasing power parity (PPP).[435]		The US's nominal GDP is estimated to be $17.528 trillion as of 2014[update][436] From 1983 to 2008, U.S. real compounded annual GDP growth was 3.3%, compared to a 2.3% weighted average for the rest of the G7.[437] The country ranks ninth in the world in nominal GDP per capita and sixth in GDP per capita at PPP.[435] The U.S. dollar is the world's primary reserve currency.[438]		The United States is the largest importer of goods and second-largest exporter, though exports per capita are relatively low. In 2010, the total U.S. trade deficit was $635 billion.[439] Canada, China, Mexico, Japan, and Germany are its top trading partners.[440] In 2010, oil was the largest import commodity, while transportation equipment was the country's largest export.[439] Japan is the largest foreign holder of U.S. public debt.[441] The largest holder of the U.S. debt are American entities, including federal government accounts and the Federal Reserve, who hold the majority of the debt.[442][443][444][445][fn 12]		In 2009, the private sector was estimated to constitute 86.4% of the economy, with federal government activity accounting for 4.3% and state and local government activity (including federal transfers) the remaining 9.3%.[448] The number of employees at all levels of government outnumber those in manufacturing by 1.7 to 1.[449] While its economy has reached a postindustrial level of development and its service sector constitutes 67.8% of GDP, the United States remains an industrial power.[450] The leading business field by gross business receipts is wholesale and retail trade; by net income it is manufacturing.[451] In the franchising business model, McDonald's and Subway are the two most recognized brands in the world. Coca-Cola is the most recognized soft drink company in the world.[452]		Chemical products are the leading manufacturing field.[453] The United States is the largest producer of oil in the world, as well as its second-largest importer.[454] It is the world's number one producer of electrical and nuclear energy, as well as liquid natural gas, sulfur, phosphates, and salt. The National Mining Association provides data pertaining to coal and minerals that include beryllium, copper, lead, magnesium, zinc, titanium and others.[455][456]		Agriculture accounts for just under 1% of GDP,[450] yet the United States is the world's top producer of corn[457] and soybeans.[458] The National Agricultural Statistics Service maintains agricultural statistics for products that include peanuts, oats, rye, wheat, rice, cotton, corn, barley, hay, sunflowers, and oilseeds. In addition, the United States Department of Agriculture (USDA) provides livestock statistics regarding beef, poultry, pork, and dairy products. The country is the primary developer and grower of genetically modified food, representing half of the world's biotech crops.[459]		Consumer spending comprises 68% of the U.S. economy in 2015.[460] In August 2010, the American labor force consisted of 154.1 million people. With 21.2 million people, government is the leading field of employment. The largest private employment sector is health care and social assistance, with 16.4 million people. About 12% of workers are unionized, compared to 30% in Western Europe.[461] The World Bank ranks the United States first in the ease of hiring and firing workers.[462] The United States is ranked among the top three in the Global Competitiveness Report as well. It has a smaller welfare state and redistributes less income through government action than European nations tend to.[463]		The United States is the only advanced economy that does not guarantee its workers paid vacation[464] and is one of just a few countries in the world without paid family leave as a legal right, with the others being Papua New Guinea, Suriname and Liberia.[465] While federal law currently does not require sick leave, it is a common benefit for government workers and full-time employees at corporations.[466] 74% of full-time American workers get paid sick leave, according to the Bureau of Labor Statistics, although only 24% of part-time workers get the same benefits.[466] In 2009, the United States had the third-highest workforce productivity per person in the world, behind Luxembourg and Norway. It was fourth in productivity per hour, behind those two countries and the Netherlands.[467]		The 2008–2012 global recession significantly affected the United States, with output still below potential according to the Congressional Budget Office.[468] It brought high unemployment (which has been decreasing but remains above pre-recession levels), along with low consumer confidence, the continuing decline in home values and increase in foreclosures and personal bankruptcies, an escalating federal debt crisis, inflation, and rising petroleum and food prices. There remains a record proportion of long-term unemployed, continued decreasing household income, and tax and federal budget increases.[469][470][471]		Americans have the highest average household and employee income among OECD nations, and in 2007 had the second-highest median household income.[472][473][474] According to the Census Bureau, median household income was $53,657 in 2014.[475] Despite accounting for only 4.4% of the global population, Americans collectively possess 41.6% of the world's total wealth,[476] and Americans make up roughly half of the world's population of millionaires.[477] The Global Food Security Index ranked the U.S. number one for food affordability and overall food security in March 2013.[478] Americans on average have over twice as much living space per dwelling and per person as European Union residents, and more than every EU nation.[479] For 2013 the United Nations Development Programme ranked the United States 5th among 187 countries in its Human Development Index and 28th in its inequality-adjusted HDI (IHDI).[480]		There has been a widening gap between productivity and median incomes since the 1970s.[481] However, the gap between total compensation and productivity is not as wide because of increased employee benefits such as health insurance.[482] While inflation-adjusted ("real") household income had been increasing almost every year from 1947 to 1999, it has since been flat on balance and has even decreased recently.[483] According to Congressional Research Service, during this same period, immigration to the United States increased, while the lower 90% of tax filers incomes became stagnant, and eventually decreasing since 2000.[484] The rise in the share of total annual income received by the top 1 percent, which has more than doubled from 9 percent in 1976 to 20 percent in 2011, has significantly affected income inequality,[485] leaving the United States with one of the widest income distributions among OECD nations.[486] The post-recession income gains have been very uneven, with the top 1 percent capturing 95 percent of the income gains from 2009 to 2012.[487] The extent and relevance of income inequality is a matter of debate.[488][disputed – discuss][489]		Wealth, like income and taxes, is highly concentrated; the richest 10% of the adult population possess 72% of the country's household wealth, while the bottom half claim only 2%.[491] Between June 2007 and November 2008 the global recession led to falling asset prices around the world. Assets owned by Americans lost about a quarter of their value.[492] Since peaking in the second quarter of 2007, household wealth was down $14 trillion, but has since increased $14 trillion over 2006 levels.[493][494] At the end of 2014, household debt amounted to $11.8 trillion,[495] down from $13.8 trillion at the end of 2008.[496]		There were about 578,424 sheltered and unsheltered homeless persons in the U.S. in January 2014, with almost two-thirds staying in an emergency shelter or transitional housing program.[497] In 2011 16.7 million children lived in food-insecure households, about 35% more than 2007 levels, though only 1.1% of U.S. children, or 845,000, saw reduced food intake or disrupted eating patterns at some point during the year, and most cases were not chronic.[498] According to a 2014 report by the Census Bureau, one in five young adults lives in poverty today, up from one in seven in 1980.[499]		Personal transportation is dominated by automobiles, which operate on a network of 4 million miles (6.4 million km) of public roads,[501] including one of the world's longest highway systems at 57,000 miles (91700 km).[502] The world's second-largest automobile market,[503] the United States has the highest rate of per-capita vehicle ownership in the world, with 765 vehicles per 1,000 Americans.[504] About 40% of personal vehicles are vans, SUVs, or light trucks.[505] The average American adult (accounting for all drivers and non-drivers) spends 55 minutes driving every day, traveling 29 miles (47 km).[506]		Mass transit accounts for 9% of total U.S. work trips.[508][509] Transport of goods by rail is extensive, though relatively low numbers of passengers (approximately 31 million annually) use intercity rail to travel, partly because of the low population density throughout much of the U.S. interior.[510][511] However, ridership on Amtrak, the national intercity passenger rail system, grew by almost 37% between 2000 and 2010.[512] Also, light rail development has increased in recent years.[513] Bicycle usage for work commutes is minimal.[514]		The civil airline industry is entirely privately owned and has been largely deregulated since 1978, while most major airports are publicly owned.[515] The three largest airlines in the world by passengers carried are U.S.-based; American Airlines is number one after its 2013 acquisition by US Airways.[516] Of the world's 50 busiest passenger airports, 16 are in the United States, including the busiest, Hartsfield–Jackson Atlanta International Airport, and the fourth-busiest, O'Hare International Airport in Chicago.[517] In the aftermath of the 9/11 attacks of 2001, the Transportation Security Administration was created to police airports and commercial airliners.		The United States energy market is about 29,000 terawatt hours per year.[518] Energy consumption per capita is 7.8 tons (7076 kg) of oil equivalent per year, the 10th-highest rate in the world. In 2005, 40% of this energy came from petroleum, 23% from coal, and 22% from natural gas. The remainder was supplied by nuclear power and renewable energy sources.[519] The United States is the world's largest consumer of petroleum.[520]		For decades, nuclear power has played a limited role relative to many other developed countries, in part because of public perception in the wake of a 1979 accident. In 2007, several applications for new nuclear plants were filed.[521] The United States has 27% of global coal reserves.[522] It is the world's largest producer of natural gas and crude oil.[523]		Issues that affect water supply in the United States include droughts in the West, water scarcity, pollution, a backlog of investment, concerns about the affordability of water for the poorest, and a rapidly retiring workforce. Increased variability and intensity of rainfall as a result of climate change is expected to produce both more severe droughts and flooding, with potentially serious consequences for water supply and for pollution from combined sewer overflows.[524][525][fn 13]		American public education is operated by state and local governments, regulated by the United States Department of Education through restrictions on federal grants. In most states, children are required to attend school from the age of six or seven (generally, kindergarten or first grade) until they turn 18 (generally bringing them through twelfth grade, the end of high school); some states allow students to leave school at 16 or 17.[528]		About 12% of children are enrolled in parochial or nonsectarian private schools. Just over 2% of children are homeschooled.[529] The U.S. spends more on education per student than any nation in the world, spending more than $11,000 per elementary student in 2010 and more than $12,000 per high school student.[530] Some 80% of U.S. college students attend public universities.[531]		The United States has many competitive private and public institutions of higher education. The majority of the world's top universities listed by different ranking organizations are in the U.S.[532][533][534] There are also local community colleges with generally more open admission policies, shorter academic programs, and lower tuition. Of Americans 25 and older, 84.6% graduated from high school, 52.6% attended some college, 27.2% earned a bachelor's degree, and 9.6% earned graduate degrees.[535] The basic literacy rate is approximately 99%.[10][536] The United Nations assigns the United States an Education Index of 0.97, tying it for 12th in the world.[537]		As for public expenditures on higher education, the U.S. trails some other OECD nations but spends more per student than the OECD average, and more than all nations in combined public and private spending.[530][538] As of 2012[update], student loan debt exceeded one trillion dollars, more than Americans owe on credit cards.[539]		The United States is home to many cultures and a wide variety of ethnic groups, traditions, and values.[28][540] Aside from the Native American, Native Hawaiian, and Native Alaskan populations, nearly all Americans or their ancestors settled or immigrated within the past five centuries.[541] Mainstream American culture is a Western culture largely derived from the traditions of European immigrants with influences from many other sources, such as traditions brought by slaves from Africa.[28][542] More recent immigration from Asia and especially Latin America has added to a cultural mix that has been described as both a homogenizing melting pot, and a heterogeneous salad bowl in which immigrants and their descendants retain distinctive cultural characteristics.[28]		Core American culture was established by Protestant British colonists and shaped by the frontier settlement process, with the traits derived passed down to descendants and transmitted to immigrants through assimilation. Americans have traditionally been characterized by a strong work ethic, competitiveness, and individualism,[543] as well as a unifying belief in an "American creed" emphasizing liberty, equality, private property, democracy, rule of law, and a preference for limited government.[544] Americans are extremely charitable by global standards. According to a 2006 British study, Americans gave 1.67% of GDP to charity, more than any other nation studied, more than twice the second place British figure of 0.73%, and around twelve times the French figure of 0.14%.[545][546]		The American Dream, or the perception that Americans enjoy high social mobility, plays a key role in attracting immigrants.[547] Whether this perception is realistic has been a topic of debate.[548][549][550][551][437][552] While mainstream culture holds that the United States is a classless society,[553] scholars identify significant differences between the country's social classes, affecting socialization, language, and values.[554] Americans' self-images, social viewpoints, and cultural expectations are associated with their occupations to an unusually close degree.[555] While Americans tend greatly to value socioeconomic achievement, being ordinary or average is generally seen as a positive attribute.[556]		Mainstream American cuisine is similar to that in other Western countries. Wheat is the primary cereal grain with about three-quarters of grain products made of wheat flour[557] and many dishes use indigenous ingredients, such as turkey, venison, potatoes, sweet potatoes, corn, squash, and maple syrup which were consumed by Native Americans and early European settlers.[558] These home grown foods are part of a shared national menu on one of America's most popular holidays; Thanksgiving, when some Americans make traditional foods to celebrate the occasion.[559]		Characteristic dishes such as apple pie, fried chicken, pizza, hamburgers, and hot dogs derive from the recipes of various immigrants. French fries, Mexican dishes such as burritos and tacos, and pasta dishes freely adapted from Italian sources are widely consumed.[561] Americans drink three times as much coffee as tea.[562] Marketing by U.S. industries is largely responsible for making orange juice and milk ubiquitous breakfast beverages.[563][564]		American eating habits owe a great deal to that of their British culinary roots with some variations. Although American lands could grow newer vegetables that Britain could not, most colonists would not eat these new foods until accepted by Europeans.[565] Over time American foods changed to a point that food critic, John L. Hess stated in 1972: "Our founding fathers were as far superior to our present political leaders in the quality of their food as they were in the quality of their prose and intelligence".[566]		The American fast food industry, the world's largest,[567] pioneered the drive-through format in the 1940s.[568] Fast food consumption has sparked health concerns. During the 1980s and 1990s, Americans' caloric intake rose 24%;[561] frequent dining at fast food outlets is associated with what public health officials call the American "obesity epidemic".[569] Highly sweetened soft drinks are widely popular, and sugared beverages account for nine percent of American caloric intake.[570]		In the 18th and early 19th centuries, American art and literature took most of its cues from Europe. Writers such as Nathaniel Hawthorne, Edgar Allan Poe, and Henry David Thoreau established a distinctive American literary voice by the middle of the 19th century. Mark Twain and poet Walt Whitman were major figures in the century's second half; Emily Dickinson, virtually unknown during her lifetime, is now recognized as an essential American poet.[571] A work seen as capturing fundamental aspects of the national experience and character—such as Herman Melville's Moby-Dick (1851), Twain's The Adventures of Huckleberry Finn (1885), F. Scott Fitzgerald's The Great Gatsby (1925) and Harper Lee's To Kill a Mockingbird (1960)—may be dubbed the "Great American Novel".[572]		Twelve U.S. citizens have won the Nobel Prize in Literature, most recently Bob Dylan in 2016. William Faulkner, Ernest Hemingway and John Steinbeck are often named among the most influential writers of the 20th century.[573] Popular literary genres such as the Western and hardboiled crime fiction developed in the United States. The Beat Generation writers opened up new literary approaches, as have postmodernist authors such as John Barth, Thomas Pynchon, and Don DeLillo.[574]		The transcendentalists, led by Thoreau and Ralph Waldo Emerson, established the first major American philosophical movement. After the Civil War, Charles Sanders Peirce and then William James and John Dewey were leaders in the development of pragmatism. In the 20th century, the work of W. V. O. Quine and Richard Rorty, and later Noam Chomsky, brought analytic philosophy to the fore of American philosophical academia. John Rawls and Robert Nozick led a revival of political philosophy. Cornel West and Judith Butler have led a continental tradition in American philosophical academia. Chicago school economists like Milton Friedman, James M. Buchanan, and Thomas Sowell have affected various fields in social and political philosophy.[575][576]		In the visual arts, the Hudson River School was a mid-19th-century movement in the tradition of European naturalism. The realist paintings of Thomas Eakins are now widely celebrated. The 1913 Armory Show in New York City, an exhibition of European modernist art, shocked the public and transformed the U.S. art scene.[577] Georgia O'Keeffe, Marsden Hartley, and others experimented with new, individualistic styles. Major artistic movements such as the abstract expressionism of Jackson Pollock and Willem de Kooning and the pop art of Andy Warhol and Roy Lichtenstein developed largely in the United States. The tide of modernism and then postmodernism has brought fame to American architects such as Frank Lloyd Wright, Philip Johnson, and Frank Gehry.[578] Americans have long been important in the modern artistic medium of photography, with major photographers including Alfred Stieglitz, Edward Steichen, and Ansel Adams.[579]		One of the first major promoters of American theater was impresario P. T. Barnum, who began operating a lower Manhattan entertainment complex in 1841. The team of Harrigan and Hart produced a series of popular musical comedies in New York starting in the late 1870s. In the 20th century, the modern musical form emerged on Broadway; the songs of musical theater composers such as Irving Berlin, Cole Porter, and Stephen Sondheim have become pop standards. Playwright Eugene O'Neill won the Nobel literature prize in 1936; other acclaimed U.S. dramatists include multiple Pulitzer Prize winners Tennessee Williams, Edward Albee, and August Wilson.[581]		Though little known at the time, Charles Ives's work of the 1910s established him as the first major U.S. composer in the classical tradition, while experimentalists such as Henry Cowell and John Cage created a distinctive American approach to classical composition. Aaron Copland and George Gershwin developed a new synthesis of popular and classical music.		Choreographers Isadora Duncan and Martha Graham helped create modern dance, while George Balanchine and Jerome Robbins were leaders in 20th-century ballet.		The rhythmic and lyrical styles of African-American music have deeply influenced American music at large, distinguishing it from European traditions. Elements from folk idioms such as the blues and what is now known as old-time music were adopted and transformed into popular genres with global audiences. Jazz was developed by innovators such as Louis Armstrong and Duke Ellington early in the 20th century. Country music developed in the 1920s, and rhythm and blues in the 1940s.[582]		Elvis Presley and Chuck Berry were among the mid-1950s pioneers of rock and roll. In the 1960s, Bob Dylan emerged from the folk revival to become one of America's most celebrated songwriters and James Brown led the development of funk. More recent American creations include hip hop and house music. American pop stars such as Presley, Michael Jackson, and Madonna have become global celebrities,[582] as have contemporary musical artists such as Taylor Swift, Britney Spears, Katy Perry, and Beyoncé as well as hip hop artists Jay-Z, Eminem and Kanye West.[583] Rock bands such as Metallica, the Eagles, and Aerosmith are among the highest grossing in worldwide sales.[584][585][586]		Hollywood, a northern district of Los Angeles, California, is one of the leaders in motion picture production.[587] The world's first commercial motion picture exhibition was given in New York City in 1894, using Thomas Edison's Kinetoscope.[588] The next year saw the first commercial screening of a projected film, also in New York, and the United States was in the forefront of sound film's development in the following decades. Since the early 20th century, the U.S. film industry has largely been based in and around Hollywood, although in the 21st century an increasing number of films are not made there, and film companies have been subject to the forces of globalization.[589]		Director D. W. Griffith, the top American filmmaker during the silent film period, was central to the development of film grammar, and producer/entrepreneur Walt Disney was a leader in both animated film and movie merchandising.[590] Directors such as John Ford redefined the image of the American Old West and history, and, like others such as John Huston, broadened the possibilities of cinema with location shooting, with great influence on subsequent directors. The industry enjoyed its golden years, in what is commonly referred to as the "Golden Age of Hollywood", from the early sound period until the early 1960s,[591] with screen actors such as John Wayne and Marilyn Monroe becoming iconic figures.[592][593] In the 1970s, film directors such as Martin Scorsese, Francis Ford Coppola and Robert Altman were a vital component in what became known as "New Hollywood" or the "Hollywood Renaissance",[594] grittier films influenced by French and Italian realist pictures of the post-war period.[595] Since, directors such as Steven Spielberg, George Lucas and James Cameron have gained renown for their blockbuster films, often characterized by high production costs, and in return, high earnings at the box office, with Cameron's Avatar (2009) earning more than $2 billion.[596]		Notable films topping the American Film Institute's AFI 100 list include Orson Welles's Citizen Kane (1941), which is frequently cited as the greatest film of all time,[597][598] Casablanca (1942), The Godfather (1972), Gone with the Wind (1939), Lawrence of Arabia (1962), The Wizard of Oz (1939), The Graduate (1967), On the Waterfront (1954), Schindler's List (1993), Singin' in the Rain (1952), It's a Wonderful Life (1946) and Sunset Boulevard (1950).[599] The Academy Awards, popularly known as the Oscars, have been held annually by the Academy of Motion Picture Arts and Sciences since 1929,[600] and the Golden Globe Awards have been held annually since January 1944.[601]		American football is by several measures the most popular spectator sport;[603] the National Football League (NFL) has the highest average attendance of any sports league in the world, and the Super Bowl is watched by millions globally. Baseball has been regarded as the U.S. national sport since the late 19th century, with Major League Baseball (MLB) being the top league. Basketball and ice hockey are the country's next two leading professional team sports, with the top leagues being the National Basketball Association (NBA) and the National Hockey League (NHL). These four major sports, when played professionally, each occupy a season at different, but overlapping, times of the year. College football and basketball attract large audiences.[604] In soccer, the country hosted the 1994 FIFA World Cup, the men's national soccer team qualified for ten World Cups and the women's team has won the FIFA Women's World Cup three times; Major League Soccer is the sport's highest league in the United States (featuring 19 American and 3 Canadian teams). The market for professional sports in the United States is roughly $69 billion, roughly 50% larger than that of all of Europe, the Middle East, and Africa combined.[605]		Eight Olympic Games have taken place in the United States. As of 2014, the United States has won 2,400 medals at the Summer Olympic Games, more than any other country, and 281 in the Winter Olympic Games, the second most behind Norway.[606] While most major U.S. sports have evolved out of European practices, basketball, volleyball, skateboarding, and snowboarding are American inventions, some of which have become popular in other countries. Lacrosse and surfing arose from Native American and Native Hawaiian activities that predate Western contact.[607] The most watched individual sports are golf and auto racing, particularly NASCAR.[608][609] Rugby union is considered the fastest growing sport in the U.S., with registered players numbered at 115,000+ and a further 1.2 million participants.[610]		The four major broadcasters in the U.S. are the National Broadcasting Company (NBC), Columbia Broadcasting System (CBS), the American Broadcasting Company (ABC), and Fox. The four major broadcast television networks are all commercial entities. Cable television offers hundreds of channels catering to a variety of niches.[611] Americans listen to radio programming, also largely commercial, on average just over two-and-a-half hours a day.[612]		In 1998, the number of U.S. commercial radio stations had grown to 4,793 AM stations and 5,662 FM stations. In addition, there are 1,460 public radio stations. Most of these stations are run by universities and public authorities for educational purposes and are financed by public or private funds, subscriptions and corporate underwriting. Much public-radio broadcasting is supplied by NPR (formerly National Public Radio). NPR was incorporated in February 1970 under the Public Broadcasting Act of 1967; its television counterpart, PBS, was also created by the same legislation. (NPR and PBS are operated separately from each other.) As of September 30, 2014[update], there are 15,433 licensed full-power radio stations in the U.S. according to the U.S. Federal Communications Commission (FCC).[613]		Well-known newspapers are The Wall Street Journal, The New York Times and USA Today. Although the cost of publishing has increased over the years, the price of newspapers has generally remained low, forcing newspapers to rely more on advertising revenue and on articles provided by a major wire service, such as the Associated Press or Reuters, for their national and world coverage. With very few exceptions, all the newspapers in the U.S. are privately owned, either by large chains such as Gannett or McClatchy, which own dozens or even hundreds of newspapers; by small chains that own a handful of papers; or in a situation that is increasingly rare, by individuals or families. Major cities often have "alternative weeklies" to complement the mainstream daily papers, for example, New York City's The Village Voice or Los Angeles' LA Weekly, to name two of the best-known. Major cities may also support a local business journal, trade papers relating to local industries, and papers for local ethnic and social groups. Early versions of the American newspaper comic strip and the American comic book began appearing in the 19th century. In 1938, Superman, the comic book superhero of DC Comics, developed into an American icon.[614] Aside from web portals and search engines, the most popular websites are Facebook, YouTube, Wikipedia, Yahoo!, eBay, Amazon, and Twitter.[615]		More than 800 publications are produced in Spanish, the second most commonly used language in the United States behind English.[616][617]		The United States has been a leader in technological innovation since the late 19th century and scientific research since the mid-20th century. Methods for producing interchangeable parts were developed by the U.S. War Department by the Federal Armories during the first half of the 19th century. This technology, along with the establishment of a machine tool industry, enabled the U.S. to have large scale manufacturing of sewing machines, bicycles and other items in the late 19th century and became known as the American system of manufacturing. Factory electrification in the early 20th century and introduction of the assembly line and other labor saving techniques created the system called mass production.[618]		In 1876, Alexander Graham Bell was awarded the first U.S. patent for the telephone. Thomas Edison's research laboratory, one of the first of its kind, developed the phonograph, the first long-lasting light bulb, and the first viable movie camera.[619] The latter lead to emergence of the worldwide entertainment industry. In the early 20th century, the automobile companies of Ransom E. Olds and Henry Ford popularized the assembly line. The Wright brothers, in 1903, made the first sustained and controlled heavier-than-air powered flight.[620]		The rise of Fascism and Nazism in the 1920s and 1930s led many European scientists, including Albert Einstein, Enrico Fermi, and John von Neumann, to immigrate to the United States.[621] During World War II, the Manhattan Project developed nuclear weapons, ushering in the Atomic Age, while the Space Race produced rapid advances in rocketry, materials science, and aeronautics.[622][623]		The invention of the transistor in the 1950s, a key active component in practically all modern electronics, led to many technological developments and a significant expansion of the U.S. technology industry.[624][625][626] This in turn led to the establishment of many new technology companies and regions around the country such as in Silicon Valley in California. Advancements by American microprocessor companies such as Advanced Micro Devices (AMD), and Intel along with both computer software and hardware companies that include Adobe Systems, Apple Inc., IBM, Microsoft, and Sun Microsystems created and popularized the personal computer. The ARPANET was developed in the 1960s to meet Defense Department requirements, and became the first of a series of networks which evolved into the Internet.[627]		These advancements then lead to greater personalization of technology for individual use.[628] As of 2013[update], 83.8% of American households owned at least one computer, and 73.3% had high-speed Internet service.[629] 91% of Americans also own a mobile phone as of May 2013[update].[630] The United States ranks highly with regard to freedom of use of the internet.[631]		In the 21st century, approximately two-thirds of research and development funding comes from the private sector.[632] The United States leads the world in scientific research papers and impact factor.[633]		The United States has a life expectancy of 79.8 years at birth, up from 75.2 years in 1990.[634][635][636] The infant mortality rate of 6.17 per thousand places the United States 56th-lowest out of 224 countries.[637]		Increasing obesity in the United States and health improvements elsewhere contributed to lowering the country's rank in life expectancy from 11th in the world in 1987, to 42nd in 2007.[638] Obesity rates have more than doubled in the last 30 years, are the highest in the industrialized world, and are among the highest anywhere.[639][640] Approximately one-third of the adult population is obese and an additional third is overweight.[641] Obesity-related type 2 diabetes is considered epidemic by health care professionals.[642]		In 2010, coronary artery disease, lung cancer, stroke, chronic obstructive pulmonary diseases, and traffic accidents caused the most years of life lost in the U.S. Low back pain, depression, musculoskeletal disorders, neck pain, and anxiety caused the most years lost to disability. The most deleterious risk factors were poor diet, tobacco smoking, obesity, high blood pressure, high blood sugar, physical inactivity, and alcohol use. Alzheimer's disease, drug abuse, kidney disease and cancer, and falls caused the most additional years of life lost over their age-adjusted 1990 per-capita rates.[636] U.S. teenage pregnancy and abortion rates are substantially higher than in other Western nations, especially among blacks and Hispanics.[643]		The U.S. is a global leader in medical innovation. America solely developed or contributed significantly to 9 of the top 10 most important medical innovations since 1975 as ranked by a 2001 poll of physicians, while the European Union and Switzerland together contributed to five.[644] Since 1966, more Americans have received the Nobel Prize in Medicine than the rest of the world combined. From 1989 to 2002, four times more money was invested in private biotechnology companies in America than in Europe.[645] The U.S. health-care system far outspends any other nation, measured in both per capita spending and percentage of GDP.[646]		Health-care coverage in the United States is a combination of public and private efforts and is not universal. In 2014, 13.4% of the population did not carry health insurance.[647] The subject of uninsured and underinsured Americans is a major political issue.[648][649] In 2006, Massachusetts became the first state to mandate universal health insurance.[650] Federal legislation passed in early 2010 would ostensibly create a near-universal health insurance system around the country by 2014, though the bill and its ultimate effect are issues of controversy.[651][652]		
Toronto (/təˈrɒntoʊ/ ( listen),[10][11] locally /təˈrɒnoʊ/ ( listen)) is the most populous city in Canada and the provincial capital of Ontario.[12][13] With a population in 2016 of 2,731,571,[6][12] it is the fourth most populous city in North America after Mexico City, New York City, and Los Angeles. Toronto is the centre of the Greater Toronto Area (GTA), the most populous metropolitan area in Canada,[14] and anchors the Golden Horseshoe, a heavily urbanized region that is home to 9.2 million people,[15] or over 26% of the population of Canada.[16] A global city,[17] Toronto is an international centre of business, finance, arts, and culture,[18][19] and is recognized as one of the most multicultural and cosmopolitan cities in the world.[20][21][22][23][24]		Indigenous peoples have inhabited the area now known as Toronto for thousands of years, with the city itself sitting at the southern terminus of the ancient Toronto Carrying-Place Trail.[25] Permanent European settlement began in the 1790s, after the broadly disputed Toronto Purchase of 1787, when the Mississaugas surrendered the area to the British Crown.[26] The British established the town of York, and later designated it as the capital of Upper Canada.[27] During the War of 1812, the town was the site of the Battle of York and suffered heavy damage by U.S. troops.[28] York was renamed and incorporated as the city of Toronto in 1834, and became the capital of the province of Ontario during Canadian Confederation in 1867.[29] The city proper has since expanded past its original borders through both annexation and amalgamation with surrounding municipalities at various times in its history to its current area of 630.2 km2 (243.3 sq mi).		Located in Southern Ontario on the northwestern shore of Lake Ontario, Toronto is situated on a broad sloping plateau intersected by an extensive network of rivers, deep ravines, and urban forest,[30] with 140 independently unique and clearly defined official neighbourhoods making up the city.[31] The diverse population of Toronto reflects its current and historical role as an important destination for immigrants to Canada,[32][33] with nearly 50% of residents belonging to a visible minority population group,[34] and over 200 distinct ethnic origins represented among its inhabitants.[35] While the majority of Torontonians speak English as their primary language, there are over 160 different languages spoken in the city.[36]		Toronto is a prominent centre for music,[37] theatre,[38] motion picture production,[39] and television production,[40] and is home to the headquarters of Canada's major national broadcast networks and media outlets.[41] Its varied cultural institutions,[42] which include numerous museums and galleries, festivals and public events, entertainment districts, national historic sites, and sports activities,[43] attract over 25 million tourists each year.[44][45] Toronto is known for its many skyscrapers and high-rise buildings,[46] in particular the tallest free-standing structure in the Western Hemisphere, the CN Tower.[47] As Canada's commercial capital, the city is home to the Toronto Stock Exchange, the headquarters of Canada's five largest banks,[48] and the headquarters of many large Canadian and multinational corporations.[49] Its economy is highly diversified with strengths in technology, design, financial services, life sciences, education, arts, fashion, business services, environmental innovation, food services, and tourism.[50][51][52]						When Europeans first arrived at the site of present-day Toronto, the vicinity was inhabited by the Iroquois,[53] who by then had displaced the Wyandot (Huron) people who had occupied the region for centuries before c. 1500.[54] The name Toronto is likely derived from the Iroquois word tkaronto, meaning "place where trees stand in the water".[55] This refers to the northern end of what is now Lake Simcoe, where the Huron had planted tree saplings to corral fish. However, the word "Toronto", meaning "plenty" also appears in a French lexicon of the Huron language in 1632,[56] and appeared on French maps referring to various locations, including Georgian Bay, Lake Simcoe, and several rivers.[57] A portage route from Lake Ontario to Lake Huron running through this point, the Toronto Carrying-Place Trail, led to widespread use of the name. In the 1660s, the Iroquois established two villages within what is today Toronto, Ganatsekwyagon on the banks of the Rouge River and Teiaiagonon the banks of the Humber River. By 1701, the Mississauga had displaced the Iroquois, who abandoned the Toronto area at the end of the Beaver Wars.[58]		French traders founded Fort Rouillé on the current Exhibition grounds in 1750, but abandoned it in 1759.[59] During the American Revolutionary War, the region saw an influx of British settlers as United Empire Loyalists fled for the British-controlled lands north of Lake Ontario. The new province of Upper Canada was in the process of creation and needed a capital. In 1787, the British Lord Dorchester arranged for the Toronto Purchase with the Mississaugas of the New Credit First Nation, thereby securing more than a quarter of a million acres (1000 km2) of land in the Toronto area.[60] Dorchester intended the location to be named Toronto.[57]		In 1793, Governor John Graves Simcoe established the town of York on the Toronto Purchase lands, instead naming it after Prince Frederick, Duke of York and Albany. Simcoe decided to move the Upper Canada capital from Newark (Niagara-on-the-Lake) to York,[61] believing that the new site would be less vulnerable to attack by the United States.[62] The York garrison was constructed at the entrance of the town's natural harbour, sheltered by a long sandbar peninsula. The town's settlement formed at the eastern end of the harbour behind the peninsula, near the present-day intersection of Parliament Street and Front Street (in the "Old Town" area).		In 1813, as part of the War of 1812, the Battle of York ended in the town's capture and plunder by US forces.[63] The surrender of the town was negotiated by John Strachan. US soldiers destroyed much of the garrison and set fire to the parliament buildings during their five-day occupation. The sacking of York was a primary motivation for the Burning of Washington by British troops later in the war. York was incorporated as the City of Toronto on March 6, 1834, reverting to its original native name.		The population of only 9,000 included escaped African American slaves, some of whom were brought by the Loyalists, including Mohawk leader Joseph Brant.[64] Torontonians integrated people of colour into their society. In the 1840s an eating house at Frederick and King Streets, a place of mercantile prosperity in early Toronto, was operated by a man of colour named Bloxom.[65] Slavery was banned outright in Upper Canada in 1834. Reformist politician William Lyon Mackenzie became the first Mayor of Toronto and led the unsuccessful Upper Canada Rebellion of 1837 against the British colonial government. As a major destination for immigrants to Canada, the city grew rapidly through the remainder of the 19th century. The first significant population influx occurred when the Great Irish Famine brought a large number of Irish to the city, some of them transient, and most of them Catholic. By 1851, the Irish-born population had become the largest single ethnic group in the city. Smaller numbers of Protestant Irish immigrants were welcomed by the existing Scottish and English population, giving the Orange Order significant and long-lasting influence over Toronto society.		For brief periods Toronto was twice the capital of the united Province of Canada: first from 1849 to 1852, following unrest in Montreal, and later 1856–1858, after which Quebec became the capital until 1866 (one year before Confederation). Since then, the capital of Canada has remained Ottawa.[66] Toronto became the capital of the province of Ontario after its official creation in 1867, the seat of government located at the Ontario Legislature located at Queen's Park. Because of its provincial capital status, the city was also the location of Government House, the residence of the viceregal representative of the Crown in right of Ontario.		Long before the Royal Military College of Canada was established in 1876, there were proposals for military colleges in Canada. Staffed by British Regulars, adult male students underwent a three-month long military course at the School of Military Instruction in Toronto. Established by Militia General Order in 1864, the school enabled officers of militia or candidates for commission or promotion in the Militia to learn military duties, drill and discipline, to command a company at Battalion Drill, to drill a company at Company Drill, the internal economy of a company, and the duties of a company's officer.[67] The school was retained at Confederation, in 1867. In 1868, Schools of cavalry and artillery instruction were formed in Toronto.[68]		In the 19th century, an extensive sewage system was built, and streets became illuminated with gas lighting as a regular service. Long-distance railway lines were constructed, including a route completed in 1854 linking Toronto with the Upper Great Lakes. The Grand Trunk Railway and the Northern Railway of Canada joined in the building of the first Union Station in downtown. The advent of the railway dramatically increased the numbers of immigrants arriving, commerce and industry, as had the Lake Ontario steamers and schooners entering port before. These enabled Toronto to become a major gateway linking the world to the interior of the North American continent.		Toronto became the largest alcohol distillation (in particular, spirits) centre in North America; the Gooderham and Worts Distillery operations became the world's largest whiskey factory by the 1860s. A preserved section of this once dominant local industry remains in the Distillery District. The harbour allowed for sure access to grain and sugar imports used in processing. Expanding port and rail facilities brought in northern timber for export and imported Pennsylvania coal. Industry dominated the waterfront for the next 100 years.		Horse-drawn streetcars gave way to electric streetcars in 1891, when the city granted the operation of the transit franchise to the Toronto Railway Company. The public transit system passed into public ownership in 1921 as the Toronto Transportation Commission, later renamed the Toronto Transit Commission. The system now has the third-highest ridership of any city public transportation system in North America.[69]		The Great Toronto Fire of 1904 destroyed a large section of downtown Toronto, but the city was quickly rebuilt. The fire caused more than $10 million in damage, and resulted in more stringent fire safety laws and expansion of the city's fire department.		The city received new immigrant groups beginning in the late 19th century into the early 20th century, particularly Germans, French, Italians, and Jews from various parts of Eastern Europe. They were soon followed by Chinese, Russians, Poles, and immigrants from other Eastern European nations. As the Irish before them, many of these new migrants lived in overcrowded shanty-type slums, such as "the Ward" which was centred on Bay Street, now the heart of the country's financial district. Despite its fast-paced growth, by the 1920s, Toronto's population and economic importance in Canada remained second to the much longer established Montreal. However, by 1934, the Toronto Stock Exchange had become the largest in the country.		Following the Second World War, refugees from war-torn Europe and Chinese job-seekers arrived, as well as construction labourers, particularly from Italy and Portugal. Following the elimination of racially based immigration policies by the late 1960s, immigration began from all parts of the world. Toronto's population grew to more than one million in 1951 when large-scale suburbanization began, and doubled to two million by 1971. By the 1980s, Toronto had surpassed Montreal as Canada's most populous city and the chief economic hub. During this time, in part owing to the political uncertainty raised by the resurgence of the Quebec sovereignty movement, many national and multinational corporations moved their head offices from Montreal to Toronto and Western Canadian cities.[70]		In 1954, the City of Toronto and 12 surrounding municipalities were federated into a regional government known as Metropolitan Toronto.[71] The postwar boom had resulted in rapid suburban development and it was believed that a coordinated land use strategy and shared services would provide greater efficiency for the region. The metropolitan government began to manage services that crossed municipal boundaries, including highways, police services, water and public transit. In that year, a half-century after the Great Fire of 1904, disaster struck the city again when Hurricane Hazel brought intense winds and flash flooding. In the Toronto area, 81 people were killed, nearly 1,900 families were left homeless, and the hurricane caused more than $25 million in damage.[72]		In 1967, the seven smallest municipalities of Metropolitan Toronto were merged into their larger neighbours, resulting in a six-municipality configuration that included the old City of Toronto and the surrounding municipalities of East York, Etobicoke, North York, Scarborough, and York. [73] In 1998, the Conservative provincial government led by Mike Harris dissolved the metropolitan government despite vigorous opposition from the component municipalities and overwhelming rejection in a municipal plebiscite. All six municipalities were amalgamated into a single municipality, creating the current City of Toronto, successor of the old City of Toronto. North York mayor Mel Lastman became the first "megacity" mayor and the 62nd Mayor of Toronto. John Tory is the current mayor.		On March 6, 2009, the city celebrated the 175th anniversary of its inception as the City of Toronto in 1834. Toronto hosted the 4th G20 summit during June 26–27, 2010. This included the largest security operation in Canadian history and, following large-scale protests and rioting, resulted in the largest mass arrest (more than a thousand people) in Canadian history.[74]		On July 8, 2013, severe flash flooding hit Toronto after an afternoon of slow moving, intense thunderstorms. Toronto Hydro estimated that 450,000 people were without power after the storm and Toronto Pearson International Airport reported that 126 mm (5 in) of rain had fallen over five hours, more than during Hurricane Hazel.[75] Within six months, December 20, 2013, Toronto was brought to a halt by the worst ice storm in the city's history rivaling the severity of the 1998 Ice Storm. Toronto went on to host WorldPride in June 2014[76] and the Pan American Games in 2015.[77]		Toronto covers an area of 630 square kilometres (243 sq mi),[78] with a maximum north-south distance of 21 kilometres (13 mi) and a maximum east-west distance of 43 km (27 mi). It has a 46-kilometre (29 mi) long waterfront shoreline, on the northwestern shore of Lake Ontario. The Toronto Islands and Port Lands extend out into the lake, allowing for a somewhat sheltered Toronto Harbour south of the downtown core.[79] The city's borders are formed by Lake Ontario to the south, Etobicoke Creek and Highway 427 to the west, Steeles Avenue to the north and the Rouge River and the Scarborough-Pickering Townline to the east.		The city is mostly flat or gentle hills and the land gently slopes upward away from the lake. The flat land is interrupted by numerous ravines cut by numerous creeks and the valleys of the three rivers in Toronto: the Humber River in the west end and the Don River east of downtown at opposite ends of the Toronto Harbour, and the Rouge River at the city's eastern limits. Most of the ravines and valley lands in Toronto today are park lands, and recreational trails are laid out along the ravines and valleys. The original town was laid out in a grid plan on the flat plain north of the harbour, and this plan was extended outwards as the city grew. The width and depth of several of the ravines and valleys are such that several grid streets such as Finch Avenue, Leslie Street, Lawrence Avenue, and St. Clair Avenue, terminate on one side of a ravine or valley and continue on the other side. Toronto has many bridges spanning the ravines. Large bridges such as the Prince Edward Viaduct were built to span wide river valleys.		Despite its deep ravines, Toronto is not remarkably hilly, but its elevation does increase steadily away from the lake. Elevation differences range from 75 metres (246 ft) above sea level at the Lake Ontario shore to 209 m (686 ft) ASL near the York University grounds in the city's north end at the intersection of Keele Street and Steeles Avenue.[80] There are occasional hilly areas; in particular, midtown Toronto has a number of sharply sloping hills. Lake Ontario remains occasionally visible from the peaks of these ridges as far north as Eglinton Avenue, 7 to 8 kilometres (4.3 to 5.0 mi) inland.		The other major geographical feature of Toronto is its escarpments. During the last ice age, the lower part of Toronto was beneath Glacial Lake Iroquois. Today, a series of escarpments mark the lake's former boundary, known as the "Iroquois Shoreline". The escarpments are most prominent from Victoria Park Avenue to the mouth of Highland Creek where they form the Scarborough Bluffs. Other observable sections include the area near St. Clair Avenue West between Bathurst Street and the Don River, and north of Davenport Road from Caledonia to Spadina Road; the Casa Loma grounds sit above this escarpment.		The geography of the lake shore is greatly changed since the first settlement of Toronto. Much of the land on the north shore of the harbour is landfill, filled in during the late 19th century. Until then, the lakefront docks (then known as wharves) were set back farther inland than today. Much of the adjacent Port Lands on the east side of the harbour was a wetland filled in early in the 20th century. The shoreline from the harbour west to the Humber River has been extended into the lake. Further west, landfill has created extensions of land such as Humber Bay Park.		The Toronto Islands were a natural peninsula until a storm in 1858 severed their connection to the mainland, creating a channel to the harbour. The peninsula was formed by longshore drift taking the sediments deposited along the Scarborough Bluffs shore and transporting them to the Islands area. The other source of sediment for the Port Lands wetland and the peninsula was the deposition of the Don River, which carved a wide valley through the sedimentary land of Toronto and deposited it in the harbour, which is quite shallow. The harbour and the channel of the Don River have been dredged numerous times for shipping. The lower section of the Don River was straightened and channelled in the 19th century. The former mouth drained into a wetland; today the Don drains into the harbour through a concrete waterway, the Keating Channel.		The city of Toronto has a humid continental climate (Köppen: Dfa), with warm, humid summers and cold winters.[81] The city experiences four distinct seasons, with considerable variance in length.[82] Some parts of the north and east of the city such as Scarborough and the suburbs, have a climate classified as humid continental climate (Köppen: Dfb). As a result of the rapid passage of weather systems (such as high- and low-pressure systems), the weather is variable from day to day in all seasons.[82] Owing to urbanization and its proximity to water, Toronto has a fairly low diurnal temperature range. The denser urban scape makes for warmer nights year around; the average nighttime temperature is about 3.0 °C (5.40 °F) warmer in the city than in rural areas in all months.[83] However, it can be noticeably cooler on many spring and early summer afternoons under the influence of a lake breeze since Lake Ontario is cool, relative to the air during these seasons.[83] These lake breezes mostly occur in summer, bringing relief on hot days.[83] Other low-scale maritime effects on the climate include lake-effect snow, fog, and delaying of spring- and fall-like conditions, known as seasonal lag.[83]		Winters are cold with frequent snow.[84] During the winter months, temperatures are usually below 0 °C (32 °F).[84] Toronto winters sometimes feature cold snaps when maximum temperatures remain below −10 °C (14 °F), often made to feel colder by wind chill. Occasionally, they can drop below −25 °C (−13 °F).[84] Snowstorms, sometimes mixed with ice and rain, can disrupt work and travel schedules, while accumulating snow can fall anytime from November until mid-April. However, mild stretches also occur in most winters, melting accumulated snow. The summer months are characterized by very warm temperatures.[84] Daytime temperatures are usually above 20 °C (68 °F), and often rise above 30 °C (86 °F).[84] However, they can occasionally surpass 35 °C (95 °F) accompanied by high humidity. Spring and autumn are transitional seasons with generally mild or cool temperatures with alternating dry and wet periods.[83] Daytime temperatures average around 10 to 12 °C (50 to 54 °F) during these seasons.[84]		Precipitation is fairly evenly distributed throughout the year, but summer is usually the wettest season, the bulk falling during thunderstorms. There can be periods of dry weather, but drought-like conditions are rare.[citation needed] The average yearly precipitation is about 831 mm (32.7 in), with an average annual snowfall of about 122 cm (48 in).[85] Toronto experiences an average of 2,066 sunshine hours, or 45% of daylight hours, varying between a low of 28% in December to 60% in July.[85]		According to the classification applied by Natural Resources Canada, Toronto is located in plant hardiness zones 5b to 7a.[86][87]				Lawrence Richards, a member of the Faculty of Architecture at the University of Toronto, has said: "Toronto is a new, brash, rag-tag place—a big mix of periods and styles."[94] Toronto's buildings vary in design and age with many structures dating back to the mid-19th-century, while other prominent buildings were just newly built in the first decade of the 21st century. Bay-and-gable houses, mainly found in Old Toronto, are a distinct architectural feature of the city. Defining the Toronto skyline is the CN Tower, a telecommunications and tourism hub. Completed in 1976 at a height of 553.33 metres (1,815 ft 5 in), it was the world's tallest[95] freestanding structure until 2007 when it was surpassed by Burj Khalifa.[96]		Toronto is a city of high-rises, having 1,800 buildings over 30 metres (98 ft).[97]		Through the 1960s and 1970s, significant pieces of Toronto's architectural heritage were demolished to make way for redevelopment or parking. In contrast, since the 2000s, Toronto has experienced a period of architectural revival, with several buildings by world-renowned architects having opened during the late 2000s. Daniel Libeskind's Royal Ontario Museum addition, Frank Gehry's remake of the Art Gallery of Ontario, and Will Alsop's distinctive Ontario College of Art & Design expansion are among the city's new showpieces.[98] The historic Distillery District, located on the eastern edge of downtown has been redeveloped into a pedestrian-oriented arts, culture and entertainment neighbourhood.[99]		Toronto encompasses a geographical area formerly administered by many separate municipalities. These municipalities have each developed a distinct history and identity over the years, and their names remain in common use among Torontonians. Former municipalities include East York, Etobicoke, Forest Hill, Mimico, North York, Parkdale, Scarborough, Swansea, Weston and York. Throughout the city there exist hundreds of small neighbourhoods and some larger neighbourhoods covering a few square kilometres.		The many residential communities of Toronto express a character distinct from that of the skyscrapers in the commercial core. Victorian and Edwardian-era residential buildings can be found in enclaves such as Rosedale, Cabbagetown, The Annex, and Yorkville. The Wychwood Park neighbourhood, historically significant for the architecture of its homes, and for being one of Toronto's earliest planned communities, was designated as an Ontario Heritage Conservation district in 1985.[100] The Casa Loma neighbourhood is named after Casa Loma, a castle built in 1911 by Sir Henry Pellat, complete with gardens, turrets, stables, an elevator, secret passages, and a bowling alley.[101] Spadina House is a 19th-century manor that is now a museum.[102]		The pre-amalgamation City of Toronto covers the area generally known as downtown, but also older neighbourhoods to the east, west, and north of downtown. It includes the core of Toronto and remains the most densely populated part of the city. The Financial District contains the First Canadian Place, Toronto-Dominion Centre, Scotia Plaza, Royal Bank Plaza, Commerce Court and Brookfield Place. This area includes, among others, the neighbourhoods of St. James Town, Garden District, St. Lawrence, Corktown, and Church and Wellesley. From that point, the Toronto skyline extends northward along Yonge Street.		Old Toronto is also home to many historically wealthy residential enclaves, such as Yorkville, Rosedale, The Annex, Forest Hill, Lawrence Park, Lytton Park, Deer Park, Moore Park, and Casa Loma, most stretching away from downtown to the north. East and west of Downtown, neighbourhoods such as Kensington Market, Chinatown, Leslieville, Cabbagetown and Riverdale are home to bustling commercial and cultural areas as well as communities of artists with studio lofts, with many middle- and upper-class professionals. Other neighbourhoods in the central city retain an ethnic identity, including two smaller Chinatowns, the Greektown area, Little Italy, Portugal Village, and Little India, along with others.		The inner suburbs are contained within the former municipalities of York and East York. These are mature and traditionally working-class areas, consisting primarily of post–World War I small, single-family homes and small apartment blocks. Neighbourhoods such as Crescent Town, Thorncliffe Park, Weston, and Oakwood–Vaughan consist mainly of high-rise apartments, which are home to many new immigrant families. During the 2000s, many neighbourhoods have become ethnically diverse and have undergone gentrification as a result of increasing population, and a housing boom during the late 1990s and first two decades of the 21st century. The first neighbourhoods affected were Leaside and North Toronto, gradually progressing into the western neighbourhoods in York. Some of the area's housing is in the process of being replaced or remodelled.		The outer suburbs comprising the former municipalities of Etobicoke (west), Scarborough (east) and North York (north) largely retain the grid plan laid before post-war development. Sections were long established and quickly growing towns before the suburban housing boom began and the emergence of metropolitan government, existing towns or villages such as Mimico, Islington and New Toronto in Etobicoke; Willowdale, Newtonbrook and Downsview in North York; Agincourt, Wexford and West Hill in Scarborough where suburban development boomed around or between these and other towns beginning in the late 1940s. Upscale neighbourhoods were built such as the Bridle Path in North York, the area surrounding the Scarborough Bluffs in Guildwood, and most of central Etobicoke, such as Humber Valley Village, and The Kingsway. One of largest and earliest "planned communities" was Don Mills, parts of which were first built in the 1950s.[103] Phased development, mixing single-detached housing with higher-density apartment blocks, became more popular as a suburban model of development. Over the late 20th century and early 21st century, North York City Centre, Etobicoke City Centre and Scarborough City Centre have emerged as secondary business districts outside Downtown Toronto. High-rise development in these areas has given the former municipalities distinguishable skylines of their own with high-density transit corridors serving them.		In the 1800s, a thriving industrial area developed around Toronto Harbour and lower Don River mouth, linked by rail and water to Canada and the United States. Examples included the Gooderham and Worts Distillery, Canadian Malting Company, the Toronto Rolling Mills, the Union Stockyards and the Davies pork processing facility (the inspiration for the "Hogtown" nickname). This industrial area expanded west along the harbour and rail lines and was supplemented by the infilling of the marshlands on the east side of the harbour to create the Port Lands. A garment industry developed along lower Spadina Avenue, the "Fashion District". Beginning in the late 19th century, industrial areas were set up on the outskirts, such as West Toronto/The Junction, where the Stockyards relocated in 1903. The Great Fire of 1904 destroyed a large amount of industry in the downtown. Some of the companies moved west along King Street, some as far west as Dufferin Street; where the large Massey-Harris farm equipment manufacturing complex was located. Over time, pockets of industrial land mostly followed rail lines and later highway corridors as the city grew outwards. This trend continues to this day, the largest factories and distribution warehouses are located in the suburban environs of Peel and York Regions; but also within the current city: Etobicoke (concentrated around Pearson Airport), North York, and Scarborough.		Many of Toronto's former industrial sites close to (or in) Downtown have been redeveloped including parts of the Toronto waterfront, the rail yards west of downtown, and Liberty Village, the Massey-Harris district and large-scale development is underway in the West Don Lands. The Gooderham & Worts Distillery produced spirits until 1990, and is preserved today as the "Distillery District," the largest and best-preserved collection of Victorian industrial architecture in North America. The District is a national heritage site; it was listed by National Geographic magazine as a "top pick" in Canada for travellers. Some industry remains in the area, including the Redpath Sugar Refinery. Similar areas that still retain their post-industrial character, but are now largely residential are the Fashion District, Corktown, and parts of South Riverdale and Leslieville. Toronto still has some active older industrial areas, such as Brockton Village, Mimico and New Toronto. In the west end of Old Toronto and York, the Weston/Mount Dennis and The Junction areas still contain factories, meat-packing facilities and railyards close to medium-density residential, although the Union Stockyards moved out in the late 20th Century.		The "brownfield" industrial area of the Port Lands, on the east side of the harbour, is one area planned for redevelopment.[104] Formerly a marsh that was filled in to create industrial space, it was never intensely developed, its land unsuitable for large-scale development, because of flooding and unstable soil.[105] It still contains numerous industrial uses, such as the Portlands Energy Centre power plant, some port facilities, some movie and TV production studios, a concrete processing facility and various low-density industrial facilities. The Waterfront Toronto agency has developed plans for a naturalized mouth to the Don River and to create a flood barrier around the Don, making more of the land on the harbour suitable for higher-value residential and commercial development.[106] A former chemicals plant site along the Don River is slated to become a large commercial complex and transportation hub.		Toronto has a diverse array of public spaces, from city squares to public parks overlooking ravines. Nathan Phillips Square is the city's main square in downtown, and forms the entrance to City Hall. Yonge-Dundas Square, near City Hall, has also gained attention in recent years as one of the busiest gathering spots in the city. Other squares include Harbourfront Square, on the Toronto waterfront, and the civic squares at the former city halls of the defunct Metropolitan Toronto, most notably Mel Lastman Square in North York. The Toronto Public Space Committee is an advocacy group concerned with the city's public spaces. In recent years, Nathan Phillips Square has been refurbished with new facilities, and the central waterfront along Queen's Quay West has been updated recently with a new street architecture and a new square next to Harbourfront Centre.		There are many large downtown parks, which include Allan Gardens, Christie Pits, Grange Park, Little Norway Park, Moss Park, Queen's Park, Riverdale Park and Trinity Bellwoods Park. An almost hidden park is the compact Cloud Gardens,[107] which has both open areas and a glassed-in greenhouse, near Queen and Yonge. South of downtown are two large parks on the waterfront: Tommy Thompson Park on the Leslie Street Spit, which has a nature preserve, is open on weekends; and the Toronto Islands, accessible from downtown by ferry. Large parks in the outer areas include High Park, Humber Bay Park, Centennial Park, Downsview Park, Guild Park and Gardens, Morningside Park and Rouge Park. Toronto also operates several public golf courses. Most ravine lands and river bank floodplains in Toronto are public parklands. After Hurricane Hazel in 1954, construction of buildings on floodplains was outlawed, and private lands were bought for conservation. In 1999, Downsview Park, a former military base in North York, initiated an international design competition to realize its vision of creating Canada's first national urban park. The winner, "Tree City", was announced in May 2000. Approximately 8,000 hectares (20,000 acres), or 12.5% of Toronto's land base is maintained parkland.[108] Toronto's largest park is Morningside Park, which is 241.46 hectares (596.7 acres) in size.[108]		In the winter, Nathan Phillips Square, Harbourfront Centre, and Mel Lastman Square feature popular rinks for public ice-skating. Etobicoke's Colonel Sam Smith Trail opened in 2011 and is Toronto's first skating trail. Centennial Park and Earl Bales Park offer outdoor skiing and snowboarding slopes with a chairlift, rental facilities, and lessons. Several parks have marked cross-country skiing trails.		Toronto theatre and performing arts scene has more than fifty ballet and dance companies, six opera companies, two symphony orchestras and a host of theatres. The city is home to the National Ballet of Canada, the Canadian Opera Company, the Toronto Symphony Orchestra, the Canadian Electronic Ensemble, and the Canadian Stage Company. Notable performance venues include the Four Seasons Centre for the Performing Arts, Roy Thomson Hall, the Princess of Wales Theatre, the Royal Alexandra Theatre, Massey Hall, the Toronto Centre for the Arts, the Elgin and Winter Garden Theatres and the Sony Centre for the Performing Arts (originally the "O'Keefe Centre" and formerly the "Hummingbird Centre").		Ontario Place features the world's first permanent IMAX movie theatre, the Cinesphere,[109] as well as the Budweiser Stage, an open-air venue for music concerts. In spring 2012, Ontario Place closed after a decline in attendance over the years. Although the Molson Amphitheatre and harbour still operate, the park and Cinesphere are no longer in use. There are plans to revitalise Ontario Place.[110]		Each summer, the Canadian Stage Company presents an outdoor Shakespeare production in Toronto's High Park called "Dream in High Park". Canada's Walk of Fame acknowledges the achievements of successful Canadians, with a series of stars on designated blocks of sidewalks along King Street and Simcoe Street.		The production of domestic and foreign film and television is a major local industry. Toronto as of 2011[update] ranks as the third largest production centre for film and television after Los Angeles and New York City,[111] sharing the nickname "Hollywood North" with Vancouver.[112][113][114] The Toronto International Film Festival is an annual event celebrating the international film industry. Another prestigious film festival is the Toronto Student Film Festival, that screens the works of students ages 12–18 from many different countries across the globe.		Toronto's Scotiabank Caribbean Carnival (also known as Caribana) takes place from mid-July to early August of every summer.[115] Primarily based on the Trinidad and Tobago Carnival, the first Caribana took place in 1967 when the city's Caribbean community celebrated Canada's Centennial. More than forty years later, it has grown to attract one million people to Toronto's Lake Shore Boulevard annually. Tourism for the festival is in the hundred thousands, and each year, the event generates over $400 million in revenue into Ontario's economy.[116]		One of the largest events in the city, Pride Week takes place in late June, and is one of the largest LGBT festivals in the world.		The Royal Ontario Museum (ROM) is a museum of world culture and natural history. The Toronto Zoo,[118][119] is home to over 5,000 animals representing over 460 distinct species. The Art Gallery of Ontario contains a large collection of Canadian, European, African and contemporary artwork, and also plays host to exhibits from museums and galleries all over the world. The Gardiner Museum of ceramic art is the only museum in Canada entirely devoted to ceramics, and the Museum's collection contains more than 2,900 ceramic works from Asia, the Americas, and Europe. The city also hosts the Ontario Science Centre, the Bata Shoe Museum, and Textile Museum of Canada. Other prominent art galleries and museums include the Design Exchange, the Museum of Inuit Art, the TIFF Bell Lightbox, the Museum of Contemporary Canadian Art, the Institute for Contemporary Culture, the Toronto Sculpture Garden, the CBC Museum, the Redpath Sugar Museum, the University of Toronto Art Centre, Hart House, the TD Gallery of Inuit Art and the Aga Khan Museum. The city also runs its own museums, which include the Spadina House.		The Don Valley Brick Works is a former industrial site that opened in 1889, and was partly restored as a park and heritage site in 1996, with further restoration and reuse being completed in stages since then. The Canadian National Exhibition ("The Ex") is held annually at Exhibition Place, and it is the oldest annual fair in the world. The Ex has an average attendance of 1.25 million.[120]		City shopping areas include the Yorkville neighbourhood, Queen West, Harbourfront, the Entertainment District, the Financial District, and the St. Lawrence Market neighbourhood. The Eaton Centre is Toronto's most popular tourist attraction with over 52 million visitors annually.[121]		Greektown on the Danforth is home to the annual "Taste of the Danforth" festival which attracts over one million people in 2½ days.[122] Toronto is also home to Casa Loma, the former estate of Sir Henry Pellatt, a prominent Toronto financier, industrialist and military man. Other notable neighbourhoods and attractions include The Beaches, the Toronto Islands, Kensington Market, Fort York, and the Hockey Hall of Fame.		Toronto is represented in six major league sports, with teams in the National Hockey League, Major League Baseball, National Basketball Association, Canadian Football League, Major League Soccer and Canadian Women's Hockey League. It was formerly represented in a seventh, the USL W-League, until that announced on November 6, 2015 that it would cease operation ahead of 2016 season.[123][124] The city's major sports venues include the Air Canada Centre, Rogers Centre (formerly SkyDome), Ricoh Coliseum, and BMO Field.		Toronto is home to the Toronto Maple Leafs, one of the National Hockey League's Original Six clubs, and has also served as home to the Hockey Hall of Fame since 1958. The city had a rich history of ice hockey championships. Along with the Maple Leafs' 13 Stanley Cup titles, the Toronto Marlboros and St. Michael's College School-based Ontario Hockey League teams, combined, have won a record 12 Memorial Cup titles. The Toronto Marlies of the American Hockey League also play in Toronto at Ricoh Coliseum and are the farm team for the Maple Leafs.		The city is home to the Toronto Blue Jays professional baseball team of the Major League Baseball (MLB). The team has won two World Series titles (1992, 1993). The Blue Jays play their home games at the Rogers Centre, in the downtown core. Toronto has a long history of minor-league professional baseball dating back to the 1800s, culminating in the baseball Maple Leafs, whose owner first proposed a MLB team for Toronto.		The Toronto Raptors entered the National Basketball Association in 1995, and have since earned seven playoff spots and three Atlantic Division titles in 20 seasons. The Raptors are the only NBA team with their own television channel, NBA TV Canada. They and the Maple Leafs play their home games at the Air Canada Centre. In 2016, Toronto hosted the 65th NBA All-Star game, the first to be held outside the United States.[125]		The city is represented in the Canadian Football League by the Toronto Argonauts, who have won 16 Grey Cup titles. Toronto played host to the 95th Grey Cup in 2007, the first held in the city since 1992. Later in 2012, while hosting and participating in the 100th Grey Cup, they won the game to the delight of the home fans.		Toronto is represented in Major League Soccer by the Toronto FC, who have won four Canadian Championship titles. They share BMO Field with the Toronto Argonauts. Toronto has a high level of participation in soccer across the city at several smaller stadiums and fields. Toronto FC entered the league as an expansion team.		The Toronto Wolfpack became Canada's first professional rugby league team and the world's first transatlantic professional sports team when they began play in the Rugby Football League's League One competition in 2017.[126]		The Toronto Rock are the city's National Lacrosse League team. They won five Champion's Cup titles in seven years in the late 1990s and early first decade of the 21st century, appearing in an NLL record five straight championship games from 1999 to 2003, and are currently first all-time in the number of Champion's Cups won. The Rock share the Air Canada Centre with the Maple Leafs and the Raptors.		Toronto has hosted several National Football League exhibition games at the Rogers Centre. Ted Rogers leased the Buffalo Bills from Ralph Wilson for the purposes of having the Bills play eight home games in the city between 2008 and 2013. Toronto was home to the International Bowl, an NCAA sanctioned post-season football game that pitted a Mid-American Conference team against a Big East Conference team. From 2007 to 2010, the game was played at Rogers Centre annually in January.		Toronto is home to the Toronto Rush, a semi-professional ultimate team that competes in the American Ultimate Disc League (AUDL).[127][128] Ultimate (disc), in Canada, has its beginning roots in Toronto, with 3300 players competing annually in the Toronto Ultimate Club (League).[129]		Toronto, along with Montreal, hosts an annual tennis tournament called the Canadian Open (not to be confused with the identically named golf tournament) between the months of July and August. In odd-numbered years, the men's tournament is held in Montreal, while the women's tournament is held in Toronto, and vice versa in even-numbered years.		The city hosts the annual Honda Indy Toronto car race, part of the IndyCar Series schedule, held on a street circuit at Exhibition Place. It was known previously as the Champ Car's Molson Indy Toronto from 1986 to 2007. Both thoroughbred and standardbred horse racing events are conducted at Woodbine Racetrack in Rexdale.		Toronto hosted the 2015 Pan American Games in July 2015, and the 2015 Parapan American Games in August 2015. It beat the cities of Lima, Peru and Bogotá, Colombia, to win the rights to stage the games.[130] The games were the largest multi-sport event ever to be held in Canada (in terms of athletes competing), double the size of the 2010 Winter Olympics in Vancouver.[131]		Toronto was a candidate city for the 1996 and 2008 Summer Olympics, which were awarded to Atlanta and Beijing respectively.[132]		Historic sports clubs of Toronto include the Granite Club (established in 1836), the Royal Canadian Yacht Club (established in 1852), the Toronto Cricket Skating and Curling Club (established before 1827), the Argonaut Rowing Club (established in 1872), the Toronto Lawn Tennis Club (established in 1881), and the Badminton and Racquet Club (established in 1924).		Toronto is Canada's largest media market,[133] and has four conventional dailies, two alt-weeklies, and three free commuter papers in a greater metropolitan area of about 6 million inhabitants. The Toronto Star and the Toronto Sun are the prominent daily city newspapers, while national dailies The Globe and Mail and the National Post are also headquartered in the city. The Toronto Star, The Globe and Mail, and National Post are broadsheet newspapers. Metro and 24 Hours are distributed as free commuter newspapers. Several magazines and local newspapers cover Toronto, including Now and Toronto Life, while numerous magazines are produced in Toronto, such as Canadian Business, Chatelaine, Flare and Maclean's.		Toronto contains the headquarters of the major English-language Canadian television networks CBC, CTV, City, Global, The Sports Network (TSN) and Sportsnet. Much (formerly MuchMusic), M3 (formerly MuchMore) and MTV Canada are the main music television channels based in the city, though they no longer primarily show music videos as a result of channel drift.		Toronto is an international centre for business and finance. Generally considered the financial capital of Canada, Toronto has a high concentration of banks and brokerage firms on Bay Street, in the Financial District. The Toronto Stock Exchange is the world's seventh-largest stock exchange by market capitalization.[134] The five largest financial institutions of Canada, collectively known as the Big Five, have national offices in Toronto.[50]		The city is an important centre for the media, publishing, telecommunication, information technology and film production industries; it is home to Bell Media, Rogers Communications, and Torstar. Other prominent Canadian corporations in the Greater Toronto Area include Magna International, Celestica, Manulife, Sun Life Financial, the Hudson's Bay Company, and major hotel companies and operators, such as Four Seasons Hotels and Fairmont Hotels and Resorts.		Although much of the region's manufacturing activities take place outside the city limits, Toronto continues to be a wholesale and distribution point for the industrial sector. The city's strategic position along the Quebec City–Windsor Corridor and its road and rail connections help support the nearby production of motor vehicles, iron, steel, food, machinery, chemicals and paper. The completion of the Saint Lawrence Seaway in 1959 gave ships access to the Great Lakes from the Atlantic Ocean.		Toronto's unemployment rate was 6.7% as of July 2016.[135] According to the website Nimbeo Toronto's cost of living index ranked it tenth in Canada in 2016.[136]		The city's population grew by 4% (96,073 residents) between 1996 and 2001, 1% (21,787 residents) between 2001 and 2006, and 4.3% (111,779 residents) between 2006 and 2011. Persons aged 14 years and under made up 17.5% of the population, and those aged 65 years and over made up 13.6%. The median age was 36.9 years. Foreign-born people made up 49.9% of the population.[138] The city's gender population is 48% male and 52% female.[139] Women outnumber men in all age groups over 20.[140] In 2011, 49.1% of the residents of the city proper belonged to a visible minority group,[34] and visible minorities are projected to comprise a majority in the Toronto CMA by 2017.[141] In 1981, Toronto's visible minority population was 13.6%.[142]		According to the United Nations Development Programme, Toronto has the second-highest percentage of constant foreign-born population among world cities, after Miami, Florida. While Miami's foreign-born population has traditionally consisted primarily of Cubans and other Latin Americans, no single nationality or culture dominates Toronto's immigrant population, placing it among the most diverse cities in the world.[138] Visible minorities are projected to increase to 63% of the city's population by 2031.[143] Over 100,000 immigrants arrive in the Greater Toronto Area annually.[144]		In the 2011 Canadian census, the most common ethnic origins in the city of Toronto were as follows:		Toronto has a racially diverse population. In 2011 its population defined itself thus:[34]		This diversity is reflected in Toronto's ethnic neighbourhoods, which include Chinatown, Corso Italia, Greektown, Kensington Market (alternative/counterculture), Koreatown, Little India, Little Italy, Little Jamaica, Little Portugal and Roncesvalles (Polish community).[146]		In 2011, the most commonly reported religion in Toronto was Christianity, adhered to by 54.1% of the population. A plurality, 28.2%, of the city's population was Catholic, followed by Protestants (11.9%), Christian Orthodox (4.3%), and members of other Christian denominations (9.7%). With the city's significant number of Methodist Christians, Toronto was historically referred to as the Methodist Rome.[147]		Other religions significantly practised in the city are Islam (8.2%), Hinduism (5.6%), Judaism (3.8%), Buddhism (2.7%), and Sikhism (0.8%). Those with no religious affiliation made up 24.2% of Toronto's population.[34]		While English is the predominant language spoken by Torontonians, many other languages have considerable numbers of local speakers.[148] The varieties of Chinese and Italian are the second and third most widely spoken languages at work.[149][150] Despite Canada's official bilingualism, while 9.7% of Ontario's Francophones live in Toronto, only 0.6% of the population reported French as a singular language spoken most often at home; meanwhile 64% reported speaking predominantly English only and 28.3% primarily used a non-official language; 7.1% reported commonly speaking multiple languages at home.[151][152] The city's 9-1-1 emergency services are equipped to respond in over 150 languages.[153]		Toronto is a single-tier municipality governed by a mayor–council system. The structure of the municipal government is stipulated by the City of Toronto Act. The Mayor of Toronto is elected by direct popular vote to serve as the chief executive of the city. The Toronto City Council is a unicameral legislative body, comprising 44 councillors representing geographical wards throughout the city.[154] The mayor and members of the city council serve four-year terms without term limits. (Until the 2006 municipal election, the mayor and city councillors served three-year terms.) However, on November 18, 2013, council voted to modify the city's government by transferring many executive powers from the mayor to the deputy mayor, and itself.[155]		As of 2016, the city council has twelve standing committees, each consisting of a Chairman, (some have a vice-chair), and a number of councillors.[156] The Mayor names the committee chairs and the remaining membership of the committees is appointed by City Council. An executive committee is formed by the chairs of each of standing committee, along with the mayor, the deputy mayor and four other councillors. Councillors are also appointed to oversee the Toronto Transit Commission and the Toronto Police Services Board.		The city has four community councils that consider local matters. City Council has delegated final decision-making authority on local, routine matters, while others—like planning and zoning issues—are recommended to the city council. Each city councillor serves as a member on a community council.[156]		There are about 40 subcommittees and advisory committees appointed by the city council. These bodies are made up of city councillors and private citizen volunteers. Examples include the Pedestrian Committee, Waste Diversion Task Force 2010, and the Task Force to Bring Back the Don.[157]		Toronto had an operating budget of C$7.6 billion in 2006.[158] The city receives funding from the Government of Ontario in addition to tax revenues and user fees, spending 36% on provincially mandated programmes, 53% on major municipal purposes such as the Toronto Public Library and the Toronto Zoo, and 11% on capital financing and non-programme expenditures.[159]		The low crime rate in Toronto has resulted in the city having a reputation as one of the safest major cities in North America.[160][161][162] For instance, in 2007, the homicide rate for Toronto was 3.3 per 100,000 people, compared with Atlanta (19.7), Boston (10.3), Los Angeles (10.0), New York City (6.3), Vancouver (3.1), and Montreal (2.6). Toronto's robbery rate also ranks low, with 207.1 robberies per 100,000 people, compared with Los Angeles (348.5), Vancouver (266.2), New York City (265.9), and Montreal (235.3).[163][164][165][166][167][168] Toronto has a comparable rate of car theft to various U.S. cities, although it is not among the highest in Canada.[160]		Toronto recorded its largest number of homicides in 1991 with 89, a rate of 3.9 per 100,000.[169][170] In 2005, Toronto media coined the term "Year of the Gun", because of a record number of gun-related homicides, 52, out of 80 homicides in total.[162][171] The total number of homicides dropped to 70 in 2006, that year, nearly 2,000 people in Toronto were victims of a violent gun-related crime, about one-quarter of the national total.[172] 84 homicides were committed in 2007, roughly half of which involved guns. Gang-related incidents have also been on the rise; between the years of 1997 and 2005, over 300 gang-related homicides have occurred. As a result, the Ontario government developed an anti-gun strategy.[173] In 2011, Toronto's murder rate plummeted to 45 murders—nearly a 26% drop from the previous year. The 45 homicides were the lowest number the city has recorded since 1986.[174] While subsequent years did see a return to higher rates, the nearly flat line of 56 homicides in 2012 and 57 in both 2013 and 2014 continued to be a significant improvement over the previous decade; and the year-to-date figure of 47 murders at November 23, 2015 continued that overall trend of improvement.[175]		Toronto has a number of post-secondary academic institutions. The University of Toronto, established in 1827, is Canada's largest university and has two satellite campuses, one of which is located in the city's eastern district of Scarborough while the other is located in the neighbouring city of Mississauga. York University, Canada's third-largest university, founded in 1959, is located in the northwest part of the city. Toronto is also home to Ryerson University, OCAD University, and the University of Guelph-Humber.		There are four diploma- and degree-granting colleges in Toronto. These are Seneca College, Humber College, Centennial College and George Brown College. The city is also home to a satellite campus of the francophone Collège Boréal.		The Royal Conservatory of Music, which includes the Glenn Gould School, is a school of music located downtown. The Canadian Film Centre is a film, television and new media training institute founded by filmmaker Norman Jewison. Tyndale University College and Seminary is a Christian post-secondary institution and Canada's largest seminary.		The Toronto District School Board (TDSB) operates 588 public schools. Of these, 451 are elementary and 116 are secondary (high) schools.[176] Additionally, the Toronto Catholic District School Board manages the city's publicly funded Roman Catholic schools, while the Conseil scolaire de district du Centre-Sud-Ouest and the Conseil scolaire de district catholique Centre-Sud manage public and Roman Catholic French-language schools, respectively. There are also numerous private university-preparatory schools including the University of Toronto Schools, the Upper Canada College and Havergal College.		The Toronto Public Library[177] consists of 100[178] branches with more than 11 million items in its collection.[179]		Toronto is home to 20 public hospitals, including: the Hospital for Sick Children, Mount Sinai Hospital, St. Michael's Hospital, North York General Hospital, Toronto General Hospital, Toronto Western Hospital, St. Joseph's Health Centre, Rouge Valley Health System, The Scarborough Hospital, Sunnybrook Health Sciences Centre, Centre for Addiction and Mental Health (CAMH), and Princess Margaret Cancer Centre, as well as the University of Toronto Faculty of Medicine.		In 2007, Toronto was reported as having some of the longer average ER wait times in Ontario. Toronto hospitals at the time employed a system of triage to ensure life-threatening injuries receive rapid treatment.[180] After initial screening, initial assessments by physicians were completed within the waiting rooms themselves for greater efficiency, within a median of 1.2 hours. Tests, consultations, and initial treatments were also provided within waiting rooms. 50% of patients waited 4 hours before being transferred from the emergency room to another room.[180] The least-urgent 10% of cases wait over 12 hours.[180] The extended waiting-room times experienced by some patients were attributed to an overall shortage of acute care beds.[180]		Toronto's Discovery District[181] is a centre of research in biomedicine. It is located on a 2.5-square-kilometre (620-acre) research park that is integrated into Toronto's downtown core. It is also home to the Medical and Related Sciences Centre (MaRS),[182] which was created in 2000 to capitalize on the research and innovation strength of the Province of Ontario. Another institute is the McLaughlin Centre for Molecular Medicine (MCMM).[183]		Toronto also has some specialized hospitals located outside of the downtown core. These hospitals include Baycrest for geriatric care and Holland Bloorview Kids Rehabilitation Hospital for children with disabilities.		Toronto is also host to a wide variety of health-focused non-profit organizations that work to address specific illnesses for Toronto, Ontario and Canadian residents. Organizations include: The Crohn's and Colitis Foundation of Canada, the Heart and Stroke Foundation of Canada, the Canadian Cancer Society, the Alzheimer Society of Canada, Alzheimer Society of Ontario and Alzheimer Society of Toronto, all situated in the same office at Yonge and Eglinton, the Leukemia & Lymphoma Society of Canada, the Canadian Breast Cancer Foundation, the Canadian Foundation for AIDS Research, Cystic Fibrosis Canada, the Canadian Mental Health Association, the ALS Society of Canada, and many others. These organizations work to help people within the GTA, Ontario or Canada who are affected by these illnesses. As well, most engage in fundraising to promote research, services, and public awareness.		Toronto is a central transportation hub for road, rail and air networks in Southern Ontario. There are many forms of transport in the city of Toronto, including highways and public transit. Toronto also has an extensive network of bicycle lanes and multi-use trails and paths.		Toronto's main public transportation system is operated by the Toronto Transit Commission (TTC).[69] The backbone of its public transport network is the Toronto subway system, which includes three heavy-rail rapid transit lines spanning the city, including the U-shaped Line 1 and east-west Line 2. A light metro line also exists, exclusively serving the eastern district of Scarborough but discussion is underway to replace it with a heavy-rail line.		The TTC also operates an extensive network of buses and streetcars, with the latter serving the downtown core, and buses providing service to many parts of the city not served by the sparse subway network. TTC buses and streetcars use the same fare system as the subway, and many subway stations offer a fare-paid area for transfers between rail and surface vehicles.		There have been numerous plans to extend the subway and implement light-rail lines, but many efforts have been thwarted by budgetary concerns. Since July 2011, the only subway-related work is the Spadina subway (line 1) extension north of Sheppard West Station (formerly named Downsview) to Vaughan Metropolitan Centre. By November 2011, construction on Line 5 Eglinton began. Line 5 is scheduled to finish by 2021.[184][185] In 2015, the Ontario government promised to fund the Finch West LRT (line 7) which is to be completed by 2021.[186]		Toronto's public transit network also connects to other municipal networks such as York Region Transit, Viva, Durham Region Transit, and MiWay.		The Government of Ontario also operates a commuter rail and bus transit system called GO Transit in the Greater Toronto Area. GO Transit carries over 250,000 passengers every weekday (2013) and 57 million annually, with a majority of them travelling to or from Union Station.[187][188] GO Transit is implementing RER (Regional Express Rail) into its system.[189]		Canada's busiest airport, Toronto Pearson International Airport (IATA: YYZ), straddles the city's western boundary with the suburban city of Mississauga. Limited commercial and passenger service to nearby destinations in Canada and the USA is also offered from the Billy Bishop Toronto City Airport (IATA: YTZ) on the Toronto Islands, southwest of downtown. Toronto/Buttonville Municipal Airport (IATA: YKZ) in Markham provides general aviation facilities. Toronto/Downsview Airport (IATA: YZD), near the city's north end, is owned by de Havilland Canada and serves the Bombardier Aerospace aircraft factory.		The Union Pearson Express is a train service that provides a direct link between Pearson International and Union Station. It began carrying passengers in June 2015.		Hamilton's John C. Munro International Airport (IATA: YHM) and Buffalo's Buffalo Niagara International Airport (IATA: BUF) also serve as alternate airports for the Toronto area in addition to serving their respective cities.		Toronto Union Station serves as the hub for VIA Rail's intercity services in Central Canada, and includes services to various parts of Ontario, Corridor services to Montreal and national capital Ottawa, and long distance services to Vancouver and New York City.		The Toronto Bus Terminal in downtown Toronto also serves as a hub for intercity bus services in Southern Ontario, served by multiple companies and providing a comprehensive network of services in Ontario and neighboring provinces and states. GO Transit, the regional commuter rail operator also provides some intercity services from Union Station Bus Terminal as part of the commuter network.		Currently there are no scheduled intercity ferry services departing from Toronto. A ferry service across Lake Ontario previously connected Toronto with Rochester, New York, but the service was cancelled in 2006.[190]		The grid of major city streets was laid out by a concession road system, in which major arterial roads are 6,600 ft (2.0 km) apart (with some exceptions, particularly in Scarborough and Etobicoke, as they were originally separate townships). Major east-west arterial roads are generally parallel with the Lake Ontario shoreline, and major north-south arterial roads are roughly perpendicular to the shoreline, though slightly angled north of Eglinton Avenue. This arrangement is sometimes broken by geographical accidents, most notably the Don River ravines.		Toronto's grid north is approximately 18.5° to the west of true north.		There are a number of municipal expressways and provincial highways that serve Toronto and the Greater Toronto Area. In particular, Highway 401 bisects the city from west to east, bypassing the downtown core. It is the busiest road in North America,[191] and one of the busiest highways in the world.[192][193] Other provincial highways include Highway 400 which connects the city with Northern Ontario and beyond and Highway 404, an extension of the Don Valley Parkway into the northern suburbs. The Queen Elizabeth Way (QEW), North America's first divided intercity highway, terminates at Toronto's western boundary and connects Toronto to Niagara Falls and Buffalo. The main municipal expressways in Toronto include the Gardiner Expressway, the Don Valley Parkway, and to some extent, Allen Road. The Greater Toronto Area suffers from chronic traffic congestion problems, and Toronto has the second worst traffic congestion in Canada after Vancouver.[194]		
Catholicism portal		Augustine of Hippo (/ɔːˈɡʌstᵻn/ or /ˈɔːɡəstiːn/; 13 November 354 – 28 August 430)[4] was an early Christian theologian and philosopher[5] whose writings influenced the development of Western Christianity and Western philosophy. He was the bishop of Hippo Regius in north Africa and is viewed as one of the most important Church Fathers in Western Christianity for his writings in the Patristic Era. Among his most important works are The City of God and Confessions.		According to his contemporary, Jerome, Augustine "established anew the ancient Faith."[note 1] In his early years, he was influenced by Manichaeism and afterward by the neo-Platonism of Plotinus. After his baptism and conversion to Christianity in 386, Augustine developed his own approach to philosophy and theology, accommodating a variety of methods and perspectives.[6] Believing that the grace of Christ was indispensable to human freedom, he helped formulate the doctrine of original sin and made seminal contributions to the development of just war theory. When the Western Roman Empire began to disintegrate, Augustine developed the concept of the Church as a spiritual City of God, distinct from the material Earthly City.[7] His thoughts profoundly influenced the medieval worldview. The segment of the Church that adhered to the concept of the Trinity as defined by the Council of Nicaea and the Council of Constantinople [8] closely identified with Augustine's On the Trinity.		Augustine is recognized as a saint in the Catholic Church, the Eastern Christian Church, and the Anglican Communion and as a preeminent Doctor of the Church. He is also the patron of the Augustinians. His memorial is celebrated on 28 August, the day of his death. Augustine is the patron saint of brewers, printers, theologians, the alleviation of sore eyes, and a number of cities and dioceses.[9] Many Protestants, especially Calvinists and Lutherans, consider him to be one of the theological fathers of the Protestant Reformation due to his teachings on salvation and divine grace.[10][11][12] Lutherans, and Martin Luther in particular, have held Augustine in preeminence (after the Bible and St. Paul). Luther himself was a member of the Order of the Augustinian Eremites (1505–1521).		In the East, some of his teachings are disputed and have in the 20th century in particular come under attack by such theologians as John Romanides.[13] But other theologians and figures of the Eastern Orthodox Church have shown significant appropriation of his writings, chiefly Georges Florovsky.[14] The most controversial doctrine surrounding his name is the filioque,[15] which has been rejected by the Orthodox Church.[16] Other disputed teachings include his views on original sin, the doctrine of grace, and predestination.[15] Nevertheless, though considered to be mistaken on some points, he is still considered a saint, and has even had influence on some Eastern Church Fathers, most notably Saint Gregory Palamas.[17] In the Orthodox Church his feast day is celebrated on 15 June.[15][18] Church scholar and historian Diarmaid MacCulloch writes "his impact on Western Christian thought can hardly be overstated; only his beloved example Paul of Tarsus, has been more influential, and Westerners have generally seen Paul through Augustine's eyes."[19]						Augustine of Hippo (/ɔːˈɡʌstᵻn/,[4] /əˈɡʌstᵻn/,[20] or /ˈɔːɡʌstᵻn/;[21] Latin: Aurelius Augustinus Hipponensis;[note 2] 13 November 354 – 28 August 430), also known as Saint Augustine, Saint Austin,[22] (/ˈɔːstᵻn/ or /ˈɑːstᵻn/),[23] is known by various cognomens throughout the Christian world across its many denominations including Blessed Augustine,[24] and the Doctor of Grace[25] (Latin: Doctor gratiae)		Hippo Regius, where Augustine was the bishop, was in modern-day Annaba, Algeria, located in Numidia (Roman province of Africa).		Augustine was born in the year 354 AD in the municipium of Thagaste (now Souk Ahras, Algeria) in Roman Africa.[26][27] His mother, Monica or Monnica,[28] was a devout Christian; his father Patricius was a Pagan who converted to Christianity on his deathbed.[29] Scholars generally agree that Augustine and his family were Berbers, an ethnic group indigenous to North Africa,[30][31][32][33] but that they were heavily Romanized, speaking only Latin at home as a matter of pride and dignity.[30] In his writings, Augustine leaves some information as to the consciousness of his African heritage. For example, he refers to Apuleius as "the most notorious of us Africans,"[34] to Ponticianus as "a country man of ours, insofar as being African,"[35] and to Faustus of Mileve as "an African Gentleman."[36]		Augustine's family name, Aurelius, suggests that his father's ancestors were freedmen of the gens Aurelia given full Roman citizenship by the Edict of Caracalla in 212. Augustine's family had been Roman, from a legal standpoint, for at least a century when he was born.[37] It is assumed that his mother, Monica, was of Berber origin, on the basis of her name,[38][39] but as his family were honestiores, an upper class of citizens known as honorable men, Augustine's first language is likely to have been Latin.[38]		At the age of 11, Augustine was sent to school at Madaurus (now M'Daourouch), a small Numidian city about 19 miles (31 km) south of Thagaste. There he became familiar with Latin literature, as well as pagan beliefs and practices.[40] His first insight into the nature of sin occurred when he and a number of friends stole fruit they did not want from a neighborhood garden. He tells this story in his autobiography, The Confessions. He remembers that he did not steal the fruit because he was hungry, but because "it was not permitted."[41] His very nature, he says, was flawed. 'It was foul, and I loved it. I loved my own error—not that for which I erred, but the error itself."[41] From this incident he concluded the human person is naturally inclined to sin, and in need of the grace of Christ.		At the age of 17, through the generosity of his fellow citizen Romanianus,[42] Augustine went to Carthage to continue his education in rhetoric. It was while he was a student in Carthage that he read Cicero's dialogue Hortensius (now lost), which he described as leaving a lasting impression and sparking his interest in philosophy.[43] Although raised as a Christian, Augustine left the church to follow the Manichaean religion, much to his mother's despair.[44] As a youth Augustine lived a hedonistic lifestyle for a time, associating with young men who boasted of their sexual exploits. The need to gain their acceptance forced inexperienced boys like Augustine to seek or make up stories about sexual experiences.[45] It was during this period that he uttered his famous prayer, "Grant me chastity and continence, but not yet."[46]		At about the age of 19, Augustine began an affair with a young woman in Carthage. Though his mother wanted him to marry a person of his class, the woman remained his lover[47] for over fifteen years[48] and gave birth to his son Adeodatus,[49] who was viewed as extremely intelligent by his contemporaries. In 385, Augustine ended his relationship with his lover in order to prepare himself to marry a ten-year-old heiress. (He had to wait for two years because the legal age of marriage for women was twelve.) By the time he was able to marry her, however, he instead decided to become a celibate priest.[48][50]		Augustine was from the beginning a brilliant student, with an eager intellectual curiosity, but he never mastered Greek[51] —he tells us that his first Greek teacher was a brutal man who constantly beat his students, and Augustine rebelled and refused to study. By the time he realized that he needed to know Greek, it was too late; and although he acquired a smattering of the language, he was never eloquent with it. However, his mastery of Latin was another matter. He became an expert both in the eloquent use of the language and in the use of clever arguments to make his points.		Augustine taught grammar at Thagaste during 373 and 374. The following year he moved to Carthage to conduct a school of rhetoric and would remain there for the next nine years.[42] Disturbed by unruly students in Carthage, he moved to establish a school in Rome, where he believed the best and brightest rhetoricians practiced, in 383. However, Augustine was disappointed with the apathetic reception. It was the custom for students to pay their fees to the professor on the last day of the term, and many students attended faithfully all term, and then did not pay.		Manichaean friends introduced him to the prefect of the City of Rome, Symmachus, who while traveling through Carthage had been asked by the imperial court at Milan[52] to provide a rhetoric professor. Augustine won the job and headed north to take his position in Milan in late 384. Thirty years old, he had won the most visible academic position in the Latin world at a time when such posts gave ready access to political careers.		Although Augustine showed some fervour for Manichaeism, he was never an initiate or "elect", but an "auditor", the lowest level in the sect's hierarchy.[52] While still at Carthage a disappointing meeting with the Manichaean Bishop, Faustus of Mileve, a key exponent of Manichaean theology, started Augustine's scepticism of Manichaeanism.[52] In Rome, he reportedly turned away from Manichaeanism, embracing the scepticism of the New Academy movement. Because of his education, Augustine had great rhetorical prowess and was very knowledgeable of the philosophies behind many faiths.[53] At Milan, his mother's religiosity, Augustine's own studies in Neoplatonism, and his friend Simplicianus all urged him towards Christianity.[42] Initially Augustine was not strongly influenced by Christianity and its ideologies, but after coming in contact with Ambrose of Milan, Augustine reevaluated himself and was forever changed.		Like Augustine, Ambrose was a master of rhetoric, but older and more experienced.[54] Augustine was very much influenced by Ambrose, even more than by his own mother and others he admired. Augustine arrived in Milan and was immediately taken under the wing by Ambrose. Within his Confessions, Augustine states, "That man of God received me as a father would, and welcomed my coming as a good bishop should."[55]		Soon, their relationship grew, as Augustine wrote, "And I began to love him, of course, not at the first as a teacher of the truth, for I had entirely despaired of finding that in thy Church—but as a friendly man."[55] Augustine visited Ambrose in order to see if Ambrose was one of the greatest speakers and rhetoricians in the world. More interested in his speaking skills than the topic of speech, Augustine quickly discovered that Ambrose was a spectacular orator. Eventually, Augustine says that he was spiritually led into the faith of Christianity.[55]		Augustine's mother had followed him to Milan and arranged a marriage for him. Although Augustine accepted this marriage, for which he had to abandon his concubine, he was deeply hurt by the loss of his lover. He wrote, "My mistress being torn from my side as an impediment to my marriage, my heart, which clave to her, was racked, and wounded, and bleeding." Augustine confessed that he was not a lover of wedlock so much as a slave of lust, so he procured another concubine since he had to wait two years until his fiancée came of age. However, his emotional wound was not healed, even began to fester.[56]		There is evidence that Augustine may have considered this former relationship to be equivalent to marriage.[57] In his Confessions, he admitted that the experience eventually produced a decreased sensitivity to pain. Augustine eventually broke off his engagement to his eleven-year-old fiancée, but never renewed his relationship with either of his concubines. Alypius of Thagaste steered Augustine away from marriage, saying that they could not live a life together in the love of wisdom if he married. Augustine looked back years later on the life at Cassiciacum, a villa outside of Milan where he gathered with his followers, and described it as Christianae vitae otium – the Christian life of leisure.[58]		In late August of 386,[60] at the age of 31, after having heard and been inspired and moved by the story of Ponticianus's and his friends' first reading of the life of Saint Anthony of the Desert, Augustine converted to Christianity. As Augustine later told it, his conversion was prompted by a childlike voice he heard telling him to "take up and read" (Latin: tolle, lege), which he took as a divine command to open the Bible and read the first thing he saw. Augustine read from Paul's Epistle to the Romans – the "Transformation of Believers" section, consisting of chapters 12 to 15 – wherein Paul outlines how the Gospel transforms believers, and the believers' resulting behaviour. The specific part to which Augustine opened his Bible was Romans chapter 13, verses 13 and 14, to wit:		Not in rioting and drunkenness, not in chambering and wantonness, not in strife and envying, but put on the Lord Jesus Christ, and make no provision for the flesh to fulfill the lusts thereof.[61]		He later wrote an account of his conversion – his very transformation, as Paul described – in his Confessions (Latin: Confessiones), which has since become a classic of Christian theology and a key text in the history of autobiography. This work is an outpouring of thanksgiving and penitence. Although it is written as an account of his life, the Confessions also talks about the nature of time, causality, free will, and other important philosophical topics.[62] The following is taken from that work:		Late have I loved Thee, O Lord; and behold, Thou wast within and I without, and there I sought Thee. Thou was with me when I was not with Thee. Thou didst call, and cry, and burst my deafness. Thou didst gleam, and glow, and dispell my blindness. Thou didst touch me, and I burned for Thy peace. For Thyself Thou hast made us, And restless our hearts until in Thee they find their ease. Late have I loved Thee, Thou Beauty ever old and ever new.[62]		Ambrose baptized Augustine, along with his son Adeodatus, in Milan on Easter Vigil, April 24–25, 387.[63] A year later, in 388, Augustine completed his apology On the Holiness of the Catholic Church.[52] That year, also, Adeodatus and Augustine returned home to Africa.[42] Augustine's mother Monica died at Ostia, Italy, as they prepared to embark for Africa.[64] Upon their arrival, they began a life of aristocratic leisure at Augustine's family's property.[65][66] Soon after, Adeodatus, too, died.[67] Augustine then sold his patrimony and gave the money to the poor. The only thing he kept was the family house, which he converted into a monastic foundation for himself and a group of friends.[42]		In 391 Augustine was ordained a priest in Hippo Regius (now Annaba), in Algeria. He became a famous preacher (more than 350 preserved sermons are believed to be authentic), and was noted for combating the Manichaean religion, to which he had formerly adhered.[52]		In 395, he was made coadjutor Bishop of Hippo, and became full Bishop shortly thereafter,[68] hence the name "Augustine of Hippo"; and he gave his property to the church of Thagaste.[69] He remained in that position until his death in 430. He wrote his autobiographical Confessions in 397–398. His work The City of God was written to console his fellow Christians shortly after the Visigoths had sacked Rome in 410.		Augustine worked tirelessly in trying to convince the people of Hippo to convert to Christianity. Though he had left his monastery, he continued to lead a monastic life in the episcopal residence. He left a regula for his monastery that led to his designation as the "patron saint of regular clergy."[70]		Much of Augustine's later life was recorded by his friend Possidius, bishop of Calama (present-day Guelma, Algeria), in his Sancti Augustini Vita. Possidius admired Augustine as a man of powerful intellect and a stirring orator who took every opportunity to defend Christianity against its detractors. Possidius also described Augustine's personal traits in detail, drawing a portrait of a man who ate sparingly, worked tirelessly, despised gossip, shunned the temptations of the flesh, and exercised prudence in the financial stewardship of his see.[71]		Shortly before Augustine's death the Vandals, a Germanic tribe that had converted to Arianism, invaded Roman Africa. The Vandals besieged Hippo in the spring of 430, when Augustine entered his final illness. According to Possidius, one of the few miracles attributed to Augustine, the healing of an ill man, took place during the siege.[71]:43 According to Possidius, Augustine spent his final days in prayer and repentance, requesting that the penitential Psalms of David be hung on his walls so that he could read them. He directed that the library of the church in Hippo and all the books therein should be carefully preserved. He died on 28 August 430.[71]:57 Shortly after his death, the Vandals lifted the siege of Hippo, but they returned not long thereafter and burned the city. They destroyed all of it but Augustine's cathedral and library, which they left untouched.[72]		Augustine was canonized by popular acclaim, and later recognized as a Doctor of the Church in 1298 by Pope Boniface VIII.[73] His feast day is 28 August, the day on which he died. He is considered the patron saint of brewers, printers, theologians, sore eyes, and a number of cities and dioceses.[9]		According to Bede's True Martyrology, Augustine's body was later translated or moved to Cagliari, Sardinia, by the Catholic bishops expelled from North Africa by Huneric. Around 720, his remains were transported again by Peter, bishop of Pavia and uncle of the Lombard king Liutprand, to the church of San Pietro in Ciel d'Oro in Pavia, in order to save them from frequent coastal raids by Muslims. In January 1327, Pope John XXII issued the papal bull Veneranda Santorum Patrum, in which he appointed the Augustinians guardians of the tomb of Augustine (called Arca), which was remade in 1362 and elaborately carved with bas-reliefs of scenes from Augustine's life.		In October 1695, some workmen in the Church of San Pietro in Ciel d'Oro in Pavia discovered a marble box containing some human bones (including part of a skull). A dispute arose between the Augustinian hermits (Order of Saint Augustine) and the regular canons (Canons Regular of Saint Augustine) as to whether these were the bones of Augustine. The hermits did not believe so; the canons affirmed that they were. Eventually Pope Benedict XIII (1724–1730) directed the Bishop of Pavia, Monsignor Pertusati, to make a determination. The bishop declared that, in his opinion, the bones were those of Saint Augustine.[74]		The Augustinians were expelled from Pavia in 1700, taking refuge in Milan with the relics of Augustine, and the disassembled Arca, which were removed to the cathedral there. San Pietro fell into disrepair, but was finally rebuilt in the 1870s, under the urging of Agostino Gaetano Riboldi, and reconsecrated in 1896 when the relics of Augustine and the shrine were once again reinstalled.[75][76]		Catholicism portal		Augustine's large contribution of writings covered diverse fields including theology, philosophy and sociology. Along with John Chrysostom, Augustine was among the most prolific scholars of the early church by quantity of surviving writings.		Augustine was one of the first Christian ancient Latin authors with a very clear vision of theological anthropology.[77] He saw the human being as a perfect unity of two substances: soul and body. In his late treatise On Care to Be Had for the Dead, section 5 (420 AD) he exhorted to respect the body on the grounds that it belonged to the very nature of the human person.[78] Augustine's favourite figure to describe body-soul unity is marriage: caro tua, coniunx tua – your body is your wife.[79][80][81]		Initially, the two elements were in perfect harmony. After the fall of humanity they are now experiencing dramatic combat between one another. They are two categorically different things. The body is a three-dimensional object composed of the four elements, whereas the soul has no spatial dimensions.[82] Soul is a kind of substance, participating in reason, fit for ruling the body.[83]		Augustine was not preoccupied, as Plato and Descartes were, with going too much into details in efforts to explain the metaphysics of the soul-body union. It sufficed for him to admit that they are metaphysically distinct: to be a human is to be a composite of soul and body, and the soul is superior to the body. The latter statement is grounded in his hierarchical classification of things into those that merely exist, those that exist and live, and those that exist, live, and have intelligence or reason.[84][85]		Like other Church Fathers such as Athenagoras,[86] Tertullian,[87] Clement of Alexandria and Basil of Caesarea,[88] Augustine "vigorously condemned the practice of induced abortion", and although he disapproved of an abortion during any stage of pregnancy, he made a distinction between early abortions and later ones.[89] He acknowledged the distinction between "formed" and "unformed" fetuses mentioned in the Septuagint translation of Exodus 21:22-23, which is considered as wrong translation of the word "harm" from the original Hebrew text as "form" in the Greek Septuagint and based in Aristotelian distinction "between the fetus before and after its supposed 'vivification'", and did not classify as murder the abortion of an "unformed" fetus since he thought that it could not be said with certainty that the fetus had already received a soul.[89][90]		Augustine held that "the timing of the infusion of the soul was a mystery known to God alone".[91] However, he considered procreation as one of the goods of marriage; abortion figured as a means, along with drugs which cause sterility, of frustrating this good. It lay along a continuum which included infanticide as an instance of ‘lustful cruelty’ or ‘cruel lust.’ Augustine called the use of means to avoid the birth of a child an ‘evil work:’ a reference to either abortion or contraception or both."[92] Because of "the defective science of his day", Bishop Robert F. Vasa claims that Augustine would be convinced that an "unformed" fetus had already received a soul "if Augustine had access to ultrasound images or if he had seen the film, The Silent Scream."[92]		In City of God, Augustine rejected both the immortality of the human race proposed by pagans, and contemporary ideas of ages (such as those of certain Greeks and Egyptians) that differed from the Church's sacred writings.[93] In The Literal Interpretation of Genesis, Augustine took the view that everything in the universe was created simultaneously by God, and not in seven calendar days like a literal interpretation of Genesis would require. He argued that the six-day structure of creation presented in the Book of Genesis represents a logical framework, rather than the passage of time in a physical way – it would bear a spiritual, rather than physical, meaning, which is no less literal. One reason for this interpretation is the passage in Sirach 18:1, creavit omnia simul ("He created all things at once"), which Augustine took as proof that the days of Genesis 1 had to be taken non-literally.[94]		Augustine also does not envision original sin as causing structural changes in the universe, and even suggests that the bodies of Adam and Eve were already created mortal before the Fall.[95] Apart from his specific views, Augustine recognizes that the interpretation of the creation story is difficult, and remarks that we should be willing to change our mind about it as new information comes up.[96]		Augustine developed his doctrine of the Church principally in reaction to the Donatist sect. He taught that there is one Church, but that within this Church there are two realities, namely, the visible aspect (the institutional hierarchy, the Catholic sacraments, and the laity) and the invisible (the souls of those in the Church, who are either dead, sinful members or elect predestined for Heaven). The former is the institutional body established by Christ on earth which proclaims salvation and administers the sacraments, while the latter is the invisible body of the elect, made up of genuine believers from all ages, and who are known only to God. The Church, which is visible and societal, will be made up of "wheat" and "tares", that is, good and wicked people (as per Mat. 13:30), until the end of time. This concept countered the Donatist claim that only those in a state of grace were the "true" or "pure" church on earth, and that priests and bishops who were not in a state of grace had no authority or ability to confect the sacraments.[11]:28		Augustine's ecclesiology was more fully developed in City of God. There he conceives of the church as a heavenly city or kingdom, ruled by love, which will ultimately triumph over all earthly empires which are self-indulgent and ruled by pride. Augustine followed Cyprian in teaching that the bishops and priests of the Church are the successors of the Apostles,[11] and that their authority in the Church is God-given.		Augustine originally believed in premillennialism, namely that Christ would establish a literal 1,000-year kingdom prior to the general resurrection, but later rejected the belief, viewing it as carnal. He was the first theologian to expound a systematic doctrine of amillennialism, although some theologians and Christian historians believe his position was closer to that of modern postmillennialists. The mediaeval Catholic church built its system of eschatology on Augustinian amillennialism, where Christ rules the earth spiritually through his triumphant church.[97]		During the Reformation theologians such as John Calvin accepted amillennialism. Augustine taught that the eternal fate of the soul is determined at death,[98][99] and that purgatorial fires of the intermediate state purify only those that died in communion with the Church. His teaching provided fuel for later theology.[98]		Although Augustine did not develop an independent Mariology, his statements on Mary surpass in number and depth those of other early writers.[100] Even before the Council of Ephesus, he defended the Ever-Virgin Mary as the Mother of God, believing her to be "full of grace" (following earlier Latin writers such as Jerome) on account of her sexual integrity and innocence.[101] Likewise, he affirmed that the Virgin Mary "conceived as virgin, gave birth as virgin and stayed virgin forever."[102]		Augustine took the view that, if a literal interpretation contradicts science and our God-given reason, the Biblical text should be interpreted metaphorically. While each passage of Scripture has a literal sense, this "literal sense" does not always mean that the Scriptures are mere history; at times they are rather an extended metaphor.[103]		Augustine taught that Original sin of Adam and Eve was either an act of foolishness (insipientia) followed by pride and disobedience to God or that pride came first.[note 3] The first couple disobeyed God, who had told them not to eat of the Tree of the knowledge of good and evil (Gen 2:17).[104] The tree was a symbol of the order of creation.[105] Self-centeredness made Adam and Eve eat of it, thus failing to acknowledge and respect the world as it was created by God, with its hierarchy of beings and values.[note 4]		They would not have fallen into pride and lack of wisdom, if Satan hadn't sown into their senses "the root of evil" (radix Mali).[106] Their nature was wounded by concupiscence or libido, which affected human intelligence and will, as well as affections and desires, including sexual desire.[note 5] In terms of metaphysics, concupiscence is not a being but bad quality, the privation of good or a wound.[107]		Augustine's understanding of the consequences of the original sin and of necessity of the redeeming grace was developed in the struggle against Pelagius and his Pelagian disciples, Caelestius and Julian of Eclanum,[11] who had been inspired by Rufinus of Syria, a disciple of Theodore of Mopsuestia.[108] They refused to agree that original sin wounded human will and mind, insisting that the human nature was given the power to act, to speak, and to think when God created it. Human nature cannot lose its moral capacity for doing good, but a person is free to act or not to act in a righteous way. Pelagius gave an example of eyes: they have capacity for seeing, but a person can make either good or bad use of it.[109]:355–356[110]		Like Jovinian, Pelagians insisted that human affections and desires were not touched by the fall either. Immorality, e.g. fornication, is exclusively a matter of will, i.e. a person does not use natural desires in a proper way. In opposition to that, Augustine pointed out the apparent disobedience of the flesh to the spirit, and explained it as one of the results of original sin, punishment of Adam and Eve's disobedience to God.[111]		Augustine had served as a "Hearer" for the Manichaeans for about nine years,[112] who taught that the original sin was carnal knowledge.[113] But his struggle to understand the cause of evil in the world started before that, at the age of nineteen.[114] By malum (evil) he understood most of all concupiscence, which he interpreted as a vice dominating person and causing in men and women moral disorder. Agostino Trapè insists that Augustine's personal experience cannot be credited for his doctrine about concupiscence. He considers Augustine's marital experience to be quite normal, and even exemplary, aside from the absence of Christian wedding rites.[115] As J. Brachtendorf showed, Augustine used Ciceronian Stoic concept of passions, to interpret Paul's doctrine of universal sin and redemption.[116]		The view that not only human soul but also senses were influenced by the fall of Adam and Eve was prevalent in Augustine's time among the Fathers of the Church.[117] It is clear that the reason for Augustine's distancing from the affairs of the flesh was different from that of Plotinus, a neo-Platonist[note 6] who taught that only through disdain for fleshly desire could one reach the ultimate state of mankind.[118] Augustine taught the redemption, i.e. transformation and purification, of the body in the resurrection.[119]		Some authors perceive Augustine's doctrine as directed against human sexuality and attribute his insistence on continence and devotion to God as coming from Augustine's need to reject his own highly sensual nature as described in the Confessions. But in view of his writings it is apparently a misunderstanding.[109]:312[note 7] Augustine taught that human sexuality has been wounded, together with the whole of human nature, and requires redemption of Christ. That healing is a process realized in conjugal acts. The virtue of continence is achieved thanks to the grace of the sacrament of Christian marriage, which becomes therefore a remedium concupiscentiae – remedy of concupiscence.[120][121] The redemption of human sexuality will be, however, fully accomplished only in the resurrection of the body.[122]		The sin of Adam is inherited by all human beings. Already in his pre-Pelagian writings, Augustine taught that Original Sin is transmitted to his descendants by concupiscence,[123] which he regarded as the passion of both, soul and body,[note 8] making humanity a massa damnata (mass of perdition, condemned crowd) and much enfeebling, though not destroying, the freedom of the will.[98]:1200–1204		Augustine's formulation of the doctrine of original sin was confirmed at numerous councils, i.e. Carthage (418), Ephesus (431), Orange (529), Trent (1546) and by popes, i.e. Pope Innocent I (401–417) and Pope Zosimus (417–418). Anselm of Canterbury established in his Cur Deus Homo the definition that was followed by the great 13th-century Schoolmen, namely that Original Sin is the "privation of the righteousness which every man ought to possess", thus separating it from concupiscence, with which some of Augustine's disciples had defined it[109]:371[124] as later did Luther and Calvin.[98]:1200–1204 In 1567, Pope Pius V condemned the identification of Original Sin with concupiscence.[98]:1200–1204		Augustine taught that God orders all things while preserving human freedom.[125]:44 Prior to 396, he believed that predestination was based on God's foreknowledge of whether individuals would believe, that God's grace was "a reward for human assent".[125]:48–49 Later, in response to Pelagius, Augustine said that the sin of pride consists in assuming that "we are the ones who choose God or that God chooses us (in his foreknowledge) because of something worthy in us", and argued that God's grace causes individual act of faith.[125]:47–48		Scholars are divided over whether Augustine's teaching implies double predestination, or the belief that God chooses some people for damnation as well as some for salvation. Catholic scholars tend to deny that he held such a view while some Protestants and secular scholars have held that Augustine did believe in double predestination.[126] Some Protestant theologians, such as Justo L. González[11]:44 and Bengt Hägglund,[10] interpret Augustine's teaching that grace is irresistible, results in conversion, and leads to perseverance.		In On Rebuke and Grace (De correptione et gratia), Augustine wrote: "And what is written, that He wills all men to be saved, while yet all men are not saved, may be understood in many ways, some of which I have mentioned in other writings of mine; but here I will say one thing: He wills all men to be saved, is so said that all the predestinated may be understood by it, because every kind of men is among them."[12]		Also in reaction against the Donatists, Augustine developed a distinction between the "regularity" and "validity" of the sacraments. Regular sacraments are performed by clergy of the Catholic Church, while sacraments performed by schismatics are considered irregular. Nevertheless, the validity of the sacraments do not depend upon the holiness of the priests who perform them (ex opere operato); therefore, irregular sacraments are still accepted as valid provided they are done in the name of Christ and in the manner prescribed by the Church. On this point Augustine departs from the earlier teaching of Cyprian, who taught that converts from schismatic movements must be re-baptised.[11] Augustine taught that sacraments administered outside the Catholic Church, though true sacraments, avail nothing. However, he also stated that baptism, while it does not confer any grace when done outside the Church, does confer grace as soon as one is received into the Catholic Church.		Augustine upheld the early Christian understanding of the real presence of Christ in the Eucharist, saying that Christ's statement, "This is my body" referred to the bread he carried in his hands,[127][128] and that Christians must have faith that the bread and wine are in fact the body and blood of Christ, despite what they see with their eyes.[129]		Against the Pelagians, Augustine strongly stressed the importance of infant baptism. About the question whether baptism is an absolute necessity for salvation, however, Augustine appears to have refined his beliefs during his lifetime, causing some confusion among later theologians about his position. He said in one of his sermons that only the baptized are saved.[130] This belief was shared by many early Christians. However, a passage from his City of God, concerning the Apocalypse, may indicate that Augustine did believe in an exception for children born to Christian parents.[131]		Augustine's contemporaries often believed astrology to be an exact and genuine science. Its practitioners were regarded as true men of learning and called mathemathici. Astrology played a prominent part in Manichaean doctrine, and Augustine himself was attracted by their books in his youth, being particularly fascinated by those who claimed to foretell the future. Later, as a bishop, he used to warn that one should avoid astrologers who combine science and horoscopes. (Augustine's term "mathematici", meaning "astrologers", is sometimes mistranslated as "mathematicians".) According to Augustine, they were not genuine students of Hipparchus or Eratosthenes but "common swindlers".[132][109]:63[133][134]		Epistemological concerns shaped Augustine's intellectual development. His early dialogues [Contra academicos (386) and De Magistro (389)], both written shortly after his conversion to Christianity, reflect his engagement with sceptical arguments and show the development of his doctrine of divine illumination. The doctrine of illumination claims that God plays an active and regular part in human perception (as opposed to God designing the human mind to be reliable consistently, as in, for example, Descartes' idea of clear and distinct perceptions) and understanding by illuminating the mind so that human beings can recognize intelligible realities that God presents. According to Augustine, illumination is obtainable to all rational minds, and is different from other forms of sense perception. It is meant to be an explanation of the conditions required for the mind to have a connection with intelligible entities.[5]		Augustine also posed the problem of other minds throughout different works, most famously perhaps in On the Trinity (VIII.6.9), and developed what has come to be a standard solution: the argument from analogy to other minds.[135] In contrast to Plato and other earlier philosophers, Augustine recognized the centrality of testimony to human knowledge and argued that what others tell us can provide knowledge even if we don't have independent reasons to believe their testimonial reports.[136]		Augustine asserted that Christians should be pacifists as a personal, philosophical stance.[137] However, peacefulness in the face of a grave wrong that could only be stopped by violence would be a sin. Defence of one's self or others could be a necessity, especially when authorized by a legitimate authority. While not breaking down the conditions necessary for war to be just, Augustine coined the phrase in his work The City of God.[138] In essence, the pursuit of peace must include the option of fighting for its long-term preservation.[139] Such a war could not be pre-emptive, but defensive, to restore peace.[140] Thomas Aquinas, centuries later, used the authority of Augustine's arguments in an attempt to define the conditions under which a war could be just.[141][142]		Included in Augustine's theodicy is the claim that God created humans and angels as rational beings possessing free will. Free will was not intended for sin, meaning it is not equally predisposed to both good and evil. A will defiled by sin is not considered as "free" as it once was because it is bound by material things, which could be lost or be difficult to part with, resulting in unhappiness. Sin impairs free will, while grace restores it. Only a will that was once free can be subjected to sin's corruption.[143]		The Catholic Church considers Augustine's teaching to be consistent with free will.[144] He often said that anyone can be saved if they wish.[144] While God knows who will and won't be saved, with no possibility for the latter to be saved in their lives, this knowledge represents God's perfect knowledge of how humans will freely choose their destinies.[144]		Augustine led many clergy under his authority at Hippo to free their slaves "as an act of piety."[145] He boldly wrote a letter urging the emperor to set up a new law against slave traders and was very much concerned about the sale of children. Christian emperors of his time for 25 years had permitted sale of children, not because they approved of the practice, but as a way of preventing infanticide when parents were unable to care for a child. Augustine noted that the tenant farmers in particular were driven to hire out or to sell their children as a means of survival.[146]		In his book, The City of God, he presents the development of slavery as a product of sin and as contrary to God's divine plan. He wrote that God "did not intend that this rational creature, who was made in his image, should have dominion over anything but the irrational creation – not man over man, but man over the beasts." Thus he wrote that righteous men in primitive times were made shepherds of cattle, not kings over men. "The condition of slavery is the result of sin", he declared.[147] In The City of God, Augustine wrote he felt slavery was not a punishment. He wrote: "Slavery is not penal in character and planned by that law which commands the preservation of the natural order and forbids disturbance."		Against certain Christian movements, some of which rejected the use of Hebrew Scripture, Augustine countered that God had chosen the Jews as a special people,[148] and he considered the scattering of Jewish people by the Roman Empire to be a fulfillment of prophecy.[149] He rejected homicidal attitudes, quoting part of the same prophecy, namely "Slay them not, lest they should at last forget Thy law" (Psalm 59:11). Augustine, who believed Jewish people would be converted to Christianity at "the end of time", argued that God had allowed them to survive their dispersion as a warning to Christians; as such, he argued, they should be permitted to dwell in Christian lands.[150] The sentiment sometimes attributed to Augustine that Christians should let the Jews "survive but not thrive" (it is repeated by author James Carroll in his book Constantine's Sword, for example)[151][152] is apocryphal and is not found in any of his writings.[153]		For Augustine, the evil of sexual immorality was not in the sexual act itself, but rather in the emotions that typically accompany it. In On Christian Doctrine Augustine contrasts love, which is enjoyment on account of God, and lust, which is not on account of God.[154] Augustine claims that, following the Fall, sexual passion has become necessary for copulation (as required to stimulate male erection), sexual passion is an evil result of the Fall, and therefore, evil must inevitably accompany sexual intercourse (On marriage and concupiscence 1.19). Therefore, following the Fall, even marital sex carried out merely to procreate the species inevitably perpetuates evil (On marriage and concupiscence 1.27; A Treatise against Two Letters of the Pelagians 2.27). For Augustine, proper love exercises a denial of selfish pleasure and the subjugation of corporeal desire to God. The only way to avoid evil caused by sexual intercourse is to take the "better" way (Confessions 8.2) and abstain from marriage (On marriage and concupiscence 1.31). Sex within marriage is not, however, for Augustine a sin, although necessarily producing the evil of sexual passion. Based on the same logic, Augustine also declared the pious virgins raped during the sack of Rome to be innocent because they did not intend to sin nor enjoy the act.[155][156]		Before the Fall, Augustine believed that sex was a passionless affair, "just like many a laborious work accomplished by the compliant operation of our other limbs, without any lascivious heat"; the penis would have been engorged for sexual intercourse "simply by the direction of the will, not excited by the ardour of concupiscence" (On marriage and concupiscence 2.29; cf. City of God 14.23). After the Fall, by contrast, the penis cannot be controlled by mere will, subject instead to both unwanted impotence and involuntary erections: "Sometimes the urge arises unwanted; sometimes, on the other hand, it forsakes the eager lover, and desire grows cold in the body while burning in the mind... It arouses the mind, but it does not follow through what it has begun and arouse the body also" (City of God 14.16).		Augustine believed that Adam and Eve had both already chosen in their hearts to disobey God's command not to eat of the Tree of Knowledge before Eve took the fruit, ate it, and gave it to Adam.[157][158] Accordingly, Augustine did not believe that Adam was any less guilty of sin.[157][159] Augustine does praise women and their role in society and in the Church. In his Tractates on the Gospel of John, Augustine, commenting on the Samaritan woman from John 4:1–42, uses the woman as a figure of the Church in agreement with the New Testament teaching that the Church is the bride of Christ. "Husbands, love your wives, as Christ loved the church and gave himself up for her." [160]		Augustine is considered an influential figure in the history of education. A work early in Augustine's writings is De Magistro (On the Teacher), which contains insights about education. His ideas changed as he found better directions or better ways of expressing his ideas. In the last years of his life Saint Augustine wrote his Retractationes, reviewing his writings and improving specific texts. Henry Chadwick believes an accurate translation of "retractationes" may be "reconsiderations". Reconsiderations can be seen as an overarching theme of the way Saint Augustine learned. Augustine's understanding of the search for understanding, meaning, and truth as a restless journey leaves room for doubt, development, and change.[161]		Augustine was a strong advocate of critical thinking skills. Because written works were still rather limited during this time, spoken communication of knowledge was very important. His emphasis on the importance of community as a means of learning distinguishes his pedagogy from some others. Augustine believed that dialectic is the best means for learning and that this method should serve as a model for learning encounters between teachers and students. Saint Augustine's dialogue writings model the need for lively interactive dialogue among learners.[161]		He recommended adapting educational practices to fit the students' educational backgrounds:		If a student has been well educated in a wide variety of subjects, the teacher must be careful not to repeat what they have already learned, but to challenge the student with material which they do not yet know thoroughly. With the student who has had no education, the teacher must be patient, willing to repeat things until the student understands, and sympathetic. Perhaps the most difficult student, however, is the one with an inferior education who believes he understands something when he does not. Augustine stressed the importance of showing this type of student the difference between "having words and having understanding" and of helping the student to remain humble with his acquisition of knowledge.		Under the influence of Bede, Alcuin, and Rabanus Maurus, De catechizandis rudibus came to exercise an important role in the education of clergy at the monastic schools, especially from the eighth century onwards.[162]		Augustine believed that students should be given an opportunity to apply learned theories to practical experience. Yet another of Augustine's major contributions to education is his study on the styles of teaching. He claimed there are two basic styles a teacher uses when speaking to the students. The mixed style includes complex and sometimes showy language to help students see the beautiful artistry of the subject they are studying. The grand style is not quite as elegant as the mixed style, but is exciting and heartfelt, with the purpose of igniting the same passion in the students' hearts. Augustine balanced his teaching philosophy with the traditional Bible-based practice of strict discipline.		Augustine was one of the most prolific Latin authors in terms of surviving works, and the list of his works consists of more than one hundred separate titles.[163] They include apologetic works against the heresies of the Arians, Donatists, Manichaeans and Pelagians; texts on Christian doctrine, notably De Doctrina Christiana (On Christian Doctrine); exegetical works such as commentaries on Genesis, the Psalms and Paul's Letter to the Romans; many sermons and letters; and the Retractationes, a review of his earlier works which he wrote near the end of his life.		Apart from those, Augustine is probably best known for his Confessions, which is a personal account of his earlier life, and for De civitate Dei (The City of God, consisting of 22 books), which he wrote to restore the confidence of his fellow Christians, which was badly shaken by the sack of Rome by the Visigoths in 410. His On the Trinity, in which he developed what has become known as the 'psychological analogy' of the Trinity, is also considered to be among his masterpieces, and arguably one of the greatest theological works of all time.[citation needed] He also wrote On Free Choice of the Will (De libero arbitrio), addressing why God gives humans free will that can be used for evil.		In both his philosophical and theological reasoning, Augustine was greatly influenced by Stoicism, Platonism and Neoplatonism, particularly by the work of Plotinus, author of the Enneads, probably through the mediation of Porphyry and Victorinus (as Pierre Hadot has argued). Although he later abandoned Neoplatonism, some ideas are still visible in his early writings.[164] His early and influential writing on the human will, a central topic in ethics, would become a focus for later philosophers such as Schopenhauer, Kierkegaard, and Nietzsche. He was also influenced by the works of Virgil (known for his teaching on language), and Cicero (known for his teaching on argument).[5]		Philosopher Bertrand Russell was impressed by Augustine's meditation on the nature of time in the Confessions, comparing it favourably to Kant's version of the view that time is subjective.[165] Catholic theologians generally subscribe to Augustine's belief that God exists outside of time in the "eternal present"; that time only exists within the created universe because only in space is time discernible through motion and change. His meditations on the nature of time are closely linked to his consideration of the human ability of memory. Frances Yates in her 1966 study The Art of Memory argues that a brief passage of the Confessions, 10.8.12, in which Augustine writes of walking up a flight of stairs and entering the vast fields of memory[166] clearly indicates that the ancient Romans were aware of how to use explicit spatial and architectural metaphors as a mnemonic technique for organizing large amounts of information.		Augustine's philosophical method, especially demonstrated in his Confessions, had continuing influence on Continental philosophy throughout the 20th century. His descriptive approach to intentionality, memory, and language as these phenomena are experienced within consciousness and time anticipated and inspired the insights of modern phenomenology and hermeneutics.[167] Edmund Husserl writes: "The analysis of time-consciousness is an age-old crux of descriptive psychology and theory of knowledge. The first thinker to be deeply sensitive to the immense difficulties to be found here was Augustine, who laboured almost to despair over this problem."[168]		Martin Heidegger refers to Augustine's descriptive philosophy at several junctures in his influential work Being and Time.[note 9] Hannah Arendt began her philosophical writing with a dissertation on Augustine's concept of love, Der Liebesbegriff bei Augustin (1929): "The young Arendt attempted to show that the philosophical basis for vita socialis in Augustine can be understood as residing in neighbourly love, grounded in his understanding of the common origin of humanity."[169]		Jean Bethke Elshtain in Augustine and the Limits of Politics tried to associate Augustine with Arendt in their concept of evil: "Augustine did not see evil as glamorously demonic but rather as absence of good, something which paradoxically is really nothing. Arendt ... envisioned even the extreme evil which produced the Holocaust as merely banal [in Eichmann in Jerusalem]."[170]		Augustine's philosophical legacy continues to influence contemporary critical theory through the contributions and inheritors of these 20th-century figures. Seen from a historical perspective, there are three main perspectives on the political thought of Augustine: first, political Augustinianism; second, Augustinian political theology; and third, Augustinian political theory.[171]		Thomas Aquinas was influenced heavily by Augustine. On the topic of original sin, Aquinas proposed a more optimistic view of man than that of Augustine in that his conception leaves to the reason, will, and passions of fallen man their natural powers even after the Fall, without "supernatural gifts".[98]:1203 While in his pre-Pelagian writings Augustine taught that Adam's guilt as transmitted to his descendants much enfeebles, though does not destroy, the freedom of their will, Protestant reformers Martin Luther and John Calvin affirmed that Original Sin completely destroyed liberty (see total depravity).[98]:1200–1204		According to Leo Ruickbie, Augustine's arguments against magic, differentiating it from miracle, were crucial in the early Church's fight against paganism and became a central thesis in the later denunciation of witches and witchcraft. According to Professor Deepak Lal, Augustine's vision of the heavenly city has influenced the secular projects and traditions of the Enlightenment, Marxism, Freudianism and eco-fundamentalism.[172] Post-Marxist philosophers Antonio Negri and Michael Hardt rely heavily on Augustine's thought, particularly The City of God, in their book of political philosophy Empire.		Augustine has influenced many modern-day theologians and authors such as John Piper. Hannah Arendt, an influential 20th-century political theorist, wrote her doctoral dissertation in philosophy on Augustine, and continued to rely on his thought throughout her career. Ludwig Wittgenstein extensively quotes Augustine in Philosophical Investigations for his approach to language, both admiringly, and as a sparring partner to develop his own ideas, including an extensive opening passage from the Confessions. Contemporary linguists have argued that Augustine has significantly influenced the thought of Ferdinand de Saussure, who did not 'invent' the modern discipline of semiotics, but rather built upon Aristotelian and Neoplatonist knowledge from the Middle Ages, via an Augustinian connection: "as for the constitution of Saussurian semiotic theory, the importance of the Augustinian thought contribution (correlated to the Stoic one) has also been recognized. Saussure did not do anything but reform an ancient theory in Europe, according to the modern conceptual exigencies."[173]		In his autobiographical book Milestones, Pope Benedict XVI claims Augustine as one of the deepest influences in his thought.		Much of Augustine's conversion is dramatized in the oratorio La conversione di Sant'Agostino (1750) composed by Johann Adolph Hasse. The libretto for this oratorio, written by Duchess Maria Antonia of Bavaria, draws upon the influence of Metastasio (the finished libretto having been edited by him) and is based off an earlier five-act play Idea perfectae conversionis dive Augustinus written by the Jesuit priest Franz Neumayr.[174] In the libretto Augustine's mother Monica is presented as a prominent character that is worried that Augustine might not convert to Christianity. As Dr. Andrea Palent[175] says:		Maria Antonia Walpurgis revised the five-part Jesuit drama into a two-part oratorio liberty in which she limits the subject to the conversion of Augustine and his submission to the will of God. To this was added the figure of the mother, Monica, so as to let the transformation appear by experience rather than the dramatic artifice of deus ex machina.		Throughout the oratorio Augustine shows his willingness to turn to God, but the burden of the act of conversion weighs heavily on him. This is displayed by Hasse through extended recitative passages.		
A baymouth bar is a depositional feature as a result of longshore drift. It is a spit that completely closes access to a bay, thus sealing it off from the main body of water. It is different from a barrier island separating a lagoon because it closes the bay off completely, not partially.		These bars usually consist of accumulated gravel and sand carried by the current of longshore drift and deposited at a less turbulent part of the current. Thus, they most commonly occur across artificial bay and river entrances due to the loss of kinetic energy in the current after wave refraction.				
An islet is a very small island.						As suggested by its origin as islette, an Old French diminutive of "isle",[1] use of the term implies small size, but little attention is given to drawing an upper limit on its applicability.		Whether an islet is considered a rock or not can have significant economic consequences under Article 121 of the UN Convention on the Law of the Sea, which stipulates that "Rocks which cannot sustain human habitation or economic life of their own shall have no exclusive economic zone or continental shelf." One long-term dispute over the status of such an islet was that of Snake Island (Black Sea).[2][3][4]		The International Court of Justice jurisprudence however sometimes ignores islets, regardless of inhabitation status, in deciding territorial disputes; it did so in 2009 in adjudicating the Romania-Ukraine dispute, and previously in the dispute between Libya and Malta involving the islet of Filfla.[2][5]		There are thousands of islets on Earth: approximately 24,000 islands and islets in the Stockholm archipelago alone. The following is a list of example islets from around the world.		
The wakes week is a holiday period in parts of England and Scotland. Originally a religious celebration or feast, the tradition of the wakes week developed into a secular holiday, particularly in North West England during the Industrial Revolution. In Scotland each city has a "trades fortnight": two weeks in the summer when tradesmen take their holidays.		Although a strong tradition during the 19th and 20th centuries, the observance of the holiday has almost disappeared in recent times due to the decline of the manufacturing industries in the United Kingdom and the standardisation of school holidays across England.						In 601 AD Pope Gregory I wrote a letter to Mellitus (a member of the Gregorian mission sent to England to convert the Anglo-Saxons from their native paganism to Christianity) which read:[1]		When, therefore, Almighty God shall bring you to the most reverend man our brother bishop, St Augustine, tell him what I have, upon mature deliberation on the affair of the English, thought of; namely, that the temples of the idols in that nation ought not to be destroyed. Let holy water be made, and sprinkled in the said temples; let altars be erected, and let relics be deposited in them. For since those temples are built, it is requisite that they be converted from the worship of the devils to the service of the true God; that the nation, not seeing those temples destroyed, may remove error from their hearts, and knowing and adoring the true God, may the more familiarly resort to the same places to which they have been accustomed. And because they are wont to sacrifice many oxen in honour of the devils, let them celebrate a religious and solemn festival, not slaughtering the beasts for devils, but to be consumed by themselves, to the praise of God...		Every church at its consecration was given the name of a patron saint, and either the day of its consecration or the saint's feast day became the church's festival. Church services began at sunset on Saturday and the night of prayer was called a vigil, eve or, due to the late hour "wake", from the Old English waecan.[2] Each village had a wake with quasi-religious celebrations such as rushbearing followed by church services then sports, games, dancing and drinking.[3] As wakes became more secular the more boisterous entertainments were moved from the sabbath to Saturday and Monday was reserved for public entertainments such as bands, games and funfairs.[4]		During the Industrial Revolution the tradition of the wakes was adapted into a regular summer holiday particularly, but not exclusively, in the North of England and industrialised areas of the Midlands where each locality nominated a wakes week during which the local factories, collieries and other industries closed for a week. The wakes holiday started as an unpaid holiday when the mills and factories were closed for maintenance.		Each town in Lancashire took the holiday on a different week in the summer so that from June to September one town was on holiday each week.[5] In 1906 an agreement on unpaid holidays was reached which became the pattern for the wakes holidays in Lancashire mill towns. It was implemented in 1907 and guaranteed 12 days annual holiday including bank holidays — this was increased to 15 days in 1915.[6]		There was a long-held belief amongst the working classes of the north of England in the benefits of bathing in the sea during the months of August and September, as there was said to be "physic in the sea". The expansion of the railway network led Blackpool to become a seaside resort catering mainly for the Lancashire working classes. Southport catered for the slightly better off and Morecambe attracted visitors from the West Riding textile towns.[7] The railway link to Blackpool from the mill town of Oldham was completed in 1846 and in the peak year of 1860 more than 23,000 holidaymakers travelled on special trains to the resort during wakes week from that town alone.[8]		In the last quarter of the 19th century, trips increased from day trips to full weeks away and 'Wakes Saving' or 'Going-Off' clubs became popular. The saving clubs were a feature of the industrial north until paid holidays became a reality in the 1940s and '50s.[9]		There is a merry, happy time, To grace withal this simple rhyme: There is jovial, joyous hour, Of mirth and jollity in store: The Wakes! The Wakes! The jocund wakes! My wandering memory now forsakes The present busy scene of things, Erratic upon Fancy's wings, For olden times, with garlands crown'd And rush-carts green on many a mound. In hamlets bearing a great name, The first in astronomic fame.  — From The Village Festival by Droylsden poet Elijah Ridings (1802-1872).[10]		The tradition has now disappeared in most of the UK due to the decline of traditional manufacturing industries and schools objecting to the holidays at crucial exam times.[11] It was common for local authorities to allocate a one-week school holiday to coincide with wakes week in lieu of holiday time elsewhere in the year but schools began to discontinue the wakes week holiday after the introduction of the National Curriculum and the standardisation of school holidays across England.[12] Councils no longer have a statutory power to set dates for public holidays following the introduction of the Employment Act 1989 and the Local Government etc (Scotland) Act 1994.[13]		Notes		Bibliography		
In geography, a sound is a large sea or ocean inlet larger than a bay, deeper than a bight, and wider than a fjord; or a narrow sea or ocean channel between two bodies of land (see also strait).[1][2]		There is little consistency in the use of "sound" in English-language place names.						A sound is often formed by the seas flooding a river valley. This produces a long inlet where the sloping valley hillsides descend to sea-level and continue beneath the water to form a sloping sea floor. The Marlborough Sounds in New Zealand are a good example of this type of formation.		Sometimes a sound is produced by a glacier's carving out a valley on a coast then receding, or the sea's invading a glacier valley. The glacier produces a sound that often has steep, near vertical sides that extend deep under water. The sea floor is often flat and deeper at the landward end than the seaward end, due to glacial moraine deposits. This type of sound is more properly termed a fjord (or fiord). The sounds in Fiordland, New Zealand, have been formed this way.		A sound generally connotes a protected anchorage.		In the more general northern European usage, a sound is a strait or the most narrow part of a strait. In Scandinavia and around the Baltic Sea, there are more than a hundred straits named Sund, mostly named for the island they separate from the continent or a larger island.		In contrast, the Sound is the internationally recognized,[3] short name for the Øresund, the narrow stretch of water that separates Denmark and Sweden, and is the main waterway between the Baltic Sea and the North Sea. It is also a colloquial short name, among others, for Plymouth Sound, England.		In areas explored by the British in the late 18th Century, particularly the northwest coast of North America, the term "sound" was applied to inlets containing large islands, such as Howe Sound in Vancouver and Puget Sound in Washington State. It was also applied to bodies of open water not fully open to the ocean, such as Caamaño Sound or Queen Charlotte Sound in Canada, or broadenings or mergings at the openings of inlets, like Cross Sound in Alaska and Fitz Hugh Sound in British Columbia.		In the United States, Long Island Sound separates Long Island from the eastern shores of the Bronx, Westchester County, and southern Connecticut, but on the Atlantic Ocean side of Long Island, the body of water between Long Island and its barrier beaches is termed the Great South Bay. Pamlico Sound is a similar lagoon that lies between North Carolina and its barrier beaches, the Outer Banks, in a similar situation. The Mississippi Sound separates the Gulf of Mexico from the mainland, along much of the gulf coasts of Alabama and Mississippi. On the West Coast, Puget Sound, by contrast, is a deep arm of the ocean.		The term sound is derived from the Anglo-Saxon or Old Norse word sund, which also means "swimming".[2]		The word sund is already documented in Old Norse and Old English as meaning "gap" (or "narrow access"). This suggests a relation to verbs meaning "to separate", such as absondern and aussondern (German), söndra (Swedish), sondre (Norwegian), as well as the English noun sin, German Sünde ("apart from God's law"), and Swedish synd. English has also the adjective "asunder" and the noun "sundry', and Swedish has the adjective sönder ("broken").		In Swedish and in both Norwegian languages, "sund" is the general term for any strait. In Swedish and Nynorsk, it is even part of names worldwide, such as in Swedish "Berings sund" and "Gibraltar sund", and in Nynorsk "Beringsundet" and "Gibraltarsundet".		Much further south, there are many sounds in the southwestern tip of South Island. From north to south they are:		Media related to Sounds (geography) at Wikimedia Commons		
A surf break (also break, shore break, or big wave break[1]) is a permanent (or semi permanent) obstruction such as a coral reef, rock, shoal, or headland that causes a wave to break,[2] forming a barreling wave or other wave that can be surfed, before it eventually collapses. The topography of the seabed determines the shape of the wave and type of break. Since shoals can change size and location, affecting the break, it takes commitment and skill to find good breaks. Some surf breaks are quite dangerous, since the surfer can collide with a reef or rocks below the water.		Surf breaks may be defended vehemently by surfers, as human activities and constructions can have unintended and unpredictable consequences which can be either positive, negative, or unknown.		In 2008, surfers and environmentalists opposed a toll road project in Orange County, California that would have changed sediment patterns and affected the world-class Trestles surf break north of San Onofre State Beach which attracted 400,000 surfers in 2007.[3]		In 2007, the NSW Geographical Names Register began formally recognizing names of surf breaks in Australia, defining a surf break as a "permanent obstruction such as a reef, headland, bombora, rock or sandbar, which causes waves to break".[2]		One of the largest surf breaks in the world is the Jaws surf break in Maui, Hawaii, with waves that reach a maximum height of 40–60 feet (12–18 m).[4] However waves which break off Nazaré in Portugal have been recorded to exceed 80 feet, with estimates of waves ridden up to over 100 feet, from trough to peak. The peculiar ocean bathymetry off Nazare is largely responsible for the very large wave faces.						There are numerous types of surf breaks. These are defined as permanent or semi permanent obstructions that causes a wave to break, rather than by the nature of the wave itself (see under 'Types of surfable waves' below).		Artificial wave pools are an example of technology changing what is considered a 'surf break' or 'surfable wave'.		Some 'surf break' locations may be partly or wholly formed and influenced by human activities (see under 'Human influence on surf breaks' below). These effects are variable and may be either negative or positive with respect to the effect on local surf quality.		A point break refers to the place where waves hit a point of land or rocks jutting out from the coastline. Bells Beach in Australia and Jardim do Mar in Madeira, Portugal are examples of point breaks.		They can break either left or right, and in rare cases forms a central peak which breaks both ways around a central headland. (E.g. Punta Rocas in Peru). The bottom can be made of rocks, sand, or coral.		A beach break takes place where waves break on a usually sandy seabed. An example of a classic beach break is Hossegor in Southern France, which is famous for waves of up to 20 feet (6.1 m).		Sometimes 'beaches' can contain little or no sand, and the 'beach' bottom may be only rock or boulders and pebbles. A 'boulder beach' is an example.		A reef break happens when a wave breaks over a coral reef or a rocky seabed. Examples are Cloudbreak in Fiji and Jaws in Maui.		A reef break may occur close to the shore, or well offshore from the shoreline, breaking in open ocean and petering out before the wave reaches the shore. Examples include Queenscliff Bommie in Australia and Dungeons in South Africa. In Australia these open ocean reefs are sometimes called Bombora or 'Bommie' waves, after the aboriginal word for offshore reef, 'bombora'. Sometimes reefs which occur in open ocean but which do not breach the surface are also called 'Banks'. The Cortes Bank off California is an example.		There are also examples of man-made reefs specifically designed and made for surfing. Some artificial harbours also create new reef break waves. Examples include Newcastle Harbour in Australia.		'Shipwreck breaks' usually form from sand build up over submerged or partly submerged shipwrecks.		They may be either temporary or more or less permanent, depending on whether the wreck remains in place for a significant period. Examples occur at The Wreck, Byron Bay, New South Wales, and at Stockton Beach, Newcastle, New South Wales.		A shore break is a wave that breaks directly on, or very close to the shore. This happens when the beach is very steep at the shoreline. These waves are really just a form of beach or reef break, but breaking very close to the shore.		A rivermouth break breaks at or near the entrance to a river or creek. It can break as either a left-breaking or right-breaking wave, or a peak which breaks both ways. The bottom is usually sand, but can be pebbles, rocks, or even coral reef.		Examples include Mundaka in Spain, and Merimbula Bar in Australia.		They are sometimes called 'Bar' breaks because of the way the sand piles up along the shoreline.		These waves break along or near a jetty. They are also called 'groynes' in some places. Examples include Long Beach in New York, The Wedge in California, and Duranbah Groyne in Australia.		Jetty and groyne style waves are known for often exhibiting constructive interference between different incoming waves to produce a significantly larger, 'wedging' style of wave, due to the unusual extension of obstruction that juts out significantly from the shore, and which wave shape is often favored by surfers. This is an example of a human influence which actually may improve a wave's shape and quality for surfing, however in other cases the effect for surfing may be negative.		Natural 'wedge' style constructive interference can however occur on any type of surf break, provided the local wave dynamics are favorable.		A type of open ocean surf break, these occur where sand build ups occur well offshore to produce breaking waves in the open ocean, which are sometimes called 'Outer Banks', which are similar to open ocean reefs except that they are generally made of sand, and may disappear or change with storms. The 'Outer Banks' in North Carolina is an example. They can also be made of more permanent rocky reefs.		Numerous tidal bore waves are known, some of which have also been surfed for several kilometres or more and many kilometres from the ocean, making them the longest rideable waves in the world.		They are formed where stronger and larger tides enter a river or deltaic system, allowing the tide to forcefully push and extend up the river, sometimes forming rideable waves. The waves can be singular or multiple crested.		They form at specific times of the day, month, and year due to tidal currents, and can be accurately predicted.		Well known examples include several in the Amazon Basin, in Brazil, at the Severn Bore in the United Kingdom, and in Sumatra, Indonesia.		These are waves which are created in some fast flowing rivers or creeks, allowing a surfer to ride a wave for several minutes or more whilst standing or lying more or less stationary within the river. The force of the flow along an uneven river bed allows a standing wave to form, and the surfer to be able to ride the wave successfully. They are relatively rare as local wave dynamics tend to be very specific.		Examples include on the Zambesi River, and near Munich, Germany.		They also sometimes form when an inland lagoon or lake breaches its entry to the sea, forming standing waves in the channel between the lagoon and sea. Examples include at Waimea in Hawaii.		These are waves generated in an artificially created pool with a powerful wave-generating device, to form waves which can be surfed without any need for an existing, natural water environment, such as an ocean or shoreline. Wave pools can therefore be built almost anywhere, and several designs and models (which have also been patented) are under construction throughout the world as of 2016.		In December 2015, former world surfing champion and current professional surfer Kelly Slater revealed a new type of wave pool at an unknown location, which was able to demonstrably show well-shaped barrelling style waves over several hundred metres at around head-high or more, which quality and size had not previously been achieved by any wave pool design or construction. The ability to create genuine, long, barreling surfable waves at locations far from natural shorelines might prove to be a game-changer within surfing culture and history.		Wave pools are currently the subject of much research and development, and there are a number of planned and existing commercial operations.		As opposed to permanent or semi permanent obstructions which cause waves to break, surfable waves are sometimes defined by the nature of their generation.		Ocean swells form from the longer term amalgamation of wind-generated waves on the surface. The stronger the wind and the longer the area over which it blows, generally the larger the swell.		If large enough, local wind-generated chop can be surfed, but usually only after it has amalgamated into genuine swell from a distance.		A large ship such as an oil tanker can sometimes create rideable waves at the shoreline. These are usually surfed only when the waves are otherwise very small, such as in a large inland lake.		There has been unconfirmed reports of an offhsore boat being used to make waves during surf contests when the surf was otherwise very small.		Although rare, surfable tsunami waves from earthquakes has been recorded.		One documented place an earthquake-generated tsunami has been surfed is at Punta Hermosa in Peru, at the offshore Kon Tiki reef, where the tsunami-generated waves were ridden about 1 kilometre from the shore, before further rising and crashing into the nearby shoreline. The surfers did not know these were tsunami waves until after the event.		Surfable seismic-style waves generated from landslides, volcanic eruptions or meteorite impacts into the ocean are all possible, but all of these are very rare, unpredictable, and have not been documented as being surfed.		Waves have been surfed and documented from the action of calving ice from glaciers, which falls into the adjacent water and forms a tsunami-type wave which surges away from the glacier.		These form when a large storm or hurricane forces water in front of it, due to the combined action of strong winds over long distances. The water can pile up towards the shore and create a moving surge of water.		These surges can be surfed, although they have not been specifically documented.		These occur where waves are formed from the returning backwash of a wave which has previously gone up a steep shoreline or beach, or sometimes reflected from an ocean rockface or wall. They can sometimes form a surfable wave in a direction oblique to, or opposite from the original wave direction. An example was shown in the film Endless Summer, in Tahiti, called 'Ins and Outs'.		Backwash breaking parallel to or obliquely to the angle of the shore is sometimes also called sidewash, which can form from the reflection of a wave breaking against adjacent obstructions such as jetties, groynes, or rockwalls, or simply from the action of backwashing waves which strike a shoreline at an angle.		Sidewash and backwash is relatively common, and may amplify another incoming breaking wave's size due to constructive interference. When this process happens with an open ocean swell the resulting wave can also be significantly larger due to constructive interference from either deep water refraction or diffraction, or both. This type of effect is suggested to occur at two of the largest surf breaks in the world, at Nazaré in Portugal, and Jaws in Hawaii.		Backwash and sidewash also sometimes form in conjunction with rips on beaches.		These are formed from the action of fast flowing water over an uneven river or creek bed. The dynamics are very specific and not many naturally occurring surfable standing river waves are known, but examples include on the Zambesi river and near Munich, Germany.		Some rivers can also exhibit a surfable wave 'front' during flash flood events, particularly within narrow canyons. These have been ridden by people on surf craft caught in a flash flood event, such as on an inflatable tyre, although not usually intentionally. It is technically a wave front, with a breaking wave which can carry one downstream, so may be classified as a 'surf break', but others may classify this as simply a type of river riding.		These form where strong tidal currents enter a river or deltaic system, pushing shorewards and creating a surfable wave, and can extend for many kilometers. Surfable examples are known in China, Sumatra, the Amazon Basin, and the United Kingdom. They can be multiple or single crested wave fronts.		These are made in an artificially created pool with a powerful wave generating device, to form generally small waves, which can be surfed without any need for an ocean or shoreline.		They are currently the subject of much research and development, and there are a number of commercial operations.		'Surf break' locations and the quality of surf may be negatively or positively affected by human activities.		In some cases, surf breaks themselves may be partly formed from the influence of human activities. These include from the construction of local jetties (e.g. at Ocean Beach, New York), or from the dredging and dumping of nearby river sand (at Coolangatta's 'Superbank', Queensland, which sand sourced from the nearby Tweed River which commenced in the late 1990s and has now formed an almost continuous 2 km long sand bottomed point break), or from sand build up around local shipwrecks (such as at Stockton Beach, New South Wales). These effects may be either temporary, or more or less permanent.		The effects of human influences are variable, and may be either negative or positive with respect to the effect on local surf quality, and in some cases may affect one nearby surf break positively and another negatively.		Generally speaking, local surfers are opposed to potential unintentional consequences of local constructions or development which may not have adequately assessed or considered the effect on local surf quality, particularly where the local surf quality is considered substantial or culturally or socio-economically significant. Such effects may not have been taken into account during various development proposals.		There are examples of world-renowned surf breaks which have been significantly and negatively effected or destroyed by various engineering or other human influences, although it is important to note that some renowned surf breaks have also been markedly improved by various human influences.		These constructions create local sand build up which may improve the local surf quality.		Examples occur at Ocean Beach New York, and Duranbah Groyne New South Wales. They are also called 'groynes' in some places.		Negative effects on surf quality from such constructions are also known.		These may create changes to local surf dynamics which can be either negative or positive with respect to surf quality. Most were made in previous decades and centuries and the effects on surf quality at the time were not known. Examples include at Newcastle Harbour, in New South Wales.		These unintentional 'constructions' may allow sand to build up around the wreck, sometimes forming surfable waves.		Sand dredging and dumping from nearby rivers can affect the quality of nearby surf breaks, due to changes in the amount of sand available to form over the bottom. In many sand bottom point breaks, more sand often means better quality.		The 'Superbank' in Queensland is a world class surf break, partly formed from the influence of nearby sand dredging and dumping. This sand is sourced form the nearby Tweed River, which dredging program began in the late 1990s. This program has generally improved the surf quality, forming a now more or less continuous 2 km long sand bottomed surf break, linking up what was previously 3 different point breaks (Snapper, Greenmount, and Kirra) into now one more or continuous surf break, and now also one of the longest point breaks in the world.		Whilst the surf quality at Snapper and Greenmount has generally improved, the bottom section of the break, the world-class Kirra point break, which was formerly considered one of the best in the world, has generally suffered.		Proposals have been put forward to attempt to alleviate or change the program, to attempt to restore the quality of previous surf at Kirra, however it is not clear how the improvements made to nearby Snapper and Greenmount would also be then affected. There may be an optimum amount of sand dredging and build up which allows all three breaks to be generally improved, as was perhaps the case in the early 2000s.		'Artificial reef breaks' are an example of a construction which intentionally alters the local seabed dynamics to attempt to improve the local surf quality. The success of these has proved to be variable to date, with both positive and neutral cases known.		Reactions to local artificial reef construction proposals is mixed and variable, and is usually examined on a case by case basis.		Artificial wave pools use a powerful wave generating device which creates surfable waves without the need for a coastline or shoreline. They can therefore allow surf activity to occur many kilometers inland from the sea or ocean.		They are the subject of current research and development, and a number of commercial operations are in existence.		These form where lagoons disconnected to the ocean are deliberately breached, which allows a narrow fast flowing channel to form which lowers the water level and re-connect the inland water system with the ocean. Sometimes surfable 'standing waves' are formed and surfed during these events, which can become a cultural attraction.		This is largely an illegal fishing activity which occurs in some countries whereby explosives are used over coral reefs to kill and stun the fish, allowing them to be then netted and caught more easily. The practice is largely illegal, as it negatively effects both marine life and also changes and destroys the local seabed and coral topography, creating largely negative effects on local surf conditions.		The mobility of sand dunes sometimes allows a greater supply of sand to be deposited in adjacent local point breaks, creating more even surf conditions on these point break style waves. When these dunes are destroyed or stabilised, the supply of sand may be reduced, effecting local surf conditions. This has occurred at the Bruce's Beauties surf break in South Africa, where wave quality was no longer the same once the adjacent dunes were developed with residential style housing. Areas adjacent to river systems where the supply of sand is reduced can also be similarly affected.		
In the history of the United Kingdom, the Victorian era was the period of Queen Victoria's reign, from 20 June 1837 until her death on 22 January 1901. The era followed the Georgian period and preceded the Edwardian period, and its later half overlaps with the first part of the Belle Époque era of continental Europe. Defined according to sensibilities and political concerns, the period is sometimes considered to begin with the passage of the Reform Act 1832. The period is characterised as one of relative peace among the great powers (as established by the Congress of Vienna), increased economic activity, "refined sensibilities" and national self-confidence for Great Britain.[1]		Ideologically, the Victorian era witnessed resistance to the rationalism that defined the Georgian period and an increasing turn towards romanticism and mysticism with regard to religion, social values, and arts.[2] In international relations, the supremacy of the Royal Navy helped maintain a period of relative peace among the great powers (Pax Britannica) as well as economic, colonial, and industrial consolidation, a notable exception being the Crimean War (1853-6). Britain embarked on global imperial expansion, particularly in Asia and Africa, which made the British Empire the largest empire in history.		Domestically, the political agenda was increasingly liberal, with a number of shifts in the direction of gradual political reform, industrial reform, and the widening of the voting franchise. There were unprecedented demographic changes: the population of England and Wales almost doubled from 16.8 million in 1851 to 30.5 million in 1901,[3] and Scotland's population also rose rapidly, from 2.8 million in 1851 to 4.4 million in 1901. However, Ireland's population decreased sharply, from 8.2 million in 1841 to less than 4.5 million in 1901, mostly due to the Great Famine.[4] Between 1837 and 1901 about 15 million emigrated from Great Britain, mostly to the United States, Canada, South Africa, New Zealand, and Australia.[5]		The two main political parties during the era remained the Whigs/Liberals and the Conservatives; by its end, the Labour Party had formed as a distinct political entity. These parties were led by such prominent statesmen as Lord Melbourne, Sir Robert Peel, Lord Derby, Lord Palmerston, Benjamin Disraeli, William Gladstone, and Lord Salisbury. The unsolved problems relating to Irish Home Rule played a great part in politics in the later Victorian era, particularly in view of Gladstone's determination to achieve a political settlement in Ireland.						In the strictest sense, the Victorian era covers the duration of Victoria's reign as Queen of the United Kingdom of Great Britain and Ireland, from her accession on 20 June 1837—after the death of her uncle, William IV—until her death on 22 January 1901, after which she was succeeded by her eldest son, Edward VII. Her reign lasted for 63 years and seven months, a longer period than any of her predecessors. The term 'Victorian' was in contemporaneous usage to describe the era.[6] The era has also been understood more extensively as a period that possessed sensibilities and characteristics distinct from those adjacent, in which case it is sometimes dated to begin before Victoria's accession—typically from the passage of or agitation for (during the 1830s) the Reform Act 1832, which introduced a wide-ranging change to the electoral system of England and Wales. Definitions according to a distinct sensibility or politics have also created scepticisim about the worth of the label "Victorian", though there have equally been defences of it as a marker of time.[7]		In 1832, after much political agitation, the Reform Act was passed on the third attempt. The Act abolished many borough seats and created others in their place, as well as expanding the franchise in England and Wales (a Scottish Reform Act and Irish Reform Act were passed separately). Minor reforms followed in 1835 and 1836.		On June 20 1837, Victoria became Queen of the United Kingdom on the death of her uncle, William IV. Being female, Victoria was prevented by Salic law from acceding to the throne of Hanover, as had been the custom for British monarchs since the Hanoverian succession; the kingdom passed instead to her uncle, who became King Ernest Augustus I of Hanover. The government at the time of Victoria's accession was led by the Whig prime minister Lord Melbourne, but within two years he had resigned, and the Tory politician Sir Robert Peel formed a new ministry. In the same year, a seizure of opium exports to China prompted the First Opium War against the Qing dynasty, and British imperial India initiated the First Anglo-Afghan War—one of the first major conflicts of the Great Game between Britain and Russia.[8]		In 1840, Queen Victoria married Prince Albert of Saxe-Coburg-Saalfield and gave birth to her first child, Victoria, who became Princess Royal. In the same year, the Treaty of Waitangi established British sovereignty over New Zealand. The signing of the Treaty of Nanking in 1842 ended the First Opium War and gave Britain control over Hong Kong Island, but a disastrous retreat from Kabul in the same year led to the annihilation of a British army column. In 1845, the Great Famine began to cause mass starvation and disease in Ireland, ultimately initiating widespread emigration;[9] in response, the Peel government repealed the Corn Laws, in the process leading to its downfall and replacement by the Whig ministry of Lord John Russell.[10]		In 1853, Britain intervened alongside France in the Crimean War, then being fought between the Ottoman and Russian empires; it sought to ensure that Russia could not benefit from the declining status of the Ottoman Empire,[11] a strategic consideration known as the Eastern Question. The conflict marked a rare breach in the Pax Britannica, the period of relative peace (1815-1914) that existed among the Great Powers of the time (and especially in Britain's interaction with them). On its conclusion in 1856 with the Treaty of Paris, Russia was prohibited from hosting a military presence in the Crimea. In October of the same year, the Second Opium War saw Britain once again in conflict with the Qing dynasty.		During 1857-8, an uprising by sepoys against the East India Company was suppressed, an event that led to the end of Company rule in India and the transferral of administration to the direct rule by the Crown.[12]		In 1861, Prince Albert died.[8] In 1867, the second Reform Act was passed, expanding the franchise, and the British North America Act consolidated the country's possessions in that region into a Canadian Confederation.[13]		In 1878, Britain was a plenipotentiary at the Treaty of Berlin, which gave de jure recognition to the independent states of Romania, Serbia, and Montenegro.		Nonconformist conscience describes the moral sensibility of the Nonconformist churches—those which dissent from the established Church of England—that influenced British politics in the 19th and early 20th centuries.[14][15] In the 1851 census of church attendance, noncomformists who went to chapel comprised half the attendance of Sunday services.[16] Noncomformists were focused in the fast-growing urban middle class.[17] The two categories of this group were in addition to the evangelicals or "Low Church" element in the Church of England: "Old Dissenters," dating from the 16th and 17th centuries, included Baptists, Congregationalists, Quakers, Unitarians, and Presbyterians outside Scotland; "New Dissenters" emerged in the 18th century and were mainly Methodists. The "Nonconformist conscience" of the Old group emphasised religious freedom and equality, the pursuit of justice, and opposition to discrimination, compulsion, and coercion. The New Dissenters (and also the Anglican evangelicals) stressed personal morality issues, including sexuality, temperance, family values, and Sabbath-keeping. Both factions were politically active, but until the mid-19th century, the Old group supported mostly Whigs and Liberals in politics, while the New—like most Anglicans—generally supported Conservatives. In the late 19th century, the New Dissenters mostly switched to the Liberal Party. The result was a merging of the two groups, strengthening their great weight as a political pressure group. The joined together on new issues especially regarding schools and temperance, with the latter of special interest to Methodists.[18][19] By 1914 the linkage was weakening and by the 1920s it was virtually dead.[20]		Parliament had long imposed a series of political disabilities on Nonconformists outside Scotland. They could not hold most public offices, they had to pay local taxes to the Anglican church, be married by Anglican ministers, and be denied attendance at Oxford or degrees at Cambridge. Dissenters demanded the removal of political and civil disabilities that applied to them (especially those in the Test and Corporation Acts). The Anglican establishment strongly resisted until 1828.[21] Disseneters organized into a political pressure group and succeeded in 1828 in repeal of some restrictions. It was a major achievement for an outside group, but the Dissenters were not finished and the early Victorian period saw them even more active and successful in eliminating their grievances.[22] Next on the agenda was the matter of church rates, which were local taxes at the parish level for the support of the parish church building in England and Wales. Only buildings of the established church received the tax money. Civil disobedience was attempted but was met with the seizure of personal property and even imprisonment. The compulsory factor was finally abolished in 1868 by William Ewart Gladstone, and payment was made voluntary.[23] While Gladstone was a moralistic evangelical inside the Church of England, he had strong support in the Nonconformist community.[24][25] The marriage question was settled in 1837, by allowing local government registrars to handle marriages. Nonconformist ministers in their own chapels were allowed to marry couples if a registrar was present. Also in 1836, civil registration of births, deaths, and marriages was taken from the hands of local parish officials and given to local government registrars. Burial of the dead was a more troubling problem, for urban chapels had no graveyards, and sought to use the traditional graveyards controlled by the established church. The Burials Act of 1880 finally allowed that.[26]		Oxford University required students seeking admission to submit to the 39 articles of the Church of England. Cambridge required that for a diploma. The two ancient universities opposed giving a charter to the new London University in the 1830s because it had no such restriction. London University, nevertheless, was established in 1837, and by the 1850s Oxford dropped its restrictions. In 1871 Gladstone sponsored legislation that provided full access to degrees and fellowships. The Scottish universities never had restrictions. Nonconformists (especially Unitarians and Presbyterians) played major roles in founding new universities in the late 19th century at Manchester, as well as Birmingham, Liverpool and Leeds.[27]		In prose, the novel rose from a position of relative neglect during the 1830s to become the leading literary genre by the end of the era.[6][28] In the 1830s and 1840s, the social novel (also "Condition-of-England novels") responded to the social, political and economic upheaval associated with industrialisation. Though it remained influential throughout the period, there was a notable resurgence of Gothic fiction in the fin de siecle, such as in Robert Louis Stevenson's novella Strange Case of Dr Jekyll and Mr Hyde (1886) and Oscar Wilde's The Picture of Dorian Gray (1891).		Popular forms of entertainment varied by social class. Victorian Britain, like the periods before it, was interested in literature (see Charles Dickens, Arthur Conan Doyle, Charlotte, Emily and Anne Brontë, Robert Louis Stevenson and William Makepeace Thackeray), theatre and the arts (see Aesthetic movement and Pre-Raphaelite Brotherhood), and music, drama, and opera were widely attended. Michael Balfe was the most popular British grand opera composer of the period, while the most popular musical theatre was a series of fourteen comic operas by Gilbert and Sullivan, although there was also musical burlesque and the beginning of Edwardian musical comedy in the 1890s. Drama ranged from low comedy to Shakespeare (see Henry Irving). There were, however, other forms of entertainment. Gentlemen went to dining clubs, like the Beefsteak club or the Savage club. Gambling at cards in establishments popularly called casinos was wildly popular during the period: so much so that evangelical and reform movements specifically targeted such establishments in their efforts to stop gambling, drinking, and prostitution.[29]		Brass bands and 'The Bandstand' became popular in the Victorian era. The band stand was a simple construction that not only created an ornamental focal point, but also served acoustic requirements whilst providing shelter from the changeable British weather. It was common to hear the sound of a brass band whilst strolling through parklands. At this time musical recording was still very much a novelty.[30]		The Victorian era marked the golden age of the British circus.[31]Astley's Amphitheatre in Lambeth, London, featuring equestrian acts in a 42-foot wide circus ring, was the epicentre of the 19th century circus. The permanent structure sustained three fires but as an institution lasted a full century, with Andrew Ducrow and William Batty managing the theatre in the middle part of the century. William Batty would also build his own 14,000-person arena, known commonly as Batty's Hippodrome, in Kensington Gardens and draw crowds from the Crystal Palace Exhibition. Travelling circuses, like Pablo Fanque's, dominated the British provinces, Scotland, and Ireland (Fanque would enjoy fame again in the 20th century when John Lennon would buy an 1843 poster advertising his circus and adapt the lyrics for The Beatles song, Being for the Benefit of Mr. Kite!). Fanque also stands out as a black man who achieved great success and enjoyed great admiration among the British public only a few decades after Britain had abolished slavery.[32][32]		Another form of entertainment involved 'spectacles' where paranormal events, such as mesmerism, communication with the dead (by way of mediumship or channelling), ghost conjuring and the like, were carried out to the delight of crowds and participants. Such activities were more popular at this time than in other periods of recent Western history.[33]		Natural history became increasingly an "amateur" activity. Particularly in Britain and the United States, this grew into specialist hobbies such as the study of birds, butterflies, seashells (malacology/conchology), beetles and wild flowers. Amateur collectors and natural history entrepreneurs played an important role in building the large natural history collections of the nineteenth and early twentieth centuries.[34][35]		Middle-class Victorians used the train services to visit the seaside, helped by the Bank Holiday Act of 1871, which created a number of fixed holidays. Large numbers travelling to quiet fishing villages such as Worthing, Brighton, Morecambe and Scarborough began turning them into major tourist centres, and people like Thomas Cook saw tourism and even overseas travel as viable businesses.[36]		The Victorian Era saw the introduction and development of many modern sports.[37] Often originating in the public schools, they exemplified new ideals of manliness.[38] Cricket,[39] cycling, croquet, horse-riding, and many water activities are examples of some of the popular sports in the Victorian Era. [40]		The modern game of tennis originated in Birmingham, England, between 1859 and 1865. The world's oldest tennis tournament, the Wimbledon championships, were first played in London in 1877. Britain was an active competitor in all the Olympic Games starting in 1896.		Historians have characterised the mid-Victorian era (1850–1870) as Britain's "Golden Years".[42] There was prosperity, as the national income per person grew by half. Much of the prosperity was due to the increasing industrialisation, especially in textiles and machinery, as well as to the worldwide network of trade and engineering that produced profits for British merchants, and exports from[clarification needed] across the globe. There was peace abroad (apart from the short Crimean war, 1854–56), and social peace at home. Opposition to the new order melted away, says Porter. The Chartist movement peaked as a democratic movement among the working class in 1848; its leaders moved to other pursuits, such as trade unions and cooperative societies. The working class ignored foreign agitators like Karl Marx in their midst, and joined in celebrating the new prosperity. Employers typically were paternalistic and generally recognised the trade unions.[43] Companies provided their employees with welfare services ranging from housing, schools and churches, to libraries, baths, and gymnasia. Middle-class reformers did their best to assist the working classes' aspirations to middle-class norms of "respectability".		There was a spirit of libertarianism, says Porter, as people felt they were free. Taxes were very low, and government restrictions were minimal. There were still problem areas, such as occasional riots, especially those motivated by anti-Catholicism. Society was still ruled by the aristocracy and the gentry, who controlled high government offices, both houses of Parliament, the church, and the military. Becoming a rich businessman was not as prestigious as inheriting a title and owning a landed estate. Literature was doing well, but the fine arts languished as the Great Exhibition of 1851 showcased Britain's industrial prowess rather than its sculpture, painting or music. The educational system was mediocre; the main universities (outside Scotland) were likewise mediocre.[44] Historian Llewellyn Woodward has concluded:[45]		The Victorians were impressed by science and progress and felt that they could improve society in the same way as they were improving technology. Britain was the leading world center for advanced engineering and technology. Its engineering firms were in worldwide demand for designing and constructing railways.[46][47]		A central development during the Victorian era was the improvement of communication. The new railways all allowed goods, raw materials, and people to be moved about, rapidly facilitating trade and industry. The financing of railways became an important specialty of London's financiers.[48] The railway system led to a reorganisation of society more generally, with "railway time" being the standard by which clocks were set throughout Britain; the complex railway system setting the standard for technological advances and efficiency. Steam ships such as the SS Great Britain and SS Great Western made international travel more common but also advanced trade, so that in Britain it was not just the luxury goods of earlier times that were imported into the country but essentials and raw materials such as corn and cotton from the United States and meat and wool from Australia. One more important innovation in communications was the Penny Black, the first postage stamp, which standardised postage to a flat price regardless of distance sent.		Even later communication methods such as electric power, telegraph, and telephones, had an impact. Photography was realised in 1839 by Louis Daguerre in France and William Fox Talbot in Britain. By 1889, hand-held cameras were available.[49]		Similar sanitation reforms, prompted by the Public Health Acts 1848 and 1869, were made in the crowded, dirty streets of the existing cities, and soap was the main product shown in the relatively new phenomenon of advertising. A great engineering feat in the Victorian Era was the sewage system in London. It was designed by Joseph Bazalgette in 1858. He proposed to build 82 mi (132 km) of sewer system linked with over 1,000 mi (1,600 km) of street sewers. Many problems were encountered but the sewers were completed. After this, Bazalgette designed the Thames Embankment which housed sewers, water pipes and the London Underground. During the same period, London's water supply network was expanded and improved, and a gas network for lighting and heating was introduced in the 1880s.[50]		The model town of Saltaire was founded, along with others, as a planned environment with good sanitation and many civic, educational and recreational facilities, although it lacked a pub, which was regarded as a focus of dissent. During the Victorian era, science grew into the discipline it is today. In addition to the increasing professionalism of university science, many Victorian gentlemen devoted their time to the study of natural history. This study of natural history was most powerfully advanced by Charles Darwin and his theory of evolution first published in his book On the Origin of Species in 1859.		Although initially developed in the early years of the 19th century, gas lighting became widespread during the Victorian era in industry, homes, public buildings and the streets. The invention of the incandescent gas mantle in the 1890s greatly improved light output and ensured its survival as late as the 1960s. Hundreds of gasworks were constructed in cities and towns across the country. In 1882, incandescent electric lights were introduced to London streets, although it took many years before they were installed everywhere.		One of the great achievements of the Industrial Revolution in Britain was the introduction and advancement of railway systems, not only in the United Kingdom and the British Empire but across the world. British engineers and financiers designed, built and funded many major systems. They retained an ownership share even while turning over management to locals; that ownership was largely liquidated in 1914-1916 to pay for the World War. Railroads originated in England because industrialists had already discovered the need for inexpensive transportation to haul coal for the new steam engines, and to supply parts to specialized factories, and to take products to market. The existing system of canals was inexpensive but was too slow and too limited in geography.[51]		The engineers and businessmen needed to create and finance a railway system were available; they knew how to invent, to build, and to finance a large complex system. The first quarter of the 19th century involved numerous experiments with locomotives and rail technology. By 1825 railways were commercially feasible, as demonstrated by George Stephenson (1791-1848) when he built the Stockton and Darlington. On his first run, his locomotive pulled 38 freight and passenger cars at speeds as high as 12 miles per hour. Stephenson went on to design many more railways and is best known for standardizing designs, such as the "standard gauge" of rail spacing, at 4 feet 8 ½ inches.[52] Thomas Brassey (1805–70) was even more prominent, operating construction crews that at one point in the 1840s totalled 75,000 men throughout Europe, the British Empire, and Latin America.[53] Brassey took thousands of British engineers and mechanics across the globe to build new lines. They invented and improved thousands of mechanical devices, and developed the science of civil engineering to build roadways, tunnels and bridges.[54]		Britain had a superior financial system based in London that funded both the railways in Britain and also in many other parts of the world, including the United States, up until 1914. The boom years were 1836 and 1845–47 when Parliament authorised 8,000 miles of lines at a projected cost of £200 million, which was about the same value as the country’s annual Gross Domestic Product (GDP) at that time. A new railway needed a charter, which typically cost over £200,000 (about $1 million) to obtain from Parliament, but opposition could effectively prevent its construction. The canal companies, unable or unwilling to upgrade their facilities to compete with railways, used political power to try to stop them. The railways responded by purchasing about a fourth of the canal system, in part to get the right of way, and in part to buy off critics. Once a charter was obtained, there was little government regulation, as laissez-faire and private ownership had become accepted practices.[55]		The different lines typically had exclusive territory, but given the compact size of Britain, this meant that multiple competing lines could provide service between major cities. George Hudson (1800-1871) became the "railway king" of Britain. He merged various independent lines and set up a "Clearing House" in 1842 which rationalized interconnections by establishing uniform paperwork and standard methods for transferring passengers and freight between lines, and rates when one system used freight cars owned by another. By 1850, rates had fallen to a penny a ton mile for coal, at speeds of up to fifty miles an hour. Britain now had had the model for the world in a well integrated, well-engineered system that allowed fast, cheap movement of freight and people, and which could be replicated in other major nations.		The railways directly or indirectly employed tens of thousands of engineers, mechanics, repairmen and technicians, as well as statisticians and financial planners. They developed new and more efficient and less expensive techniques. Most important, they created a mindset of how technology could be used in many different forms of business. Railways had a major impact on industrialization. By lowering transportation costs, they reduced costs for all industries moving supplies and finished goods, and they increased demand for the production of all the inputs needed for the railroad system itself. By 1880, there were 13,500 locomotives which each carried 97,800 passengers a year, or 31,500 tons of freight.[56]		India provides an example of the London-based financiers pouring money and expertise into a very well built system designed for military reasons (after the Mutiny of 1857), and with the hope that it would stimulate industry. The system was overbuilt and much too elaborate and expensive for the small amount of freight traffic it carried. However, it did capture the imagination of the Indians, who saw their railways as the symbol of an industrial modernity—but one that was not realized until a century or so later.[57]		Medicine progressed during Queen Victoria's reign. Although nitrous oxide, or laughing gas, had been proposed as an anaesthetic as far back as 1799 by Humphry Davy, it wasn't until 1846 when an American dentist named William Morton started using ether on his patients that anaesthetics became common in the medical profession.[58] In 1847 chloroform was introduced as an anaesthetic by James Young Simpson.[59] Chloroform was favoured by doctors and hospital staff because it is much less flammable than ether, but critics complained that it could cause the patient to have a heart attack.[59] Chloroform gained in popularity in England and Germany after John Snow gave Queen Victoria chloroform for the birth of her eighth child (Prince Leopold).[60] By 1920, chloroform was used in 80 to 95% of all narcoses performed in the UK and German-speaking countries.[59]		Anaesthetics made painless dentistry possible. At the same time sugar consumption in the British diet increased, greatly increasing instances of tooth decay .[61] As a result, more and more people were having teeth extracted and needing dentures. This gave rise to "Waterloo Teeth", which were real human teeth set into hand-carved pieces of ivory from hippopotamus or walrus jaws.[61][62] The teeth were obtained from executed criminals, victims of battlefields, from grave-robbers, and were even bought directly from the desperately impoverished.[61]		Medicine also benefited from the introduction of antiseptics by Joseph Lister in 1867 in the form of carbolic acid (phenol).[63] He instructed the hospital staff to wear gloves and wash their hands, instruments, and dressings with a phenol solution and in 1869, he invented a machine that would spray carbolic acid in the operating theatre during surgery.[63]		The Victorian era was a time of unprecedented population growth in Britain. The population rose from 13.9 million in 1831 to 32.5 million in 1901. Two major contributary factors were fertility rates and mortality rates. Britain was the first country to undergo the Demographic transition and the Agricultural and Industrial Revolutions.		Britain had the lead in rapid economic and population growth. At the time, Thomas Malthus believed this lack of growth outside Britain was due to the 'Malthusian trap'. That is, the tendency of a population to expand geometrically while resources grew more slowly, reaching a crisis (such as famine, war, or epidemic) which would reduce the population to a sustainable size. Britain escaped the 'Malthusian trap' because the Industrial Revolution had a positive impact on living standards.[64] People had more money and could improve their standards; therefore, a population increase was sustainable.		In the Victorian era, fertility rates increased in every decade until 1901, when the rates started evening out.[65] There were several reasons for this. One is biological: with improving living standards, a higher proportion of women were biologically able to have children. Another possible explanation is social. In the 19th century, the marriage rate increased, and people were getting married at a very young age until the end of the century, when the average age of marriage started to increase again slowly. The reasons why people got married younger and more frequently are uncertain. One theory is that greater prosperity allowed people to finance marriage and new households earlier than previously possible. With more births within marriage, it seems inevitable that marriage rates and birth rates would rise together.		Birth rates were originally measured by the 'Crude birth rate' – births per year divided by total population. This is indeed a crude measure, as key groups and their fertility rates are not clear. It is likely to be affected mainly by changes in the age distribution of the population. The Net Reproduction Rate was then introduced as an alternative measure: it measures the average fertility rate of women of child-bearing ages.		The evening out of fertility rates at the beginning of the 20th century was mainly the result of a few big changes: availability of forms of birth control, and changes in people's attitude towards sex.[66]		The mortality rates in England changed greatly through the 19th century. There was no catastrophic epidemic or famine in England or Scotland in the 19th century – it was the first century in which a major epidemic did not occur throughout the whole country, and deaths per 1000 of population per year in England and Wales fell from 21.9 from 1848–54 to 17 in 1901 (cf, for instance, 5.4 in 1971).[67] Social class had a significant effect on mortality rates: the upper classes had a lower rate of premature death early in the 19th century than poorer classes did.[68]		Environmental and health standards rose throughout the Victorian era; improvements in nutrition may also have played a role, although the importance of this is debated.[67] Sewage works were improved, as was the quality of drinking water. With a healthier environment, diseases were caught less easily and did not spread as much. Technology improved because the population had more money to spend on medical technology (for example, techniques to prevent death in childbirth, so that more women and children survived), which also led to a greater number of cures for diseases. However, there was a cholera epidemic in London in 1848–49, which killed 14,137 people, and another in 1853 killing 10,738. Reformers rushed to complete a modern London sewerage system.[69] Tuberculosis (spread in congested dwellings), lung diseases from the mines and typhoid remained common.		Gothic Revival architecture became increasingly significant during the period, leading to the Battle of the Styles between Gothic and Classical ideals. Charles Barry's architecture for the new Palace of Westminster, which had been badly damaged in an 1834 fire, was built in the medieval style of Westminster Hall, the surviving part of the building. It constructed a narrative of cultural continuity, set in opposition to the violent disjunctions of Revolutionary France, a comparison common to the period, as expressed in Thomas Carlyle's The French Revolution: A History and Charles Dickens' Great Expectations and A Tale of Two Cities. Gothic was also supported by critic John Ruskin, who argued that it epitomised communal and inclusive social values, as opposed to Classicism, which he considered to epitomise mechanical standardisation.[citation needed]		The middle of the 19th century saw The Great Exhibition of 1851, the first World's Fair, which showcased the greatest innovations of the century. At its centre was the Crystal Palace, a modular glass and iron structure – the first of its kind. It was condemned by Ruskin as the very model of mechanical dehumanisation in design but later came to be presented as the prototype of Modern architecture. The emergence of photography, showcased at the Great Exhibition, resulted in significant changes in Victorian art with Queen Victoria being the first British monarch to be photographed. John Everett Millais was influenced by photography (notably in his portrait of Ruskin) as were other Pre-Raphaelite artists. It later became associated with the Impressionistic and Social Realist techniques that would dominate the later years of the period in the work of artists such as Walter Sickert and Frank Holl.		The long-term effect of the reform movements was to tightly link the nonconformist element with the Liberal party. The dissenters gave significant support to moralistic issues, such as temperance and sabbath enforcement. The nonconformist conscience, as it was called, was repeatedly called upon by Gladstone for support for his moralistic foreign policy.[70] In election after election, Protestant ministers rallied their congregations to the Liberal ticket. In Scotland, the Presbyterians played a similar role to the Nonconformist Methodists, Baptists and other groups in England and Wales [71] The political strength of Dissent faded sharply after 1920 with the secularization of British society in the 20th century.		The rise of the middle class during the era had a formative effect on its character; the historian Walter E. Houghton reflects that "once the middle class attained political as well as financial eminence, their social influence became decisive. The Victorian frame of mind is largely composed of their characteristic modes of thought and feeling".[72]		Industrialisation brought with it a rapidly growing middle class whose increase in numbers had a significant effect on the social strata itself: cultural norms, lifestyle, values and morality. Identifiable characteristics came to define the middle class home and lifestyle. Previously, in town and city, residential space was adjacent to or incorporated into the work site, virtually occupying the same geographical space. The difference between private life and commerce was a fluid one distinguished by an informal demarcation of function. In the Victorian era, English family life increasingly became compartmentalised, the home a self-contained structure housing a nuclear family extended according to need and circumstance to include blood relations. The concept of "privacy" became a hallmark of the middle-class life.		The English home closed up and darkened over the decade (1850s), the cult of domesticity matched by a cult of privacy. Bourgeois existence was a world of interior space, heavily curtained off and wary of intrusion, and opened only by invitation for viewing on occasions such as parties or teas. "The essential, unknowability of each individual, and society's collaboration in the maintenance of a façade behind which lurked innumerable mysteries, were the themes which preoccupied many mid-century novelists."[73]		There were four major factors that radically transformed newspapers in 19th century Britain. First, by the 1830s the government had ended very high taxes and lifted severe legal restraints. Second, new machines, especially the rotary press, allowed the printing of tens of thousands of copies a day at a low cost. Third, the newspapers reached out to new readers in multiple ways, including features, illustrations, and advertisements that enlarged the audience. Finally, the franchise was expanded from one or two percent of the men to a majority, and newspapers became the primary means of political education.[74]		In 1817 Thomas Barnes became general editor of The Times; he was a political radical, a sharp critic of parliamentary hypocrisy and a champion of freedom of the press.[75] Under Barnes and his successor in 1841, John Thadeus Delane, the influence of The Times rose to great heights, especially in politics and in the financial district (the City of London). It spoke of reform.[76] The Times originated the practice of sending war correspondents to cover particular conflicts. W. H. Russell wrote immensely influential dispatches on the Crimean War of 1853-1856; for the first time, the public could read about the reality of warfare. Russell wrote one dispatch that highlighted the surgeons' "inhumane barbarity" and the lack of ambulance care for wounded troops. Shocked and outraged, the public reacted in a backlash that led to major reforms especially in the provision of nursing, led by Florence Nightingale.[77]		The Manchester Guardian was founded in Manchester in 1821 by a group of non-conformist businessmen. Its most famous editor, Charles Prestwich Scott, made the Guardian into a world-famous newspaper in the 1890s. The Daily Telegraph in 1856 became the first penny newspaper in London. It was funded by advertising revenue based on a large audience.		Opportunities for leisure activities increased dramatically as real wages continued to grow and hours of work continued to decline. In urban areas, the nine-hour workday became increasingly the norm; the 1874 Factory Act limited the workweek to 56.5 hours, encouraging the movement toward an eventual eight-hour workday. Furthermore, a system of routine annual vacations came into play, starting with white-collar workers and moving into the working-class.[78][79] Some 200 seaside resorts emerged thanks to cheap hotels and inexpensive railway fares, widespread banking holidays and the fading of many religious prohibitions against secular activities on Sundays.[80]		By the late Victorian era, the leisure industry had emerged in all cities. It provided scheduled entertainment of suitable length at convenient locales at inexpensive prices. These included sporting events, music halls, and popular theater. By 1880 football was no longer the preserve of the social elite, as it attracted large working-class audiences. Average gate attendance was 5000 in 1905, rising to 23,000 in 1913. That amounted to 6 million paying customers with a weekly turnover of £400,000. Sports by 1900 generated some three percent of the total gross national product. Professional sports were the norm, although some new activities reached an upscale amateur audience, such as lawn tennis and golf. Women were now allowed in some sports, such as archery, tennis, badminton and gymnastics.[81]		The very rapid growth in population in the 19th century in the cities included the new industrial and manufacturing cities, as well as service centers such as Edinburgh and London. The critical factor was financing, which was handled by building societies that dealt directly with large contracting firms. [82][83] Private renting from housing landlords was the dominant tenure. P. Kemp says this was usually of advantage to tenants.[84] People moved in so rapidly that there was not enough capital to build adequate housing for everyone, so low income newcomers squeezed into increasingly overcrowded slums. Clean water, sanitation, and public health facilities were inadequate; the death rate was high, especially infant mortality, and tuberculosis among young adults. Cholera from polluted water and typhoid were endemic. Unlike rural areas, there were no famines such as devastated Ireland in the 1840s.[85] [86][87]		19th century Britain saw a huge population increase accompanied by rapid urbanisation stimulated by the Industrial Revolution. Wage rates improved steadily; real wages (after taking inflation into account) were 65 percent higher in 1901, compared 1871. Much of the money was saved, as the number of depositors in savings banks rose from 430,000 in 1831, to 5.2 million in 1887, and their deposits from £14 million to over £90 million.[88] People flooded into industrial areas and commercial cities faster than housing could be built, resulting in overcrowding And lagging sanitation facilities such as fresh water and sewage. These problems were magnified in London, where the population grew at record rates. Large houses were turned into flats and tenements, and as landlords failed to maintain these dwellings, slum housing developed. Kellow Chesney described the situation as follows: "Hideous slums, some of them acres wide, some no more than crannies of obscure misery, make up a substantial part of the metropolis... In big, once handsome houses, thirty or more people of all ages may inhabit a single room."[89] Significant changes happened in the British Poor Law system in England and Wales, Scotland, and Ireland. These included a large expansion in workhouses (or poorhouses in Scotland), although with changing populations during the era.		The early Victorian era before the reforms of the 1840s became notorious for the employment of young children in factories and mines and as chimney sweeps.[91][92] Child labour played an important role in the Industrial Revolution from its outset: novelist Charles Dickens, for example, worked at the age of 12 in a blacking factory, with his family in a debtors' prison. Reformers wanted the children in school: in 1840 only about 20 percent of the children in London had any schooling. By 1860 about half of the children between 5 and 15 were in school (including Sunday school).[93]		The children of the poor were expected to help towards the family budget, often working long hours in dangerous jobs for low wages.[89] Agile boys were employed by the chimney sweeps; small children were employed to scramble under machinery to retrieve cotton bobbins; and children were also employed to work in coal mines, crawling through tunnels too narrow and low for adults. Children also worked as errand boys, crossing sweepers, shoe blacks, or sold matches, flowers, and other cheap goods.[89] Some children undertook work as apprentices to respectable trades, such as building, or as domestic servants (there were over 120,000 domestic servants in London in the mid 19th century). Working hours were long: builders might work 64 hours a week in summer and 52 in winter, while domestic servants were theoretically on duty 80-hours a week.		"Mother bides at home, she is troubled with bad breath, and is sair weak in her body from early labour. I am wrought with sister and brother, it is very sore work; cannot say how many rakes or journeys I make from pit's bottom to wall face and back, thinks about 30 or 25 on the average; the distance varies from 100 to 250 fathom. I carry about 1 cwt. and a quarter on my back; have to stoop much and creep through water, which is frequently up to the calves of my legs." (Isabella Read, 12 years old, coal-bearer, testimony gathered by Ashley's Mines Commission 1842)[90]		As early as 1802 and 1819, Factory Acts were passed to limit the working hours of workhouse children in factories and cotton mills to 12 hours per day. These acts were largely ineffective and after radical agitation, by for example the "Short Time Committees" in 1831, a Royal Commission recommended in 1833 that children aged 11–18 should work a maximum of 12 hours per day, children aged 9–11 a maximum of eight hours, and children under the age of nine should no longer be permitted to work. This act, however, only applied to the textile industry, and further agitation led to another act in 1847 limiting both adults and children to 10-hour working days.[93]		The Victorian era is famous for the Victorian standards of personal morality. Historians generally agree that the middle classes held high personal moral standards (and usually followed them), but have debated whether the working classes followed suit. Moralists in the late 19th century such as Henry Mayhew decried the slums for their supposed high levels of cohabitation without marriage and illegitimate births. However new research using computerized matching of data files shows that the rates of cohabitation were quite low—under 5%—for the working class and the poor. By contrast in 21st century Britain, nearly half of all children are born outside marriage, and nine in ten newlyweds have been cohabitating.[94]		Prostitution had been a factor in city life for centuries. The reformers started mobilizing in the late 1840s, major news organisations, clergymen, and single women became increasingly concerned about prostitution, which came to be known as "The Great Social Evil".[95] Estimates of the number of prostitutes in London in the 1850s vary widely (in his landmark study, Prostitution, William Acton reported that the police estimated there were 8,600 in London alone in 1857).		While the Magdalene Asylums had been reforming prostitutes since the mid-18th century, the years between 1848 and 1870 saw a veritable explosion in the number of institutions working to "reclaim" these "fallen women" from the streets and retrain them for entry into respectable society — usually for work as domestic servants. The theme of prostitution and the "fallen woman" (any woman who has had sexual intercourse out of marriage) became a staple feature of mid-Victorian literature and politics. In the writings of Henry Mayhew, Charles Booth, Charles Dickens and others, prostitution began to be seen as a social problem.		When Parliament passed the first of the Contagious Diseases Acts in 1864 (which allowed the local constabulary to force any woman suspected of venereal disease to submit to its inspection), Josephine Butler's crusade to repeal the CD Acts yoked the anti-prostitution cause with the emergent feminist movement. Butler attacked the long-established double standard of sexual morality.[96]		Prostitutes were often presented as victims in sentimental literature such as Thomas Hood's poem The Bridge of Sighs, Elizabeth Gaskell's novel Mary Barton, and Dickens' novel Oliver Twist. The emphasis on the purity of women found in such works as Coventry Patmore's The Angel in the House led to the portrayal of the prostitute and fallen woman as soiled, corrupted, and in need of cleansing.[97]		This emphasis on female purity was allied to the stress on the homemaking role of women, who helped to create a space free from the pollution and corruption of the city. In this respect, the prostitute came to have symbolic significance as the embodiment of the violation of that divide. The double standard remained in force. Divorce legislation introduced in 1857 allowed for a man to divorce his wife for adultery, but a woman could only divorce if adultery were accompanied by cruelty. The anonymity of the city led to a large increase in prostitution and unsanctioned sexual relationships. Dickens and other writers associated prostitution with the mechanisation and industrialisation of modern life, portraying prostitutes as human commodities consumed and thrown away like refuse when they were used up. Moral reform movements attempted to close down brothels, something that has sometimes been argued to have been a factor in the concentration of street-prostitution.[98]		
Kent /ˈkɛnt/ is a county in South East England and one of the home counties. It borders Greater London to the north west, Surrey to the west and East Sussex to the south west. The county also shares borders with Essex along the estuary of the River Thames, and with the French department of Pas-de-Calais along the English Channel. The county town is Maidstone.		Canterbury Cathedral in Kent has been the seat of the Archbishop of Canterbury, leader of the Church of England, since the conversion of England to Christianity by Saint Augustine began in the 6th century. Between London and the Strait of Dover, which separates it from mainland Europe, Kent has seen both diplomacy and conflict, ranging from the Leeds Castle peace talks of 1978 and 2004 to the Battle of Britain in World War II.		England relied on the county's ports to provide warships through much of its history; the Cinque Ports in the 12th–14th centuries and Chatham Dockyard in the 16th–20th centuries were of particular importance. France can be seen clearly in fine weather from Folkestone and the White Cliffs of Dover. Hills in the form of the North Downs and the Greensand Ridge span the length of the county and in the series of valleys in between and to the south are most of the county's 26 castles.		Because of its relative abundance of fruit-growing and hop gardens, Kent is known as 'The Garden of England'.[2][3] The title was defended in 2006 when a survey of beautiful counties by the UKTV Style Gardens channel put Kent in fifth place, behind North Yorkshire, Devon, Derbyshire and Gloucestershire.[4]		Kent's economy is greatly diversified. Haulage, logistics, and tourism are major industries; major industries in north-west Kent include aggregate building materials, printing and scientific research. Coal mining has also played its part in Kent's industrial heritage. Large parts of Kent are within the London commuter belt and its strong transport connections to the capital and the nearby continent makes Kent a high income county. Twenty-eight per cent of the county forms part of two Areas of Outstanding Natural Beauty: the North Downs and The High Weald.						The name Kent is believed to be of British Celtic origin and was known in Old English as Cent, Cent lond, Centrice. In Latin sources Kent is mentioned as Cantia, Canticum. The meaning is explained by some researchers as "coastal district," or "corner-land, land on the edge" (compare Welsh cant "bordering of a circle, tire, edge," Breton cant "circle").[5] If so, the name could be related to the same ancient word as the name of Cantabria, a coastal province in Spain.		The area has been occupied since the Palaeolithic era, as attested by finds from the quarries at Swanscombe. The Medway megaliths were built during the Neolithic era. There is a rich sequence of Bronze Age, Iron Age, and Roman era occupation, as indicated by finds and features such as the Ringlemere gold cup and the Roman villas of the Darent valley.[6]		The modern name of Kent is derived from the Brythonic word kantos meaning "rim" or "border" or maybe from a homonymous word kanto "horn, hook" (< PIE *kn̥g-tó, cfr. cornwall < cornus "horn"). This describes the eastern part of the current county area as a border land or coastal district. Julius Caesar had described the area as Cantium, or home of the Cantiaci in 51 BC.[7] The extreme west of the modern county was by the time of Roman Britain occupied by Iron Age tribes, known as the Regnenses.		East Kent became a kingdom of the Jutes during the 5th century[8] and was known as Cantia from about 730 and recorded as Cent in 835. The early medieval inhabitants of the county were known as the Cantwara, or Kent people. These people regarded the city of Canterbury as their capital.[9]		In 597, Pope Gregory I appointed the religious missionary (who became Saint Augustine of Canterbury after his death) as the first Archbishop of Canterbury. In the previous year, Augustine successfully converted the pagan King Æthelberht of Kent to Christianity. The Diocese of Canterbury became Britain's first Episcopal See with first cathedral and has since remained England's centre of Christianity.[10] The second designated English cathedral was in Kent at Rochester Cathedral.[11]		In the 11th century, the people of Kent adopted the motto Invicta, meaning "undefeated". This naming followed the invasion of Britain by William of Normandy. The Kent people's continued resistance against the Normans led to Kent's designation as a semi-autonomous county palatine in 1067. Under the nominal rule of William's half-brother Odo of Bayeux, the county was granted similar powers to those granted in the areas bordering Wales and Scotland.[12] Kent was traditionally partitioned into East and West Kent, and into lathes and hundreds.		During the medieval and early modern period, Kent played a major role in several of England's most notable rebellions, including the Peasants' Revolt of 1381, led by Wat Tyler,[13] Jack Cade's Kent rebellion of 1450, and Wyatt's Rebellion of 1554 against Queen Mary I.[14]		The Royal Navy first used the River Medway in 1547. By the reign of Elizabeth I (1558–1603) a small dockyard had been established at Chatham. By 1618, storehouses, a ropewalk, a drydock, and houses for officials had been built downstream from Chatham.[15]		By the 17th century, tensions between Britain and the powers of the Netherlands and France led to increasing military build-up in the county. Forts were built all along the coast following the raid on the Medway, a successful attack by the Dutch navy on the shipyards of the Medway towns in 1667.[16]		The 18th century was dominated by wars with France, during which the Medway became the primary base for a fleet that could act along the Dutch and French coasts. When the theatre of operation moved to the Atlantic, this role was assumed by Portsmouth and Plymouth, with Chatham concentrating on shipbuilding and ship repair. As an indication of the area's military importance, the first Ordnance Survey map ever drawn was a one-inch map of Kent, published in 1801.[17] Many of the Georgian naval buildings still stand.		In the early 19th century, smugglers were very active on the Kent coastline. Gangs such as The Aldington Gang brought spirits, tobacco and salt to the county, and transported goods such as wool across the sea to France.[18]		In 1889, the County of London was created and it took over responsibility for local administration of parts of north-west Kent. This included the towns of Deptford, Greenwich, Woolwich, Lee, Eltham, Charlton, Kidbrooke and Lewisham. In 1900 the area of Penge was gained. Some of Kent is contiguous with the Greater London sprawl, notably parts of Dartford.		During World War II, much of the Battle of Britain was fought in the skies over the county. Between June 1944 and March 1945, over 10,000 V1 flying bombs or "Doodlebugs", were fired toward London from bases in Northern France. Although many were destroyed by aircraft, anti-aircraft guns, and barrage balloons, both London and Kent were hit by around 2,500 of these bombs.		After the war, Kent's borders changed several more times. In 1965 the London boroughs of Bromley and Bexley were created from nine towns formerly in Kent.[19][20] In 1998, Rochester, Chatham, Gillingham, and Rainham left the administrative county of Kent to form the Unitary Authority of Medway. During this reorganisation, through an "apparent" administrative oversight, the city of Rochester lost its official city status.[21] In 2016 consultations began between five Kent local authorities (Canterbury, Thanet, Dover, Shepway and Ashford) with a view to forming a new Unitary Authority for East Kent, outside the auspices of Kent County Council.		For almost nine centuries a small part of present-day East London (the North Woolwich, London E16 area), formed part of Kent. The most likely reason for this is that in 1086 Hamon, dapifer and Sheriff of Kent, owned the manor and, perhaps illegally, annexed it to Kent. It ceased to be considered part of the county in 1965[disputed (for: contradicting related articles)  – discuss] upon creation of the London Borough of Newham.		Kent is one of the warmest parts of Britain. On 10 August 2003, in the hamlet of Brogdale near Faversham the temperature reached 38.5 °C (101.3 °F), the hottest temperature ever officially recorded in the United Kingdom.[22]		Kent is in the southeastern corner of England. It borders the River Thames and the North Sea to the north, and the Straits of Dover and the English Channel to the south. France is 34 kilometres (21 mi) across the Strait.[24]		The major geographical features of the county are determined by a series of ridges and valleys running east-west across the county. These are the results of erosion of the Wealden dome, a dome across Kent and Sussex created by alpine movements 10–20 million years ago. This dome consists of an upper layer of chalk above successive layers of Upper Greensand, Gault Clay, Lower Greensand, Weald Clay, and Wealden sandstone. The ridges and valleys formed when the exposed clay eroded faster than the exposed chalk, greensand, or sandstone.		Sevenoaks, Maidstone, Ashford, and Folkestone are built on greensand,[25] while Tonbridge and Tunbridge Wells are built on sandstone.[26] Dartford, Gravesend, the Medway towns, Sittingbourne, Faversham, Canterbury, Deal, and Dover are built on chalk.[25][26] The easterly section of the Wealden dome has been eroded away by the sea, and cliffs such as the White Cliffs of Dover are present where a chalk ridge known as the North Downs meets the coast. Spanning Dover and Westerham is the Kent Downs Area of Outstanding Natural Beauty.[27]		The Wealden dome is a Mesozoic structure lying on a Palaeozoic foundation, which can often create the right conditions for coal formation. This is found in East Kent roughly between Deal, Canterbury, and Dover. The Coal Measures within the Westphalian Sandstone are deep about 250–400 m (820–1,310 ft) and subject to flooding. They occur in two major troughs, which extend under the English Channel where similar coalfields are located.[28]		Seismic activity has occasionally been recorded in Kent, though the epicentres were offshore. In 1382 and 1580 there were two earthquakes exceeding 6.0 on the Richter Scale. In 1776, 1950, and on 28 April 2007 there were earthquakes of around 4.3. The 2007 earthquake caused physical damage in Folkestone.[29] A further quake on 22 May 2015 measured 4.2 on the Richter Scale.[30] The epicentre was in the Sandwich area of east Kent at a depth of some ten miles from the surface. There was little if any damage reported.		The coastline of Kent is continuously changing, due to tectonic uplift and coastal erosion. Until about 960, the Isle of Thanet was an island, separated by the Wantsum channel, formed around a deposit of chalk; over time, the channels silted up with alluvium. Similarly Romney Marsh and Dungeness have been formed by accumulation of alluvium.[26]		Kent's principal river, the River Medway, rises near East Grinstead in Sussex and flows eastwards to Maidstone. Here it turns north and breaks through the North Downs at Rochester, then joins the estuary of the River Thames as its final tributary near Sheerness. The Medway is some 112 kilometres (70 mi) long.[31][32] The river is tidal as far as Allington lock, but in earlier times, cargo-carrying vessels reached as far upstream as Tonbridge.[31] The Medway has captured the head waters of other rivers such as the River Darent. Other rivers of Kent include the River Stour in the east.		At the 2011 census,[33] Kent, including Medway, had 1,727,665 residents (18.0% of which in Medway); had 711,847 households (17.5% of which in Medway) and had 743,436 dwellings (14.8% of which in Medway). 51.1% of Kent's population excluding Medway was female — as to Medway this proportion was 50.4%.		The tables below provide statistics for the administrative county of Kent, that is, excluding Medway.		Kent County Council (KCC) and its 12 district councils administer most of the county (3352 km²), while the Medway Towns Council, a unitary authority and commonly called Medway Council, administers the more densely populated remainder (192 km²).[34] Together they have around 300 town and parish councils. Kent County Council's headquarters are in Maidstone,[35] while Medway's offices are at Gun Wharf, Chatham.		At the 2013 county council elections, control of Kent County Council was held by the Conservatives, which won 44 of the council's 83 seats. 17 seats were won by the United Kingdom Independence Party, 13 by the Labour Party, 7 were won by the Liberal Democrats, 1 by the Green Party and 1 by the Swanscombe and Greenhithe Residents Association. At the 2007 local elections, control of Medway Council was held by the Conservatives; 33 of the council's 55 seats were held by the Conservatives, 13 by the Labour Party, 8 by the Liberal Democrats and 1 by an Independent.[36] All but one of Kent's district councils are controlled by the Conservatives, a minority Labour administration taking control of Thanet District in December 2011 following the defection of a Conservative councillor to the Independent group. In the council elections of May 2015 the United Kingdom Independence Party (UKIP) took control of the Council, the first and so far only one in the UK. In October 2015 UKIP lost overall control following a series of resignations, although remaining the largest party, only for UKIP to regain control once more following ward elections in August 2016.		At the national level, Kent is represented in Parliament by 17 MPs, all of whom were Conservative until the general election of June 2017.[37] During this election the constituency of Canterbury elected Rosie Duffield, the first ever labour MP to hold the seat since the constituency was formed in 1918.[38] Kent is in the European Parliament constituency of South East England, which elects ten members of the European Parliament.[39]		At the 2001 UK census,[33] employment statistics for the residents in Kent, including Medway, were as follows: 41.1% in full-time employment, 12.4% in part-time employment, 9.1% self-employed, 2.9% unemployed, 2.3% students with jobs, 3.7% students without jobs, 12.3% retired, 7.3% looking after home or family, 4.3% permanently sick or disabled, and 2.7% economically inactive for other reasons. Of residents aged 16–74, 16% had a higher education qualification or the equivalent, compared to 20% nationwide.[33]		The average hours worked per week by residents of Kent were 43.1 for males and 30.9 for females. Their industry of employment was 17.3% retail, 12.4% manufacturing, 11.8% real estate, 10.3% health and social work, 8.9% construction, 8.2% transport and communications, 7.9% education, 6.0% public administration and defence, 5.6% finance, 4.8% other community and personal service activities, 4.1% hotels and restaurants, 1.6% agriculture, 0.8% energy and water supply, 0.2% mining, and 0.1% private households. This is higher than the whole of England for construction and transport/communications, and lower for manufacturing.		Kent is sometimes known as the "Garden of England" for its abundance of orchards and hop gardens. Distinctive hop-drying buildings called oasts are common in the countryside, although many have been converted into dwellings. Nearer to London, market gardens also flourish.		Kent is the main area for hazelnut production in the UK.[40] However, in recent years, there has been a significant drop in agriculture, and industry and services are increasing their utilisation of the area. This is illustrated by the following table of economic indicator gross value added (GVA) between 1995 and 2000 (figures are in millions of British Pounds Sterling).[41]		North Kent is heavily industrialised with cement-making at Northfleet and Cuxton, brickmaking at Sittingbourne, shipbuilding on the Medway and Swale, engineering and aircraft design and construction at Rochester, chemicals at Dartford and papermaking at Swanley, and oil refining at Grain.[19] A steel mini mill in Sheerness and a rolling mill in Queenborough.There are two nuclear power stations at Dungeness, although the older one, built in 1965, was closed at the end of 2006.[42]		Cement-making, papermaking, and coal-mining were important industries in Kent during the 19th and 20th century. Cement came to the fore in the 19th century when massive building projects were undertaken. The ready supply of chalk and huge pits between Stone and Gravesend bear testament to that industry. There were also other workings around Burham on the tidal Medway.[43]		Kent's original paper mills stood on streams like the River Darent, tributaries of the River Medway, and on the River Stour. Two 18th century mills were on the River Len and at Tovil on the River Loose. In the late 19th century huge modern mills were built at Dartford and Northfleet on the River Thames and at Kemsley on The Swale. In pre-industrial times, almost every village and town had its own windmill or watermill, with over 400 windmills known to have stood at some time. Twenty eight survive within the county today, plus two replica mills and a further two in that part of Kent now absorbed into London. All the major rivers in the county were used to power watermills.		From about 1900, several coal pits operated in East Kent. The Kent Coalfield was mined during the 20th century at several collieries,[44] including Chislet, Tilmanstone, Betteshanger, and the Snowdown Colliery, which ran from 1908 to 1986.[45]		The west of the county (including Tunbridge Wells, Tonbridge and Sevenoaks) has less than 50% of the average claimant count for low incomes or worklessness as the coastal districts of Dover, Shepway (main conurbation: Folkestone and Hythe) and Thanet (chiefly three resorts: Ramsgate, Broadstairs and Margate). West and Central Kent has long had many City of London commuters. Since the Channel Tunnel Rail Link improvements of 2009 to High Speed 1, services from Ebbsfleet near Dartford and from Ashford have become frequent, express to Central London, Paris and Brussels.		Kent's geographical location between the Straits of Dover and London has impacted its architecture, as has its cretacious geology and its good farming land and fine building clays. Kent's countryside pattern was determined by a gavelkind inheritance system that generated a proliferation of small settlements. There was no open-field system, and the large tracts were owned by the two great abbeys, Christ Church, Canterbury and St Augustine's Abbey, that did not pass into the hands of the king during the Reformation. Canterbury Cathedral is the United Kingdom's metropolitan cathedral; it was founded in AD 598 and displays architecture from all periods. There are nine Anglo-Saxon churches in Kent. Rochester Cathedral is England's second oldest cathedral, the present building built in the Early English Style.[46] These two dioceses ensured that every village had a parish church.		The sites of Richborough Castle and Dover Castle, along with two strategic sites along Watling Street, were fortified by the Romans and Normans. Other important sites include Canterbury city walls and Rochester Castle.[clarification needed][47] There remained a need to defend London and thus Kent. Deal Castle, Walmer Castle, Sandown Castle (whose remains were eroded by the sea in the 1990s) were constructed in late mediaeval times, and HM Dockyard, at Chatham and its surrounding castles and forts—Upnor Castle, Great Lines, and Fort Amherst—more recently.		Kent has three unique vernacular architecture forms: the Oast house, the Wealden hall house, and Kentish peg-tiles.		Kent has bridge trusts to maintain its bridges, and though the great bridge (1387) at Rochester was replaced there are medieval structures at Aylesford, Yalding and Teston.[48] With the motorways in the late twentieth century came the M2 motorway bridge spanning the Medway and the Dartford tunnel and the Dartford Bridge spanning the Thames.		The Bluewater shopping centre is the United Kingdom's largest shopping mall.		Kent has provided inspiration for several notable writers and artists. Canterbury's religious role gave rise to Chaucer's Canterbury Tales, a key development in the English language. The father of novelist Charles Dickens worked at the Chatham Dockyard; in many of his books, the celebrated novelist featured the scenery of Chatham, Rochester, and the Cliffe marshes.[49] During the late 1930s, Nobel Prize-awarded novelist William Golding worked as a teacher at Maidstone Grammar School, where he met his future wife Ann Brookfield.[50]		A number of significant artists came from Kent, including Thomas Sidney Cooper, a painter of landscapes, often incorporating farm animals,[51] Richard Dadd, a maker of faery paintings, and Mary Tourtel, the creator of the children's book character, Rupert Bear. The artist Clive Head was also born in Kent. The landscape painter J. M. W. Turner spent part of his childhood in the town of Margate in East Kent, and regularly returned to visit it throughout his life. The East Kent coast inspired many of his works, including some of his most famous seascapes.[52] Kent has also been the home to artists including Frank Auerbach, Tracey Emin and Stass Paraskos.		Kent was also the location of the largest number of art schools in the country during the nineteenth century, estimated by the art historian David Haste, to approach two hundred. This is believed to be the result of Kent being a front line county during the Napoleonic Wars. At this time, before the invention of photography, draughtsman were used to draw maps and topographical representations of the fields of battle, and after the wars ended many of these settled permanently in the county in which they had been based. Once the idea of art schools had been established, even in small towns in Kent, the tradition continued, although most of the schools were very small one man operations, each teaching a small number of daughters of the upper classes how to draw and make watercolour paintings. Nonetheless, some of these small art schools developed into much larger organisations, including Canterbury College of Art, founded by Thomas Sidney Cooper in 1868, which is today the University for the Creative Arts.[53]		The county's largest theatre is the Marlowe Theatre, situated in the centre of Canterbury. It re-opened, after being completely rebuilt, in October 2011.[54] Music festivals that take place in Kent include Chilled in a Field Festival, Electric Gardens, Hop Farm Festival, In the Woods Festival, and Lounge On The Farm.		With the Roman invasion, a road network was constructed to connect London to the Channel ports of Dover, Lympne and Richborough. The London–Dover road was Watling Street. These roads are now approximately the A2, B2068, A257, and the A28. The A2 runs through Dartford (A207), Gravesend, Rochester, Canterbury and Dover; the A20 through Eltham, Wrotham, Maidstone, Charing, Ashford. Hythe, Folkestone and Dover; the A21 around Sevenoaks, Tonbridge, Tunbridge Wells and on to Hastings in East Sussex.[19] In the 1960s, two motorways were built; the M2 from Medway to Faversham, and the M20 from Swanley to Folkestone. Part of the M25 runs through Kent, from Westerham to the Kent and Essex tunnel at Dartford. The Dartford tunnel has been joined by the Queen Elizabeth II Bridge, together providing four lanes in each direction. The M26 motorway, built in 1980, provides a short link between the M25 at Sevenoaks and the M20 near Wrotham. Kent currently has more motorways by distance than any other county in the UK, with sections of the M2, M20, M25 and M26 totalling 173 km (107 mi) within the extents of the ceremonial county.		The medieval Cinque Ports, except for the Port of Dover, have all now silted up. The Medway Estuary has been an important port and naval base for 500 years. The River Medway is tidal up to Allington and navigable up to Tonbridge. Kent's two canals are the Royal Military Canal between Hythe and Rye, which still exists, and the Thames and Medway Canal between Strood and Gravesend. Built in 1824, it was purchased in 1846 by the railways, which partially backfilled it.[19] Container ports are located at Ramsgate and Thamesport.		The earliest locomotive-driven passenger-carrying railway in Britain was the Canterbury and Whitstable Railway which opened in 1830.[55] This and the London and Greenwich Railway later merged into South Eastern Railway (SER).[56] By the 1850s, SER's networks had expanded to Ashford, Ramsgate, Canterbury, Tunbridge Wells, and the Medway towns. SER's major London termini were London Bridge, Charing Cross, and Cannon Street. Kent also had a second major railway, the London, Chatham and Dover Railway (LCDR). Originally the East Kent Railway in 1858, it linked the northeast Kent coast with London terminals at Victoria and Blackfriars.		The two companies merged in 1899, forming the South Eastern and Chatham Railway (SECR), further amalgamated with other railways by the Railways Act 1921 to form the Southern Railway.[56] Britain's railways were nationalised in 1948, forming British Railways (shortened to British Rail in the mid-1960s). The railways were privatised in 1996 and most Kent passenger services were franchised to Connex South Eastern.[57] Following financial difficulties, Connex lost the franchise and was replaced by South Eastern Trains and after Southeastern.[58]		The Channel Tunnel was completed in 1994 and High Speed 1 in November 2007 with a London terminus at St Pancras. A new station, Ebbsfleet International, opened between Dartford and Gravesend, serving northern Kent.[59] The high speed lines will be utilised to provide a faster train service to coastal towns like Ramsgate and Folkestone. This station is in addition to the existing station at Ashford International, which has suffered a massive cut in service as a result.		In addition to the "main line" railways, there are several light, heritage, and industrial railways in Kent. There are three heritage, standard gauge railways; Spa Valley Railway near Tunbridge Wells on the old Tunbridge Wells West branch, East Kent Railway on the old East Kent coalfield area and the Kent and East Sussex Railway on the Weald around Tenterden. In addition there is the 15-inch (380 mm) gauge, Romney, Hythe and Dymchurch Railway on the southeast Kent coast along the Dungeness peninsula. Finally, there is the 2 ft 6 in (0.76 m), industrial Sittingbourne & Kemsley Light Railway, previously the Bowaters Paper Railway.		A limited number of charter flights are provided by London Ashford Airport at Lydd. However, most passengers across the South East use the larger Heathrow, Gatwick, Stansted and Luton airports.		In 2002, it was revealed that the government was considering building a new four-runway airport on the marshland near the village of Cliffe on Hoo Peninsula.[60] This plan was dropped in 2003 following protests by cultural and environmental groups.[61] However further plans for a Thames Estuary Airport on the Kent coast have subsequently emerged, including the Thames Hub Airport, again sited on the Isle of Grain and designed by Lord Foster,[62][63] and the London Britannia Airport plan, colloquially known as "Boris Island" due to its being championed by the former Mayor of London Boris Johnson, which would see a six runway airport built on an artificial island to be located towards the Shivering Sands area, north-east of Whitstable.[63][64] Both of these options were dropped in 2014 in favour of expansion at either Gatwick or Heathrow Airport, the latter finally being the chosen option following Teresa May's installation as Prime Minister in summer 2016.				Kent has four universities: Canterbury Christ Church University with campuses throughout East Kent; University of Kent, with campuses in Canterbury and Medway; University of Greenwich (a London University), with sites at Woolwich, Eltham, London and Medway; the University for the Creative Arts (UCA) also has three of its five campuses in the county.		Although much of Britain adopted a comprehensive education system in the 1970s, Kent County Council (KCC) and Medway Unitary Authority are among around fifteen[65] local authorities still providing wholly selective education through the eleven-plus examination with students allocated a place at a secondary modern school or at a grammar school.		Together, the two Kent authorities have 38 of the 164 grammar schools remaining in Britain.[65][66]		Kent County Council has the largest education department of any local council in Britain,[67] providing school places for over 289,000 pupils.		In 2005–06, Kent County Council and Medway introduced a standardised school year, based on six terms, as recommended by the Local Government Association in its 2000 report, "The Rhythms of Schooling".[68]		Kent County Council Local Education Authority maintains 96 secondary schools, of which 33 are selective schools and 63 are secondary modern schools.		Kent has the highest number of National Challenge schools in England: schools which are branded 'failing' based on the British Government's floor targets that 30% of pupils achieve at least 5 GCSE grades A* to C.[70] Of the 63 secondary modern schools, 33 missed this target; thus 52% of Kent secondary modern schools (34% out of all 96 maintained secondary schools) are 'failing'.[71]		In association football, Kent's highest ranked football team is Gillingham FC, who play in Football League One.[72] Maidstone United were a Football League side from 1989 until going bankrupt in 1992. Kent clubs in the higher levels of non-league football include the current incarnation of Maidstone United and Dover Athletic playing in the National League and Dartford, Ebbsfleet United and Margate all playing in National League South, the sixth tier of the English football pyramid.		Kent is represented in cricket by Kent County Cricket Club. The club was a founder member of the County Championship in 1890 and have won the competition, the major domestic first-class cricket competition, seven times. They are based at the St Lawrence Ground in Canterbury and also play matches at the Nevill Ground in Royal Tunbridge Wells and the County Cricket Ground, Beckenham.[73] The Kent Women cricket team has won the Women's County Championship seven times since it was established in 1997. Cricket has traditionally been a popular sport in the county and Kent is considered one of the locations in which the game first developed. Teams have represented the county since the early 18th century. The Kent Cricket League is the top level of club competition within Kent and features teams from throughout the county, including areas such as Beckenham and Bexley which were formerly part of the county.		Canterbury Hockey Club and Holcombe Hockey Club both play in the top division in both the men's and women's England Hockey Leagues. Sevenoaks Hockey Club's women first XI plays in the second tier of national competition. In Rugby Union Canterbury RFC play in the fourth tier of English rugby in the National League 2 South. Gravesend RFC and Tonbridge Juddians both play in the fifth tier National League 3 London & SE. Blackheath FC, a club within the historic boundaries of the county, play in National League 1, the third tier of English rugby.		In motorsport, the Brands Hatch circuit near Swanley has played host to a number of national and international racing events, and hosted 12 runnings of the British Grand Prix in various years between 1964 and 1986.		Much of Kent is served by the BBC's South East region, which is based in Tunbridge Wells and provides local news for the county and East Sussex. Its commercial rival is ITV Meridian Ltd, which has a newsroom at The Maidstone Studios despite the main studio being based in Hampshire. Main transmitters providing these services are located at West Hougham, near Dover and Blue Bell Hill, located between Chatham and Maidstone. A powerful relay transmitter at Tunbridge Wells serves the town and surrounding area. Those parts of Kent closest to London such as Swanley, Westerham, Dartford, Gravesend and Sevenoaks lie within the ITV London and BBC London areas, taking their television signals from the Crystal Palace transmitter.		Kent has three county-wide stations – BBC Radio Kent, based in Tunbridge Wells; and the commercial stations Heart and Gold, both based in Whitstable and London.[74]		Most of the county is covered by local radio network KMFM, owned by the KM Group. Since March 2012, programmes have been the same across all seven stations in the network:[75] KMFM Ashford, KMFM Canterbury, KMFM Maidstone, KMFM Medway, KMFM Shepway and White Cliffs Country, KMFM Thanet and KMFM West Kent.		The county has eight community radio stations run by various organisations.		Dover Community Radio (DCR) offers a podcasting service for the people of Dover district on their website, hoping in the future to apply for a community radio licence to cover the town and its environs.		A newly established Digital Radio platform has been created in Deal. Deal Radio is an online radio station created for the East Kent communities in and around the town of Deal. www.dealradio.co.uk		The KM Group, KOS Media and Kent Regional News and Media all provide local newspapers for most of the large towns and cities. County-wide papers include the Kent Messenger, Kent on Saturday, Kent on Sunday, and the Kent and Sussex Courier.		
The littoral zone is the part of a sea, lake or river that is close to the shore. In coastal environments the littoral zone extends from the high water mark, which is rarely inundated, to shoreline areas that are permanently submerged. It always includes this intertidal zone and is often used to mean the same as the intertidal zone. However, the meaning of "littoral zone" can extend well beyond the intertidal zone.		There is no single definition. What is regarded as the full extent of the littoral zone, and the way the littoral zone is divided into subregions, varies in different contexts (lakes and rivers have their own definitions). The use of the term also varies from one part of the world to another, and between different disciplines. For example, military commanders speak of the littoral in ways that are quite different from marine biologists.		The adjacency of water gives a number of distinctive characteristics to littoral regions. The erosive power of water results in particular types of landforms, such as sand dunes, and estuaries. The natural movement of the littoral along the coast is called the littoral drift. Biologically, the ready availability of water enables a greater variety of plant and animal life, and particularly the formation of extensive wetlands. In addition, the additional local humidity due to evaporation usually creates a microclimate supporting unique types of organisms.		The word "littoral" is used both as a noun and an adjective. It derives from the Latin noun litus, litoris, meaning "shore". (The doubled 't' is a late medieval innovation and the word is sometimes seen in the more classical-looking spelling 'litoral'.)						In oceanography and marine biology, the idea of the littoral zone is extended roughly to the edge of the continental shelf. Starting from the shoreline, the littoral zone begins at the spray region just above the high tide mark. From here, it moves to the intertidal region between the high and low water marks, and then out as far as the edge of the continental shelf. These three subregions are called, in order, the supralittoral zone, the eulittoral zone and the sublittoral zone.		The supralittoral zone (also called the splash, spray or supratidal zone) is the area above the spring high tide line that is regularly splashed, but not submerged by ocean water. Seawater penetrates these elevated areas only during storms with high tides. Organisms here must cope also with exposure to fresh water from rain, cold, heat and predation by land animals and seabirds. At the top of this area, patches of dark lichens can appear as crusts on rocks. Some types of periwinkles, Neritidae and detritus feeding Isopoda commonly inhabit the lower supralittoral.[1]		The eulittoral zone (also called the midlittoral or mediolittoral zone) is the intertidal zone also known as the foreshore. It extends from the spring high tide line, which is rarely inundated, to the spring low tide line, which is rarely not inundated. The wave action and turbulence of recurring tides shapes and reforms cliffs, gaps, and caves, offering a huge range of habitats for sedentary organisms. Protected rocky shorelines usually show a narrow almost homogenous eulittoral strip, often marked by the presence of barnacles. Exposed sites show a wider extension and are often divided into further zones. For more on this, see intertidal ecology.		The sublittoral zone starts immediately below the eulittoral zone. This zone is permanently covered with seawater and is approximately equivalent to the neritic zone.		In physical oceanography, the sublittoral zone refers to coastal regions with significant tidal flows and energy dissipation, including non-linear flows, internal waves, river outflows and oceanic fronts. In practice, this typically extends to the edge of the continental shelf, with depths around 200 meters.		In marine biology, the sublittoral refers to the areas where sunlight reaches the ocean floor, that is, where the water is never so deep as to take it out of the photic zone. This results in high primary production and makes the sublittoral zone the location of the majority of sea life. As in physical oceanography, this zone typically extends to the edge of the continental shelf. The benthic zone in the sublittoral is much more stable than in the intertidal zone; temperature, water pressure, and the amount of sunlight remain fairly constant. Sublittoral corals do not have to deal with as much change as intertidal corals. Corals can live in both zones, but they are more common in the sublittoral zone.		Within the sublittoral, marine biologists also identify the following:		Shallower regions of the sublittoral zone, extending not far from the shore, are sometimes referred to as the subtidal zone.		In freshwater situations, littoral zones occur on the edge of large lakes and rivers, often with extensive areas of wetland. Hence, they are sometimes referred to as fringing wetlands. Here, the effects of tides are minimal, so other definitions of "littoral" are used. For example, the Minnesota Department of Natural Resources defines littoral as that portion of the lake that is less than 15 feet in depth.[2]		The littoral zone may form a narrow or broad fringing wetland, with extensive areas of aquatic plants sorted by their tolerance to different water depths. Typically, four zones are recognized, from higher to lower on the shore: wooded wetland, wet meadow, marsh and aquatic vegetation.[3] The relative areas of these four types depends not only on the profile of the shoreline, but upon past water levels. The area of wet meadow is particularly dependent upon past water levels;[4] in general, the area of wet meadows along lakes and rivers increases with natural water level fluctuations.[5][6] Many of the animals in lakes and rivers are dependent upon the wetlands of littoral zones, since the rooted plants provide habitat and food. Hence, a large and productive littoral zone is considered an important characteristic of a healthy lake or river.[4]		Littoral zones are at particular risk for two reasons. First, human settlement is often attracted to shorelines, and settlement often disrupts breeding habitats for littoral zone species. For example, many turtles are killed on roads when they leave the water to lay their eggs in upland sites. Fish can be negatively affected by docks and retaining walls which remove breeding habitat in shallow water. Some shoreline communities even deliberately try to remove wetlands since they may interfere with activities like swimming. Overall, the presence of human settlement has a demonstrated negative impact upon adjoining wetlands.[7] An equally serious problem is the tendency to stabilize lake or river levels with dams. Dams removed the spring flood which carries nutrients into littoral zones, and reduces the natural fluctuation of water levels upon which many wetland plants and animals depend.[8][9] Hence, over time, dams can reduce the area of wetland from a broad littoral zone to a narrow band of vegetation. Marshes and wet meadows are at particular risk.		For the purposes of naval operations, the United States Navy divides the littoral zone in the ways shown on the diagram at the top of this article. The United States Army Corps of Engineers and Environmental Protection Agency have their own definitions, and these have legal implications.		
Tides are the rise and fall of sea levels caused by the combined effects of the gravitational forces exerted by the Moon and the Sun and the rotation of Earth.		The times and amplitude of tides at any given locale are influenced by the alignment of the Sun and Moon, by the pattern of tides in the deep ocean, by the amphidromic systems of the oceans, and the shape of the coastline and near-shore bathymetry (see Timing). Some shorelines experience a semi-diurnal tide—two nearly equal high and low tides each day. Other locations experience a diurnal tide—only one high and low tide each day. A "mixed tide"—two uneven tides a day, or one high and one low—is also possible.[1][2][3]		Tides vary on timescales ranging from hours to years due to a number of factors. To make accurate records, tide gauges at fixed stations measure water level over time. Gauges ignore variations caused by waves with periods shorter than minutes. These data are compared to the reference (or datum) level usually called mean sea level.[4]		While tides are usually the largest source of short-term sea-level fluctuations, sea levels are also subject to forces such as wind and barometric pressure changes, resulting in storm surges, especially in shallow seas and near coasts.		Tidal phenomena are not limited to the oceans, but can occur in other systems whenever a gravitational field that varies in time and space is present. For example, the solid part of the Earth is affected by tides, though this is not as easily seen as the water tidal movements.								Tide changes proceed via the following stages:		Oscillating currents produced by tides are known as tidal streams. The moment that the tidal current ceases is called slack water or slack tide. The tide then reverses direction and is said to be turning. Slack water usually occurs near high water and low water. But there are locations where the moments of slack tide differ significantly from those of high and low water.[5]		Tides are commonly semi-diurnal (two high waters and two low waters each day), or diurnal (one tidal cycle per day). The two high waters on a given day are typically not the same height (the daily inequality); these are the higher high water and the lower high water in tide tables. Similarly, the two low waters each day are the higher low water and the lower low water. The daily inequality is not consistent and is generally small when the Moon is over the equator.[6]		From the highest level to the lowest:		Tidal constituents are the net result of multiple influences impacting tidal changes over certain periods of time. Primary constituents include the Earth's rotation, the position of the Moon and Sun relative to the Earth, the Moon's altitude (elevation) above the Earth's equator, and bathymetry. Variations with periods of less than half a day are called harmonic constituents. Conversely, cycles of days, months, or years are referred to as long period constituents.		Tidal forces affect the entire earth, but the movement of solid Earth occurs by mere centimeters. In contrast, the atmosphere is much more fluid and compressible so its surface moves by kilometers, in the sense of the contour level of a particular low pressure in the outer atmosphere.		In most locations, the largest constituent is the "principal lunar semi-diurnal", also known as the M2 (or M2) tidal constituent. Its period is about 12 hours and 25.2 minutes, exactly half a tidal lunar day, which is the average time separating one lunar zenith from the next, and thus is the time required for the Earth to rotate once relative to the Moon. Simple tide clocks track this constituent. The lunar day is longer than the Earth day because the Moon orbits in the same direction the Earth spins. This is analogous to the minute hand on a watch crossing the hour hand at 12:00 and then again at about 1:05½ (not at 1:00).		The Moon orbits the Earth in the same direction as the Earth rotates on its axis, so it takes slightly more than a day—about 24 hours and 50 minutes—for the Moon to return to the same location in the sky. During this time, it has passed overhead (culmination) once and underfoot once (at an hour angle of 00:00 and 12:00 respectively), so in many places the period of strongest tidal forcing is the above-mentioned, about 12 hours and 25 minutes. The moment of highest tide is not necessarily when the Moon is nearest to zenith or nadir, but the period of the forcing still determines the time between high tides.		Because the gravitational field created by the Moon weakens with distance from the Moon, it exerts a slightly stronger than average force on the side of the Earth facing the Moon, and a slightly weaker force on the opposite side. The Moon thus tends to "stretch" the Earth slightly along the line connecting the two bodies. The solid Earth deforms a bit, but ocean water, being fluid, is free to move much more in response to the tidal force, particularly horizontally. As the Earth rotates, the magnitude and direction of the tidal force at any particular point on the Earth's surface change constantly; although the ocean never reaches equilibrium—there is never time for the fluid to "catch up" to the state it would eventually reach if the tidal force were constant—the changing tidal force nonetheless causes rhythmic changes in sea surface height.		When there are two high tides each day with different heights (and two low tides also of different heights), the pattern is called a mixed semi-diurnal tide.[8]		The semi-diurnal range (the difference in height between high and low waters over about half a day) varies in a two-week cycle. Approximately twice a month, around new moon and full moon when the Sun, Moon, and Earth form a line (a configuration known as a syzygy[9]), the tidal force due to the sun reinforces that due to the Moon. The tide's range is then at its maximum; this is called the spring tide. It is not named after the season, but, like that word, derives from the meaning "jump, burst forth, rise", as in a natural spring.		When the Moon is at first quarter or third quarter, the Sun and Moon are separated by 90° when viewed from the Earth, and the solar tidal force partially cancels the Moon's. At these points in the lunar cycle, the tide's range is at its minimum; this is called the neap tide, or neaps. Neap is an Anglo-Saxon word meaning "without the power", as in forđganges nip (forth-going without-the-power).[10]		Spring tides result in high waters that are higher than average, low waters that are lower than average, 'slack water' time that is shorter than average, and stronger tidal currents than average. Neaps result in less-extreme tidal conditions. There is about a seven-day interval between springs and neaps.		Spring tide: Sun and Moon on the same side (0°)		Neap tide: Sun and Moon at 90°		Spring tide: Sun and Moon at opposite sides (180°)		Neap tide: Sun and Moon at 270°		Spring tide: Sun and Moon at the same side (cycle restarts)		The changing distance separating the Moon and Earth also affects tide heights. When the Moon is closest, at perigee, the range increases, and when it is at apogee, the range shrinks. Every  7 1⁄2 lunations (the full cycles from full moon to new to full), perigee coincides with either a new or full moon causing perigean spring tides with the largest tidal range. Even at its most powerful this force is still weak,[11] causing tidal differences of inches at most.[12]		These include solar gravitational effects, the obliquity (tilt) of the Earth's equator and rotational axis, the inclination of the plane of the lunar orbit and the elliptical shape of the Earth's orbit of the sun.		A compound tide (or overtide) results from the shallow-water interaction of its two parent waves.[13]		Because the M2 tidal constituent dominates in most locations, the stage or phase of a tide, denoted by the time in hours after high water, is a useful concept. Tidal stage is also measured in degrees, with 360° per tidal cycle. Lines of constant tidal phase are called cotidal lines, which are analogous to contour lines of constant altitude on topographical maps. High water is reached simultaneously along the cotidal lines extending from the coast out into the ocean, and cotidal lines (and hence tidal phases) advance along the coast. Semi-diurnal and long phase constituents are measured from high water, diurnal from maximum flood tide. This and the discussion that follows is precisely true only for a single tidal constituent.		For an ocean in the shape of a circular basin enclosed by a coastline, the cotidal lines point radially inward and must eventually meet at a common point, the amphidromic point. The amphidromic point is at once cotidal with high and low waters, which is satisfied by zero tidal motion. (The rare exception occurs when the tide encircles an island, as it does around New Zealand, Iceland and Madagascar.) Tidal motion generally lessens moving away from continental coasts, so that crossing the cotidal lines are contours of constant amplitude (half the distance between high and low water) which decrease to zero at the amphidromic point. For a semi-diurnal tide the amphidromic point can be thought of roughly like the center of a clock face, with the hour hand pointing in the direction of the high water cotidal line, which is directly opposite the low water cotidal line. High water rotates about the amphidromic point once every 12 hours in the direction of rising cotidal lines, and away from ebbing cotidal lines. This rotation is generally clockwise in the southern hemisphere and counterclockwise in the northern hemisphere, and is caused by the Coriolis effect. The difference of cotidal phase from the phase of a reference tide is the epoch. The reference tide is the hypothetical constituent "equilibrium tide" on a landless Earth measured at 0° longitude, the Greenwich meridian.[16]		In the North Atlantic, because the cotidal lines circulate counterclockwise around the amphidromic point, the high tide passes New York Harbor approximately an hour ahead of Norfolk Harbor. South of Cape Hatteras the tidal forces are more complex, and cannot be predicted reliably based on the North Atlantic cotidal lines.		Investigation into tidal physics was important in the early development of heliocentrism[citation needed] and celestial mechanics, with the existence of two daily tides being explained by the Moon's gravity. Later the daily tides were explained more precisely by the interaction of the Moon's and the sun's gravity.		Seleucus of Seleucia theorized around 150 B.C. that tides were caused by the Moon.		Medieval understanding of the tides was primarily based on works of Muslim astronomers, which became available through Latin translation starting from the 12th century.[17] Abu Ma'shar (d. circa 886), in his Introductorium in astronomiam, taught that ebb and flood tides were caused by the moon (although earlier in Europe, Bede (d. 736) also reckoned that the moon is involved).[17] Abu Ma'shar discussed the effects of wind and moon's phases relative to the sun on the tides.[17] In the 12th century, al-Bitruji (d. circa 1204) contributed the notion that the tides were caused by the general circulation of the heavens.[17]		Simon Stevin in his 1608 De spiegheling der Ebbenvloet, The theory of ebb and flood, dismissed a large number of misconceptions that still existed about ebb and flood. Stevin pleaded for the idea that the attraction of the Moon was responsible for the tides and spoke in clear terms about ebb, flood, spring tide and neap tide, stressing that further research needed to be made.[18][19]		In 1609 Johannes Kepler also correctly suggested that the gravitation of the Moon caused the tides,[20] which he based upon ancient observations and correlations. It was originally mentioned in Ptolemy's Tetrabiblos[21] as having derived from ancient observation.		Galileo Galilei in his 1632 Dialogue Concerning the Two Chief World Systems, whose working title was Dialogue on the Tides, gave an explanation of the tides. The resulting theory, however, was incorrect as he attributed the tides to the sloshing of water caused by the Earth's movement around the sun. He hoped to provide mechanical proof of the Earth's movement. The value of his tidal theory is disputed. Galileo rejected Kepler's explanation of the tides.		Isaac Newton (1642–1727) was the first person to explain tides as the product of the gravitational attraction of astronomical masses. His explanation of the tides (and many other phenomena) was published in the Principia (1687)[22][23] and used his theory of universal gravitation to explain the lunar and solar attractions as the origin of the tide-generating forces.[24] Newton and others before Pierre-Simon Laplace worked the problem from the perspective of a static system (equilibrium theory), that provided an approximation that described the tides that would occur in a non-inertial ocean evenly covering the whole Earth.[22] The tide-generating force (or its corresponding potential) is still relevant to tidal theory, but as an intermediate quantity (forcing function) rather than as a final result; theory must also consider the Earth's accumulated dynamic tidal response to the applied forces, which response is influenced by ocean depth, the Earth's rotation, and other factors.[25]		In 1740, the Académie Royale des Sciences in Paris offered a prize for the best theoretical essay on tides. Daniel Bernoulli, Leonhard Euler, Colin Maclaurin and Antoine Cavalleri shared the prize.[26]		Maclaurin used Newton's theory to show that a smooth sphere covered by a sufficiently deep ocean under the tidal force of a single deforming body is a prolate spheroid (essentially a three-dimensional oval) with major axis directed toward the deforming body. Maclaurin was the first to write about the Earth's rotational effects on motion. Euler realized that the tidal force's horizontal component (more than the vertical) drives the tide. In 1744 Jean le Rond d'Alembert studied tidal equations for the atmosphere which did not include rotation.		In 1770 James Cook's barque HMS Endeavour grounded on the Great Barrier Reef. Attempts were made to refloat her on the following tide which failed, but the tide after that lifted her clear with ease. Whilst she was being repaired in the mouth of the Endeavour River Cook observed the tides over a period of seven weeks. At neap tides both tides in a day were similar, but at springs the tides rose 7 feet (2.1 m) in the morning but 9 feet (2.7 m) in the evening.[27]		Pierre-Simon Laplace formulated a system of partial differential equations relating the ocean's horizontal flow to its surface height, the first major dynamic theory for water tides. The Laplace tidal equations are still in use today. William Thomson, 1st Baron Kelvin, rewrote Laplace's equations in terms of vorticity which allowed for solutions describing tidally driven coastally trapped waves, known as Kelvin waves.[28][29][30]		Others including Kelvin and Henri Poincaré further developed Laplace's theory. Based on these developments and the lunar theory of E W Brown describing the motions of the Moon, Arthur Thomas Doodson developed and published in 1921[31] the first modern development of the tide-generating potential in harmonic form: Doodson distinguished 388 tidal frequencies.[32] Some of his methods remain in use.[33]		The tidal force produced by a massive object (Moon, hereafter) on a small particle located on or in an extensive body (Earth, hereafter) is the vector difference between the gravitational force exerted by the Moon on the particle, and the gravitational force that would be exerted on the particle if it were located at the Earth's center of mass. The solar gravitational force on the Earth is on average 179 times stronger than the lunar, but because the Sun is on average 389 times farther from the Earth, its field gradient is weaker. The solar tidal force is 46% as large as the lunar.[34] More precisely, the lunar tidal acceleration (along the Moon–Earth axis, at the Earth's surface) is about 1.1 × 10−7 g, while the solar tidal acceleration (along the Sun–Earth axis, at the Earth's surface) is about 0.52 × 10−7 g, where g is the gravitational acceleration at the Earth's surface.[35] Venus has the largest effect of the other planets, at 0.000113 times the solar effect.		The ocean's surface is closely approximated by an equipotential surface, (ignoring ocean currents) commonly referred to as the geoid. Since the gravitational force is equal to the potential's gradient, there are no tangential forces on such a surface, and the ocean surface is thus in gravitational equilibrium. Now consider the effect of massive external bodies such as the Moon and Sun. These bodies have strong gravitational fields that diminish with distance and act to alter the shape of an equipotential surface on the Earth. This deformation has a fixed spatial orientation relative to the influencing body. The Earth's rotation relative to this shape causes the daily tidal cycle. Gravitational forces follow an inverse-square law (force is inversely proportional to the square of the distance), but tidal forces are inversely proportional to the cube of the distance. The ocean surface moves because of the changing tidal equipotential, rising when the tidal potential is high, which occurs on the parts of the Earth nearest to and furthest from the Moon. When the tidal equipotential changes, the ocean surface is no longer aligned with it, so the apparent direction of the vertical shifts. The surface then experiences a down slope, in the direction that the equipotential has risen.		Ocean depths are much smaller than their horizontal extent. Thus, the response to tidal forcing can be modelled using the Laplace tidal equations which incorporate the following features:		The boundary conditions dictate no flow across the coastline and free slip at the bottom.		The Coriolis effect (inertial force) steers flows moving towards the equator to the west and flows moving away from the equator toward the east, allowing coastally trapped waves. Finally, a dissipation term can be added which is an analog to viscosity.		The theoretical amplitude of oceanic tides caused by the moon is about 54 centimetres (21 in) at the highest point, which corresponds to the amplitude that would be reached if the ocean possessed a uniform depth, there were no landmasses, and the Earth were rotating in step with the moon's orbit. The sun similarly causes tides, of which the theoretical amplitude is about 25 centimetres (9.8 in) (46% of that of the moon) with a cycle time of 12 hours. At spring tide the two effects add to each other to a theoretical level of 79 centimetres (31 in), while at neap tide the theoretical level is reduced to 29 centimetres (11 in). Since the orbits of the Earth about the sun, and the moon about the Earth, are elliptical, tidal amplitudes change somewhat as a result of the varying Earth–sun and Earth–moon distances. This causes a variation in the tidal force and theoretical amplitude of about ±18% for the moon and ±5% for the sun. If both the sun and moon were at their closest positions and aligned at new moon, the theoretical amplitude would reach 93 centimetres (37 in).		Real amplitudes differ considerably, not only because of depth variations and continental obstacles, but also because wave propagation across the ocean has a natural period of the same order of magnitude as the rotation period: if there were no land masses, it would take about 30 hours for a long wavelength surface wave to propagate along the equator halfway around the Earth (by comparison, the Earth's lithosphere has a natural period of about 57 minutes). Earth tides, which raise and lower the bottom of the ocean, and the tide's own gravitational self attraction are both significant and further complicate the ocean's response to tidal forces.		Earth's tidal oscillations introduce dissipation at an average rate of about 3.75 terawatts.[36] About 98% of this dissipation is by marine tidal movement.[37] Dissipation arises as basin-scale tidal flows drive smaller-scale flows which experience turbulent dissipation. This tidal drag creates torque on the moon that gradually transfers angular momentum to its orbit, and a gradual increase in Earth–moon separation. The equal and opposite torque on the Earth correspondingly decreases its rotational velocity. Thus, over geologic time, the moon recedes from the Earth, at about 3.8 centimetres (1.5 in)/year, lengthening the terrestrial day.[38] Day length has increased by about 2 hours in the last 600 million years. Assuming (as a crude approximation) that the deceleration rate has been constant, this would imply that 70 million years ago, day length was on the order of 1% shorter with about 4 more days per year.		The shape of the shoreline and the ocean floor changes the way that tides propagate, so there is no simple, general rule that predicts the time of high water from the Moon's position in the sky. Coastal characteristics such as underwater bathymetry and coastline shape mean that individual location characteristics affect tide forecasting; actual high water time and height may differ from model predictions due to the coastal morphology's effects on tidal flow. However, for a given location the relationship between lunar altitude and the time of high or low tide (the lunitidal interval) is relatively constant and predictable, as is the time of high or low tide relative to other points on the same coast. For example, the high tide at Norfolk, Virginia, U.S., predictably occurs approximately two and a half hours before the Moon passes directly overhead.		Land masses and ocean basins act as barriers against water moving freely around the globe, and their varied shapes and sizes affect the size of tidal frequencies. As a result, tidal patterns vary. For example, in the U.S., the East coast has predominantly semi-diurnal tides, as do Europe's Atlantic coasts, while the West coast predominantly has mixed tides.[39][40][41]		From ancient times, tidal observation and discussion has increased in sophistication, first marking the daily recurrence, then tides' relationship to the sun and moon. Pytheas travelled to the British Isles about 325 BC and seems to be the first to have related spring tides to the phase of the moon.		In the 2nd century BC, the Babylonian astronomer, Seleucus of Seleucia, correctly described the phenomenon of tides in order to support his heliocentric theory.[42] He correctly theorized that tides were caused by the moon, although he believed that the interaction was mediated by the pneuma. He noted that tides varied in time and strength in different parts of the world. According to Strabo (1.1.9), Seleucus was the first to link tides to the lunar attraction, and that the height of the tides depends on the moon's position relative to the sun.[43]		The Naturalis Historia of Pliny the Elder collates many tidal observations, e.g., the spring tides are a few days after (or before) new and full moon and are highest around the equinoxes, though Pliny noted many relationships now regarded as fanciful. In his Geography, Strabo described tides in the Persian Gulf having their greatest range when the moon was furthest from the plane of the equator. All this despite the relatively small amplitude of Mediterranean basin tides. (The strong currents through the Euripus Strait and the Strait of Messina puzzled Aristotle.) Philostratus discussed tides in Book Five of The Life of Apollonius of Tyana. Philostratus mentions the moon, but attributes tides to "spirits". In Europe around 730 AD, the Venerable Bede described how the rising tide on one coast of the British Isles coincided with the fall on the other and described the time progression of high water along the Northumbrian coast.		The first tide table in China was recorded in 1056 AD primarily for visitors wishing to see the famous tidal bore in the Qiantang River. The first known British tide table is thought to be that of John Wallingford, who died Abbot of St. Albans in 1213, based on high water occurring 48 minutes later each day, and three hours earlier at the Thames mouth than upriver at London.[44]		William Thomson (Lord Kelvin) led the first systematic harmonic analysis of tidal records starting in 1867. The main result was the building of a tide-predicting machine using a system of pulleys to add together six harmonic time functions. It was "programmed" by resetting gears and chains to adjust phasing and amplitudes. Similar machines were used until the 1960s.[45]		The first known sea-level record of an entire spring–neap cycle was made in 1831 on the Navy Dock in the Thames Estuary. Many large ports had automatic tide gauge stations by 1850.		William Whewell first mapped co-tidal lines ending with a nearly global chart in 1836. In order to make these maps consistent, he hypothesized the existence of amphidromes where co-tidal lines meet in the mid-ocean. These points of no tide were confirmed by measurement in 1840 by Captain Hewett, RN, from careful soundings in the North Sea.[28]		The tidal forces due to the Moon and Sun generate very long waves which travel all around the ocean following the paths shown in co-tidal charts. The time when the crest of the wave reaches a port then gives the time of high water at the port. The time taken for the wave to travel around the ocean also means that there is a delay between the phases of the moon and their effect on the tide. Springs and neaps in the North Sea, for example, are two days behind the new/full moon and first/third quarter moon. This is called the tide's age.[46][47]		The ocean bathymetry greatly influences the tide's exact time and height at a particular coastal point. There are some extreme cases; the Bay of Fundy, on the east coast of Canada, is often stated to have the world's highest tides because of its shape, bathymetry, and its distance from the continental shelf edge.[48] Measurements made in November 1998 at Burntcoat Head in the Bay of Fundy recorded a maximum range of 16.3 metres (53 ft) and a highest predicted extreme of 17 metres (56 ft). [49] [50] Similar measurements made in March 2002 at Leaf Basin, Ungava Bay in northern Quebec gave similar values (allowing for measurement errors), a maximum range of 16.2 metres (53 ft) and a highest predicted extreme of 16.8 metres (55 ft).[49][50] Ungava Bay and the Bay of Fundy lie similar distances from the continental shelf edge, but Ungava Bay is free of pack ice for only about four months every year while the Bay of Fundy rarely freezes.		Southampton in the United Kingdom has a double high water caused by the interaction between the M2 and M4 tidal constituents.[51] Portland has double low waters for the same reason. The M4 tide is found all along the south coast of the United Kingdom, but its effect is most noticeable between the Isle of Wight and Portland because the M2 tide is lowest in this region.		Because the oscillation modes of the Mediterranean Sea and the Baltic Sea do not coincide with any significant astronomical forcing period, the largest tides are close to their narrow connections with the Atlantic Ocean. Extremely small tides also occur for the same reason in the Gulf of Mexico and Sea of Japan. Elsewhere, as along the southern coast of Australia, low tides can be due to the presence of a nearby amphidrome.		Isaac Newton's theory of gravitation first enabled an explanation of why there were generally two tides a day, not one, and offered hope for a detailed understanding of tidal forces and behavior. Although it may seem that tides could be predicted via a sufficiently detailed knowledge of instantaneous astronomical forcings, the actual tide at a given location is determined by astronomical forces accumulated over many days. In addition, precise results require detailed knowledge of the shape of all the ocean basins—their bathymetry, and coastline shape.		Current procedure for analysing tides follows the method of harmonic analysis introduced in the 1860s by William Thomson. It is based on the principle that the astronomical theories of the motions of sun and moon determine a large number of component frequencies, and at each frequency there is a component of force tending to produce tidal motion, but that at each place of interest on the Earth, the tides respond at each frequency with an amplitude and phase peculiar to that locality. At each place of interest, the tide heights are therefore measured for a period of time sufficiently long (usually more than a year in the case of a new port not previously studied) to enable the response at each significant tide-generating frequency to be distinguished by analysis, and to extract the tidal constants for a sufficient number of the strongest known components of the astronomical tidal forces to enable practical tide prediction. The tide heights are expected to follow the tidal force, with a constant amplitude and phase delay for each component. Because astronomical frequencies and phases can be calculated with certainty, the tide height at other times can then be predicted once the response to the harmonic components of the astronomical tide-generating forces has been found.		The main patterns in the tides are		The Highest Astronomical Tide is the perigean spring tide when both the sun and moon are closest to the Earth.		When confronted by a periodically varying function, the standard approach is to employ Fourier series, a form of analysis that uses sinusoidal functions as a basis set, having frequencies that are zero, one, two, three, etc. times the frequency of a particular fundamental cycle. These multiples are called harmonics of the fundamental frequency, and the process is termed harmonic analysis. If the basis set of sinusoidal functions suit the behaviour being modelled, relatively few harmonic terms need to be added. Orbital paths are very nearly circular, so sinusoidal variations are suitable for tides.		For the analysis of tide heights, the Fourier series approach has in practice to be made more elaborate than the use of a single frequency and its harmonics. The tidal patterns are decomposed into many sinusoids having many fundamental frequencies, corresponding (as in the lunar theory) to many different combinations of the motions of the Earth, the moon, and the angles that define the shape and location of their orbits.		For tides, then, harmonic analysis is not limited to harmonics of a single frequency.[52] In other words, the harmonies are multiples of many fundamental frequencies, not just of the fundamental frequency of the simpler Fourier series approach. Their representation as a Fourier series having only one fundamental frequency and its (integer) multiples would require many terms, and would be severely limited in the time-range for which it would be valid.		The study of tide height by harmonic analysis was begun by Laplace, William Thomson (Lord Kelvin), and George Darwin. A.T. Doodson extended their work, introducing the Doodson Number notation to organise the hundreds of resulting terms. This approach has been the international standard ever since, and the complications arise as follows: the tide-raising force is notionally given by sums of several terms. Each term is of the form		where A is the amplitude, ω is the angular frequency usually given in degrees per hour corresponding to t measured in hours, and p is the phase offset with regard to the astronomical state at time t = 0 . There is one term for the moon and a second term for the sun. The phase p of the first harmonic for the moon term is called the lunitidal interval or high water interval. The next step is to accommodate the harmonic terms due to the elliptical shape of the orbits. Accordingly, the value of A is not a constant but also varying with time, slightly, about some average figure. Replace it then by A(t) where A is another sinusoid, similar to the cycles and epicycles of Ptolemaic theory. Accordingly,		which is to say an average value A with a sinusoidal variation about it of magnitude Aa, with frequency ωa and phase pa. Thus the simple term is now the product of two cosine factors:		Given that for any x and y		it is clear that a compound term involving the product of two cosine terms each with their own frequency is the same as three simple cosine terms that are to be added at the original frequency and also at frequencies which are the sum and difference of the two frequencies of the product term. (Three, not two terms, since the whole expression is ( 1 + cos ⁡ x ) cos ⁡ y {\displaystyle (1+\cos x)\cos y} .) Consider further that the tidal force on a location depends also on whether the moon (or the sun) is above or below the plane of the equator, and that these attributes have their own periods also incommensurable with a day and a month, and it is clear that many combinations result. With a careful choice of the basic astronomical frequencies, the Doodson Number annotates the particular additions and differences to form the frequency of each simple cosine term.		Remember that astronomical tides do not include weather effects. Also, changes to local conditions (sandbank movement, dredging harbour mouths, etc.) away from those prevailing at the measurement time affect the tide's actual timing and magnitude. Organisations quoting a "highest astronomical tide" for some location may exaggerate the figure as a safety factor against analytical uncertainties, distance from the nearest measurement point, changes since the last observation time, ground subsidence, etc., to avert liability should an engineering work be overtopped. Special care is needed when assessing the size of a "weather surge" by subtracting the astronomical tide from the observed tide.		Careful Fourier data analysis over a nineteen-year period (the National Tidal Datum Epoch in the U.S.) uses frequencies called the tidal harmonic constituents. Nineteen years is preferred because the Earth, moon and sun's relative positions repeat almost exactly in the Metonic cycle of 19 years, which is long enough to include the 18.613 year lunar nodal tidal constituent. This analysis can be done using only the knowledge of the forcing period, but without detailed understanding of the mathematical derivation, which means that useful tidal tables have been constructed for centuries.[53] The resulting amplitudes and phases can then be used to predict the expected tides. These are usually dominated by the constituents near 12 hours (the semi-diurnal constituents), but there are major constituents near 24 hours (diurnal) as well. Longer term constituents are 14 day or fortnightly, monthly, and semiannual. Semi-diurnal tides dominated coastline, but some areas such as the South China Sea and the Gulf of Mexico are primarily diurnal. In the semi-diurnal areas, the primary constituents M2 (lunar) and S2 (solar) periods differ slightly, so that the relative phases, and thus the amplitude of the combined tide, change fortnightly (14 day period).[54]		In the M2 plot above, each cotidal line differs by one hour from its neighbors, and the thicker lines show tides in phase with equilibrium at Greenwich. The lines rotate around the amphidromic points counterclockwise in the northern hemisphere so that from Baja California Peninsula to Alaska and from France to Ireland the M2 tide propagates northward. In the southern hemisphere this direction is clockwise. On the other hand, M2 tide propagates counterclockwise around New Zealand, but this is because the islands act as a dam and permit the tides to have different heights on the islands' opposite sides. (The tides do propagate northward on the east side and southward on the west coast, as predicted by theory.)		The exception is at Cook Strait where the tidal currents periodically link high to low water. This is because cotidal lines 180° around the amphidromes are in opposite phase, for example high water across from low water at each end of Cook Strait. Each tidal constituent has a different pattern of amplitudes, phases, and amphidromic points, so the M2 patterns cannot be used for other tide components.		Because the moon is moving in its orbit around the earth and in the same sense as the Earth's rotation, a point on the earth must rotate slightly further to catch up so that the time between semidiurnal tides is not twelve but 12.4206 hours—a bit over twenty-five minutes extra. The two peaks are not equal. The two high tides a day alternate in maximum heights: lower high (just under three feet), higher high (just over three feet), and again lower high. Likewise for the low tides.		When the Earth, moon, and sun are in line (sun–Earth–moon, or sun–moon–Earth) the two main influences combine to produce spring tides; when the two forces are opposing each other as when the angle moon–Earth–sun is close to ninety degrees, neap tides result. As the moon moves around its orbit it changes from north of the equator to south of the equator. The alternation in high tide heights becomes smaller, until they are the same (at the lunar equinox, the moon is above the equator), then redevelop but with the other polarity, waxing to a maximum difference and then waning again.		The tides' influence on current flow is much more difficult to analyse, and data is much more difficult to collect. A tidal height is a simple number which applies to a wide region simultaneously. A flow has both a magnitude and a direction, both of which can vary substantially with depth and over short distances due to local bathymetry. Also, although a water channel's center is the most useful measuring site, mariners object when current-measuring equipment obstructs waterways. A flow proceeding up a curved channel is the same flow, even though its direction varies continuously along the channel. Surprisingly, flood and ebb flows are often not in opposite directions. Flow direction is determined by the upstream channel's shape, not the downstream channel's shape. Likewise, eddies may form in only one flow direction.		Nevertheless, current analysis is similar to tidal analysis: in the simple case, at a given location the flood flow is in mostly one direction, and the ebb flow in another direction. Flood velocities are given positive sign, and ebb velocities negative sign. Analysis proceeds as though these are tide heights.		In more complex situations, the main ebb and flood flows do not dominate. Instead, the flow direction and magnitude trace an ellipse over a tidal cycle (on a polar plot) instead of along the ebb and flood lines. In this case, analysis might proceed along pairs of directions, with the primary and secondary directions at right angles. An alternative is to treat the tidal flows as complex numbers, as each value has both a magnitude and a direction.		Tide flow information is most commonly seen on nautical charts, presented as a table of flow speeds and bearings at hourly intervals, with separate tables for spring and neap tides. The timing is relative to high water at some harbour where the tidal behaviour is similar in pattern, though it may be far away.		As with tide height predictions, tide flow predictions based only on astronomical factors do not incorporate weather conditions, which can completely change the outcome.		The tidal flow through Cook Strait between the two main islands of New Zealand is particularly interesting, as the tides on each side of the strait are almost exactly out of phase, so that one side's high water is simultaneous with the other's low water. Strong currents result, with almost zero tidal height change in the strait's center. Yet, although the tidal surge normally flows in one direction for six hours and in the reverse direction for six hours, a particular surge might last eight or ten hours with the reverse surge enfeebled. In especially boisterous weather conditions, the reverse surge might be entirely overcome so that the flow continues in the same direction through three or more surge periods.		A further complication for Cook Strait's flow pattern is that the tide at the north side (e.g. at Nelson) follows the common bi-weekly spring–neap tide cycle (as found along the west side of the country), but the south side's tidal pattern has only one cycle per month, as on the east side: Wellington, and Napier.		The graph of Cook Strait's tides shows separately the high water and low water height and time, through November 2007; these are not measured values but instead are calculated from tidal parameters derived from years-old measurements. Cook Strait's nautical chart offers tidal current information. For instance the January 1979 edition for 41°13·9’S 174°29·6’E (north west of Cape Terawhiti) refers timings to Westport while the January 2004 issue refers to Wellington. Near Cape Terawhiti in the middle of Cook Strait the tidal height variation is almost nil while the tidal current reaches its maximum, especially near the notorious Karori Rip. Aside from weather effects, the actual currents through Cook Strait are influenced by the tidal height differences between the two ends of the strait and as can be seen, only one of the two spring tides at the north end (Nelson) has a counterpart spring tide at the south end (Wellington), so the resulting behaviour follows neither reference harbour.[citation needed]		Tidal energy can be extracted by two means: inserting a water turbine into a tidal current, or building ponds that release/admit water through a turbine. In the first case, the energy amount is entirely determined by the timing and tidal current magnitude. However, the best currents may be unavailable because the turbines would obstruct ships. In the second, the impoundment dams are expensive to construct, natural water cycles are completely disrupted, ship navigation is disrupted. However, with multiple ponds, power can be generated at chosen times. So far, there are few installed systems for tidal power generation (most famously, La Rance at Saint Malo, France) which face many difficulties. Aside from environmental issues, simply withstanding corrosion and biological fouling pose engineering challenges.		Tidal power proponents point out that, unlike wind power systems, generation levels can be reliably predicted, save for weather effects. While some generation is possible for most of the tidal cycle, in practice turbines lose efficiency at lower operating rates. Since the power available from a flow is proportional to the cube of the flow speed, the times during which high power generation is possible are brief.		Tidal flows are important for navigation, and significant errors in position occur if they are not accommodated. Tidal heights are also important; for example many rivers and harbours have a shallow "bar" at the entrance which prevents boats with significant draft from entering at low tide.		Until the advent of automated navigation, competence in calculating tidal effects was important to naval officers. The certificate of examination for lieutenants in the Royal Navy once declared that the prospective officer was able to "shift his tides".[55]		Tidal flow timings and velocities appear in tide charts or a tidal stream atlas. Tide charts come in sets. Each chart covers a single hour between one high water and another (they ignore the leftover 24 minutes) and show the average tidal flow for that hour. An arrow on the tidal chart indicates the direction and the average flow speed (usually in knots) for spring and neap tides. If a tide chart is not available, most nautical charts have "tidal diamonds" which relate specific points on the chart to a table giving tidal flow direction and speed.		The standard procedure to counteract tidal effects on navigation is to (1) calculate a "dead reckoning" position (or DR) from travel distance and direction, (2) mark the chart (with a vertical cross like a plus sign) and (3) draw a line from the DR in the tide's direction. The distance the tide moves the boat along this line is computed by the tidal speed, and this gives an "estimated position" or EP (traditionally marked with a dot in a triangle).		Nautical charts display the water's "charted depth" at specific locations with "soundings" and the use of bathymetric contour lines to depict the submerged surface's shape. These depths are relative to a "chart datum", which is typically the water level at the lowest possible astronomical tide (although other datums are commonly used, especially historically, and tides may be lower or higher for meteorological reasons) and are therefore the minimum possible water depth during the tidal cycle. "Drying heights" may also be shown on the chart, which are the heights of the exposed seabed at the lowest astronomical tide.		Tide tables list each day's high and low water heights and times. To calculate the actual water depth, add the charted depth to the published tide height. Depth for other times can be derived from tidal curves published for major ports. The rule of twelfths can suffice if an accurate curve is not available. This approximation presumes that the increase in depth in the six hours between low and high water is: first hour — 1/12, second — 2/12, third — 3/12, fourth — 3/12, fifth — 2/12, sixth — 1/12.		Intertidal ecology is the study of ecosystems between the low- and high-water lines along a shore. At low water, the intertidal zone is exposed (or emersed), whereas at high water, it is underwater (or immersed). Intertidal ecologists therefore study the interactions between intertidal organisms and their environment, as well as among the different species. The most important interactions may vary according to the type of intertidal community. The broadest classifications are based on substrates — rocky shore or soft bottom.		Intertidal organisms experience a highly variable and often hostile environment, and have adapted to cope with and even exploit these conditions. One easily visible feature is vertical zonation, in which the community divides into distinct horizontal bands of specific species at each elevation above low water. A species' ability to cope with desiccation determines its upper limit, while competition with other species sets its lower limit.		Humans use intertidal regions for food and recreation. Overexploitation can damage intertidals directly. Other anthropogenic actions such as introducing invasive species and climate change have large negative effects. Marine Protected Areas are one option communities can apply to protect these areas and aid scientific research.		The approximately fortnightly tidal cycle has large effects on intertidal[56] and marine organisms.[57] Hence their biological rhythms tend to occur in rough multiples of this period. Many other animals such as the vertebrates, display similar rhythms. Examples include gestation and egg hatching. In humans, the menstrual cycle lasts roughly a lunar month, an even multiple of the tidal period. Such parallels at least hint at the common descent of all animals from a marine ancestor.[58]		When oscillating tidal currents in the stratified ocean flow over uneven bottom topography, they generate internal waves with tidal frequencies. Such waves are called internal tides.		Shallow areas in otherwise open water can experience rotary tidal currents, flowing in directions that continually change and thus the flow direction (not the flow) completes a full rotation in  12 1⁄2 hours (for example, the Nantucket Shoals).[59]		In addition to oceanic tides, large lakes can experience small tides and even planets can experience atmospheric tides and Earth tides. These are continuum mechanical phenomena. The first two take place in fluids. The third affects the Earth's thin solid crust surrounding its semi-liquid interior (with various modifications).		Large lakes such as Superior and Erie can experience tides of 1 to 4 cm (0.39 to 1.6 in), but these can be masked by meteorologically induced phenomena such as seiche.[60] The tide in Lake Michigan is described as 0.5 to 1.5 inches (13 to 38 mm)[61] or  1 3⁄4 inches.[62] This is so small that other larger effects completely mask any tide, and as such these lakes are considered non-tidal.[63]		Atmospheric tides are negligible at ground level and aviation altitudes, masked by weather's much more important effects. Atmospheric tides are both gravitational and thermal in origin and are the dominant dynamics from about 80 to 120 kilometres (50 to 75 mi), above which the molecular density becomes too low to support fluid behavior.		Earth tides or terrestrial tides affect the entire Earth's mass, which acts similarly to a liquid gyroscope with a very thin crust. The Earth's crust shifts (in/out, east/west, north/south) in response to lunar and solar gravitation, ocean tides, and atmospheric loading. While negligible for most human activities, terrestrial tides' semi-diurnal amplitude can reach about 55 centimetres (22 in) at the equator—15 centimetres (5.9 in) due to the sun—which is important in GPS calibration and VLBI measurements. Precise astronomical angular measurements require knowledge of the Earth's rotation rate and polar motion, both of which are influenced by Earth tides. The semi-diurnal M2 Earth tides are nearly in phase with the moon with a lag of about two hours.[citation needed]		Galactic tides are the tidal forces exerted by galaxies on stars within them and satellite galaxies orbiting them. The galactic tide's effects on the Solar System's Oort cloud are believed to cause 90 percent of long-period comets.[64]		Tsunamis, the large waves that occur after earthquakes, are sometimes called tidal waves, but this name is given by their resemblance to the tide, rather than any actual link to the tide. Other phenomena unrelated to tides but using the word tide are rip tide, storm tide, hurricane tide, and black or red tides. Many of these usages are historic and refer to the earlier meaning of tide as "a portion of time, a season".[65]		
Southern California (colloquially known as SoCal) is a geographic and cultural region that generally comprises California's 10 southernmost counties.[1][2] The region is traditionally described as eight counties, based on demographics and economic ties: Imperial, Los Angeles, Orange, Riverside, San Bernardino, San Diego, Santa Barbara, and Ventura.[3] The more extensive 10-county definition, which includes Kern and San Luis Obispo counties, is also used and is based on historical political divisions.[1]		The 8-county and 10-county definitions are not used for the greater Southern California Megaregion, one of the 11 megaregions of the United States. The megaregion is more expansive, extending east into Las Vegas, Nevada and south across the Mexican border into Tijuana.[4]		Southern California includes the heavily built-up urban area which stretches along the Pacific coast from Ventura through the Greater Los Angeles Area and the Inland Empire, and down to Greater San Diego. Southern California's population encompasses seven metropolitan areas: the Los Angeles metropolitan area (Los Angeles and Orange counties), the Inland Empire, (Riverside and San Bernardino counties), the San Diego metropolitan area, the Oxnard–Thousand Oaks–Ventura metropolitan area, the Santa Barbara metropolitan area, the San Luis Obispo metropolitan area, and the El Centro area. The Los Angeles area has over 12 million inhabitants, while the Riverside-San Bernardino area has over 4 million inhabitants and the San Diego area has over 3 million inhabitants. For Combined Statistical Area (CSA) purposes, the five counties of Los Angeles, Orange, Riverside, San Bernardino, and Ventura, are all combined to make up the Greater Los Angeles Area with over 17.5 million people. With over 22 million people, Southern California contains roughly 60 percent of California's population.		The Colorado Desert and the Colorado River are located on Southern California's eastern border with Arizona, and the Mojave Desert is located north on California's Nevada border. Southern California's southern border is part of the Mexico–United States border.						Within Southern California are two major cities, Los Angeles and San Diego, as well as three of the country's largest metropolitan areas.[5] With a population of 4,042,000, Los Angeles is the most populous city in California and the second most populous in the United States. South of Los Angeles and with a population of 1,307,402 is San Diego, the second most populous city in the state and the eighth most populous in the nation.		The counties of Los Angeles, Orange, San Diego, San Bernardino, and Riverside are the five most populous in the state, and are in the top 15 most populous counties in the United States.[6]		The motion picture, television, and music industry are centered in the Los Angeles area in Southern California. Hollywood, a district within Los Angeles, gives its name to the American motion picture industry, which is synonymous with the neighborhood's name. Headquartered in Southern California are The Walt Disney Company (which also owns ABC), Sony Pictures, Universal, MGM, Paramount Pictures, 20th Century Fox, and Warner Brothers. Universal, Warner Brothers, and Sony also run major record companies.		Southern California is also home to a large homegrown surf and skateboard culture. Companies such as Vans, Volcom, Quiksilver, No Fear, RVCA, and Body Glove are all headquartered here. Professional skateboarder Tony Hawk; professional surfers Rob Machado, Tim Curran, Bobby Martinez, Pat O'Connell, Dane Reynolds, and Chris Ward live in Southern California. Some of the world's famous surf spots are in Southern California as well, including Trestles, Rincon, The Wedge, Huntington Beach, and Malibu. Some of the world's biggest action sports events, including the X Games,[7] Boost Mobile Pro,[8] and the U.S. Open of Surfing, are all held in Southern California. Southern California is also important to the world of yachting. The annual Transpacific Yacht Race, or Transpac, from Los Angeles to Hawaii, is one of yachting's premier events. The San Diego Yacht Club held the America's Cup, the most prestigious prize in yachting, from 1988 to 1995 and hosted three America's Cup races during that time.		Southern California is home to many sports franchises and sports networks such as Fox Sports Net.		Many locals and tourists frequent the Southern California coast for its beaches. The desert city of Palm Springs is especially popular.		Southern California is not a formal geographic designation and definitions of what constitutes Southern California vary. Geographically, California's North-South midway point lies at exactly 37° 9' 58.23" latitude, around 11 miles (18 km) south of San Jose; however, this does not coincide with the popular use of the term. When the state is divided into two areas (Northern and Southern California), the term "Southern California" usually refers to the 10 southernmost counties of the state. This definition coincides neatly with the county lines at 35° 47′ 28″ North latitude, which form the northern borders of San Luis Obispo, Kern, and San Bernardino counties. Another definition for Southern California uses Point Conception and the Tehachapi Mountains as the northern boundary.		Though there is no official definition for the northern boundary of Southern California, such a division has existed from the time when Mexico ruled California and political disputes raged between the Californios of Monterrey in the upper part and Los Angeles in the lower part of Alta California. Following the acquisition of California by the United States, the division continued as part of the attempt by several pro-slavery politicians to arrange the division of Alta California at 36 degrees, 30 minutes, the line of the Missouri Compromise. Instead, the passing of the Compromise of 1850 enabled California to be admitted to the Union as a free state, preventing Southern California from becoming its own separate slave state.		Subsequently, Californians (dissatisfied with inequitable taxes and land laws) and pro-slavery Southerners in the lightly populated "Cow Counties" of Southern California attempted three times in the 1850s to achieve a separate statehood or territorial status separate from Northern California. The last attempt, the Pico Act of 1859, was passed by the California State Legislature and signed by State Governor John B. Weller. It was approved overwhelmingly by nearly 75 percent of voters in the proposed Territory of Colorado. This territory was to include all the counties up to the then much larger Tulare County (that included what is now Kings, most of Kern, and part of Inyo counties) and San Luis Obispo County. The proposal was sent to Washington, D.C. with a strong advocate in Senator Milton Latham. However, the secession crisis following the election of Abraham Lincoln in 1860 and the subsequent American Civil War led to the proposal never coming to a vote.[9][10]		In 1900, the Los Angeles Times defined Southern California as including "the seven counties of Los Angeles, San Bernardino, Orange, Riverside, San Diego, Ventura and Santa Barbara." In 1999, the Times added a newer county, Imperial, to that list.[11]		The state is most commonly divided and promoted by its regional tourism groups, consisting of Northern, Central, and Southern California regions. The two American Automobile Association (AAA) Auto Clubs of the state, the California State Automobile Association, and the Automobile Club of Southern California, choose to simplify matters by dividing the state along the lines where their jurisdictions for membership apply, as either northern or Southern California, in contrast to the three-region point of view. Another influence is the geographical phrase South of the Tehachapis, which would split the Southern region off at the crest of that transverse range, but in that definition, the desert portions of north Los Angeles County and eastern Kern and San Bernardino Counties would be included in the Southern California region due to their remoteness from the central valley and interior desert landscape.		Southern California consists of a heavily developed urban environment, home to some of the largest urban areas in the state, along with vast areas that have been left undeveloped. It is the third most populated megalopolis in the United States, after the Great Lakes Megalopolis and the Northeastern Megalopolis. Much of Southern California is famous for its large, spread-out, suburban communities and use of automobiles and highways. The dominant areas are Los Angeles, Orange County, San Diego, and Riverside-San Bernardino, each of which are the centers of their respective metropolitan areas, composed of numerous smaller cities and communities. The urban area is also host to an international metropolitan region in the form of San Diego–Tijuana, created by the urban area spilling over into Baja California.		Traveling south on Interstate 5, the main gap to continued urbanization is Camp Pendleton. The cities and communities along Interstate 15 and Interstate 215 are so interrelated that Temecula and Murrieta have as much connection with the San Diego metropolitan area as they do with the Inland Empire. To the east, the United States Census Bureau considers the San Bernardino and Riverside County areas, Riverside-San Bernardino area as a separate metropolitan area from Los Angeles County. Newly developed exurbs formed in the Antelope Valley, north of Los Angeles, the Victor Valley, and the Coachella Valley with the Imperial Valley. Also, population growth was high in the Bakersfield-Kern County, Santa Maria and San Luis Obispo areas.		Southern California contains several different types of climate, including Mediterranean, semi-arid and desert, with infrequent rain and many sunny days. Summers are hot or warm, and dry, while winters are mild, and rainfall is low to moderate depending on the area. Although heavy rain can occur, it is unusual. This climatic pattern was alluded to in the hit song, It Never Rains (In Southern California). While snow is very rare in the Southwest of the state, it occurs occasionally in the Southeast region of the state.		Southern California consists of one of the more varied collections of geologic, topographic, and natural ecosystem landscapes in a diversity outnumbering other major regions in the state and country. The region spans from Pacific Ocean islands, shorelines, beaches, and coastal plains, through the Transverse and Peninsular Ranges with their peaks, and into the large and small interior valleys, to the vast deserts of California.		Southern California is divided into:		Each year, Southern California has about 10,000 earthquakes. Nearly all of them are so small that they are not felt. Only several hundred have been greater than magnitude 3.0, and only about 15–20 have been greater than magnitude 4.0.[22] The magnitude 6.7 1994 Northridge earthquake was particularly destructive, causing a substantial number of deaths, injuries, and structural collapses as well as the most property damage of any earthquake in U.S. history at an estimated $20 billion.[23]		Many faults are able to produce a magnitude greater than 6.7 earthquake, such as the San Andreas Fault, which can produce a magnitude 8.0 event. Other faults include the San Jacinto Fault, the Puente Hills Fault, and the Elsinore Fault Zone. The United States Geological Survey (USGS) has released a California earthquake forecast,[24] which models earthquake occurrence in California.		Southern California is divided culturally, politically, and economically into distinct regions, each containing its own culture and atmosphere, anchored usually by a city with both national and sometimes global recognition, which is often the hub of economic activity for its respective region and being home to many tourist destinations. Each region is further divided into many culturally distinct areas but as a whole, combine to create the Southern California atmosphere.		*Part of multiple regions		As of the 2010 United States Census, Southern California has a population of 22,680,010. Despite a reputation for high growth rates, Southern California's rate grew less than the state average of 10.0 percent in the 2000s. This was due to California's growth becoming concentrated in the northern part of the state as result of a stronger, tech-oriented economy in the Bay Area and an emerging Greater Sacramento region.		Southern California consists of one Combined Statistical Area, eight Metropolitan Statistical Areas, one international metropolitan area, and multiple metropolitan divisions. The region is home to two extended metropolitan areas that exceed five million in population. These are the Greater Los Angeles Area at 17,786,419, and San Diego–Tijuana at 5,105,768.[25][26] Of these metropolitan areas, the Los Angeles-Long Beach-Santa Ana metropolitan area, Riverside-San Bernardino-Ontario metropolitan area, and Oxnard-Thousand Oaks-Ventura metropolitan area form Greater Los Angeles;[27] while the El Centro metropolitan area and San Diego-Carlsbad-San Marcos metropolitan area form the Southern Border Region.[28][29] North of Greater Los Angeles are the Santa Barbara, San Luis Obispo, and Bakersfield metropolitan areas.		Los Angeles (with a 2017 census-estimated population of 4.0 million people[30]) and San Diego (at 1.3 million people) are the two largest cities in all of California and are in the top eight largest cities in the United States. In Southern California, there are also 12 cities with more than 200,000 residents and 34 cities over 100,000 residents. Many of Southern California's most developed cities lie along or in close proximity to the coast, with the exception of San Bernardino and Riverside.		Southern California has a diverse economy and is one of the largest economies in the United States. It is dominated and heavily dependent upon the abundance of petroleum, as opposed to other regions where automobiles are not nearly as dominant, due to the vast majority of transport that runs on this fuel. Southern California is famous for tourism and the entertainment industry. Other industries include software, automotive, ports, finance, biomedical, and regional logistics. The region was a leader in the housing bubble from 2001 to 2007 and has been heavily impacted by the housing crash.		Since the 1920s, motion pictures, petroleum, and aircraft manufacturing have been major industries. In one of the richest agricultural regions in the U.S., cattle and citrus were major industries until farmlands were turned into suburbs. Although military spending cutbacks have had an impact, aerospace continues to be a major factor.[31]		Southern California is home to many major business districts. Central business districts (CBD) include Downtown Los Angeles, Downtown San Diego, Downtown San Bernardino and South Coast Metro. Within the Los Angeles Area are the major business districts of Downtown Burbank, Downtown Santa Monica, Downtown Glendale and Downtown Long Beach. Los Angeles itself has many business districts, such as Downtown Los Angeles and those lining the Wilshire Boulevard Miracle Mile, including Century City, Westwood, and Warner Center in the San Fernando Valley. The area of Santa Monica and Venice (and perhaps some of Culver City) is informally referred to as "Silicon Beach" because of the concentration of financial and marketing technology-centric firms located in the region.		The San Bernardino-Riverside area maintains the business districts of Downtown San Bernardino, Hospitality Business/Financial Centre, University Town which are in San Bernardino and Downtown Riverside.		Orange County is a rapidly developing business center that includes Downtown Santa Ana, the South Coast Metro, and Newport Center districts, as well as the Irvine business centers of The Irvine Spectrum, West Irvine, and international corporations headquartered at the University of California, Irvine. West Irvine includes the Irvine Tech Center and Jamboree Business Parks.		Downtown San Diego is the CBD of San Diego, though the city is filled with business districts. These include Carmel Valley, Del Mar Heights, Mission Valley, Rancho Bernardo, Sorrento Mesa, and University City. Most of these districts are located in Northern San Diego and some within North County regions.		Los Angeles		Orange County		Riverside & San Bernardino		San Diego		Southern California is home to Los Angeles International Airport, the second-busiest airport in the United States by passenger volume (see World's busiest airports by passenger traffic) and the third-busiest by international passenger volume (see Busiest airports in the United States by international passenger traffic); San Diego International Airport, the busiest single-runway airport in the world; Van Nuys Airport, the world's busiest general aviation airport; major commercial airports at Orange County, Bakersfield, Ontario, Burbank and Long Beach; and numerous smaller commercial and general aviation airports.		Six of the seven lines of the commuter rail system, Metrolink, run out of Downtown Los Angeles, connecting Los Angeles, Ventura, San Bernardino, Riverside, Orange, and San Diego counties with the other line connecting San Bernardino, Riverside, and Orange counties directly.		Southern California is also home to the Port of Los Angeles, the country's busiest commercial port; the adjacent Port of Long Beach, the country's second busiest container port; and the Port of San Diego.		The following table shows all airports listed by the Federal Aviation Association (FAA) as a hub airport:[32]		Sections of the Southern California freeway system are often referred to by names rather than by the official numbers.		The Tech Coast is a moniker that has gained use as a descriptor for the region's diversified technology and industrial base as well as its multitude of prestigious and world-renowned research universities and other public and private institutions. Amongst these include five University of California campuses (Irvine, Los Angeles, Riverside, Santa Barbara, and San Diego), 12 California State University campuses (Bakersfield, Channel Islands, Dominguez Hills, Fullerton, Los Angeles, Long Beach, Northridge, Pomona, San Bernardino, San Diego, San Marcos, and San Luis Obispo); and private institutions such as the California Institute of Technology, Chapman University, the Claremont Colleges (Claremont McKenna College, Harvey Mudd College, Pitzer College, Pomona College, and Scripps College), Loma Linda University, Loyola Marymount University, Occidental College, Pepperdine University, University of Redlands, University of San Diego, and the University of Southern California.		Professional sports teams in Southern California include teams from the NFL (Los Angeles Rams, Los Angeles Chargers), NBA (Los Angeles Lakers, Los Angeles Clippers); MLB (Los Angeles Dodgers, Los Angeles Angels of Anaheim, San Diego Padres), NHL (Los Angeles Kings, Anaheim Ducks), and MLS (LA Galaxy).		Southern California also is home to a number of popular NCAA sports programs such as the UCLA Bruins, the USC Trojans, and the San Diego State Aztecs. The Bruins and the Trojans both field teams in NCAA Division I in the Pac-12 Conference, and there is a longtime rivalry between the schools.		Coordinates: 34°00′N 117°00′W﻿ / ﻿34.000°N 117.000°W﻿ / 34.000; -117.000		
In sedimentary geology and fluvial geomorphology, avulsion is the rapid abandonment of a river channel and the formation of a new river channel. Avulsions occur as a result of channel slopes that are much less steep than the slope that the river could travel if it took a new course.[1]						Avulsions are common in river deltas, where sediment deposits as the river enters the ocean and channel gradients are typically very small.[2] This process is also known as delta switching.		Deposition from the river results in the formation of an individual deltaic lobe that pushes out into the sea. An example of a deltaic lobe is the bird's-foot delta of the Mississippi River, pictured at right with its sediment plumes. As the deltaic lobe advances, the slope of the river channel becomes lower because the river channel is longer but has the same change in elevation (see slope or gradient). As the slope of the river channel decreases, it becomes unstable for two reasons. First, water under the force of gravity will tend to flow in the most direct course downslope. If the river could breach its natural levees (i.e., during a flood), it would spill out onto a new course with a shorter route to the ocean, thereby obtaining a more stable steeper slope.[1] Second, as its slope is reduced, the amount of shear stress on the bed will decrease, resulting in deposition of more sediment within the channel and thus raising of the channel bed relative to the floodplain. This will make it easier for the river to breach its levees and cut a new channel that enters the ocean at a steeper slope.		When this avulsion occurs, the new channel carries sediment out to the ocean, building a new deltaic lobe.,[3][4] The abandoned delta eventually subsides.[5]		This process is also related to the distributary network of river channels that can be observed within a river delta. When the channel does this, some of its flow can remain in the abandoned channel. When these channel switching events happen repeatedly over time, a mature delta will gain a distributary network.[6]		Subsidence of the delta and/or sea-level rise can further cause backwater and deposition in the delta. This deposition fills the channels and leaves a geologic record of channel avulsion in sedimentary basins. On average, an avulsion will occur every time the bed of a river channel aggrades enough that the river channel is superelevated above the floodplain by one channel-depth. In this situation, enough hydraulic head is available that any breach of the natural levees will result in an avulsion.[7][8]		Rivers can also avulse due to the erosion of a new channel that creates a straighter path through the landscape. This can happen during large floods in situations in which the slope of the new channel is significantly greater than that of the old channel. Where the new channel's slope is about the same as the old channel's slope, a partial avulsion will occur in which both channels are occupied by flow.[9] An example of an erosional avulsion is the 2006 avulsion of the Suncook River in New Hampshire, in which heavy rains caused flow levels to rise. The flow level rise was pronounced behind an old mill dam, which produced a shallowly-sloping pool that overtopped a sand and gravel quarry, connected with a downstream section of channel, and cut a new (and shorter) channel at a rate of 25–50 meters per hour.[10] Sediment mobilised by this erosional avulsion produced a depositionally-forced meander cutoff further downstream by superelevating the bed around the meander bend to nearly the level of the floodplain.[11]		An example of a minor avulsion is known as a meander cutoff, where the high-sinuosity meander bend is abandoned in favour of the high-slope. This occurs when the ratio between the channel slope and the potential slope after an avulsion is less than about 1/5.[1]		Avulsion typically occurs during large floods which carry the power necessary to rapidly change the landscape. Dam removal could also lead to avulsion.		Avulsions usually occur as a downstream to upstream process via head cutting erosion. If a bank of a current stream is breached a new trench will be cut into the existing floodplain. It either cuts through floodplain deposits or reoccupies an old channel.[12]		Avulsions have been investigated in the deltas or coastal plain channels as a result of obstructions such as log-jams and possible tectonic influences.[13]		
Brackish marshes develop by salt marshes where a significant freshwater influx dilutes the seawater to brackish levels of salinity. This commonly happens upstream from salt marshes by estuaries of coastal rivers or near the mouths of coastal rivers with heavy freshwater discharges in the conditions of low tidal ranges.[1]		
A tombolo, from the Italian tombolo, derived from the Latin tumulus, meaning 'mound', and sometimes translated as ayre, is a deposition landform in which an island is attached to the mainland by a narrow piece of land such as a spit or bar. Once attached, the island is then known as a tied island.		Several islands tied together by bars which rise above the water level are called a tombolo cluster.[1] Two or more tombolos may form an enclosure (called a lagoon) that can eventually fill with sediment.						The shoreline moves toward the island (or detached breakwater) due to accretion of sand in the lee of the island where wave energy and longshore drift are reduced and therefore deposition of sand occurs.		True tombolos are formed by wave refraction and diffraction. As waves near an island, they are slowed by the shallow water surrounding it. These waves then bend around the island to the opposite side as they approach. The wave pattern created by this water movement causes a convergence of longshore drift on the opposite side of the island. The beach sediments that are moving by lateral transport on the lee side of the island will accumulate there, conforming to the shape of the wave pattern. In other words, the waves sweep sediment together from both sides. Eventually, when enough sediment has built up, the beach shoreline, known as a spit, will connect with an island and form a tombolo.[2]		In the case of longshore drift from one single or a dominant direction, like at Chesil Beach or Spurn Head, the flow of material is along the coast in a movement which is not determined by the now tied island, such as Portland, which it has reached. In this and similar cases, while the strip of beach material connected to the island may be technically called a tombolo because it links the island to the land, it is better thought of in terms of its formation – as a spit or otherwise.		Tombolos are more prone to natural fluctuations of profile and area as a result of tidal and weather events than a normal beach is. Because of this susceptibility to weathering, tombolos are sometimes made more sturdy through the construction of roads or parking lots. The sediments that make up a tombolo are coarser towards the bottom and finer towards the surface. It is easy to see this pattern when the waves are destructive and wash away finer grained material at the top, revealing coarser sands and cobbles as the base.		Sea level rise may also contribute to accretion, as material is pushed up with rising sea levels. This is the case with Chesil Beach (which connects the Isle of Portland to Dorset in England), notable because the shingle ridge is parallel rather than at right angles to the coast.		Tombolos demonstrate the sensitivity of shorelines. A small piece of land, such as an island, can change the way that waves move, leading to different deposition of sediments.		
Coordinates: 60°N 95°W﻿ / ﻿60°N 95°W﻿ / 60; -95		Canada (/ˈkænədə/ ( listen); French: [kanadɑ]) is a country in the northern part of North America. Its ten provinces and three territories extend from the Atlantic to the Pacific and northward into the Arctic Ocean, covering 9.98 million square kilometres (3.85 million square miles), making it the world's second-largest country by total area and the fourth-largest country by land area. Canada's southern border with the United States is the world's longest bi-national land border. The majority of the country has a cold or severely cold winter climate, but southerly areas are warm in summer. Canada is sparsely populated, the majority of its land territory being dominated by forest and tundra and the Rocky Mountains. It is highly urbanized with 82 per cent of the 35.15 million people concentrated in large and medium-sized cities, many near the southern border. Its capital is Ottawa, and its largest metropolitan areas are Toronto, Montreal and Vancouver.		Various indigenous peoples had inhabited what is now Canada for thousands of years prior to European colonization. Beginning in the 16th century, British and French claims were made on the area, with the colony of Canada first being established by the French in 1535 during Jacques Cartier's second voyage to New France. As a consequence of various conflicts, Great Britain gained and lost territories within British North America until it was left, in the late 18th century, with what mostly geographically comprises Canada today. Pursuant to the British North America Act, on July 1, 1867, the colonies of Canada, New Brunswick, and Nova Scotia joined to form the semi-autonomous federal Dominion of Canada. This began an accretion of provinces and territories to the mostly self-governing Dominion to the present ten provinces and three territories forming modern Canada.		In 1931, Canada achieved near-total independence from the United Kingdom with the Statute of Westminster 1931, but at the time, Canada decided to allow the British Parliament to temporarily retain the power to amend Canada's constitution, on request from the Parliament of Canada. With the Constitution Act 1982, Canada took over that authority (as the conclusion of Patriation), removing the last remaining ties of legal dependence on the British Parliament, giving the country full sovereignty.		Canada is a federal parliamentary democracy and a constitutional monarchy, with Queen Elizabeth II being the head of state. The country is officially bilingual at the federal level. It is one of the world's most ethnically diverse and multicultural nations, the product of large-scale immigration from many other countries. Its advanced economy is the tenth-largest in the world, relying chiefly upon its abundant natural resources and well-developed international trade networks. Canada's long and complex relationship with the United States has had a significant impact on its economy and culture.		Canada is a developed country and has the fifteenth-highest nominal per capita income globally as well as the tenth-highest ranking in the Human Development Index. It ranks among the highest in international measurements of government transparency, civil liberties, quality of life, economic freedom, and education. Canada is a realm within the Commonwealth of Nations, a member of the Francophonie, and part of several major international and intergovernmental institutions or groupings including the United Nations, the North Atlantic Treaty Organization, the G7 (formerly G8), the Group of Ten, the G20, the North American Free Trade Agreement and the Asia-Pacific Economic Cooperation forum.						While a variety of theories have been postulated for the etymological origins of Canada, the name is now accepted as coming from the St. Lawrence Iroquoian word kanata, meaning "village" or "settlement".[11] In 1535, indigenous inhabitants of the present-day Quebec City region used the word to direct French explorer Jacques Cartier to the village of Stadacona.[12] Cartier later used the word Canada to refer not only to that particular village, but to the entire area subject to Donnacona (the chief at Stadacona);[12] by 1545, European books and maps had begun referring to this small region along the Saint Lawrence River as Canada.[12]		From the 16th to the early 18th century "Canada" referred to the part of New France that lay along the Saint Lawrence River.[13] In 1791, the area became two British colonies called Upper Canada and Lower Canada collectively named the Canadas; until their union as the British Province of Canada in 1841.[14] Upon Confederation in 1867, Canada was adopted as the legal name for the new country at the London Conference, and the word Dominion was conferred as the country's title.[15] The transition away from the use of Dominion was formally reflected in 1982 with the passage of the Canada Act, which refers only to Canada. Later that year, the name of the national holiday was changed from Dominion Day to Canada Day.[16] The term Dominion is also used to distinguish the federal government from the provinces, though after the Second World War the term federal had replaced dominion.[17]		Indigenous peoples in present-day Canada include the First Nations, Inuit, and Métis,[18] the latter being a mixed-blood people who originated in the mid-17th century when First Nations and Inuit people married European settlers.[18] The term "Aboriginal" as a collective noun is a specific term of art used in some legal documents, including the Constitution Act 1982.[19]		The first inhabitants of North America migrated from Siberia by way of the Bering land bridge[20] and arrived at least 15,000 years ago, though increasing evidence suggests an even earlier arrival.[21] The Paleo-Indian archeological sites at Old Crow Flats and Bluefish Caves are two of the oldest sites of human habitation in Canada.[22] The characteristics of Canadian indigenous societies included permanent settlements, agriculture, complex societal hierarchies, and trading networks.[23][24] Some of these cultures had collapsed by the time European explorers arrived in the late 15th and early 16th centuries and have only been discovered through archeological investigations.[25]		The indigenous population at the time of the first European settlements is estimated to have been between 200,000[26] and two million,[27] with a figure of 500,000 accepted by Canada's Royal Commission on Aboriginal Peoples.[28] As a consequence of contact with Europeans, Canada's indigenous peoples suffered from repeated outbreaks of newly introduced infectious diseases, such as influenza, measles, and smallpox (to which they had no natural immunity), resulting in a forty to eighty percent population decrease in the centuries after the European arrival.[26][29]		Although not without conflict, European Canadians' early interactions with First Nations and Inuit populations were relatively peaceful.[30] The Crown and indigenous peoples began interactions during the European colonization period, though the Inuit, in general, had more limited interaction with European settlers.[31] First Nations and Métis peoples played a critical part in the development of European colonies in Canada, particularly for their role in assisting European coureur des bois and voyageurs in the exploration of the continent during the North American fur trade.[32] From the late 18th century, European Canadians encouraged indigenous peoples to assimilate into their own culture.[33] These attempts reached a climax in the late 19th and early 20th centuries with forced integration and relocations.[34] A period of redress is underway, which started with the appointment of the Truth and Reconciliation Commission of Canada by the Canadian government.[35]		The first known attempt at European colonization began when Norsemen settled briefly at L'Anse aux Meadows in Newfoundland around 1000 AD.[36] No further European exploration occurred until 1497, when Italian seafarer John Cabot explored and claimed Canada's Atlantic coast in the name of King Henry VII of England.[37][38] Then Basque and Portuguese mariners established seasonal whaling and fishing outposts along the Atlantic coast in the early 16th century.[39] In 1534, French explorer Jacques Cartier explored the Gulf of Saint Lawrence where, on July 24, he planted a 10-metre (33 ft) cross bearing the words "Long Live the King of France" and took possession of the territory New France in the name of King Francis I.[40] In general the settlements appear to have been short-lived, possibly due to the similarity of outputs producible in Scandinavia and northern Canada and the problems of navigating trade routes at that time.[41]		In 1583, Sir Humphrey Gilbert, by the royal prerogative of Queen Elizabeth I, founded St. John's, Newfoundland, as the first North American English colony.[42] French explorer Samuel de Champlain arrived in 1603 and established the first permanent European settlements at Port Royal (in 1605) and Quebec City (in 1608).[43] Among the colonists of New France, Canadiens extensively settled the Saint Lawrence River valley and Acadians settled the present-day Maritimes, while fur traders and Catholic missionaries explored the Great Lakes, Hudson Bay, and the Mississippi watershed to Louisiana.[44] The Beaver Wars broke out in the mid-17th century over control of the North American fur trade.[45]		The English established additional colonies in Cupids and Ferryland, Newfoundland, beginning in 1610.[46] The Thirteen Colonies to the south were founded soon after.[39] A series of four wars erupted in colonial North America between 1689 and 1763; the later wars of the period constituted the North American theatre of the Seven Years' War.[47] Mainland Nova Scotia came under British rule with the 1713 Treaty of Utrecht, and the 1763 Treaty of Paris ceded Canada and most of New France to Britain after the Seven Years' War.[48]		The Royal Proclamation of 1763 created the Province of Quebec out of New France, and annexed Cape Breton Island to Nova Scotia.[16] St. John's Island (now Prince Edward Island) became a separate colony in 1769.[49] To avert conflict in Quebec, the British Parliament passed the Quebec Act of 1774, expanding Quebec's territory to the Great Lakes and Ohio Valley.[50] It re-established the French language, Catholic faith, and French civil law there. This angered many residents of the Thirteen Colonies, fuelling anti-British sentiment in the years prior to the 1775 outbreak of the American Revolution.[16]		The 1783 Treaty of Paris recognized American independence and ceded the newly added territories south (but not north) of the Great Lakes to the new United States.[51] New Brunswick was split from Nova Scotia as part of a reorganization of Loyalist settlements in the Maritimes.[52] To accommodate English-speaking Loyalists in Quebec, the Constitutional Act of 1791 divided the province into French-speaking Lower Canada (later Quebec) and English-speaking Upper Canada (later Ontario), granting each its own elected legislative assembly.[53]		The Canadas were the main front in the War of 1812 between the United States and the United Kingdom. Peace came in 1815; no boundaries were changed. Immigration resumed at a higher level, with over 960,000 arrivals from Britain 1815–50.[54] New arrivals included refugees escaping the Great Irish Famine as well as Gaelic-speaking Scots displaced by the Highland Clearances.[55] Infectious diseases killed between 25 and 33 per cent of Europeans who immigrated to Canada before 1891.[26]		The desire for responsible government resulted in the abortive Rebellions of 1837.[56] The Durham Report subsequently recommended responsible government and the assimilation of French Canadians into English culture.[16] The Act of Union 1840 merged the Canadas into a united Province of Canada and responsible government was established for all provinces of British North America by 1849.[57] The signing of the Oregon Treaty by Britain and the United States in 1846 ended the Oregon boundary dispute, extending the border westward along the 49th parallel. This paved the way for British colonies on Vancouver Island (1849) and in British Columbia (1858).[58]		Following several constitutional conferences, the 1867 Constitution Act officially proclaimed Canadian Confederation on July 1, 1867, initially with four provinces: Ontario, Quebec, Nova Scotia, and New Brunswick.[59][60] Canada assumed control of Rupert's Land and the North-Western Territory to form the Northwest Territories, where the Métis' grievances ignited the Red River Rebellion and the creation of the province of Manitoba in July 1870.[61] British Columbia and Vancouver Island (which had been united in 1866) joined the confederation in 1871, while Prince Edward Island joined in 1873.[62]		The Canadian parliament passed a bill introduced by the Conservative Cabinet that established a National Policy of tariffs to protect the nascent Canadian manufacturing industries.[60] To open the West, parliament also approved sponsoring the construction of three transcontinental railways (including the Canadian Pacific Railway), opening the prairies to settlement with the Dominion Lands Act, and establishing the North-West Mounted Police to assert its authority over this territory.[63][64] In 1898, during the Klondike Gold Rush in the Northwest Territories, parliament created the Yukon Territory. The Cabinet of Liberal Prime Minister Wilfrid Laurier fostered continental European immigrants settling the prairies and Alberta and Saskatchewan became provinces in 1905.[62]		Because Britain still maintained control of Canada's foreign affairs under the Confederation Act, its declaration of war in 1914 automatically brought Canada into World War I.[65] Volunteers sent to the Western Front later became part of the Canadian Corps, which played a substantial role in the Battle of Vimy Ridge and other major engagements of the war.[66] Out of approximately 625,000 Canadians who served in World War I, some 60,000 were killed and another 172,000 were wounded.[67] The Conscription Crisis of 1917 erupted when the Unionist Cabinet's proposal to augment the military's dwindling number of active members with conscription was met with vehement objections from French-speaking Quebecers.[68] The Military Service Act brought in compulsory military service, though it, coupled with disputes over French language schools outside Quebec, deeply alienated Francophone Canadians and temporarily split the Liberal Party.[68] In 1919, Canada joined the League of Nations independently of Britain,[66] and the 1931 Statute of Westminster affirmed Canada's independence.[4]		The Great Depression in Canada during the early 1930s saw an economic downturn, leading to hardship across the country.[69] In response to the downturn, the Co-operative Commonwealth Federation (CCF) in Saskatchewan introduced many elements of a welfare state (as pioneered by Tommy Douglas) in the 1940s and 1950s.[70] On the advice of Prime Minister William Lyon Mackenzie King, war with Germany was declared effective September 10, 1939, by King George VI, seven days after the United Kingdom. The delay underscored Canada's independence.[66]		The first Canadian Army units arrived in Britain in December 1939. In all, over a million Canadians served in the armed forces during World War II and approximately 42,000 were killed and another 55,000 were wounded.[71] Canadian troops played important roles in many key battles of the war, including the failed 1942 Dieppe Raid, the Allied invasion of Italy, the Normandy landings, the Battle of Normandy, and the Battle of the Scheldt in 1944.[66] Canada provided asylum for the Dutch monarchy while that country was occupied and is credited by the Netherlands for major contributions to its liberation from Nazi Germany.[72] The Canadian economy boomed during the war as its industries manufactured military materiel for Canada, Britain, China, and the Soviet Union.[66] Despite another Conscription Crisis in Quebec in 1944, Canada finished the war with a large army and strong economy.[73]		The financial crisis of the Great Depression had led the Dominion of Newfoundland to relinquish responsible government in 1934 and become a crown colony ruled by a British governor.[74] After two bitter referendums, Newfoundlanders voted to join Canada in 1949 as a province.[75]		Canada's post-war economic growth, combined with the policies of successive Liberal governments, led to the emergence of a new Canadian identity, marked by the adoption of the Maple Leaf Flag in 1965,[76] the implementation of official bilingualism (English and French) in 1969,[77] and the institution of official multiculturalism in 1971.[78] Socially democratic programs were also instituted, such as Medicare, the Canada Pension Plan, and Canada Student Loans, though provincial governments, particularly Quebec and Alberta, opposed many of these as incursions into their jurisdictions.[79]		Finally, another series of constitutional conferences resulted in the Canada Act 1982, the patriation of Canada's constitution from the United Kingdom, concurrent with the creation of the Canadian Charter of Rights and Freedoms.[80][81][82] Canada had established complete sovereignty as an independent country, with the Queen's role as monarch of Canada separate from her role as the British monarch or the monarch of any of the other Commonwealth realms.[83][84] In 1999, Nunavut became Canada's third territory after a series of negotiations with the federal government.[85]		At the same time, Quebec underwent profound social and economic changes through the Quiet Revolution of the 1960s, giving birth to a modern secular nationalist movement.[86] The radical Front de libération du Québec (FLQ) ignited the October Crisis with a series of bombings and kidnappings in 1970[87] and the sovereignist Parti Québécois was elected in 1976, organizing an unsuccessful referendum on sovereignty-association in 1980. Attempts to accommodate Quebec nationalism constitutionally through the Meech Lake Accord failed in 1990.[88] This led to the formation of the Bloc Québécois in Quebec and the invigoration of the Reform Party of Canada in the West.[89][90] A second referendum followed in 1995, in which sovereignty was rejected by a slimmer margin of 50.6 to 49.4 percent.[91] In 1997, the Supreme Court ruled that unilateral secession by a province would be unconstitutional and the Clarity Act was passed by parliament, outlining the terms of a negotiated departure from Confederation.[88]		In addition to the issues of Quebec sovereignty, a number of crises shook Canadian society in the late 1980s and early 1990s. These included the explosion of Air India Flight 182 in 1985, the largest mass murder in Canadian history;[92] the École Polytechnique massacre in 1989, a university shooting targeting female students;[93] and the Oka Crisis of 1990,[94] the first of a number of violent confrontations between the government and indigenous groups.[95] Canada also joined the Gulf War in 1990 as part of a US-led coalition force and was active in several peacekeeping missions in the 1990s, including the UNPROFOR mission in the former Yugoslavia.[96]		Canada sent troops to Afghanistan in 2001, but declined to join the US-led invasion of Iraq in 2003.[97] In 2011, Canadian forces participated in the NATO-led intervention into the Libyan civil war,[98] and also became involved in battling the Islamic State insurgency in Iraq in the mid-2010s.[99]		Canada occupies much of the continent of North America, sharing land borders with the contiguous United States to the south, and the US state of Alaska to the northwest. Canada stretches from the Atlantic Ocean in the east to the Pacific Ocean in the west; to the north lies the Arctic Ocean.[100] Greenland is to the northeast. By total area (including its waters), Canada is the second-largest country in the world, after Russia. By land area alone, however, Canada ranks fourth, the difference being due to it having the world's largest proportion of fresh water lakes.[101]		Canada is home to the world's northernmost settlement, Canadian Forces Station Alert, on the northern tip of Ellesmere Island – latitude 82.5°N – which lies 817 kilometres (508 mi) from the North Pole.[102] Much of the Canadian Arctic is covered by ice and permafrost. Canada has the longest coastline in the world, with a total length of 243,042 kilometres (151,019 mi);[103] additionally, its border with the United States is the world's longest land border, stretching 8,891 kilometres (5,525 mi).[104]		Since the end of the last glacial period, Canada has consisted of eight distinct forest regions, including extensive boreal forest on the Canadian Shield.[105] Canada has over 2,000,000 lakes (563 greater than 100 km2 (39 sq mi)), more than any other country, containing much of the world's fresh water.[106][107] There are also fresh-water glaciers in the Canadian Rockies and the Coast Mountains.[108]		Canada is geologically active, having many earthquakes and potentially active volcanoes, notably Mount Meager, Mount Garibaldi, Mount Cayley, and the Mount Edziza volcanic complex.[109] The volcanic eruption of the Tseax Cone in 1775 was among Canada's worst natural disasters, killing an estimated 2,000 Nisga'a people and destroying their village in the Nass River valley of northern British Columbia.[110] The eruption produced a 22.5-kilometre (14.0 mi) lava flow, and, according to Nisga'a legend, blocked the flow of the Nass River.[111]		Average winter and summer high temperatures across Canada vary from region to region. Winters can be harsh in many parts of the country, particularly in the interior and Prairie provinces, which experience a continental climate, where daily average temperatures are near −15 °C (5 °F), but can drop below −40 °C (−40 °F) with severe wind chills.[112] In noncoastal regions, snow can cover the ground for almost six months of the year, while in parts of the north snow can persist year-round. Coastal British Columbia has a temperate climate, with a mild and rainy winter. On the east and west coasts, average high temperatures are generally in the low 20s °C (70s °F), while between the coasts, the average summer high temperature ranges from 25 to 30 °C (77 to 86 °F), with temperatures in some interior locations occasionally exceeding 40 °C (104 °F).[113]		Canada has a parliamentary system within the context of a constitutional monarchy, the monarchy of Canada being the foundation of the executive, legislative, and judicial branches.[114][115][116] The sovereign is Queen Elizabeth II, who is also monarch of 15 other Commonwealth countries and each of Canada's 10 provinces. As such, the Queen's representative, the Governor General of Canada (at present David Johnston), carries out most of the federal royal duties in Canada.[117][118]		The direct participation of the royal and viceroyal figures in areas of governance is limited.[116][119][120] In practice, their use of the executive powers is directed by the Cabinet, a committee of ministers of the Crown responsible to the elected House of Commons and chosen and headed by the Prime Minister of Canada (at present Justin Trudeau),[121] the head of government. The governor general or monarch may, though, in certain crisis situations exercise their power without ministerial advice.[119] To ensure the stability of government, the governor general will usually appoint as prime minister the person who is the current leader of the political party that can obtain the confidence of a plurality in the House of Commons.[122] The Prime Minister's Office (PMO) is thus one of the most powerful institutions in government, initiating most legislation for parliamentary approval and selecting for appointment by the Crown, besides the aforementioned, the governor general, lieutenant governors, senators, federal court judges, and heads of Crown corporations and government agencies.[119] The leader of the party with the second-most seats usually becomes the Leader of Her Majesty's Loyal Opposition and is part of an adversarial parliamentary system intended to keep the government in check.[123]		Each of the 338 members of parliament in the House of Commons is elected by simple plurality in an electoral district or riding. General elections must be called by the governor general, either on the advice of the prime minister, or if the government loses a confidence vote in the House.[124][125] Constitutionally, an election may be held no more than five years after the preceding election, although the Canada Elections Act limits this to four years with a fixed election date in October. The 105 members of the Senate, whose seats are apportioned on a regional basis, serve until age 75.[126] Five parties had representatives elected to the federal parliament in the 2015 election: the Liberal Party of Canada who currently form the government, the Conservative Party of Canada who are the Official Opposition, the New Democratic Party, the Bloc Québécois, and the Green Party of Canada.[127]		Canada's federal structure divides government responsibilities between the federal government and the ten provinces. Provincial legislatures are unicameral and operate in parliamentary fashion similar to the House of Commons.[120] Canada's three territories also have legislatures, but these are not sovereign and have fewer constitutional responsibilities than the provinces.[128] The territorial legislatures also differ structurally from their provincial counterparts.[129]		The Bank of Canada is the central bank of the country. In addition, the Minister of Finance and Minister of Industry utilize the Statistics Canada agency for financial planning and economic policy development.[130] The Bank of Canada is the sole authority authorized to issue currency in the form of Canadian bank notes.[131] The bank does not issue Canadian coins; they are issued by the Royal Canadian Mint.[132]		The Constitution of Canada is the supreme law of the country, and consists of written text and unwritten conventions.[133] The Constitution Act, 1867 (known as the British North America Act prior to 1982), affirmed governance based on parliamentary precedent and divided powers between the federal and provincial governments.[134] The Statute of Westminster 1931 granted full autonomy and the Constitution Act, 1982, ended all legislative ties to the UK, as well as adding a constitutional amending formula and the Canadian Charter of Rights and Freedoms.[135] The Charter guarantees basic rights and freedoms that usually cannot be over-ridden by any government—though a notwithstanding clause allows the federal parliament and provincial legislatures to override certain sections of the Charter for a period of five years.[136]		The Indian Act, various treaties and case laws were established to mediate relations between Europeans and native peoples.[137] Most notably, a series of eleven treaties known as the Numbered Treaties were signed between the indigenous and the reigning Monarch of Canada between 1871 and 1921.[138] These treaties are agreements with the Canadian Crown-in-Council, administered by Canadian Aboriginal law, and overseen by the Minister of Indigenous and Northern Development. The role of the treaties and the rights they support were reaffirmed by Section Thirty-five of the Constitution Act, 1982.[137] These rights may include provision of services, such as health care, and exemption from taxation.[139] The legal and policy framework within which Canada and First Nations operate was further formalized in 2005, through the First Nations–Federal Crown Political Accord.[137]		Canada's judiciary plays an important role in interpreting laws and has the power to strike down Acts of Parliament that violate the constitution. The Supreme Court of Canada is the highest court and final arbiter and has been led since 2000 by the Chief Justice Beverley McLachlin (the first female Chief Justice).[140] Its nine members are appointed by the governor general on the advice of the prime minister and minister of justice. All judges at the superior and appellate levels are appointed after consultation with nongovernmental legal bodies. The federal Cabinet also appoints justices to superior courts in the provincial and territorial jurisdictions.[141]		Common law prevails everywhere except in Quebec, where civil law predominates. Criminal law is solely a federal responsibility and is uniform throughout Canada.[142] Law enforcement, including criminal courts, is officially a provincial responsibility, conducted by provincial and municipal police forces.[143] However, in most rural areas and some urban areas, policing responsibilities are contracted to the federal Royal Canadian Mounted Police.[144]		Canada is recognized as a middle power for its role in international affairs with a tendency to pursue multilateral solutions.[145] Canada's foreign policy based on international peacekeeping and security is carried out through coalitions and international organizations, and through the work of numerous federal institutions.[146] Canada's peacekeeping role during the 20th century has played a major role in its global image.[147] The strategy of the Canadian government's foreign aid policy reflects an emphasis to meet the Millennium Development Goals, while also providing assistance in response to foreign humanitarian crises.[148]		Canada was a founding member of the United Nations and has membership in the World Trade Organization, the G20 and the Organisation for Economic Co-operation and Development (OECD).[145] Canada is also a member of various other international and regional organizations and forums for economic and cultural affairs.[149] Canada acceded to the International Covenant on Civil and Political Rights in 1976.[150] Canada joined the Organization of American States (OAS) in 1990 and hosted the OAS General Assembly in 2000 and the 3rd Summit of the Americas in 2001.[151] Canada seeks to expand its ties to Pacific Rim economies through membership in the Asia-Pacific Economic Cooperation forum (APEC).[152]		Canada and the United States share the world's longest undefended border, co-operate on military campaigns and exercises, and are each other's largest trading partner.[153][154] Canada nevertheless has an independent foreign policy, most notably maintaining full relations with Cuba since, and declining to officially participate in the 2003 invasion of Iraq.[155] Canada also maintains historic ties to the United Kingdom and France and to other former British and French colonies through Canada's membership in the Commonwealth of Nations and the Francophonie.[156] Canada is noted for having a positive relationship with the Netherlands, owing, in part, to its contribution to the Dutch liberation during World War II.[72]		Canada's strong attachment to the British Empire and Commonwealth led to major participation in British military efforts in the Second Boer War, World War I and World War II.[157] Since then, Canada has been an advocate for multilateralism, making efforts to resolve global issues in collaboration with other nations.[158][159] During the Cold War, Canada was a major contributor to UN forces in the Korean War and founded the North American Aerospace Defense Command (NORAD) in co-operation with the United States to defend against potential aerial attacks from the Soviet Union.[160]		During the Suez Crisis of 1956, future Prime Minister Lester B. Pearson eased tensions by proposing the inception of the United Nations Peacekeeping Force, for which he was awarded the 1957 Nobel Peace Prize.[161] As this was the first UN peacekeeping mission, Pearson is often credited as the inventor of the concept.[162] Canada has since served in over 50 peacekeeping missions, including every UN peacekeeping effort until 1989,[66] and has since maintained forces in international missions in Rwanda, the former Yugoslavia, and elsewhere; Canada has sometimes faced controversy over its involvement in foreign countries, notably in the 1993 Somalia Affair.[163]		In 2001, Canada deployed troops to Afghanistan as part of the US stabilization force and the UN-authorized, NATO-led International Security Assistance Force.[164] In February 2007, Canada, Italy, the United Kingdom, Norway, and Russia announced their joint commitment to a $1.5-billion project to help develop vaccines for developing nations, and called on other countries to join them.[165] In August 2007, Canada's territorial claims in the Arctic were challenged after a Russian underwater expedition to the North Pole; Canada has considered that area to be sovereign territory since 1925.[166]		The nation employs a professional, volunteer military force of approximately 79,000 active personnel and 32,250 reserve personnel.[167] The unified Canadian Forces (CF) comprise the Canadian Army, Royal Canadian Navy, and Royal Canadian Air Force. In 2013, Canada's military expenditure totalled approximately C$19 billion, or around 1% of the country's GDP.[168][169]		Canada is a federation composed of ten provinces and three territories. In turn, these may be grouped into four main regions: Western Canada, Central Canada, Atlantic Canada, and Northern Canada (Eastern Canada refers to Central Canada and Atlantic Canada together). Provinces have more autonomy than territories, having responsibility for social programs such as health care, education, and welfare.[170] Together, the provinces collect more revenue than the federal government, an almost unique structure among federations in the world. Using its spending powers, the federal government can initiate national policies in provincial areas, such as the Canada Health Act; the provinces can opt out of these, but rarely do so in practice. Equalization payments are made by the federal government to ensure that reasonably uniform standards of services and taxation are kept between the richer and poorer provinces.[171]		Canada is the world's tenth-largest economy as of 2016[update], with a nominal GDP of approximately US$1.52 trillion.[7] It is a member of the Organisation for Economic Co-operation and Development (OECD) and the Group of Eight (G8), and is one of the world's top ten trading nations, with a highly globalized economy.[172][173] Canada is a mixed economy, ranking above the US and most western European nations on The Heritage Foundation's index of economic freedom,[174] and experiencing a relatively low level of income disparity.[175] The country's average household disposable income per capita is over US$23,900, higher than the OECD average.[176] Furthermore, the Toronto Stock Exchange is the seventh-largest stock exchange in the world by market capitalization, listing over 1,500 companies with a combined market capitalization of over US$2 trillion as of 2015[update].[177]		In 2014, Canada's exports totalled over C$528 billion, while its imported goods were worth over $524 billion, of which approximately $351 billion originated from the United States, $49 billion from the European Union, and $35 billion from China.[178] The country's 2014 trade surplus totalled C$5.1 billion, compared with a C$46.9 billion surplus in 2008.[179][180]		Since the early 20th century, the growth of Canada's manufacturing, mining, and service sectors has transformed the nation from a largely rural economy to an urbanized, industrial one.[181] Like many other developed countries, the Canadian economy is dominated by the service industry, which employs about three-quarters of the country's workforce.[182] However, Canada is unusual among developed countries in the importance of its primary sector, in which the forestry and petroleum industries are two of the most prominent components.[183]		Canada is one of the few developed nations that are net exporters of energy.[185] Atlantic Canada possesses vast offshore deposits of natural gas, and Alberta also hosts large oil and gas resources. The vastness of the Athabasca oil sands and other assets results in Canada having a 13% share of global oil reserves, comprising the world's third-largest share after Venezuela and Saudi Arabia.[186] Canada is additionally one of the world's largest suppliers of agricultural products; the Canadian Prairies are one of the most important global producers of wheat, canola, and other grains.[187] Canada's Ministry of Natural Resources provides statistics regarding its major exports; the country is a leading exporter of zinc, uranium, gold, nickel, aluminum, steel, iron ore, coking coal and lead.[188] Many towns in northern Canada, where agriculture is difficult, are sustainable because of nearby mines or sources of timber. Canada also has a sizeable manufacturing sector centred in southern Ontario and Quebec, with automobiles and aeronautics representing particularly important industries.[189]		Canada's economic integration with the United States has increased significantly since World War II.[190] The Automotive Products Trade Agreement of 1965 opened Canada's borders to trade in the automobile manufacturing industry.[191] In the 1970s, concerns over energy self-sufficiency and foreign ownership in the manufacturing sectors prompted Prime Minister Pierre Trudeau's Liberal government to enact the National Energy Program (NEP) and the Foreign Investment Review Agency (FIRA).[192] In the 1980s, Prime Minister Brian Mulroney's Progressive Conservatives abolished the NEP and changed the name of FIRA to Investment Canada, to encourage foreign investment.[193] The Canada – United States Free Trade Agreement (FTA) of 1988 eliminated tariffs between the two countries, while the North American Free Trade Agreement (NAFTA) expanded the free-trade zone to include Mexico in 1994.[187] In the mid-1990s, Jean Chrétien's Liberal government began to post annual budgetary surpluses, and steadily paid down the national debt.[194]		Adjusted for inflation, 2014		The global financial crisis of 2008 caused a major recession, which led to a significant rise in unemployment in Canada.[196] Canada's federal debt was estimated to total $566.7 billion for the fiscal year 2010–11, up from $463.7 billion in 2008–09.[197] In addition, Canada's net foreign debt rose by $41 billion to $194 billion in the first quarter of 2010.[198] However, Canada's regulated banking sector (comparatively conservative among G8 nations), the federal government's pre-crisis budgetary surpluses, and its long-term policies of lowering the national debt, resulted in a less severe recession compared to other G8 nations.[199] As of 2015[update], the Canadian economy has largely stabilized and has seen a modest return to growth, although the country remains troubled by volatile oil prices, sensitivity to the Eurozone crisis and higher-than-normal unemployment rates.[200][201] The federal government and many Canadian industries have also started to expand trade with emerging Asian markets, in an attempt to diversify exports; Asia is now Canada's second-largest export market after the United States.[202][203] Widely debated oil pipeline proposals, in particular, are hoped to increase exports of Canadian oil reserves to China.[204][205]		In 2015, Canada spent approximately C$31.6 billion on domestic research and development, of which around $7 billion was provided by the federal and provincial governments.[206] As of 2015[update], the country has produced thirteen Nobel laureates in physics, chemistry, and medicine,[207][208] and was ranked fourth worldwide for scientific research quality in a major 2012 survey of international scientists.[209] It is furthermore home to the headquarters of a number of global technology firms.[210] Canada has one of the highest levels of Internet access in the world, with over 33 million users, equivalent to around 94 percent of its total 2014 population.[211]		The Canadian Space Agency operates a highly active space program, conducting deep-space, planetary, and aviation research, and developing rockets and satellites.[212] Canada was the third country to design and construct a satellite after the Soviet Union and the United States, with the 1962 Alouette 1 launch.[213] Canada is a participant in the International Space Station (ISS), and is a pioneer in space robotics, having constructed the Canadarm, Canadarm2 and Dextre robotic manipulators for the ISS and NASA's Space Shuttle.[214] Since the 1960s, Canada's aerospace industry has designed and built numerous marques of satellite, including Radarsat-1 and 2, ISIS and MOST.[215] Canada has also produced one of the world's most successful and widely used sounding rockets, the Black Brant; over 1,000 Black Brants have been launched since the rocket's introduction in 1961.[216] In 1984, Marc Garneau became Canada's first male astronaut, followed by Canada's second and first female astronaut Roberta Bondar in 1992.[217]		The 2016 Canadian census enumerated a total population of 35,151,728, an increase of around 5.0 percent over the 2011 figure.[218][219] Between 2011 and May 2016, Canada's population grew by 1.7 million people with immigrants accounting for two-thirds of the increase.[220] Between 1990 and 2008, the population increased by 5.6 million, equivalent to 20.4 percent overall growth.[221] The main drivers of population growth are immigration and, to a lesser extent, natural growth.[222] Canada has one of the highest per-capita immigration rates in the world,[223] driven mainly by economic policy and, to a lesser extent, family reunification.[224][225] The Canadian public as-well as the major political parties support the current level of immigration.[224][226][227] In 2014, a total of 260,400 immigrants were admitted to Canada.[228] The Canadian government anticipated between 280,000 and 305,000 new permanent residents in the following years.[229] a similar number of immigrants as in recent years.[230] New immigrants settle mostly in major urban areas such as Toronto, Montreal and Vancouver.[231] Canada also accepts large numbers of refugees,[232] accounting for over 10 percent of annual global refugee resettlements.[233]		Canada's population density, at 3.7 inhabitants per square kilometre (9.6/sq mi), is among the lowest in the world.[235] Canada spans latitudinally from the 83rd parallel north to the 41st parallel north, and approximately 95% of the population is found south of the 55th parallel north.[236] About four-fifths of the population lives within 150 kilometres (93 mi) of the contiguous United States border.[237] The most densely populated part of the country, accounting for nearly 50 percent, is the Quebec City – Windsor Corridor, situated in Southern Quebec and Southern Ontario along the Great Lakes and the Saint Lawrence River.[234][236] An additional 30 percent live along the British Columbia Lower Mainland, and the Calgary–Edmonton Corridor in Alberta.[238]		In common with many other developed countries, Canada is experiencing a demographic shift towards an older population, with more retirees and fewer people of working age. In 2006, the average age was 39.5 years;[239] by 2011, it had risen to approximately 39.9 years.[240] As of 2013[update], the average life expectancy for Canadians is 81 years.[241] The majority of Canadians (69.9%) live in family households, 26.8% report living alone, and those living with unrelated persons reported at 3.7%.[242] The average size of a household in 2006 was 2.5 people.[242]		According to a 2012 report by the Organisation for Economic Co-operation and Development (OECD), Canada is one of the most educated countries in the world;[243] the country ranks first worldwide in the number of adults having tertiary education, with 51 percent of Canadian adults having attained at least an undergraduate college or university degree.[243] Canada spends about 5.3% of its GDP on education.[244] The country invests heavily in tertiary education (more than 20 000 USD per student).[245] As of 2014[update], 89 percent of adults aged 25 to 64 have earned the equivalent of a high-school degree, compared to an OECD average of 75 percent.[176]		Since the adoption of section 23 of the Constitution Act, 1982, education in both English and French has been available in most places across Canada.[246] Canadian provinces and territories are responsible for education provision.[247] The mandatory school age ranges between 5–7 to 16–18 years,[248] contributing to an adult literacy rate of 99 percent.[100] In 2002, 43 percent of Canadians aged 25 to 64 possessed a post-secondary education; for those aged 25 to 34, the rate of post-secondary education reached 51 percent.[249] The Programme for International Student Assessment indicates that Canadian students perform well above the OECD average, particularly in mathematics, science, and reading.[250][251]		Self-reported ethnic origins of Canadians (2011 census)[2]		According to the 2006 census, the country's largest self-reported ethnic origin is Canadian (accounting for 32% of the population), followed by English (21%), French (15.8%), Scottish (15.1%), Irish (13.9%), German (10.2%), Italian (4.6%), Chinese (4.3%), First Nations (4.0%), Ukrainian (3.9%), and Dutch (3.3%).[252] There are 600 recognized First Nations governments or bands, encompassing a total of 1,172,790 people.[253] Canada's indigenous population is growing at almost twice the national rate, and four percent of Canada's population claimed an indigenous identity in 2006. Another 16.2 percent of the population belonged to a non-indigenous visible minority.[254] In 2006, the largest visible minority groups were South Asian (4.0%), Chinese (3.9%) and Black (2.5%). Between 2001 and 2006, the visible minority population rose by 27.2 percent.[255] In 1961, less than two percent of Canada's population (about 300,000 people) were members of visible minority groups.[256] By 2007, almost one in five (19.8%) were foreign-born, with nearly 60 percent of new immigrants coming from Asia (including the Middle East).[257] The leading sources of immigrants to Canada were China, the Philippines and India.[258] According to Statistics Canada, visible minority groups could account for a third of the Canadian population by 2031.[259]		Canada is religiously diverse, encompassing a wide range of beliefs and customs. Canada has no official church, and the government is officially committed to religious pluralism.[260] Freedom of religion in Canada is a constitutionally protected right, allowing individuals to assemble and worship without limitation or interference.[261] The practice of religion is now generally considered a private matter throughout society and the state.[262] With Christianity in decline after having once been central and integral to Canadian culture and daily life,[263] Canada has become a post-Christian, secular state.[264][265][266][267] The majority of Canadians consider religion to be unimportant in their daily lives,[268] but still believe in God.[269] According to the 2011 census, 67.3% of Canadians identify as Christian; of these, Roman Catholics make up the largest group, accounting for 38.7% of the population. Much of the remainder is made up of Protestants, who accounted for approximately 27% in a 2011 survey.[270][271] The largest Protestant denomination is the United Church of Canada (accounting for 6.1% of Canadians), followed by Anglicans (5.0%), and Baptists (1.9%).[3] Secularization has been growing since the 1960s.[272][273] In 2011, 23.9% declared no religious affiliation, compared to 16.5% in 2001.[274] The remaining 8.8% are affiliated with non-Christian religions, the largest of which are Islam (3.2%) and Hinduism (1.5%).[3]		A multitude of languages are used by Canadians, with English and French (the official languages) being the mother tongues of approximately 60% and 20% of Canadians, respectively.[276] Nearly 6.8 million Canadians listed a non-official language as their mother tongue.[277] Some of the most common non-official first languages include Chinese (mainly Cantonese; 1,072,555 first-language speakers), Punjabi (430,705), Spanish (410,670), German (409,200), and Italian (407,490).[278] Canada's federal government practices official bilingualism, which is applied by the Commissioner of Official Languages in consonance with Section 16 of the Canadian Charter of Rights and Freedoms and the Federal Official Languages Act English and French have equal status in federal courts, parliament, and in all federal institutions. Citizens have the right, where there is sufficient demand, to receive federal government services in either English or French and official-language minorities are guaranteed their own schools in all provinces and territories.[279]		The 1977 Charter of the French Language established French as the official language of Quebec.[280] Although more than 85 percent of French-speaking Canadians live in Quebec, there are substantial Francophone populations in New Brunswick, Alberta, and Manitoba; Ontario has the largest French-speaking population outside Quebec.[281] New Brunswick, the only officially bilingual province, has a French-speaking Acadian minority constituting 33 percent of the population.[282] There are also clusters of Acadians in southwestern Nova Scotia, on Cape Breton Island, and through central and western Prince Edward Island.[283]		Other provinces have no official languages as such, but French is used as a language of instruction, in courts, and for other government services, in addition to English. Manitoba, Ontario, and Quebec allow for both English and French to be spoken in the provincial legislatures, and laws are enacted in both languages. In Ontario, French has some legal status, but is not fully co-official.[284] There are 11 indigenous language groups, composed of more than 65 distinct languages and dialects.[285] Of these, only the Cree, Inuktitut and Ojibway languages have a large enough population of fluent speakers to be considered viable to survive in the long term.[286] Several indigenous languages have official status in the Northwest Territories.[287] Inuktitut is the majority language in Nunavut, and is one of three official languages in the territory.[288]		Additionally, Canada is home to many sign languages, some of which are Indigenous.[289] American Sign Language (ASL) is spoken across the country due to the prevalence of ASL in primary and secondary schools.[290] Due to its historical relation to the francophone culture, Quebec Sign Language (LSQ) is spoken primarily in Quebec, although there are sizeable Francophone communities in New Brunswick, Ontario and Manitoba.[291]		Canada's culture draws influences from its broad range of constituent nationalities, and policies that promote a "just society" are constitutionally protected.[292][293] Canada has placed emphasis on equality and inclusiveness for all its people.[294] Multiculturalism is often cited as one of Canada's significant accomplishments,[295] and a key distinguishing element of Canadian identity.[296][297] In Quebec, cultural identity is strong, and many commentators speak of a culture of Quebec that is distinct from English Canadian culture.[298] However, as a whole, Canada is in theory a cultural mosaic—a collection of regional ethnic subcultures.[299]		Canada's approach to governance emphasizing multiculturalism, which is based on selective immigration, social integration, and suppression of far-right politics, has wide public support.[300] Government policies such as publicly funded health care, higher taxation to redistribute wealth, the outlawing of capital punishment, strong efforts to eliminate poverty, strict gun control, and the legalization of same-sex marriage are further social indicators of Canada's political and cultural values.[301][302] Canadians also identify with the country's health care institutions, peacekeeping, the National park system and the Canadian Charter of Rights and Freedoms.[296][303]		Historically, Canada has been influenced by British, French, and indigenous cultures and traditions. Through their language, art and music, Indigenous peoples continue to influence the Canadian identity.[304] During the 20th century, Canadians with African, Caribbean and Asian nationalities have added to the Canadian identity and its culture.[305] Canadian humour is an integral part of the Canadian identity and is reflected in its folklore, literature, music, art and media. The primary characteristics of Canadian humour are irony, parody, and satire.[306] Many Canadian comedians have archived international success in the American TV and film industries and are amongst the most recognized in the world.[307]		Canada has a well-developed media sector, but its cultural output; particularly in English films, television shows, and magazines, is often overshadowed by imports from the United States.[308] As a result, the preservation of a distinctly Canadian culture is supported by federal government programs, laws, and institutions such as the Canadian Broadcasting Corporation (CBC), the National Film Board of Canada (NFB), and the Canadian Radio-television and Telecommunications Commission (CRTC).[309]		Canada's national symbols are influenced by natural, historical, and indigenous sources. The use of the maple leaf as a Canadian symbol dates to the early 18th century. The maple leaf is depicted on Canada's current and previous flags, and on the Arms of Canada.[311] The Arms of Canada is closely modelled after the royal coat of arms of the United Kingdom with French and distinctive Canadian elements replacing or added to those derived from the British version.[312] The Great Seal of Canada is a governmental seal used for purposes of state, being set on letters patent, proclamations and commissions, for representatives of the Queen and for the appointment of cabinet ministers, lieutenant governors, senators, and judges.[313][314] Other prominent symbols include the beaver, Canada goose, and common loon, the Crown, the Royal Canadian Mounted Police,[311] and more recently the totem pole and Inuksuk.[315] Canadian coins feature many of these symbols: the loon on the $1 coin, the Arms of Canada on the 50¢ piece, the beaver on the nickel.[316] The penny, removed from circulation in 2013, featured the maple leaf.[317] The Queen' s image appears on $20 bank notes, and on the obverse of all current Canadian coins.[316]		Canadian literature is often divided into French- and English-language literatures, which are rooted in the literary traditions of France and Britain, respectively.[318] There are four major themes that can be found within historical Canadian literature; nature, frontier life, Canada's position within the world, all three of which tie into the garrison mentality.[319] By the 1990s, Canadian literature was viewed as some of the world's best.[320] Canada's ethnic and cultural diversity are reflected in its literature, with many of its most prominent modern writers focusing on ethnic life.[321] Arguably, the best-known living Canadian writer internationally (especially since the deaths of Robertson Davies and Mordecai Richler) is Margaret Atwood, a prolific novelist, poet, and literary critic.[322] Numerous other Canadian authors have accumulated international literary awards;[323] including Nobel Laureate Alice Munro, who has been called the best living writer of short stories in English;[324] and Booker Prize recipient Michael Ondaatje, who is perhaps best known for the novel The English Patient, which was adapted as a film of the same name that won the Academy Award for Best Picture.[325]		Canadian visual art has been dominated by figures such as Tom Thomson – the country's most famous painter – and by the Group of Seven.[326] Thomson's career painting Canadian landscapes spanned a decade up to his death in 1917 at age 39.[327] The Group were painters with a nationalistic and idealistic focus, who first exhibited their distinctive works in May 1920. Though referred to as having seven members, five artists—Lawren Harris, A. Y. Jackson, Arthur Lismer, J. E. H. MacDonald, and Frederick Varley—were responsible for articulating the Group's ideas. They were joined briefly by Frank Johnston, and by commercial artist Franklin Carmichael. A. J. Casson became part of the Group in 1926.[328] Associated with the Group was another prominent Canadian artist, Emily Carr, known for her landscapes and portrayals of the Indigenous peoples of the Pacific Northwest Coast.[329] Since the 1950s, works of Inuit art have been given as gifts to foreign dignitaries by the Canadian government.[330]		The Canadian music industry is the sixth-largest in the world producing internationally renowned composers, musicians and ensembles.[331] Music broadcasting in the country is regulated by the CRTC.[332] The Canadian Academy of Recording Arts and Sciences presents Canada's music industry awards, the Juno Awards, which were first awarded in 1970.[333] The Canadian Music Hall of Fame established in 1976 honours Canadian musicians for their lifetime achievements.[334] Patriotic music in Canada dates back over 200 years as a distinct category from British patriotism, preceding the first legal steps to independence by over 50 years. The earliest, The Bold Canadian, was written in 1812.[335] The national anthem of Canada, "O Canada", was originally commissioned by the Lieutenant Governor of Quebec, the Honourable Théodore Robitaille, for the 1880 St. Jean-Baptiste Day ceremony, and was officially adopted in 1980.[336] Calixa Lavallée wrote the music, which was a setting of a patriotic poem composed by the poet and judge Sir Adolphe-Basile Routhier. The text was originally only in French, before it was translated to English in 1906.[337]		The roots of organized sports in Canada date back to the 1770s.[338] Canada's official national sports are ice hockey and lacrosse.[339] Golf, tennis, skiing, badminton, volleyball, cycling, swimming, bowling, rugby union, canoeing, equestrian, squash and the study of martial arts are widely enjoyed at the youth and amateur levels.[340]		Canada shares several major professional sports leagues with the United States.[341] Canadian teams in these leagues include seven franchises in the National Hockey League, as well as three Major League Soccer teams and one team in each of Major League Baseball and the National Basketball Association. Other popular professional sports in Canada include Canadian football, which is played in the Canadian Football League, National Lacrosse League lacrosse, and curling.[342]		Canada has participated in almost every Olympic Games since its Olympic debut in 1900,[343] and has hosted several high-profile international sporting events, including the 1976 Summer Olympics in Montreal,[344] the 1988 Winter Olympics in Calgary,[345] the 1994 Basketball World Championship,[346] the 2007 FIFA U-20 World Cup,[347] the 2010 Winter Olympics in Vancouver,[348] and Whistler, British Columbia,[349] and the 2015 FIFA Women's World Cup.[350]		Overview		History		Geography and climate		Government and law		Social welfare		Foreign relations and military		Economy		Demography and statistics		Culture						
A beach tag (also beach badge or beach token) is an admission pass that must be purchased to access a beach. It is commonly associated with the New Jersey Shore. The system restricts summer beach access to residents and paying visitors. Visitors and residents in communities with the beach tag system typically pay a fee for a daily, weekly or seasonal pass. Staff patrol the beach looking for people who are not displaying their tag, and visitors without one are asked to purchase a tag or leave. Beaches with a beach-tag program use the proceeds to offset the maintenance and staffing costs associated with running a beach, such as funding lifeguards, restrooms, and trash removal.[1]						Daily, weekly, and seasonal tags are usually available at beaches,[1] and each municipality sets its own rates and policies. Beaches typically do not charge for children under the age of twelve and may offer discounts to seniors.[1] In certain municipalities, discounts are given for seasonal passes purchased before a specific date (e.g. May 15 in Seaside Heights, New Jersey[2]).		Beach tags are controversial because the public trust doctrine generally gives the public the right to access the intertidal zone,[3][4] and guests may feel that a beach with beach tags should offer a superior service to free beaches.[1] Detractors debate whether beach tags are actually to restrict beach use to people who are paying visitors of hotels, beach house rentals and local residents.[1] The beach tag offered by one municipality does not grant access to beaches in other municipalities because each town has its own rules. For example, Long Beach Island is about twenty miles long, but there are six municipalities, each with its own beach tags; beach-goers cannot purchase one tag and use it in a different municipality. [1] Proponents of beach tags suggest that they improve the cleanliness and safety of the beaches, making them akin to user fees that prevent freeloading.[5] In addition, proponents note that the beaches that require beach tags are those located in smaller cities, and beach tags allow small towns to offer a similar product to the larger centers.[1]		In Evanston, Illinois, "beach tokens" may be required for entrance to the beach for people and even pets.[6][7] The beach tokens are often made of metal or other durable material, to enable them to withstand swimming. The bearer may just carry them around their neck or on their swimsuit. The goals of beach tokens is to restrict the beach to only community members or to generate user fees for lifeguards and maintenance (e.g. trash removal).		
Over the past two decades, biogeomorphology has developed as an established research field examining the interrelationship between organisms and geomorphic processes in a variety of environments, both marine, and terrestrial (Naylor, Larissa A. 2005). Coastal biogeomorphology looks at the interaction between marine organisms, and coastal geomorphic processes (Reed, D.J. 2000). Biogeomorphology is a subdisclipline of Geomorphology.		This can include not only microorganisms and plants, but animals as well. These interactions are very important factors in the development of certain environments like salt marsh, mangrove and other types of coastal wetlands as well as influencing coastal and shoreline stability (Reed, D.J. 2000). There are three main processes related to biogeomorphology; bioerosion, bioprotection, and bioconstruction (Naylor, Larissa A. 2005). Bioerosion is the erosion of ocean substrates by living organisms. Bioprotection refers to the protection of substrate from various forms erosion by the presence of organisms, and the structures they create (i.e. coral reefs). Finally bioconstruction refers to the physical construction of biological structures on ocean substrate (Naylor, Larissa A. 2005). Marine biota interact with landform processes by building structures, accumulating carbonate sediments, accelerating erosion by boring or bioturbation, and marine plant life contribute to shoreline stability, especially in marsh and wetland environments (Bernal P., and P.M. Holligan 1992).		The interaction between marine biota and geologic processes is very important to shoreline stability, especially in soft sedimentary environments where sediments are more likely to erode away. Benthic, and planktonic organisms, as well as Shellfish filter, package, and even bind fine sediments together in tidal regions. This action reduces turbidity in the area by solidifying and protecting loose, soft sediments, and thus allowing for more colonization by other organisms. If disturbance of these soft sediments occurs, particularly through human interaction like shellfish harvesting, dredging, or the introduction of toxins the environment may drastically change. If this occurs, and marine biota are removed from the environment, erosion can occur, or increase, especially in regions prone to wave action and tidal resuspension (Bernal P., and P.M. Holligan 1992).		Bernal P., and P.M. Holligan (1992) . Marine and Coastal Systems. In J.C.I Dooge, Gordan Goodman, J.W.M. Riviere, Julia Marton-Lefevre, and Timothy O’Riordan (Ed.’s), An Agenda of Science for Environment and Development into the 21st Century (pp. 157-171). Cambridge, UK: Cambridge University Press.		Naylor, Larissa A. (2005) The contribution of biogeomorphology to the emerging field of geobiology. Palaeogeography, Palaeoclimatology, and Palaeoecology 219(1-2):35-51		Reed, D.J. (2000). Coastal biogeomorphology: an integrated approach to understanding the evolution, morphology, and sustainability of temperate coastal marshes, In J.E. Hobbie (Ed.), Estuarine science: a synthetic approach to research and practice (pp. 347-361) Washington, DC: Island Press		
Swimwear is clothing designed to be worn by people engaging in a water-based activity or water sports, such as swimming, diving and surfing, or sun-orientated activities, such as sun bathing. Different types may be worn by men, women, and children. Swimwear is described by a number of names, some of which are used only in particular locations, including swimsuit, bathing suit, swimming costume, bathing costume, swimming suit, swimmers, swimming togs, bathers, cossie (short for "costume"), or swimming trunks for men, besides others.		A swimsuit can be worn as an undergarment in sports that require a wetsuit such as water skiing, scuba diving, surfing, and wakeboarding. Swimsuits may also be worn to display the wearer's physical attributes, as in the case of beauty pageants or bodybuilding contests, and glamour photography and magazines like the annual Sports Illustrated Swimsuit Issue feature models and sports personalities in swimsuits.		There is a very wide range of styles of modern swimsuits available, which vary as to body coverage and materials. The choice of style may depend on community standards of modesty, as well as current fashions, and personal preferences. The choice will also consider the occasion, for example whether it is to be worn for a passive occasion such as sunbathing or for an activity such as surfing or competition. Swimwear for men usually exposes the chest, while suits for women usually cover at least the breasts.						Rayon was used in the 1920s in the manufacture of tight-fitting swimsuits,[1] but its durability, especially when wet, proved problematic,[2] with jersey and silk also sometimes being used.[3]		In the 1930s, new materials were being developed and use in swimwear, particularly latex and nylon, and swimsuits gradually began hugging the body,[4] especially women's swimsuits.		In western culture, men's swimsuit styles include boardshorts, jammers, swim trunks, briefs or "speedos", thongs, and g-strings, in order of decreasing lower body coverage, and Women's swimsuits include one-piece, bikinis, or thongs. While they go through many trends in pattern, length and cut there is not much modification to the original variety of suit. A recent innovation is the burqini, favored by some Muslim women, which covers the whole body and head (but not face) in a manner similar to a diver's wetsuit. These are an updated version of full-body swimwear, which has been available for centuries, but conforms with Islam's traditional emphasis on modest dress. In Egypt, the term "Sharia swimsuit" is used to describe full-body swimwear.[5]		One piece swimsuit covers the crotch and buttocks, available in stylistic variations and generally refers to a bikini bottom or thong worn alone without a top.		In other cultures (particularly the UK) the term 'trunks' is used to describe swim briefs, although it has been increasingly common for any men's swimwear to be generically described as 'trunks'.		Swimsuits can be skin-tight or loose-fitting. They are often lined with another layer of fabric if the outer fabric becomes transparent when wet.		Swimsuits range from designs that almost completely cover the body to designs that expose almost all of the body. The choice of swimsuit will depend on personal and community standards of modesty and on considerations such as how much or how little sun protection is desired, and prevailing fashions. Almost all swimsuits cover the genitals and pubic hair, while most except thongs or G-string cover much or all of the buttocks.[8]		Most swimsuits in western culture leave at least the head, shoulders, arms, and lower part of the leg (below the knee) exposed. Women's swimsuits generally cover at least the areola and bottom half of the breasts, but some are designed for the top part of the swimsuit to be removed. In many countries, young girls and sometimes women choose not to wear a swimsuit top, and this can vary with the occasion, location, age, etc.		Both men and women may sometimes wear swimsuits covering more of the body when swimming in cold water (see also wetsuit and dry suit). In colder temperatures, the swimwear is needed to conserve body heat and protect the body core from hypothermia.		Competitive swimwear generally refers to the swimsuit, clothing, equipment and accessories used in the aquatic sports of swimming, diving, synchronized swimming, triathlon and water polo.		Some swimsuits are designed specifically for swimming competitions where they may be constructed of a special low resistance fabric that reduces skin drag. For some kinds of swimming and diving, special bodysuits called "diveskins" are worn. These suits are made from spandex and provide little thermal protection, but they do protect the skin from stings and abrasion. Most competitive swimmers also wear special swimsuits including partial bodysuits, racerback styles, jammers and racing briefs to assist their glide through the water thus gaining a speed advantage.		Unlike regular swimsuits, which are designed mainly for the aesthetic appearances, swimsuits designed to be worn during competitions are manufactured to assist the athlete in swim competitions. They reduce friction and drag in the water, increasing the efficiency of the swimmer's forward motion. The tight fits allow for easy movement and are said to reduce muscle vibration,[9] thus reducing drag. This also reduces the possibility that a high forwards dive will remove a divers swimwear. Starting around 2000, in an effort to improve the effectiveness of the swimsuits, engineers have taken to designing them to replicate the skin of sea based animals, sharks in particular.		In July 2009, FINA voted to ban non-textile (non-woven) swimsuits in competitive events from 2010. The new policy was implemented to combat the issues associated with performance enhancing swimsuits, hindering the ability to accurately measure the performance of swimmers. Subsequently, the new ruling states that men's swimsuits may maximally cover the area from the navel to the knee, and women's' counterparts from the shoulder to the knee.[10][11]		Some swimmers use a specialized training suit called drag suits to artificially increase drag during practice. Drag suits are swimwear with an outer layer of looser fabric – often mesh or nylon – to increase resistance against the water and build up the swimmer's endurance. They come in a variety of styles, but most resemble a looser fitting square-cut or swim brief.				Germs, bacteria, and mold can grow very quickly on wet bathing suits. Medical professionals warn that wearing damp swimwear for long periods of time can cause a number of infections and rashes in children and adults, and warn against sharing bathing suits with others.[12][13] They suggest that changing out of a wet bathing suit right away can help prevent vaginal infections and itching in females[14][15] and Tinea Cruris ("Jock Itch") in males.[16]		In public swimming pools in France for reasons of hygiene, it is only permitted to wear closer fitting styles of swimwear. Men, for instance, must wear "Speedo" style bathing suits and not baggy shorts or trunks.[17]		In classical antiquity swimming and bathing were done naked. There are Roman murals which show women playing sports and exercising wearing two-piece suits covering the areas around their breasts and hips in a fashion remarkably similar to the present-day bikini. However, there is no evidence that they were used for swimming. All classical pictures of swimming show nude swimmers.		In various cultural traditions one swims, if not in the nude, in a version in suitable material of a garment or undergarment commonly worn on land, e.g. a loincloth such as the Japanese man's fundoshi.		In the United Kingdom until the mid-19th century there was no law against nude swimming, and each town was free to make its own laws. For example, the Bath Corporation official bathing dress code of 1737 prescribed, for men:		It is Ordered Established and Decreed by this Corporation that no Male person above the age of ten years shall at any time hereafter go into any Bath or Baths within this City by day or by night without a Pair of Drawers and a Waistcoat on their bodies.[18]		In rivers, lakes, streams and the sea men swam in the nude, where the practice was common. Those who didn't swim in the nude, stripped to their underwear. The English practice of men swimming in the nude was banned in the United Kingdom in 1860. Drawers, or caleçons as they were called, came into use in the 1860s. Even then there were many who protested against them and wanted to remain in the nude. Francis Kilvert described men's bathing suits coming into use in the 1870s as "a pair of very short red and white striped drawers".[19]		Female bathing costumes were derived from those worn at Bath and other spas. It would appear that until the 1670s nude female bathing in the spas was the norm and that after that time women bathed clothed. Celia Fiennes gave a detailed description of the standard ladies' bathing costume in 1687:		The Ladyes go into the bath with Garments made of a fine yellow canvas, which is stiff and made large with great sleeves like a parson’s gown; the water fills it up so that it is borne off that your shape is not seen, it does not cling close as other linning, which Lookes sadly in the poorer sort that go in their own linning. The Gentlemen have drawers and wastcoates of the same sort of canvas, this is the best linning, for the bath water will Change any other yellow.[20]		The Bath Corporation official bathing dress code of 1737 prescribed, for women:		No Female person shall at any time hereafter go into a Bath or Baths within this City by day or by night without a decent Shift on their bodies.[18]		The Expedition of Humphrey Clinker was published in 1771 and its description of ladies’ bathing costume is different from that of Celia Fiennes a hundred years earlier:		The ladies wear jackets and petticoats of brown linen, with chip hats, in which they fix their handkerchiefs to wipe the sweat from their faces; but, truly, whether it is owing to the steam that surrounds them, or the heat of the water, or the nature of the dress, or to all these causes together, they look so flushed, and so frightful, that I always turn my eyes another way.[21]		Penelope Byrde points out that Smollett’s description may not be accurate, for he describes a two-piece costume, not the one piece shift or smock that most people describe and is depicted in contemporary prints. His description does, however, tally with Elizabeth Grant’s description of the guide’s costume at Ramsgate in 1811. The only difference is in the fabric the costumes are made of. Flannel, however, was a common fabric for sea bathing costumes as many believed the warmer fabric was necessary in cold water.[22]		In the 18th century women wore "bathing gowns" in the water; these were long dresses of fabrics that would not become transparent when wet, with weights sewn into the hems so that they would not rise up in the water. The men's swim suit, a rather form-fitting wool garment with long sleeves and legs similar to long underwear, was developed and would change little for a century.		In the 19th century, the woman's double suit was common, comprising a gown from shoulder to knees plus a set of trousers with leggings going down to the ankles.		In the Victorian era, popular beach resorts were commonly equipped with bathing machines designed to avoid the exposure of people in swimsuits, especially to people of the opposite sex.		In the United States, beauty pageants of women in bathing costumes became popular from the 1880s. However, such events were not regarded as respectable. Beauty contests became more respectable with the first modern "Miss America" contest held in 1921, though less respectable beauty contests continued to be held.		1870s bathing dress		Bathing suit, ca 1885		Bathing suit, 1890-1895		In 1907, the swimmer Annette Kellerman from Australia visited the United States as an "underwater ballerina", a version of synchronized swimming involving diving into glass tanks. She was arrested for indecent exposure because her swimsuit showed arms, legs and the neck. Kellerman changed the suit to have long arms and legs and a collar, still keeping the close fit that revealed the shapes underneath. She later starred in several movies, including one about her life. She marketed a line of bathing suits and her style of one-piece suits came to be known as "the Annette Kellerman". The Annette Kellerman was considered the most offensive style of swimsuit in the 1920s and became the focus of censorship efforts.[23][24]		Despite opposition from some groups, the form-fitting style proved popular. It was not long before swimwear started to shrink further. At first arms were exposed and then legs up to mid-thigh. Necklines receded from around the neck down to around the top of the bosom. The development of new fabrics allowed for new varieties of more comfortable and practical swimwear.[25]		Annette Kellerman in her one-piece bathing suit		Cotton jersey bathing suit ca.1910s		Jantzen Helanca knitted nylon swimsuit ca.1955-1965		JAG High cut, zippered swimsuit ca.1985-1995		Due to the figure-hugging nature of these garments, glamour photography since the 1940s and 1950s has often featured people wearing swimsuits. This type of glamour photography eventually evolved into swimsuit photography exemplified by the annual Sports Illustrated Swimsuit Issue. Beauty contests also required contestants to wear form-fitting swimsuits.		The first bikinis appeared just after World War II. Early examples were not very different from the women's two pieces common since the 1920s, except that they had a gap below the breast line allowing for a section of bare midriff. They were named after Bikini Atoll, the site of several nuclear weapons tests, for their supposed explosive effect on the viewer.		Through the 1950s, it was thought proper for the lower part of the bikini to come up high enough to cover the navel. From the 1960s on, the bikini shrank in all directions until it sometimes covered little more than the nipples and genitalia, although less revealing models giving more support to the breasts remained popular. At the same time, fashion designer Rudi Gernreich introduced the monokini, a topless suit for women consisting of a modest bottom supported by two thin straps. Although not a commercial success, the suit opened eyes to new design possibilities. In the 1980s the thong or "tanga" came out of Brazil, said to have been inspired by traditional garments of native tribes in the Amazon. However, the one-piece suit continued to be popular for its more modest approach.		Men's swimsuits developed roughly in parallel to women's during this period, with the shorts covering progressively less. Eventually racing-style "speedo" suits became popular—and not just for their speed advantages. Thongs, G-strings, and bikini style suits are also worn. Typically these are more popular in more tropical regions; however, they may also be worn at public swimming pools and inland lakes. But in the 1990s, longer and baggier shorts became popular, with the hems often reaching to the knees. Often called boardshorts and swim trunks, these were often worn lower on the hips than regular shorts.		Since the early twentieth century a naturist movement has developed in western countries that seeks a return to non-sexual nakedness when swimming and during other appropriate activities.[26] Some women prefer to engage in water or sun activities with their torso uncovered. The practice is often described as "toplessness" or "topfreedom". In some places around the world, nude beaches have been set aside for people who choose to engage in normal beach activities in the nude.		As an alternative to a swimsuit, some people wear trousers, underpants or a T-shirt either as a makeshift swimsuit or because they prefer regular clothes over swimsuits. Using a T-shirt can also provide extra protection against sunburn. In some countries, such as Thailand and Philippines, swimming in regular clothes is the norm while swimsuits are rare. At beaches, this may be more accepted than at swimming pools, which tend not to permit the use of underwear as swimwear[27] because underwear is unlined, may become translucent, and may be perceived as unclean.		
Gravel /ˈɡrævəl/ is a loose aggregation of rock fragments. Gravel is classified by particle size range and includes size classes from granule- to boulder-sized fragments. In the Udden-Wentworth scale gravel is categorized into granular gravel (2 to 4 mm or 0.079 to 0.157 in) and pebble gravel (4 to 64 mm or 0.2 to 2.5 in). One cubic metre of gravel typically weighs about 1,800 kg (or a cubic yard weighs about 3,000 pounds).		Gravel is an important commercial product, with a number of applications. Many roadways are surfaced with gravel, especially in rural areas where there is little traffic. Globally, far more roads are surfaced with gravel than with concrete or tarmac; Russia alone has over 400,000 km (250,000 mi) of gravel roads.[1] Both sand and small gravel are also important for the manufacture of concrete.						Large gravel deposits are a common geological feature, being formed as a result of the weathering and erosion of rocks. The action of rivers and waves tends to pile up gravel in large accumulations. This can sometimes result in gravel becoming compacted and concreted into the sedimentary rock called conglomerate. Where natural gravel deposits are insufficient for human purposes, gravel is often produced by quarrying and crushing hard-wearing rocks, such as sandstone, limestone, or basalt. Quarries where gravel is extracted are known as gravel pits. Southern England possesses particularly large concentrations of them due to the widespread deposition of gravel in the region during the Ice Ages.		As of 2006, the United States is the world's leading producer and consumer of gravel.[2][3]		The word gravel comes from the Breton language. In Breton, "grav" means coast. Adding the "-el" suffix in Breton denotes the component parts of something larger. Thus "gravel" means the small stones which make up such a beach on the coast. Many dictionaries ignore the Breton language, citing Old French gravele[4] or gravelle.[5]		Gravel often has the meaning a mixture of different size pieces of stone mixed with sand and possibly some clay. In American English, small stones without sand mixed in are known as crushed stone.[6][7]		Types of gravel include:		In locales where gravelly soil is predominant, plant life is generally more sparse.[9] This outcome derives from the inferior ability of gravels to retain moisture, as well as the corresponding paucity of mineral nutrients, since finer soils that contain such minerals are present in smaller amounts.		Media related to Gravel at Wikimedia Commons		
In geography, a cape is a headland or a promontory of large size extending into a body of water, usually the sea.[1] A cape usually represents a marked change in trend of the coastline. Their proximity to the coastline makes them prone to natural forms of erosion, mainly tidal actions. This results in capes having a relatively short geologic lifespan. Capes can be formed by glaciers, volcanoes, and changes in sea level. Erosion plays a large role in each of these methods of formation.[citation needed]		
In chemistry, a suspension is a heterogeneous mixture containing solid particles that are sufficiently large for sedimentation. Usually they must be larger than one micrometer. A suspension is a heterogeneous mixture in which the solute particles do not dissolve but get suspended throughout the bulk of the medium. Particles of suspension are visible to the naked eye. It is when particles are left floating around freely in a solvent.[1] The internal phase (solid) is dispersed throughout the external phase (fluid) through mechanical agitation, with the use of certain excipients or suspending agents. Unlike colloids, suspensions will eventually settle. An example of a suspension would be sand in water. The suspended particles are visible under a microscope and will settle over time if left undisturbed. This distinguishes a suspension from a colloid, in which the suspended particles are smaller and do not settle.[2] Colloids and suspensions are different from solutions, in which the dissolved substance (solute) does not exist as a solid, and solvent and solute are homogeneously mixed.		A suspension of liquid droplets or fine solid particles in a gas is called an aerosol or particulate. In the atmosphere these consist of fine dust and soot particles, sea salt, biogenic and volcanogenic sulfates, nitrates, and cloud droplets.		Suspensions are classified on the basis of the dispersed phase and the dispersion medium, where the former is essentially solid while the latter may either be a solid, a liquid, or a gas.		In modern chemical process industries, high-shear mixing technology has been used to create many novel suspensions.		Suspensions are unstable from the thermodynamic point of view; however, they can be kinetically stable over a large period of time, which determines their shelf life. This time span needs to be measured to ensure the best product quality to the final consumer. "Dispersion stability refers to the ability of a dispersion to resist change in its properties over time."[3]		Note: Definition based on that in ref.[4]						Multiple light scattering coupled with vertical scanning is the most widely used technique to monitor the dispersion state of a product, hence identifying and quantifying destabilization phenomena.[6][7][8][9] It works on concentrated dispersions without dilution. When light is sent through the sample, it is back scattered by the particles. The backscattering intensity is directly proportional to the size and volume fraction of the dispersed phase. Therefore, local changes in concentration (sedimentation) and global changes in size (flocculation, aggregation) are detected and monitored.		The kinetic process of destabilisation can be rather long (up to several months or even years for some products) and it is often required for the formulator to use further accelerating methods in order to reach reasonable development time for new product design. Thermal methods are the most commonly used and consists in increasing temperature to accelerate destabilisation (below critical temperatures of phase and degradation). Temperature affects not only the viscosity, but also interfacial tension in the case of non-ionic surfactants or more generally interactions forces inside the system. Storing a dispersion at high temperatures enables simulation of real life conditions for a product (e.g. tube of sunscreen cream in a car in the summer), but also to accelerate destabilisation processes up to 200 times including vibration, centrifugation and agitation are sometimes used. They subject the product to different forces that pushes the particles / film drainage. However, some emulsions would never coalesce in normal gravity, while they do under artificial gravity.[10] Moreover, segregation of different populations of particles have been highlighted when using centrifugation and vibration.[11] Common examples of suspensions include:		
Beach polo is a team sport and close variant of arena polo.						A game of beach polo consists of two three-player teams as opposed to the usual four-player teams in field polo. A game consists of four seven-minute periods of play, called chukkers. The game is played in an enclosed sand arena with sideboards of approximately four feet in height, designed to keep the ball in play. Depending on playing areas available, some of the playing arenas have enclosed ends while others allow for 20 yards of run out room for the horses, past the end line, and utilize standing goal posts.		Two umpires are suggested for tournament play which may be stationed outside the arena to officiate the game. Penalties are called and resulting free hits are awarded to the fouled party.		Traditional polo ponies are used with players changing horses following each chukker.		Unlike the hard plastic ball used in field polo, beach polo employs a leather or rubber inflated ball no less than 12.5 inches in circumference. Other equipment employed is the same as that used in field or arena polo.		Dubai's Rashid Al Habtoor and Sam Katiela have been credited[by whom?] with the creation of the game in 2004, followed by the Miami Beach Polo World Cup in the United States in 2005. Additional tournaments and matches have arisen in Argentina, Australia, Austria, Belgium, Chile, China, Colombia, Croatia, England,[1] France, Germany, India, Italy, Mexico, New Zealand, Poland, Spain, Thailand, The Netherlands, Uruguay and Wales.		Tournament competition ranges from entry level in Austria (on Lake Worthersee in Carinthia, Austria) to Miami Beach's higher-handicaped team play. International polo players include Argentine 10-goaler Gonzalo Pieres, Mexico's Carlos Gracida (9), USA 9-goaler Mike Azzaro and Australian 8-goaler Ruki Baillieu.		In 2008, the International Beach Polo Association was created, by current Chairman Alex Webbe, in an effort to increase the number of participating countries, to assist in promoting these events and to make rules and handicaps for the game more uniform.		In 2009 the Miami Beach Polo Club held the first South Beach Women's Polo Cup, a competition that fielded eight teams of women from six different countries. Following the 2010 AMG Miami Beach Polo World Cup, Matias Magrini (Argentina) became the first player elevated to a 10-goal handicap in the history of beach polo play.		The island of Jersey (off the coast of Normandy, France) staged its first beach polo tournament in September 2012 while New Zealand planned staged a tournament in December 2013, and Croatia created their first beach polo event in 2016.				
An inlet is an indentation of a shoreline, usually long and narrow, such as a small bay or arm,[1] that often leads to an enclosed body of salt water, such as a sound, bay, lagoon, or marsh.						In sea coasts, an inlet usually refers to the actual connection between a bay and the ocean and is often called an "entrance" or a recession in the shore of a sea, lake, or river. A certain kind of inlet created by glaciation is a fjord, typically but not always in mountainous coastlines and also in montane lakes.		Complexes of large inlets or fjords may be called sounds, e.g., Puget Sound, Howe Sound, Karmsund (sund is Scandinavian for "sound"). Some fjord-type inlets are called canals, e.g., Portland Canal, Lynn Canal, Hood Canal, and some are channels, e.g., Dean Channel and Douglas Channel.		Tidal amplitude, wave intensity, and wave direction are all factors that influence sediment flux in inlets[2]		
The International Standard Book Number (ISBN) is a unique[a][b] numeric commercial book identifier.		An ISBN is assigned to each edition and variation (except reprintings) of a book. For example, an e-book, a paperback and a hardcover edition of the same book would each have a different ISBN. The ISBN is 13 digits long if assigned on or after 1 January 2007, and 10 digits long if assigned before 2007. The method of assigning an ISBN is nation-based and varies from country to country, often depending on how large the publishing industry is within a country.		The initial ISBN configuration of recognition was generated in 1967 based upon the 9-digit Standard Book Numbering (SBN) created in 1966. The 10-digit ISBN format was developed by the International Organization for Standardization (ISO) and was published in 1970 as international standard ISO 2108 (the SBN code can be converted to a ten digit ISBN by prefixing it with a zero).		Occasionally, a book may appear without a printed ISBN if it is printed privately or the author does not follow the usual ISBN procedure; however, this can be rectified later.[1]		Another identifier, the International Standard Serial Number (ISSN), identifies periodical publications such as magazines; and the International Standard Music Number (ISMN) covers for musical scores.						The Standard Book Numbering (SBN) code is a 9-digit commercial book identifier system created by Gordon Foster, Emeritus Professor of Statistics at Trinity College, Dublin,[2] for the booksellers and stationers WHSmith and others in 1965.[3] The ISBN configuration of recognition was generated in 1967 in the United Kingdom by David Whitaker[4] (regarded as the "Father of the ISBN"[5]) and in 1968 in the US by Emery Koltay[4] (who later became director of the U.S. ISBN agency R.R. Bowker).[5][6][7]		The 10-digit ISBN format was developed by the International Organization for Standardization (ISO) and was published in 1970 as international standard ISO 2108.[3][4] The United Kingdom continued to use the 9-digit SBN code until 1974. ISO has appointed the International ISBN Agency as the registration authority for ISBN worldwide and the ISBN Standard is developed under the control of ISO Technical Committee 46/Subcommittee 9 TC 46/SC 9. The ISO on-line facility only refers back to 1978.[8]		An SBN may be converted to an ISBN by prefixing the digit "0". For example, the second edition of Mr. J. G. Reeder Returns, published by Hodder in 1965, has "SBN 340 01381 8" – 340 indicating the publisher, 01381 their serial number, and 8 being the check digit. This can be converted to ISBN 0-340-01381-8; the check digit does not need to be re-calculated.		Since 1 January 2007, ISBNs have contained 13 digits, a format that is compatible with "Bookland" European Article Number EAN-13s.[9]		An ISBN is assigned to each edition and variation (except reprintings) of a book. For example, an ebook, a paperback, and a hardcover edition of the same book would each have a different ISBN.[10] The ISBN is 13 digits long if assigned on or after 1 January 2007, and 10 digits long if assigned before 2007. An International Standard Book Number consists of 4 parts (if it is a 10 digit ISBN) or 5 parts (for a 13 digit ISBN):		A 13-digit ISBN can be separated into its parts (prefix element, registration group, registrant, publication and check digit), and when this is done it is customary to separate the parts with hyphens or spaces. Separating the parts (registration group, registrant, publication and check digit) of a 10-digit ISBN is also done with either hyphens or spaces. Figuring out how to correctly separate a given ISBN number is complicated, because most of the parts do not use a fixed number of digits.[13]		ISBN issuance is country-specific, in that ISBNs are issued by the ISBN registration agency that is responsible for that country or territory regardless of the publication language. The ranges of ISBNs assigned to any particular country are based on the publishing profile of the country concerned, and so the ranges will vary depending on the number of books and the number, type, and size of publishers that are active. Some ISBN registration agencies are based in national libraries or within ministries of culture and thus may receive direct funding from government to support their services. In other cases, the ISBN registration service is provided by organisations such as bibliographic data providers that are not government funded. In Canada, ISBNs are issued at no cost with the stated purpose of encouraging Canadian culture.[14] In the United Kingdom, United States, and some other countries, where the service is provided by non-government-funded organisations, the issuing of ISBNs requires payment of a fee.		Australia: ISBNs are issued by the commercial library services agency Thorpe-Bowker,[15] and prices range from $42 for a single ISBN (plus a $55 registration fee for new publishers) to $2,890 for a block of 1,000 ISBNs. Access is immediate when requested via their website.[16]		Brazil: National Library of Brazil, a government agency, is responsible for issuing ISBNs, and there is a cost of R$16 [17]		Canada: Library and Archives Canada, a government agency, is responsible for issuing ISBNs, and there is no cost. Works in French are issued an ISBN by the Bibliothèque et Archives nationales du Québec.		Colombia: Cámara Colombiana del Libro, a NGO, is responsible for issuing ISBNs. Cost of issuing an ISBN is about USD 20.		Hong Kong: The Books Registration Office (BRO), under the Hong Kong Public Libraries, issues ISBNs in Hong Kong. There is no fee.[18]		India: The Raja Rammohun Roy National Agency for ISBN (Book Promotion and Copyright Division), under Department of Higher Education, a constituent of the Ministry of Human Resource Development, is responsible for registration of Indian publishers, authors, universities, institutions, and government departments that are responsible for publishing books.[19] There is no fee associated in getting ISBN in India.[20]		Italy: The privately held company EDISER srl, owned by Associazione Italiana Editori (Italian Publishers Association) is responsible for issuing ISBNs.[21] The original national prefix 978-88 is reserved for publishing companies, starting at €49 for a ten-codes block[22] while a new prefix 979-12 is dedicated to self-publishing authors, at a fixed price of €25 for a single code.		Maldives: The National Bureau of Classification (NBC) is responsible for ISBN registrations for publishers who are publishing in the Maldives.[citation needed]		Malta: The National Book Council (Maltese: Il-Kunsill Nazzjonali tal-Ktieb) issues ISBN registrations in Malta.[23][24][25]		Morocco: The National Library of Morocco is responsible for ISBN registrations for publishing in Morocco and Moroccan-occupied portion of Western Sahara.		New Zealand: The National Library of New Zealand is responsible for ISBN registrations for publishers who are publishing in New Zealand.[26]		Pakistan: The National Library of Pakistan is responsible for ISBN registrations for Pakistani publishers, authors, universities, institutions, and government departments that are responsible for publishing books.		South Africa: The National Library of South Africa is responsible for ISBN issuance for South African publishing institutions and authors.		United Kingdom and Republic of Ireland: The privately held company Nielsen Book Services Ltd, part of Nielsen Holdings N.V., is responsible for issuing ISBNs in blocks of 10, 100 or 1000. Prices start from £120 (plus VAT) for the smallest block on a standard turnaround of ten days.[27]		United States: In the United States, the privately held company R.R. Bowker issues ISBNs.[4] There is a charge that varies depending upon the number of ISBNs purchased, with prices starting at $125.00 for a single number. Access is immediate when requested via their website.[28]		Publishers and authors in other countries obtain ISBNs from their respective national ISBN registration agency. A directory of ISBN agencies is available on the International ISBN Agency website.		The registration group identifier is a 1- to 5-digit number that is valid within a single prefix element (i.e. one of 978 or 979).[11] Registration group identifiers have primarily been allocated within the 978 prefix element.[29] The single-digit group identifiers within the 978 prefix element are: 0 or 1 for English-speaking countries; 2 for French-speaking countries; 3 for German-speaking countries; 4 for Japan; 5 for Russian-speaking countries; and 7 for People's Republic of China. An example 5-digit group identifier is 99936, for Bhutan. The allocated group IDs are: 0–5, 600–621, 7, 80–94, 950–989, 9926–9989, and 99901–99976.[30] Books published in rare languages typically have longer group identifiers.[31]		Within the 979 prefix element, the registration group identifier 0 is reserved for compatibility with International Standard Music Numbers (ISMNs), but such material is not actually assigned an ISBN.[11] The registration group identifiers within prefix element 979 that have been assigned are 10 for France, 11 for the Republic of Korea, and 12 for Italy.[32]		The original 9-digit standard book number (SBN) had no registration group identifier, but prefixing a zero (0) to a 9-digit SBN creates a valid 10-digit ISBN.		The national ISBN agency assigns the registrant element (cf. Category:ISBN agencies) and an accompanying series of ISBNs within that registrant element to the publisher; the publisher then allocates one of the ISBNs to each of its books. In most countries, a book publisher is not required by law to assign an ISBN; however, most bookstores only handle ISBN bearing publications.[citation needed]		A listing of more than 900,000 assigned publisher codes is published, and can be ordered in book form (€1399, US$1959). The web site of the ISBN agency does not offer any free method of looking up publisher codes.[33] Partial lists have been compiled (from library catalogs) for the English-language groups: identifier 0 and identifier 1.		Publishers receive blocks of ISBNs, with larger blocks allotted to publishers expecting to need them; a small publisher may receive ISBNs of one or more digits for the registration group identifier, several digits for the registrant, and a single digit for the publication element. Once that block of ISBNs is used, the publisher may receive another block of ISBNs, with a different registrant element. Consequently, a publisher may have different allotted registrant elements. There also may be more than one registration group identifier used in a country. This might occur once all the registrant elements from a particular registration group have been allocated to publishers.		By using variable block lengths, registration agencies are able to customise the allocations of ISBNs that they make to publishers. For example, a large publisher may be given a block of ISBNs where fewer digits are allocated for the registrant element and many digits are allocated for the publication element; likewise, countries publishing many titles have few allocated digits for the registration group identifier and many for the registrant and publication elements.[34] Here are some sample ISBN-10 codes, illustrating block length variations.		English-language registration group elements are 0 and 1 (2 of more than 220 registration group elements). These two registration group elements are divided into registrant elements in a systematic pattern, which allows their length to be determined, as follows:[35]		A check digit is a form of redundancy check used for error detection, the decimal equivalent of a binary check bit. It consists of a single digit computed from the other digits in the number. The method for the ten digit code is an extension of that for SBNs, the two systems are compatible, and SBN prefixed with "0" will give the same check-digit as without – the digit is base eleven, and can be 0-9 or X. The system for thirteen digit codes is not compatible and will, in general, give a different check digit from the corresponding 10 digit ISBN, and does not provide the same protection against transposition. This is because the thirteen digit code was required to be compatible with the EAN format, and hence could not contain an "X".		The 2001 edition of the official manual of the International ISBN Agency says that the ISBN-10 check digit[36] – which is the last digit of the ten-digit ISBN – must range from 0 to 10 (the symbol X is used for 10), and must be such that the sum of all the ten digits, each multiplied by its (integer) weight, descending from 10 to 1, is a multiple of 11.		For example, for an ISBN-10 of 0-306-40615-2:		Formally, using modular arithmetic, we can say:		It is also true for ISBN-10's that the sum of all the ten digits, each multiplied by its weight in ascending order from 1 to 10, is a multiple of 11. For this example:		Formally, we can say:		The two most common errors in handling an ISBN (e.g., typing or writing it) are a single altered digit or the transposition of adjacent digits. It can be proved that all possible valid ISBN-10's have at least two digits different from each other. It can also be proved that there are no pairs of valid ISBN-10's with eight identical digits and two transposed digits. (These are true only because the ISBN is less than 11 digits long, and because 11 is a prime number.) The ISBN check digit method therefore ensures that it will always be possible to detect these two most common types of error, i.e. if either of these types of error has occurred, the result will never be a valid ISBN – the sum of the digits multiplied by their weights will never be a multiple of 11. However, if the error occurs in the publishing house and goes undetected, the book will be issued with an invalid ISBN.[37]		In contrast, it is possible for other types of error, such as two altered non-transposed digits, or three altered digits, to result in a valid ISBN number (although it is still unlikely).		Modular arithmetic is convenient for calculating the check digit using modulus 11. Each of the first nine digits of the ten-digit ISBN—excluding the check digit itself—is multiplied by a number in a sequence from 10 to 2, and the remainder of the sum, with respect to 11, is computed. The resulting remainder, plus the check digit, must equal a multiple of 11 (either 0 or 11). Therefore, the check digit is (11 minus the remainder of the sum of the products modulo 11) modulo 11. Taking the remainder modulo 11 a second time accounts for the possibility that the first remainder is 0. Without the second modulo operation the calculation could end up with 11 – 0 = 11 which is invalid. (Strictly speaking the first "modulo 11" is unneeded, but it may be considered to simplify the calculation.)		For example, the check digit for an ISBN-10 of 0-306-40615-? is calculated as follows:		Thus the check digit is 2, and the complete sequence is ISBN 0-306-40615-2. The value x 10 {\displaystyle x_{10}} required to satisfy this condition might be 10; if so, an 'X' should be used.		It is possible to avoid the multiplications in a software implementation by using two accumulators. Repeatedly adding t into s computes the necessary multiples:		The modular reduction can be done once at the end, as shown above (in which case s could hold a value as large as 496, for the invalid ISBN 99999-999-9-X), or s and t could be reduced by a conditional subtract after each addition.		The 2005 edition of the International ISBN Agency's official manual[38] describes how the 13-digit ISBN check digit is calculated. The ISBN-13 check digit, which is the last digit of the ISBN, must range from 0 to 9 and must be such that the sum of all the thirteen digits, each multiplied by its (integer) weight, alternating between 1 and 3, is a multiple of 10.		Formally, using modular arithmetic, we can say:		The calculation of an ISBN-13 check digit begins with the first 12 digits of the thirteen-digit ISBN (thus excluding the check digit itself). Each digit, from left to right, is alternately multiplied by 1 or 3, then those products are summed modulo 10 to give a value ranging from 0 to 9. Subtracted from 10, that leaves a result from 1 to 10. A zero (0) replaces a ten (10), so, in all cases, a single check digit results.		For example, the ISBN-13 check digit of 978-0-306-40615-? is calculated as follows:		Thus, the check digit is 7, and the complete sequence is ISBN 978-0-306-40615-7.		In general, the ISBN-13 check digit is calculated as follows.		Let		Then		This check system – similar to the UPC check digit formula – does not catch all errors of adjacent digit transposition. Specifically, if the difference between two adjacent digits is 5, the check digit will not catch their transposition. For instance, the above example allows this situation with the 6 followed by a 1. The correct order contributes 3×6+1×1 = 19 to the sum; while, if the digits are transposed (1 followed by a 6), the contribution of those two digits will be 3×1+1×6 = 9. However, 19 and 9 are congruent modulo 10, and so produce the same, final result: both ISBNs will have a check digit of 7. The ISBN-10 formula uses the prime modulus 11 which avoids this blind spot, but requires more than the digits 0-9 to express the check digit.		Additionally, if the sum of the 2nd, 4th, 6th, 8th, 10th, and 12th digits is tripled then added to the remaining digits (1st, 3rd, 5th, 7th, 9th, 11th, and 13th), the total will always be divisible by 10 (i.e., end in 0).		The conversion is quite simple as one only needs to prefix "978" to the existing number and calculate the new checksum using the ISBN-13 algorithm.		Publishers and libraries have varied policies about the use of the ISBN check digit. Publishers sometimes fail to check the correspondence of a book title and its ISBN before publishing it; that failure causes book identification problems for libraries, booksellers, and readers.[39] For example, ISBN 0-590-76484-5 is shared by two books – Ninja gaiden® : a novel based on the best-selling game by Tecmo (1990) and Wacky Laws (1997), both published by Scholastic.		Most libraries and booksellers display the book record for an invalid ISBN issued by the publisher. The Library of Congress catalogue contains books published with invalid ISBNs, which it usually tags with the phrase "Cancelled ISBN".[40] However, book-ordering systems such as Amazon.com will not search for a book if an invalid ISBN is entered to its search engine.[citation needed] OCLC often indexes by invalid ISBNs, if the book is indexed in that way by a member library.		Only the term "ISBN" should be used; the terms "eISBN" and "e-ISBN" have historically been sources of confusion and should be avoided. If a book exists in one or more digital (e-book) formats, each of those formats must have its own ISBN. In other words, each of the three separate EPUB, Amazon Kindle, and PDF formats of a particular book will have its own specific ISBN. They should not share the ISBN of the paper version, and there is no generic "eISBN" which encompasses all the e-book formats for a title.[41]		Currently the barcodes on a book's back cover (or inside a mass-market paperback book's front cover) are EAN-13; they may have a separate barcode encoding five digits for the currency and the recommended retail price.[42] For 10 digit ISBNs, the number "978", the Bookland "country code", is prefixed to the ISBN in the barcode data, and the check digit is recalculated according to the EAN13 formula (modulo 10, 1x and 3x weighting on alternate digits).		Partly because of an expected shortage in certain ISBN categories, the International Organization for Standardization (ISO) decided to migrate to a thirteen-digit ISBN (ISBN-13). The process began 1 January 2005 and was planned to conclude 1 January 2007.[43] As of 2011, all the 13-digit ISBNs began with 978. As the 978 ISBN supply is exhausted, the 979 prefix was introduced. Part of the 979 prefix is reserved for use with the Musicland code for musical scores with an ISMN. 10 digit ISMN codes differed visually as they began with an "M" letter; the bar code represents the "M" as a zero (0), and for checksum purposes it counted as a 3. All ISMNs are now 13 digits commencing 979-0; 979-1 to 979-9 will be used by ISBN.		Publisher identification code numbers are unlikely to be the same in the 978 and 979 ISBNs, likewise, there is no guarantee that language area code numbers will be the same. Moreover, the ten-digit ISBN check digit generally is not the same as the thirteen-digit ISBN check digit. Because the GTIN-13 is part of the Global Trade Item Number (GTIN) system (that includes the GTIN-14, the GTIN-12, and the GTIN-8), the 13-digit ISBN falls within the 14-digit data field range.[44]		Barcode format compatibility is maintained, because (aside from the group breaks) the ISBN-13 barcode format is identical to the EAN barcode format of existing 10-digit ISBNs. So, migration to an EAN-based system allows booksellers the use of a single numbering system for both books and non-book products that is compatible with existing ISBN based data, with only minimal changes to information technology systems. Hence, many booksellers (e.g., Barnes & Noble) migrated to EAN barcodes as early as March 2005. Although many American and Canadian booksellers were able to read EAN-13 barcodes before 2005, most general retailers could not read them. The upgrading of the UPC barcode system to full EAN-13, in 2005, eased migration to the ISBN-13 in North America.		
Gut is a geographical term with two meanings:						Many guts are straits but some are at a river mouths where tidal currents are strong. The comparatively large quantities of water that flow quite quickly through a gut can cause heavy erosion that results in a channel deeper than the rest of the surrounding seabed, and the currents may present a hazard to ships and boats at times.		The term "gut" is primarily (though not exclusively) applied to channels of the coastal waters of the Atlantic coast of North America. A similar term of related but not identical meaning, "gat", is applied to some narrow waterways of the North Sea and Baltic Sea coasts of Europe.		Some bodies of water named "Gut" are:		Many other channels in Canada are named "Gut".[8] Applied to proper names, "gut" is sometimes used more broadly. For instance South Gut and North Gut at the settlement of South Gut St. Anns, Nova Scotia are just inlets, while Brewery Gut in England and The Gut in Ontario are fast-flowing stretches of river, Jigsaw Rock Gut in Antarctica is a gully, and Gardner's Gut in New Zealand is a cave system. Conversely, some guts are not so named, such as The Rip, a gut in Australia, where the term "gut" is not used.		Another meaning for "gut" in geography is a small creek,[1] and this is seen in proper names in eastern North America from the Mid-Atlantic states (for instance, The Gut in Pennsylvania, Ash Gut in Delaware,[9] and other streams)[10] down into the Caribbean (for instance Guinea Gut, Fish Bay Gut, Cob Gut, Battery Gut and other rivers and streams in the United States Virgin Islands, in many rivers and streams of the Dutch Caribbean, and in Jamaica (Sandy Gut,[11] Bens Gut River,[12] White Gut River)).[13]		
Uniola paniculata or sea oats, also known as seaside oats, araña, and arroz de costa,[1] is a tall subtropical grass that is an important component of coastal sand dune and beach plant communities in the southeastern United States, eastern Mexico and some Caribbean islands. Its large seed heads that turn golden brown in late summer give the plant its common name. Its tall leaves trap wind-blown sand and promote sand dune growth, while its deep roots and extensive rhizomes act to stabilize them, so the plant helps protect beaches and property from damage due to high winds, storm surges and tides. It also provides food and habitat for birds, small animals and insects.[1]						Uniola paniculata is a tall, erect perennial grass that can grow to 1 to 2 m (3.3 to 6.6 ft) in height. Its long, thin leaves reach lengths of 20 to 40 cm (8 to 15.5 in) and are about 0.6 cm (0.24 in) in width, tapering to a pointed apex. The plant produces inflorescences of flat spikelets, each of which contains 10 to12 wind-pollinated florets.[1] These ripen to golden brown infructescences or seed heads in late summer. The seeds are dispersed by wind and can be carried long distances by storms and ocean currents, but reproduction commonly occurs vegetatively by forming buds around stem bases.[2]		The plant forms dense surface roots and penetrating deep roots that are colonized by beneficial organisms such as micorrhizal fungi. Rhizomes are elongate and produce extensive lateral growth. They root readily when buried in sand.[2]		Uniola paniculata uses a C4 pathway for carbon fixation.[3]		Uniola paniculata is found on beach fronts and barrier islands along the Atlantic Coast from Virginia to Florida, and the Gulf Coast from Florida to Tabasco, Mexico. It also occurs in the Bahamas and northwestern Cuba. It grows primarily on foredunes and dune crests. It is uncommon in swales between dunes where salt spray is limited, and it is rarely found inland.[1][2]		Due to the harsh conditions in which it grows, U. paniculata has little competition from other plants. It is heat tolerant and highly resistant to drought, salinity and brief inundation by sea water. It grows in loose sand rather than finer-grained silty or clay-rich soils and does not tolerate water-logging.[4] The plants tend to trap blowing sand, and burial of the plant base by sand stimulates growth and helps the plant spread by tacking down the rhizomes.[5]		U. paniculata is adversely affected by urban encroachment. Treated and untreated sewage, urban runoff and pollution from marinas all impact the plant. Off-road vehicles and foot traffic damage the plants, disrupt their roots and compact the sand. Loss of the plants leads to erosion and loss of protective dunes.[2]		Sea oats are well suited to saline environments, and as such, are important to barrier island ecology and are often used in sand stabilization projects because their long root structure firmly holds loose sand. For example, in Fort Lauderdale, Florida, colonies of sea oats have been planted at several beaches. The oats are a crucial component of the area's hurricane defense strategy and have helped to stave off damage from tropical storms. The sea oat colonies and nascent dune structure they support are expected to flourish for the foreseeable future.[6]		Sea oats are a protected grass in most states along the southeastern Atlantic coast. Picking or disturbing sea oats is punishable by fine in Georgia, Florida, South Carolina, and North Carolina.[7][8]		Seeds of U. paniculata provide food for red-winged blackbirds, sparrows and other songbirds, as well as marsh rabbits and mice.[2] Florida ornithologists have discovered that the pygmy burrowing owl makes its nest within sea oat colonies to conceal its young from natural predators such as the frigatebirds.[citation needed]		
An ocean current is a continuous, directed movement of seawater generated by forces acting upon this mean flow, such as breaking waves, wind, the Coriolis effect, cabbeling, temperature and salinity differences, while tides are caused by the gravitational pull of the Sun and Moon. Depth contours, shoreline configurations, and interactions with other currents influence a current's direction and strength. Therefore ocean currents are primarily horizontal water movements.		Ocean currents flow for great distances, and together, create the global conveyor belt which plays a dominant role in determining the climate of many of the Earth’s regions. More specifically, ocean currents influence the temperature of the regions through which they travel. For example, warm currents traveling along more temperate coasts increase the temperature of the area by warming the sea breezes that blow over them. Perhaps the most striking example is the Gulf Stream, which makes northwest Europe much more temperate than any other region at the same latitude. Another example is Lima, Peru where the climate is cooler (sub-tropical) than the tropical latitudes in which the area is located, due to the effect of the Humboldt Current.						Surface oceanic currents are sometimes wind driven and develop their typical clockwise spirals in the northern hemisphere and counter-clockwise rotation in the southern hemisphere due to imposed wind stresses. In these wind driven currents, the Ekman spiral effect results in the currents flowing at an angle to the driving winds. In addition, the areas of surface ocean currents move somewhat with the seasons; this is most notable in equatorial currents.		Deep ocean basins generally have a non-symmetric surface current, in that the eastern equatorward-flowing branch is broad and diffuse whereas the western poleward flowing branch is very narrow. These western boundary currents (of which the Gulf Stream is an example) are a consequence of the rotation of the Earth.		Deep ocean currents are driven by density and temperature gradients. Thermohaline circulation is also known as the ocean's conveyor belt (which refers to deep ocean density driven ocean basin currents). These currents, called submarine rivers, flow under the surface of the ocean and are hidden from immediate detection. Where significant vertical movement of ocean currents is observed, this is known as upwelling and downwelling. Deep ocean currents are currently being researched using a fleet of underwater robots called Argo.		The South Equatorial Currents of the Atlantic and Pacific straddle the equator. Though the Coriolis effect is weak near the equator (and absent at the equator), water moving in the currents on either side of the equator is deflected slightly poleward and replaced by deeper water. Thus, equatorial upwelling occurs in these westward flowing equatorial surface currents. Upwelling is an important process because this water from within and below the pycnocline is often rich in nutrients and greatly benefits the growth of marine organisms. By contrast, generally poor conditions for growth prevail in most of the open tropical ocean because strong layering isolates deep, nutrient rich water from the sunlit ocean surface.		Surface currents make up only 8% of all water in the ocean, are generally restricted to the upper 400 m (1,300 ft) of ocean water, and are separated from lower regions by varying temperatures and salinity which affect the density of the water, which in turn, defines each oceanic region. Because the movement of deep water in ocean basins is caused by density driven forces and gravity, deep waters sink into deep ocean basins at high latitudes where the temperatures are cold enough to cause the density to increase.		Ocean currents are measured in sverdrup (sv), where 1 sv is equivalent to a volume flow rate of 1,000,000 m3 (35,000,000 cu ft) per second.		Surface currents are found on the surface of an ocean, and are driven by large scale wind currents. They are directly affected by the wind—the Coriolis effect plays a role in their behaviors.[1]		Horizontal and vertical currents also exist below the pycnocline in the ocean's deeper waters. The movement of water due to differences in density as a function of water temperature and salinity is called thermohaline circulation. Ripple marks in sediments, scour lines, and the erosion of rocky outcrops on deep-ocean floors are evidence that relatively strong, localized bottom currents exist. Some of these currents may move as rapidly as 60 centimeters (24 inches) per second.		These currents are strongly influenced by bottom topography, since dense, bottom water must forcefully flow over and around depressions and projections in the seafloor. Thus, they are sometimes called contour currents. Bottom currents generally move equator-ward at or near the western boundaries of ocean basins (below the western boundary surface currents). The deep-water masses are not capable of moving water at speeds comparable to that of wind-driven surface currents. Water in some of these currents may move only 1 to 2 meters per day; however, even at that slow speed, the Coriolis effect modifies their pattern of flow.		Antarctic Bottom Water is the most distinctive of the deep-water masses. It is characterized by a salinity of 34.65‰, a temperature of -0.5 °C (30 °F), and a density of 1.0279 grams per cubic centimeter. This water is noted for its extreme density (the densest in the world ocean), for the great amount of it produced near Antarctic coasts, and for its ability to migrate north along the seafloor. Most Antarctic Bottom Water forms near the Antarctic coast south of South America during winter. Salt is concentrated in pockets between crystals of pure water and then squeezed out of the freezing mass to form a frigid brine. Between 20 million and 50 million cubic meters of this brine form every second. The water's great density causes it to sink toward the continental shelf, where it mixes with nearly equal parts of water from the southern Antarctic Circumpolar Current. The mixture settles along the edge of Antarctica's continental shelf, descends along the slope, and spreads along the deep-sea bed, creeping north in slow sheets. Antarctic Bottom Water flows many times as slowly as the water in surface currents: in the Pacific it may take a thousand years to reach the equator. Antarctic Bottom Water also flows into the Atlantic Ocean basin, where it flows north at a faster rate than in the Pacific. Antarctic Bottom Water has been identified as high as 40° N on the Atlantic floor.		A small amount of dense bottom water also forms in the northern polar ocean. Although, the topography of the Arctic Ocean basin prevents most of the bottom water from escaping, with the exception of deep channels formed in the submarine ridges between Scotland, Iceland, and Greenland. These channels allow the cold, dense water formed in the Arctic to flow into the North Atlantic to form North Atlantic Deep Water. North Atlantic Deep Water forms when the relatively warm and salty North Atlantic Ocean cools as cold winds from northern Canada sweep over it. Exposed to the chilled air, water at the latitude of Iceland releases heat, cools from 10 °C to 2 °C, and sinks. Gulf Stream water that sinks in the north is replaced by warm water flowing clockwise along the U.S. east coast in the North Atlantic gyre.		Knowledge of surface ocean currents is essential in reducing costs of shipping, since traveling with them reduces fuel costs. In the wind powered sailing-ship era, knowledge of wind patterns and ocean currents was even more essential. A good example of this is the Agulhas Current, which long prevented Portuguese sailors from reaching India. In recent times, around-the-world sailing competitors make good use of surface currents to build and maintain speed. Ocean currents are also very important in the dispersal of many life forms. An example is the life-cycle of the European Eel.		Ocean currents are important in the study of marine debris, and vice versa. These currents also affect temperatures throughout the world. For example, the ocean current that brings warm water up the north Atlantic to northwest Europe also cumulatively and slowly blocks ice from forming along the seashores, which would also block ships from entering and exiting inland waterways and seaports, hence ocean currents play a decisive role in influencing the climates of regions through which they flow. Cold ocean water currents flowing from polar and sub-polar regions bring in a lot of plankton that are crucial to the continued survival of several key sea creature species in marine ecosystems. Since plankton are the food of fish, abundant fish populations often live where these currents prevail.		Ocean currents can also be used for marine power generation, with areas off of Japan, Florida and Hawaii being considered for test projects.		The OSCAR Near-realtime global ocean surface currents website describes the project and links to data validation and data downloads.		OSCAR data is used extensively in climate studies. maps and descriptions or annotations of climatic anomalies have been published in the monthly Climate Diagnostic Bulletin since 2001 and are routinely used to monitor ENSO and to test weather prediction models. OSCAR currents are routinely used to evaluate the surface currents in Global Circulation Models (GCMs), for example in NCEP Global Ocean Data Assimilation System (GODAS) and European Centre for Medium-Range Weather Forecasts (ECMWF).[2]		
A shore or a shoreline is the fringe of land at the edge of a large body of water, such as an ocean, sea, or lake. In physical oceanography, a shore is the wider fringe that is geologically modified by the action of the body of water past and present, while the beach is at the edge of the shore, representing the intertidal zone where there is one.[1] In contrast to a coast, a shore can border any body of water, while the coast must border an ocean; in that sense a coast is a type of shore; however, coast often refers to an area far wider than the shore, often streaching miles into the interior.		Shores are influenced by the topography of the surrounding landscape, as well as by water induced erosion, such as waves. The geological composition of rock and soil dictates the type of shore which is created.						Riviera is an Italian word for "shoreline",[2][3][4] ultimately derived from Latin ripa ("riverbank"). It came to be applied as a proper name to the coast of the Ligurian Sea, in the form riviera ligure, then shortened to riviera. Historically, the Ligurian Riviera extended from Capo Corvo (Punta Bianca) south of Genoa, north and west into what is now French territory past Monoco and sometimes as far as Marseilles.[2][5][6] Now it is divided into the Italian Riviera and the French Riviera. Although the French use the term "Riviera" to refer to the Italian Riviera, and call the French portion the "Côte d'Azur".[3]		As a result of the fame of the Ligurian rivieras, the term came into English to refer to any shoreline, especially one that is sunny, topographically diverse and popular with tourists.[2] Such places using the term include the Australian Riviera in Queensland and the Turkish Riviera along the Aegean Sea.[3]		
The piping plover (Charadrius melodus) is a small sand-colored, sparrow-sized shorebird that nests and feeds along coastal sand and gravel beaches in North America. The adult has yellow-orange legs, a black band across the forehead from eye to eye, and a black stripe running along the breast line. This chest band is usually thicker in males during the breeding season, and it is the only reliable way to tell the sexes apart. The bird is difficult to see when it is standing still, as it blends well with open, sandy beach habitats. It typically runs in short spurts and stops.		There are two subspecies of piping plovers: the eastern population is known as Charadrius melodus melodus and the mid-west population is known as C. m. circumcinctus. The bird's name is derived from its plaintive bell-like whistles which are often heard before the bird is visible.		Total population is currently estimated at about 6,510 individuals. A preliminary estimate showed 3,350 birds in 2003 on the Atlantic Coast alone, 52% of the total.[2] The population has been increasing since 1999.		Their breeding habitat includes beaches and sand flats on the Atlantic coast, the shores of the Great Lakes, and in the mid-west of Canada and the United States. They nest on sandy or gravel beaches or shoals. These shorebirds forage for food on beaches, usually by sight, moving across the beaches in short bursts. Generally, piping plovers will forage for food around the high tide wrack zone and along the water's edge. They eat mainly insects, marine worms, and crustaceans.						Two subspecies are recognized, including nominate C. m. melodus of the Atlantic Coast and C. m. circumcinctus of the Great Plains. On average, circumcinctus is darker overall with more contrastingly dark cheeks and lores. Breeding male circumcinctuses show more extensive black on forehead and bill-base and more often shows complete breast-bands. Some overlap exists.		The piping plover is a stout bird with a large rounded head, a short thick neck, and a stubby bill. It is a sand-colored, dull gray/khaki, sparrow-sized shorebird. The adult has yellow-orange legs, a black band across the forehead from eye to eye, and a black ring around the neck during the breeding season. During nonbreeding season, the black bands become less pronounced.[3] Its bill is orange with a black tip. It ranges from 15–19 cm (5.9–7.5 in) in length, with a wingspan of 35–41 cm (14–16 in) and a mass of 42–64 g (1.5–2.3 oz).[4]		The piping plover's light call is a soft, whistled peep peep given by standing and flying birds. Its frequently heard alarm call is a soft pee-werp, which the second syllable lower pitched.		The piping plover lives the majority of its life on open sandy beaches or rocky shores, often in high, dry sections away from water. They can be found on the Atlantic Coast of the U.S. and Canada on the ocean or bay beaches and on the Great Lakes shores. It builds its nests higher on the shore near beach grass and other objects. It is very rare to see a piping plover anywhere outside of sand or rocky beaches/shores while not migrating. Piping plovers are often found to migrate south to The Bahamas during winter months.[5]		Piping plovers migrate from their northern range in the summer to the south in the winter months, migrating to the Gulf of Mexico, the southern Atlantic coast of the United States and the Caribbean. They begin migrating north beginning in mid-March. Their breeding grounds extend from southern Newfoundland south to the northern parts of South Carolina.[6] Migration south begins in August for some adults and fledglings, and by mid-September most piping plovers have headed south for winter.		The piping plover usually arrives at sandy beaches to breed in mid to late April.[7]		Males will begin claiming territories and pairing up in late March. When pairs are formed, the male begins digging out several scrapes (nests) along the high shore near the beach-grass line. The males also perform elaborate courtship ceremonies, including stone tossing and courtship flights featuring repeated dives.[3] Scrapes, small depressions in the sand dug by kicking the sand, are often in the same area that least terns choose to colonize. Females will sit and evaluate the scrapes, then choose a good scrape and decorate the nest with shells and debris to camouflage it. Once a scrape is seen as sufficient, the female will allow the male to copulate with her. The male begins a mating ritual of standing upright and "marching" towards the female, puffing himself up and quickly stomping his legs. If the female had seen the scrape as adequate, she will allow the male to stand on her back and copulation occurs within a few minutes.		Most first-time nest attempts in each breeding season are four-egg nests which appear as early as mid-to-late April. Females lay one egg every other day. Second, third and sometimes fourth nesting attempts may have only three or two eggs. Incubation of the nest is shared by both the male and the female. Incubation is generally 27 days and eggs usually all hatch on the same day.		After chicks hatch, they are able to feed within hours. The adults' role is then to protect them from the elements by brooding them. They also alert them to any danger. Like many other species of plovers, adult piping plovers will often feign a "broken wing display", drawing attention to themselves and away from the chicks when a predator may be threatening the chicks' safety. The broken wing display is also used during the nesting period to distract predators from the nest.[3] A major defense mechanism of the chicks is their ability to blend in with the sand. It takes about 30 days before chicks achieve flight capability. They must be able to fly at least 50 yd (46 m) before they can be considered fledglings.		To protect the nests from predators during incubation, many conservationists use exclosures, such as round turkey-wire cages with screened tops. These allow the adults to move in and out but stop predators from getting to the eggs. After the chicks hatch, many areas will put up snow fencing to restrict driving and pets for the safety of the chicks. Threats to nests include crows, cats, raccoons, and foxes, among others. Exclosures are not always used, as they occasionally draw more attention to the nest than would occur without the exclosure. Natural hazards to eggs or chicks include storms, high winds, and abnormal high tides; human disturbances can cause the abandonment of nests and chicks as well. It is best to stay away from any bird that appears distressed to prevent any unintended consequences.		The piping plover is globally threatened and endangered; it is uncommon and local within its range, and has been listed by the United States as "endangered" in the Great Lakes region and "threatened" in the remainder of its breeding range.[8] While it is federally threatened, the piping plover has been listed as state endangered in Illinois, Indiana, Maine, Michigan, Minnesota, Nebraska, New Hampshire, New York, New Jersey, Ohio, Pennsylvania, and Wisconsin. The Parker River Refuge on Plum Island, Massachusetts is a national network of lands and rivers dedicated to the safety of its native wildlife and specifically the Piping Plover. Protecting the Piper with full beach closures, the Refuge now "has the second largest plover population on the North Shore".[9]		In eastern Canada, the piping plover is found only on coastal beaches. In 1985, it was declared an endangered species by the Committee on the Status of Endangered Wildlife in Canada.[10] A large population in Ontario has disappeared entirely.[11] In 2008, however, piping plover nests were found at Wasaga Beach and near Sauble Beach, Ontario, along the Ontario Great Lakes shores.[12] There is also some evidence of nesting at other sites in Ontario, including Port Elgin, Ontario in 2014.[13][14]		In the 19th century and early 20th century, the piping plover was utilized for its feathers, as were many other birds at the time, as decorations for women's hats. These decorations, called plumes, became a symbol of high society, especially those from larger rare birds. This practice led to its initial population decline. The Migratory Bird Treaty Act of 1918 helped the population recover through the 1930s.[15] The second decline in the piping plover's population and range has been attributed to increased development, shoreline stabilization efforts,[16] habitat loss and human activity near nesting sites in the decades following World War II.[15] The Great Lakes populations eventually shrank to only around two dozen.[11]		Critical nesting habitats are now being protected to help the population during its breeding season. Populations have seen significant increases since the protection programs began, but the species remains in serious danger. Current conservation strategies include identification and preservation of known nesting sites; public education; limiting or preventing pedestrian and/or off-road vehicle (ORV) traffic near nests and hatched chicks; limiting predation of free-ranging cats, dogs and other pets on breeding pairs, eggs and chicks;[17] and removal of foxes, raccoons, skunks, and other predators.[18]		In coastal areas such as Plymouth,[19] Cape Cod, Long Island, Sandy Hook,[20] Cape Henlopen State Park in Delaware, North Manitou Island in Lake Michigan, and most recently, Cape Hatteras National Seashore on the Outer Banks of North Carolina, beach access to pedestrians and ORVs has been limited to protect piping plovers and their chicks at critical times of the breeding season.		Various environmental organizations are involved in aiding restoration efforts. The Goldenrod Foundation [1] unsuccessfully filed suit against the Town of Plymouth in 2010 and 2015 to restrict offroad vehicle access to breeding habitat.[21][22]		Area closed within Cape Henlopen State Park, Delaware, where piping plovers are known to nest		Piping plover protected nesting area on Cavendish Beach, P.E.I.		
The Sun Belt is a region of the United States generally considered to stretch across the Southeast and Southwest. Another rough definition of the region is the area south of the 36th parallel. The region is noted for its mild winter, frequent sunny skies, and growing economic opportunities. The sun belt is the fastest growing region in the United States. Within the region, desert/semi-desert (California, Nevada, Arizona, New Mexico, Oklahoma, and Texas), Mediterranean (California), humid subtropical (Oklahoma, Texas, Louisiana, Mississippi, Alabama, Arkansas, Florida, Georgia, South Carolina, North Carolina), and tropical (Florida) climates can be found.		The Sun Belt has seen substantial population growth since the 1960s from an influx of people seeking a warm and sunny climate, a surge in retiring baby boomers, and growing economic opportunities. The advent of air conditioning created more comfortable summer conditions and allowed more manufacturing and industry to locate in the sunbelt. Since much of the construction in the sun belt is new or recent, housing styles and design are often modern and open. Recreational opportunities in the sun belt are often not tied strictly to one season, and many tourist and resort cities, such as Miami, Los Angeles, Las Vegas, Orlando, Myrtle Beach, Tucson, and Palm Springs support a tourist industry all year. [3][4]						The Sun Belt comprises the southern tier of the United States, including the states of Alabama, Arizona, Florida, Georgia, Louisiana, Mississippi, New Mexico, South Carolina, Texas, roughly two-thirds of California (up to Greater Sacramento), and parts of Arkansas, North Carolina, and Nevada. Five of the states—Arizona, California, Florida, Nevada, and Texas—are sometimes collectively called the Sand States because of their abundance of beaches or deserts.[5]		First employed by political analyst Kevin Phillips in his 1969 book The Emerging Republican Majority,[6] the term "Sun Belt" became synonymous with the southern third of the nation in the early 1970s. In this period, economic and political prominence shifted from the Midwest and Northeast to the South and West. Factors such as the warmer climate, the migration of workers from Mexico, and a boom in the agriculture industry allowed the southern third of the United States to grow economically. The climate spurred not only agricultural growth, but also the migration of many retirees to retirement communities in the region, especially in Florida and Arizona.		Industries such as aerospace, defense, and oil boomed in the Sun Belt as companies took advantage of the low involvement of labor unions in the region (due to more recent industrialization, 1930s–1950s) and the proximity of military installations that were major consumers of their products. The oil industry helped propel states such as Texas and Louisiana forward, and tourism grew in Florida and Southern California. More recently, high tech and new economy industries have been major drivers of growth in California, Florida, Texas, and other parts of the Sun Belt. Texas and California rank among the top five states in the nation with the most Fortune 500 companies.[7]		In 2005, the U.S. Census Bureau projected that approximately 88% of the nation's population growth between 2000 and 2030 would occur in the Sun Belt.[8] California, Texas, and Florida were each expected to add more than 12 million people during that time, which would make them by far the most populous states in America. Nevada, Arizona, Florida, and Texas were expected to be the fastest-growing states.		Events leading up to and including the 2008–2009 recession led some to question whether growth projections for the Sun Belt had been overstated.[9] The economic bubble that led to the recession appeared, to some observers, to have been more acute in the Sun Belt than other parts of the country. Additionally, the traditional lure of cheaper labor markets in the region compared with America's older industrial centers has been eroded by overseas outsourcing trends.		One of the greatest threats facing the belt in the coming decades is water shortages.[10] Communities in California are making plans to build multiple desalination plants to supply fresh water and avert near-term crises.[11] Texas, Georgia, and Florida also face increasingly serious shortages because of their rapidly expanding populations.[12]		Lingering effects from the Great Recession slowed down, and in some places even stopped, the migration from the Frost Belt to the Sun Belt, according to data tracking people's movements over the year from July 2012–2013. Americans remained cautious about moving to a different state over this period.[13] However, migration to the Sun Belt from the Frost Belt resumed again, according to 2015 Census data estimates, with growing migration to the Sun Belt and out of the Frost Belt and California.[14][15]		The environment in the belt is extremely valuable, not only to local and state governments, but to the federal government. Eight of the ten states have extremely high biodiversity (ranging from 3,800 to 6,700 species, not including marine life).[16] The Sun Belt also has the highest number of distinct ecosystems: chaparral, deciduous, desert, grasslands, and tropical rainforest.		Some endangered species live within the belt,[17][18] including:		The five largest metropolitan statistical areas are Los Angeles, Dallas, Houston, Miami, and Atlanta. The Los Angeles area is by far the largest, with over 13 million inhabitants as of 2012[update]. The ten largest metropolitan statistical areas are found in California, Texas, Georgia, North Carolina, Florida, and Arizona.[20] Additionally, the cross-border metropolitan areas of San Diego-Tijuana and El Paso–Juárez lie partially within the Sun Belt. Seven of the ten largest cities in the United States are located in the Sun Belt: Los Angeles (2), Houston (4), Phoenix (6), San Antonio (7), San Diego (8), Dallas (9), and San Jose (10).		Coordinates: 32°N 100°W﻿ / ﻿32°N 100°W﻿ / 32; -100		
The intertidal zone, also known as the foreshore and seashore and sometimes referred to as the littoral zone, is the area that is above water at low tide and under water at high tide (in other words, the area between tide marks). This area can include many different types of habitats, with many types of animals, such as starfish, sea urchins, and numerous species of coral. The well-known area also includes steep rocky cliffs, sandy beaches, or wetlands (e.g., vast mudflats). The area can be a narrow strip, as in Pacific islands that have only a narrow tidal range, or can include many meters of shoreline where shallow beach slopes interact with high tidal excursion. Peritidal zone is similar but a somewhat wider zone, extending from above the highest tide level to below that of the lowest tide level.		Organisms in the intertidal zone are adapted to an environment of harsh extremes.[1][not in citation given] The intertidal zone is also home to many several species from different taxa including Porifera, Annelids, Coelenterates, Mollusks, crustaceans, Arthropods, etc.[1] Water is available regularly with the tides but varies from fresh with rain to highly saline and dry salt with drying between tidal inundations. Wave splash can dislodge residents from the littoral zone. With the intertidal zone's high exposure to the sun, the temperature range can be anything from very hot with full sun to near freezing in colder climates. Some microclimates in the littoral zone are ameliorated by local features and larger plants such as mangroves. Adaptation in the littoral zone allows the use of nutrients supplied in high volume on a regular basis from the sea, which is actively moved to the zone by tides. Edges of habitats, in this case land and sea, are themselves often significant ecologies, and the littoral zone is a prime example.		A typical rocky shore can be divided into a spray zone or splash zone (also known as the supratidal zone), which is above the spring high-tide line and is covered by water only during storms, and an intertidal zone, which lies between the high and low tidal extremes. Along most shores, the intertidal zone can be clearly separated into the following subzones: high tide zone, middle tide zone, and low tide zone. The intertidal zone is one of a number of marine biomes or habitats, including estuaries, neritic, surface and deep zones.						Marine biologists divide the intertidal region into three zones (low, middle, and high), based on the overall average exposure of the zone. The low intertidal zone, which borders on the shallow subtidal zone, is only exposed to air at the lowest of low tides and is primarily marine in character. The mid intertidal zone is regularly exposed and submerged by average tides. The high intertidal zone is only covered by the highest of the high tides, and spends much of its time as terrestrial habitat. The high intertidal zone borders on the splash zone (the region above the highest still-tide level, but which receives wave splash). On shores exposed to heavy wave action, the intertidal zone will be influenced by waves, as the spray from breaking waves will extend the intertidal zone.		Depending on the substratum and topography of the shore, additional features may be noticed. On rocky shores, tide pools form in depressions that fill with water as the tide rises. Under certain conditions, such as those at Morecambe Bay, quicksand may form.		This subregion is mostly submerged - it is only exposed at the point of low tide and for a longer period of time during extremely low tides. This area is teeming with life; the most notable difference with this subregion to the other three is that there is much more marine vegetation, especially seaweeds. There is also a great biodiversity. Organisms in this zone generally are not well adapted to periods of dryness and temperature extremes. Some of the organisms in this area are abalone, sea anemones, brown seaweed, chitons, crabs, green algae, hydroids, isopods, limpets, mussels, nudibranchs, sculpin, sea cucumber, sea lettuce, sea palms, starfish, sea urchins, shrimp, snails, sponges, surf grass, tube worms, and whelks. Creatures in this area can grow to larger sizes because there is more available energy in the localized ecosystem. Also, marine vegetation can grow to much greater sizes than in the other three intertidal subregions due to the better water coverage. The water is shallow enough to allow plenty of light to reach the vegetation to allow substantial photosynthetic activity, and the salinity is at almost normal levels. This area is also protected from large predators such as fish because of the wave action and the relatively shallow water.		The intertidal region is an important model system for the study of ecology, especially on wave-swept rocky shores. The region contains a high diversity of species, and the zonation created by the tides causes species ranges to be compressed into very narrow bands. This makes it relatively simple to study species across their entire cross-shore range, something that can be extremely difficult in, for instance, terrestrial habitats that can stretch thousands of kilometres. Communities on wave-swept shores also have high turnover due to disturbance, so it is possible to watch ecological succession over years rather than decades.		The burrowing invertebrates that make up large portions of sandy beach ecosystems are known to travel relatively great distances in cross-shore directions as beaches change on the order of days, semilunar cycles, seasons, or years.[2] The distribution of some species has been found to correlate strongly with geomorphic datums such as the high tide strand and the water table outcrop.[2]		Since the foreshore is alternately covered by the sea and exposed to the air, organisms living in this environment must have adaptions for both wet and dry conditions. Hazards include being smashed or carried away by rough waves, exposure to dangerously high temperatures, and desiccation. Typical inhabitants of the intertidal rocky shore include urchins, sea anemones, barnacles, chitons, crabs, isopods, mussels, starfish, and many marine gastropod molluscs such as limpets and whelks.		As with the dry sand part of a beach, legal and political disputes can arise over the ownership and use of the foreshore. One recent example is the New Zealand foreshore and seabed controversy. In legal discussions, the foreshore is often referred to as the wet-sand area.		For privately owned beaches in the United States, some states such as Massachusetts use the low water mark as the dividing line between the property of the State and that of the beach owner. Other states such as California use the high-water mark.		In the UK, the foreshore is generally deemed to be owned by the Crown although there are notable exceptions, especially what are termed several fisheries, which can be historic deeds to title, dating back to King John's time or earlier, and the Udal Law, which applies generally in Orkney and Shetland.		In Greece, according to the L. 2971/01, the foreshore zone is defined as the area of the coast that might be reached by the maximum climbing of the waves on the coast (maximum wave run-up on the coast) in their maximum capacity (maximum referring to the "usually maximum winter waves" and of course not to exceptional cases, such as tsunamis etc.). The foreshore zone, apart of the exceptions of the law, is public, and permanent constructions are not allowed on it.		The Intertidal Zone was used as a title for Stephen Hillenburg's old comic strip. The comic strip starred "Bob The Sponge", who would later go on to become SpongeBob SquarePants.		Mussels in the intertidal zone in Cornwall, England.		Barnacles and limpets in the intertidal zone near Newquay, Cornwall, England.		A tidal pool in the intertidal zone during low tide, Sunrise-on-Sea, South Africa.		Unexplained crumbs of sand that appear to have been deposited around stone by escaping air.		Rocks in intertidal zone completely covered by mussels, at Bangchuidao Scenic Area, Dalian, Liaoning Province, China.		
A submarine canyon is a steep-sided valley cut into the seabed of the continental slope, sometimes extending well onto the continental shelf, having nearly vertical walls, and occasionally having canyon wall heights of up to 5 km, from canyon floor to canyon rim, as with the Great Bahama Canyon.[1] Just as above-sea-level canyons serve as channels for the flow of water across land, submarine canyons serve as channels for the flow of turbidity currents across the seafloor. Turbidity currents are flows of dense, sediment laden waters that are supplied by rivers, or generated on the seabed by storms, submarine landslides, earthquakes, and other soil disturbances. Turbidity currents travel down slope at great speed (as much as 70 km/h), eroding the continental slope and finally depositing sediment onto the abyssal plain, where the particles settle out.[2]		About 3% of submarine canyons include shelf valleys that have cut transversely across continental shelves, and which begin with their upstream ends in alignment with and sometimes within the mouths of large rivers, such as the Congo River and the Hudson Canyon. About 28.5% of submarine canyons cut back into the edge of the continental shelf, whereas the majority (about 68.5%) of submarine canyons have not managed at all to cut significantly across their continental shelves, having their upstream beginnings or "heads" on the continental slope, below the edge of continental shelves.[3]		The formation of submarine canyons is believed to occur as the result of at least two main process: 1) erosion by turbidity current erosion; and 2) slumping and mass wasting of the continental slope. While at first glance, the erosion patterns of submarine canyons may appear to mimic those of river-canyons on land, due to the markedly different erosion processes that have been found to take place underwater at the soil/ water interface, several notably different erosion patterns have been observed in the formation of typical submarine canyons.[2][4]		Many canyons have been found at depths greater than 2 km below sea level. Some may extend seawards across continental shelves for hundreds of kilometres before reaching the abyssal plain. Ancient examples have been found in rocks dating back to the Neoproterozoic.[5] Turbidites are deposited at the downstream mouths or ends of canyons, building an abyssal fan.						Submarine canyons are more common on the steep slopes found on active margins compared to those on the gentler slopes found on passive margins.[6] They show erosion through all substrates, from unlithified sediment to crystalline rock. Canyons are steeper, shorter, more dendritic and more closely spaced on active than on passive continental margins.[3] The walls are generally very steep and can be near vertical. The walls are subject to erosion by bioerosion, or slumping. There are an estimated 9,477 submarine canyons on earth, covering about 11% of the continental slope.[7]		Many mechanisms have been proposed for the formation of submarine canyons. Their primary causes have been subject to debate since the early 1930s.[10]		An early and obvious theory was that the canyons present today were carved during glacial times, when sea level was about 125 meters below present sea level, and rivers flowed to the edge of the continental shelf. However, while many (but not all) canyons are found offshore from major rivers, subaerial river erosion cannot have been active to the water depths as great as 3000 meters where canyons have been mapped, as it is well established (by many lines of evidence) that sea levels did not fall to those depths.		The major mechanism of canyon erosion is now thought to be turbidity currents and underwater landslides. Turbidity currents are dense, sediment-laden currents which flow downslope when an unstable mass of sediment that has been rapidly deposited on the upper slope fails, perhaps triggered by earthquakes. There is a spectrum of turbidity- or density-current types ranging from "muddy water" to massive mudflow, and evidence of both these end members can be observed in deposits associated with the deeper parts of submarine canyons and channels, such as lobate deposits (mudflow) and levees along channels.		Mass wasting, slumping, and submarine landslides are forms of slope failures (the effect of gravity on a hillslope) observed in submarine canyons. Mass wasting is the term used for the slower and smaller action of material moving downhill. Slumping is generally used for rotational movement of masses on a hillside. Landslides, or slides, generally comprise the detachment and displacement of sediment masses.		It is now understood that many mechanisms of submarine canyon creation have had effect to greater or lesser degree in different places, even within the same canyon, or at different times during a canyon's development. However, if a primary mechanism must be selected, the downslope lineal morphology of canyons and channels and the transportation of excavated or loose materials of the continental slope over extensive distances require that various kinds of turbidity or density currents act as major participants.		In addition to the processes described above, submarine canyons that are especially deep may form by another method. In certain cases, a sea with a bed significantly below sea level is cut off from the larger ocean to which it is usually connected. The sea which is normally repleted by contact and inflow from the ocean is now no longer replenished and hence dries up over a period of time, which can be very short if the local climate is arid. In this scenario, rivers that previously flowed into the sea at a sea level elevation now can cut far deeper into the bottom of the bed now exposed. The Messinian Salinity Crisis is an example of this phenomenon; between five and six million years ago, the Mediterranean Sea became isolated from the Atlantic Ocean and evaporated away in roughly a thousand years. During this time, the Nile River delta, among other rivers, extended far beyond its present location, both in depth and length. In a cataclysmic event, the Mediterranean sea basin was flooded. One relevant consequence is that the submarine canyons eroded are now far below the present sea level.		
A developed country, industrialized country, more developed country, or "more economically developed country" (MEDC), is a sovereign state that has a highly developed economy and advanced technological infrastructure relative to other less industrialized nations. Most commonly, the criteria for evaluating the degree of economic development are gross domestic product (GDP), gross national product (GNP), the per capita income, level of industrialization, amount of widespread infrastructure and general standard of living.[1] Which criteria are to be used and which countries can be classified as being developed are subjects of debate.		Developed countries have post-industrial economies, meaning the service sector provides more wealth than the industrial sector. They are contrasted with developing countries, which are in the process of industrialization, or undeveloped countries, which are pre-industrial and almost entirely agrarian. As of 2015, advanced economies comprise 60.8% of global GDP based on nominal values and 42.9% of global GDP based on purchasing-power parity (PPP) according to the International Monetary Fund.[2] In 2015, the ten largest advanced economies by GDP in both nominal and PPP terms were Australia, Canada, France, Germany, Italy, Japan, South Korea, Spain, the United Kingdom, and the United States.[3]						Terms similar to developed country include "advanced country", "industrialized country", "'more developed country" (MDC), "more economically developed country" (MEDC), "Global North country", "first world country", and "post-industrial country". The term industrialized country may be somewhat ambiguous, as industrialization is an ongoing process that is hard to define. The first industrialized country was the United Kingdom, followed by Belgium. Later it spread further to Germany, United States, France and other Western European countries. According to some economists such as Jeffrey Sachs, however, the current divide between the developed and developing world is largely a phenomenon of the 20th century.[4]		Economic criteria have tended to dominate discussions. One such criterion is income per capita; countries with high gross domestic product (GDP) per capita would thus be described as developed countries. Another economic criterion is industrialization; countries in which the tertiary and quaternary sectors of industry dominate would thus be described as developed. More recently another measure, the Human Development Index (HDI), which combines an economic measure, national income, with other measures, indices for life expectancy and education has become prominent. This criterion would define developed countries as those with a very high (HDI) rating.		According to the United Nations Statistics Division:		There is no established convention for the designation of "developed" and "developing" countries or areas in the United Nations system.[5]		And it notes that:		The designations "developed" and "developing" are intended for statistical convenience and do not necessarily express a judgement about the stage reached by a particular country or area in the development process.[6]		The UN HDI is a statistical measure that gauges a country's level of human development. While there is a strong correlation between having a high HDI score and a prosperous economy, the UN points out that the HDI accounts for more than income or productivity. Unlike GDP per capita or per capita income, the HDI takes into account how income is turned "into education and health opportunities and therefore into higher levels of human development."		Since 1990, Norway (2001–2006, 2009–2013), Japan (1990–1991 and 1993), Canada (1992 and 1994–2000) and Iceland (2007–2008) have had the highest HDI score. The top 47 countries have scores ranging from 0.793 in Barbados to 0.955 in Norway.		Many countries listed by IMF or[Note 1] CIA as "advanced" (as of 2009), possess an HDI over 0.788 (as of 2010). Many countries[Note 2] possessing an HDI of 0.788 and over (as of 2010) are also listed by IMF or CIA as "advanced" (as of 2009). Thus, many "advanced economies" (as of 2009) are characterized by an HDI score of 0.9 or higher (as of 2007). Since April 2016, the IMF classifies Macau as an advanced economy.[7]		The latest report was launched on 21 March 2017.[8]		As a non-UN member, the government of Taiwan calculates its own HDI, which had a value of 0.882 in 2011.[9] Additionally, while the HDI for the Chinese special administrative region of Hong Kong is calculated by the UN, it is not for Macau. The Macanese government calculated the territory's HDI to be 0.868 in 2011. These values place both Taiwan and Macau well within the list of countries with "Very high human development".[10] Furthermore, in 2009 a United Nations project calculated the HDI for all of its members, as well as Taiwan, Macau, and many dependent territories. The HDI values for the countries of San Marino and Monaco, which have not been included in official annual HDI reports, were found to be at 0.961 and 0.956 respectively. This places both countries firmly within the category of countries with "Very high human development" as well. The dependent territories with HDI values equivalent to "Very high human development" were: Jersey, Cayman Islands, Bermuda, Guernsey, Gibraltar, Norfolk Island, Faroe Islands, Isle of Man, British Virgin Islands, Falkland Islands, Aruba, Puerto Rico, Martinique, Greenland, and Guam.[11] Of note, the HDI values in the 2009 report were calculated using the old HDI formula, while HDI values after the year 2010 are calculated with a different formula.		Some institutions have produced lists of developed countries: the UN (list shown above), the CIA,[12] and some providers of stock market indices(the FTSE Group, MSCI, S&P, Dow Jones, STOXX, etc.). The latter is not included here because its association of developed countries with countries with both high incomes and developed markets is not deemed as directly relevant.[why?][Note 3]		However many other institutions have created more general lists referred to when discussing developed countries. For example, the International Monetary Fund (IMF) identifies 39 "advanced economies".[7][13] The OECD's 35 members are known as the "developed countries club"[14][15][16] The World Bank identifies 78 "high income countries".[17]		According to the World Bank the following 78 countries (including territories) are classified as "high-income economies".[17] In parentheses are the year(s) during which they held such classification since classification began in 1987.[18]		According to the International Monetary Fund, the following 39 economies are classified as "advanced economies":[7]		The CIA has modified an older version of the IMF's list of Advanced Economies, noting that the IMF's Advanced Economies list "would presumably also cover"[12] some smaller countries. These include:		There are 33 members in the High-income OECD category, as determined by the World Bank.[19][20] The High-income OECD membership is as follows:		25 countries in Europe:		3 countries in Asia:		3 countries in the Americas:		2 countries in Oceania:		There are 29 OECD member countries and the European Union—in the Development Assistance Committee (DAC),[21] a group of the world's major donor countries that discuss issues surrounding development aid and poverty reduction in developing countries.[22] The following OECD member countries are DAC members:		23 countries wholly or partly in Europe:		2 countries in Asia:		2 countries in North America:		2 countries in Oceania:		There are 22 permanent members in the Paris Club (French: Club de Paris), a group of officials from major creditor countries whose role is to find coordinated and sustainable solutions to the payment difficulties experienced by debtor countries.		15 countries wholly or partly in Europe:		3 countries in Asia:		3 countries in The Americas:		1 country in Oceania:		The list below represents a national accounts derived indicator based on adjusted gross income, which is defined as "the balance of primary incomes of an institutional unit or sector by adding all current transfers, except social transfers in kind, receivable by that unit or sector and subtracting all current transfers, except social transfers in kind, payable by that unit or sector; it is the balancing item in the Secondary Distribution of Income Account" [23] "plus transfers in kind" received mainly from government, such as healthcare and education.[24] It is based on the national accounts, which follows a standardized accounting (System of National Accounts) so to allow for comparability. It is also not survey based, which avoids survey errors and underreporting. The following is published by the OECD and is presented in PPPs so as to adjust for costs of living.		
In geography, a bight is a bend or curve in a coastline, river, or other geographical feature.[1] It typically indicates a large, open bay, often only slightly receding.[2] It is distinguished from a sound by being shallower. Traditionally, explorers defined a bight as a bay that could be sailed out of on a single tack in a square-rigged sailing vessel, regardless of the direction of the wind (typically meaning the apex of the bight is less than 25 degrees from the edges).		
The Disneyland Railroad is a 3-foot (914 mm) narrow-gauge heritage railroad and attraction in the Disneyland theme park of the Disneyland Resort in Anaheim, California, in the United States. Its route is 1.2 miles (1.9 km) long with four train stations, encircling almost everything in the park. The rail line, which was built by WED Enterprises, is operated with two steam locomotives built by WED and three historic steam locomotives originally built by Baldwin Locomotive Works. The attraction originated as a concept created by Walt Disney, who drew inspiration from the ridable miniature Carolwood Pacific Railroad built in his backyard. Since 1955 when the Disneyland Railroad first opened to the public at the park's grand opening, it has been consistently billed as one of the top attractions, and for many years visitors had to buy a top-tier ticket to ride the train. It is one of the world's most popular steam-powered railroads, with an estimated 6.6 million passengers served each year. (Full article...)		August 7: Raksha Bandhan (Hinduism, 2017); Assyrian Martyrs Day (1933)		Joseph Marie Jacquard (d. 1834) · Richard Sykes (b. 1942) · Frances Oldham Kelsey (d. 2015)		The filmography of Laurel and Hardy, a motion picture comedy team, consists of 106 films released between 1921 and 1951. Together they appeared in 34 silent shorts, 45 sound shorts, and 27 full-length sound feature films. Stan Laurel and Oliver Hardy were established as film comedians prior to their teaming, with Laurel appearing in over 50 silent films and Hardy in over 250. Although they first worked together in the film The Lucky Dog (1921), this was a chance pairing and it was not until 1926 when both separately signed contracts with the Hal Roach film studio that they appeared in movie shorts together. Laurel and Hardy officially became a team the following year, in their eleventh silent short film The Second Hundred Years (1927). The pair remained with the Roach studio until 1940. Between 1941 and 1945 they appeared in eight features and one short for 20th Century Fox and Metro-Goldwyn-Mayer. After finishing their movie commitments Laurel and Hardy concentrated on stage shows, embarking on a music hall tour of Great Britain. (Full list...)		In a Roman Osteria is an oil painting on canvas completed by the Danish painter Carl Bloch in 1866. Commissioned by the merchant Moritz G. Melchior, it depicts the interior of an osteria, with Melchior and some friends in the background. It has been in the collection of the National Gallery of Denmark since 1935.		Painting: Carl Bloch		Wikipedia is hosted by the Wikimedia Foundation, a non-profit organization that also hosts a range of other projects:		This Wikipedia is written in English. Started in 2001 (2001), it currently contains 5,455,325 articles. Many other Wikipedias are available; some of the largest are listed below.		
Rail transport is a means of transferring of passengers and goods on wheeled vehicles running on rails, also known as tracks. It is also commonly referred to as train transport. In contrast to road transport, where vehicles run on a prepared flat surface, rail vehicles (rolling stock) are directionally guided by the tracks on which they run. Tracks usually consist of steel rails, installed on ties (sleepers) and ballast, on which the rolling stock, usually fitted with metal wheels, moves. Other variations are also possible, such as slab track, where the rails are fastened to a concrete foundation resting on a prepared subsurface.		Rolling stock in a rail transport system generally encounters lower frictional resistance than road vehicles, so passenger and freight cars (carriages and wagons) can be coupled into longer trains. The operation is carried out by a railway company, providing transport between train stations or freight customer facilities. Power is provided by locomotives which either draw electric power from a railway electrification system or produce their own power, usually by diesel engines. Most tracks are accompanied by a signalling system. Railways are a safe land transport system when compared to other forms of transport.[Nb 1] Railway transport is capable of high levels of passenger and cargo utilization and energy efficiency, but is often less flexible and more capital-intensive than road transport, when lower traffic levels are considered.		The oldest, man-hauled railways date back to the 6th century BC, with Periander, one of the Seven Sages of Greece, credited with its invention. Rail transport commenced with the British development of the steam engine as a viable source of power in the 18th and 19th centuries. Steam locomotives were first developed in the United Kingdom in the early 19th century. Built by George Stephenson and his son Robert's company Robert Stephenson and Company, the Locomotion No. 1 is the first steam locomotive to carry passengers on a public rail line, the Stockton and Darlington Railway in 1825. George also built the first public inter-city railway line in the world to use steam locomotives, the Liverpool and Manchester Railway which opened in 1830. With steam engines, one could construct mainline railways, which were a key component of the Industrial Revolution. Also, railways reduced the costs of shipping, and allowed for fewer lost goods, compared with water transport, which faced occasional sinking of ships. The change from canals to railways allowed for "national markets" in which prices varied very little from city to city. The invention and development of the railway in the United Kingdom was one of the most important technological inventions of the 19th century.		In the 1880s, electrified trains were introduced, and also the first tramways and rapid transit systems came into being. Starting during the 1940s, the non-electrified railways in most countries had their steam locomotives replaced by diesel-electric locomotives, with the process being almost complete by 2000. During the 1960s, electrified high-speed railway systems were introduced in Japan and later in some other countries. Other forms of guided ground transport outside the traditional railway definitions, such as monorail or maglev, have been tried but have seen limited use. Following decline after World War II due to competition from cars, rail transport has had a revival in recent decades due to road congestion and rising fuel prices, as well as governments investing in rail as a means of reducing CO2 emissions in the context of concerns about global warming.						The history of the growth, decline and restoration to use of rail transport can be divided up into several discrete periods defined by the principal means of motive power used.		The earliest evidence of a railway was a 6-kilometre (3.7 mi) Diolkos wagonway, which transported boats across the Corinth isthmus in Greece during the 6th century BC. Trucks pushed by slaves ran in grooves in limestone, which provided the track element. The Diolkos operated for over 600 years.[1]		Railways began reappearing in Europe after the Dark Ages. The earliest known record of a railway in Europe from this period is a stained-glass window in the Minster of Freiburg im Breisgau in Germany, dating from around 1350.[2] In 1515, Cardinal Matthäus Lang wrote a description of the Reisszug, a funicular railway at the Hohensalzburg Castle in Austria. The line originally used wooden rails and a hemp haulage rope, and was operated by human or animal power. The line still exists, albeit in updated form, and is one of the oldest railways still to operate.[3][4]		By 1550, narrow gauge railways with wooden rails were common in mines in Europe.[5] By the early 17th century, wooden wagonways were common in England and Wales for transporting coal from mines to canal wharfs for transshipment to boats. The world's oldest working railway, built in 1758, is the Middleton Railway in Leeds. In 1764, the first gravity railroad in the United States was built in Lewiston, New York.[6] The first permanent tramway was the Leiper Railroad in 1810.[7]		The first iron plate railway, made with wrought iron plates on top of wooden rails, came into use in 1768.[8] This allowed a variation of gauge to be used. At first only balloon loops could be used for turning, but later, movable points were taken into use that allowed for switching.[9] From the 1790s, iron edge rails began to appear in Great Britain.[10] In 1803, William Jessop opened the Surrey Iron Railway in south London, arguably the world's first horse-drawn public railway.[11] The invention of the wrought iron rail by John Birkinshaw in 1820 allowed the short, brittle, and often uneven, cast iron rails to be extended to 15 feet (4.6 m) lengths.[12] These were succeeded by steel in 1857.[10]		The development of the steam engine during the Industrial Revolution in Great Britain by Thomas Newcomen in 1712,[13] initially for pumping water, spurred ideas for mobile steam locomotives that could haul heavy weights on tracks. James Watt's patented steam engines of 1769 (patent revised in 1782) were heavy, low-pressure engines which were not suitable for use in locomotives. However, in 1804, using high-pressure steam, Richard Trevithick demonstrated the first locomotive-hauled train at Merthyr Tydfil, in South Wales.[14][15] Accompanied with Andrew Vivian, it ran with mixed success,[16] breaking some of the brittle cast-iron plates.[17] Two years later, the first passenger horse-drawn railway was opened nearby between Swansea and Mumbles.[18]		In 1811, John Blenkinsop designed the first successful and practical railway locomotive[19]—a rack railway worked by a steam locomotive between Middleton Colliery and Leeds on the Middleton Railway. His first locomotive, called Salamanca, was built in the following year.[20]:20 In 1825, George Stephenson built the Locomotion for the Stockton and Darlington Railway, north east England, which was the first public steam railway in the world. In 1829, he built the Rocket, which was entered in and won the Rainhill Trials. This success led to Stephenson establishing his company as the pre-eminent builder of steam locomotives for Railways in Great Britain and Ireland, the United States, and much of Europe.[20]:24–30		In 1830, the first intercity route, the Liverpool and Manchester Railway, was opened. The gauge was that used for the early wagon-ways, which had been adopted for the Stockton and Darlington Railway,[21] with a 1,435 mm (4 ft 8 1⁄2 in) width which became known as the international standard gauge, still used by about 60% of the world's railways. This spurred the spread of rail transport outside the British Isles.		By the early 1850s, Great Britain had over 7,000 miles (11,000 km) of railway, a stunning achievement given that only twenty years had elapsed since the opening of the Liverpool and Manchester Railway.[22]		Railroads (as they are known in the US) were built on a far larger scale than those in Continental Europe, both in terms of the distances covered, and also in the loading gauge adopted, which allowed for heavier locomotives and double-deck trains. The railroad era in the United States began in 1829 with the Stourbridge Lion steam locomotive which had been imported from Britain. The John Bull (still the oldest operable engine-powered vehicle in the US of any kind, as of 1981) was imported from Britain in 1831. In 1830, Peter Cooper's locomotive, Tom Thumb, first steamed along 13 miles (21 km) of Baltimore and Ohio railroad track.[23] In 1833, the nation's second railroad ran 136 miles (219 km) from Charleston to Hamburg in South Carolina.[24] Not until the 1850s, though, did railroads offer long distance service at reasonable rates. A journey from Philadelphia to Charleston involved eight different gauges, which meant that passengers and freight had to change trains seven times. Only at places like Bowling Green, Kentucky, were the railroads connected to one another.		The Baltimore and Ohio Railroad that opened in 1830 was the first to evolve from a single line to a network in the United States.[25] By 1831, a steam railway connected Albany and Schenectady, New York, a distance of 16 miles (26 km), which was covered in 40 minutes.[26]		The years between 1850 and 1890 saw phenomenal growth in the US railroad system, which at its peak constituted one third of the world's total mileage.[27][not in citation given] Although the American Civil War placed a temporary halt to major new developments, the conflict did demonstrate the enormous strategic importance of railways at times of war. After the war, major developments include the first elevated railway built in New York in 1867 as well as the symbolically important first transcontinental railroad completed in 1869.[28]		Experiments with electrical railways were started by Robert Davidson in 1838. He completed a battery-powered carriage capable of 6.4 km/h (4 mph). The Gross-Lichterfelde Tramway was the first to use electricity fed to the trains en route, when it opened in 1881. Overhead wires were taken into use in the Mödling and Hinterbrühl Tram in Austria in October 1883. At first, this was taken into use on tramways that, until then, had been horse-drawn tramcars. The first conventional completely electrified railway mainline was the 106 km Valtellina line in Italy that was opened on 4 September 1902.		During the 1890s, many large cities, such as London, Paris and New York City used the new technology to build rapid transit for urban commuting. In smaller cities, tramways became common and were often the only mode of public transport until the introduction of buses in the 1920s. In North America, interurbans became a common mode to reach suburban areas. At first, all electric railways used direct current but, in 1904, the Stubaital Line in Austria opened with alternating current.[29]		Steam locomotives require large pools of labour to clean, load, maintain and run. After World War II, dramatically increased labour costs in developed countries made steam an increasingly costly form of motive power. At the same time, the war had forced improvements in internal combustion engine technology that made diesel locomotives cheaper and more powerful. This caused many railway companies to initiate programmes to convert all unelectrified sections from steam to diesel locomotion.		Following the large-scale construction of motorways after the war, rail transport became less popular for commuting and air transport started taking large market shares from long-haul passenger trains. Most tramways were either replaced by rapid transit or buses, while high transshipment costs caused short-haul freight trains to become uncompetitive. The 1973 oil crisis led to a change of mind set and most tram systems that had survived into the 1970s remain today. At the same time, containerization allowed freight trains to become more competitive and participate in intermodal freight transport. With the 1964 introduction of the Shinkansen high-speed rail in Japan, trains could again have a dominant position on intercity travel. During the 1970s, the introduction of automated rapid transit systems allowed cheaper operation. The 1990s saw an increased focus on accessibility and low-floor trains. Many tramways have been upgraded to light rail and many cities that closed their old tramways have reopened new light railway systems.		Many benchmarks in equipment and infrastructure led to the growing use of railways. Some innovative features taking place in the 19th and 20th centuries included wood cars replaced with all-steel cars, which provided better safety and maintenance; iron rails replaced with steel rails, which provided higher speed and capacity with lower weight and cost; stove-heated cars to steam-heating cars, piped from locomotive; gas lighting to electric lighting, with use of battery/alternator unit beneath the car; development of air conditioning with additional underbody equipment and ice compartment. Some innovative rolling stock included the lightweight, diesel-powered streamliner, which was a modernistic, aerodynamically styled train with flowing contours; then came the ultra-lightweight car with internal combustion engine in each train's power car; others included the dome car, turbined-powered trains, bi-level rolling stock, and the high-tech/high-speed electric trains.[30][page needed]		Even more, in the first half of the 20th century, infrastructure elements adopted technological changes including the continuously welded rail that was 1⁄4 mile (0.40 km) long; concrete tie usage; double tracking major lines; intermodal terminal and handling technology; advances in diesel-electric propulsion to include AC traction systems and propulsion braking systems; and just-in-time inventory control. Beyond technology, even management of systems saw improvements with the adoption of environmental impact concerns; heightened concern of employee and public safety; introduction of urban area rail networks and public agencies to manage them; and downsizing of industry employment with greater use of contractors and consultants.[31]		A train is a connected series of rail vehicles that move along the track. Propulsion for the train is provided by a separate locomotive or from individual motors in self-propelled multiple units. Most trains carry a revenue load, although non-revenue cars exist for the railway's own use, such as for maintenance-of-way purposes. The engine driver (engineer in North America) controls the locomotive or other power cars, although people movers and some rapid transits are under automatic control.		Traditionally, trains are pulled using a locomotive. This involves one or more powered vehicles being located at the front of the train, providing sufficient tractive force to haul the weight of the full train. This arrangement remains dominant for freight trains and is often used for passenger trains. A push-pull train has the end passenger car equipped with a driver's cab so that the engine driver can remotely control the locomotive. This allows one of the locomotive-hauled train's drawbacks to be removed, since the locomotive need not be moved to the front of the train each time the train changes direction. A railroad car is a vehicle used for the haulage of either passengers or freight.		A multiple unit has powered wheels throughout the whole train. These are used for rapid transit and tram systems, as well as many both short- and long-haul passenger trains. A railcar is a single, self-powered car, and may be electrically-propelled or powered by a diesel engine. Multiple units have a driver's cab at each end of the unit, and were developed following the ability to build electric motors and engines small enough to fit under the coach. There are only a few freight multiple units, most of which are high-speed post trains.		Steam locomotives are locomotives with a steam engine that provides adhesion. Coal, petroleum, or wood is burned in a firebox, boiling water in the boiler to create pressurized steam. The steam travels through the smokebox before leaving via the chimney or smoke stack. In the process, it powers a piston that transmits power directly through a connecting rod (US: main rod) and a crankpin (US: wristpin) on the driving wheel (US main driver) or to a crank on a driving axle. Steam locomotives have been phased out in most parts of the world for economical and safety reasons, although many are preserved in working order by heritage railways.		Electric locomotives draw power from a stationary source via an overhead wire or third rail. Some also or instead use a battery. In locomotives that are powered by high voltage alternating current, a transformer in the locomotive converts the high voltage, low current power to low voltage, high current used in the traction motors that power the wheels. Modern locomotives may use three-phase AC induction motors or direct current motors. Under certain conditions, electric locomotives are the most powerful traction.[citation needed] They are also the cheapest to run and provide less noise and no local air pollution.[citation needed] However, they require high capital investments both for the overhead lines and the supporting infrastructure, as well as the generating station that is needed to produce electricity. Accordingly, electric traction is used on urban systems, lines with high traffic and for high-speed rail.		Diesel locomotives use a diesel engine as the prime mover. The energy transmission may be either diesel-electric, diesel-mechanical or diesel-hydraulic but diesel-electric is dominant. Electro-diesel locomotives are built to run as diesel-electric on unelectrified sections and as electric locomotives on electrified sections.		Alternative methods of motive power include magnetic levitation, horse-drawn, cable, gravity, pneumatics and gas turbine.		A passenger train travels between stations where passengers may embark and disembark. The oversight of the train is the duty of a guard/train manager/conductor. Passenger trains are part of public transport and often make up the stem of the service, with buses feeding to stations. Passenger trains provide long-distance intercity travel, daily commuter trips, or local urban transit services. They even include a diversity of vehicles, operating speeds, right-of-way requirements, and service frequency. Passenger trains usually can be divided into two operations: intercity railway and intracity transit. Whereas as intercity railway involve higher speeds, longer routes, and lower frequency (usually scheduled), intracity transit involves lower speeds, shorter routes, and higher frequency (especially during peak hours).[31]		Intercity trains are long-haul trains that operate with few stops between cities. Trains typically have amenities such as a dining car. Some lines also provide over-night services with sleeping cars. Some long-haul trains have been given a specific name. Regional trains are medium distance trains that connect cities with outlying, surrounding areas, or provide a regional service, making more stops and having lower speeds. Commuter trains serve suburbs of urban areas, providing a daily commuting service. Airport rail links provide quick access from city centres to airports.		High-speed rail are special inter-city trains that operate at much higher speeds than conventional railways, the limit being regarded at 200 to 320 kilometres per hour (120 to 200 mph). High-speed trains are used mostly for long-haul service and most systems are in Western Europe and East Asia. The speed record is 574.8 km/h (357.2 mph), set by a modified French TGV.[32][33] Magnetic levitation trains such as the Shanghai airport train use under-riding magnets which attract themselves upward towards the underside of a guideway and this line has achieved somewhat higher peak speeds in day-to-day operation than conventional high-speed railways, although only over short distances. Due to their heightened speeds, route alignments for high-speed rail tend to have shallower grades and broader curves than conventional railways.		Their high kinetic energy translates to higher horsepower-to-ton ratios (e.g. 20 horsepower per short ton or 16 kilowatts per tonne); this allows trains to accelerate and maintain higher speeds and negotiate steep grades as momentum builds up and recovered in downgrades (reducing cut, fill, and tunnelling requirements). Since lateral forces act on curves, curvatures are designed with the highest possible radius. All these features are dramatically different from freight operations, thus justifying exclusive high-speed rail lines if it is economically feasible.[31]		Higher-speed rail services are intercity rail services that have top speeds higher than conventional intercity trains but the speeds are not as high as those in the high-speed rail services. These services are provided after improvements to the conventional rail infrastructure in order to support trains that can operate safely at higher speeds.		Rapid transit is an intracity system built in large cities and has the highest capacity of any passenger transport system. It is usually grade-separated and commonly built underground or elevated. At street level, smaller trams can be used. Light rails are upgraded trams that have step-free access, their own right-of-way and sometimes sections underground. Monorail systems are elevated, medium-capacity systems. A people mover is a driverless, grade-separated train that serves only a few stations, as a shuttle. Due to the lack of uniformity of rapid transit systems, route alignment varies, with diverse rights-of-way (private land, side of road, street median) and geometric characteristics (sharp or broad curves, steep or gentle grades). For instance, the Chicago 'L' trains are designed with extremely short cars to negotiate the sharp curves in the Loop. New Jersey's PATH has similar-sized cars to accommodate curves in the trans-Hudson tunnels. San Francisco's BART operates large cars on its well-engineered routes.[31]		A freight train hauls cargo using freight cars specialized for the type of goods. Freight trains are very efficient, with economy of scale and high energy efficiency. However, their use can be reduced by lack of flexibility, if there is need of transshipment at both ends of the trip due to lack of tracks to the points of pick-up and delivery. Authorities often encourage the use of cargo rail transport due to its environmental profile.[34]		Container trains have become the dominant type in the US for non-bulk haulage. Containers can easily be transshipped to other modes, such as ships and trucks, using cranes. This has succeeded the boxcar (wagon-load), where the cargo had to be loaded and unloaded into the train manually. The intermodal containerization of cargo has revolutionized the supply chain logistics industry, reducing ship costs significantly. In Europe, the sliding wall wagon has largely superseded the ordinary covered wagons. Other types of cars include refrigerator cars, stock cars for livestock and autoracks for road vehicles. When rail is combined with road transport, a roadrailer will allow trailers to be driven onto the train, allowing for easy transition between road and rail.		Bulk handling represents a key advantage for rail transport. Low or even zero transshipment costs combined with energy efficiency and low inventory costs allow trains to handle bulk much cheaper than by road. Typical bulk cargo includes coal, ore, grains and liquids. Bulk is transported in open-topped cars, hopper cars and tank cars.		Railway tracks are laid upon land owned or leased by the railway company. Owing to the desirability of maintaining modest grades, rails will often be laid in circuitous routes in hilly or mountainous terrain. Route length and grade requirements can be reduced by the use of alternating cuttings, bridges and tunnels—all of which can greatly increase the capital expenditures required to develop a right of way, while significantly reducing operating costs and allowing higher speeds on longer radius curves. In densely urbanized areas, railways are sometimes laid in tunnels to minimize the effects on existing properties.		Track consists of two parallel steel rails, anchored perpendicular to members called ties (sleepers) of timber, concrete, steel, or plastic to maintain a consistent distance apart, or rail gauge. Rail gauges are usually categorized as standard gauge (used on approximately 54.8% of the world's existing railway lines), broad gauge, and narrow gauge.[citation needed] In addition to the rail gauge, the tracks will be laid to conform with a Loading gauge which defines the maximum height and width for railway vehicles and their loads to ensure safe passage through bridges, tunnels and other structures.		The track guides the conical, flanged wheels, keeping the cars on the track without active steering and therefore allowing trains to be much longer than road vehicles. The rails and ties are usually placed on a foundation made of compressed earth on top of which is placed a bed of ballast to distribute the load from the ties and to prevent the track from buckling as the ground settles over time under the weight of the vehicles passing above.		The ballast also serves as a means of drainage. Some more modern track in special areas is attached by direct fixation without ballast. Track may be prefabricated or assembled in place. By welding rails together to form lengths of continuous welded rail, additional wear and tear on rolling stock caused by the small surface gap at the joints between rails can be counteracted; this also makes for a quieter ride (passenger trains).		On curves the outer rail may be at a higher level than the inner rail. This is called superelevation or cant. This reduces the forces tending to displace the track and makes for a more comfortable ride for standing livestock and standing or seated passengers. A given amount of superelevation is most effective over a limited range of speeds.		Turnouts, also known as points and switches, are the means of directing a train onto a diverging section of track. Laid similar to normal track, a point typically consists of a frog (common crossing), check rails and two switch rails. The switch rails may be moved left or right, under the control of the signalling system, to determine which path the train will follow.		Spikes in wooden ties can loosen over time, but split and rotten ties may be individually replaced with new wooden ties or concrete substitutes. Concrete ties can also develop cracks or splits, and can also be replaced individually. Should the rails settle due to soil subsidence, they can be lifted by specialized machinery and additional ballast tamped under the ties to level the rails.		Periodically, ballast must be removed and replaced with clean ballast to ensure adequate drainage. Culverts and other passages for water must be kept clear lest water is impounded by the trackbed, causing landslips. Where trackbeds are placed along rivers, additional protection is usually placed to prevent streambank erosion during times of high water. Bridges require inspection and maintenance, since they are subject to large surges of stress in a short period of time when a heavy train crosses.		The inspection of railway equipment is essential for the safe movement of trains. Many types of defect detectors are in use on the world's railroads. These devices utilize technologies that vary from a simplistic paddle and switch to infrared and laser scanning, and even ultrasonic audio analysis. Their use has avoided many rail accidents over the 70 years they have been used.		Railway signalling is a system used to control railway traffic safely to prevent trains from colliding. Being guided by fixed rails which generate low friction, trains are uniquely susceptible to collision since they frequently operate at speeds that do not enable them to stop quickly or within the driver's sighting distance; road vehicles, which encounter a higher level of friction between their rubber tyres and the road surface, have much shorter braking distances. Most forms of train control involve movement authority being passed from those responsible for each section of a rail network to the train crew. Not all methods require the use of signals, and some systems are specific to single track railways.		The signalling process is traditionally carried out in a signal box, a small building that houses the lever frame required for the signalman to operate switches and signal equipment. These are placed at various intervals along the route of a railway, controlling specified sections of track. More recent technological developments have made such operational doctrine superfluous, with the centralization of signalling operations to regional control rooms. This has been facilitated by the increased use of computers, allowing vast sections of track to be monitored from a single location. The common method of block signalling divides the track into zones guarded by combinations of block signals, operating rules, and automatic-control devices so that only one train may be in a block at any time.		The electrification system provides electrical energy to the trains, so they can operate without a prime mover on board. This allows lower operating costs, but requires large capital investments along the lines. Mainline and tram systems normally have overhead wires, which hang from poles along the line. Grade-separated rapid transit sometimes use a ground third rail.		Power may be fed as direct or alternating current. The most common DC voltages are 600 and 750 V for tram and rapid transit systems, and 1,500  and 3,000 V for mainlines. The two dominant AC systems are 15 kV AC and 25 kV AC.		A railway station serves as an area where passengers can board and alight from trains. A goods station is a yard which is exclusively used for loading and unloading cargo. Large passenger stations have at least one building providing conveniences for passengers, such as purchasing tickets and food. Smaller stations typically only consist of a platform. Early stations were sometimes built with both passenger and goods facilities.[35]		Platforms are used to allow easy access to the trains, and are connected to each other via underpasses, footbridges and level crossings. Some large stations are built as culs-de-sac, with trains only operating out from one direction. Smaller stations normally serve local residential areas, and may have connection to feeder bus services. Large stations, in particular central stations, serve as the main public transport hub for the city, and have transfer available between rail services, and to rapid transit, tram or bus services.		Since the 1980s, there has been an increasing trend to split up railway companies, with companies owning the rolling stock separated from those owning the infrastructure. This is particularly true in Europe, where this arrangement is required by the European Union. This has allowed open access by any train operator to any portion of the European railway network. In the UK, the railway track is state owned, with a public controlled body (Network Rail) running, maintaining and developing the track, while Train Operating Companies have run the trains since privatization in the 1990s.[36]		In the U.S., virtually all rail networks and infrastructure outside the Northeast Corridor are privately owned by freight lines. Passenger lines, primarily Amtrak, operate as tenants on the freight lines. Consequently, operations must be closely synchronized and coordinated between freight and passenger railroads, with passenger trains often being dispatched by the host freight railroad. Due to this shared system, both are regulated by the Federal Railroad Administration (FRA) and may follow the AREMA recommended practices for track work and AAR standards for vehicles.[31]		The main source of income for railway companies is from ticket revenue (for passenger transport) and shipment fees for cargo. Discounts and monthly passes are sometimes available for frequent travellers (e.g. season ticket and rail pass). Freight revenue may be sold per container slot or for a whole train. Sometimes, the shipper owns the cars and only rents the haulage. For passenger transport, advertisement income can be significant.		Governments may choose to give subsidies to rail operation, since rail transport has fewer externalities than other dominant modes of transport. If the railway company is state-owned, the state may simply provide direct subsidies in exchange for increased production. If operations have been privatized, several options are available. Some countries have a system where the infrastructure is owned by a government agency or company—with open access to the tracks for any company that meets safety requirements. In such cases, the state may choose to provide the tracks free of charge, or for a fee that does not cover all costs. This is seen as analogous to the government providing free access to roads. For passenger operations, a direct subsidy may be paid to a public-owned operator, or public service obligation tender may be helt, and a time-limited contract awarded to the lowest bidder. Total EU rail subsidies amounted to €73 billion in 2005.[37]		Amtrak, the US passenger rail service, and Canada's Via Rail are private railroad companies chartered by their respective national governments. As private passenger services declined because of competition from automobiles and airlines, they became shareholders of Amtrak either with a cash entrance fee or relinquishing their locomotives and rolling stock. The government subsidizes Amtrak by supplying start-up capital and making up for losses at the end of the fiscal year.[30][page needed]		Trains can travel at very high speed, but they are heavy, are unable to deviate from the track and require a great distance to stop. Possible accidents include derailment (jumping the track), a collision with another train or collision with automobiles, other vehicles or pedestrians at level crossings. The last accounts for the majority of rail accidents and casualties. The most important safety measures to prevent accidents are strict operating rules, e.g. railway signalling and gates or grade separation at crossings. Train whistles, bells or horns warn of the presence of a train, while trackside signals maintain the distances between trains.		An important element in the safety of many high-speed inter-city networks such as Japan's Shinkansen is the fact that trains only run on dedicated railway lines, without level crossings. This effectively eliminates the potential for collision with automobiles, other vehicles or pedestrians, vastly reduces the likelihood of collision with other trains and helps ensure services remain timely.		As in any infrastructure asset, railways must keep up with periodic inspection and maintenance in order to minimize effect of infrastructure failures that can disrupt freight revenue operations and passenger services. Because passengers are considered the most crucial cargo and usually operate at higher speeds, steeper grades, and higher capacity/frequency, their lines are especially important. Inspection practices include track geometry cars or walking inspection. Curve maintenance especially for transit services includes gauging, fastener tightening, and rail replacement.		Rail corrugation is a common issue with transit systems due to the high number of light-axle, wheel passages which result in grinding of the wheel/rail interface. Since maintenance may overlap with operations, maintenance windows (nighttime hours, off-peak hours, altering train schedules or routes) must be closely followed. In addition, passenger safety during maintenance work (inter-track fencing, proper storage of materials, track work notices, hazards of equipment near states) must be regarded at all times. At times, maintenance access problems can emerge due to tunnels, elevated structures, and congested cityscapes. Here, specialized equipment or smaller versions of conventional maintenance gear are used.[31]		Unlike highways or road networks where capacity is disaggregated into unlinked trips over individual route segments, railway capacity is fundamentally considered a network system. As a result, many components are causes and effects of system disruptions. Maintenance must acknowledge the vast array of a route's performance (type of train service, origination/destination, seasonal impacts), line's capacity (length, terrain, number of tracks, types of train control), trains throughput (max speeds, acceleration/deceleration rates), and service features with shared passenger-freight tracks (sidings, terminal capacities, switching routes, and design type).[31]		Rail transport is an energy-efficient[40] but capital-intensive means of mechanized land transport. The tracks provide smooth and hard surfaces on which the wheels of the train can roll with a relatively low level of friction being generated. Moving a vehicle on and/or through a medium (land, sea, or air) requires that it overcomes resistance to its motion caused by friction. A land vehicle's total resistance (in pounds or Newtons) is a quadratic function of the vehicle's speed:		where:		Essentially, resistance differs between vehicle's contact point and surface of roadway. Metal wheels on metal rails have a significant advantage of overcoming resistance compared to rubber-tyred wheels on any road surface (railway – 0.001g at 10 miles per hour (16 km/h) and 0.024g at 60 miles per hour (97 km/h); truck – 0.009g at 10 miles per hour (16 km/h) and 0.090 at 60 miles per hour (97 km/h)). In terms of cargo capacity combining speed and size being moved in a day:		In terms of the horsepower to weight ratio, a slow-moving barge requires 0.2 horsepower per short ton (0.16 kW/t), a railway and pipeline requires 2.5 horsepower per short ton (2.1 kW/t), and truck requires 10 horsepower per short ton (8.2 kW/t). However, at higher speeds, a railway overcomes the barge and proves most economical.[31]		As an example, a typical modern wagon can hold up to 113 tonnes (125 short tons) of freight on two four-wheel bogies. The track distributes the weight of the train evenly, allowing significantly greater loads per axle and wheel than in road transport, leading to less wear and tear on the permanent way. This can save energy compared with other forms of transport, such as road transport, which depends on the friction between rubber tyres and the road. Trains have a small frontal area in relation to the load they are carrying, which reduces air resistance and thus energy usage.		In addition, the presence of track guiding the wheels allows for very long trains to be pulled by one or a few engines and driven by a single operator, even around curves, which allows for economies of scale in both manpower and energy use; by contrast, in road transport, more than two articulations causes fishtailing and makes the vehicle unsafe.		Considering only the energy spent to move the means of transport, and using the example of the urban area of Lisbon, electric trains seem to be on average 20 times more efficient than automobiles for transportation of passengers, if we consider energy spent per passenger-distance with similar occupation ratios.[41] Considering an automobile with a consumption of around 6 l/100 km (47 mpg‑imp; 39 mpg‑US) of fuel, the average car in Europe has an occupancy of around 1.2 passengers per automobile (occupation ratio around 24%) and that one litre of fuel amounts to about 8.8 kWh (32 MJ), equating to an average of 441 Wh (1,590 kJ) per passenger-km. This compares to a modern train with an average occupancy of 20% and a consumption of about 8.5 kW·h/km (31 MJ/km; 13.7 kW·h/mi), equating to 21.5 Wh (77 kJ) per passenger-km, 20 times less than the automobile.		Due to these benefits, rail transport is a major form of passenger and freight transport in many countries. It is ubiquitous in Europe, with an integrated network covering virtually the whole continent. In India, China, South Korea and Japan, many millions use trains as regular transport. In North America, freight rail transport is widespread and heavily used, but intercity passenger rail transport is relatively scarce outside the Northeast Corridor, due to increased preference of other modes, particularly automobiles and airplanes.[30][page needed][42] South Africa, northern Africa and Argentina have extensive rail networks, but some railways elsewhere in Africa and South America are isolated lines. Australia has a generally sparse network befitting its population density but has some areas with significant networks, especially in the southeast. In addition to the previously existing east-west transcontinental line in Australia, a line from north to south has been constructed. The highest railway in the world is the line to Lhasa, in Tibet,[43] partly running over permafrost territory. Western Europe has the highest railway density in the world and many individual trains there operate through several countries despite technical and organizational differences in each national network.		Railways are central to the formation of modernity and ideas of progress.[44] Railways contribute to social vibrancy and economic competitiveness by transporting multitudes of customers and workers to city centres and inner suburbs. Hong Kong has recognized rail as "the backbone of the public transit system" and as such developed their franchised bus system and road infrastructure in comprehensive alignment with their rail services.[45] China's large cities such as Beijing, Shanghai, and Guangzhou recognize rail transit lines as the framework and bus lines as the main body to their metropolitan transportation systems.[46] The Japanese Shinkansen was built to meet the growing traffic demand in the "heart of Japan's industry and economy" situated on the Tokyo-Kobe line.[47]		During much of the 20th century, rail was an invaluable element of military mobilization, allowing for the quick and efficient transport of large numbers of reservists to their mustering-points, and infantry soldiers to the front lines. However, by the 21st century, rail transport - limited to locations on the same continent, and vulnerable to air attack - had largely been displaced by the adoption of aerial transport.		Railways channel growth towards dense city agglomerations and along their arteries, as opposed to highway expansion, indicative of the U.S. transportation policy, which incents development of suburbs at the periphery, contributing to increased vehicle miles travelled, carbon emissions, development of greenfield spaces, and depletion of natural reserves. These arrangements revalue city spaces, local taxes,[48] housing values, and promotion of mixed use development.[49][50]		European development economists have argued that the existence of modern rail infrastructure is a significant indicator of a country's economic advancement: this perspective is illustrated notably through the Basic Rail Transportation Infrastructure Index (known as BRTI Index).[51]		In total, Russian Railways receives 112 billion roubles (around US$1.5 billion) annually from the government.[62]		Current subsidies for Amtrak (passenger rail) are around $1.4 billion.[63] The rail freight industry does not receive subsidies.		In 2014, total rail spending by China was $130 billion and is likely to remain at a similar rate for the rest of the country's next Five Year Period (2016-2020).[64]		The Indian railways are subsidized by around ₹400 billion (US$6.2 billion), of which around 60% goes to commuter rail and short-haul trips.[65][66]				
Coastal geography is the study of the constantly changing region between the ocean and the land, incorporating both the physical geography (i.e. coastal geomorphology, geology and oceanography) and the human geography (sociology and history) of the coast. It includes understanding coastal weathering processes, particularly wave action, sediment movement and weather, and the ways in which humans interact with the coast.						The waves of different strengths that constantly hit against the shoreline are the primary movers and shapers of the coastline. Despite the simplicity of this process, the differences between waves and the rocks they hit result in hugely varying shapes.		The effect that waves have depends on their strength. Strong waves, also called destructive waves, occur on high-energy beaches and are typical of winter. They reduce the quantity of sediment present on the beach by carrying it out to bars under the sea. Constructive, weak waves are typical of low-energy beaches and occur most during summer. They do the opposite to destructive waves and increase the size of the beach by piling sediment up onto the berm.		One of the most important transport mechanisms results from wave refraction. Since waves rarely break onto a shore at right angles, the upward movement of water onto the beach (swash) occurs at an oblique angle. However, the return of water (backwash) is at right angles to the beach, resulting in the net movement of beach material laterally. This movement is known as beach drift (Figure 3). The endless cycle of swash and backwash and resulting beach drift can be observed on all beaches. This may differ between coasts.		Probably the most important effect is longshore drift (LSD)(Also known as Littoral Drift), the process by which sediment is continuously moved along beaches by wave action. LSD occurs because waves hit the shore at an angle, pick up sediment (sand) on the shore and carry it down the beach at an angle (this is called swash). Due to gravity, the water then falls back perpendicular to the beach, dropping its sediment as it loses energy (this is called backwash). The sediment is then picked up by the next wave and pushed slightly further down the beach, resulting in a continual movement of sediment in one direction. This is the reason why long strips of coast are covered in sediment, not just the areas around river mouths, which are the main sources of beach sediment. LSD is reliant on a constant supply of sediment from rivers and if sediment supply is stopped or sediment falls into a submarine canals at any point along a beach, this can lead to bare beaches further along the shore.		LSD helps create many landforms including barrier islands, bay beaches and spits. In general LSD action serves to straighten the coast because the creation of barriers cuts off bays from the sea while sediment usually builds up in bays because the waves there are weaker (due to wave refraction), while sediment is carried away from the exposed headlands. The lack of sediment on headlands removes the protection of waves from them and makes them more vulnerable to weathering while the gathering of sediment in bays (where longshore drift is unable to remove it) protects the bays from further erosion and makes them pleasant recreational beaches.		In tropical regions in particular, plants and animals not only affect the weathering of rocks but are a source of sediment themselves. The shells and skeletons of many organisms are of calcium carbonate and when this is broken down it forms sediment, limestone and clay.		The main physical Weathering process on beaches is salt-crystal growth. Wind carries salt spray onto rocks, where it is absorbed into small pores and cracks within the rocks. There the water evaporates and the salt crystallises, creating pressure and often breaking down the rock. In some beaches calcium carbonate is able to bind together other sediments to form beachrock and in warmer areas dunerock. Wind erosion is also a form of erosion, dust and sand is carried around in the air and slowly erodes rock, this happens in a similar way in the sea were the salt and sand is washed up onto the rocks.		The sea level on earth regularly rises and falls due to climatic changes. During cold periods more of the Earth’s water is stored as ice in glaciers while during warm periods it is released and sea levels rise to cover more land. Sea levels are currently quite high, while just 18,000 years ago during the Pleistocene ice age they were quite low. Global warming may result in further rises in the future, which presents a risk to coastal cities as most would be flooded by only small rises. As sea levels rise, fjords and rias form. Fjords are flooded glacial valleys and rias are flooded river valleys. Fjords typically have steep rocky sides, while rias have dendritic drainage patterns typical of drainage zones. As tectonic plates move about the Earth they can rise and fall due to changing pressures and the presence of glaciers. If a beach is moving upwards relative to other plates this is known as isostatic change and raised beaches can be formed.		This is found in the U.K. as above the line from the Wash to the Severn estuary, the land was covered in ice sheets during the last ice age. The weight of the ice caused northeast Scotland to sink, displacing the southeast and forcing it to rise. As the ice sheets receded the reverse process happened, as the land was released from the weight. At current estimates the southeast is sinking at a rate of about 2 mm per year, with northeast Scotland rising by the same amount.		If the coast suddenly changes direction, especially around an estuary, spits are likely to form. Long shore drift pushes the sediment along the beach but when it reaches a turn as in the diagram, the long shore drift does not always easily turn with it, especially near an estuary where the outward flow from a river may push sediment away from the coast. The area may be also be shielded from wave action, preventing much long shore drift. On the side of the headland receiving weaker waves, shingle and other large sediments will build up under the water where waves are not strong enough to move them along. This provides a good place for smaller sediments to build up to sea level. The sediment, after passing the headland will accumulate on the other side and not continue down the beach, sheltered both by the headland and the shingle.		Slowly over time sediment simply builds on this area, extending the spit outwards, forming a barrier of sand. Once in a while, the wind direction will change and come from the other direction. During this period the sediment will be pushed along in the other direction. The spit will start to grow backwards, forming a 'hook'. After this time the spit will grow again in the original direction. Eventually the spit will not be able to grow any further because it is no longer sufficiently sheltered from erosion by waves, or because the estuary current prevents sediment resting. Usually in the salty but calm waters behind the spit there will form a salt marshland. Spits often form around the breakwater of artificial harbours requiring dredging.		Occasionally, if there is no estuary then it is possible for the spit to grow across to the other side of the bay and form what is called a bar, or barrier. Barriers come in several varieties, but all form in a manner similar to spits. They usually enclose a bay to form a lagoon. They can join two headlands or join a headland to the mainland. When an island is joined to the mainland with a bar or barrier it is known as a tombolo. This usually occurs due to wave refraction, but can also be caused by isostatic change, a change in the level of the land (e.g. Chesil Beach). An example of this is along the Holderness coastline.[citation needed]		
A "shell beach" is a sea beach that routinely has an unusually large accumulation of seashells washed up on it. Seashells are most often the dead empty shells of marine mollusks, but may also include tests or shells of other kinds of marine animals.		The majority of beaches in the world are primarily composed of rock particles such as sand, grit, gravel, pebbles, etc, but in rare cases (including Shell Beach in Western Australia) a beach can be composed entirely of seashells, both broken and whole valves.		One area in the USA that is famous for its shell beaches is Sanibel Island on the Gulf Coast of Florida. In South Africa, the beaches of Jeffreys Bay are famous for shells, as is the Sulu Archipelago in the Philippines.		The phrase "shell beach" has also become a place name for several areas which feature beaches rich in shells:		Related names include:		The phrase "shell beach" has also been used in the following contexts:		
Integrated coastal zone management (ICZM) or Integrated coastal management (ICM) is a process for the management of the coast using an integrated approach, regarding all aspects of the coastal zone, including geographical and political boundaries, in an attempt to achieve sustainability		This concept was born in 1992 during the Earth Summit of Rio de Janeiro. The specifics regarding ICZM is set out in the proceedings of the summit within Agenda 21, Chapter 17.		The European Commission defines the ICZM as follows:-		ICZM is a dynamic, multidisciplinary and iterative process to promote sustainable management of coastal zones. It covers the full cycle of information collection, planning (in its broadest sense), decision making, management and monitoring of implementation. ICZM uses the informed participation and cooperation of all stakeholders to assess the societal goals in a given coastal area, and to take actions towards meeting these objectives. ICZM seeks, over the long-term, to balance environmental, economic, social, cultural and recreational objectives, all within the limits set by natural dynamics. 'Integrated' in ICZM refers to the integration of objectives and also to the integration of the many instruments needed to meet these objectives. It means integration of all relevant policy areas, sectors, and levels of administration. It means integration of the terrestrial and marine components of the target territory, in both time and space.		To further understand the idea of ICZM several aspects can be defined and further explained. The coastal zone, the concept of sustainability and the term integration all within a coastal management context can be individually defined, while the expectations and framework of ICZM can be further explained. This entry uses the example of the New Zealand national framework to illustrate ICZM.						Defining the Coastal zone is of particular importance to the idea of ICZM. But the fuzziness of borders due to the dynamic nature of the coast makes it difficult to clearly define. Most simply the coast can be thought of as an area of interaction between the land and the ocean. Ketchum (1972)[1] defined the area as:		The band of dry land and adjacent ocean space (water and submerged land) in which terrestrial processes and land uses directly affect oceanic processes and uses, and vice versa.		Issues arise with the diversity of features present on the coast and the spatial scales of the interacting systems. Coasts being dynamic in nature are influenced differently all around the world. Influences such as river systems, may reach far inland increasing the complexity and scale of the zone. These issues make it difficult to clearly identify hinterlands and subscribe any subsequent management.		Whilst acknowledging a physical coastal zone, the inclusion of ecosystems, resources and human activity within the zone is important. It is the human activities that warrant management. These activities are responsible for disrupting the natural coastal systems. To add to the complexity of this zone, administrative boundaries use arbitrary lines that dissect the zone, often leading to fragmented management. This sectored approach focuses on specific activities such as land use and fisheries, often leading to adverse effects in another sector.		The dynamic processes that occur within the coastal zones produce diverse and productive ecosystems which have been of great importance historically for human populations.[2] Coastal margins equate to only 8% of the worlds surface area but provide 25% of global productivity. Stress on this environment comes with approximately 70% of the world’s population being within a day’s walk of the coast.[3] Two-thirds of the world’s cities occur on the coast.[4]		Valuable resources such as fish and minerals are considered to be common property and are in high demand for coastal dwellers for subsistence use, recreation and economic development.[5] Through the perception of common property, these resources have been subjected to intensive and specific exploitation. For example; 90% of the world’s fish harvest comes from within national exclusive economic zones, most of which are within the sight of shore.[3] This type of practice has led to a problem that has cumulative effects. The addition of other activities adds to the strain placed on this environment. As a whole, human activity in the coastal zone generally degrades the systems by taking unsustainable quantities of resources. The effects are further exacerbated with the input of pollutant wastes. This provides the need for management. Due to the complex nature of human activity in this zone a holistic approach is required to obtain a sustainable outcome.		The concept behind the idea of ICZM is sustainability. For ICZM to succeed, it must be sustainable. Sustainability entails a continuous process of decision making, so there is never an end-state just a readjustment of the equilibrium between development and the protection of the environment.[6] The concept of Sustainability or sustainable development came to fruition in the 1987 report of the World Commission on Environment and Development, Our Common Future. It stated sustainable development is “to meet the needs of the present without compromising the ability of future generations to meet their own needs”.[7]		Highlighted are three main standpoints which summarise the idea of Sustainable development, they are:		To simplify these points, sustainability should acknowledge the right of humans to live a life that is healthy and productive. It should allow for equal distribution of benefits to all people and in doing so protect the environment through appropriate use.[6]		Sustainability is by no means a set of prescriptive actions, more accurately it is a way of thinking. Adapting this way of thinking paves the way for a longer-term view with a more holistic approach, something successful ICZM can achieve.[8]		As previously stated, for ICZM to be successful it must adhere to the principles that define sustainability and act upon them in ways that are integrated. An optimal balance between environmental protection and the development of economic and social sectors is paramount.[9] As part of the holistic approach ICZM applies, many aspects within a coastal zone are expected to be considered and accounted for. These include but are not limited to: the spatial, functional, legal, policy, knowledge, and participation dimensions.[10] Below are four identified goals of ICZM:		Failure to include these aspects and goals would lead to a form of unsustainable management, undermining the paradigms explicit to ICZM.		The term ‘integration’ can be adopted for many different purposes, it is therefore quite important to define the term in the context of the management of the coastal zone to appreciate the intentions of ICZM. Integration within ICZM occurs in and between many different levels, 5 types of integration that occur within ICZM,[6] are explained below;		Integration among sectors: Within the coastal environment there are many sectors that operate. These human activities are largely economic activities such as tourism, fisheries, and port companies. A sense of co-operation between sectors is the main requirement for sector integration within ICZM. This comes from the realisation of a common goal focused around sustainability and the appreciation of one another within the area.		Integration between land and water elements of the coastal zone: This is the realisation of the physical environment being a whole. The coastal environment is a dynamic relationship between many processes all of which are interdependent. The link must be made between imposing a change on one system or feature and its inevitable ‘flow on’ effects.		Integration among levels of government: Between levels of governance, consistency and co-operation is needed throughout planning and policy making. ICZM is most effective where initiatives have common purpose at local, regional, and national levels. Common goals and actions increase efficiency and mitigate confusion.		Integration between nations: This sees ICZM as an important tool on a global scale. If goals and beliefs are common on a supranational scale, large scale problems could be mitigated or avoided.		Integration among disciplines: Throughout ICZM, knowledge should be accepted from all disciplines. All means of scientific, cultural, traditional, political and local expertise need to be accounted for. By including all these elements a truly holistic approach towards management can be achieved.		The term integration in a coastal management context has many horizontal and vertical aspects, which reflects the complexity of the task and it proves a challenge to implement.		Management must embrace a holistic viewpoint of the functions that makeup the complex and dynamic nature of interactions in the coastal environment.[12] Management framework must be applied to a defined geographical limit (often complicated) and should operate with a high level of integration.[11] Due to the diverse nature of the world’s coastline and coastal environments, it is not possible to create a framework that is ‘one-size-fits-all.’ Different activities, interests and issues also complicate matters. So management will always be unique to countries, regions and ultimately on a local scale.		A common thought process and decision making framework however, can be fairly uniform as a part of ICZM around the world. To achieve the principles set out in sustainable types of management a step by step process can be adhered to.		Firstly, issues and problems need to be identified and assessments of these need to be quantified. This first step will include integration between government, sectoral entities and local residents. The assessments also have to be broad in their application. Once the issues and problems have been identified and weighted, an effective management plan can be made. The plan will be specific to the area in question. Thirdly, the adoption of the plan can be carried out. They can be legally binding statutory plans, strategies or objectives which are generally quite powerful or they can be non-statutory processes and can act as a guide for future development.[8] This duality is largely beneficial as the future can be taken into account, but still provide for a firm stance based in the present.[2] The fourth step is implementation, this active phase includes; law enforcement, education, development etc. The implementation activities will be of course, be as unique as their environments and can take many forms. The last phase is evaluation of the whole process. The principles of sustainability mean that there is no ‘end state.’ ICZM is an ongoing process which should constantly readjust the equilibrium between economic development and the protection of the environment. Feedback is a crucial part of the process and allows for continued effectiveness even when a situation may change. Public participation and stakeholder involvement is essential in ICZM processes, not only in terms of a democratic approach, but also from a technical–instrumental point of view, in order to reduce decisional conflicts (Ioppolo et al., 2013).[13]		≥→×× At the Conference of the Plenipotentiaries on the ICZM Protocol that took place on 20–21 January 2008 in Madrid, the ICZM Protocol was signed. Under the presidency of the Minister of Environment of Spain, H.E. Ms. Cristina Narbona Ruiz, fourteen Contracting Parties of the Barcelona Convention signed the Protocol. These are the following: Algeria, Croatia, France, Greece, Israel, Italy, Malta, Monaco, Montenegro, Morocco, Slovenia, Spain, Syria and Tunisia. All other Parties announced to do so in the very near future. This is the 7th Protocol in the framework of the Barcelona Convention, and the decision to approve the draft text and recommendation to the Conference of the Plenipotentiaries to sign it was taken at the 15th Ordinary Meeting of the Contracting Parties during their meeting in Almeria, on 15–18 January 2008. All the parties are convinced that this Protocol is a crucial milestone in the history of the Mediterranean Action Plan of the United Nations Environment Programme (UNEP/MAP), the first-ever Regional Seas Programme under UNEP's umbrella. It will allow the countries to better manage their coastal zones, as well as to deal with the emerging coastal environmental challenges, such as the climate change.		The ICZM Protocol is a unique legal instrument in the entire international community and the Mediterranean countries are proud of this fact. They are willing to share these experiences with other coastal countries of the world. The signing of the Protocol came after six years of dedicated work of all the Parties. Syria entered history for being the sixth, and "enter-into-force", country for the ICZM Protocol! Namely, the President of the Syrian Arab Republic issued a Legislative Decree No. 85 dated 31 September 2010 for the ratification of the ICZM Protocol. With this 6th ratification, the ICZM Protocol entered into force one month later provided that Syria deposits the instrument of ratification to the depositary country, i.e. Spain. In September 2012, Croatia and Morocco ratified the Protocol, which brought the number of ratifications to 9 (Slovenia, Montenegro, Albania, Spain, France, European Union, Syria, Croatia, Morocco).		The Action Plan for the implementation of the ICZM Protocol 2012-2019 was adopted on the occasion of the CoP 17, held in Paris from 8 to 10 February 2012. The core purposes and objectives of this Action Plan are to implement the Protocol based on country-based planning and regional co-ordination, namely: 1. Support the effective implementation of the ICZM Protocol at regional, national and local levels including through a Common Regional Framework for ICZM; 2. Strengthen the capacities of Contracting Parties to implement the Protocol and use in an effective manner ICZM policies, instruments, tools and processes; and 3. Promote the ICZM Protocol and its implementation within the region, and promote it globally by developing synergies with relevant Conventions and Agreements.		A road-map for the implementation of the ICZM Process, prepared by Priority Actions Programme Regional Activity Centre (PAP/RAC), is available on the Coastal Wiki platform of the PEGASO and ENCORA projects: ICZM Process.		On May 8, 2014 the Israeli Government ratified the ICZM Protocol. This Resolution (#1588) was made in accordance with Article 19(b) of the Government Rules of Procedure. The ICZM Protocol ratification by Israel brings the number of ratifications to 10.		It has become tradition in the Mediterranean to celebrate the Coast Day after it had first been organised in 2007. The main purpose of the Mediterranean Coast Day is to raise awareness of the importance of the coast as both natural and economic resource, as well as to warn of the risks to which it is exposed due to natural phenomena and human actions. September 25 was chosen as the Mediterranean Coast Day to honour the date when Slovenia ratified the ICZM Protocol as the first Mediterranean country to do so. Each year the central Mediterranean celebration is organised in a different country, while other countries organise their own events. Thus, in 2007 and 2008 the central celebration was organised in Sardinia, Italy. In 2009 the host to the central celebration was Turkey, in 2010 Slovenia, in 2011 Algeria, in 2012 Croatia, in 2013 Italy and in 2014 Tunisia. In 2014, a short animated movie “A good climate for change” was produced by PAP/RAC (in co-operation with BONOBO Studio Zagreb, Croatia) for the 2014 Mediterranean Coast Day. The movie was officially launched on the occasion of the central regional celebration of the Mediterranean Coast Day in Tunisia which was organised in the frame of the MedPartnership project.		Major constraints of ICZM are mostly institutional, rather than technological.[10] The ‘top-down’ approach of administrative decision making sees problematisation as a tool promoting ICZM through the idea of sustainability.[10] Community-based ‘bottom-up’ approaches can perceive problems and issues that are specific to a local area. The benefit of this is that the problems are real and acknowledged rather than searched for to fit an imposed strategy or policy. Public consultation and involvement is very important for current ‘top-down’ approaches, as it can incorporate this ‘bottom-up’ idea into the policies made. Prescriptive ‘top-down’ methods have not able to effectively address problems of resource utilization in poor coastal communities as perceptions of the coastal zone differ with regard to developed and developing countries.[10] This leads on to another constraint to ICZM, the idea of common property.		The coastal environment has huge historical and cultural connections with human activity. Its wealth of resources have provided for millennia, with regard to ICZM how does management become legally binding if the dominant perception of the coast is of a common area available to all? And should it?[3] Enforcing restrictions or change to activities within the coastal zone can be difficult as these resources are often very important to people’s livelihoods. The idea of the coast being common property fouls ‘top-down’ approaches. The idea of common property itself is not all that clean, This perception can lead to cumulative exploitation of resources – the very problem this management seeks to extinguish.		New Zealand is quite unique as it uses sustainable management within legislation, with a high level of importance placed on to the coastal environment.[2] The Resource Management Act (RMA) (1991) promoted sustainable development and mandated the preparation of a New Zealand Coastal Policy Statement (NZCPS), a national framework for coastal planning. It is the only national policy statement that was mandatory.[14] All subsequent planning must not be inconsistent with the NZCPS, making it a very important document.[2] Regional authorities are required to produce Regional coastal policy plans under the RMA (1991) but strangely enough, they only need to include the marine environment seaward of the mean high water mark. But many regional councils have chosen to integrate the ‘dry’ landward area within their plans, breaking down the artificial barriers.[2] This attempt at ICZM is still in its early days running into many legislative hurdles and is yet to achieve a fully ecosystems-based approach. But as part of ICZM, evaluation and adoption of changes is important and ongoing changes to the NZCPS in the form of reviews is currently happening.[14] This will provide an excellent stepping stone for future initiatives and the development of a fully integrated form of coastal management.		Preparation of comprehensive management plans for optimum utilization of existent sources and potentials in all developed and developing countries is one of the appropriate approaches for constant and permanent utilization of natural, human and financial sources. The versatility of natural sources in coastal areas has made private and governmental users and investors to participate in this section to gain the utmost profits. Therefore, the necessity of preparation and implementation of management plans for perpetual utilization of existent sources in coastal areas has become inevitable. Iran, possessing some 6000 km of coastline in north and south, owns abundant economic capacities in coastal zones and regarding the versatility of nature and coast operators and management of coastal activities and operations, necessity of attention to Integrated Coastal Zone Management becomes more significant. Such necessity has gained its legal support through ratification of arrangements no. 40 from transportation chapter of third and article no. 63 of fourth economic, social and cultural economic schedule and its executive regulations. The General Director of coasts and ports engineering of Ports and Maritime Organization was detailed to take the studies of ICZM into consideration. The first phase of these studies began in spring 2003 and was fulfilled in autumn 2006. The outcome of this phase was compilation of following reports accomplished by several national and international skilled consultants: 1- Project Methodology 2- Scrutinized scope of services related to studies 3- Investigation of studies' needs and project preparation and performance 4- Study, definition and determination of Iranian coastal zones boundaries 6- Investigation of International concepts, methods and experiences about Integrated Coastal Zone Management 7- Study and investigation of different features of Integrated Coastal Zone Management in Iran 8- Preparation and designation of geographic database 9- Purchasing and preparing basic data The second phase of studies started up in autumn 2005 and since then this phase has been fully accomplished and presented, In which six competent Iranian consultants with some cooperation of international consultants are responsible for preparing the eleven results of second part of the studies.[15]		The European Parliament and the European Council "adopted in 2002 a Recommendation on Integrated Coastal Zone Management which defines the principles sound coastal planning and management. These include the need to base planning on sound and shared knowledge, the need to take a long-term and cross-sector perspective, to pro-actively involve stakeholders and the need to take into account both the terrestrial and the marine components of the coastal zone".[16]		The Integrated Coastal Zone Management (ICZM) appears to be a key element for the sustainable development of these zones. However this recent notion may not be adapted to all cases.[17] The natural disasters Sumatra earthquake and the Indian Ocean tsunami have made a lot of impact on the coastal environment and also the stakeholder's perception on mitigation and management of coastal hazards.[18] Successful implementation is still a major challenge to the idea of ICZM .		
A marine transgression is a geologic event during which sea level rises relative to the land and the shoreline moves toward higher ground, resulting in flooding. Transgressions can be caused either by the land sinking or the ocean basins filling with water (or decreasing in capacity). Transgressions and regressions may be caused by tectonic events such as orogenies, severe climate change such as ice ages or isostatic adjustments following removal of ice or sediment load.		During the Cretaceous, seafloor spreading created a relatively shallow Atlantic basin at the expense of deeper Pacific basin. This reduced the world's ocean basin capacity and caused a rise in sea level worldwide. As a result of this sea level rise, the oceans transgressed completely across the central portion of North America and created the Western Interior Seaway from the Gulf of Mexico to the Arctic Ocean.		The opposite of transgression is regression, in which the sea level falls relative to the land and exposes former sea bottom. During the Pleistocene Ice Ages, so much water was removed from the oceans and stored on land as year-round glaciers that the ocean regressed 120 m, exposing the Bering land bridge between Alaska and Asia.		Sedimentary facies changes may indicate transgressions and regressions and are often easily identified, because of the unique conditions required to deposit each type of sediment. For instance, coarse-grained clastics like sand are usually deposited in nearshore, high-energy environments; fine-grained sediments however, such as silt and carbonate muds, are deposited farther offshore, in deep, low-energy waters.[1]		Thus, a transgression reveals itself in the sedimentary column when there is a change from nearshore facies (such as sandstone) to offshore ones (such as marl), from the oldest to the youngest rocks. A regression will feature the opposite pattern, with offshore facies changing to nearshore ones.[1] The strata represent regressions less clearly, as their upper layers are often marked by an erosional unconformity.		These are both idealized scenarios; in practice identifying transgression or regressions can be more complicated. For instance, a regression may be indicated by a change from carbonates to shale only, or a transgression from sandstone to shale, and so on. Lateral changes in facies are also important; a well-marked transgression sequence in an area where an epeiric sea was deep may be only partial farther away, where the water was shallow. One should consider such factors when interpreting a specific sedimentary column.		
Macadam is a type of road construction, pioneered by Scottish engineer John Loudon McAdam around 1820, in which single-sized crushed stone layers of small angular stones are placed in shallow lifts and compacted thoroughly. A binding layer of stone dust (crushed stone from the original material) may form; it may also, after rolling, be covered with a binder to keep dust and stones together. The method simplified what had been considered state of the art at that point.						Pierre-Marie-Jérôme Trésaguet is sometimes considered the first person to bring post-Roman science to road building. A Frenchman from an engineering family, he worked paving roads in Paris from 1757 to 1764. As chief engineer of road construction of Limoges, he had opportunity to develop a better and cheaper method of road construction. In 1775, Tresaguet became engineer-general and presented his answer for road improvement in France, which soon became standard practice there.[1]		Trésaguet had recommended a roadway consisting of three layers of stones laid on a crowned subgrade with side ditches for drainage. The first two layers consisted of angular hand-broken aggregate, maximum size 3 inches (7.6 cm), to a depth of about 8 inches (20 cm). The third layer was about 2 inches (5 cm) thick with a maximum aggregate size of 1 inch (2.5 cm).[2] This top level surface permitted a smoother shape and protected the larger stones in the road structure from iron wheels and horse hooves. To keep the running surface level with the countryside, this road was put in a trench, which created drainage problems. These problems were addressed by changes that included digging deep side ditches, making the surface as solid as possible, and constructing the road with a difference in elevation (height) between the two edges, that difference being referred to interchangeably as the road's camber or cross slope.[2]		Thomas Telford, born in Dumfriesshire Scotland,[3] was a surveyor and engineer who applied Tresaguet's road building theories. In 1801 Telford worked for the British Commission of Highlands Roads and Bridges. He became director of the Holyhead Road Commission between 1815 and 1830. Telford extended Tresaguet's theories, but emphasized high-quality stone. He recognized that some of the road problems of the French could be avoided by using cubical stone blocks.[4]		Telford used 30 cm × 25 cm × 15 cm (11.8 in × 9.8 in × 5.9 in)[dubious – discuss] partially shaped paving stones (pitchers), with a slight flat face on the bottom surface. He turned the other faces more vertically than Tresaguet's method. The longest edge was arranged crossways to the traffic direction, and the joints were broken in the method of conventional brickwork, but with the smallest faces of the pitcher forming the upper and lower surfaces.[4]		Broken stone was wedged into the spaces between the tapered perpendicular faces to provide the layer with good lateral control. Telford kept the natural formation level and used masons to camber the upper surface of the blocks. He placed a 6-inch (15 cm) layer of stone no bigger than 6 cm (2.4 in) on top of the rock foundation. To finish the road surface he covered the stones with a mixture of gravel and broken stone. This structure came to be known as "Telford pitching." Telford's road depended on a resistant structure to prevent water from collecting and corroding the strength of the pavement. Telford raised the pavement structure above ground level whenever possible.		Where the structure could not be raised, Telford drained the area surrounding the roadside. Previous road builders in Britain ignored drainage problems and Telford's rediscovery of these principles was a major contribution to road construction.[5] Though notably of around the same time, John Metcalf was a strong advocate that drainage was in-fact an important factor to road construction, and astonished colleagues by building dry roads through marshland. He accomplished this by installing a layer of brushwood and heather.		John Loudon McAdam was born in Ayr, Scotland in 1756. In 1787 he became a trustee of the Ayrshire Turnpike in the Scottish Lowlands and during the next seven years this hobby became an obsession. He moved to Bristol, England in 1802 and became a Commissioner for Paving in 1806.[7] On 15 January 1816 he was elected Surveyor-General of roads for the Turnpike Trust, and was now responsible for 149 miles of road.[7] McAdam first put his ideas about road construction into major practice, the first 'macadamised' stretch of road being Marsh Road at Ashton Gate, Bristol.[7] He also began to actively propagate his ideas in two booklets called Remarks (or Observations) on the Present System of Roadmaking, (which ran nine editions between 1816 and 1827) and A Practical Essay on the Scientific Repair and Preservation of Public Roads, published in 1819.[8]		McAdam's method was simpler, yet more effective at protecting roadways: he discovered that massive foundations of rock upon rock were unnecessary, and asserted that native soil alone would support the road and traffic upon it, as long as it was covered by a road crust that would protect the soil underneath from water and wear.[9]		Unlike Telford and other road builders of the time, McAdam laid his roads as level as possible. His 30-foot-wide (9.1 m) road required only a rise of 3 inches (7.6 cm) from the edges to the centre. Cambering and elevation of the road above the water table enabled rain water to run off into ditches on either side.[10]		Size of stones was central to the McAdam's road building theory. The lower 20-centimetre (7.9 in) road thickness was restricted to stones no larger than 7.5 centimetres (3.0 in). The upper 5-centimetre (2.0 in) layer of stones was limited to 2 centimetres (0.79 in) size and stones were checked by supervisors who carried scales. A workman could check the stone size himself by seeing if the stone would fit into his mouth. The importance of the 2 cm stone size was that the stones needed to be much smaller than the 10 cm width of the iron carriage tyres that travelled on the road.[5]		McAdam believed that the "proper method" of breaking stones for utility and rapidity was accomplished by people sitting down and using small hammers, breaking the stones so that none of them was larger than six ounces in weight. He also wrote that the quality of the road would depend on how carefully the stones were spread on the surface over a sizeable space, one shovelful at a time.[11]		McAdam directed that no substance that would absorb water and affect the road by frost should be incorporated into the road. Neither was anything to be laid on the clean stone to bind the road. The action of the road traffic would cause the broken stone to combine with its own angles, merging into a level, solid surface that would withstand weather or traffic.[12]		Through his road-building experience McAdam had learned that a layer of broken angular stones would act as a solid mass and would not require the large stone layer previously used to build roads. Keeping the surface stones smaller than the tyre width made a good running surface for traffic. The small surface stones also provided low stress on the road, so long as it could be kept reasonably dry.[13]		The first macadam road built in the United States was constructed between Hagerstown and Boonsboro, Maryland and was named at the time Boonsborough Turnpike Road. This was the last section of unimproved road between Baltimore on the Chesapeake Bay to Wheeling on the Ohio River. Stagecoaches traveling the Hagerstown to Boonsboro road in the winter took 5 to 7 hours to cover the 10-mile (16 km) stretch.[15][16] This road was completed in 1823, using McAdam's road techniques, except that the finished road was compacted with a cast-iron roller instead of relying on road traffic for compaction.[17][15][16] The second American road built using McAdam principles was the Cumberland Road which was 73 miles (117 km) long and was completed in 1830 after five years of work.[15][16]		McAdam's renown is due to his effective and economical construction, which was a great improvement over the methods used by his generation. He emphasized that roads could be constructed for any kind of traffic, and he helped to alleviate the resentment travelers felt toward increasing traffic on the roads. His legacy lies in his advocacy of effective road maintenance and management. He advocated a central road authority and the trained professional official, who could be paid a salary that would keep him from corruption. This professional could give his entire time to his duties and be held responsible for his actions.[18]		McAdam's road building technology was applied to roads by other engineers. One of these engineers was Richard Edgeworth, who filled the gaps between the surface stones with a mixture of stone dust and water, providing a smoother surface for the increased traffic using the roads.[19] This basic method of construction is sometimes known as water-bound macadam. Although this method required a great deal of manual labour, it resulted in a strong and free-draining pavement. Roads constructed in this manner were described as "macadamized."[19]		With the advent of motor vehicles, dust became a serious problem on macadam roads. The area of low air pressure created under fast-moving vehicles sucked dust from the road surface, creating dust clouds and a gradual unraveling of the road material.[20] This problem was approached by spraying tar on the surface to create tar-bound macadam. On March 13, 1902 in Monaco, a Swiss doctor, Ernest Guglielminetti, came upon the idea of using tar from Monaco's Gasworks for binding the dust.[21] Later a mixture of coal tar and ironworks slag, patented by Edgar Purnell Hooley as tarmac, was introduced.		A more durable road surface (modern mixed asphalt pavement) sometimes referred to in the US as blacktop, was introduced in the 1920s. This pavement method mixed the aggregates into the asphalt with the binding material before they were laid. The macadam surface method laid the stone and sand aggregates on the road and then sprayed it with the binding material.[22] While macadam roads have now been resurfaced in most developed countries, some are preserved along stretches of roads such as the United States' National Road.[citation needed]		Because of the historic use of macadam as a road surface, roads in some parts of the United States (as parts of Pennsylvania) are often referred to as macadam, even though they might be made of asphalt or concrete. Similarly, the term "tarmac" is sometimes colloquially misapplied to asphalt roads or aircraft runways.[23]				
1 French Land Register data, which excludes lakes, ponds, glaciers > 1 km² (0.386 sq mi or 247 acres) and river estuaries.		Nice (/ˈniːs/, French pronunciation: ​[nis]; Niçard Occitan: Niça, classical norm, or Nissa, nonstandard, pronounced [ˈnisa]; Italian: Nizza [ˈnittsa]; Greek: Νίκαια; Latin: Nicaea) is the fifth most populous city in France and the capital of the Alpes-Maritimes département. The urban area of Nice extends beyond the administrative city limits, with a population of about 1 million[1][2] on an area of 721 km2 (278 sq mi).[1] Located in the French Riviera, on the south east coast of France on the Mediterranean Sea, at the foot of the Alps, Nice is the second-largest French city on the Mediterranean coast and the second-largest city in the Provence-Alpes-Côte d'Azur region after Marseille. Nice is about 13 kilometres (8 miles) from the principality of Monaco, and its airport is a gateway to the principality as well.		The city is nicknamed Nice la Belle (Nissa La Bella in Niçard), which means Nice the Beautiful, which is also the title of the unofficial anthem of Nice, written by Menica Rondelly in 1912.		The area of today's Nice contains Terra Amata, an archaeological site which displays evidence of a very early use of fire. Around 350 BC, Greeks of Marseille founded a permanent settlement and called it Nikaia, after Nike, the goddess of victory.[3] Through the ages, the town has changed hands many times. Its strategic location and port significantly contributed to its maritime strength. For centuries it was a dominion of Savoy, and was then part of France between 1792 and 1815, when it was returned to Piedmont-Sardinia until its re-annexation by France in 1860.		The natural beauty of the Nice area and its mild Mediterranean climate came to the attention of the English upper classes in the second half of the 18th century, when an increasing number of aristocratic families took to spending their winters there. The city's main seaside promenade, the Promenade des Anglais ("Walkway of the English') owes its name to visitors to the resort.[4] For decades now, the picturesque Nicean surroundings have attracted not only those in search of relaxation, but also those seeking inspiration. The clear air and soft light have particularly appealed to some of Western culture's most outstanding painters, such as Marc Chagall, Henri Matisse, Niki de Saint Phalle and Arman. Their work is commemorated in many of the city's museums, including Musée Marc Chagall, Musée Matisse and Musée des Beaux-Arts.[5] Nice has the second largest hotel capacity in the country[6] and it is one of its most visited cities, receiving 4 million tourists every year.[7] It also has the third busiest airport in France, after the two main Parisian ones.[8] It is the historical capital city of the County of Nice (Comté de Nice).						The first known hominid settlements in the Nice area date back about 400,000 years;[9] the Terra Amata archeological site shows one of the earliest uses of fire, construction of houses, and flint findings dated to around 230,000 years ago.[10] Nice (Nicaea) was probably founded around 350 BC by the Greeks of Massalia (Marseille), and was given the name of Nikaia (Νίκαια) in honour of a victory over the neighbouring Ligurians; Nike (Νίκη) was the Greek goddess of victory. The city soon became one of the busiest trading ports on the Ligurian coast; but it had an important rival in the Roman town of Cemenelum, which continued to exist as a separate city until the time of the Lombard invasions. The ruins of Cemenelum are in Cimiez, now a district of Nice.		In the 7th century, Nice joined the Genoese League formed by the towns of Liguria. In 729 the city repulsed the Saracens; but in 859 and again in 880 the Saracens pillaged and burned it, and for most of the 10th century remained masters of the surrounding country.		During the Middle Ages, Nice participated in the wars and history of Italy. As an ally of Pisa it was the enemy of Genoa, and both the King of France and the Holy Roman Emperor endeavoured to subjugate it; but in spite of this it maintained its municipal liberties. During the 13th and 14th centuries the city fell more than once into the hands of the Counts of Provence, but it regained its independence even though related to Genoa.		The medieval city walls surrounded the Old Town. The landward side was protected by the River Paillon, which was later covered over and is now the tram route towards the Acropolis.		The east side of the town was protected by fortifications on Castle Hill. Another river flowed into the port on the east side of Castle Hill. Engravings suggest that the port area was also defended by walls.		Under Monoprix in Place de Garibaldi are excavated remains of a well-defended city gate on the main road from Turin.		In 1388 the commune placed itself under the protection of the Counts of Savoy. Nice participated – directly or indirectly – in the history of Savoy until 1860.		The maritime strength of Nice now rapidly increased until it was able to cope with the Barbary pirates; the fortifications were largely extended and the roads to the city improved. In 1561 Emmanuel Philibert, Duke of Savoy abolished the use of Latin as an administrative language and established the Italian language as the official language of government affairs in Nice.		During the struggle between Francis I and Charles V great damage was caused by the passage of the armies invading Provence; pestilence and famine raged in the city for several years. In 1538, in the nearby town of Villeneuve-Loubet, through the mediation of Pope Paul III, the two monarchs concluded a ten years' truce.[11]		In 1543, Nice was attacked by the united Franco-Ottoman forces of Francis I and Barbarossa Hayreddin Pasha, in the Siege of Nice; though the inhabitants repulsed the assault which followed the terrible bombardment, they were ultimately compelled to surrender, and Barbarossa was allowed to pillage the city and to carry off 2,500 captives. Pestilence appeared again in 1550 and 1580.		In 1600, Nice was briefly taken by the Duke of Guise. By opening the ports of the county to all nations, and proclaiming full freedom of trade (1626), the commerce of the city was given great stimulus, the noble families taking part in its mercantile enterprises.		Captured by Nicolas Catinat in 1691, Nice was restored to Savoy in 1696; but it was again besieged by the French in 1705, and in the following year its citadel and ramparts were demolished.		The Treaty of Utrecht (1713) once more gave the city back to the Duke of Savoy, who was on that same occasion recognised as King of Sicily. In the peaceful years which followed, the "new town" was built. From 1744 until the Treaty of Aix-la-Chapelle (1748) the French and Spaniards were again in possession. In 1775 the king, who in 1718 had swapped his sovereignty of Sicily for the Kingdom of Sardinia, destroyed all that remained of the ancient liberties of the commune. Conquered in 1792 by the armies of the First French Republic, the County of Nice continued to be part of France until 1814; but after that date it reverted to the Kingdom of Piedmont-Sardinia.		After the Treaty of Turin was signed in 1860 between the Sardinian king and Napoleon III, the County was again and definitively ceded to France as a territorial reward for French assistance in the Second Italian War of Independence against Austria, which saw Lombardy united with Piedmont-Sardinia. The cession was ratified by a regional referendum: over 25,000 electors out of a total of 30,700 were in favour of the attachment to France. Savoy was also transferred to the French crown by similar means. Giuseppe Garibaldi, born in Nice, opposed the cession to France, arguing that the ballot was rigged by the French. Italian irredentists considered the acquisition of Nice to be one of their main nationalist goals, along with Istria, Dalmatia, Corsica and Trentino. In 1942–1943 the city was occupied and administered by Italy.		The 20th century saw the arrival of modern transportation. In 1900, the Tramway de Nice electrified its horse-drawn streetcars and spread its network to the entire département from Menton to Cagnes-sur-Mer. By the 1930s more bus connections were added in the area. In the 1930s Nice hosted international car racing in the Formula Libre (predecessor to Formula One) on the so-called Circuit Nice. The circuit started along the waterfront just south of the Jardin Albert I, then headed westward along the Promenade des Anglais followed by a hairpin turn at the Hotel Negresco to come back eastward and around the Jardin Albert I before heading again east along the beach on the Quai des Etats-Unis.		As war broke out in September 1939, Nice became a city of refuge for many displaced foreigners, notably Jews fleeing the Nazi progression into Eastern Europe. From Nice many sought further shelter in the French colonies, Morocco and North and South America. After July 1940 and the establishment of the Vichy Regime, antisemitic aggressions accelerated the exodus, starting in July 1941 and continuing through 1942. On 26 August 1942, 655 Jews of foreign origin were rounded up by the Laval government and interned in the Auvare barracks. Of these, 560 were deported to Drancy internment camp on 31 August 1942. Due to the activity of the Jewish banker Angelo Donati and of the Capuchin friar Père Marie-Benoît the local authorities hindered the application of anti-Jewish Vichy laws.[12]		The first résistants to the new regime were a group of High School seniors of the Lycée de Nice, now Lycée Masséna, in September 1940, later arrested and executed in 1944 near Castellane. The first public demonstrations occurred on 14 July 1942 when several hundred protesters took to the streets along the Avenue de la Victoire and in the Place Masséna. In November 1942 German troops moved into most of unoccupied France, but Italian troops moved into a smaller zone including Nice. A certain ambivalence remained among the population, many of whom were recent immigrants of Italian ancestry. However, the resistance gained momentum after the Italian surrender in 1943 when the German army occupied the former Italian zone. Reprisals intensified between December 1943 and July 1944, when many partisans were tortured and executed by the local Gestapo and the French Milice. Nice was also heavily bombarded by American aircraft in preparation for the Allied landing in Provence (1000 dead or wounded and more than 5600 people homeless) and famine ensued during summer 1944. American paratroopers entered the city on 30 August 1944 and Nice was finally liberated. The consequences of the war were heavy: the population decreased by 15% and economic life was totally disrupted.		In the second half of the 20th century, Nice enjoyed an economic boom primarily driven by tourism and construction. Two men dominated this period: Jean Médecin, mayor for 33 years from 1928 to 1943 and from 1947 to 1965, and his son Jacques, mayor for 24 years from 1966 to 1990. Under their leadership, there was extensive urban renewal, including many new constructions. These included the convention centre, theatres, new thoroughfares and expressways. The arrival of the Pieds-Noirs, refugees from Algeria after 1962 independence, also gave the city a boost and somewhat changed the make-up of its population and traditional views. By the late 1980s, rumors of political corruption in the city government surfaced; and eventually formal accusations against Jacques Médecin forced him to flee France in 1990. Later arrested in Uruguay in 1993, he was extradited back to France in 1994, convicted of several counts of corruption and associated crimes and sentenced to imprisonment.		On 16 October 1979, a landslide and an undersea slide caused two tsunamis that hit the western coast of Nice; these events killed between 8 and 23 people.		In February 2001, European leaders met in Nice to negotiate and sign what is now the Treaty of Nice, amending the institutions of the European Union.		In 2003, local Chief Prosecutor Éric de Montgolfier alleged that some judicial cases involving local personalities had been suspiciously derailed by the local judiciary, which he suspected of having unhealthy contacts through Masonic lodges with the defendants. A controversial official report stated later that Montgolfier had made unwarranted accusations.		On 14 July 2016, a truck was deliberately driven into a crowd of people by Mohamed Lahouaiej-Bouhlel on the Promenade des Anglais. The crowd was watching a fireworks display in celebration of Bastille Day.[13] Eighty-seven people were killed, including the perpetrator, who was shot dead by police.[14][15] Another 202 were injured, with 52 in critical care and 25 in intensive care, according to the Paris prosecutor.[16]		The coat of arms of Nice appeared for the first time in a copy of the Regulations of Amadeus VIII, probably written around 1430.[17] The Nice is symbolised by a red eagle on white background, placed on three mountains, which can be described in French heraldic language as "d'argent à une aigle de gueule posée sur trois coupeaux".[17] ("Upon argent a red eagle is displayed, posed upon three mounds.") The arms have only undergone minor changes: the eagle has become more and more stylised, it now "wears" a coronet for the County of Nice, and the three mountains are now surrounded by a stylised sea.[17]		The presence of the eagle, an imperial emblem, shows that these arms are related to the power of the House of Savoy. The eagle standing over the three hills is a depiction of Savoy, referring to its domination over the country around Nice.[17] The combination of white and red (argent and gules) is a reference to the colours of the flag of Savoy.[17] The three mountains symbolise a territorial honour, without concern for geographic realism.[17]		Located in the Provence-Alpes-Côte d'Azur region, Nice is a commune and the prefecture (administrative capital) of the Alpes-Maritimes département. However, it is also the largest city in France that is not a regional capital; the much larger Marseille is its regional capital. Christian Estrosi was elected as mayor in 2008. He was reelected for a second term in April 2014 ( that will end in 2020). He is a member of the Republicans (formerly the Union for a Popular Movement), the party supporting former President Nicolas Sarkozy. He resigned in June 2016. Philippe Pradal replaced him as mayor on 13 June 2016.[18] On 16 May 2017, he became mayor again after resigning from his seat as president of the regional council.[19]		The city is divided over 9 cantons: Nice-1, 2, 3, 4, 5, 6, 7, 8 and 9.		Nice has a hot-summer Mediterranean climate (Köppen: Csa), enjoying mild winters with moderate rainfall. It is one of the warmest Mediterranean climates for its latitude. Summers are warm to hot, dry, and sunny. Rainfall is rare in this season, and a typical July month only records one or two days with measurable rainfall. The temperature is typically above 20 °C (68 °F) and frequently reaches 30 °C (86 °F). The climate data is recorded from the airport, located just metres from the sea. Summer temperatures, therefore, are often higher in the city. The average maximum temperature in the warmest months of July and August is about 27 °C (81 °F). The highest recorded temperature was 37.7 °C (99.9 °F) on 1 August 2006. Autumn generally starts sunny in September and becomes more cloudy and rainy towards October, while temperatures usually remain above 20 °C (68 °F) until November where days start to cool down to around 17 °C (63 °F). Winters are characterised by mild days (11 to 17 °C (52 to 63 °F)), cool nights (4 to 9 °C (39 to 48 °F)) and variable weather. Days can be either sunny and dry or damp and rainy. Frost is unusual and snowfalls are so extremely rare that they are remembered by inhabitants as special events. The average minimum temperature in January is around 5 °C (41 °F). Spring starts mild and rainy in late March, and is increasingly warm and sunny towards June.		The natural vegetation of Nice is typical for a Mediterranean landscape, with a heavy representation of broadleaf evergreen shrubs. Trees tend to be scattered but form dense forests in some areas. Large native tree species include evergreens such as holm oak, stone pine and arbutus. Many introduced species grow in parks and gardens. Palms, eucalyptus and citrus fruits are among the trees which give Nice a subtropical appearance. But there are also species familiar to temperate areas around the world; examples include horse chestnut, linden and even Norway spruce.		Geographically, Nice consists of two large bays. Villefranche-sur-Mer sits on an enclosed bay, while the main expanse of the city lies between the old port city and the Aeroport de Côte d'Azur, across a gently curving bay. The city rises from the flat beach into gentle rising hills, then is bounded by surrounding mountains that represent the Southern and nearly the Western extent of the Ligurian Alps range.		Nice is the seat of the Chambre de commerce et d'industrie Nice Côte d'Azur. It manages the Nice - Côte d'Azur Airport and the Cannes - Mandelieu Airport, as well as the Port of Nice. Investors from France and abroad can benefit from the assistance of the Côte d'Azur Economic Development Agency Team Côte d'Azur.		Among tourists, Nice is the second most popular French city after Paris[citation needed], a fact which, combined with the difficulties of land travel at long distance (partly because of the Alps), allows it to have the third busiest airport in France in terms of passenger numbers (close to 10,000,000 passengers in 2005). It is easily accessible, being less than 6 hours from Paris by train, and the airport is located just minutes away from the city.		Nice has one conference centre: the Palais des Congrès Acropolis. The city also has several business parks, including l'Arenas, Nice the Plain, Nice Méridia, Saint Isidore, and the Northern Forum.		In addition, the city features several shopping centres such as Nicetoile, Nice TNL, Nice Lingostière, Northern Forum, St-Isidore, the Trinity (around the Auchan hypermarket) and Cap3000 in Saint-Laurent-du-Var.		Sophia Antipolis is a technology park northwest of Antibes. Much of the park is within the commune of Valbonne. Established between 1970 and 1984, it primarily houses companies in the fields of computing, electronics, pharmacology and biotechnology. Several institutions of higher learning are also located here, along with the European headquarters of W3C. The park is named after Sophie Glikman-Toumarkine, the wife of French Senator Pierre Laffitte, founder of the park, and incidentally, Sophia, the goddess of wisdom. The second half of the park's name is derived from Antipolis, the ancient Greek name of Antibes.		The Nice metropolitan area had a GDP amounting to $47.7 billion, and $34,480 per capita,[23] slightly lower than the French average.		The port of Nice is also known as Lympia port. This name comes from the Lympia spring which fed a small lake in a marshy zone where work on the port was started in 1745. Today this is the principal harbour installation of Nice – there is also a small port in the Carras district. The port is the first port cement manufacturer in France, linked to the treatment plants of the rollers of the valley of Paillon. Fishing activities remain but the number of professional fishermen is now less than 10. Nice, being the point of continental France nearest to Corsica, has ferry connections with the island developed with the arrival of NGV (navires à grande vitesse) or high-speed craft. Two companies provide the connections: SNCM, a partially public company and Corsica Ferries – Sardinia Ferries, an entirely private company. Located in front of the port, the Place Cassini has been renamed Place of Corsica.		Nice Côte d'Azur Airport is the third most important airport in France after Charles de Gaulle Airport and Orly Airport, both in Paris. It is on the Promenade des Anglais, near l'Arénas and has two terminals. Due to its proximity to the Principality of Monaco, it also serves as that city–state's airport. A helicopter service provided by Heli Air Monaco and Monacair links the city and airport; it averages 39 flights a day. It is run by the Chamber of Commerce and the Nice Côte d'Azur industry.[clarification needed] Its director is Hervé de Place, director of the Côte d'Azur airports, which includes Cannes - Mandelieu Airport. In 2009, 9,830,987 passengers travelled through the airport.[24]		The main railway station is Nice-Ville, served both by high speed TGV trains connecting Paris and Nice in less than 6 hours and by local commuter TER services. Marseille is reached in 2.5 hours. Nice also has international connections to Italy, Switzerland, Belgium, and Russia.[25] Nice is also served by several suburban stations including Nice St-Augustin, Nice St-Roch and Nice Riquier.		Nice is also the southern terminus of the independently run Chemins de Fer de Provence railway line which connects the city with Digne in approximatively 4 hours. A metro-like suburban service is also provided on the southern part of the line.		Tramway de Nice began operating horse-drawn trams in 1879. Electrified in 1900, the combined length of the network reached 144 km (89.48 mi) by 1930. The replacement of trams with trolleybuses began in 1948 and was completed in 1953. In 2007, the new Tramway de Nice linked the northern and eastern suburbs via the city centre. Two other lines are currently in the planning stage. The second line will run east-west from Place Masséna to the Nice Côte d'Azur Airport,[26] extending to Cagnes-sur-Mer and Le Port, while the third line will provide a connection to the future TGV Nice Saint-Augustin Lingostière rail station.[27]		The A8 autoroute and the Route nationale 7 pass through the Nice agglomeration, linking Marseille with Italy.		The Promenade des Anglais ("Promenade of the English") is a promenade along the Baie des Anges ("Bay of the Angels"), which is a bay of the Mediterranean, in Nice. Before Nice was urbanised, the coastline at Nice was just bordered by a deserted stretch of beach covered with large pebbles. The first houses were located on higher ground well away from the sea, as wealthy tourists visiting Nice in the 18th century did not come for the beach, but for the gentle winter weather. The areas close to the water were home to Nice's dockworkers and fishermen.		In the second half of the 18th century, many wealthy English people took to spending the winter in Nice, enjoying the panorama along the coast. When a particularly harsh winter up north brought an influx of beggars to Nice, some of the rich Englishmen proposed a useful project for them: the construction of a walkway (chemin de promenade) along the sea.		The city of Nice, intrigued by the prospect of a pleasant promenade, greatly increased the scope of the work. The Promenade was first called the Camin dei Anglès (the English Way) by the Niçois in their native dialect, Nissart. After the annexation of Nice by France in 1860 it was rechristened La Promenade des Anglais, replacing the former Nissart name with its French translation.		The Hotel Negresco on the Promenade des Anglais was named after Henri Negresco (1868–1920) who had the palatial hotel constructed in 1912. In keeping with the conventions of the time, when the Negresco first opened in 1913 its front opened on the side opposite the Mediterranean.		Another place worth mentioning is the small street parallel to the Promenade des Anglais, leading from Nice's downtown, beginning at Place Masséna and running parallel to the promenade in the direction of the airport for a short distance of about 4 blocks. This section of the city is referred to as the "Zone Pietonne", or "Pedestrian Zone". Cars are not allowed (with exception to delivery trucks), making this avenue a popular walkway. Here, tourists can find a fine selection of restaurants, specializing in various types of cuisine, including Niçoise, French, Japanese, Chinese, Vietnamese, Spanish and Italian. There is also a large selection of cafés where one can sit and enjoy an apéritif, as well as several bakeries with coffee, cake, and a terrace. There are also plenty of small shops selling clothing, shoes, and souvenirs.		Old Nice is also home to the Opéra de Nice. It was constructed at the end of the 19th century under the design of François Aune, to replace King Charles Félix's Maccarani Theater. Today, it is open to the public and provides a regular program of performances.		Other sights include:		The Place Masséna is the main square of the city. Before the Paillon River was covered over, the Pont-Neuf was the only practicable way between the old town and the modern one. The square was thus divided into two parts (North and South) in 1824. With the demolition of the Masséna Casino in 1979, the Place Masséna became more spacious and less dense and is now bordered by red ochre buildings of Italian architecture.		The recent rebuilding of the tramline gave the square back to the pedestrians, restoring its status as a real Mediterranean square. It is lined with palm trees and stone pines, instead of being the rectangular roundabout of sorts it had become over the years. Since its construction, the Place Masséna has always been the spot for great public events. It is used for concerts, and particularly during the summer festivals, the Corso carnavalesque (carnival parade) in February, the military procession of 14 July (Bastille Day) or other traditional celebrations and banquets.		The Place Masséna is a two-minute walk from the Promenade des Anglais, old town, town centre, and Albert I Garden (Jardin Albert Ier). It is also a large crossroads between several of the main streets of the city: avenue Jean Médecin, avenue Félix Faure, boulevard Jean Jaurès, avenue de Verdun and rue Gioffredo.		The Place Garibaldi also stands out for its architecture and history. It is named after Giuseppe Garibaldi, hero of the Italian unification (born in Nice in 1807 when Nice was part of the Napoleonic Empire, before reverting to the Kingdom of Piedmont-Sardinia). The square was built at the end of the 18th century and served as the entry gate to the city and end of the road to Turin. It took several names between 1780 and 1870 (Plaça Pairoulièra, Place de la République, Place Napoléon, Place d'Armes, Place Saint-Augustin, Piazza Vittorio) and finally Place Garibaldi in September 1870.		A statue of Garibaldi, who was fiercely in favour of the union of Nice with Italy, stands in the centre of the square. The recent rebuilding of the area to accommodate the new tramway line gave mostly the entire square to pedestrians. The architecture is in line with the Turin model, which was the norm of urban renewal throughout the entire realm of the House of Savoy.		It is a crossroads between the Vieux Nice (old town) and the town centre. Place Garibaldi is close to the eastern districts of Nice, Port Lympia (Lympia Harbour), and the TNL commercial centre. This square is also a junction of several important streets: the boulevard Jean-Jaurès, the avenue de la République, the rue Cassini and the rue Catherine-Ségurane.		Entirely enclosed and pedestrianised, this square is located in the heart of the old town. With typical buildings in red and yellow ochres surrounding the square, the cathédrale Sainte-Réparate and the fountain in the centre, place Rossetti is a must-see spot in the old town. By day, the place is invaded by the terraces of traditional restaurants and the finest ice-cream makers. By night, the environment changes radically, with tourists and youths flocking to the square, where music reverberates on the walls of the small square. The square's lighting at night gives it a magical aspect.		Place Rossetti is in the centre of the old town, streets Jesus, Rossetti, Mascoïnat and the Pont-vieux (old bridge)		The Cours Saleya is situated parallel to the Quai des États-Unis. In the past, it belonged to the upper classes. It is probably the most traditional square of the town, with its daily flower market. The Cours Saleya also opens on the Palais des Rois Sardes (Palace of the Kings of Sardinia). In the present, the court is mostly a place of entertainment.		As its name indicates, the Place du Palais is where the Palais de la Justice (Law courts) of Nice is located. On this square, there also is the Palais Rusca, which also belongs to the justice department (home of the tribunal de grande instance).		The square is also notable due to the presence of the city clock. Today, the Place du Palais is alive day and night. Often, groups of youths will hangout on the steps leading to the Palais de la Justice. Concerts, films, and other major public events frequently occur in this space.		It is situated halfway between the Cours Saleya and Place Masséna.		Sources : Ldh/EHESS/Cassini until 1962, INSEE database from 1968 (population without double counting and municipal population from 2006)		The metropolitan area of Nice, defined by INSEE, is home to 888,784 inhabitants (fifth most populous in France) and its urban area totals 933,080 inhabitants, which makes it the sixth largest in France.		Roughly 10% of the population has foreign citizenship.		The six largest immigrant groups are from:		The city saw a big demographic rise in the second half of the 19th century, a period when the population more than doubled, mainly due to French immigration. At the beginning of the 20th century, this rise intensified with the arrival of internal immigrants from the County of Nice itself.[citation needed]		After the First World War, the city had a strong increase in population. Immigration was again the reason of this growth. The hotel industry and that of the construction industry, in full strength in the 1920s, attracted the world more and more and thus made it possible for Nice to become a town of national importance. In 1921, Nice then became the eleventh most populous town of France, then in 1931, the eighth, before being ranked sixth in 1946; thereafter the city reached its current demographic level due to the arrival of sixty thousand people including French citizens from Algeria.[citation needed]		Since the 1970s, the number of inhabitants has not changed significantly; the relatively high migration to Nice is compensated by a natural negative growth of the population. Nice has a high proportion of elderly people.[citation needed], and as such has one of the highest median ages in France.		Currently, the population of the city is growing again, the most likely reason of which is a preference for the climate.[citation needed] Nice was projected to have 360,000 citizens in 2008, and will have 370,000 by 2012.[citation needed]		The Observatoire de Nice (Nice Observatory) is located on the summit of Mont Gros. The observatory was established in 1879 by the banker Raphaël Bischoffsheim. The architect was Charles Garnier, and Gustave Eiffel designed the main dome.		The 76-cm (30-inch) refractor telescope that became operational in 1888 was at that time the world's largest telescope. It was outperformed one year later by the 36-inch (91-cm) refractor at the Lick Observatory at University of California, Santa Cruz.		As a scientific institution, the Nice Observatory was merged with CERGA in 1988 to form the Observatoire de la Côte d'Azur. Many scientific activities still take place on the Nice Observatory site on Mount Gross above the city including gravity-wave and high-energy astrophysics, astrometric and interferometric astronomy and planetary science. The city is the namesake for the Nice model, which was developed at the observatory in 2005.		Nice is one of the oldest human settlements in the world. Terra-Amata, an archaeological site dating from the Lower Palaeolithic age, is situated near Nice. Nice itself was established by the ancient Greeks. There was also an independent Roman city, Cemenelum, near Nice, where the hill of Cimiez is located. It is an archaeological site with treasures, of which only a small part has been excavated. The excavated site includes thermal baths, arenas and Roman road.		Since the 2nd century AD, the light of the city has attracted many famous painters and sculptors such as Chagall, Matisse, Niki de Saint Phalle, Klein, Arman and Sosno. Nice inspired many composers and intellectuals in different countries e.g. Berlioz, Rossini, Nietzsche etc.		Nice also has numerous museums of all kinds: Musée Marc Chagall, Musée Matisse (arenas of Cimiez containing Roman ruins), Musée des Beaux-Arts, Musée international d'Art naïf Anatole Jakovsky, Musée Terra-Amata, Museum of Asian Art, Musée d'art moderne et d'art contemporain which devotes much space to the well-known École of Nice ”), Museum of Natural History, Musée Masséna, Naval Museum and Galerie des Ponchettes.		Being a vacation resort, Nice hosts many festivals throughout the year, such as the Carnaval de Nice and the Nice Jazz Festival.		Nice has a distinct culture due to its unique history. The local language Niçard (Nissart) is an Occitan dialect (but some Italian scholars argue that it is a Ligurian dialect). It is still spoken by a substantial minority. Strong Italian and (to a lesser extent) Corsican influences make it more intelligible to Italians than other extant Provençal dialects.		In the past, Nice welcomed many immigrants from Italy (who continue to make up a large proportion of the population), as well as Spanish and Portuguese immigrants. However, in the past few decades immigration has been opened to include immigrants from all over the world, particularly those from former Northern and Western African colonies, as well as southeast Asia. Traditions are still alive, especially in folk music and dances. The most famous dance is the farandole.		Since 1860 a cannon (based at the Château east of Old Nice) is shot at twelve o'clock sharp. The detonation can be heard almost all over the city. This tradition goes back to Sir Thomas Coventry, who intended to remind the citizens of having lunch on time.[29]		The cuisine of Nice is especially close to those of Provence but also Liguria and Piedmont and uses local ingredients (olive oil, anchovies, fruit and vegetables) but also those from more remote regions, in particular from Northern Europe, because ships which came to pick up olive oil arrived full of food products, such as dried haddock.		Nice has a few local dishes. There is a local tart made with onions and anchovies (or anchovy paste), named "Pissaladière". Socca is a type of pancake made from chickpea flour. Farcis niçois is a dish made from vegetables stuffed with a mixture of breadcrumbs, meat (generally sausage and ground beef), and herbs; and salade niçoise is a tomato salad with green peppers of the "Corne" variety, baked eggs, tuna or anchovies, and olives.		Local meat comes from neighbouring valleys, such as the sheep of Sisteron. Local fish, such as mullets, bream, sea urchins, and anchovies (alevins) are used to a great extent, so much so that it has given birth to a proverb: "fish are born in the sea and die in oil".[30]		Examples of Niçois specialties include:		Nice is twinned with:[31]		
Kemp's ridley sea turtle[2] (Lepidochelys kempii), or the Atlantic ridley sea turtle, is the rarest species of sea turtle and is critically endangered. It is one of two living species in the genus Lepidochelys (the other one being L. olivacea, the olive ridley sea turtle).						Kemp's ridley is a small sea turtle species, reaching maturity at 58–70 cm (23–28 in) carapace length and weighing only 36–45 kg (79–99 lb).[3] Typical of sea turtles, it has a dorsoventrally depressed body with specially adapted flipper-like front limbs and a beak. Kemp's ridley turtle is the smallest of the sea turtles, with adults reaching a maximum of 75 cm (30 in) in carapace length and weighing a maximum of 50 kg (110 lb).[3] The adult has an oval carapace that is almost as wide as it is long and is usually olive-gray in color. The carapace has five pairs of costal scutes. In each bridge adjoining the plastron to the carapace are four inframarginal scutes, each of which is perforated by a pore. The head has two pairs of prefrontal scales. Hatchlings are black on both sides. Kemp's ridley has a triangular-shaped head with a somewhat hooked beak with large crushing surfaces. This turtle is a shallow-water benthic feeder with a diet consisting primarily of crabs.		Kemp's ridley sea turtles generally prefer warm waters, but inhabit waters as far north as New Jersey, They migrate to the Gulf of Mexico and Florida, where they often inhabit the waters off Louisiana.[4][citation needed]		Their range includes the Atlantic Ocean and the Gulf of Mexico. Almost all females return each year to a single beach—Rancho Nuevo in the Mexican state of Tamaulipas—to lay eggs. The females arrive in large groups of hundreds or thousands in nesting aggregations called arribadas, which is a Spanish word for "arrival."[5][6]		Some travel as far away as the coast of Ireland, and two individuals managed to journey as far as the coasts of Devonshire.[citation needed]		Kemp's ridley turtle feeds on mollusks, crustaceans, jellyfish, fish, algae or seaweed, and sea urchins. Juvenile Kemp's ridleys primarily feed on crabs.[7]		Juvenile turtles tend to live in floating sargassum seaweed beds for their first years.[8] Then they range between northwest Atlantic waters and the Gulf of Mexico while growing into maturity.		These turtles change color as they mature. As hatchlings, they are almost entirely a dark purple , but mature adults have a yellow-green or white plastron and a grey-green carapace. They reach sexual maturity at the age of 10-12.[9]		The nesting season for these turtles is April to August. They nest mostly on a 16-mile beach in the Mexican state of Tamaulipas and on Padre Island in the US state of Texas, and elsewhere on the Gulf coast. They mate offshore. Gravid females land in groups on beaches in what is commonly called an arribada[8] or mass nesting. They prefer areas with dunes or, secondarily, swamps. The estimated number of nesting females in 1947 was 89,000, but shrank to an estimated 7,702 by 1985.[10]		Females nest two or three times during a season, keeping 10 to 10 days between nestings. Incubation takes 45 to 70 days. On average, around 110 eggs are in a clutch. The hatchlings' sex is decided by the temperature in the area during incubation. If the temperature is below 29.5 °C, the offspring will be mainly male.		Hatchling		Hatchling		Juvenile turtle		Adult turtle nesting		Deceased adult		These turtles are called Kemp's ridley because Richard Moore Kemp (1825-1908) of Key West was the first to send a specimen to Samuel Garman at Harvard.[11] However, the etymology of the name "ridley" itself is unknown. Prior to the term being popularly used (for both species in the genus), L. kempii at least was known as the "turtle".[12]		At least one source also refers to Kemp's ridley as a "heartbreak turtle". In her book The Great Ridley Rescue, Pamela Philips claimed the name was coined by fishermen who witnessed the turtles dying after being "turned turtle" (on their backs). The fishermen said the turtles "died of a broken heart".[13][14]		Hunting first depleted their numbers, but today, major threats include habitat loss, pollution, and entanglement in shrimping nets.		Mexico first protected Kemp's ridleys in the 1960s. In the United States, Kemp's ridley turtle was first listed under the Endangered Species Conservation Act of 1970[15] on December 2, 1970, and subsequently under the Endangered Species Act (ESA) of 1973. A binational recovery plan was developed in 1984, and revised in 1992. A draft public review draft of the second revision was published by NOAA Fisheries in March 2010.[16] This revision includes an updated threat assessment.[17]		One mechanism used to protect turtles from fishing nets is the turtle excluder device (TED). Because the biggest danger to the population of Kemp’s ridley sea turtles is shrimp trawls, the device is attached to the shrimp trawl. It is a grid of bars with an opening at the top or bottom, fitted into the neck of the shrimp trawl. It allows small animals to slip through the bars and be caught while larger animals, such as sea turtles, strike the bars and are ejected, thus avoiding possible drowning.		In September 2007, Corpus Christi, Texas, wildlife officials found a record of 128 Kemp's ridley sea turtle nests on Texas beaches, including 81 on North Padre Island (Padre Island National Seashore) and four on Mustang Island. The figure was exceeded in each of the following 7 years (see graph to 2013, provisional figures for 2014 as at July, 118.[18]). Wildlife officials released 10,594 Kemp's ridley hatchlings along the Texas coast that year. The turtles are popular in Mexico, as boot material and food.[19]		Some Kemp's ridleys were airlifted from Mexico after the 1979 blowout of the Ixtoc 1 rig, which spilled millions of gallons of oil into the Gulf of Mexico.		Since April 30, 2010, 10 days after the accident on the Deepwater Horizon, 156 sea turtle deaths were recorded; most were Kemp’s ridleys.[citation needed] Louisiana Department of Wildlife and Fisheries biologists and enforcement agents rescued Kemp's ridleys in Grand Isle.[20][citation needed] "Most" of the 456 oiled turtles that were rescued, cleaned, and released by US Fish and Wildlife Service were Kemp's ridleys.[21]		Of the endangered marine species frequenting Gulf waters, only Kemp’s ridley relies on the region as its sole breeding ground.[22]		As part of the effort to save the species from some of the effects of the Deepwater Horizon oil spill, scientists took nests and incubated them elsewhere; 67 eggs were collected from a nest along the Florida Panhandle on June 26, 2010, and brought to a temperature-controlled warehouse at NASA’s Kennedy Space Center, where 56 hatched,[citation needed] and 22 were released on 11 July 2010.[23]		The overall plan was to collect eggs from about 700 sea turtle nests, incubate them, and release the young on beaches across Alabama and Florida over a period of months.[23][24] Eventually, 278 nests were collected, including only a few Kemp' ridley nests.[25]		
In Greek mythology, the Sirens (Greek singular: Σειρήν Seirēn; Greek plural: Σειρῆνες Seirēnes) were dangerous creatures, who lured nearby sailors with their enchanting music and voices to shipwreck on the rocky coast of their island. Roman poets placed them on some small islands called Sirenum scopuli. In some later, rationalized traditions, the literal geography of the "flowery" island of Anthemoessa, or Anthemusa,[1] is fixed: sometimes on Cape Pelorum and at others in the islands known as the Sirenuse, near Paestum, or in Capreae.[2] All such locations were surrounded by cliffs and rocks.						The etymology of the name is at present contested. Robert S. P. Beekes has suggested a Pre-Greek origin.[3] Others connect the name to σειρά (seirá "rope, cord") and εἴρω (eírō "to tie, join, fasten"), resulting in the meaning "binder, entangler",[4] i. e. one who binds or entangles through magic song. This could be connected to the famous scene of Odysseus being bound to the mast of his ship, in order to resist their song.[5]		Sirens were believed to combine women and birds in various ways. In early Greek art, Sirens were represented as birds with large women's heads, bird feathers and scaly feet. Later, they were represented as female figures with the legs of birds, with or without wings, playing a variety of musical instruments, especially harps. The tenth-century Byzantine encyclopedia Suda says that from their chests up Sirens had the form of sparrows, below they were women, or, alternatively, that they were little birds with women's faces.[6] Birds were chosen because of their beautiful voices. Later Sirens were sometimes depicted as beautiful women, whose bodies, not only their voices, are seductive.		The first-century Roman historian Pliny the Elder discounted Sirens as pure fable, "although Dinon, the father of Clearchus, a celebrated writer, asserts that they exist in India, and that they charm men by their song, and, having first lulled them to sleep, tear them to pieces."[7] In his notebooks Leonardo da Vinci wrote of the Siren, "The siren sings so sweetly that she lulls the mariners to sleep; then she climbs upon the ships and kills the sleeping mariners."		In 1917, Franz Kafka wrote in The Silence of the Sirens, "Now the Sirens have a still more fatal weapon than their song, namely their silence. And though admittedly such a thing never happened, it is still conceivable that someone might possibly have escaped from their singing; but from their silence certainly never."		Although a Sophocles fragment makes Phorcys their father,[8] when Sirens are named, they are usually as daughters of the river god Achelous,[9] with Terpsichore,[10] Melpomene, Calliope[11] or Sterope. In Euripides' play, Helen (167), Helen in her anguish calls upon "Winged maidens, daughters of the Earth (Chthon)." Although they lured mariners, the Greeks portrayed the Sirens in their "meadow starred with flowers" and not as sea deities. Roman writers linked the Sirens more closely to the sea, as daughters of Phorcys.[12] Sirens are found in many Greek stories, notably in Homer's Odyssey.		Their number is variously reported as from two to five. In the Odyssey, Homer says nothing of their origin or names, but gives the number of the Sirens as two.[13] Later writers mention both their names and number: some state that there were three, Peisinoe, Aglaope, and Thelxiepeia (Tzetzes, ad Lycophron 7l2; Pseudo-Apollodorus, Bibliotheca E7. 18) or Parthenope, Ligeia, and Leucosia (Eustathius, loc. cit.; Strabo v. §246, 252; Servius' commentary on Virgil's Georgics iv. 562); Apollonius followed Hesiod gives their names as Thelxinoe, Molpe, and Aglaophonos (Scholiast on Homer's Odyssey 12. 168, trans. Evelyn-White); Suidas gives their names as Thelxiepeia, Peisinoe, and Ligeia (Suidas s.v. Seirenas); Hyginus gives the number of the Sirens as four: Teles, Raidne, Molpe, and Thelxiope (Fabulae, praefat. p. 30, ed. Bunte)[14]; Eustathius (Commentaries §1709) states that they were two, Aglaopheme and Thelxiepeia; An ancient vase painting attests the two names as Himerope and Thelxiepeia. Their individual names are variously rendered in the later sources as Thelxiepeia/Thelxiope/Thelxinoe, Molpe, Himerope, Aglaophonos/Aglaope/Aglaopheme, Pisinoe/Peisinoë/Peisithoe, Parthenope, Ligeia, Leucosia, Raidne, and Teles.[15][16][17][18]		According to Ovid (43 BC–17 AD), the Sirens were the companions of young Persephone.[26] They were given wings by Demeter to search for Persephone when she was abducted. However, the Fabulae of Hyginus (64 BC–17 AD) has Demeter cursing the Sirens for failing to intervene in the abduction of Persephone. According to Hyginus, sirens were fated to live only until the mortals who heard their songs were able to pass by them.[27]		It is also said that Hera, queen of the gods, persuaded the Sirens to enter a singing contest with the Muses. The Muses won the competition and then plucked out all of the Sirens' feathers and made crowns out of them.[28] Out of their anguish from losing the competition, writes Stephanus of Byzantium, the Sirens turned white and fell into the sea at Aptera ("featherless"), where they formed the islands in the bay that were called Leukai ("the white ones", modern Souda).[29]		In the Argonautica (third century BC), Jason had been warned by Chiron that Orpheus would be necessary in his journey.[30] When Orpheus heard their voices, he drew out his lyre and played his music more beautifully than they, drowning out their voices. One of the crew, however, the sharp-eared hero Butes, heard the song and leapt into the sea, but he was caught up and carried safely away by the goddess Aphrodite.		Odysseus was curious as to what the Sirens sang to him, and so, on the advice of Circe, he had all of his sailors plug their ears with beeswax and tie him to the mast. He ordered his men to leave him tied tightly to the mast, no matter how much he would beg. When he heard their beautiful song, he ordered the sailors to untie him but they bound him tighter. When they had passed out of earshot, Odysseus demonstrated with his frowns to be released.[31] Some post-Homeric authors state that the Sirens were fated to die if someone heard their singing and escaped them, and that after Odysseus passed by they therefore flung themselves into the water and perished.[32]		Statues of Sirens in a funerary context are attested since the classical era, in mainland Greece, as well as Asia Minor and Magna Graecia. The so-called "Siren of Canosa" – Canosa di Puglia is a site in Apulia that was part of Magna Graecia – was said to accompany the dead among grave goods in a burial. She appeared to have some psychopomp characteristics, guiding the dead on the after-life journey. The cast terracotta figure bears traces of its original white pigment. The woman bears the feet, wings and tail of a bird. The sculpture is conserved in the National Archaeological Museum of Spain, in Madrid. The Sirens were called the Muses of the lower world, classical scholar Walter Copland Perry (1814–1911) observed: "Their song, though irresistibly sweet, was no less sad than sweet, and lapped both body and soul in a fatal lethargy, the forerunner of death and corruption."[33] Their song is continually calling on Persephone. The term "siren song" refers to an appeal that is hard to resist but that, if heeded, will lead to a bad conclusion. Later writers have implied that the Sirens were cannibals, based on Circe's description of them "lolling there in their meadow, round them heaps of corpses rotting away, rags of skin shriveling on their bones."[34] As linguist Jane Ellen Harrison (1850–1928) notes of "The Ker as siren": "It is strange and beautiful that Homer should make the Sirens appeal to the spirit, not to the flesh."[35] The siren song is a promise to Odysseus of mantic truths; with a false promise that he will live to tell them, they sing,		Once he hears to his heart's content, sails on, a wiser man.		We know all the pains that the Greeks and Trojans once endured on the spreading plain of Troy when the gods willed it so—		"They are mantic creatures like the Sphinx with whom they have much in common, knowing both the past and the future", Harrison observed. "Their song takes effect at midday, in a windless calm. The end of that song is death."[37] That the sailors' flesh is rotting away, suggests it has not been eaten. It has been suggested that, with their feathers stolen, their divine nature kept them alive, but unable to provide food for their visitors, who starved to death by refusing to leave.[38]		By the fourth century, when pagan beliefs were overtaken by Christianity, the belief in literal sirens was discouraged. Although Saint Jerome, who produced the Latin Vulgate version of the bible, used the word sirens to translate Hebrew tannīm ("jackals") in Isaiah 13:22, and also to translate a word for "owls" in Jeremiah 50:39, this was explained by Ambrose to be a mere symbol or allegory for worldly temptations, and not an endorsement of the Greek myth.[39]		The Early Christian euhemerist interpretation of mythologized human beings received a long-lasting boost from Isidore's Etymologiae:		They [the Greeks] imagine that "there were three Sirens, part virgins, part birds," with wings and claws. "One of them sang, another played the flute, the third the lyre. They drew sailors, decoyed by song, to shipwreck. According to the truth, however, they were prostitutes who led travelers down to poverty and were said to impose shipwreck on them." They had wings and claws because Love flies and wounds. They are said to have stayed in the waves because a wave created Venus.[40]		Sirens continued to be used as a symbol for the dangerous temptation embodied by women regularly throughout Christian art of the medieval era; however, in the 17th century, some Jesuit writers began to assert their actual existence, including Cornelius a Lapide, who said of woman, "her glance is that of the fabled basilisk, her voice a siren's voice—with her voice she enchants, with her beauty she deprives of reason—voice and sight alike deal destruction and death."[41] Antonio de Lorea also argued for their existence, and Athanasius Kircher argued that compartments must have been built for them aboard Noah's Ark.[42]		Charles Burney expounded c. 1789, in A General History of Music: "The name, according to Bochart, who derives it from the Phoenician, implies a songstress. Hence it is probable, that in ancient times there may have been excellent singers, but of corrupt morals, on the coast of Sicily, who by seducing voyagers, gave rise to this fable."[43] John Lemprière in his Classical Dictionary (1827) wrote, "Some suppose that the Sirens were a number of lascivious women in Sicily, who prostituted themselves to strangers, and made them forget their pursuits while drowned in unlawful pleasures. The etymology of Bochart, who deduces the name from a Phoenician term denoting a songstress, favors the explanation given of the fable by Damm.[44] This distinguished critic makes the Sirens to have been excellent singers, and divesting the fables respecting them of all their terrific features, he supposes that by the charms of music and song they detained travellers, and made them altogether forgetful of their native land."[45]		The theme of perilous mythical female creatures seeking to seduce men with their beautiful singing is paralleled in the Danish medieval ballad known as "Elvehøj", in which the singers are elves. The ballad is also conserved in a Swedish version. A modern literary appropriation of the myth is to be seen in Clemens Brentano's Lore Lay ballad, published in his novel Godwi oder Das steinerne Bild der Mutter (1801).		
Ayre is the name used for shingle beaches in Orkney and Shetland.[1][2] The word is derived from the Old Norse "eyrr" meaning a shingle beach or gravelly place [3] and may be applied to ordinary beaches, to cliff-foot beaches such as the Lang Ayre[4] in Northmavine, Shetland, to spits, bars and tombolos, but only if formed of shingle. More than 130 such shingle beaches are named on Ordnance Survey maps of Shetland, but far fewer in Orkney, where most beaches are formed of sand. The word in its Old Norse form is common in Iceland and it also occurs in a few place names in the north and west of the Scottish mainland which had a strong Norse influence, such as Eriboll ("a homestead on a shingle beach"). Churchill Barrier number 4 in Orkney used a shingle spit, the Ayre of Cara on South Ronaldsay, as its southern landfall. The ayre is still named on maps, despite its having all but vanished under the causeway and the sand dunes that have accumulated on its eastern side.		The term "ayre" is sometimes wrongly applied to sand tombolos (e.g. St. Ninian's tombolo in Shetland) and to the lakes and lagoons impounded by bay-head bars, which are more properly called oyces [5] in Orkney and houbs in Shetland		
Sand art is the practice of modelling sand into an artistic form, such as a sand brushing, sand sculpture, sandpainting, or sand bottles. A sandcastle is a type of sand sculpture resembling a miniature building, often a castle.		The two basic building ingredients, sand and water, are available in abundance on a sandy beach, so most sand play takes place there, or in a sandpit. Tidal beaches generally have sand that limits height and structure because of the shape of the sand grains. Good sculpture sand is somewhat dirty, having silt and clay that helps lock the irregular-shaped sand grains together.		Sand castles are typically made by children for fun, but there are also sand-sculpture contests for adults that involve large, complex constructions. The largest sandcastle made in a contest was 18 feet tall; the owner, Ronald Malcnujio, a five-foot-high man, had to use several ladders, each the height of the sandcastle. His sculpture consisted of one ton of sand and 10 litres of water to sculpt.						Sand grains will always stick together unless the sand is reasonably fine. While dry sand is loose, wet sand is adherent if the proper amounts of sand and water are used in the mixture. The reason for this is that water forms little "bridges" between the grains of sand when it is damp due to the forces of surface tension.[1]		When the sand dries out or gets wet, the shape of a structure may change, and "landslides" are common. Furthermore, the mixture of fine (mostly sharper) and coarse sand granules is very important to achieve good "sand construction" results. Fine granules that have been rounded by the natural influences of seas, rivers or fluvials, in turn negatively influence the bonding between the individual granules as they more easily slide past each other. Research[2] is thus necessary to find the most suitable sand to achieve an optimal, landslide-free construction.		Shovels and buckets are the main construction tools used in creating sand castles and sand sculptures, although some people use only their hands. A simple sand castle can be made by filling a bucket with damp sand, placing it upside-down on the beach, and removing the bucket. For larger constructions, water from the sea to mix with the sand can be brought to the building site with a bucket or other container. Sometimes other materials, such as pieces of wood and plastic are constructed to hold piles of sand in place and in specific shapes - these are called forms.		Sand sculpting as an art form has become very popular in recent years, especially in coastal beach areas. Hundreds of annual competitions are held all over the world. Techniques[3] can be quite sophisticated, and record-breaking achievements have been noted in the Guinness World Records. Sometimes, contests are staged as advertising or promotional events. Most Sand sculptors come from other disciplines but there are a few that earn their living solely from Sand related activities.		A variant on the sandcastle is the drip castle, made by mixing the sand with water and dripping it from a fist held above. Some refer to the technique as "dribbling". When the slurry of sand and water lands on existing sand structures, the effect is Gaudi-esque.		From 1989 until 2009, a World Championship in Sand Sculpture was held in Harrison Hot Springs in Harrison, British Columbia, Canada, also known as "Harrisand". The competition had solo, double and team categories. The "World championship was held in ft Myers, Florida and other venues for a limited time. Other countries hold their own versions of the world championships as it is not possible to get all the people who may qualify in the same place at the same time due to the expense and logistics.		The world's tallest sand castle was built on Myrtle Beach in South Carolina by Team Sandtastic as part of the 2007 Sun Fun Festival. The structure was 49.55 feet (15.1 m) high. It took 10 days to construct and used 300 truckloads of sand.[4]		The world's record for the most simultaneous sand angles made at one time was done in Ludington, Michigan, on June 10, 2017. It was performed by 1,387 sand angel people at the same time. This is almost 4 times the previous record of 352 made in Pembrokeshire, Wales, on June 6, 2015. The duration they lasted making sand angels was for 30 seconds - twice as long as the 15 seconds at Pembrokeshire.[5][6]		A popular game is building a heap of sand, as high as possible, to withstand the upcoming tide.		A sandcastle with a moat, at low tide		The sea moving in to surround the castle		The castle as an island		An example of a drip castle		One of the main attractions of a sandy beach, especially for children, is playing with the sand, as it presents more possibilities than an ordinary sandbox.		One can make a mountain, a pit (encountering clay or the water table), canals, tunnels, bridges, a sculpture (representing a person, animal, etc., like a statue, or a scale model of a building), and many other things.		Tunnels large enough to enter are extremely hazardous; children and adults die every year when such underground chambers collapsed under weight and instability of sand, or due to the tide coming up or the structure being hit by a wave. Sometimes, a dam can be built to hold back the water, tidal forts, which are incredibly large sandcastles with thick walls to protect the keep from the sea, can be built, or canals can be dug to contain the water.		Burying someone up to his or her neck in sand, or burying oneself, is another popular beach activity.		A sand glass is a work of craftsmanship in which two sheets of glass show an amount of sand in two colors, which is immersed in water. Unlike sand paintings, a sand glass is meant to be turned, the sand, traditionally in black and a light color, moving into new dunes. The term "Sand Glass" is a translation of the term in Portuguese "Quadro de Areia", literally Sand Frame or Sand Picture, used in English courses to differentiate this kind of craft from sand paintings. Unlike sand paintings, which are traditionally found in the Northeast region of Brazil, these are found on the streets of other region's big cities and in stores, in many colors and sizes.		
The tropics are a region of the Earth surrounding the Equator. They are delimited in latitude by the Tropic of Cancer in the Northern Hemisphere at 23°26′13.2″ (or 23.437°) N and the Tropic of Capricorn in the Southern Hemisphere at 23°26′13.2″ (or 23.437°) S; these latitudes correspond to the axial tilt of the Earth. The tropics are also referred to as the tropical zone and the torrid zone (see geographical zone). The tropics include all the areas on the Earth where the Sun contacts the zenith, a point directly overhead, at least once during the solar year (which is a subsolar point).		The tropics are distinguished from the other climatic and biomatic regions of Earth, which are the middle latitudes and the polar regions on either side of the equatorial zone.		The Tropics comprise 40% of the Earth's surface area[1] and contain 36% of the Earth's landmass.[2]As of 2014[update], the region is home to 40% of the world population, and this figure is projected to reach 50% by the late 2030s.[3]						"Tropical" is sometimes used in a general sense for a tropical climate to mean warm to hot and moist year-round, often with the sense of lush vegetation.		Many tropical areas have a dry and wet season. The wet season, rainy season or green season is the time of year, ranging from one or more months, when most of the average annual rainfall in a region falls.[4] Areas with wet seasons are disseminated across portions of the tropics and subtropics.[5] Under the Köppen climate classification, for tropical climates, a wet-season month is defined as a month where average precipitation is 60 millimetres (2.4 in) or more.[6] Tropical rainforests technically do not have dry or wet seasons, since their rainfall is equally distributed through the year.[7] Some areas with pronounced rainy seasons see a break in rainfall during mid-season when the intertropical convergence zone or monsoon trough moves poleward of their location during the middle of the warm season;[8] typical vegetation in these areas ranges from moist seasonal tropical forests to savannahs.		When the wet season occurs during the warm season, or summer, precipitation falls mainly during the late afternoon and early evening hours. The wet season is a time when air quality improves, freshwater quality improves and vegetation grows significantly, leading to crop yields late in the season. Floods cause rivers to overflow their banks, and some animals to retreat to higher ground. Soil nutrients diminish and erosion increases. The incidence of malaria increases in areas where the rainy season coincides with high temperatures. Animals have adaptation and survival strategies for the wetter regime. Unfortunately, the previous dry season leads to food shortages into the wet season, as the crops have yet to mature.		Regions within the tropics may well not have a tropical climate. There are alpine tundra and snow-capped peaks, including Mauna Kea, Mount Kilimanjaro, and the Andes as far south as the northernmost parts of Chile and Argentina. Under the Köppen climate classification, much of the area within the geographical tropics is classed not as "tropical" but as "dry" (arid or semi-arid) including the Sahara Desert, the Atacama Desert and Australian Outback.		Tropical plants and animals are those species native to the tropics. Tropical ecosystems may consist of tropical rainforests, seasonal tropical forests, dry (often deciduous) forests, spiny forests, desert and other habitat types. There are often significant areas of biodiversity, and species endemism present, particularly in rainforests and seasonal forests. Some examples of important biodiversity and high endemism ecosystems are El Yunque National Forest in Puerto Rico, Costa Rican and Nicaraguan rainforests, Amazon Rainforest territories of several South American countries, Madagascar dry deciduous forests, the Waterberg Biosphere of South Africa, and eastern Madagascar rainforests. Often the soils of tropical forests are low in nutrient content, making them quite vulnerable to slash-and-burn deforestation techniques, which are sometimes an element of shifting cultivation agricultural systems.		In biogeography, the tropics are divided into Paleotropics (Africa, Asia and Australia) and Neotropics (Caribbean, Central America, and South America). Together, they are sometimes referred to as the Pantropic. The Neotropical region should not be confused with the ecozone of the same name; in the Old World, there is no such ambiguity, as the Paleotropics correspond to the Afrotropical, Indomalayan, and partly the Australasian and Oceanic ecozones.		"Tropicality" refers to the geographic imagery that many people outside the tropics have of that region. The idea of tropicality gained renewed interest in modern geographical discourse when French geographer Pierre Gourou published Les Pays Tropicaux (The Tropical World, in English), in the late 1940s.[9]		Tropicality encompasses at least two contradictory imageries. One is that the tropics represent a Garden of Eden, a heaven on Earth;[10] the alternative is that the tropics are primitive and essentially lawless. The latter view was often discussed in Western literature—more so than the first.[10]		Western scholars also theorized about the reasons that tropical areas were deemed "inferior" to regions in the Northern Hemisphere. A popular explanation focused on the differences in climate—tropical regions typically have much warmer weather than northern regions. This theme led some scholars, including Gourou, to argue that warmer climates correlate to primitive indigenous populations lacking control over nature, compared to northern populations having "mastered nature".[11]		A Morpho peleides (blue morpho) tropical butterfly		A Graphium agamemnon (tailed jay) belongs to the swallowtail family		Tropical fish in Indonesia		
Submersion is the sustainable cyclic portion of coastal erosion where coastal sediments move from the visible portion of a beach to the submerged nearshore region, and later return to the original visible portion of the beach. The recovery portion of the sustainable cycle of sediment behaviour is (accretion).		The sediment that is submerged during rough weather forms landforms including storm bars. In calmer weather waves return sediment to the visible part of the beach. Due to longshore drift some sediment can end up further along the beach from where it started. Often coastal areas have developed sustainable coastal positions where the sediment moving off beaches is sustainable submersion. On many inhabited coastlines, anthropogenic interference in coastal processes has meant that erosion is often more permanent than submersion.		The term erosion often is associated with undesirable impacts on the environment, whereas submersion should be celebrated as a sustainable part of healthy foreshores. Communities making decisions about coastal management need to develop understanding of the components of beach recession and be able to separate the component that is temporary sustainable submersion from the more serious irreversible anthropogenic or climate change erosion portion.		
Feces or faeces (British and Latin) are the solid or semisolid metabolic waste from an animal's digestive tract, discharged through the anus or cloaca during a process called defecation. Urine and feces together are called excreta.		Collected feces has various uses, namely as fertilizer or soil conditioner in agriculture, as a fuel source, construction material, or for medicinal purposes (fecal transplants or fecal bacteriotherapy, in the case of human feces).		After an animal has digested eaten material, the remains of that material are discharged from its body as waste. Although it is lower in energy than the food from which it is derived, feces may retain a large amount of energy, often 50% of that of the original food.[1] This means that of all food eaten, a significant amount of energy remains for the decomposers of ecosystems. Many organisms feed on feces, from bacteria to fungi to insects such as dung beetles, who can sense odors from long distances.[2] Some may specialize in feces, while others may eat other foods as well. Feces serve not only as a basic food, but also as a supplement to the usual diet of some animals. This is known as coprophagia, and occurs in various animal species such as young elephants eating the feces of their mothers in order to gain essential gut flora, or by other animals such as dogs, rabbits, and monkeys.		Feces and urine, which reflect ultraviolet light, are important to raptors such as kestrels, who can see the near ultraviolet and thus find their prey by their middens and territorial markers.[3]		Seeds also may be found in feces. Animals who eat fruit are known as frugivores. An advantage for a plant in having fruit is that animals will eat the fruit and unknowingly disperse the seed in doing so. This mode of seed dispersal is highly successful, as seeds dispersed around the base of a plant are unlikely to succeed and often are subject to heavy predation. Provided the seed can withstand the pathway through the digestive system, it is not only likely to be far away from the parent plant, but is even provided with its own fertilizer.		Organisms that subsist on dead organic matter or detritus are known as detritivores, and play an important role in ecosystems by recycling organic matter back into a simpler form that plants and other autotrophs may absorb once again. This cycling of matter is known as the biogeochemical cycle. To maintain nutrients in soil it is therefore important that feces return to the area from which they came, which is not always the case in human society where food may be transported from rural areas to urban populations and then feces disposed of into a river or sea.		The distinctive odor of feces is due to bacterial action. Gut flora produce compounds such as indole, skatole, and thiols (sulfur-containing compounds), as well as the inorganic gas hydrogen sulfide. These are the same compounds that are responsible for the odor of flatulence. Consumption of foods prepared with spices may result in the spices being undigested and adding to the odor of feces.		The perceived bad odor of feces has been hypothesized to be a deterrent for humans, as consuming or touching it may result in sickness or infection.[4] Human perception of the odor may be contrasted by a non-human animal's perception of it; for example, an animal who eats feces may be attracted to its odor.		In humans and depending on the individual and the circumstances, defecation may occur daily, or once every two or three days to several times a day. Extensive hardening of the feces may cause prolonged interruption in the routine and is called constipation.		Human fecal matter varies significantly in appearance, depending on diet and health.[5] Normally it is semisolid, with a mucus coating. The brown coloration comes from a combination of bile and bilirubin, which comes from dead red blood cells.		In newborn babies, initially fecal matter is yellow-green after the meconium. This coloration comes from the presence of bile alone. In time, as the body starts expelling bilirubin from dead red blood cells, it acquires its familiar brown appearance, unless the baby is breast feeding, in which case it remains soft, pale yellowish, and not completely malodorous, until the baby begins to eat significant amounts of other food.		Throughout the life of an ordinary human, one may experience many types of feces. A "green" stool is from rapid transit of feces through the intestines (or the consumption of certain blue or green food dyes in quantity), and "clay-like" appearance to the feces is the result of a lack of bilirubin.		Pets can be trained to use litter boxes or wait to be allowed outside to defecate. Training can be done in several ways, especially dependent on species. An example is crate training for dogs. Several companies market cleaning products for pet owners whose pets have soiled carpets in the home.		The feces of animals often are used as fertilizer; see guano and manure.		Dry animal dung is used as a fuel source in many countries around the world by burning it. Some animal feces, especially those of camel, bison, and cattle, are used as fuel when dried.[6]		Animals such as the giant panda[7] and zebra[8] possess gut bacteria capable of producing biofuel. The bacteria, Brocadia anammoxidans, can create the rocket fuel hydrazine from feces.[9][10]		A coprolite is fossilized feces and is classified as a trace fossil. In paleontology they give evidence about the diet of an animal. They were first described by William Buckland in 1829. Prior to this they were known as "fossil fir cones" and "bezoar stones". They serve a valuable purpose in paleontology because they provide direct evidence of the predation and diet of extinct organisms.[11] Coprolites may range in size from a few millimetres to more than 60 centimetres.		Paleofeces are ancient human feces, often found as part of archaeological excavations or surveys. Intact feces of ancient people may be found in caves in arid climates and in other locations with suitable preservation conditions. These are studied to determine the diet and health of the people who produced them through the analysis of seeds, small bones, and parasite eggs found inside. These feces may contain information about the person excreting the material as well as information about the material. They also may be analyzed chemically for more in-depth information on the individual who excreted them, using lipid analysis and ancient DNA analysis. The success rate of usable DNA extraction is relatively high in paleofeces, making it more reliable than skeletal DNA retrieval.[12]		The reason this analysis is possible at all is due to the digestive system not being entirely efficient, in the sense that not everything that passes through the digestive system is destroyed. Not all of the surviving material is recognizable, but some of it is. Generally, this material is the best indicator archaeologists can use to determine ancient diets, as no other part of the archaeological record is so direct an indicator.[13]		A process that preserves feces in a way that they may be analyzed later is called the Maillard reaction. This reaction creates a casing of sugar that preserves the feces from the elements. To extract and analyze the information contained within, researchers generally have to freeze the feces and grind it up into powder for analysis.[14]		Animal dung occasionally is used as a cement to make adobe mudbrick huts,[15] or even in throwing sports such as cow pat throwing or camel dung throwing contests.[16]		Kopi Luwak (pronounced [ˈkopi ˈlu.aʔ]), or civet coffee, is coffee made from coffee berries that have been eaten by and passed through the digestive tract of the Asian palm civet (Paradoxurus hermaphroditus). Giant pandas provide fertilizer for the world's most expensive green tea.[17] In Malaysia, tea is made from the droppings of stick insects fed on guava leaves.		In northern Thailand, elephants are used to digest coffee beans in order to make Black Ivory coffee, which is among the world's most expensive coffees.[17]		Dog feces were used in the tanning process of leather during the Victorian era. Collected dog feces, known as "pure", "puer", or "pewer",[18] were mixed with water to form a substance known as "bate." Enzymes in the dog feces helped to relax the fibrous structure of the hide before the final stages of tanning.[19]		Elephants, hippos, koalas and pandas are born with sterile intestines, and require bacteria obtained from eating the feces of their mothers to digest vegetation.		Feces is the scientific terminology, while the term stool is also commonly used in medical contexts.[20] Outside of scientific contexts, these terms are less common, with the most common layman's term being poo (or poop in North American English). The term shit is also in common use, although is widely considered vulgar or offensive. There are many other terms, with some of the more widely used being crap, dump, load and turd.[21]		The word faeces is the plural of the Latin word faex meaning "dregs". In most English-language usage, there is no singular form, making the word a plurale tantum;[22] out of various major dictionaries, only one enters variation from plural agreement.[23]		"Feces" is used more in biology and medicine than in other fields (reflecting science's tradition of classical Latin and New Latin)		As with urine, there are many synonyms in informal registers for feces. Many are euphemismistic, colloquial, or both; some are profane (such as shit), whereas most belong chiefly to child-directed speech (such as poo or poop) or to crude humor (such as deuce or turd). It is also represented in emoji form in the Miscellaneous Symbols and Pictographs block of Unicode as U+1F4A9 💩 pile of poo, called unchi or unhci-kun in Japan.[25][26]		The feces of animals often have special names, for example:		In all human cultures, feces elicit varying degrees of disgust, a basic human emotion.[citation needed] Disgust is experienced primarily in relation to the sense of taste (either perceived or imagined) and, secondarily to anything that causes a similar feeling by sense of smell, touch, or vision.		
A raised beach, marine terrace, coastal terrace,[1] or perched coastline is a relatively flat, horizontal or gently inclined surface of marine origin,[2] mostly an old abrasion platform which has been lifted out of the sphere of wave activity (sometimes called "tread"). Thus, it lies above or under the current sea level, depending on the time of its formation.[3][4] It is bounded by a steeper ascending slope on the landward side and a steeper descending slope on the seaward side[2] (sometimes called "riser"). Due to its generally flat shape it is often used for anthropogenic structures such as settlements and infrastructure.[3]		A raised beach is an emergent coastal landform. Raised beaches and marine terraces are beaches or wave-cut platforms raised above the shoreline by a relative fall in the sea level.[5]		Around the world, a combination of tectonic coastal uplift and Quaternary sea-level fluctuations has resulted in the formation of marine terrace sequences, most of which were formed during separate interglacial highstands that can be correlated to marine isotope stages (MIS).[6]		A marine terrace commonly retains a shoreline angle or inner edge, the slope inflection between the marine abrasion platform and the associated paleo sea-cliff. The shoreline angle represents the maximum shoreline of a transgression and therefore a paleo-sea level.						The platform of a marine terrace usually has a gradient between 1°–5° depending on the former tidal range with, commonly, a linear to concave profile. The width is quite variable, reaching up to 1,000 metres (3,300 ft), and seems to differ between the northern and southern hemispheres.[9] The cliff faces that delimit the platform can vary in steepness depending on the relative roles of marine and subaerial processes.[10] At the intersection of the former shore (wave-cut/abrasion-) platform and the rising cliff face the platform commonly retains a shoreline angle or inner edge (notch) that indicates the location of the shoreline at the time of maximum sea ingression and therefore a paleo-sea level.[11] Sub-horizontal platforms usually terminate in a low tide cliff, and it is believed that the occurrence of these platforms depends on tidal activity.[10] Marine terraces can extend for several tens of kilometers parallel to the coast.[3]		Older terraces are covered by marine and/or alluvial or colluvial materials while the uppermost terrace levels usually are less well preserved.[12] While marine terraces in areas of relatively rapid uplift rates (> 1 mm/year) can often be correlated to individual interglacial periods or stages, those in areas of slower uplift rates may have a polycyclic origin with stages of returning sea levels following periods of exposure to weathering.[2]		Marine terraces can be covered by a wide variety of soils with complex histories and different ages. In protected areas, allochtonous sandy parent materials from tsunami deposits may be found. Common soil types found on marine terraces include planosols and solonetz.[13]		It is now widely thought that marine terraces are formed during the separated highstands of interglacial stages correlated to marine isotope stages (MIS).[14][15][16][17][18]		The formation of marine terraces is controlled by changes in environmental conditions and by tectonic activity during recent geological times. Changes in climatic conditions have led to eustatic sea-level oscillations and isostatic movements of the Earth’s crust, especially with the changes between glacial and interglacial periods.		Processes of eustasy lead to glacioeustatic sea level fluctuations due to changes of the water volume in the oceans and hence to regressions and transgressions of the shoreline. At times of maximum glacial extent during the last glacial period, the sea level was about 100 metres (330 ft) lower compared to today. Eustatic sea level changes can also be caused by changes in the void volume of the oceans, either through sedimento-eustasy or tectono-eustasy.[19]		Processes of isostasy involve the uplift of continental crusts along with their shorelines. Today, the process of glacial isostatic adjustment mainly applies to Pleistocene glaciated areas.[19] In Scandinavia, for instance, the present rate of uplift reaches up to 10 millimetres (0.39 in)/year.[20]		In general, eustatic marine terraces were formed during separate sea level highstands of interglacial stages[19][21] and can be correlated to marine oxygene isotopic stages (MIS).[22][23] Glacioisostatic marine terraces were mainly created during stillstands of the isostatic uplift.[19] When eustasy was the main factor for the formation of marine terraces, derived sea level fluctuations can indicate former climate changes. This conclusion has to be treated with care, as isostatic adjustments and tectonic activities can be extensively overcompensated by a eustatic sea level rise. Thus, in areas of both eustatic and isostatic or tectonic influences, the course of the relative sea level curve can be complicated.[24] Hence, most of today's marine terrace sequences were formed by a combination of tectonic coastal uplift and Quaternary sea level fluctuations.		Jerky tectonic uplifts can also lead to marked terrace steps while smooth relative sea level changes may not result in obvious terraces, and their formations are often not referred to as marine terraces.[11]		Marine terraces often result from marine erosion along rocky coast lines[2] in temperate regions due to wave attack and sediment carried in the waves. Erosion also takes place in connection with weathering and cavitation. The speed of erosion is highly dependent on the shoreline material (hardness of rock[10]), the bathymetry, and the bedrock properties and can be between only a few millimeters per year for granitic rocks and more than 10 metres (33 ft) per year for volcanic ejecta.[10][25] The retreat of the sea cliff generates a shore (wave-cut/abrasion-) platform through the process of abrasion. A relative change of the sea level leads to regressions or transgressions and eventually forms another terrace (marine-cut terrace) at a different altitude while notches in the cliff face indicate short stillstands.[25]		It is believed that the terrace gradient increases with tidal range and decreases with rock resistance. In addition, the relationship between terrace width and the strength of the rock is inverse, and higher rates of uplift and subsidence as well as a higher slope of the hinterland increases the number of terraces formed during a certain time.[26]		Furthermore, shore platforms are formed by denudation and marine-built terraces arise from accumulations of materials removed by shore erosion.[2] Thus a marine terrace can be formed by both erosion and accumulation. However, there is an ongoing debate about the roles of wave erosion and weathering in the formation of shore platforms.[10]		Reef flats or uplifted coral reefs are another kind of marine terrace found in intertropical regions. They are a result of biological activity, shoreline advance and accumulation of reef materials.[2]		While a terrace sequence can date back hundreds of thousands of years, its degradation is a rather fast process. On the one hand a deeper transgression of cliffs into the shoreline may completely destroy previous terraces; on the other hand older terraces might be decayed[25] or covered by deposits, colluvia or alluvial fans.[3] Erosion and backwearing of slopes caused by incisive streams play another important role in this degradation process.[25]		The total displacement of the shoreline relative to the age of the associated interglacial stage allows calculation of a mean uplift rate or the calculation of eustatic level at a particular time if the uplift is known.		In order to estimate vertical uplift, the eustatic position of the considered paleo sea levels relative to the present one must be known as precisely as possible. Our chronology relies principally on relative dating based on geomorphologic criteria but in all cases we associated the shoreline angle of the marine terraces with numerical ages. The best-represented terrace worldwide is the one correlated to the last interglacial maximum (MISS 5e) (Hearty and Kindler, 1995; Johnson and Libbey, 1997, Pedoja et al., 2006 a,[27] b,[28] c[29]). Age of MISS 5e is arbitrarily fixed to range from 130 to 116 ka (Kukla et al., 2002[30]) but is demonstrated to range from 134 to 113 ka in Hawaii and Barbados (Muhs et al., 2002) with a peak from 128 to 116 ka on tectonically stable coastlines (Muhs, 2002). Older marine terraces well represented in worldwide sequences are those related to MIS 9 (~303-339 ka) and 11 (~362-423 ka) (Imbrie et al., 1984[31]). Compilations show that sea level was 3 ± 3 meters higher during MISS 5e, MIS 9 and 11 than during the present one and –1 ± 1 m to the present one during MIS 7 (Hearty and Kindler, 1995,[32] Zazo, 1999[33]). Consequently, MIS 7 (~180-240 ka; Imbrie et al., 1984) marine terraces are less pronounced and sometimes absent (Zazo, 1999). When the elevations of these terraces are higher than the uncertainties in paleo-eustatic sea level mentioned for the Holocene and Late Pleistocene, these uncertainties have no effect on overall interpretation.		Sequence can also occurs where the accumulation of ice sheets have depressed the land so that when the ice sheets melts the land readjusts with time thus raising the height of the beaches (glacio-isostatic rebound)and in places where co-seismic uplift occur. In the latter case, the terrace are not correlated with sea level highstand even if co-seismic terrace are known only for the Holocene.		For exact interpretations of the morphology extensive datings, surveying and mapping of marine terraces is applied. This includes stereoscopic aerial photographic interpretation (ca. 1 : 10,000 - 25,000[11]), on-site inspections with topographic maps (ca. 1 : 10,000) and analysis of eroded and accumulated material. Moreover, the exact altitude can be determined with an aneroid barometer or preferably with a levelling instrument mounted on a tripod. It should be measured with the accuracy of 1 cm and at about every 50 – 100 m, depending on the topography. In remote areas technics of photogrammetry and tacheometry can be applied.[24]		Different methods for dating and correlation of marine terraces can be used and combined.		The morphostratigraphic approach focuses especially in regions of marine regression on the altitude as the most important criterion to distinguish coast lines of different ages. Moreover, individual marine terraces can be correlated based on their size and continuity. Also paleo-soils as well as glacial, fluvial, eolian and periglacial landforms and sediments may be used to find correlations between terraces.[24] On New Zealand’s North Island, for instance, tephra and loess were used to date and correlate marine terraces.[34] At the terminus advance of former glaciers marine terraces can be correlated by their size, as their width decreases with age due to the slowly thawing glaciers along the coast line.[24]		The lithostratigraphic approach uses typical sequences of sediment and rock strata to prove sea level fluctuations on the basis of an alternation of terrestrial and marine sediments or littoral and shallow marine sediments. Those strata show typical layers of transgressive and regressive patterns.[24] However, an unconformity in the sediment sequence might make this analysis difficult.[35]		The biostratigraphic approach uses remains of organisms which can indicate the age of a marine terrace. For that often mollusc shells, foraminifera or pollen are used. Especially Mollusca can show specific properties depending on their depth of sedimentation. Thus they can be used to estimate former water depths.[24]		Marine terraces are often correlated to marine oxygene isotopic stages (MIS) (e.g. Johnson, M. E.; Libbey, L. K. 1997[22]) and can also be roughly dated using their stratigraphic position.[24]		There are various methods for the direct dating of marine terraces and their related materials including 14C radiocarbon dating, which is the most common one.[36] E.g. this method has been used on the North Island of New Zealand to date several marine terraces.[37] It utilizes terrestrial biogenic materials in coastal sediments such as mollusc shells analyzing the 14C isotope.[24] In some cases dating based on the 230Th/234U ratio was applied though in case of detrital contamination or low uranium concentrations a high resolution dating was found to be difficult.[38] In a study in southern Italy paleomagnetism was used to carry out paleomagnetic datings[39] and luminescence dating (OSL) was used in different studies on the San Andreas Fault[40] and on the Quaternary Eupcheon Fault in South Korea.[41] In the last decennia, the dating of marine terraces has been enhanced since the arrival of terrestrial cosmogenic nuclides method, and particularly through the use of 10Be and 26Al cosmogenic isotopes produced in-situ.[42][43][44] These isotopes record the duration of surface exposure to cosmic rays.[45] and this exposure age reflects the age of abandonment of a marine terrace by the sea.		In order to calculate the eustatic sea level for each dated terrace it is assumed that the eustatic sea-level position corresponding to at least one marine terrace is known and that the uplift rate has remained essentially constant in each section.[2]		Marine terraces play an important role in the research on tectonics and earthquakes. They may show patterns and rates of tectonic uplift[40][44][46] and thus may be used to estimate the tectonic activity in a certain region.[41] In some cases the exposed secondary landforms can be correlated with known seismic events such as the 1855 Wairarapa earthquake on the Wairarapa Fault near Wellington, New Zealand which produced a 2.7 m uplift.[47] This figure can be estimated from the vertical offset between raised shorelines in the area.[48]		Furthermore, with the knowledge of eustatic sea level fluctuations the speed of isostatic uplift can be estimated[49] and eventually the change of relative sea levels for certain regions can be reconstructed. Thus marine terraces also provide information for the research on climate change and trends in future sea level changes.[10][50]		When analyzing the morphology of marine terraces it must be considered, that both eustasy and isostasy can have an influence on the formation process. This way can be assessed, whether there were changes in sea level or whether tectonic activities took place.		Raised beaches are found in a wide variety of coast and geodynamical background such as subduction on the pacific coast of South America (Pedoja et al., 2006), of North America, passive margin of the Atlantic coast of South America (Rostami et al., 2000[51]), collision context on the Pacific coast of Kamchatka (Pedoja et al., 2006), Papua New Guinea, New Zealand, Japan (Ota and Yamaguchi, 2004), passive margin of the South China sea coast (Pedoja et al., in press), on west-facing Atlantic coasts, such as Donegal Bay, County Cork and County Kerry in Ireland; Bude, Widemouth Bay, Crackington Haven, Tintagel, Perranporth and St Ives in Cornwall, the Vale of Glamorgan, Gower Peninsula, Pembrokeshire and Cardigan Bay in Wales, the Isle of Jura and Isle of Arran in Scotland, Finistère in Brittany and Galicia in Northern Spain and at Squally Point in Eatonville, Nova Scotia within the Cape Chignecto Provincial Park.		Other important sites include various coasts of New Zealand, e.g. Turakirae Head near Wellington being one of the world’s best and most thoroughly studied examples.[47][48][52] Also along the Cook Strait in New Zealand there is a well-defined sequence of uplifted marine terraces from the late Quaternary at Tongue Point. It features a well preserved lower terrace from the last interglacial, a widely eroded higher terrace from the penultimate interglacial and another still higher terrace, which is nearly completely decayed.[47] Furthermore, on New Zealand’s North Island at the eastern Bay of Plenty a sequence of seven marine terraces has been studied.[12][37]		Along many coasts of mainland and islands around the Pacific, marine terraces are typical coastal features. An especially prominent marine terraced coastline can be found north of Santa Cruz, near Davenport, California, where terraces probably have been raised by repeated slip earthquakes on the San Andreas Fault.[40][53] Hans Jenny (pedologist) famously researched the pygmy forests of the Mendocino and Sonoma county marine terraces. The marine terrace's "ecological staircase" of Salt Point State Park is also bound by the San Andreas Fault.		Along the coasts of South America marine terraces are present,[44][54] where the highest ones are situated where plate margins lie above subducted oceanic ridges and the highest and most rapid rates of uplift occur.[7][46] At Cape Laundi, Sumba Island, Indonesia an ancient patch reef can be found at 475 m above sea level as part of a sequence of coral reef terraces with eleven terraces being wider than 100 m.[55] The coral marine terraces at Huon Peninsula, New Guinea, which extend over 80 km and rise over 600 m above present sea level[56] are currently on UNESCO’s tentative list for world heritage sites under the name Houn Terraces - Stairway to the Past.[57]		Other considerable examples include marine terraces rising up to 360 m on some Philippine Islands[58] and along the Mediterranean Coast of North Africa, especially in Tunisia, rising up to 400 m.[59]		Uplift can also be registered through tidal notch sequences. Notches are often portrayed as lying at sea level; however notch types actually form a continuum from wave notches formed in quiet conditions at sea level to surf notches formed in more turbulent conditions and as much as 2 m (6.6 ft) above sea level (Pirazzoli et al., 1996 in Rust and Kershaw, 2000[60]). As stated above, there was at least one higher sea level during the Holocene, so that some notches may not contain a tectonic component in their formation.		
Barrier islands are coastal landforms and a type of dune system that are exceptionally flat or lumpy areas of sand that form by wave and tidal action parallel to the mainland coast. They usually occur in chains, consisting of anything from a few islands to more than a dozen. They are subject to change during storms and other action, but absorb energy and protect the coastlines and create areas of protected waters where wetlands may flourish. A barrier chain may extend uninterrupted for over a hundred kilometers, excepting the tidal inlets that separate the islands, the longest and widest being Padre Island of Texas.[1] The length and width of barriers and overall morphology of barrier coasts are related to parameters including tidal range, wave energy, sediment supply, sea-level trends, and basement controls.[2] The amount of vegetation on the barrier has a large impact on the height and evolution of the island.[3]		Chains of barrier islands can be found along approximately thirteen percent of the world's coastlines.[4] They display different settings, suggesting that they can form and be maintained in a variety of environmental settings. Numerous theories have been given to explain their formation.						The shoreface is the part of the barrier where the ocean meets the shore of the island. The barrier island body itself separates the shoreface from the backshore and lagoon/tidal flat area. Characteristics common to the lower shoreface are fine sands with mud and possibly silt. Further out into the ocean the sediment becomes finer. The effect from the waves at this point is weak because of the depth. Bioturbation is common and many fossils can be found here.		The middle shore face is located in the upper shoreface. The middle shoreface is strongly influenced by wave action because of its depth. Closer to shore the grain size will be medium size sands with shell pieces common. Since wave action is heavier, bioturbation is not likely.		The upper shore face is constantly affected by wave action. This results in development of herringbone sedimentary structures because of the constant differing flow of waves. Grain size is larger sands.		The foreshore is the area on land between high and low tide. Like the upper shoreface, it is constantly affected by wave action. Cross bedding and lamination are present and coarser sands are present because of the high energy present by the crashing of the waves. The sand is also very well sorted.		The backshore is always above the highest water level point. The berm is also found here which marks the boundary between the foreshore and backshore. Wind is the important factor here, not water. During strong storms high waves and wind can deliver and erode sediment from the backshore.		The dunes are typical of a barrier island, located at the top of the backshore. See Coastal Dunes for more information. The dunes will display characteristics of typical aeolian wind blown dunes. The difference here is that dunes on a barrier island typically contain coastal vegetation roots and marine bioturbation.		The lagoon and tidal flat area is located behind the dune and backshore area. Here the water is still and this allows for fine silts, sands, and mud to settle out. Lagoons can become host to an anaerobic environment. This will allow high amounts of organic rich mud to form. Vegetation is also common.		Water levels may be higher than the island during storm events. This situation can lead to overwash, which brings sand from the front of the island to the top and/or landward side of the island. This process leads to the evolution and migration of the barrier island.[5]		Scientists have proposed numerous explanations for the formation of barrier islands for more than 150 years. There are three major theories: offshore bar, spit accretion, and submergence.[2] No single theory can explain the development of all barriers, which are distributed extensively along the world's coastlines. Scientists accept the idea that barrier islands, including other barrier types, can form by a number of different mechanisms.[6]		There appears to be some general requirements for formation. Barrier island systems develop most easily on wave-dominated coasts with a small to moderate tidal range. Coasts are classified into three groups based on tidal range: microtidal, 0–2 meter tidal range; mesotidal, 2–4 meter tidal range; and macrotidal, >4 meter tidal range. Barrier islands tend to form primarily along microtidal coasts, where they tend to be well developed and nearly continuous. They are less frequently formed in mesotidal coasts, where they are typically short with tidal inlets common. Barrier islands are very rare along macrotidal coasts.[7] Along with a small tidal range and a wave-dominated coast, there must be a relatively low gradient shelf. Otherwise, sand accumulation into a sandbar would not occur and instead would be dispersed throughout the shore. An ample sediment supply is also a requirement for barrier island formation.[4] The last major requirement for barrier island formation is a stable sea level. It is especially important for sea level to remain relatively unchanged during barrier island formation and growth. If sea level changes are too drastic, time will be insufficient for wave action to accumulate sand into a dune, which will eventually become a barrier island through aggradation. The formation of barrier islands requires a constant sea level so that waves can concentrate the sand into one location.[8]		In 1845 the Frenchman Elie de Beaumont published an account of barrier formation. He believed that waves moving into shallow water churned up sand, which was deposited in the form of a submarine bar when the waves broke and lost much of their energy. As the bars developed vertically, they gradually rose above sea level, forming barrier islands.		American geologist Grove Karl Gilbert first argued in 1885 that the barrier sediments came from longshore sources. He proposed that sediment moving in the breaker zone through agitation by waves in longshore drift would construct spits extending from headlands parallel to the coast. The subsequent breaching of spits by storm waves would form barrier islands.[9]		William John McGee reasoned in 1890 that the East and Gulf coasts of the United States were undergoing submergence, as evidenced by the many drowned river valleys that occur along these coasts, including Raritan, Delaware and Chesapeake bays. He believed that during submergence, coastal ridges were separated from the mainland, and lagoons formed behind the ridges.[10] He used the Mississippi-Alabama barrier islands (consists of Cat, Ship, Horn, Petit Bois and Dauphin Islands) as an example where coastal submergence formed barrier islands. His interpretation was later shown to be incorrect when the ages of the coastal stratigraphy and sediment were more accurately determined.[11]		Along the coast of Louisiana, former lobes of the Mississippi River delta have been reworked by wave action, forming beach ridge complexes. Prolonged sinking of the marshes behind the barriers has converted these former vegetated wetlands to open-water areas. In a period of 125 years, from 1853 to 1978, two small semi-protected bays behind the barrier developed as the large water body of Lake Pelto, leading to Isles Dernieres's detachment from the mainland.[6]		An unusual natural structure in New Zealand may give clues to the formation processes of barrier islands. The Boulder Bank, at the entrance to Nelson Haven at the northern end of the South Island, is a unique 13 km-long stretch of rocky substrate a few metres in width. It is not strictly a barrier island, as it is linked to the mainland at one end. The Boulder Bank is composed of granodiorite from Mackay Bluff, which lies close to the point where the bank joins the mainland. It is still debated what process or processes have resulted in this odd structure, though longshore drift is the most accepted hypothesis. Studies have been conducted since 1892 to determine the speed of boulder movement. Rates of the top-course gravel movement have been estimated at 7.5 metres a year.[12]		Barrier islands are critically important in mitigating ocean swells and other storm events for the water systems on the mainland side of the barrier island, as well as protecting the coastline. This effectively creates a unique environment of relatively low energy, brackish water. Multiple wetland systems such as lagoons, estuaries, and/or marshes can result from such conditions depending on the surroundings. They are typically rich habitats for a variety of flora and fauna. Without barrier islands, these wetlands could not exist; they would be destroyed by daily ocean waves and tides as well as ocean storm events. One of the most prominent examples is the Louisiana barrier islands.[13]		
A gulf in geography is a large bay that is an arm of an ocean or sea. Not all geological features which could be considered a gulf have "Gulf" in the name, for example the Bay of Bengal or Arabian Sea.[1]		The term may refer to:		
Nudity, or nakedness, is the state of wearing no clothing.[1] The wearing of clothing is a predominantly human characteristic arising from functional needs such as protection from the elements and from cold temperatures, after the loss of body hair, and migration to colder regions.[2] The amount of clothing worn depends on functional considerations, such as a need for warmth, as well as social circumstances. In some situations, a minimum amount of clothing or none at all may be considered socially acceptable, while in others much more clothing may be expected. Social considerations involve cultural issues of modesty, subjective decency and social norms, besides other considerations, and these may depend on the context. There may also be legal considerations.						Full nudity refers to complete nudity, while partial nudity refers to less than full nudity, with parts of the body covered in some manner. The term partial nudity is sometimes used to refer to exposure of skin beyond what the person using the expression considers to be within the limits of modesty. If the exposure is within the standards of modesty of a given culture and setting (e.g. wearing a bikini at a non-nude beach), terms such as nudity, partial or otherwise, are not normally used. If however, the degree of exposure exceeds the cultural norms of the setting, or if the activity or setting includes nudity as an understood part of its function, such as a nude beach, terminology relating to nudity and degrees thereof are typically used. Toplessness is regarded by most people as partial nudity.		Full frontal nudity describes a state of full nudity with the subject facing forward with the whole front of the body exposed, including intimate parts such as a man's penis or woman's vulva. Partial frontal nudity typically only refers to the exposure of the breasts. Non-frontal nudity describes nudity where the whole back side of the body, including the buttocks, is exposed, or a side-view from any other direction.		Hair probably evolved in mammals before about 220 million years ago. The closest genetic relatives of humans, apes and especially chimpanzees, possess an almost complete covering of fur.		Humans are today the only naked primate in nature, that is, most of the body is not naturally covered by fur. Reliable information on the development of nudity and the passage of time are not yet possible because hair does not fossilize.		Researchers at the University of Utah in 2004 found that human skin contains photoreceptors like those in the retina, allowing it to mount an immediate defence against damaging ultraviolet radiations. They suspect that the protein that protects the skin from sunlight evolved following the loss of protective hair, which happened about 1.2 million years ago.[3]		People have a variety of views on nudity, both of their own as well as those of others. This would depend on their level of inhibition, cultural background and upbringing, as well as on context. A society's attitude to public nudity varies depending on the culture, time, location and context of an activity. There are many exceptions and particular circumstances in which nudity is tolerated, accepted or even encouraged in public spaces. Such examples would include a nude beach, within some intentional communities (such as naturist resorts or clubs) and at special events.		In general and across cultures, public indications of sexual arousal are commonly regarded as embarrassing, both to the person aroused and the onlooker, and for this reason those parts of the human body that would indicate arousal are normally covered. Arousal is most evidently indicated by the sex organs and women's breasts, which are routinely covered, even when other parts of the body may be freely uncovered. Yet the nudity taboo may have meanings deeper than the immediate possibility of sexual arousal, for example, in the cumulative weight of tradition and habit. Clothing also expresses and symbolizes authority, and more general norms and values besides those of a sexual nature.		While some European countries, such as Germany, are rather tolerant of public nudity,[4] in many countries public nudity may meet social disapproval or even constitute a misdemeanor of indecent exposure. In 2012, the city council of San Francisco proposed a ban on public nudity in the inner city area. This was met by harsh resistance since the city is usually known for its liberal culture.[5][6] Similarly, park rangers began filing tickets against nudists at San Onofre State Beach in 2010, also a place with long tradition of public nudity.[7]		Some people take part in non-sexual public nude events. These may be in a naturist resort or club or at a nude beach. Outdoor nude recreation can take place in private or rural areas, though generally limited to warm weather.		Others practice casual public nudity. Topfree sunbathing is considered acceptable by many on the beaches of Finland, France, Spain, Italy and most of the rest of Europe (and even in some outdoor swimming pools); however, exposure of the genitals is restricted to nudist areas in most regions. In the United States, topfree sunbathing and wearing thongs are not common in many areas, but are limited to nude beaches in various locations. It is normally acceptable for men in the U.S. to be barechested or shirtless when engaged in outdoor recreational activities.		Where the social acceptability of nudity in certain places may be well understood, the legal position is often less clear cut. In England, for example, the law does not actually prohibit simple public nudity, but does forbid indecent exposure[citation needed]. In practice, this means that successful prosecution hangs on whether there is a demonstrable intention to shock others, rather than simply a desire to be nude in a public place. Specifically, using nudity to "harass, alarm or distress" others is an offence against the Public Order Act of 1986. Occasional attempts to prove this point by walking naked around the country therefore often result in periods of arrest, followed by release without charge, and inconsistencies in the approach between different police jurisdictions. Differences in the law between England and Scotland appear to make the position harder for naked ramblers once they reach Scotland.		Photography of installations of massed nude people in public places, as made repeatedly around the world by Spencer Tunick, claim artistic merit.		Nudity is at times used to draw attention to a cause, with the participants desiring to remain anonymous. Public nude events are at times staged as a forum for usually unrelated messages, such as clothing-optional bike rides. At times, the cause is merely a personal justification for taking part in a nude event, which are popular in their own right. Many nude calendars are produced each year featuring naked men or women. Some of these are produced to raise money for charities or other causes. Nudity, like sexuality, is also used to draw attention for a commercial purpose, such as for promotion or advertising.		In the privacy of their own homes, people are more casual in relation to clothing, though what each considers appropriate varies considerably. What and how much clothing a person removes depends on a number of considerations, including the cultural background and on whether the person is alone in the privacy of their own homes. A person's cultural background as well as their religious teachings will affect the way they view their own nudity, alone or in the presence of others, as well as viewing the nudity of others. Some cultures deprecate nudity even in a private context.		Another factor is the level of privacy to which a person can be assured - for example, some parts of a home may be seen from the outside or there may be a possibility of others walking in. The expectation of privacy may be confined to the home and sometimes the backyard. Inside the home, it may be restricted to the bedroom or just the bathroom. If a person is not alone, their comfort in removing clothing in front of another person will generally depend on the nature of a relationship of those who jointly occupy the same private space, as well as the attitudes of others to nudity. Besides the nature of a relationship, attitudes and incidences of nudity will also depend on the level of inhibition that each person has, as well as the level of privacy to which that they can be assured. Sometimes a person may unintentionally intrude on a person who is in the nude, which may lead to embarrassment of one or both of the people. The nude person may seek to quickly cover their private parts, while the clothed person may turn away, but this also depends on cultural differences and the relationship of the people.		In the case of nudity in front of those who do not normally occupy the same private space, that will usually depend on whether the outsider is comfortable with the nudity and whether the nudity is reciprocated, as in the case of social nudism. Social nudism may take place in any private social context, such as at one's home with friends or with acquaintances at a nudist facility or event, such as a naturist club, community center, resort or other facility. Some social gatherings may organise party games, which may involve some level of nudity, such as strip games. Strip games can be played by single-sex groups or by mixed groups and may be intended to generate an atmosphere of fun and lighten the social atmosphere, or to heighten the sexual atmosphere.		A 1999 survey by the Federation of Canadian Naturists found, besides other things, that 39% of Canadians "have walked or would walk around their house nude"; that naturists tend to have above average incomes; that urban dwellers are more likely to be naturists than country dwellers; and that people under the age of 25 are the most likely to be naturists.[8] According to a 2004 United States survey, 31% of men and 14% of women report sleeping in the nude,[9] while a 1996 BBC survey revealed that in the UK 47% of men and 17% of women do.[10]		Nudity in front of a sexual partner is widely accepted, but not in all cases. For example, some partners insist on nudity only at the time and place of sex, or with subdued lighting; during bathing with the partner or afterward; covered by a sheet or blanket, or while sleeping.		The invention of photography and more recently the video camera has opened the art of capturing images of people and scenes at a relatively low cost to the true amateur. A person can now capture images in both public and private situations. A feature of most private photographs and videos is that they are not intended for viewing outside of a very limited range of people, and seldom if ever by the general public. Amateur photography, which includes nude photography, which has previously been produced for personal enjoyment, is increasingly being more widely disseminated through the internet, at times without the knowledge and consent of the subject of the photograph, and to their subsequent embarrassment. Also, the use of secret photography to capture images of an unsuspecting person (undressed or not, and whether for personal use, or intended for posting on the Internet) creates additional personal privacy issues.		There are differences of opinion as to whether, and if so to what extent, parents should appear naked in front of their children. Gordon and Schroeder report that parental nudity varies considerably from family to family.[11] They say that "there is nothing inherently wrong with bathing with children or otherwise appearing naked in front of them", noting that doing so may provide an opportunity for parents to provide important information. They note that by ages five to six, children begin to develop a sense of modesty, and recommend to parents who wish to be sensitive to their children's wishes that they limit such activities from that age onwards. Bonner recommends against nudity in the home if children exhibit sexual play of a type that is considered problematic.[12]		A U.S. study by Alfred Kinsey found that 75% of the participants stated that there was never nudity in the home when they were growing up, 5% of the participants said that there was "seldom" nudity in the home, 3% said "often", and 17% said that it was "usual". The study found that there was no significant difference between what was reported by men and by women with respect to frequency of nudity in the home.[13]		In a 1995 review of the literature, Paul Okami concluded that there was no reliable evidence linking exposure to parental nudity to any negative effect.[14] Three years later, his team finished an 18-year longitudinal study that showed that, if anything, such exposure was associated with slight beneficial effects, particularly for boys.[15]		Attitudes toward children seeing nude people vary substantially, depending on the child's culture, age and the context of the nudity (see also the section Home above).		Television and radio regulations in many countries require broadcasters to avoid transmitting images or language considered inappropriate for children from 5:30 am to 9 pm (the so-called "watershed"). In the United Kingdom, the Broadcasting Code states, "Nudity before the watershed must be justified by the context."[16] In the U.S., the safe harbor rule forbids depictions of nudity between the hours of 6 am and 10 pm. Violators may be subject to civil legal action and sanctions if the Federal Communications Commission (FCC) determines the broadcaster did not meet its standards of "decency". "Material is indecent if, in context, it depicts or describes sexual or excretory organs or activities in terms patently offensive as measured by contemporary community standards for the broadcast medium."[17]		Attitudes to nudity vary substantially throughout Europe. Male and female nudity in Scandinavia is not uncommon. The region has a very open attitude about nudity, although it strictly prohibits children's access to pornography.[18]		Another issue has been the nudity of children in front of other children.		In continental Europe, students tend to shower communally after physical education classes, separated by gender. Fathers taking their young daughters or mothers taking their young sons into the gender-separated changing rooms is mostly viewed as non-controversial, although some public baths have introduced family changing rooms. Some private gymnasiums have instituted rules specifically banning family members of opposite genders taking their children into single-sex locker rooms.[citation needed]		In the U.S. and some of the English-speaking majority of Canada, students at public schools have historically been required to shower communally with classmates of the same sex after physical education classes. In the U.S., public objections and the threat of lawsuits have resulted in a number of school districts in recent years changing policy to make showers optional. Private boarding schools and military academies in the U.S. often have communal showers, since the focus there is on 24-hours-a-day education and rooming, rather than just acting as day schools. Students in these establishments need places to clean themselves daily.[19] A court case in Colorado noted that students have a reduced expectation of personal privacy in regards to "communal undress" while showering after physical education classes.[20] According to an interview with a middle school principal, most objections to showering at school that he had heard were actually from the students' parents rather than from the students.[21]		Children who are within a naturist home will usually also be naked, together with their family, and may see and be seen by non-family members in the nude. They may also be taken to naturist venues and events where they, their families and others would also generally be nude.		Nudity in film has, since the development of the medium, been somewhat controversial, though there was no defined censorship, especially of nudity, in the early years of Hollywood, until the Hays Code of the 1930s. Under present-day guidelines, most nude scenes in films have had to be justified as being part of the story, in the concept of "artistically justifiable nudity". In some cases nudity is itself the object of a film or is used in the development of the character of the subject. There are film scenes where nudity, in routine and non-sexual situations, such as mixed shower scenes, has been used to emphasize gender equality in the future.[22][23][24]		In some cases, nudity has been criticized as "superfluous" or "gratuitous" to the plot, and some film producers have been accused of including nudity in a film to appeal to audiences. Many actors and actresses have appeared nude, or exposing parts of their bodies or dressed in ways considered provocative by contemporary standards at some point in their careers.		Erotic films usually contain nudity, and nudity in a sexual context is common in pornographic films. A film on naturism, or about people for whom nudity is common, for example, many societies and people who live in hot climates, or films set in times such as the 1960s or 1970s era of liberation, may contain non-sexual nudity, and many non-pornographic films contain nude scenes.		Mainstream art generally reflects – with some exceptions – social standards of aesthetics and morality of a society at various periods of time. Beyond mainstream standards, artistic expression may be merely tolerated, or be considered as fringe. Since prehistoric time, humans, both male and female, have been depicted in all states of dress, including all states of undress. Nudity in all styles has been and continues to be found in art. Nudity is also a subject of many literary works and in film. All professionally produced works of art use stylised compositions to depict the nude body. This also applies to cinema, where even nude scenes are staged and rehearsed.		The erotic aspect of nudity in the arts has been an important factor in its attraction, and has come to be associated with certain states and emotions, such as innocence, playfulness, vulnerability, etc. Pornography does not necessarily involve a naked person, but it involves sexualized scenes, and usually it does not claim to have any artistic merit.		The visual arts were at times the only means available to the general public to view a nude body. Today, the opportunities available for the viewing of the nude body are very wide, and these include magazines, television, films, and the Internet.		Depictions of child nudity or children with nude adults appear in works of art in various cultures and historical periods. These attitudes have changed over time and have become increasingly frowned upon particularly in recent years,[25] especially in the case of photography. In recent years, there have been a few incidents in which snapshots taken by parents of their infant or toddler children bathing or otherwise naked were challenged as child pornography.[26]		In May 2008, police in Sydney, Australia, raided an exhibition by the photographer Bill Henson featuring images of naked children on allegations of child pornography.[27][28] Comparable artworks by Henson had been exhibited without incident since 1975, perhaps indicating that this sensitivity has heightened in recent years.		In June 2008, it was reported in The Age that police would have no basis to prosecute Henson over his photographs of naked teenagers, after they were declared "mild and justified" and given a PG rating by the Australian Classification Board, suggesting viewing by children under the age of 16 is suitable with parental guidance.[29] Out of protest, the Art Monthly Australia magazine published an image of the 6-year-old Olympia Nelson taken by her mother, Polixeni Papapetrou. According to the then-11-year-old Olympia, she did not believe the photograph amounted to abuse and was upset with Prime Minister Kevin Rudd's remark that he hated it. Olympia's father, art critic Professor Robert Nelson, defended it, saying: "It has nothing to do with pedophilia. The connection between artistic pictures and pedophilia cannot be made and there is no evidence for it."[30][31]		A full-body scanner is a device that creates an image of a person's nude body through their clothing to look for hidden objects without physically removing their clothes or making physical contact. They are increasingly being deployed at airports and train stations in many countries.		One technology used under the name "full-body scanner" is the millimeter wave scanner, the active form of which reflects extremely high frequency radio waves off the body to make an image on which one can see some types of objects hidden under the clothes. Passive millimeter wave screening devices rely on only the raw energy that is naturally emitted from the human body or objects concealed on the body; passive devices do not transmit millimeter waves.[32][33] Another technology in use is the backscatter X-ray.		In some situations, nudity is imposed on a person. For example, imposed nudity (full or partial) can be part of a corporal punishment or as humiliation, especially when administered in public. In fact, torture manuals have distinguished between the male and female psychological aversion to self-exposure versus being disrobed.		Nazis used forced nudity to attempt to humiliate inmates in concentration camps. This was depicted in the film Schindler's List.[34]		In 2003, Abu Ghraib prison in Baghdad (Iraq) gained international notoriety for accounts of torture and abuses by members of the United States Army Reserve during the post-invasion period. Photographic images were circulated that exposed the posing of prisoners naked, sometimes bound, and being intimidated and otherwise humiliated, resulting in widespread condemnation of the abuse.		Functional nudity for a short time, such as when changing clothes on a beach, is sometimes acceptable, while staying nude on the beach generally is not nor is it legal in some jurisdictions. On designated nude beaches, it is acceptable and legal to be nude.		Breastfeeding in public is forbidden in some jurisdictions, not legislated for in others, and a legal right in public and the workplace in yet others. Where it is a legal right, some mothers may be reluctant to breastfeed,[35][36] and some people may object to the practice.[37]		In some cultures, toplessness is regarded as partial nudity, and the exposure of breasts or nipples may be regarded as indecent exposure. However, in many western societies and in appropriate settings, such as while suntanning, toplessness is not, of itself, normally regarded as indecent.[citation needed] In the United States, however, exposure of female nipples is a criminal offense in many states and not usually allowed in public (see indecent exposure), while in the United Kingdom, nudity may not be used to "harass, alarm or distress" according to the Public Order Act of 1986.[38] Different standards apply to art, with one example being the dome of the US Capitol featuring a fresco depicting goddesses with their breasts exposed.		Prosecution of cases has given rise to a movement advocating "topfreedom", promoting equal rights for women to have no clothing above the waist, on the same basis that would apply to men in the same circumstances. The term topfree rather than topless is advocated to avoid the latter term's perceived sexual connotations.		Naturism (or nudism) is a cultural and political movement practising, advocating and defending private and public nudity. It is also a lifestyle based on personal, family and/or social preference.[39][40]		Naturists reject contemporary standards of modesty, which discourage personal, family and social nudity. They instead seek to create a social environment where individuals feel comfortable in the company of nude people, and being seen nude, either just by other naturists, or also by the general public.[39][40]		The trend in some European countries (for instance Germany, Finland and the Netherlands) is to allow both genders to bathe together naked. Many German spas allow mixed nude bathing. For example, the Friedrichsbad in Baden-Baden has designated times when mixed nude bathing is permitted. Most German (not to mention French, Spanish and Greek) beaches and swimming pools offer FKK (clothing-optional) areas. In general, continental Europeans have a more relaxed attitude about nudity than is seen in the British-influenced world. Some have attributed this difference to the influence of Queen Victoria's husband Albert, who was raised in a very restricting religious sect (see Victorian morality).		The sauna, originating from Finland, is attended nude in its source country[41] as well as in most Scandinavian and in the German-speaking countries of Europe.[42] This is true even when a swimsuit must be worn in the swimming pool area of the same complex.[41] Saunas are very common in modern Finland, where there is one sauna for every three people[43] and became very popular in the remainder of Europe in recent decades. German soldiers had got to know the Finnish saunas during their fight against the Soviet Union in the Continuation War, where Germany and Finland fought on the same side. Finnish hygiene depended so exclusively on saunas, that they had built saunas not only in mobile tents but even in bunkers.[42]. After the war, the German soldiers brought the habit back to Germany and Austria, where it became popular in the second half of the 20th century.[42] The German sauna culture also became popular in neighbouring contries such as Switzerland, Belgium, the Netherlands and Luxemburg.[44] In contrast to Scandinavia, public sauna facilities in these countries commonly do not seggregate genders while still keeping the rule of general nudity.[45][44]		In Russia, public banyas are also attended nude, however, they are always segregated by gender, either by having separate sections, or by days of the week. Shared areas (such as swimming pools), if present, can only be attended in bathing suits.		Attitudes in Western cultures are not all the same as explained above, and likewise attitudes in non-Western cultures are many and variant. In almost all cultures, acceptability of nudity depends on the situation.		Cultural and/or religious traditions usually dictate what is proper and what is not socially acceptable. Many non-Western cultures allow women to breastfeed in public, while some have very strict laws about showing any bare skin.		In Africa, women have used stripping naked on purpose as a curse, both historically, and in modern times. The idea is that women give life and they can take it away. The curse initiates an extreme form of ostracism, which anthropologist Terisa Turner has likened to "social execution". The curse extends to foreign men as well, and is believed to cause impotence, madness or other similar harm.[46] The threat has been used successfully in mass protests against the petroleum industry in Nigeria,[47] by Leymah Gbowee during the Second Liberian Civil War,[48] and against President Laurent Gbagbo of the Ivory Coast.[49]		Different traditions exist among, for example, sub-Saharan Africans, partly persisting in the post-colonial era. Whereas it is the norm among some ethnic and family groups including some Burkinabese and Nilo-Saharan (e.g. Nuba and Surma people) in daily life or on particular occasions not to wear any clothes or without any covering below the waist – for example, at highly attended stick-fighting tournaments well-exposed young men use the occasion to catch the eye of a prospective bride.		In modern Liberia, soldiers under General "Butt Naked" Joshua Blahyi fought naked in order to terrorize their opponents.[50] Nude except for lace-up leather shoes and a gun, the general led his fierce Butt Naked Battalion into battle on behalf of the warlord Roosevelt Johnson, who hired the unclothed warriors for their fearlessness and fighting skills.		In Brazil, the Yawalapiti, an indigenous Xingu tribe in the Amazon Basin, practice a funeral ritual known as Quarup, to celebrate life, death and rebirth, and also involves the presentation of all young girls who have begun menstruating since the last Quarup and whose time has come to choose a partner.		In Japan, public baths are very common. Bathing nude with family members or friends in public bath houses, saunas, or natural hot springs (Onsen) is popular.		In Korea, public baths (Jjimjilbang) are widespread and communal nude bathing is normal, although nudity is not permitted in unisex areas.		Nudity is considered shamelessness in the conservative society of India, although nude beaches can be found in Goa and nude saints like those of the Digambara sect of Jainism and Hindu Sadhus are respected and worshipped.		In many Muslim countries, public nudity is illegal.		
Coral reefs are diverse underwater ecosystems held together by calcium carbonate structures secreted by corals. Coral reefs are built by colonies of tiny animals found in marine water that contain few nutrients. Most coral reefs are built from stony corals, which in turn consist of polyps that cluster in groups. The polyps belong to a group of animals known as Cnidaria, which also includes sea anemones and jellyfish. Unlike sea anemones, corals secrete hard carbonate exoskeletons which support and protect the coral polyps. Most reefs grow best in warm, shallow, clear, sunny and agitated water.		Often called "rainforests of the sea", shallow coral reefs form some of the most diverse ecosystems on Earth. They occupy less than 0.1% of the world's ocean surface, about half the area of France, yet they provide a home for at least 25% of all marine species,[1][2][3][4] including fish, mollusks, worms, crustaceans, echinoderms, sponges, tunicates and other cnidarians.[5] Paradoxically, coral reefs flourish even though they are surrounded by ocean waters that provide few nutrients. They are most commonly found at shallow depths in tropical waters, but deep water and cold water corals also exist on smaller scales in other areas.		Coral reefs deliver ecosystem services to tourism, fisheries and shoreline protection. The annual global economic value of coral reefs is estimated between US$29.8-375 billion.[6][7] However, coral reefs are fragile ecosystems, partly because they are very sensitive to water temperature. They are under threat from climate change, oceanic acidification, blast fishing, cyanide fishing for aquarium fish, sunscreen use,[8] overuse of reef resources, and harmful land-use practices, including urban and agricultural runoff and water pollution, which can harm reefs by encouraging excess algal growth.[9][10][11]						Most of the coral reefs we can see today were formed after the last glacial period when melting ice caused the sea level to rise and flood the continental shelves. This means that most modern coral reefs are less than 10,000 years old. As communities established themselves on the shelves, the reefs grew upwards, pacing rising sea levels. Reefs that rose too slowly could become drowned reefs. They are covered by so much water that there was insufficient light.[12] Coral reefs are found in the deep sea away from continental shelves, around oceanic islands and as atolls. The vast majority of these islands are volcanic in origin. The few exceptions have tectonic origins where plate movements have lifted the deep ocean floor on the surface.		In 1842 in his first monograph, The Structure and Distribution of Coral Reefs,[13] Charles Darwin set out his theory of the formation of atoll reefs, an idea he conceived during the voyage of the Beagle. He theorized uplift and subsidence of the Earth's crust under the oceans formed the atolls.[14] Darwin’s theory sets out a sequence of three stages in atoll formation. It starts with a fringing reef forming around an extinct volcanic island as the island and ocean floor subsides. As the subsidence continues, the fringing reef becomes a barrier reef, and ultimately an atoll reef.		Darwin’s theory starts with a volcanic island which becomes extinct		As the island and ocean floor subside, coral growth builds a fringing reef, often including a shallow lagoon between the land and the main reef.		As the subsidence continues, the fringing reef becomes a larger barrier reef further from the shore with a bigger and deeper lagoon inside.		Ultimately, the island sinks below the sea, and the barrier reef becomes an atoll enclosing an open lagoon.		Darwin predicted that underneath each lagoon would be a bed rock base, the remains of the original volcano. Subsequent drilling proved this correct. Darwin's theory followed from his understanding that coral polyps thrive in the clean seas of the tropics where the water is agitated, but can only live within a limited depth range, starting just below low tide. Where the level of the underlying earth allows, the corals grow around the coast to form what he called fringing reefs, and can eventually grow out from the shore to become a barrier reef.		Where the bottom is rising, fringing reefs can grow around the coast, but coral raised above sea level dies and becomes white limestone. If the land subsides slowly, the fringing reefs keep pace by growing upwards on a base of older, dead coral, forming a barrier reef enclosing a lagoon between the reef and the land. A barrier reef can encircle an island, and once the island sinks below sea level a roughly circular atoll of growing coral continues to keep up with the sea level, forming a central lagoon. Barrier reefs and atolls do not usually form complete circles, but are broken in places by storms. Like sea level rise, a rapidly subsiding bottom can overwhelm coral growth, killing the coral polyps and the reef, due to what is called coral drowning.[16] Corals that rely on zooxanthellae can drown when the water becomes too deep for their symbionts to adequately photosynthesize, due to decreased light exposure.[17]		The two main variables determining the geomorphology, or shape, of coral reefs are the nature of the underlying substrate on which they rest, and the history of the change in sea level relative to that substrate.		The approximately 20,000-year-old Great Barrier Reef offers an example of how coral reefs formed on continental shelves. Sea level was then 120 m (390 ft) lower than in the 21st century.[18][19] As sea level rose, the water and the corals encroached on what had been hills of the Australian coastal plain. By 13,000 years ago, sea level had risen to 60 m (200 ft) lower than at present, and many hills of the coastal plains had become continental islands. As the sea level rise continued, water topped most of the continental islands. The corals could then overgrow the hills, forming the present cays and reefs. Sea level on the Great Barrier Reef has not changed significantly in the last 6,000 years,[19] and the age of the modern living reef structure is estimated to be between 6,000 and 8,000 years.[20] Although the Great Barrier Reef formed along a continental shelf, and not around a volcanic island, Darwin's principles apply. Development stopped at the barrier reef stage, since Australia is not about to submerge. It formed the world's largest barrier reef, 300–1,000 m (980–3,280 ft) from shore, stretching for 2,000 km (1,200 mi).[21]		Healthy tropical coral reefs grow horizontally from 1 to 3 cm (0.39 to 1.18 in) per year, and grow vertically anywhere from 1 to 25 cm (0.39 to 9.84 in) per year; however, they grow only at depths shallower than 150 m (490 ft) because of their need for sunlight, and cannot grow above sea level.[22]		As the name implies, the bulk of coral reefs is made up of coral skeletons from mostly intact coral colonies. As other chemical elements present in corals become incorporated into the calcium carbonate deposits, aragonite is formed. However, shell fragments and the remains of calcareous algae such as the green-segmented genus Halimeda can add to the reef's ability to withstand damage from storms and other threats. Such mixtures are visible in structures such as Eniwetok Atoll.[23]		The three principal reef types are:		Other reef types or variants are:		Coral reef ecosystems contain distinct zones that represent different kinds of habitats. Usually, three major zones are recognized: the fore reef, reef crest, and the back reef (frequently referred to as the reef lagoon).		All three zones are physically and ecologically interconnected. Reef life and oceanic processes create opportunities for exchange of seawater, sediments, nutrients, and marine life among one another.		Thus, they are integrated components of the coral reef ecosystem, each playing a role in the support of the reefs' abundant and diverse fish assemblages.		Most coral reefs exist in shallow waters less than 50 m deep. Some inhabit tropical continental shelves where cool, nutrient rich upwelling does not occur, such as Great Barrier Reef. Others are found in the deep ocean surrounding islands or as atolls, such as in the Maldives. The reefs surrounding islands form when islands subside into the ocean, and atolls form when an island subsides below the surface of the sea.		Alternatively, Moyle and Cech distinguish six zones, though most reefs possess only some of the zones.[25]		The reef surface is the shallowest part of the reef. It is subject to the surge and the rise and fall of tides. When waves pass over shallow areas, they shoal, as shown in the diagram at the right. This means the water is often agitated. These are the precise condition under which corals flourish. Shallowness means there is plenty of light for photosynthesis by the symbiotic zooxanthellae, and agitated water promotes the ability of coral to feed on plankton. However, other organisms must be able to withstand the robust conditions to flourish in this zone.		The off-reef floor is the shallow sea floor surrounding a reef. This zone occurs by reefs on continental shelves. Reefs around tropical islands and atolls drop abruptly to great depths, and do not have a floor. Usually sandy, the floor often supports seagrass meadows which are important foraging areas for reef fish.		The reef drop-off is, for its first 50 m, habitat for many reef fish who find shelter on the cliff face and plankton in the water nearby. The drop-off zone applies mainly to the reefs surrounding oceanic islands and atolls.		The reef face is the zone above the reef floor or the reef drop-off. This zone is often the most diverse area of the reef. Coral and calcareous algae growths provide complex habitats and areas which offer protection, such as cracks and crevices. Invertebrates and epiphytic algae provide much of the food for other organisms.[25] A common feature on this forereef zone is spur and groove formations which serve to transport sediment downslope.		The reef flat is the sandy-bottomed flat, which can be behind the main reef, containing chunks of coral. This zone may border a lagoon and serve as a protective area, or it may lie between the reef and the shore, and in this case is a flat, rocky area. Fishes tend to prefer living in that flat, rocky area, compared to any other zone, when it is present.[25]		The reef lagoon is an entirely enclosed region, which creates an area less affected by wave action that often contains small reef patches.[25]		However, the "topography of coral reefs is constantly changing. Each reef is made up of irregular patches of algae, sessile invertebrates, and bare rock and sand. The size, shape and relative abundance of these patches changes from year to year in response to the various factors that favor one type of patch over another. Growing coral, for example, produces constant change in the fine structure of reefs. On a larger scale, tropical storms may knock out large sections of reef and cause boulders on sandy areas to move."[26]		Coral reefs are estimated to cover 284,300 km2 (109,800 sq mi),[27] just under 0.1% of the oceans' surface area. The Indo-Pacific region (including the Red Sea, Indian Ocean, Southeast Asia and the Pacific) account for 91.9% of this total. Southeast Asia accounts for 32.3% of that figure, while the Pacific including Australia accounts for 40.8%. Atlantic and Caribbean coral reefs account for 7.6%.[2]		Although corals exist both in temperate and tropical waters, shallow-water reefs form only in a zone extending from approximately 30° N to 30° S of the equator. Tropical corals do not grow at depths of over 50 meters (160 ft). The optimum temperature for most coral reefs is 26–27 °C (79–81 °F), and few reefs exist in waters below 18 °C (64 °F).[28] However, reefs in the Persian Gulf have adapted to temperatures of 13 °C (55 °F) in winter and 38 °C (100 °F) in summer.[29] There are 37 species of scleractinian corals identified in such harsh environment around Larak Island.[30]		Deep-water coral can exist at greater depths and colder temperatures at much higher latitudes, as far north as Norway.[31] Although deep water corals can form reefs, very little is known about them.		Coral reefs are rare along the west coasts of the Americas and Africa, due primarily to upwelling and strong cold coastal currents that reduce water temperatures in these areas (respectively the Peru, Benguela and Canary streams).[32] Corals are seldom found along the coastline of South Asia—from the eastern tip of India (Chennai) to the Bangladesh and Myanmar borders[2]—as well as along the coasts of northeastern South America and Bangladesh, due to the freshwater release from the Amazon and Ganges Rivers respectively.		Alive corals are colonies of small animals embedded in calcium carbonate shells. It is a mistake to think of coral as plants or rocks. Coral heads consist of accumulations of individual animals called polyps, arranged in diverse shapes.[37] Polyps are usually tiny, but they can range in size from a pinhead to 12 inches (30 cm) across.		Reef-building or hermatypic corals live only in the photic zone (above 50 m), the depth to which sufficient sunlight penetrates the water, allowing photosynthesis to occur. Coral polyps do not photosynthesize, but have a symbiotic relationship with microscopic algae of the genus Symbiodinium, commonly referred to as zooxanthellae. These organisms live within the tissues of polyps and provide organic nutrients that nourish the polyp. Because of this relationship, coral reefs grow much faster in clear water, which admits more sunlight. Without their symbionts, coral growth would be too slow to form significant reef structures. Corals get up to 90% of their nutrients from their symbionts.[38]		Reefs grow as polyps and other organisms deposit calcium carbonate,[39][40] the basis of coral, as a skeletal structure beneath and around themselves, pushing the coral head's top upwards and outwards.[41] Waves, grazing fish (such as parrotfish), sea urchins, sponges, and other forces and organisms act as bioeroders, breaking down coral skeletons into fragments that settle into spaces in the reef structure or form sandy bottoms in associated reef lagoons. Many other organisms living in the reef community contribute skeletal calcium carbonate in the same manner.[42] Coralline algae are important contributors to reef structure in those parts of the reef subjected to the greatest forces by waves (such as the reef front facing the open ocean). These algae strengthen the reef structure by depositing limestone in sheets over the reef surface.		Typical shapes for coral species are wrinkled brains, cabbages, table tops, antlers, wire strands and pillars. These shapes can depend on the life history of the coral, like light exposure and wave action,[43] and events such as breakages.[44]		Corals reproduce both sexually and asexually. An individual polyp uses both reproductive modes within its lifetime. Corals reproduce sexually by either internal or external fertilization. The reproductive cells are found on the mesenteries, membranes that radiate inward from the layer of tissue that lines the stomach cavity. Some mature adult corals are hermaphroditic; others are exclusively male or female. A few species change sex as they grow.		Internally fertilized eggs develop in the polyp for a period ranging from days to weeks. Subsequent development produces a tiny larva, known as a planula. Externally fertilized eggs develop during synchronized spawning. Polyps release eggs and sperm into the water en masse, simultaneously. Eggs disperse over a large area. The timing of spawning depends on time of year, water temperature, and tidal and lunar cycles. Spawning is most successful when there is little variation between high and low tide. The less water movement, the better the chance for fertilization. Ideal timing occurs in the spring. Release of eggs or planula usually occurs at night, and is sometimes in phase with the lunar cycle (three to six days after a full moon). The period from release to settlement lasts only a few days, but some planulae can survive afloat for several weeks. They are vulnerable to predation and environmental conditions. The lucky few planulae which successfully attach to substrate next confront competition for food and space.[citation needed]		There are eight clades of Symbiodinium phylotypes. Most research has been completed on the Symbiodinium clades A–D. Each one of the eight contributes their own benefits as well as less compatible attributes to the survival of their coral hosts. Each photosynthetic organism has a specific level of sensitivity to photodamage of compounds needed for survival, such as proteins. Rates of regeneration and replication determine the organism's ability to survive. Phylotype A is found more in the shallow regions of marine waters. It is able to produce mycosporine-like amino acids that are UV resistant, using a derivative of glycerin to absorb the UV radiation and allowing them to become more receptive to warmer water temperatures. In the event of UV or thermal damage, if and when repair occurs, it will increase the likelihood of survival of the host and symbiont. This leads to the idea that, evolutionarily, clade A is more UV resistant and thermally resistant than the other clades.[45]		Clades B and C are found more frequently in the deeper water regions, which may explain the higher susceptibility to increased temperatures. Terrestrial plants that receive less sunlight because they are found in the undergrowth can be analogized to clades B, C, and D. Since clades B through D are found at deeper depths, they require an elevated light absorption rate to be able to synthesize as much energy. With elevated absorption rates at UV wavelengths, the deeper occurring phylotypes are more prone to coral bleaching versus the more shallow clades. Clade D has been observed to be high temperature-tolerant, and as a result it has a higher rate of survival than clades B and C.[45]		Brain coral		Staghorn coral		Spiral wire coral		Pillar coral		Mushroom coral		Maze coral		Black coral		Fluorescent coral[46]		Recent oceanographic research has brought to light the reality of this paradox by confirming that the oligotrophy of the ocean euphotic zone persists right up to the swell-battered reef crest. When you approach the reef edges and atolls from the quasidesert of the open sea, the near absence of living matter suddenly becomes a plethora of life, without transition. So why is there something rather than nothing, and more precisely, where do the necessary nutrients for the functioning of this extraordinary coral reef machine come from?"		In The Structure and Distribution of Coral Reefs, published in 1842, Darwin described how coral reefs were found in some areas of the tropical seas but not others, with no obvious cause. The largest and strongest corals grew in parts of the reef exposed to the most violent surf and corals were weakened or absent where loose sediment accumulated.[48]		Tropical waters contain few nutrients[49] yet a coral reef can flourish like an "oasis in the desert".[50] This has given rise to the ecosystem conundrum, sometimes called "Darwin's paradox": "How can such high production flourish in such nutrient poor conditions?"[51][52][53]		Coral reefs cover less than 0.1% of the surface of the world’s ocean, about half the land area of France, yet they support over one-quarter of all marine species. This diversity results in complex food webs, with large predator fish eating smaller forage fish that eat yet smaller zooplankton and so on. However, all food webs eventually depend on plants, which are the primary producers. Coral reefs' primary productivity is very high, typically producing 5–10 grams of carbon per square meter per day (gC·m−2·day−1) biomass.[54][55]		One reason for the unusual clarity of tropical waters is they are deficient in nutrients and drifting plankton. Further, the sun shines year-round in the tropics, warming the surface layer, making it less dense than subsurface layers. The warmer water is separated from deeper, cooler water by a stable thermocline, where the temperature makes a rapid change. This keeps the warm surface waters floating above the cooler deeper waters. In most parts of the ocean, there is little exchange between these layers. Organisms that die in aquatic environments generally sink to the bottom, where they decompose, which releases nutrients in the form of nitrogen (N), phosphorus (P) and potassium (K). These nutrients are necessary for plant growth, but in the tropics, they do not directly return to the surface.[citation needed]		Plants form the base of the food chain, and need sunlight and nutrients to grow. In the ocean, these plants are mainly microscopic phytoplankton which drift in the water column. They need sunlight for photosynthesis, which powers carbon fixation, so they are found only relatively near the surface. But they also need nutrients. Phytoplankton rapidly use nutrients in the surface waters, and in the tropics, these nutrients are not usually replaced because of the thermocline.[citation needed]		Around coral reefs, lagoons fill in with material eroded from the reef and the island. They become havens for marine life, providing protection from waves and storms.		Most importantly, reefs recycle nutrients, which happens much less in the open ocean. In coral reefs and lagoons, producers include phytoplankton, as well as seaweed and coralline algae, especially small types called turf algae, which pass nutrients to corals.[56] The phytoplankton are eaten by fish and crustaceans, who also pass nutrients along the food web. Recycling ensures fewer nutrients are needed overall to support the community.		Coral reefs support many symbiotic relationships. In particular, zooxanthellae provide energy to coral in the form of glucose, glycerol, and amino acids.[57] Zooxanthellae can provide up to 90% of a coral’s energy requirements.[38] In return, as an example of mutualism, the corals shelter the zooxanthellae, averaging one million for every cubic centimeter of coral, and provide a constant supply of the carbon dioxide they need for photosynthesis.		Corals also absorb nutrients, including inorganic nitrogen and phosphorus, directly from water. Many corals extend their tentacles at night to catch zooplankton that brush them when the water is agitated. Zooplankton provide the polyp with nitrogen, and the polyp shares some of the nitrogen with the zooxanthellae, which also require this element.[56] The varying pigments in different species of zooxanthellae give them an overall brown or golden-brown appearance, and give brown corals their colors. Other pigments such as reds, blues, greens, etc. come from colored proteins made by the coral animals. Coral which loses a large fraction of its zooxanthellae becomes white (or sometimes pastel shades in corals that are richly pigmented with their own colorful proteins) and is said to be bleached, a condition which, unless corrected, can kill the coral.		Sponges are another key: they live in crevices in the coral reefs. They are efficient filter feeders, and in the Red Sea they consume about 60% of the phytoplankton that drifts by. The sponges eventually excrete nutrients in a form the corals can use.[58]		The roughness of coral surfaces is the key to coral survival in agitated waters. Normally, a boundary layer of still water surrounds a submerged object, which acts as a barrier. Waves breaking on the extremely rough edges of corals disrupt the boundary layer, allowing the corals access to passing nutrients. Turbulent water thereby promotes reef growth and branching. Without the nutritional gains brought by rough coral surfaces, even the most effective recycling would leave corals wanting in nutrients.[59]		Studies have shown that deep nutrient-rich water entering coral reefs through isolated events may have significant effects on temperature and nutrient systems.[60][61] This water movement disrupts the relatively stable thermocline that usually exists between warm shallow water to deeper colder water. Leichter et al. (2006)[62] found that temperature regimes on coral reefs in the Bahamas and Florida were highly variable with temporal scales of minutes to seasons and spatial scales across depths.		Water can be moved through coral reefs in various ways, including current rings, surface waves, internal waves and tidal changes.[60][63][64][65] Movement is generally created by tides and wind. As tides interact with varying bathymetry and wind mixes with surface water, internal waves are created. An internal wave is a gravity wave that moves along density stratification within the ocean. When a water parcel encounters a different density it will oscillate and create internal waves.[66] While internal waves generally have a lower frequency than surface waves, they often form as a single wave that breaks into multiple waves as it hits a slope and moves upward.[67] This vertical break up of internal waves causes significant diapycnal mixing and turbulence.[68][69] Internal waves can act as nutrient pumps, bringing plankton and cool nutrient-rich water up to the surface.[60][65][70][71][72][73][74][75][76][77][78]		The irregular structure characteristic of coral reef bathymetry may enhance mixing and produce pockets of cooler water and variable nutrient content.[79] Arrival of cool, nutrient-rich water from depths due to internal waves and tidal bores has been linked to growth rates of suspension feeders and benthic algae[65][78][80] as well as plankton and larval organisms.[65][81] Leichter et al.[78] proposed that Codium isthmocladum react to deep water nutrient sources due to their tissues having different concentrations of nutrients dependent upon depth. Wolanski and Hamner[72] noted aggregations of eggs, larval organisms and plankton on reefs in response to deep water intrusions. Similarly, as internal waves and bores move vertically, surface-dwelling larval organisms are carried toward the shore.[81] This has significant biological importance to cascading effects of food chains in coral reef ecosystems and may provide yet another key to unlocking "Darwin's Paradox".		Cyanobacteria provide soluble nitrates for the reef via nitrogen fixation.[82]		Coral reefs also often depend on surrounding habitats, such as seagrass meadows and mangrove forests, for nutrients. Seagrass and mangroves supply dead plants and animals which are rich in nitrogen and also serve to feed fish and animals from the reef by supplying wood and vegetation. Reefs, in turn, protect mangroves and seagrass from waves and produce sediment in which the mangroves and seagrass can root.[29]		Coral reefs form some of the world's most productive ecosystems, providing complex and varied marine habitats that support a wide range of other organisms.[83][84]Fringing reefs just below low tide level have a mutually beneficial relationship with mangrove forests at high tide level and sea grass meadows in between: the reefs protect the mangroves and seagrass from strong currents and waves that would damage them or erode the sediments in which they are rooted, while the mangroves and sea grass protect the coral from large influxes of silt, fresh water and pollutants. This level of variety in the environment benefits many coral reef animals, which, for example, may feed in the sea grass and use the reefs for protection or breeding.[85]		Reefs are home to a large variety of animals, including fish, seabirds, sponges, cnidarians (which includes some types of corals and jellyfish), worms, crustaceans (including shrimp, cleaner shrimp, spiny lobsters and crabs), mollusks (including cephalopods), echinoderms (including starfish, sea urchins and sea cucumbers), sea squirts, sea turtles and sea snakes. Aside from humans, mammals are rare on coral reefs, with visiting cetaceans such as dolphins being the main exception. A few of these varied species feed directly on corals, while others graze on algae on the reef.[2][56] Reef biomass is positively related to species diversity.[86]		The same hideouts in a reef may be regularly inhabited by different species at different times of day. Nighttime predators such as cardinalfish and squirrelfish hide during the day, while damselfish, surgeonfish, triggerfish, wrasses and parrotfish hide from eels and sharks.[23]:49		Reefs are chronically at risk of algal encroachment. Overfishing and excess nutrient supply from onshore can enable algae to outcompete and kill the coral.[87][88] Increased nutrient levels can be a result of sewage or chemical fertilizer runoff from nearby coastal developments. Runoff can carry nitrogen and phosphorus which promote excess algae growth. Algae can sometimes out-compete the coral for space. The algae can then smother the coral by decreasing the oxygen supply available to the reef. Decreased oxygen levels can slow down coral's calcification rates weakening the coral and leaving it more susceptible to disease and degradation.[89] In surveys done around largely uninhabited US Pacific islands, algae inhabit a large percentage of surveyed coral locations.[90] The algal population consists of turf algae, coralline algae, and macro algae.		Sponges are essential for the functioning of the coral reef's ecosystem. Algae and corals in coral reefs produce organic material. This is filtered through sponges which convert this organic material into small particles which in turn are absorbed by algae and corals.[91]		Over 4,000 species of fish inhabit coral reefs.[2] The reasons for this diversity remain unclear. Hypotheses include the "lottery", in which the first (lucky winner) recruit to a territory is typically able to defend it against latecomers, "competition", in which adults compete for territory, and less-competitive species must be able to survive in poorer habitat, and "predation", in which population size is a function of postsettlement piscivore mortality.[92] Healthy reefs can produce up to 35 tons of fish per square kilometer each year, but damaged reefs produce much less.[93]		Sea urchins, Dotidae and sea slugs eat seaweed. Some species of sea urchins, such as Diadema antillarum, can play a pivotal part in preventing algae from overrunning reefs.[94] Nudibranchia and sea anemones eat sponges.		A number of invertebrates, collectively called "cryptofauna," inhabit the coral skeletal substrate itself, either boring into the skeletons (through the process of bioerosion) or living in pre-existing voids and crevices. Those animals boring into the rock include sponges, bivalve mollusks, and sipunculans. Those settling on the reef include many other species, particularly crustaceans and polychaete worms.[32]		Coral reef systems provide important habitats for seabird species, some endangered. For example, Midway Atoll in Hawaii supports nearly three million seabirds, including two-thirds (1.5 million) of the global population of Laysan albatross, and one-third of the global population of black-footed albatross.[95] Each seabird species has specific sites on the atoll where they nest. Altogether, 17 species of seabirds live on Midway. The short-tailed albatross is the rarest, with fewer than 2,200 surviving after excessive feather hunting in the late 19th century.[96]		Sea snakes feed exclusively on fish and their eggs.[97][98][99] Marine birds, such as herons, gannets, pelicans and boobies, feed on reef fish. Some land-based reptiles intermittently associate with reefs, such as monitor lizards, the marine crocodile and semiaquatic snakes, such as Laticauda colubrina. Sea turtles, particularly hawksbill sea turtles, feed on sponges.[100][101][102]		Schooling reef fish		Caribbean reef squid		Banded coral shrimp		Whitetip reef shark		Green turtle		Giant clam		Soft coral, cup coral, sponges and ascidians		Banded sea krait		The shell of Latiaxis wormaldi, a coral snail		Coral reefs deliver ecosystem services to tourism, fisheries and coastline protection. The global economic value of coral reefs has been estimated to be between US $29.8 billion[6] and $375 billion per year.[7] Coral reefs protect shorelines by absorbing wave energy, and many small islands would not exist without their reefs to protect them. According to the environmental group World Wide Fund for Nature, the economic cost over a 25-year period of destroying one kilometer of coral reef is somewhere between $137,000 and $1,200,000.[103] About six million tons of fish are taken each year from coral reefs. Well-managed coral reefs have an annual yield of 15 tons of seafood on average per square kilometer. Southeast Asia's coral reef fisheries alone yield about $2.4 billion annually from seafood.[103]		To improve the management of coastal coral reefs, another environmental group, the World Resources Institute (WRI) developed and published tools for calculating the value of coral reef-related tourism, shoreline protection and fisheries, partnering with five Caribbean countries. As of April 2011, published working papers covered St. Lucia, Tobago, Belize, and the Dominican Republic, with a paper for Jamaica in preparation. The WRI was also "making sure that the study results support improved coastal policies and management planning".[104] The Belize study estimated the value of reef and mangrove services at $395–559 million annually.[105]		Bermuda's coral reefs provide economic benefits to the Island worth on average $722 million per year, based on six key ecosystem services, according to Sarkis et al (2010).[106]		Coral reefs are dying around the world.[107] In particular, coral mining, agricultural and urban runoff, pollution (organic and inorganic), overfishing, blast fishing, disease, and the digging of canals and access into islands and bays are localized threats to coral ecosystems. Broader threats are sea temperature rise, sea level rise and pH changes from ocean acidification, all associated with greenhouse gas emissions. A 2014 study lists factors such as population explosion along the coast lines, overfishing, the pollution of coastal areas, global warming and invasive species among the main reasons that have put reefs in danger of extinction.[108]		A study released in April 2013 has shown that air pollution can also stunt the growth of coral reefs; researchers from Australia, Panama and the UK used coral records (between 1880 and 2000) from the western Caribbean to show the threat of factors such as coal-burning coal and volcanic eruptions.[109] Pollutants, such as Tributyltin, a biocide released into water from in anti-fouling paint can be toxic to corals.		In 2011, researchers suggested that "extant marine invertebrates face the same synergistic effects of multiple stressors" that occurred during the end-Permian extinction, and that genera "with poorly buffered respiratory physiology and calcareous shells", such as corals, were particularly vulnerable.[110][111][112]		Rock coral on seamounts across the ocean are under fire from bottom trawling. Reportedly up to 50% of the catch is rock coral, and the practice transforms coral structures to rubble. With it taking years to regrow, these coral communities are disappearing faster than they can sustain themselves.[113]		Another cause for the death of coral reefs is bioerosion. Various fishes graze corals, dead or alive and change the morphology of coral reefs making them more susceptible to other physical and chemical threats. It has been generally observed that only the algae growing on dead corals is eaten and the live ones are not. However, this act still destroys the top layer of coral substrate and makes it harder for the reefs to sustain.[114]		In El Niño-year 2010, preliminary reports show global coral bleaching reached its worst level since another El Niño year, 1998, when 16% of the world's reefs died as a result of increased water temperature. In Indonesia's Aceh province, surveys showed some 80% of bleached corals died. Scientists do not yet understand the long-term impacts of coral bleaching, but they do know that bleaching leaves corals vulnerable to disease, stunts their growth, and affects their reproduction, while severe bleaching kills them.[115] In July, Malaysia closed several dive sites where virtually all the corals were damaged by bleaching.[116][117]		To find answers for these problems, researchers study the various factors that impact reefs. The list includes the ocean's role as a carbon dioxide sink, atmospheric changes, ultraviolet light, ocean acidification, viruses, impacts of dust storms carrying agents to far-flung reefs, pollutants, algal blooms and others. Reefs are threatened well beyond coastal areas.[citation needed] Coral reefs with one type of zooxanthellae are more prone to bleaching than are reefs with another, more hardy, species.[118]		General estimates show approximately 10% of the world's coral reefs are dead.[119][120] About 60% of the world's reefs are at risk due to destructive, human-related activities. The threat to the health of reefs is particularly high in Southeast Asia, where 95% of reefs are at risk from local threats.[121] By the 2030s, 90% of reefs are expected to be at risk from both human activities and climate change; by 2050, all coral reefs will be in danger.[122]		Current research is showing that ecotourism in the Great Barrier Reef is contributing to coral disease,[123] and that chemicals in sunscreens may contribute to the impact of viruses on zooxanthellae.[8]		Some scientists, including those associated with the National Oceanic and Atmospheric Administration, posit that US coral reefs are likely to disappear within a few decades as a result of global warming.[124]		Marine protected areas (MPAs) have become increasingly prominent for reef management. MPAs promote responsible fishery management and habitat protection. Much like national parks and wildlife refuges, and to varying degrees, MPAs restrict potentially damaging activities. MPAs encompass both social and biological objectives, including reef restoration, aesthetics, biodiversity, and economic benefits. However, there are very few MPAs that have actually made a substantial difference. Research in Indonesia, Philippines and Papua New Guinea shows that there is no significant difference between an MPA site and an unprotected site.[125][126] Conflicts surrounding MPAs involve lack of participation, clashing views of the government and fisheries, effectiveness of the area, and funding.[127] In some situations, as in the Phoenix Islands Protected Area, MPAs can also provide revenue, potentially equal to the income they would have generated without controls, as Kiribati did for its Phoenix Islands.[128]		According to the Caribbean Coral Reefs - Status Report 1970-2012 made by the IUCN. States that; stopping overfishing especially key fishes to coral reef like parrotfish, coastal zone management which reduce human pressure on reef, (for example restricting the coastal settlement, development and tourism in coastal reef) and controlling pollution specially sewage wastage, may not only reduce coral declining but also reverse it and may let to coral reef more adaptable to changes relates to climate and acidification. The report shows that healthier reef in the Caribbean are those with large population of parrotfish in countries which protect these key fishes and sea urchins, banning fish trap and Spearfishing creating "resilient reefs".[129]		To help combat ocean acidification, some laws are in place to reduce greenhouse gases such as carbon dioxide. The Clean Water Act puts pressure on state government agencies to monitor and limit runoff of pollutants that can cause ocean acidification. Stormwater surge preventions are also in place, as well as coastal buffers between agricultural land and the coastline. This act also ensures that delicate watershed ecosystems are intact, such as wetlands. The Clean Water Act is funded by the federal government, and is monitored by various watershed groups. Many land use laws aim to reduce CO2 emissions by limiting deforestation. Deforestation causes erosion, which releases a large amount of carbon stored in the soil, which then flows into the ocean, contributing to ocean acidification. Incentives are used to reduce miles traveled by vehicles, which reduces the carbon emissions into the atmosphere, thereby reducing the amount of dissolved CO2 in the ocean. State and federal governments also control coastal erosion, which releases stored carbon in the soil into the ocean, increasing ocean acidification.[130] High-end satellite technology is increasingly being employed to monitor coral reef conditions.[131]		Biosphere reserve, marine park, national monument and world heritage status can protect reefs. For example, Belize's barrier reef, Sian Ka'an, the Galapagos islands, Great Barrier Reef, Henderson Island, Palau and Papahānaumokuākea Marine National Monument are world heritage sites.[132]		In Australia, the Great Barrier Reef is protected by the Great Barrier Reef Marine Park Authority, and is the subject of much legislation, including a biodiversity action plan.[133] They have compiled a Coral Reef Resilience Action Plan. This detailed action plan consists of numerous adaptive management strategies, including reducing our carbon footprint, which would ultimately reduce the amount of ocean acidification in the oceans surrounding the Great Barrier Reef. An extensive public awareness plan is also in place to provide education on the “rainforests of the sea” and how people can reduce carbon emissions, thereby reducing ocean acidification.[134]		Inhabitants of Ahus Island, Manus Province, Papua New Guinea, have followed a generations-old practice of restricting fishing in six areas of their reef lagoon. Their cultural traditions allow line fishing, but no net or spear fishing. The result is both the biomass and individual fish sizes are significantly larger than in places where fishing is unrestricted.[135][136]		Coral aquaculture, also known as coral farming or coral gardening, is showing promise as a potentially effective tool for restoring coral reefs, which have been declining around the world.[137][138][139] The process bypasses the early growth stages of corals when they are most at risk of dying. Coral seeds are grown in nurseries, then replanted on the reef.[140] Coral is farmed by coral farmers who live locally to the reefs and farm for reef conservation or for income.		Efforts to expand the size and number of coral reefs generally involve supplying substrate to allow more corals to find a home. Substrate materials include discarded vehicle tires, scuttled ships, subway cars, and formed concrete, such as reef balls. Reefs also grow unaided on marine structures such as oil rigs.[citation needed] In large restoration projects, propagated hermatypic coral on substrate can be secured with metal pins, superglue or milliput.[141] Needle and thread can also attach A-hermatype coral to substrate.[142]		A substrate for growing corals referred to as Biorock is produced by running low voltage electrical currents through seawater to crystallize dissolved minerals onto steel structures. The resultant white carbonate (aragonite) is the same mineral that makes up natural coral reefs. Corals rapidly colonize and grow at accelerated rates on these coated structures. The electrical currents also accelerate formation and growth of both chemical limestone rock and the skeletons of corals and other shell-bearing organisms. The vicinity of the anode and cathode provides a high-pH environment which inhibits the growth of competitive filamentous and fleshy algae. The increased growth rates fully depend on the accretion activity.[143]		During accretion, the settled corals display an increased growth rate, size and density, but after the process is complete, growth rate and density return to levels comparable to natural growth, and are about the same size or slightly smaller.[143]		One case study with coral reef restoration was conducted on the island of Oahu in Hawaii. The University of Hawaii has come up with a Coral Reef Assessment and Monitoring Program to help relocate and restore coral reefs in Hawaii. A boat channel on the island of Oahu to the Hawaii Institute of Marine Biology was overcrowded with coral reefs. Also, many areas of coral reef patches in the channel had been damaged from past dredging in the channel. Dredging covers the existing corals with sand, and their larvae cannot build and thrive on sand; they can only build on to existing reefs. Because of this, the University of Hawaii decided to relocate some of the coral reef to a different transplant site. They transplanted them with the help of the United States Army divers, to a relocation site relatively close to the channel. They observed very little, if any, damage occurred to any of the colonies while they were being transported, and no mortality of coral reefs has been observed on the new transplant site, but they will be continuing to monitor the new transplant site to see how potential environmental impacts (i.e. ocean acidification) will harm the overall reef mortality rate. While trying to attach the coral to the new transplant site, they found the coral placed on hard rock is growing considerably well, and coral was even growing on the wires that attached the transplant corals to the transplant site. This gives new hope to future research on coral reef transplant sites. As a result of this coral restoration project, no environmental effects were seen from the transplantation process, no recreational activities were decreased, and no scenic areas were affected by the project. This is a great example that coral transplantation and restoration can work and thrive under the right conditions, which means there may be hope for other damaged coral reefs.[144]		Another possibility for coral restoration is gene therapy. Through infecting coral with genetically modified bacteria, it may be possible to grow corals that are more resistant to climate change and other threats.[145]		Throughout Earth history, from a few thousand years after hard skeletons were developed by marine organisms, there were almost always reefs. The times of maximum development were in the Middle Cambrian (513–501 Ma), Devonian (416–359 Ma) and Carboniferous (359–299 Ma), owing to order Rugosa extinct corals, and Late Cretaceous (100–66 Ma) and all Neogene (23 Ma–present), owing to order Scleractinia corals.		Not all reefs in the past were formed by corals: those in the Early Cambrian (542–513 Ma) resulted from calcareous algae and archaeocyathids (small animals with conical shape, probably related to sponges) and in the Late Cretaceous (100–66 Ma), when there also existed reefs formed by a group of bivalves called rudists; one of the valves formed the main conical structure and the other, much smaller valve acted as a cap.		Measurements of the oxygen isotopic composition of the aragonitic skeleton of coral reefs, such as Porites, can indicate changes in the sea surface temperature and sea surface salinity conditions of the ocean during the growth of the coral. This technique is often used by climate scientists to infer the paleoclimate of a region.[146]		
Bodden are briny bodies of water often forming lagoons, along the southwestern shores of the Baltic Sea, primarily in Germany's state of Mecklenburg-Vorpommern. These lagoons can be found especially around the island of Rügen, Usedom and the Fischland-Darss-Zingst peninsula. Some of them are protected reserves, forming the Western Pomerania Lagoon Area National Park.		They have a distinctive geological origin and are enclosed by peninsulae, spits and islands, leaving only narrow connections to adjacent bodden or the open sea. Freshwater inflow from the mainland and saltwater inflow from the open sea, which depends on wind direction and force as well as the proximity of the bodden to the sea, result in fluctuating salt gradients and distinctive ecosystems.		During the Littorina Sea transgression, an island archipelago was formed by the carving of narrow glacial basins and channels resulting from meltwater. Bodden were formed in a comparatively short period between spits and offshore sandbars. These shallow glacial scoops were then subjected to extensive sedimentation during the Holocene, resulting in lakes with depths of no more than 4–6 metres. Thermal and saline stratification is extremely unstable under these conditions, and bodden have the typical dynamics of small bodies of water with a sea connection, which is a rapid filling and draining due to tidal and wind action, and inflow of fresh water. The frequent movement of water can lead to a scouring effect, but can also with heavy pollution show a tendency toward eutrophication.[1] Due to erosion of cliffs and sedimentary deposition, the shape of the bodden coasts remains unstable. Sudden changes have been caused by stormfloods, which repeatedly closed connections to the sea or opened new ones in the past.		While bodden-type bays can be found in Mecklenburg and Denmark, the most typical bodden are located off the Pomeranian mainland between the mouth of the Recknitz river and the island of Usedom. Several adjacent bodden between the Fischland-Darß-Zingst peninsula, Hiddensee, the northern and western peninsulae of Rügen and the Pomeranian mainland are grouped as Bodden chains (Boddenketten):		Another bodden is the Bay of Greifswald (Greifswalder Bodden), the northern parts of which constitute the Rügischer Bodden with Schoritzer Wiek, Wreechensee, Having Inlet with Neuensiener See and Selliner See, and Hagensche Wiek. To the south, the Bay of Greifswald comprises Gristower Inwiek, Kooser See and Dänische Wieck (Danish Bay).		The Bay of Greifswald is connected to the West Rügen bodden chain by the Strelasund, a bodden-type strait with Glewitzer Wiek, Puddeminer Wiek and Deviner See; it is further connected to the Oder Lagoon by the Peenestrom, another bodden-type strait with Spandowerhagener Wiek, Krösliner See, Hohendorfer See, Krumminer Wiek and Achterwasser.		The bodden are important sanctuaries for many species of birds and are especially important resting places for migratory birds like cranes and geese. This was the reason for the establishment of the Western Pomerania Lagoon Area National Park (Nationalpark Vorpommersche Boddenlandschaft), comprising most of the bodden between Darß and Rügen.		Traditionally bodden have been good fishing areas, rich in mesolithic community sites, in particular the Pomeranian bodden of Rügen, Greifswald and Peenestrom. From these waters anglers regularly land 10–15 kg pike.[2]		
A pier is a raised structure in a body of water, typically supported by well-spaced piles or pillars. Bridges, buildings, and walkways may all be supported by piers. Their open structure allows tides and currents to flow relatively unhindered, whereas the more solid foundations of a quay or the closely spaced piles of a wharf can act as a breakwater, and are consequently more liable to silting. Piers can range in size and complexity from a simple lightweight wooden structure to major structures extended over 1600 metres. In American English, a pier may be synonymous with a dock.		Piers have been built for several purposes, and because these different purposes have distinct regional variances, the term pier tends to have different nuances of meaning in different parts of the world. Thus in North America and Australia, where many ports were, until recently, built on the multiple pier model, the term tends to imply a current or former cargo-handling facility. In Europe in contrast, where ports more often use basins and river-side quays than piers, the term is principally associated with the image of a Victorian cast iron pleasure pier. However, the earliest piers pre-date the Victorian age.						Piers can be categorized into different groupings according to the principal purpose.[1] However, there is considerable overlap between these categories. For example, pleasure piers often also allow for the docking of pleasure steamers and other similar craft, while working piers have often been converted to leisure use after being rendered obsolete by advanced developments in cargo-handling technology. Many piers are floating piers, to ensure that the piers raise and lower with the tide along with the boats tied to them. This prevents a situation where lines become overly taut or loose by rising or lowering tides. An overly taut or loose tie-line can damage boats by pulling them out of the water or allowing them so much leeway that they bang forcefully against the sides of the pier.		Working piers were built for the handling of passengers and cargo onto and off ships or (as at Wigan Pier) canal boats. Working piers themselves fall into two different groups. Longer individual piers are often found at ports with large tidal ranges, with the pier stretching far enough off shore to reach deep water at low tide. Such piers provided an economical alternative to impounded docks where cargo volumes were low, or where specialist bulk cargo was handled, such as at coal piers. The other form of working pier, often called the finger pier, was built at ports with smaller tidal ranges. Here the principal advantage was to give a greater available quay length for ships to berth against compared to a linear littoral quayside, and such piers are usually much shorter. Typically each pier would carry a single transit shed the length of the pier, with ships berthing bow or stern in to the shore. Some major ports consisted of large numbers of such piers lining the foreshore, classic examples being the Hudson River frontage of New York, or the Embarcadero in San Francisco.		The advent of container shipping, with its need for large container handling spaces adjacent to the shipping berths, has made working piers obsolete for the handling of general cargo, although some still survive for the handling of passenger ships or bulk cargos. One example, is in use in Progreso, Yucatán, where a pier extends more than 4 miles into the Gulf of Mexico, making it the longest pier in the world. The Progreso Pier supplies much of the peninsula with transportation for the fishing and cargo industries and serves as a port for large cruise ships in the area. Many other working piers have been demolished, or remain derelict, but some have been recycled as pleasure piers. The best known example of this is Pier 39 in San Francisco.		At Southport and the Tweed River on the Gold Coast in Australia, there are piers that support equipment for a sand bypassing system that maintains the health of sandy beaches and navigation channels.		Pleasure piers were first built in Britain during the early 19th century.[2] The earliest structures were Ryde Pier, built in 1813/4, Trinity Chain Pier near Leith, built in 1821, and Brighton Chain Pier, built in 1823.[2] Only the oldest of these piers still remains. At that time the introduction of the railways for the first time permitted mass tourism to dedicated seaside resorts. The large tidal ranges at many such resorts meant that for much of the day, the sea was not visible from dry land. The pleasure pier was the resorts' answer, permitting holidaymakers to promenade over and alongside the sea at all times.[3] The world's longest pleasure pier is at Southend-on-sea, Essex, and extends 1.3 miles (2.1 km) into the Thames estuary.[2] With a length of 2,745 feet (836.68 m), the longest pier on the West Coast of the US is the Santa Cruz Wharf.[4]		Providing a walkway out to sea, pleasure piers often include amusements and theatres as part of the attraction.[3] Such a pier may be open air, closed, or partly open, partly closed. Sometimes a pier has two decks. Galveston Island Historic Pleasure Pier in Galveston, Texas has 1 roller coaster, 15 rides, carnival games and souvenir shops.[5]		Early pleasure piers were of wooden construction, with iron structures being introduced with the construction in 1855 of Margate Jetty, in Margate, England.[6] Margate was wrecked in storms in 1978 and was never repaired.[6] The longest iron pleasure pier still remaining is in Southport, England, and dates from 1860 - however the world's oldest iron pier[7] dates from 1834 and is in Gravesend, Kent. In a 2006 UK poll, the public voted the seaside pier onto the list of icons of England.[8]		Many piers are built for the purpose of providing boatless anglers access to fishing grounds that are otherwise inaccessible. [9] Many "Free Piers" are available in larger harbors which differ from private piers. Free Piers are often primarily used for fishing.		See the List of piers article for details of piers in countries across the world.		In Blankenberge a first pleasure pier was built in 1894. After its destruction in the World War I, a new pier was built in 1933. It remained till the present day, but was partially transformed and modernized in 1999–2004.		In Nieuwpoort, Belgium there is a pleasure pier on both sides of the river IJzer.		Scheveningen, the coastal resort town of The Hague, boasts the largest pier in the Netherlands, completed in 1961. A crane, built on top of the pier's panorama tower, provides the opportunity to make a 60-metre (200 ft) high bungee jump over the North Sea waves. The present pier is a successor of an earlier pier, which was completed in 1901 but in 1943 destroyed by the German occupation forces.		The first recorded pier in England was Ryde Pier, opened in 1814 on the Isle of Wight, as a landing stage to allow ferries to and from the mainland to berth. It is still used for this purpose today.[11] It also had a leisure function in the past, with the pier head once containing a pavilion, and there are still refreshment facilities today. The oldest cast iron pier in the world is Gravesend town pier, in Kent, which opened in 1834. However, it is not recognised by the National Piers Society as being a seaside pier.[12]		Following the building of the world's first seaside pier at Ryde, the pier became fashionable at seaside resorts in England and Wales during the Victorian era, peaking in the 1860s with 22 being built in that decade.[13] A symbol of the typical British seaside holiday, by 1914, more than 100 pleasure piers were located around the UK coast.[2] Regarded as being among the finest Victorian architecture, there are still a significant number of seaside piers of architectural merit still standing, although some have been lost, including two at Brighton in East Sussex and three at Blackpool in Lancashire.[3] Two piers, Brighton's now derelict West Pier and Clevedon Pier, were Grade 1 listed. The Birnbeck Pier in Weston-super-Mare is the only pier in the world linked to an island. The National Piers Society gives a figure of 55 surviving seaside piers in England and Wales.[1]		Victorian pier at Clevedon, Somerset, England		The pier of Blankenberge, Belgium		Huntington Beach Pier, California		A typical Finnish pier with a table, chair and ladders for swimmers in Joutsa, Central Finland		Pier at Sunrise Captiva, Florida		This pier deals with varying water levels, ships and freeboards by means of stairs		A pier on the Lower Otay Reservoir in San Diego, California		Floating pier at Mohonk Mountain House		
A sea cave, also known as a littoral cave, is a type of cave formed primarily by the wave action of the sea. The primary process involved is erosion. Sea caves are found throughout the world, actively forming along present coastlines and as relict sea caves on former coastlines. Some of the largest wave-cut caves in the world are found on the coast of Norway, but are now 100 feet or more above present sea level.[1] These would still be classified as littoral caves. By contrast, in places like Thailand's Phang Nga Bay, solutionally formed caves in limestone have been flooded by the rising sea and are now subject to littoral erosion, representing a new phase of their enlargement.		Some of the best-known sea caves are European. Fingal's Cave, on the Scottish island of Staffa, is a spacious cave some 70 m long, formed in columnar basalt. The Blue Grotto of Capri, although smaller, is famous for the apparent luminescent quality of its water, imparted by light passing through underwater openings. The Romans built a stairway in its rear and a now-collapsed tunnel to the surface. The Greek islands are also noted for the variety and beauty of their sea caves. Numerous sea caves have been surveyed in England, Scotland, and in France, particularly on the Normandy coast. Until 2013, the largest known sea caves were found along the west coast of the United States, the Hawaiian islands, and the Shetland Islands. In 2013 the discovery and survey of the world's largest sea cave was announced.[2] Located on New Zealand's Otago coast on the South Island, Matainaka Cave has proven to be the world's most extensive at 1.5 km in length. Also in 2013, Crossley reported a newly surveyed complex reaching just over a kilometer in survey at Bethells Beach on New Zealand's North Island.[3]						Littoral caves may be found in a wide variety of host rocks, ranging from sedimentary to metamorphic to igneous, but caves in the latter tend to be larger due to the greater strength of the host rock. However, there are some notable exceptions as discussed below.		In order to form a sea cave, the host rock must first contain a weak zone. In metamorphic or igneous rock, this is typically either a fault as in the caves of the Channel Islands of California, or a dike as in the large sea caves of Kauai, Hawaii’s Na Pali Coast.[4][5] In sedimentary rocks, this may be a bedding-plane parting or a contact between layers of different hardness. The latter may also occur in igneous rocks, such as in the caves on Santa Cruz Island, California, where waves have attacked the contact between the andesitic basalt and the agglomerate.[6]		The driving force in littoral cave development is wave action. Erosion is ongoing anywhere that waves batter rocky coasts, but where sea cliffs contain zones of weakness, rock is removed at a greater rate along these zones. As the sea reaches into the fissures thus formed, they begin to widen and deepen due to the tremendous force exerted within a confined space, not only by direct action of the surf and any rock particles that it bears, but also by compression of air within. Blowholes (partially submerged caves that eject large sprays of sea water as waves retreat and allow rapid re-expansion of air compressed within) attest to this process. Adding to the hydraulic power of the waves is the abrasive force of suspended sand and rock. Most sea-cave walls are irregular and chunky, reflecting an erosional process where the rock is fractured piece by piece. However, some caves have portions where the walls are rounded and smoothed, typically floored with cobbles, and result from the swirling motion of these cobbles in the surf zone.		True littoral caves should not be confused with inland caves that have been intersected and revealed when a sea cliff line is eroded back, or with dissolutional voids formed in the littoral zone on tropical islands. In some regions, such as Halong Bay, Vietnam, caves in carbonate rocks are found in littoral zones, and being enlarged by littoral processes but were originally formed by dissolution. Such caves have been termed as hybrid caves.[7]		Rainwater may also influence sea-cave formation. Carbonic and organic acids leached from the soil may assist in weakening rock within fissures. As in solutional caves, small speleothems may develop in sea caves.		Sea cave chambers sometimes collapse leaving a “littoral sinkhole”. These may be quite large, such as Oregon’s Devil’s Punchbowl or the Queen’s Bath on the Na Pali coast. Small peninsulas or headlands often have caves that cut completely through them, since they are subject to attack from both sides, and the collapse of a sea cave tunnel can leave a free-standing “sea stack” along the coast. The Californian island of Anacapa is thought to have been split into three islets by such a process.		Life within sea caves may assist in their enlargement as well. For example, sea urchins drill their way into the rock, and over successive generations may remove considerable bedrock from the floors and lower walls.		Most sea caves are small in relation to other types. A compilation of sea-cave surveys as of July 2014 ( Long sea caves of the world ) shows 2 over 1000 meters, 6 over 400 meters, nine over 300 meters, 25 over 200 meters, and 108 over 100 meters in length. In Norway, several apparently relict sea caves exceed 300 meters in length. There is no doubt that many other large sea caves exist but have not been investigated due to their remote locations and/or hostile sea conditions.		Several factors contribute to the development of relatively large sea caves. The nature of the zone of weakness itself is surely a factor, although difficult to quantify. A more readily observed factor is the situation of the cave’s entrance relative to prevailing sea conditions. At Santa Cruz Island, the largest caves face into the prevailing northwest swell conditions—a factor which also makes them more difficult to survey. Caves in well-protected bays sheltered from prevailing seas and winds tend to be smaller, as are caves in areas where the seas tend to be calmer.		The type of host rock is important as well. Most of the large sea caves on the Western U.S. coast and Hawaii are in basalt,[8] a strong host rock compared to sedimentary rock. Basaltic caves can penetrate far into cliffs where most of the surface erodes relatively slowly. In weaker rock, erosion along a weaker zone may not greatly outstrip that of the cliff face. However, the world's largest sea cave has formed in the heavily fractured Caversham sandstone (Barth, 2013) changing our understanding of which host rocks can form large sea caves.		Time is another factor. The active littoral zone changes throughout geological time by an interplay between sea-level change and regional uplift. Recurrent ice ages during the Pleistocene have changed sea levels within a vertical range of some 200 meters. Significant sea caves have formed in the California Channel Islands that are now totally submerged by the rise in sea levels over the last 12 000 years. In regions of steady uplift, continual littoral erosion may produce sea caves of great height — Painted Cave is almost 40 m high at its entrance. On the Norwegian coast there are huge sea caves now uplifted 30 or more meters above sea level. Sediment dating in the largest of these (Halvikshulen in Osen, 340 m long) shows that it was formed over a period of at least a million years.[9] It may well be the longest wave-cut cave in the world. The largest cave by volume is Rikoriko Cave in the Poor Knights Islands in New Zealand with 221,494 m3.[10]		Finally, caves that are larger tend to be more complex. By far the majority of sea caves consist of a single passage or chamber. Those formed on faults tend to have canyon-like or angled passages that are very straight. In Seal Canyon Cave on Santa Cruz Island, entrance light is still visible from the back of the cave 189 m from the entrance. By contrast, caves formed along horizontal bedding planes tend to be wider with lower ceiling heights. In some areas, sea caves may have dry upper levels, lifted above the active littoral zone by regional uplift.		Sea caves can prove surprisingly complex where numerous zones of weakness—often faults—converge. In Catacombs Cave on Anacapa Island (California), at least six faults intersect.[11] In several caves of the Californian Channel Islands, long fissure passages open up into large chambers beyond. This is invariably associated with intersection of a second fault oriented almost perpendicularly to that along the entrance passage. When caves have multiple entrances, they are exposed to more wave action and hence may grow relatively faster. There is an exceptionally large cave underlying the Fogla Skerry, an islet off the coast of Papa Stour, in the Shetland Islands.[12] Though unsurveyed, estimates place it at almost 500 m of passage. Matainaka Cave in New Zealand has 12 separate entrances into which waves can penetrate and numerous joints along which intersecting passages have developed.		
A graded shoreline is a stage in the cycle of coastal development characterised by a flat and straight coastline. It is formed under the influence of wind and water from the original bays, islands, peninsulas and promontories. Sand and gravel is carried away and dumped at other locations depending on the direction and strength of sea currents. Typical of graded shorelines are the formation of dunes, wide sandy beaches and sometimes a lagoon or a spit. Where two graded shorelines meet, a headland may form with a sandy reef in the sea beyond it. Parallel to the graded shoreline sandbanks may form as a result of sediments transported away from the shore.		
London /ˈlʌndən/ ( listen) is the capital and most populous city of England and the United Kingdom.[6][7]		Standing on the River Thames in the south east of the island of Great Britain, London has been a major settlement for two millennia. It was founded by the Romans, who named it Londinium.[8] London's ancient core, the City of London, largely retains its 1.12-square-mile (2.9 km2) medieval boundaries. Since at least the 19th century, "London" has also referred to the metropolis around this core, historically split between Middlesex, Essex, Surrey, Kent, and Hertfordshire,[9][10][11] which today largely makes up Greater London,[12][13][note 1] a region governed by the Mayor of London and the London Assembly.[14][note 2][15]		London is a leading global city[16][17] in the arts, commerce, education, entertainment, fashion, finance, healthcare, media, professional services, research and development, tourism, and transportation.[18][19][20] It is crowned as the world's largest financial centre[21][22] [23][24] and has the fifth- or sixth-largest metropolitan area GDP in the world.[note 3] [25][26] London is a world cultural capital.[27][28][29] It is the world's most-visited city as measured by international arrivals[30] and has the world's largest city airport system measured by passenger traffic.[31] London is the world's leading investment destination,[32][33][34] hosting more international retailers[35][36] and ultra high-net-worth individuals[37][38] than any other city. London's universities form the largest concentration of higher education institutes in Europe.[39] In 2012, London became the first city to have hosted the modern Summer Olympic Games three times.[40]		London has a diverse range of people and cultures, and more than 300 languages are spoken in the region.[41] Its estimated mid-2016 municipal population (corresponding to Greater London) was 8,787,892,[3] the largest of any city in the European Union,[42] and accounting for 13.4% of the UK population.[43] London's urban area is the second most populous in the EU, after Paris, with 9,787,426 inhabitants at the 2011 census.[44] The city's metropolitan area is the most populous in the EU with 13,879,757 inhabitants,[note 4][2] while the Greater London Authority states the population of the city-region (covering a large part of the south east) as 22.7 million.[45][46] London was the world's most populous city from around 1831 to 1925.[47]		London contains four World Heritage Sites: the Tower of London; Kew Gardens; the site comprising the Palace of Westminster, Westminster Abbey, and St Margaret's Church; and the historic settlement of Greenwich (in which the Royal Observatory, Greenwich marks the Prime Meridian, 0° longitude, and GMT).[48] Other famous landmarks include Buckingham Palace, the London Eye, Piccadilly Circus, St Paul's Cathedral, Tower Bridge, Trafalgar Square, and The Shard. London is home to numerous museums, galleries, libraries, sporting events, and other cultural institutions, including the British Museum, National Gallery, Natural History Museum, Tate Modern, British Library, and West End theatres.[49]		The London Underground is the oldest underground railway network in the world.		The etymology of London is uncertain.[50] It is an ancient name, found in sources from the 2nd century.[AD?] It is recorded c.121 as Londinium, which points to Romano-British origin,[50] and hand-written Roman tablets recovered in the city originating from AD 65/70-80 include the word Londinio ("in London").[51] The earliest attempted explanation, now disregarded, is attributed to Geoffrey of Monmouth in Historia Regum Britanniae, written around 1136.[50] This had it that the name originated from a supposed King Lud, who had allegedly taken over the city and named it Kaerlud.[52]		From 1898, it was commonly accepted that the name was of Celtic origin and meant "place belonging to a man called *Londinos"; this explanation has since been rejected.[50] Richard Coates proposed in 1998 that it is derived from the pre-Celtic Old European *(p)lowonida, meaning "river too wide to ford", and suggested that this was a name given to the part of the River Thames which flows through London; from this, the settlement gained the Celtic form of its name, *Lowonidonjon;[53] this requires quite a serious amendment however. The ultimate difficulty lies in reconciling the Latin form Londinium with the modern Welsh Llundain, which should demand[citation needed] a form *(h)lōndinion (as opposed to *londīnion), from earlier *loundiniom. The possibility cannot be ruled out that the Welsh name was borrowed back in from English at a later date, and thus cannot be used as a basis from which to reconstruct the original name.		Until 1889, the name "London" officially applied only to the City of London, but since then it has also referred to the County of London and now to Greater London.[54]		Two recent discoveries indicate probable very early settlements near the Thames in the London area. In 1999, the remains of a Bronze Age bridge were found on the foreshore north of Vauxhall Bridge.[55] This bridge either crossed the Thames, or gave access to a now lost island in the river. Dendrochronology dated the timbers to ca. 1500 BC.[55] In 2010 the foundations of a large timber structure, dated to ca. 4500 BC, were found on the Thames foreshore, south of Vauxhall Bridge.[56] The function of the mesolithic structure is not known. Both structures are on the south bank, at a natural crossing point where the River Effra flows into the River Thames.[56]		Although there is evidence of scattered Brythonic settlements in the area, the first major settlement was founded by the Romans after the invasion of 43 AD.[57] This lasted only until around 61, when the Iceni tribe led by Queen Boudica stormed it, burning it to the ground.[58] The next, heavily planned, incarnation of Londinium prospered, and it superseded Colchester as the capital of the Roman province of Britannia in 100. At its height in the 2nd century, Roman London had a population of around 60,000.[59]		With the collapse of Roman rule in the early 5th century, London ceased to be a capital, and the walled city of Londinium was effectively abandoned, although Roman civilisation continued in the St Martin-in-the-Fields area until around 450.[60] From around 500, an Anglo-Saxon settlement known as Lundenwic developed in the same area, slightly to the west of the old Roman city.[61] By about 680, it had revived sufficiently to become a major port, although there is little evidence of large-scale production of goods. From the 820s the town declined because of repeated Viking invasions. There are three recorded Viking assaults on London; two of these were successful, in 851 and 886, although the Vikings were defeated during another attack in 994.[62]		The Vikings established Danelaw over much of the eastern and northern part of England, with its boundary roughly stretching from London to Chester. It was an area of political and geographical control imposed by the Viking incursions which was formally agreed by the Danish warlord, Guthrum and the West Saxon king Alfred the Great in 886. The Anglo-Saxon Chronicle recorded that Alfred "refounded" London in 886. Archaeological research shows that this involved abandonment of Lundenwic and a revival of life and trade within the old Roman walls. London then grew slowly until about 950, after which activity increased dramatically.[63]		By the 11th century, London was beyond all comparison the largest town in England. Westminster Abbey, rebuilt in the Romanesque style by King Edward the Confessor, was one of the grandest churches in Europe. Winchester had previously been the capital of Anglo-Saxon England, but from this time on, London became the main forum for foreign traders and the base for defence in time of war. In the view of Frank Stenton: "It had the resources, and it was rapidly developing the dignity and the political self-consciousness appropriate to a national capital."[64][65]		After winning the Battle of Hastings, William, Duke of Normandy was crowned King of England in the newly completed Westminster Abbey on Christmas Day 1066.[66] William constructed the Tower of London, the first of the many Norman castles in England to be rebuilt in stone, in the southeastern corner of the city, to intimidate the native inhabitants.[67] In 1097, William II began the building of Westminster Hall, close by the abbey of the same name. The hall became the basis of a new Palace of Westminster.[68][69]		In the 12th century, the institutions of central government, which had hitherto accompanied the royal English court as it moved around the country, grew in size and sophistication and became increasingly fixed in one place. For most purposes this was Westminster, although the royal treasury, having been moved from Winchester, came to rest in the Tower. While the City of Westminster developed into a true capital in governmental terms, its distinct neighbour, the City of London, remained England's largest city and principal commercial centre, and it flourished under its own unique administration, the Corporation of London. In 1100, its population was around 18,000; by 1300 it had grown to nearly 100,000.[70] Disaster struck in the form of the Black Death in the mid-14th century, when London lost nearly a third of its population.[71] London was the focus of the Peasants' Revolt in 1381.[72]		During the Tudor period the Reformation produced a gradual shift to Protestantism, and much of London passed from church to private ownership.[73] Woollen cloth was shipped undyed and undressed from London to the nearby shores of the Low Countries, where it was considered indispensable.[74] But the reach of English maritime enterprise hardly extended beyond the seas of north-west Europe. The commercial route to Italy and the Mediterranean Sea normally lay through Antwerp and over the Alps; any ships passing through the Strait of Gibraltar to or from England were likely to be Italian or Ragusan. Upon the re-opening of the Netherlands to English shipping in January 1565, there ensued a strong outburst of commercial activity.[75] The Royal Exchange was founded.[76] Mercantilism grew, and monopoly trading companies such as the East India Company were established, with trade expanding to the New World. London became the principal North Sea port, with migrants arriving from England and abroad. The population rose from an estimated 50,000 in 1530 to about 225,000 in 1605.[73]		In the 16th century William Shakespeare and his contemporaries lived in London at a time of hostility to the development of the theatre. By the end of the Tudor period in 1603, London was still very compact. There was an assassination attempt on James I in Westminster, in the Gunpowder Plot on 5 November 1605.[77]		In the English Civil War the majority of Londoners supported the Parliamentary cause. After an initial advance by the Royalists in 1642, culminating in the battles of Brentford and Turnham Green, London was surrounded by a defensive perimeter wall known as the Lines of Communication. The lines were built by up to 20,000 people, and were completed in under two months.[78] The fortifications failed their only test when the New Model Army entered London in 1647[clarification needed],[79] and they were levelled by Parliament the same year.[80]		London was plagued by disease in the early 17th century,[81] culminating in the Great Plague of 1665–1666, which killed up to 100,000 people, or a fifth of the population.[82]		The Great Fire of London broke out in 1666 in Pudding Lane in the city and quickly swept through the wooden buildings.[83] Rebuilding took over ten years and was supervised by Robert Hooke[84][85][86] as Surveyor of London.[87] In 1708 Christopher Wren's masterpiece, St Paul's Cathedral was completed. During the Georgian era, new districts such as Mayfair were formed in the west; new bridges over the Thames encouraged development in South London. In the east, the Port of London expanded downstream. London's development as an international financial centre matured for much of the 1700s.		In 1762, George III acquired Buckingham House and it was enlarged over the next 75 years. During the 18th century, London was dogged by crime, and the Bow Street Runners were established in 1750 as a professional police force.[88] In total, more than 200 offences were punishable by death,[89] including petty theft.[90] Most children born in the city died before reaching their third birthday.[91]		The coffeehouse became a popular place to debate ideas, with growing literacy and the development of the printing press making news widely available; and Fleet Street became the centre of the British press. Following the invasion of Amsterdam by Napoleonic armies, many financiers relocated to London, especially a large Jewish community, and the first London international issue[clarification needed] was arranged in 1817. Around the same time, the Royal Navy became the world leading war fleet[citation needed], acting as a serious deterrent to potential economic adversaries of the United Kingdom. The repeal of the Corn Laws in 1846 was specifically aimed at weakening Dutch economic power[citation needed]. London then overtook Amsterdam as the leading international financial centre[citation needed].[92]		According to Samuel Johnson:		You find no man, at all intellectual, who is willing to leave London. No, Sir, when a man is tired of London, he is tired of life; for there is in London all that life can afford.		London was the world's largest city from about 1831 to 1925.[47] London's overcrowded conditions led to cholera epidemics,[94] claiming 14,000 lives in 1848, and 6,000 in 1866.[95] Rising traffic congestion led to the creation of the world's first local urban rail network. The Metropolitan Board of Works oversaw infrastructure expansion in the capital and some of the surrounding counties; it was abolished in 1889 when the London County Council was created out of those areas of the counties surrounding the capital. London was bombed by the Germans during the First World War,[96] and during the Second World War, the Blitz and other bombings by the German Luftwaffe killed over 30,000 Londoners, destroying large tracts of housing and other buildings across the city.[97] Immediately after the war, the 1948 Summer Olympics were held at the original Wembley Stadium, at a time when London was still recovering from the war.[98]		From the 1940s onwards, London became home to a large number of immigrants, primarily from Commonwealth countries such as Jamaica, India, Bangladesh and Pakistan,[99] making London one of the most diverse cities worldwide. In 1951, the Festival of Britain was held on the South Bank.[100] The Great Smog of 1952 led to the Clean Air Act 1956, which ended the "pea soup fogs" for which London had been notorious.[101]		Primarily starting in the mid-1960s, London became a centre for the worldwide youth culture, exemplified by the Swinging London subculture[102] associated with the King's Road, Chelsea[103] and Carnaby Street.[104] The role of trendsetter was revived during the punk era.[105] In 1965 London's political boundaries were expanded to take into account the growth of the urban area and a new Greater London Council was created.[106] During The Troubles in Northern Ireland, London was subjected to bombing attacks by the Provisional IRA.[107] Racial inequality was highlighted by the 1981 Brixton riot.[108]		Greater London's population declined steadily in the decades after the Second World War, from an estimated peak of 8.6 million in 1939 to around 6.8 million in the 1980s.[109] The principal ports for London moved downstream to Felixstowe and Tilbury,[citation needed] with the London Docklands area becoming a focus for regeneration, including the Canary Wharf development. This was borne out of London's ever-increasing role as a major international financial centre during the 1980s.[110] The Thames Barrier was completed in the 1980s to protect London against tidal surges from the North Sea.[111]		The Greater London Council was abolished in 1986, which left London without a central administration until 2000 when London-wide government was restored, with the creation of the Greater London Authority.[112] To celebrate the start of the 21st century, the Millennium Dome, London Eye and Millennium Bridge were constructed.[113] On 6 July 2005 London was awarded the 2012 Summer Olympics, making London the first city to stage the Olympic Games three times.[114] On 7 July 2005, three London Underground trains and a double-decker bus were bombed in a series of terrorist attacks.[115]		In 2008, London named alongside New York City and Hong Kong as Nylonkong, being hailed as the world's three most influential global cities.[116] In January 2015, Greater London's population was estimated to be 8.63 million, the highest level since 1939.[117] During the Brexit referendum in 2016, the UK as a whole decided to leave the European Union, but a majority of London constituencies voted to remain in the EU.[118]		The administration of London is formed of two tiers: a citywide, strategic tier and a local tier. Citywide administration is coordinated by the Greater London Authority (GLA), while local administration is carried out by 33 smaller authorities.[119] The GLA consists of two elected components: the Mayor of London, who has executive powers, and the London Assembly, which scrutinises the mayor's decisions and can accept or reject the mayor's budget proposals each year. The headquarters of the GLA is City Hall, Southwark; the mayor is Sadiq Khan, the first Muslim mayor of a major Western capital.[120][121] The mayor's statutory planning strategy is published as the London Plan, which was most recently revised in 2011.[122] The local authorities are the councils of the 32 London boroughs and the City of London Corporation.[123] They are responsible for most local services, such as local planning, schools, social services, local roads and refuse collection. Certain functions, such as waste management, are provided through joint arrangements. In 2009–2010 the combined revenue expenditure by London councils and the GLA amounted to just over £22 billion (£14.7 billion for the boroughs and £7.4 billion for the GLA).[124]		The London Fire Brigade is the statutory fire and rescue service for Greater London. It is run by the London Fire and Emergency Planning Authority and is the third largest fire service in the world.[125] National Health Service ambulance services are provided by the London Ambulance Service (LAS) NHS Trust, the largest free-at-the-point-of-use emergency ambulance service in the world.[126] The London Air Ambulance charity operates in conjunction with the LAS where required. Her Majesty's Coastguard and the Royal National Lifeboat Institution operate on the River Thames,[127][128] which is under the jurisdiction of the Port of London Authority from Teddington Lock to the sea.[129]		London is the seat of the Government of the United Kingdom. Many government departments, as well as the Prime Minister's residence at 10 Downing Street, are based close to the Palace of Westminster, particularly along Whitehall.[130] The British Parliament is often referred to as the "Mother of Parliaments" (although this sobriquet was first applied to England itself by John Bright)[131] because it has been the model for most other parliamentary systems.[131] There are 73 Members of Parliament (MPs) from London, elected from local parliamentary constituencies in the national Parliament. As of May 2015, 45 are from the Labour Party, 27 are Conservatives, and one is a Liberal Democrat.[132]		Policing in Greater London, with the exception of the City of London, is provided by the Metropolitan Police Service, overseen by the Mayor through the Mayor's Office for Policing and Crime (MOPAC).[133][134] The City of London has its own police force – the City of London Police.[135] The British Transport Police are responsible for police services on National Rail, London Underground, Docklands Light Railway and Tramlink services.[136] A fourth police force in London, the Ministry of Defence Police, do not generally become involved with policing the general public.		Crime rates vary widely by area, ranging from parts with serious issues to parts considered very safe. Today crime figures are made available nationally at Local Authority[137] and Ward level.[138] In 2015 there were 118 homicides, a 25.5% increase over 2014.[139] The Metropolitan Police have made detailed crime figures, broken down by category at borough and ward level, available on their website since 2000.[140]		London, also referred to as Greater London, is one of nine regions of England and the top-level subdivision covering most of the city's metropolis.[note 5] The small ancient City of London at its core once comprised the whole settlement, but as its urban area grew, the Corporation of London resisted attempts to amalgamate the city with its suburbs, causing "London" to be defined in a number of ways for different purposes.[141]		Forty per cent of Greater London is covered by the London post town, within which 'LONDON' forms part of postal addresses.[142][143] The London telephone area code (020) covers a larger area, similar in size to Greater London, although some outer districts are excluded and some places just outside are included. The Greater London boundary has been aligned to the M25 motorway in places.[144]		Outward urban expansion is now prevented by the Metropolitan Green Belt,[145] although the built-up area extends beyond the boundary in places, resulting in a separately defined Greater London Urban Area. Beyond this is the vast London commuter belt.[146] Greater London is split for some purposes into Inner London and Outer London.[147] The city is split by the River Thames into North and South, with an informal central London area in its interior. The coordinates of the nominal centre of London, traditionally considered to be the original Eleanor Cross at Charing Cross near the junction of Trafalgar Square and Whitehall, are about 51°30′26″N 00°07′39″W﻿ / ﻿51.50722°N 0.12750°W﻿ / 51.50722; -0.12750.[148] However the geographical centre of London, on one definition, is in the London Borough of Lambeth, just 0.1 miles to the northeast of Lambeth North tube station.[149]		Within London, both the City of London and the City of Westminster have city status and both the City of London and the remainder of Greater London are counties for the purposes of lieutenancies.[150] The area of Greater London has incorporated areas that are part of the historic counties of Middlesex, Kent, Surrey, Essex and Hertfordshire.[151] London's status as the capital of England, and later the United Kingdom, has never been granted or confirmed officially—by statute or in written form.[note 6]		Its position was formed through constitutional convention, making its status as de facto capital a part of the UK's unwritten constitution. The capital of England was moved to London from Winchester as the Palace of Westminster developed in the 12th and 13th centuries to become the permanent location of the royal court, and thus the political capital of the nation.[155] More recently, Greater London has been defined as a region of England and in this context is known as London.[12]		Greater London encompasses a total area of 1,583 square kilometres (611 sq mi), an area which had a population of 7,172,036 in 2001 and a population density of 4,542 inhabitants per square kilometre (11,760/sq mi). The extended area known as the London Metropolitan Region or the London Metropolitan Agglomeration, comprises a total area of 8,382 square kilometres (3,236 sq mi) has a population of 13,709,000 and a population density of 1,510 inhabitants per square kilometre (3,900/sq mi).[156] Modern London stands on the Thames, its primary geographical feature, a navigable river which crosses the city from the south-west to the east. The Thames Valley is a floodplain surrounded by gently rolling hills including Parliament Hill, Addington Hills, and Primrose Hill. Historically London grew up at the lowest bridging point on the Thames. The Thames was once a much broader, shallower river with extensive marshlands; at high tide, its shores reached five times their present width.[157]		Since the Victorian era the Thames has been extensively embanked, and many of its London tributaries now flow underground. The Thames is a tidal river, and London is vulnerable to flooding.[158] The threat has increased over time because of a slow but continuous rise in high water level by the slow 'tilting' of Britain (up in the north and down in the south) caused by post-glacial rebound.[159]		In 1974, a decade of work began on the construction of the Thames Barrier across the Thames at Woolwich to deal with this threat. While the barrier is expected to function as designed until roughly 2070, concepts for its future enlargement or redesign are already being discussed.[160]		London has a temperate oceanic climate (Köppen: Cfb ), similar to all of southern England. Despite its reputation as being a rainy city, London receives less precipitation in a year than Rome, Bordeaux, Toulouse, Naples, Sydney and New York.[161][162][163][164][165][166] Temperature extremes for all sites in the London area range from 38.1 °C (100.6 °F) at Kew during August 2003[167] down to −16.1 °C (3.0 °F) at Northolt during January 1962.[168]		Summers are mild, but generally warm. London's average July high is 24 °C (75.2 °F). On average London will see 31 days above 25 °C (77.0 °F) each year, and 4.2 days above 30.0 °C (86.0 °F) every year. During the 2003 European heat wave there were 14 consecutive days above 30 °C (86.0 °F) and 2 consecutive days where temperatures reached 38 °C (100.4 °F), leading to hundreds of heat related deaths.[169]		Winters are generally cool, cloudy and damp with little temperature variation. Snowfall occurs occasionally and can cause travel disruption when this happens. Snowfall is more common in outer London. Spring and autumn are mixed seasons and can be pleasant. As a large city, London has a considerable urban heat island effect,[170] making the centre of London at times 5 °C (9 °F) warmer than the suburbs and outskirts. The effect of this can be seen below when comparing London Heathrow, 15 miles west of London, with the London Weather Centre, in the city centre.[171]		London's vast urban area is often described using a set of district names, such as Bloomsbury, Mayfair, Wembley and Whitechapel. These are either informal designations, reflect the names of villages that have been absorbed by sprawl, or are superseded administrative units such as parishes or former boroughs.		Such names have remained in use through tradition, each referring to a local area with its own distinctive character, but without official boundaries. Since 1965 Greater London has been divided into 32 London boroughs in addition to the ancient City of London.[176][177] The City of London is the main financial district,[178] and Canary Wharf has recently developed into a new financial and commercial hub in the Docklands to the east.		The West End is London's main entertainment and shopping district, attracting tourists.[179] West London includes expensive residential areas where properties can sell for tens of millions of pounds.[180] The average price for properties in Kensington and Chelsea is over £2 million with a similarly high outlay in most of central London.[181][182]		The East End is the area closest to the original Port of London, known for its high immigrant population, as well as for being one of the poorest areas in London.[183] The surrounding East London area saw much of London's early industrial development; now, brownfield sites throughout the area are being redeveloped as part of the Thames Gateway including the London Riverside and Lower Lea Valley, which was developed into the Olympic Park for the 2012 Olympics and Paralympics.[183]		London's buildings are too diverse to be characterised by any particular architectural style, partly because of their varying ages. Many grand houses and public buildings, such as the National Gallery, are constructed from Portland stone. Some areas of the city, particularly those just west of the centre, are characterised by white stucco or whitewashed buildings. Few structures in central London pre-date the Great Fire of 1666, these being a few trace Roman remains, the Tower of London and a few scattered Tudor survivors in the City. Further out is, for example, the Tudor-period Hampton Court Palace, England's oldest surviving Tudor palace, built by Cardinal Thomas Wolsey c.1515.[184]		Wren's late 17th-century churches and the financial institutions of the 18th and 19th centuries such as the Royal Exchange and the Bank of England, to the early 20th century Old Bailey and the 1960s Barbican Estate form part of the varied architectural heritage.		The disused - but soon to be rejuvenated - 1939 Battersea Power Station by the river in the south-west is a local landmark, while some railway termini are excellent examples of Victorian architecture, most notably St. Pancras and Paddington.[185] The density of London varies, with high employment density in the central area, high residential densities in inner London, and lower densities in Outer London.		The Monument in the City of London provides views of the surrounding area while commemorating the Great Fire of London, which originated nearby. Marble Arch and Wellington Arch, at the north and south ends of Park Lane, respectively, have royal connections, as do the Albert Memorial and Royal Albert Hall in Kensington. Nelson's Column is a nationally recognised monument in Trafalgar Square, one of the focal points of central London. Older buildings are mainly brick built, most commonly the yellow London stock brick or a warm orange-red variety, often decorated with carvings and white plaster mouldings.[186]		In the dense areas, most of the concentration is via medium- and high-rise buildings. London's skyscrapers, such as 30 St Mary Axe, Tower 42, the Broadgate Tower and One Canada Square, are mostly in the two financial districts, the City of London and Canary Wharf. High-rise development is restricted at certain sites if it would obstruct protected views of St Paul's Cathedral and other historic buildings. Nevertheless, there are a number of very tall skyscrapers in central London (see Tall buildings in London), including the 95-storey Shard London Bridge, the tallest building in the European Union.		Other notable modern buildings include City Hall in Southwark with its distinctive oval shape[187] and the British Library in Somers Town/Kings Cross. What was formerly the Millennium Dome, by the Thames to the east of Canary Wharf, is now an entertainment venue called the O2 Arena.		The London Natural History Society suggest that London is "one of the World's Greenest Cities" with more than 40 percent green space or open water. They indicate that 2000 species of flowering plant have been found growing there and that the tidal Thames supports 120 species of fish.[188] They also state that over 60 species of bird nest in central London and that their members have recorded 47 species of butterfly, 1173 moths and more than 270 kinds of spider around London. London's wetland areas support nationally important populations of many water birds. London has 38 Sites of Special Scientific Interest (SSSIs), two National Nature Reserves and 76 Local Nature Reserves.[189]		Amphibians are common in the capital, including smooth newts living by the Tate Modern, and common frogs, common toads, palmate newts and great crested newts. On the other hand, native reptiles such as slowworms, common lizards, grass snakes and adders, are mostly only seen in Outer London.[190]		Among other inhabitants of London are 10,000 foxes, so that there are now 16 foxes for every square mile (2.6 square kilometres) of London. These urban foxes are noticeably bolder than their country cousins, sharing the pavement with pedestrians and raising cubs in people's backyards. Foxes have even sneaked into the Houses of Parliament, where one was found asleep on a filing cabinet. Another broke into the grounds of Buckingham Palace, reportedly killing some of Queen Elizabeth II's prized pink flamingos. Generally, however, foxes and city folk appear to get along. A survey in 2001 by the London-based Mammal Society found that 80 percent of 3,779 respondents who volunteered to keep a diary of garden mammal visits liked having them around. This sample cannot be taken to represent Londoners as a whole.[191][192]		Other mammals found in Greater London are hedgehogs, rats, mice, rabbit, shrew, vole, and squirrels,[193] In wilder areas of Outer London, such as Epping Forest, a wide variety of mammals are found including hare, badger, field, bank and water vole, wood mouse, yellow-necked mouse, mole, shrew, and weasel, in addition to fox, squirrel and hedgehog. A dead otter was found at The Highway, in Wapping, about a mile from the Tower Bridge, which would suggest that they have begun to move back after being absent a hundred years from the city.[194] Ten of England's eighteen species of bats have been recorded in Epping Forest: soprano, nathusius and common pipistrelles, noctule, serotine, barbastelle, daubenton's, brown Long-eared, natterer's and leisler's.[195]		Among the strange sights seen in London have been a whale in the Thames,[196] while the BBC Two programme "Natural World: Unnatural History of London" shows pigeons using the London Underground to get around the city, a seal that takes fish from fishmongers outside Billingsgate Fish Market, and foxes that will "sit" if given sausages.[197]		Herds of red and fallow deer also roam freely within much of Richmond and Bushy Park. A cull takes place each November and February to ensure numbers can be sustained.[198] Epping Forest is also known for its fallow deer, which can frequently be seen in herds to the north of the Forest. A rare population of melanistic, black fallow deer is also maintained at the Deer Sanctuary near Theydon Bois. Muntjac deer, which escaped from deer parks at the turn of the twentieth century, are also found in the forest. While Londoners are accustomed to wildlife such as birds and foxes sharing the city, more recently urban deer have started becoming a regular feature, and whole herds of fallow and white-tailed deer come into residential areas at night to take advantage of London's green spaces.[199][200]		The 2011 census recorded that 2,998,264 people or 36.7% of London's population are foreign-born making London the city with the second largest immigrant population, behind New York City, in terms of absolute numbers. The table to the right shows the most common countries of birth of London residents. Note that some of the German-born population, in 18th position, are British citizens from birth born to parents serving in the British Armed Forces in Germany.[202] With increasing industrialisation, London's population grew rapidly throughout the 19th and early 20th centuries, and it was for some time in the late 19th and early 20th centuries the most populous city in the world. Its population peaked at 8,615,245 in 1939 immediately before the outbreak of the Second World War, but had declined to 7,192,091 at the 2001 Census. However, the population then grew by just over a million between the 2001 and 2011 Censuses, to reach 8,173,941 in the latter enumeration.[203]		However, London's continuous urban area extends beyond the borders of Greater London and was home to 9,787,426 people in 2011,[44] while its wider metropolitan area has a population of between 12 and 14 million depending on the definition used.[204][205] According to Eurostat, London is the most populous city and metropolitan area of the European Union and the second most populous in Europe. During the period 1991–2001 a net 726,000 immigrants arrived in London.[206]		The region covers an area of 1,579 square kilometres (610 sq mi). The population density is 5,177 inhabitants per square kilometre (13,410/sq mi),[207] more than ten times that of any other British region.[208] In terms of population, London is the 19th largest city and the 18th largest metropolitan region in the world. As of 2014[update], London has the largest number of billionaires (British Pound Sterling) in the world, with 72 residing in the city.[209] London ranks as one of the most expensive cities in the world, alongside Tokyo and Moscow.[210]		Ethnic groups in the 2011 census [211]		According to the Office for National Statistics, based on the 2011 Census estimates, 59.8 per cent of the 8,173,941 inhabitants of London were White, with 44.9 per cent White British, 2.2 per cent White Irish, 0.1 per cent gypsy/Irish traveller and 12.1 per cent classified as Other White.		20.9 per cent of Londoners are of Asian and mixed-Asian descent. 19.7 per cent are of full Asian descent, with those of mixed-Asian heritage comprising 1.2 of the population. Indians account for 6.6 per cent of the population, followed by Pakistanis and Bangladeshis at 2.7 per cent each. Chinese peoples account for 1.5 per cent of the population, with Arabs comprising 1.3 per cent. A further 4.9 per cent are classified as "Other Asian".		15.6 per cent of London's population are of Black and mixed-Black descent. 13.3 per cent are of full Black descent, with those of mixed-Black heritage comprising 2.3 per cent. Black Africans account for 7.0 per cent of London's population, with 4.2 per cent as Black Caribbean and 2.1 per cent as "Other Black". 5.0 per cent are of mixed race.		Across London, Black and Asian children outnumber White British children by about six to four in state schools.[212] Altogether at the 2011 census, of London's 1,624,768 population aged 0 to 15, 46.4 per cent were White, 19.8 per cent were Asian, 19 per cent were Black, 10.8 per cent were Mixed and 4 per cent represented another ethnic group.[213] In January 2005, a survey of London's ethnic and religious diversity claimed that there were more than 300 languages spoken in London and more than 50 non-indigenous communities with a population of more than 10,000.[214] Figures from the Office for National Statistics show that, in 2010[update], London's foreign-born population was 2,650,000 (33 per cent), up from 1,630,000 in 1997.		The 2011 census showed that 36.7 per cent of Greater London's population were born outside the UK.[215] A portion of the German-born population are likely to be British nationals born to parents serving in the British Armed Forces in Germany.[216] Estimates produced by the Office for National Statistics indicate that the five largest foreign-born groups living in London in the period July 2009 to June 2010 were those born in India, Poland, the Republic of Ireland, Bangladesh and Nigeria.[217]		According to the 2011 Census, the largest religious groupings are Christians (48.4 per cent), followed by those of no religion (20.7 per cent), Muslims (12.4 per cent), no response (8.5 per cent), Hindus (5.0 per cent), Jews (1.8 per cent), Sikhs (1.5 per cent), Buddhists (1.0 per cent) and other (0.6 per cent).		London has traditionally been Christian, and has a large number of churches, particularly in the City of London. The well-known St Paul's Cathedral in the City and Southwark Cathedral south of the river are Anglican administrative centres,[219] while the Archbishop of Canterbury, principal bishop of the Church of England and worldwide Anglican Communion, has his main residence at Lambeth Palace in the London Borough of Lambeth.[220]		Important national and royal ceremonies are shared between St Paul's and Westminster Abbey.[221] The Abbey is not to be confused with nearby Westminster Cathedral, which is the largest Roman Catholic cathedral in England and Wales.[222] Despite the prevalence of Anglican churches, observance is very low within the Anglican denomination. Church attendance continues on a long, slow, steady decline, according to Church of England statistics.[223]		London is also home to sizeable Muslim, Hindu, Sikh, and Jewish communities. Notable mosques include the East London Mosque in Tower Hamlets, London Central Mosque on the edge of Regent's Park[224] and the Baitul Futuh Mosque of the Ahmadiyya Muslim Community. Following the oil boom, increasing numbers of wealthy Hindus and Middle-Eastern Muslims have based themselves around Mayfair and Knightsbridge in West London.[225][226][227] There are large Muslim communities in the eastern boroughs of Tower Hamlets and Newham.[228] Large Hindu communities are in the north-western boroughs of Harrow and Brent, the latter of which is home to Europe's largest Hindu temple, Neasden Temple.[229] London is also home to 42 Hindu temples. There are Sikh communities in East and West London, particularly in Southall, home to one of the largest Sikh populations and the largest Sikh temple outside India.[230]		The majority of British Jews live in London, with significant Jewish communities in Stamford Hill, Stanmore, Golders Green, Finchley, Hampstead, Hendon and Edgware in North London. Bevis Marks Synagogue in the City of London is affiliated to London's historic Sephardic Jewish community. It is the only synagogue in Europe which has held regular services continuously for over 300 years. Stanmore and Canons Park Synagogue has the largest membership of any single Orthodox synagogue in the whole of Europe, overtaking Ilford synagogue (also in London) in 1998.[231] The community set up the London Jewish Forum in 2006 in response to the growing significance of devolved London Government.[232]		There are many accents that are traditionally thought of as London accents. The most well known of the London accents long ago acquired the Cockney label, which is heard both in London itself, and across the wider South East England region more generally.[233] The accent of a 21st-century Londoner varies widely; what is becoming more and more common amongst the under-30s however is some fusion of Cockney with a whole array of ethnic accents, in particular Caribbean, which form an accent labelled Multicultural London English (MLE).[234] The other widely heard and spoken accent is RP (Received Pronunciation) in various forms, which can often be heard in the media and many of other traditional professions and beyond, although this accent is not limited to London and South East England, and can also be heard selectively throughout the whole UK amongst certain social groupings.		London generates about 20 per cent of the UK's GDP[236] (or $600 billion in 2014); while the economy of the London metropolitan area—the largest in Europe—generates about 30 per cent of the UK's GDP (or an estimated $669 billion in 2005).[237] London has five major business districts: the City, Westminster, Canary Wharf, Camden & Islington and Lambeth & Southwark. One way to get an idea of their relative importance is to look at relative amounts of office space: Greater London had 27 million m2 of office space in 2001, and the City contains the most space, with 8 million m2 of office space. London has some of the highest real estate prices in the world.[238][239] London is the world's most expensive office market for the last three years according to world property journal (2015) report.[240] As of 2015[update] the residential property in London is worth $2.2 trillion – same value as that of Brazil annual GDP.[241] The city has the highest property prices of any European city according to the Office for National Statistics and the European Office of Statistics.[242] On average the price per square metre in central London is €24,252 (April 2014). This is higher than the property prices in other G8 European capital cities; Berlin €3,306, Rome €6,188 and Paris €11,229.[243]		London finance industry is based in the City of London and Canary Wharf, the two major Central Business Districts in London. London is one of the pre-eminent financial centres of the world as the most important location for international finance.[244][245] London took over as a major financial centre shortly after 1795 when the Dutch Republic collapsed before the Napoleonic armies. For many bankers established in Amsterdam (e.g. Hope, Baring), this was only time to move to London. The London financial elite was strengthened by a strong Jewish community from all over Europe capable of mastering the most sophisticated financial tools of the time.[246] This unique concentration of talents accelerated the transition from the Commercial Revolution to the Industrial Revolution. By the end of the 19th century, Britain was the wealthiest of all nations, and London a leading financial centre. Still, as of 2016 London tops the world rankings on both the Global Financial Centres Index (GFCI)[247] and The Global Cities Index.[248]		London's largest industry is finance, and its financial exports make it a large contributor to the UK's balance of payments. Around 325,000 people were employed in financial services in London until mid-2007. London has over 480 overseas banks, more than any other city in the world. It is also the world's biggest currency trading centre, accounting for some 37 percent of the $5.1 trillion average daily volume, according to the BIS.[249] Over 85 percent (3.2 million) of the employed population of greater London works in the services industries. Because of its prominent global role, London's economy had been affected by the financial crisis of 2007–2008. However, by 2010 the City has recovered; put in place new regulatory powers, proceeded to regain lost ground and re-established London's economic dominance.[250] Along with professional services headquarters, the City of London is home to the Bank of England, London Stock Exchange, and Lloyd's of London insurance market.		Over half of the UK's top 100 listed companies (the FTSE 100) and over 100 of Europe's 500 largest companies have their headquarters in central London. Over 70 per cent of the FTSE 100 are within London's metropolitan area, and 75 per cent of Fortune 500 companies have offices in London.[251]		Media companies are concentrated in London and the media distribution industry is London's second most competitive sector.[252] The BBC is a significant employer, while other broadcasters also have headquarters around the City. Many national newspapers are edited in London. London is a major retail centre and in 2010 had the highest non-food retail sales of any city in the world, with a total spend of around £64.2 billion.[253] The Port of London is the second-largest in the United Kingdom, handling 45 million tonnes of cargo each year.[254]		A growing number of technology companies are based in London notably in East London Tech City, also known as Silicon Roundabout. In April 2014, the city was among the first to receive a geoTLD.[255] In February 2014 London was ranked as the European City of the Future [256] in the 2014/15 list by FDi Magazine.[257]		The gas and electricity distribution networks that manage and operate the towers, cables and pressure systems that deliver energy to consumers across the city are managed by National Grid plc, SGN[258] and UK Power Networks.[259]		London is one of the leading tourist destinations in the world and in 2015 was ranked as the most visited city in the world with over 65 million visits.[260][261] It is also the top city in the world by visitor cross-border spending, estimated at US$20.23 billion in 2015.[262] Tourism is one of London's prime industries, employing the equivalent of 350,000 full-time workers in 2003,[263] and the city accounts for 54% of all inbound visitor spending in the UK.[264] As of 2016[update] London is the world top city destination as ranked by TripAdvisor users.[265]		In 2015, the top most-visited attractions in UK were all in London. The top 10 most visited attractions were: (with visits per venue) [266]		The number of hotel rooms in London in 2015 stood at 138,769, and is expected to grow over the years.[267]		Thousands of homeless families find themselves in emergency accommodation for at least two years.[268] A growth in the number of UK households has led to the homeless charity Shelter stating: "This growth is a result of people living longer, more people living alone or in smaller households, and net migration."[269]		Transport is one of the four main areas of policy administered by the Mayor of London,[270] however the mayor's financial control does not extend to the longer distance rail network that enters London. In 2007 he assumed responsibility for some local lines, which now form the London Overground network, adding to the existing responsibility for the London Underground, trams and buses. The public transport network is administered by Transport for London (TFL).		The lines that formed the London Underground, as well as trams and buses, became part of an integrated transport system in 1933 when the London Passenger Transport Board or London Transport was created. Transport for London is now the statutory corporation responsible for most aspects of the transport system in Greater London, and is run by a board and a commissioner appointed by the Mayor of London.[271]		London is a major international air transport hub with the busiest city airspace in the world. Eight airports use the word London in their name, but most traffic passes through six of these. Additionally, various other airports also serve London, catering primarily to general aviation flights.		The London Underground, commonly referred to as the Tube, is the oldest[279] and second longest[280] metro system in the world. The system serves 270 stations[281] and was formed from several private companies, including the world's first underground electric line, the City and South London Railway.[282] It dates from 1863.[283]		Over four million journeys are made every day on the Underground network, over 1 billion each year.[284] An investment programme is attempting to reduce congestion and improve reliability, including £6.5 billion (€7.7 billion) spent before the 2012 Summer Olympics.[285] The Docklands Light Railway (DLR), which opened in 1987, is a second, more local metro system using smaller and lighter tram-type vehicles that serve the Docklands, Greenwich and Lewisham.		There are 366 railway stations in the London Travelcard Zones on an extensive above-ground suburban railway network. South London, particularly, has a high concentration of railways as it has fewer Underground lines. Most rail lines terminate around the centre of London, running into eighteen terminal stations, with the exception of the Thameslink trains connecting Bedford in the north and Brighton in the south via Luton and Gatwick airports.[286] London has Britain's busiest station by number of passengers – Waterloo, with over 184 million people using the interchange station complex (which includes Waterloo East station) each year.[287][288] Clapham Junction is the busiest station in Europe by the number of trains passing.		With the need for more rail capacity in London, Crossrail is due to open in 2018. It will be a new railway line running east to west through London and into the Home Counties with a branch to Heathrow Airport.[289] It is Europe's biggest construction project, with a £15 billion projected cost.[290][291]		London is the centre of the National Rail network, with 70 percent of rail journeys starting or ending in London.[292] Like suburban rail services, regional and inter-city trains depart from several termini around the city centre, linking London with the rest of Britain including Birmingham, Brighton, Reading, Bristol, Cardiff, Derby, Exeter, Sheffield, Southampton, Leeds, Liverpool, Manchester, Cambridge, Newcastle-upon-Tyne, Edinburgh and Glasgow.		Some international railway services to Continental Europe were operated during the 20th century as boat trains, such as the Admiraal de Ruijter to Amsterdam and the Night Ferry to Paris and Brussels. The opening of the Channel Tunnel in 1994 connected London directly to the continental rail network, allowing Eurostar services to begin. Since 2007, high-speed trains link St. Pancras International with Lille, Paris, Brussels and European tourist destinations via the High Speed 1 rail link and the Channel Tunnel.[293] The first high-speed domestic trains started in June 2009 linking Kent to London.[294] There are plans for a second high speed line linking London to the Midlands, North West England, and Yorkshire.		Although rail freight levels are far down compared to their height, significant quantities of cargo are also carried into and out of London by rail; chiefly building materials and landfill waste.[295] As a major hub of the British railway network, London's tracks also carry large amounts of freight for the other regions, such as container freight from the Channel Tunnel and English Channel ports, and nuclear waste for reprocessing at Sellafield.[295]		London's bus network is one of the largest in the world, running 24 hours a day, with about 8,500 buses, more than 700 bus routes and around 19,500 bus stops.[296] In 2013, the network had more than 2 billion commuter trips per annum, more than the Underground.[296] Around £850 million is taken in revenue each year. London has the largest wheelchair accessible network in the world[297] and, from the 3rd quarter of 2007, became more accessible to hearing and visually impaired passengers as audio-visual announcements were introduced. The distinctive red double-decker buses are an internationally recognised trademark of London transport along with black cabs and the Tube.[298][299]		London has a modern tram network, known as Tramlink, centred on Croydon in South London. The network has 39 stops and four routes, and carried 28 million people in 2013.[300] Since June 2008 Transport for London has completely owned Tramlink, and it plans to spend £54m by 2015 on maintenance, renewals, upgrades and capacity enhancements.[301]		London's first and only cable car, known as the Emirates Air Line, opened in June 2012. Crossing the River Thames, linking Greenwich Peninsula and the Royal Docks in the east of the city, the cable car is integrated with London's Oyster Card ticketing system, although special fares are charged. Costing £60 million to build, it carries over 3,500 passengers every day, although this is very much lower than its capacity. Similar to the Santander Cycles bike hire scheme, the cable car is sponsored in a 10-year deal by the airline Emirates.		Cycling is an increasingly popular way to get around London. The launch of a cycle hire scheme in July 2010 has been successful and generally well received. The London Cycling Campaign lobbies for better provision.[302]		From being the largest port in the world, the Port of London is now only the second-largest in the United Kingdom, handling 45 million tonnes of cargo each year.[254] Most of this actually passes through the Port of Tilbury, outside the boundary of Greater London.		London has frequent river boat services on the Thames known as Thames Clippers. These run up to every 20 minutes between Embankment Pier and North Greenwich Pier. The Woolwich Ferry, with 2.5 million passengers every year,[303] is a frequent service linking the North and South Circular Roads. Other operators run both commuter and tourist boat services in London.		Although the majority of journeys involving central London are made by public transport, car travel is common in the suburbs. The inner ring road (around the city centre), the North and South Circular roads (in the suburbs), and the outer orbital motorway (the M25, outside the built-up area) encircle the city and are intersected by a number of busy radial routes—but very few motorways penetrate into inner London. A plan for a comprehensive network of motorways throughout the city (the Ringways Plan) was prepared in the 1960s but was mostly cancelled in the early 1970s. The M25 is the longest ring-road motorway in the world at 121.5 mi (195.5 km) long.[304][305] The A1 and M1 connect London to Leeds, and Newcastle and Edinburgh.		London is notorious for its traffic congestion, with the M25 motorway the busiest stretch in the country. The average speed of a car in the rush hour is 10.6 mph (17.1 km/h).[306]		In 2003, a congestion charge was introduced to reduce traffic volumes in the city centre. With a few exceptions, motorists are required to pay £10 per day to drive within a defined zone encompassing much of central London.[307][308] Motorists who are residents of the defined zone can buy a greatly reduced season pass.[309] London government initially expected the Congestion Charge Zone to increase daily peak period Underground and bus users by 20,000 people, reduce road traffic by 10 to 15 per cent, increase traffic speeds by 10 to 15 per cent, and reduce queues by 20 to 30 per cent.[310] Over the course of several years, the average number of cars entering the centre of London on a weekday was reduced from 195,000 to 125,000 cars – a 35-per-cent reduction of vehicles driven per day.[311]		London is a major global centre of higher education teaching and research and has the largest concentration of higher education institutes in Europe.[39] According to the QS World University Rankings 2015/16, London has the greatest concentration of top class universities in the world[312][313] and its international student population of around 110,000 is larger than any other city in the world.[314] A 2014 PricewaterhouseCoopers report termed London as the global capital of higher education.[315]		A number of world-leading education institutions are based in London. In the 2014/15 QS World University Rankings, Imperial College London is ranked joint 2nd in the world, University College London (UCL) is ranked 5th, and King's College London (KCL) is ranked 16th.[316] The London School of Economics has been described as the world's leading social science institution for both teaching and research.[317] The London Business School is considered one of the world's leading business schools and in 2015 its MBA programme was ranked second best in the world by the Financial Times.[318]		With 120,000 students in London,[319] the federal University of London is the largest contact teaching university in the UK.[320] It includes five multi-faculty universities – City, King's College London, Queen Mary, Royal Holloway and UCL – and a number of smaller and more specialised institutions including Birkbeck, the Courtauld Institute of Art, Goldsmiths, Guildhall School of Music and Drama, the London Business School, the London School of Economics, the London School of Hygiene & Tropical Medicine, the Royal Academy of Music, the Central School of Speech and Drama, the Royal Veterinary College and the School of Oriental and African Studies.[321] Members of the University of London have their own admissions procedures, and some award their own degrees.		A number of universities in London are outside the University of London system, including Brunel University, Imperial College London, Kingston University, London Metropolitan University,[322] University of East London, University of West London, University of Westminster, London South Bank University, Middlesex University, and University of the Arts London (the largest university of art, design, fashion, communication and the performing arts in Europe).[323] In addition there are three international universities in London – Regent's University London, Richmond, The American International University in London and Schiller International University.		London is home to five major medical schools – Barts and The London School of Medicine and Dentistry (part of Queen Mary), King's College London School of Medicine (the largest medical school in Europe), Imperial College School of Medicine, UCL Medical School and St George's, University of London – and has a large number of affiliated teaching hospitals. It is also a major centre for biomedical research, and three of the UK's eight academic health science centres are based in the city – Imperial College Healthcare, King's Health Partners and UCL Partners (the largest such centre in Europe).[324]		There are a number of business schools in London, including the London School of Business and Finance, Cass Business School (part of City University London), Hult International Business School, ESCP Europe, European Business School London, Imperial College Business School, the London Business School and the UCL School of Management. London is also home to many specialist arts education institutions, including the Academy of Live and Recorded Arts, Central School of Ballet, LAMDA, London College of Contemporary Arts (LCCA), London Contemporary Dance School, National Centre for Circus Arts, RADA, Rambert School of Ballet and Contemporary Dance, the Royal College of Art, the Royal College of Music and Trinity Laban.		The majority of primary and secondary schools and further-education colleges in London are controlled by the London boroughs or otherwise state-funded; leading examples include City and Islington College, Ealing, Hammersmith and West London College, Leyton Sixth Form College, Tower Hamlets College, Bethnal Green Academy and Newham College. There are also a number of private schools and colleges in London, some old and famous, such as City of London School, Harrow, St Paul's School, Haberdashers' Aske's Boys' School, University College School, The John Lyon School, Highgate School and Westminster School.		Leisure is a major part of the London economy, with a 2003 report attributing a quarter of the entire UK leisure economy to London.[325] Globally, the city is amongst the big four fashion capitals of the world, and according to official statistics, London is the world's third busiest film production centre, presents more live comedy than any other city,[326] and has the biggest theatre audience of any city in the world.[327]		Within the City of Westminster in London, the entertainment district of the West End has its focus around Leicester Square, where London and world film premieres are held, and Piccadilly Circus, with its giant electronic advertisements.[328] London's theatre district is here, as are many cinemas, bars, clubs, and restaurants, including the city's Chinatown district (in Soho), and just to the east is Covent Garden, an area housing speciality shops. The city is the home of Andrew Lloyd Webber, whose musicals have dominated the West End theatre since the late 20th century.[329] The United Kingdom's Royal Ballet, English National Ballet, Royal Opera, and English National Opera are based in London and perform at the Royal Opera House, the London Coliseum, Sadler's Wells Theatre, and the Royal Albert Hall, as well as touring the country.[330]		Islington's 1 mile (1.6 km) long Upper Street, extending northwards from Angel, has more bars and restaurants than any other street in the United Kingdom.[331] Europe's busiest shopping area is Oxford Street, a shopping street nearly 1 mile (1.6 km) long, making it the longest shopping street in the UK. Oxford Street is home to vast numbers of retailers and department stores, including the world-famous Selfridges flagship store.[332] Knightsbridge, home to the equally renowned Harrods department store, lies to the south-west.		London is home to designers Vivienne Westwood, Galliano, Stella McCartney, Manolo Blahnik, and Jimmy Choo, among others; its renowned art and fashion schools make it an international centre of fashion alongside Paris, Milan, and New York. London offers a great variety of cuisine as a result of its ethnically diverse population. Gastronomic centres include the Bangladeshi restaurants of Brick Lane and the Chinese restaurants of Chinatown.[333]		There is a variety of annual events, beginning with the relatively new New Year's Day Parade, a fireworks display at the London Eye; the world's second largest street party, the Notting Hill Carnival, is held on the late August Bank Holiday each year. Traditional parades include November's Lord Mayor's Show, a centuries-old event celebrating the annual appointment of a new Lord Mayor of the City of London with a procession along the streets of the City, and June's Trooping the Colour, a formal military pageant performed by regiments of the Commonwealth and British armies to celebrate the Queen's Official Birthday.[334]		London has been the setting for many works of literature. The literary centres of London have traditionally been hilly Hampstead and (since the early 20th century) Bloomsbury. Writers closely associated with the city are the diarist Samuel Pepys, noted for his eyewitness account of the Great Fire, Charles Dickens, whose representation of a foggy, snowy, grimy London of street sweepers and pickpockets has been a major influence on people's vision of early Victorian London, and Virginia Woolf, regarded as one of the foremost modernist literary figures of the 20th century.[335] The pilgrims in Geoffrey Chaucer's late 14th-century Canterbury Tales set out for Canterbury from London – specifically, from the Tabard inn, Southwark. William Shakespeare spent a large part of his life living and working in London; his contemporary Ben Jonson was also based there, and some of his work—most notably his play The Alchemist—was set in the city.[335] A Journal of the Plague Year (1722) by Daniel Defoe is a fictionalisation of the events of the 1665 Great Plague.[335] Later important depictions of London from the 19th and early 20th centuries are Dickens' novels, and Arthur Conan Doyle's Sherlock Holmes stories.[335] Modern writers pervasively influenced by the city include Peter Ackroyd, author of a "biography" of London, and Iain Sinclair, who writes in the genre of psychogeography.		London has played a significant role in the film industry. Major studios within or bordering London include Twickenham, Ealing, Shepperton, Pinewood, Elstree and Borehamwood,[336] and a special effects and post-production community centred in Soho. Working Title Films has its headquarters in London.[337] London has been the setting for films including Oliver Twist (1948), Scrooge (1951), Peter Pan (1953), The 101 Dalmatians (1961), My Fair Lady (1964), Mary Poppins (1964), Blowup (1966), The Long Good Friday (1980), Notting Hill (1999), Love Actually (2003), V For Vendetta (2005), Sweeney Todd: The Demon Barber Of Fleet Street (2008) and The King's Speech (2010). Notable actors and filmmakers from London include; Charlie Chaplin, Alfred Hitchcock, Michael Caine, Helen Mirren, Gary Oldman, Christopher Nolan, Jude Law, Benedict Cumberbatch, Tom Hardy, Keira Knightley and Daniel Day-Lewis. As of 2008[update], the British Academy Film Awards have taken place at the Royal Opera House. London is a major centre for television production, with studios including BBC Television Centre, The Fountain Studios and The London Studios. Many television programmes have been set in London, including the popular television soap opera EastEnders, broadcast by the BBC since 1985.		London is home to many museums, galleries, and other institutions, many of which are free of admission charges and are major tourist attractions as well as playing a research role. The first of these to be established was the British Museum in Bloomsbury, in 1753. Originally containing antiquities, natural history specimens, and the national library, the museum now has 7 million artefacts from around the globe. In 1824, the National Gallery was founded to house the British national collection of Western paintings; this now occupies a prominent position in Trafalgar Square.		In the latter half of the 19th century the locale of South Kensington was developed as "Albertopolis", a cultural and scientific quarter. Three major national museums are there: the Victoria and Albert Museum (for the applied arts), the Natural History Museum, and the Science Museum. The National Portrait Gallery was founded in 1856 to house depictions of figures from British history; its holdings now comprise the world's most extensive collection of portraits.[338] The national gallery of British art is at Tate Britain, originally established as an annexe of the National Gallery in 1897. The Tate Gallery, as it was formerly known, also became a major centre for modern art; in 2000, this collection moved to Tate Modern, a new gallery housed in the former Bankside Power Station.		London is one of the major classical and popular music capitals of the world and is home to major music corporations, such as Warner Music Group, as well as countless bands, musicians and industry professionals. The city is also home to many orchestras and concert halls, such as the Barbican Arts Centre (principal base of the London Symphony Orchestra and the London Symphony Chorus), Cadogan Hall (Royal Philharmonic Orchestra) and the Royal Albert Hall (The Proms).[330] London's two main opera houses are the Royal Opera House and the London Coliseum.[330] The UK's largest pipe organ is at the Royal Albert Hall. Other significant instruments are at the cathedrals and major churches. Several conservatoires are within the city: Royal Academy of Music, Royal College of Music, Guildhall School of Music and Drama and Trinity Laban.		London has numerous venues for rock and pop concerts, including the world's busiest arena the O2 arena[339] and other large arenas such as Earls Court, Wembley Arena, as well as many mid-sized venues, such as Brixton Academy, the Hammersmith Apollo and the Shepherd's Bush Empire.[330] Several music festivals, including the Wireless Festival, South West Four, Lovebox, and Hyde Park's British Summer Time are all held in London.[340] The city is home to the original Hard Rock Cafe and the Abbey Road Studios, where The Beatles recorded many of their hits. In the 1960s, 1970s and 1980s, musicians and groups like Elton John, Pink Floyd, Cliff Richard, David Bowie, Queen, The Kinks, The Rolling Stones, The Who, Eric Clapton, Led Zeppelin, The Small Faces, Iron Maiden, Fleetwood Mac, Elvis Costello, Cat Stevens, The Police, The Cure, Madness, The Jam, Ultravox, Spandau Ballet, Culture Club, Dusty Springfield, Phil Collins, Rod Stewart, Adam Ant, Status Quo and Sade, derived their sound from the streets and rhythms of London.[341]		London was instrumental in the development of punk music,[342] with figures such as the Sex Pistols, The Clash,[341] and Vivienne Westwood all based in the city. More recent artists to emerge from the London music scene include George Michael's Wham!, Kate Bush, Seal, the Pet Shop Boys, Bananarama, Siouxsie and the Banshees, Bush, the Spice Girls, Jamiroquai, Blur, McFly, The Prodigy, Gorillaz, Bloc Party, Mumford & Sons, Coldplay, Amy Winehouse, Adele, Sam Smith, Ed Sheeran, Paloma Faith, Ellie Goulding, One Direction and Florence and the Machine.[343][344][345] London is also a centre for urban music. In particular the genres UK garage, drum and bass, dubstep and grime evolved in the city from the foreign genres of hip hop and reggae, alongside local drum and bass. Music station BBC Radio 1Xtra was set up to support the rise of local urban contemporary music both in London and in the rest of the United Kingdom.[citation needed]		The largest parks in the central area of London are three of the eight Royal Parks, namely Hyde Park and its neighbour Kensington Gardens in the west, and Regent's Park to the north.[346] Hyde Park in particular is popular for sports and sometimes hosts open-air concerts. Regent's Park contains London Zoo, the world's oldest scientific zoo, and is near the tourist attraction of Madame Tussauds Wax Museum.[347][348] Primrose Hill, immediately to the north of Regent's Park, at 256 feet (78 m)[349] is a popular spot from which to view the city skyline.		Close to Hyde Park are smaller Royal Parks, Green Park and St. James's Park.[350] A number of large parks lie outside the city centre, including Hampstead Heath and the remaining Royal Parks of Greenwich Park to the south-east[351] and Bushy Park and Richmond Park (the largest) to the south-west,[352][353] Hampton Court Park is also a royal park, but, because it contains a palace, it is administered by the Historic Royal Palaces, unlike the eight Royal Parks.[354]		Close to Richmond Park is Kew Gardens which has the world's largest collection of living plants. In 2003, the gardens were put on the UNESCO list of World Heritage Sites.[355] There are also numerous parks administered by London's borough Councils, including Victoria Park in the East End and Battersea Park in the centre. Some more informal, semi-natural open spaces also exist, including the 320-hectare (790-acre) Hampstead Heath of North London,[356] and Epping Forest, which covers 2,476 hectares (6,118 acres)[357] in the east. Both are controlled by the City of London Corporation.[358][359] Hampstead Heath incorporates Kenwood House, a former stately home and a popular location in the summer months when classical musical concerts are held by the lake, attracting thousands of people every weekend to enjoy the music, scenery and fireworks.[360]		Epping Forest is a popular venue for various outdoor activities, including mountain biking, walking, horse riding, golf, angling, and orienteering.[361]		Walking is a popular recreational activity in London. Areas that provide for walks include Wimbledon Common, Epping Forest, Hampton Court Park, Hampstead Heath, the eight Royal Parks, canals and disused railway tracks.[362] Access to canals and rivers has improved recently, including the creation of the Thames Path, some 28 miles (45 km) of which is within Greater London, and The Wandle Trail; this runs 12 miles (19 km) through South London along the River Wandle, a tributary of the River Thames.[363] Other long distance paths, linking green spaces, have also been created, including the Capital Ring, the Green Chain Walk, London Outer Orbital Path ("Loop"), Jubilee Walkway, Lea Valley Walk, and the Diana, Princess of Wales Memorial Walk.[364]		London has hosted the Summer Olympics three times: in 1908, 1948, and 2012.[365][366] It was chosen in July 2005 to host the 2012 Olympics and Paralympics, making it the first city to host the modern Games three times.[40] The city was also the host of the British Empire Games in 1934.[367] In 2017 London will host the World Championships in Athletics.[368]		London's most popular sport is football and it has fourteen Football League clubs, including five in the Premier League: Arsenal, Chelsea, Crystal Palace, Tottenham Hotspur, and West Ham United.[369] Other professional teams in London are Fulham, Queens Park Rangers, Brentford, Millwall, Charlton Athletic, AFC Wimbledon, Barnet and Leyton Orient. Arsenal, Chelsea and Tottenham are the only London clubs to have won the League.		From 1924, the original Wembley Stadium was the home of the English national football team. It hosted the 1966 FIFA World Cup Final, with England defeating West Germany, and served as the venue for the FA Cup Final as well as rugby league's Challenge Cup final.[370] The new Wembley Stadium serves exactly the same purposes and has a capacity of 90,000.[371]		Two Aviva Premiership rugby union teams are based in London, Saracens and Harlequins.[372] London Scottish, London Welsh and London Irish play in the RFU Championship club and other rugby union clubs in the city include Richmond F.C., Rosslyn Park F.C., Westcombe Park R.F.C. and Blackheath F.C.. Twickenham Stadium in south-west London is the national rugby union stadium, and has a capacity of 82,000 now that the new south stand has been completed.[373]		While rugby league is more popular in the north of England, there are two professional rugby league clubs in London – the second tier Championship One team, the London Broncos, who play at the Trailfinders Sports Ground in West Ealing, and the third tier League 1 team, the London Skolars from Wood Green, Haringey; in addition, Hemel Stags from Hemel Hempstead north of London also play in League 1.		One of London's best-known annual sports competitions is the Wimbledon Tennis Championships, held at the All England Club in the south-western suburb of Wimbledon.[375] Played in late June to early July, it is the oldest tennis tournament in the world, and widely considered the most prestigious.[376][377][378]		London has two Test cricket grounds, Lord's (home of Middlesex C.C.C.) in St John's Wood[379] and the Oval (home of Surrey C.C.C.) in Kennington.[380] Lord's has hosted four finals of the Cricket World Cup. Other key events are the annual mass-participation London Marathon, in which some 35,000 runners attempt a 26.2 miles (42.2 km) course around the city,[381] and the University Boat Race on the River Thames from Putney to Mortlake.[382]		1 Tokyo-Yokohama 2 Jakarta 3 Shanghai 4 Karachi 5 Delhi				  6 Seoul-Incheon   7 Mexico City   8 Beijing   9 Lagos   10 São Paulo		11 Mumbai 12 New York 13 Osaka 14 Dhaka 15 Kolkata		16 Tehran 17 Istanbul 18 London 19 Los Angeles 20 Buenos Aires		
In geography and geology, a cliff is a vertical, or nearly vertical, rock exposure. Cliffs are formed as erosion landforms by the processes of weathering and erosion. Cliffs are common on coasts, in mountainous areas, escarpments and along rivers. Cliffs are usually formed by rock that is resistant to weathering and erosion. Sedimentary rocks most likely to form cliffs include sandstone, limestone, chalk, and dolomite. Igneous rocks such as granite and basalt also often form cliffs.		An escarpment (or scarp) is a type of cliff, formed by the movement of a geologic fault or landslide, or by differential erosion of rock layers of differing hardness.		Most cliffs have some form of scree slope at their base. In arid areas or under high cliffs, they are generally exposed jumbles of fallen rock. In areas of higher moisture, a soil slope may obscure the talus. Many cliffs also feature tributary waterfalls or rock shelters. Sometimes a cliff peters out at the end of a ridge, with tea tables or other types of rock columns remaining. Coastal erosion may lead to the formation of sea cliffs along a receding coastline.		The Ordnance Survey distinguishes between cliffs (continuous line along the top edge with projections down the face) and outcrops (continuous lines along lower edge).						Cliff comes from the Old English word clif of essentially the same meaning, cognate with Dutch, Low German, and Old Norse klif 'cliff'.[1] These may in turn all be from a Romance loanword into Primitive Germanic that has its origins in the Latin forms clivus / clevus ("slope" or "hillside").[2][3]		Given that a cliff need not be exactly vertical, there can be ambiguity about whether a given slope is a cliff or not and also about how much of a certain slope to count as a cliff. For example, given a truly vertical rock wall above a very steep slope, one could count just the rock wall or the combination. Listings of cliffs are thus inherently uncertain.		Some of the largest cliffs on Earth are found underwater. For example, an 8,000 m drop over a 4,250 m span can be found at a ridge sitting inside the Kermadec Trench.		One candidate for highest cliff in the world is Nanga Parbat's Rupal Face, which rises approximately 4,600 m, or 15,000 ft, above its base. According to other sources, the highest cliff in the world, about 1,340 m high, is the east face of Great Trango in the Karakoram mountains of northern Pakistan. This uses a fairly stringent notion of cliff, as the 1,340 m figure refers to a nearly vertical headwall of two stacked pillars; adding in a very steep approach brings the total drop from the East Face precipice to the nearby Dunge Glacier to nearly 2,000 m.		The location of the world's highest sea cliffs depends also on the definition of 'cliff' that is used. Guinness World Records states it is Kalaupapa, Hawaii,[5] at 1,010 m high. Another contender is the north face of Mitre Peak, which drops 1,683 m to Milford Sound, New Zealand.[6] These are subject to a less stringent definition, as the average slope of these cliffs at Kaulapapa is about 1.7, corresponding to an angle of 60 degrees, and Mitre Peak is similar. A more vertical drop into the sea can be found at Maujit Qaqarssuasia (also known as the 'Thumbnail') which is situated in the Torssukátak fjord area at the very tip of South Greenland and drops 1,560 m near-vertically.[7]		Considering a truly vertical drop, Mount Thor on Baffin Island in Arctic Canada is often considered the highest at 1370 m (4500 ft) high in total (the top 480 m (1600 ft) is overhanging), and is said to give it the longest vertical drop on Earth at 1,250 m (4,100 ft). However, other cliffs on Baffin Island, such as Polar Sun Spire in the Sam Ford Fjord, or others in remote areas of Greenland may be higher.		The highest cliff in the solar system may be Verona Rupes, an approximately 20 km (12 mi) high fault scarp on Miranda, a moon of Uranus.		The following is an incomplete list of cliffs of the world.		Above Sea		Above Land		Above Sea		Above Land		Several big granite faces in the Arctic region vie for the title of 'highest vertical drop on Earth', but reliable measurements are not always available. The possible contenders include (measurements are approximate):		Other notable cliffs include:		Above Sea		Above Land		Above Sea		Above Land		Cliff landforms provide unique habitat niches to a variety of plants and animals, whose preferences and needs are suited by the vertical geometry of this landform type. For example, a number of birds have decided affinities for choosing cliff locations for nesting,[16] often driven by the defensibility of these locations as well as absence of certain predators.		
In geology, a blowhole is formed as sea caves grow landwards and upwards into vertical shafts and expose themselves towards the surface, which can result in blasts of water from the top of the blowhole[1] if the geometry of the cave and blowhole and state of the weather are appropriate.[2]						Blowholes are likely to occur in areas where there are crevices, such as lava tubes, in rock along the coast.[3] These areas are often located along fault lines and on islands.[3] As powerful waves hit the coast, water rushes into these crevices and bursts out in a high pressured release.[3] It is often accompanied by a loud noise and wide spray, and for this reason, blowholes are often sites of tourism.[3]		Blowholes have the capacity to change the topography near their locations. Blowholes can eventually erode the area surrounding the crevices to form larger sea caves.[4] In some instances, the cave itself may collapse.[4] This event may create shallow pools along the coast.[5]		A blowhole is also the name of a rare geologic feature in which air is blown through a small hole at the surface due to pressure differences between a closed underground system and the surface. The blowholes of Wupatki National Monument are an example of such a phenomenon. It is estimated that the closed underground passages have a volume of at least seven billion cubic feet. Wind speeds can approach 30 miles per hour.[2] Another well-known example of the blowhole is the natural entrance to the Wind Cave[6]		Alofaaga Blowholes on Savai'i Island in Samoa		Blowholes, north coast of Barbados		Hummanaya - A blowhole located in Southern Province, Sri Lanka.		Nakalele blowhole, located near Nakalele Point in north western Maui, Hawaii.				
Sediment is a naturally occurring material that is broken down by processes of weathering and erosion, and is subsequently transported by the action of wind, water, or ice, and/or by the force of gravity acting on the particles. For example, sand and silt can be carried in suspension in river water and on reaching the sea be deposited by sedimentation and if buried this may eventually become sandstone and siltstone, ( sedimentary rocks).		Sediments are most often transported by water (fluvial processes), but also wind (aeolian processes) and glaciers. Beach sands and river channel deposits are examples of fluvial transport and deposition, though sediment also often settles out of slow-moving or standing water in lakes and oceans. Desert sand dunes and loess are examples of aeolian transport and deposition. Glacial moraine deposits and till are ice-transported sediments.						Sediment can be classified based on its grain size and/or its composition.		Sediment size is measured on a log base 2 scale, called the "Phi" scale, which classifies particles by size from "colloid" to "boulder".		Composition of sediment can be measured in terms of:		This leads to an ambiguity in which clay can be used as both a size-range and a composition (see clay minerals).		Sediment is transported based on the strength of the flow that carries it and its own size, volume, density, and shape. Stronger flows will increase the lift and drag on the particle, causing it to rise, while larger or denser particles will be more likely to fall through the flow.		Rivers and streams carry sediment in their flows. This sediment can be in a variety of locations within the flow, depending on the balance between the upwards velocity on the particle (drag and lift forces), and the settling velocity of the particle. These relationships are shown in the following table for the Rouse number, which is a ratio of sediment fall velocity to upwards velocity.		Rouse = Settling velocity Upwards velocity from lift and drag = w s κ u ∗ {\displaystyle {\textbf {Rouse}}={\frac {\text{Settling velocity}}{\text{Upwards velocity from lift and drag}}}={\frac {w_{s}}{\kappa u_{*}}}}		where		If the upwards velocity approximately equal to the settling velocity, sediment will be transported downstream entirely as suspended load. If the upwards velocity is much less than the settling velocity, but still high enough for the sediment to move (see Initiation of motion), it will move along the bed as bed load by rolling, sliding, and saltating (jumping up into the flow, being transported a short distance then settling again). If the upwards velocity is higher than the settling velocity, the sediment will be transported high in the flow as wash load.		As there are generally a range of different particle sizes in the flow, it is common for material of different sizes to move through all areas of the flow for given stream conditions.		Sediment motion can create self-organized structures such as ripples, dunes, antidunes on the river or stream bed. These bedforms are often preserved in sedimentary rocks and can be used to estimate the direction and magnitude of the flow that deposited the sediment.		Overland flow can erode soil particles and transport them downslope. The erosion associated with overland flow may occur through different methods depending on meteorological and flow conditions.		The major fluvial (river and stream) environments for deposition of sediments include:		Wind results in the transportation of fine sediment and the formation of sand dune fields and soils from airborne dust.		Glaciers carry a wide range of sediment sizes, and deposit it in moraines.		The overall balance between sediment in transport and sediment being deposited on the bed is given by the Exner equation. This expression states that the rate of increase in bed elevation due to deposition is proportional to the amount of sediment that falls out of the flow. This equation is important in that changes in the power of the flow changes the ability of the flow to carry sediment, and this is reflected in patterns of erosion and deposition observed throughout a stream. This can be localized, and simply due to small obstacles: examples are scour holes behind boulders, where flow accelerates, and deposition on the inside of meander bends. Erosion and deposition can also be regional: erosion can occur due to dam removal and base level fall. Deposition can occur due to dam emplacement that causes the river to pool, and deposit its entire load or due to base level rise.		Seas, oceans and lakes accumulate sediment over time. The sediment could consist of terrigenous material, which originates on land, but may be deposited in either terrestrial, marine, or lacustrine (lake) environments; or of sediments (often biological) originating in the body of water. Terrigenous material is often supplied by nearby rivers and streams or reworked marine sediment (e.g. sand). In the mid-ocean, the exoskeletons of dead organisms are primarily responsible for sediment accumulation.		Deposited sediments are the source of sedimentary rocks, which can contain fossils of the inhabitants of the body of water that were, upon death, covered by accumulating sediment. Lake bed sediments that have not solidified into rock can be used to determine past climatic conditions.		The major areas for deposition of sediments in the marine environment include:		One other depositional environment which is a mixture of fluvial and marine is the turbidite system, which is a major source of sediment to the deep sedimentary and abyssal basins as well as the deep oceanic trenches.		Any depression in a marine environment where sediments accumulate over time is known as a sediment trap.		The null point theory explains how sediment deposition undergoes a hydrodynamic sorting process within the marine environment leading to a seaward fining of sediment grain size.		One cause of high sediment loads from slash and burn and shifting cultivation of tropical forests. When the ground surface is stripped of vegetation and then seared of all living organisms, the upper soils are vulnerable to both wind and water erosion. In a number of regions of the earth, entire sectors of a country have become erodible. For example, on the Madagascar high central plateau, which constitutes approximately ten percent of that country's land area, most of the land area is devegetated, and gullies have eroded into the underlying soil in furrows typically in excess of 50 meters deep and one kilometer wide.[citation needed] This siltation results in discoloration of rivers to a dark red brown color and leads to fish kills.		Erosion is also an issue in areas of modern farming, where the removal of native vegetation for the cultivation and harvesting of a single type of crop has left the soil unsupported. Many of these regions are near rivers and drainages. Loss of soil due to erosion removes useful farmland, adds to sediment loads, and can help transport anthropogenic fertilizers into the river system, which leads to eutrophication.		Watershed development near coral reefs is a primary cause of sediment-related coral stress.The stripping of natural vegetation in the watershed for development exposes soil to increased wind and rainfall, and as a result, could cause exposed sediment to become more susceptible to erosion and delivery to the marine environment during rainfall events. Sediment can negatively affect corals in many ways, such as by physically smothering them, abrading their surfaces, causing corals to expend energy during sediment removal, and causing algal blooms that can ultimately lead to less space on the seafloor where juvenile corals (polyps) can settle.		When sediments are introduced into the coastal regions of the ocean, the proportion of land, marine and organic-derived sediment that characterizes the seafloor near sources of sediment output is altered. In addition, because the source of sediment (i.e. land, ocean, or organically) is often correlated with how coarse or fine sediment grain sizes that characterize an area are on average, grain size distribution of sediment will shift according to relative input of land (typically fine), marine (typically coarse), and organically-derived (variable with age) sediment. These alterations in marine sediment characterize the amount of sediment that is suspended in the water column at any given time and sediment-related coral stress.		
In physics, a wave is an oscillation accompanied by a transfer of energy that travels through a medium (mass)[citation needed]. Frequency refers to the addition of time. Wave motion transfers energy from one point to another, which displace particles of the transmission medium–that is, with little or no associated mass transport. Waves consist, instead, of oscillations or vibrations (of a physical quantity), around almost fixed locations.		A wave is a disturbance that transfers energy through matter or space. There are two main types of waves. Mechanical waves propagate through a medium, and the substance of this medium is deformed. Restoring forces then reverse the deformation. For example, sound waves propagate via air molecules colliding with their neighbors. When the molecules collide, they also bounce away from each other (a restoring force). This keeps the molecules from continuing to travel in the direction of the wave.		The second main type, electromagnetic waves, do not require a medium. Instead, they consist of periodic oscillations of electrical and magnetic fields originally generated by charged particles, and can therefore travel through a vacuum. These types vary in wavelength, and include radio waves, microwaves, infrared radiation, visible light, ultraviolet radiation, X-rays and gamma rays.		Waves are described by a wave equation which sets out how the disturbance proceeds over time. The mathematical form of this equation varies depending on the type of wave. Further, the behavior of particles in quantum mechanics are described by waves. In addition, gravitational waves also travel through space, which are a result of a vibration or movement in gravitational fields.		A wave can be transverse, where a disturbance creates oscillations that are perpendicular to the propagation of energy transfer, or longitudinal: the oscillations are parallel to the direction of energy propagation. While mechanical waves can be both transverse and longitudinal, all electromagnetic waves are transverse in free space.						A single, all-encompassing definition for the term wave is not straightforward. A vibration can be defined as a back-and-forth motion around a reference value. However, a vibration is not necessarily a wave. An attempt to define the necessary and sufficient characteristics that qualify a phenomenon as a wave results in a blurred line.		The term wave is often intuitively understood as referring to a transport of spatial disturbances that are generally not accompanied by a motion of the medium occupying this space as a whole. In a wave, the energy of a vibration is moving away from the source in the form of a disturbance within the surrounding medium (Hall 1980, p. 8). However, this motion is problematic for a standing wave (for example, a wave on a string), where energy is moving in both directions equally, or for electromagnetic (e.g., light) waves in a vacuum, where the concept of medium does not apply and interaction with a target is the key to wave detection and practical applications. There are water waves on the ocean surface; gamma waves and light waves emitted by the Sun; microwaves used in microwave ovens and in radar equipment; radio waves broadcast by radio stations; and sound waves generated by radio receivers, telephone handsets and living creatures (as voices), to mention only a few wave phenomena.		It may appear that the description of waves is closely related to their physical origin for each specific instance of a wave process. For example, acoustics is distinguished from optics in that sound waves are related to a mechanical rather than an electromagnetic wave transfer caused by vibration. Concepts such as mass, momentum, inertia, or elasticity, become therefore crucial in describing acoustic (as distinct from optic) wave processes. This difference in origin introduces certain wave characteristics particular to the properties of the medium involved. For example, in the case of air: vortices, radiation pressure, shock waves etc.; in the case of solids: Rayleigh waves, dispersion; and so on....		Other properties, however, although usually described in terms of origin, may be generalized to all waves. For such reasons, wave theory represents a particular branch of physics that is concerned with the properties of wave processes independently of their physical origin.[1] For example, based on the mechanical origin of acoustic waves, a moving disturbance in space–time can exist if and only if the medium involved is neither infinitely stiff nor infinitely pliable. If all the parts making up a medium were rigidly bound, then they would all vibrate as one, with no delay in the transmission of the vibration and therefore no wave motion. On the other hand, if all the parts were independent, then there would not be any transmission of the vibration and again, no wave motion. Although the above statements are meaningless in the case of waves that do not require a medium, they reveal a characteristic that is relevant to all waves regardless of origin: within a wave, the phase of a vibration (that is, its position within the vibration cycle) is different for adjacent points in space because the vibration reaches these points at different times.		Consider a traveling transverse wave (which may be a pulse) on a string (the medium). Consider the string to have a single spatial dimension. Consider this wave as traveling		This wave can then be described by the two-dimensional functions		or, more generally, by d'Alembert's formula:[3]		representing two component waveforms F {\displaystyle F} and G {\displaystyle G} traveling through the medium in opposite directions. A generalized representation of this wave can be obtained[4] as the partial differential equation		General solutions are based upon Duhamel's principle.[5]		The form or shape of F in d'Alembert's formula involves the argument x − vt. Constant values of this argument correspond to constant values of F, and these constant values occur if x increases at the same rate that vt increases. That is, the wave shaped like the function F will move in the positive x-direction at velocity v (and G will propagate at the same speed in the negative x-direction).[6]		In the case of a periodic function F with period λ, that is, F(x + λ − vt) = F(x − vt), the periodicity of F in space means that a snapshot of the wave at a given time t finds the wave varying periodically in space with period λ (the wavelength of the wave). In a similar fashion, this periodicity of F implies a periodicity in time as well: F(x − v(t + T)) = F(x − vt) provided vT = λ, so an observation of the wave at a fixed location x finds the wave undulating periodically in time with period T = λ/v.[7]		The amplitude of a wave may be constant (in which case the wave is a c.w. or continuous wave), or may be modulated so as to vary with time and/or position. The outline of the variation in amplitude is called the envelope of the wave. Mathematically, the modulated wave can be written in the form:[8][9][10]		where A ( x ,   t ) {\displaystyle A(x,\ t)} is the amplitude envelope of the wave, k {\displaystyle k} is the wavenumber and ϕ {\displaystyle \phi } is the phase. If the group velocity v g {\displaystyle v_{g}} (see below) is wavelength-independent, this equation can be simplified as:[11]		showing that the envelope moves with the group velocity and retains its shape. Otherwise, in cases where the group velocity varies with wavelength, the pulse shape changes in a manner often described using an envelope equation.[11][12]		There are two velocities that are associated with waves, the phase velocity and the group velocity. To understand them, one must consider several types of waveform. For simplification, examination is restricted to one dimension.		The most basic wave (a form of plane wave) may be expressed in the form:		which can be related to the usual sine and cosine forms using Euler's formula. Rewriting the argument, k x − ω t = ( 2 π λ ) ( x − v t ) {\displaystyle kx-\omega t=\left({\frac {2\pi }{\lambda }}\right)(x-vt)} , makes clear that this expression describes a vibration of wavelength λ = 2 π k {\displaystyle \lambda ={\frac {2\pi }{k}}} traveling in the x-direction with a constant phase velocity v p = ω k {\displaystyle v_{p}={\frac {\omega }{k}}\,} .[13]		The other type of wave to be considered is one with localized structure described by an envelope, which may be expressed mathematically as, for example:		where now A(k1) (the integral is the inverse Fourier transform of A(k1)) is a function exhibiting a sharp peak in a region of wave vectors Δk surrounding the point k1 = k. In exponential form:		with Ao the magnitude of A. For example, a common choice for Ao is a Gaussian wave packet:[14]		where σ determines the spread of k1-values about k, and N is the amplitude of the wave.		The exponential function inside the integral for ψ oscillates rapidly with its argument, say φ(k1), and where it varies rapidly, the exponentials cancel each other out, interfere destructively, contributing little to ψ.[13] However, an exception occurs at the location where the argument φ of the exponential varies slowly. (This observation is the basis for the method of stationary phase for evaluation of such integrals.[15]) The condition for φ to vary slowly is that its rate of change with k1 be small; this rate of variation is:[13]		where the evaluation is made at k1 = k because A(k1) is centered there. This result shows that the position x where the phase changes slowly, the position where ψ is appreciable, moves with time at a speed called the group velocity:		The group velocity therefore depends upon the dispersion relation connecting ω and k. For example, in quantum mechanics the energy of a particle represented as a wave packet is E = ħω = (ħk)2/(2m). Consequently, for that wave situation, the group velocity is		showing that the velocity of a localized particle in quantum mechanics is its group velocity.[13] Because the group velocity varies with k, the shape of the wave packet broadens with time, and the particle becomes less localized.[16] In other words, the velocity of the constituent waves of the wave packet travel at a rate that varies with their wavelength, so some move faster than others, and they cannot maintain the same interference pattern as the wave propagates.		Mathematically, the most basic wave is the (spatially) one-dimensional sine wave (or harmonic wave or sinusoid) with an amplitude u {\displaystyle u} described by the equation:		where		The units of the amplitude depend on the type of wave. Transverse mechanical waves (e.g., a wave on a string) have an amplitude expressed as a distance (e.g., meters), longitudinal mechanical waves (e.g., sound waves) use units of pressure (e.g., pascals), and electromagnetic waves (a form of transverse vacuum wave) express the amplitude in terms of its electric field (e.g., volts/meter).		The wavelength λ {\displaystyle \lambda } is the distance between two sequential crests or troughs (or other equivalent points), generally is measured in meters. A wavenumber k {\displaystyle k} , the spatial frequency of the wave in radians per unit distance (typically per meter), can be associated with the wavelength by the relation		The period T {\displaystyle T} is the time for one complete cycle of an oscillation of a wave. The frequency f {\displaystyle f} is the number of periods per unit time (per second) and is typically measured in hertz denoted as Hz. These are related by:		In other words, the frequency and period of a wave are reciprocals.		The angular frequency ω {\displaystyle \omega } represents the frequency in radians per second. It is related to the frequency or period by		The wavelength λ {\displaystyle \lambda } of a sinusoidal waveform traveling at constant speed v {\displaystyle v} is given by:[17]		where v {\displaystyle v} is called the phase speed (magnitude of the phase velocity) of the wave and f {\displaystyle f} is the wave's frequency.		Wavelength can be a useful concept even if the wave is not periodic in space. For example, in an ocean wave approaching shore, the incoming wave undulates with a varying local wavelength that depends in part on the depth of the sea floor compared to the wave height. The analysis of the wave can be based upon comparison of the local wavelength with the local water depth.[18]		Although arbitrary wave shapes will propagate unchanged in lossless linear time-invariant systems, in the presence of dispersion the sine wave is the unique shape that will propagate unchanged but for phase and amplitude, making it easy to analyze.[19] Due to the Kramers–Kronig relations, a linear medium with dispersion also exhibits loss, so the sine wave propagating in a dispersive medium is attenuated in certain frequency ranges that depend upon the medium.[20] The sine function is periodic, so the sine wave or sinusoid has a wavelength in space and a period in time.[21][22]		The sinusoid is defined for all times and distances, whereas in physical situations we usually deal with waves that exist for a limited span in space and duration in time. Fortunately, an arbitrary wave shape can be decomposed into an infinite set of sinusoidal waves by the use of Fourier analysis. As a result, the simple case of a single sinusoidal wave can be applied to more general cases.[23][24] In particular, many media are linear, or nearly so, so the calculation of arbitrary wave behavior can be found by adding up responses to individual sinusoidal waves using the superposition principle to find the solution for a general waveform.[25] When a medium is nonlinear, the response to complex waves cannot be determined from a sine-wave decomposition.		A standing wave, also known as a stationary wave, is a wave that remains in a constant position. This phenomenon can occur because the medium is moving in the opposite direction to the wave, or it can arise in a stationary medium as a result of interference between two waves traveling in opposite directions.		The sum of two counter-propagating waves (of equal amplitude and frequency) creates a standing wave. Standing waves commonly arise when a boundary blocks further propagation of the wave, thus causing wave reflection, and therefore introducing a counter-propagating wave. For example, when a violin string is displaced, transverse waves propagate out to where the string is held in place at the bridge and the nut, where the waves are reflected back. At the bridge and nut, the two opposed waves are in antiphase and cancel each other, producing a node. Halfway between two nodes there is an antinode, where the two counter-propagating waves enhance each other maximally. There is no net propagation of energy over time.		One-dimensional standing waves; the fundamental mode and the first 5 overtones.		A two-dimensional standing wave on a disk; this is the fundamental mode.		A standing wave on a disk with two nodal lines crossing at the center; this is an overtone.		Waves exhibit common behaviors under a number of standard situations, e. g.		Waves normally move in a straight line (i.e. rectilinearly) through a transmission medium. Such media can be classified into one or more of the following categories:		Absorption of waves means, if a kind of wave strikes a matter, it will be absorbed by the matter. When a wave with that same natural frequency impinges upon an atom, then the electrons of that atom will be set into vibrational motion. If a wave of a given frequency strikes a material with electrons having the same vibrational frequencies, then those electrons will absorb the energy of the wave and transform it into vibrational motion.		When a wave strikes a reflective surface, it changes direction, such that the angle made by the incident wave and line normal to the surface equals the angle made by the reflected wave and the same normal line.		Waves that encounter each other combine through superposition to create a new wave called an interference pattern. Important interference patterns occur for waves that are in phase.		Refraction is the phenomenon of a wave changing its speed. Mathematically, this means that the size of the phase velocity changes. Typically, refraction occurs when a wave passes from one medium into another. The amount by which a wave is refracted by a material is given by the refractive index of the material. The directions of incidence and refraction are related to the refractive indices of the two materials by Snell's law.		A wave exhibits diffraction when it encounters an obstacle that bends the wave or when it spreads after emerging from an opening. Diffraction effects are more pronounced when the size of the obstacle or opening is comparable to the wavelength of the wave.		The phenomenon of polarization arises when wave motion can occur simultaneously in two orthogonal directions. Transverse waves can be polarized, for instance. When polarization is used as a descriptor without qualification, it usually refers to the special, simple case of linear polarization. A transverse wave is linearly polarized if it oscillates in only one direction or plane. In the case of linear polarization. it is often useful to add the relative orientation of that plane, perpendicular to the direction of travel, in which the oscillation occurs, such as "horizontal" for instance, if the plane of polarization is parallel to the ground. Electromagnetic waves propagating in free space, for instance, are transverse; they can be polarized by the use of a polarizing filter.		Longitudinal waves, such as sound waves, do not exhibit polarization. For these waves there is only one direction of oscillation, that is, along the direction of travel.		A wave undergoes dispersion when either the phase velocity or the group velocity depends on the wave frequency. Dispersion is most easily seen by letting white light pass through a prism, the result of which is to produce the spectrum of colours of the rainbow. Isaac Newton performed experiments with light and prisms, presenting his findings in the Opticks (1704) that white light consists of several colours and that these colours cannot be decomposed any further.[26]		The speed of a transverse wave traveling along a vibrating string ( v ) is directly proportional to the square root of the tension of the string ( T ) over the linear mass density ( μ ):		where the linear density μ is the mass per unit length of the string.		Acoustic or sound waves travel at speed given by		or the square root of the adiabatic bulk modulus divided by the ambient fluid density (see speed of sound).		An electromagnetic wave consists of two waves that are oscillations of the electric and magnetic fields. An electromagnetic wave travels in a direction that is at right angles to the oscillation direction of both fields. In the 19th century, James Clerk Maxwell showed that, in vacuum, the electric and magnetic fields satisfy the wave equation both with speed equal to that of the speed of light. From this emerged the idea that light is an electromagnetic wave. Electromagnetic waves can have different frequencies (and thus wavelengths), giving rise to various types of radiation such as radio waves, microwaves, infrared, visible light, ultraviolet, X-rays, and Gamma rays.		The Schrödinger equation describes the wave-like behavior of particles in quantum mechanics. Solutions of this equation are wave functions which can be used to describe the probability density of a particle.		The Dirac equation is a relativistic wave equation detailing electromagnetic interactions. Dirac waves accounted for the fine details of the hydrogen spectrum in a completely rigorous way. The wave equation also implied the existence of a new form of matter, antimatter, previously unsuspected and unobserved and which was experimentally confirmed. In the context of quantum field theory, the Dirac equation is reinterpreted to describe quantum fields corresponding to spin-½ particles.		Louis de Broglie postulated that all particles with momentum have a wavelength		where h is Planck's constant, and p is the magnitude of the momentum of the particle. This hypothesis was at the basis of quantum mechanics. Nowadays, this wavelength is called the de Broglie wavelength. For example, the electrons in a CRT display have a de Broglie wavelength of about 10−13 m.		A wave representing such a particle traveling in the k-direction is expressed by the wave function as follows:		where the wavelength is determined by the wave vector k as:		and the momentum by:		However, a wave like this with definite wavelength is not localized in space, and so cannot represent a particle localized in space. To localize a particle, de Broglie proposed a superposition of different wavelengths ranging around a central value in a wave packet,[29] a waveform often used in quantum mechanics to describe the wave function of a particle. In a wave packet, the wavelength of the particle is not precise, and the local wavelength deviates on either side of the main wavelength value.		In representing the wave function of a localized particle, the wave packet is often taken to have a Gaussian shape and is called a Gaussian wave packet.[30] Gaussian wave packets also are used to analyze water waves.[31]		For example, a Gaussian wavefunction ψ might take the form:[32]		at some initial time t = 0, where the central wavelength is related to the central wave vector k0 as λ0 = 2π / k0. It is well known from the theory of Fourier analysis,[33] or from the Heisenberg uncertainty principle (in the case of quantum mechanics) that a narrow range of wavelengths is necessary to produce a localized wave packet, and the more localized the envelope, the larger the spread in required wavelengths. The Fourier transform of a Gaussian is itself a Gaussian.[34] Given the Gaussian:		the Fourier transform is:		The Gaussian in space therefore is made up of waves:		that is, a number of waves of wavelengths λ such that kλ = 2 π.		The parameter σ decides the spatial spread of the Gaussian along the x-axis, while the Fourier transform shows a spread in wave vector k determined by 1/σ. That is, the smaller the extent in space, the larger the extent in k, and hence in λ = 2π/k.		Gravity waves are waves generated in a fluid medium or at the interface between two media when the force of gravity or buoyancy tries to restore equilibrium. A ripple on a pond is one example.		Gravitational waves also travel through space. The first observation of gravitational waves was announced on 11 February 2016.[35] Gravitational waves are disturbances in the curvature of spacetime, predicted by Einstein's theory of general relativity.		In a nonuniform medium, in which the wavenumber k can depend on the location as well as the frequency, the phase term kx is typically replaced by the integral of k(x)dx, according to the WKB method. Such nonuniform traveling waves are common in many physical problems, including the mechanics of the cochlea and waves on hanging ropes.		
A strand plain or strandplain is a broad belt of sand along a shoreline with a surface exhibiting well-defined parallel or semi-parallel sand ridges separated by shallow swales. A strand plain differs from a barrier island in that it lacks either the lagoons or tidal marshes that separate a barrier island from the shoreline to which the strand plain is directly attached. Also, the tidal channels and inlets which cut through barrier islands are absent. Strand plains typically are created by the redistribution by waves and longshore currents of coarse sediment on either side of a river mouth. Thus, they are part of one type of wave-dominated delta.[1][2]		Examples of strand plains:				
A developing country, also called a less developed country or an underdeveloped country, is a nation or a sovereign state with a less developed industrial base and a low Human Development Index (HDI) relative to other countries.[1] There are no universally agreed-upon criteria for what makes a country developing versus developed and which countries fit these two categories,[2] although there are general reference points such as a nation's GDP per capita compared with other nations. Also the general term less-developed country should not be confused with the specific least developed country. The term "developing" describes a currently observed situation and not a dynamic or expected direction of progress. Since the late 1990s developing countries tended to demonstrate higher growth rates than the developed ones.[3]		There is criticism for using the term developing country. The term implies inferiority of a developing country or undeveloped country compared with a developed country, which many countries dislike. It assumes a desire to develop along the traditional Western model of economic development which a few countries, such as Cuba and Bhutan, choose not to follow.[4] An alternative measurement that has been suggested is that of gross national happiness. Countries on the boundary between developed and developing are often categorized under the term newly industrialized countries.[5][6][7][8]		According to authors such as Walt Whitman Rostow developing countries are in transition from traditional lifestyles towards the modern lifestyle which began in the Industrial Revolution in the 18th and 19th centuries.		In the 2016 edition of its World Development Indicators, the World Bank made a decision to no longer distinguish between “developed” and “developing” countries in the presentation of its data. Nobody has ever agreed on a definition for these terms in the first place.[9]						Various terms are used for whatever is not a developed country. Terms used include less developed country or less economically developed country, and for the more extreme, least developed country or least economically developed country.		Criteria for what is not a developed country can be obtained by inverting the factors that define a developed country:		Kofi Annan, former Secretary General of the United Nations, defined a developed country as "one that allows all its citizens to enjoy a free and healthy life in a safe environment."[10] But according to the United Nations Statistics Division,		The UN also notes,		On the other hand according to the classification from International Monetary Fund (IMF) before April 2004, all countries of Central and Eastern Europe (including Central European countries that still belongs to the "Eastern Europe Group" in the UN institutions) as well as the former Soviet Union (USSR) countries in Central Asia (Kazakhstan, Uzbekistan, Kyrgyzstan, Tajikistan and Turkmenistan) and Mongolia, were not included under either developed or developing regions, but rather were referred to as "countries in transition". They are however widely regarded (in the international reports) as "developing countries".		The IMF uses a flexible classification system that considers "(1) per capita income level, (2) export diversification—so oil exporters that have high per capita GDP would not make the advanced classification because around 70% of its exports are oil, and (3) degree of integration into the global financial system."[12]		The World Bank classifies countries into four income groups. These are set each year on July 1. Economies were divided according to 2016 GNI per capita using the following ranges of income:[13]		Since 2016 the World Bank no longer divide countries into two groups according to the out-dated concept of developed and developing [13]		Along with the current level of development, countries may be classified by how much this has changed over some amount of time.[14] This may be by absolute numbers or country ranking.		The development of a country is measured with statistical indexes such as income per capita (per person) ,(gross domestic product) per capita, life expectancy, the rate of literacy, freedom index and others. The UN has developed the Human Development Index (HDI), a compound indicator of some above statistics, to gauge the level of human development for countries where data is available. The UN sets Millennium Development Goals (MDGs) from a blueprint developed by all of the world's countries and leading development institutions, in order to evaluate growth.[15]		Developing countries are, in general, countries that have not achieved a significant degree of industrialization relative to their populations, and have, in most cases, a medium to low standard of living. There is a strong association between low income and high population growth.		The terms utilized when discussing developing countries refer to the intent and to the constructs of those who utilize these terms. Other terms sometimes used are less developed countries (LDCs), least economically developed countries (LEDCs), "underdeveloped nations" or Third World nations, and "non-industrialized nations". Conversely, developed countries, most economically developed countries (MEDCs), First World nations and "industrialized nations" are the opposite end of the spectrum.		To moderate the euphemistic aspect of the word developing, international organizations have started to use the term less economically developed country (LEDCs) for the poorest nations—which can, in no sense, be regarded as developing. That is, LEDCs are the poorest subset of LDCs. This may moderate against a belief that the standard of living across the entire developing world is the same.		The concept of the developing nation is found, under one term or another, in numerous theoretical systems having diverse orientations — for example, theories of decolonization, liberation theology, Marxism, anti-imperialism, and political economy.		Another important indicator is the sectoral changes that have occurred since the stage of development of the country. On an average, countries with a 50% contribution from the Secondary sector of Manufacturing have grown substantially. Similarly countries with a tertiary Sector stronghold also see greater rate of Economic Development.		Some researchers in development economics, such as Theodore Schultz who won a Nobel Prize in 1979, have found that literate farmers in developing countries are more productive than illiterate farmers. They therefore recommend investing in human capital (education, health, etc.) as an effective tool for economic development. Others, such as Mohammed Tamim, believe that economic development is measurable in educational level from primary school to the university. They noticed that wherever the educational level is raised, the level of development is also raised. They conclude that the percentage of the schooled population is proportional to the economic growth rate and inversely proportional in the demographic growth rate. The Take-Off of Walt Whitman Rostow can start in a country if its population is completely schooled. It is therefore necessary for the organization of a worldwide education program, itself conditioned by another worldwide program of birth control and the establishment of a worldwide organization for the implementation of this development strategy.[16]		There are several terms used to classify countries into rough levels of development. Classification of any given country differs across sources, and sometimes these classifications or the specific terminology used is considered disparaging. Use of the term "market" instead of "country" usually indicates specific focus on the characteristics of the countries' capital markets as opposed to the overall economy.		Developing countries can also be categorized by geography:		Other classifications include:		There is some criticism of the use of the term "developing country". The term implies inferiority of a "developing country" or "undeveloped country" compared with a "developed country", which many countries dislike. It is criticized for being too positive and too negative.		It assumes a desire to "develop" along the traditional Western model of economic development, which a few countries, such as Cuba and Bhutan, choose not to follow.[4]		The concept of "development" rests on the assumption that Modernization theory holds. Modernization theory, as the dominant development theory of the late 19th and 20th centuries, has largely contributed to the definition of "development". In short, it argues that there is only one way to achieve "modernity" and "development" - that of "Western" nation-states. Largely challenged today, modernization theory still holds an important role in defining "development".		The term "developing" implies mobility and does not acknowledge that development may be in decline or static in some countries, particularly in southern African states worst affected by HIV/AIDS. In such cases, the term "developing country" may be considered a euphemism. The term implies homogeneity between such countries, which vary widely. The term also implies homogeneity within such countries when wealth (and health) of the most and least affluent groups varies widely. Similarly, the term "developed country" incorrectly implies a lack of continuing economic development/growth in more-developed countries.		In general, development entails a modern infrastructure (both physical and institutional), and a move away from low value added sectors such as agriculture and natural resource extraction. Developed countries, in comparison, usually have economic systems based on continuous, self-sustaining economic growth in the tertiary sector of the economy and quaternary sector of the economy and high material standards of living. However, there are notable exceptions, as some countries considered developed have a significant component of primary industries in their national economies, e.g., Norway, Canada, Australia. The USA and Western Europe have a very important agricultural sector, and are major players in international agricultural markets. Also, natural resource extraction can be a very profitable industry (high value added), e.g., oil extraction.		An alternative measurement that has been suggested is that of gross national happiness, measuring the actual satisfaction of people as opposed to how fiscally wealthy a country is.		During the late 20th century, and with the advance of World-systems theory, the notions of "developed country" and "developing country" have started to slowly be replaced by the less-controversial, trade-based, notions of "core country", "semi-periphery country" and "periphery country". The terms of "developing countries" and "developed countries", although obsolete, still continue to be dominant, as part of the official narrative.		The following are considered developing economies according to the International Monetary Fund's World Economic Outlook Report, April 2015.[31][32]		Countries not listed by IMF		The following, including the Four Asian Tigers and new Eurozone European countries, were considered developing countries until the '90s, and are now listed as advanced economies by the IMF. Time in brackets is the time to be listed as advanced economies.		Three economies lack data before being listed as advanced economies. Because of the lack of data, it is difficult to judge whether they are advanced economies or developing economies before being listed as advanced economies.		
Geologically, a fjord or fiord (English: /ˈfjɔːrd/ ( listen) or /fiˈɔːrd/ ( listen))[1] is a long, narrow inlet with steep sides or cliffs, created by glacial erosion.[clarification needed] There are many fjords on the coasts of Alaska, British Columbia, Chile, Greenland, Iceland, the Kerguelen Islands, New Zealand, Norway, Novaya Zemlya, Labrador, Nunavut, Newfoundland, Scotland, and Washington state.[2] Norway's coastline is estimated at 29,000 kilometres (18,000 mi) with 1,190 fjords, but only 2,500 kilometres (1,600 mi) when fjords are excluded.[3]						A fjord is formed when a glacier cuts a U-shaped valley by ice segregation and abrasion of the surrounding bedrock.[4] Glacial melting is accompanied by the rebounding of Earth's crust as the ice load and eroded sediment is removed (also called isostasy or glacial rebound). In some cases this rebound is faster than sea level rise. Most fjords are deeper than the adjacent sea; Sognefjord, Norway, reaches as much as 1,300 m (4,265 ft) below sea level. Fjords generally have a sill or shoal (bedrock) at their mouth caused by the previous glacier's reduced erosion rate and terminal moraine.[5] In many cases this sill causes extreme currents and large saltwater rapids (see skookumchuck). Saltstraumen in Norway is often described as the world's strongest tidal current. These characteristics distinguish fjords from rias (e.g. the Bay of Kotor), which are drowned valleys flooded by the rising sea. Drammensfjorden is cut almost in two by the Svelvik "ridge", a sandy moraine that during the ice cover was under sea level but after the post-glacial rebound reaches 60 meters above the fjord.[6]		During the winter season there is usually little inflow of freshwater. Surface water and deeper water (down to 100 meters or more) are mixed during winter because of the steady cooling of the surface and wind. In the deep fjords there is still fresh water from the summer with less density than the saltier water along the coast. Offshore wind, common in the fjord areas during winter, sets up a current on the surface from the inner to the outer parts. This current on the surface in turn pulls dense salt water from the coast across the fjord threshold and into the deepest parts of the fjord.[7]		During the summer season there is usually a large inflow of river water in the inner areas. This freshwater gets mixed with saltwater creating a layer of brackish water with a slightly higher surface than the ocean which in turn sets up a current from the river mouths towards the ocean. This current is gradually more salty towards the coast and right under the surface current there is a reverse current of saltier water from the coast. In the deeper parts of the fjord the cold water remaining from winter is still and separated from the atmosphere by the brackish top layer. Fjords with a shallow threshold this deep water is not replaced every year and low oxygen concentration makes the deep water unsuitable for fish and animals. In the most extreme cases there is a constant barrier of freshwater on the surface and the fjord freezes over such that there is no oxygen below the surface. Drammensfjorden is one example.[7]		Gaupnefjorden branch of Sognefjorden is strongly affected by freshwater as glacial river flow in. Velfjorden has little inflow of freshwater.[8]		As late as 2000, some coral reefs were discovered along the bottoms of the Norwegian fjords.[9] These reefs were found in fjords from the north of Norway to the south. The marine life on the reefs is believed to be one of the most important reasons why the Norwegian coastline is such a generous fishing ground. Since this discovery is fairly new, little research has been done. The reefs are host to thousands of lifeforms such as plankton, coral, anemones, fish, several species of shark, and many more. Most are specially adapted to life under the greater pressure of the water column above it, and the total darkness of the deep sea.[10]		New Zealand's fjords are also host to deep-water corals, but a surface layer of dark fresh water allows these corals to grow in much shallower water than usual. An underwater observatory in Milford Sound allows tourists to view them without diving.[11]		In some places near the seaward margins of areas with fjords, the ice-scoured channels are so numerous and varied in direction that the rocky coast is divided into thousands of island blocks, some large and mountainous while others are merely rocky points or rock reefs, menacing navigation. These are called skerries.[10] The term skerry is derived from the Old Norse sker, which means a rock in the sea.[12]		Skerries most commonly formed at the outlet of fjords where submerged glacially formed valleys perpendicular to the coast join with other cross valleys in a complex array. The island fringe of Norway is such a group of skerries (called a skjærgård); many of the cross fjords are so arranged that they parallel the coast and provide a protected channel behind an almost unbroken succession of mountainous islands and skerries. By this channel one can travel through a protected passage almost the entire 1,601 km (995 mi) route from Stavanger to North Cape, Norway. The Blindleia is a skerry-protected waterway that starts near Kristiansand in southern Norway, and continues past Lillesand. The Swedish coast along Bohuslän is likewise skerry guarded. The Inside Passage provides a similar route from Seattle, Washington, and Vancouver, British Columbia, to Skagway, Alaska. Yet another such skerry protected passage extends from the Straits of Magellan north for 800 km (500 mi).		An epishelf lake forms when meltwater is trapped behind a floating ice shelf and the freshwater floats on the denser saltwater below. Its surface may freeze forming an isolated ecosystem.		The word fjord comes from Norwegian (pronounced [ˈfjuːr], [ˈfjøːr], [ˈfjuːɽ] or [ˈfjøːɽ] in various dialects), where it can have a more general meaning: in many cases to refer to any long narrow body of water, inlet or channel (for example, see Oslofjord).		The Norse verb ferd (travelling/ferrying), the Norse noun substantive fjǫrðr means a "lake-like" waterbody used for passage and ferrying, which is of Indo-European origin (*prtús from *por- or *per).[13]		The Scandinavian fjord, Proto-Scandinavian *ferþuz, is the origin for similar Germanic words: Icelandic fjörður, Swedish fjärd (for Baltic waterbodies), Scots firth.[13] The Norse noun fjǫrðr was adopted in German as Förde, used for the narrow long bays of Schleswig-Holstein, and in English as firth "fjord, river mouth". The English word ford (cf. German Furt, Low German Ford or Vörde, in Dutch names voorde, cf. Vilvoorde, Greek poros, and Latin portus) is assumed to originate from Germanic *ferþu- and indo-European root *pertu- meaning "crossing point". Fjord/firth/Förde as well as ford/Furt/Vörde/voorde refer to a Germanic noun for a travel: North Germanic ferd or färd and of the verb to travel, Dutch varen, German fahren; English to fare.[14]		As a loanword from Norwegian, it is one of the few words in the English language to start with the sequence fj.[15] The word was for a long time normally rendered fiord,[16] a spelling preserved in place names such as Grise Fiord, but now generally current only in New Zealand English.		The use of the word fjord in Norwegian, Danish and Swedish is more general than in English and in international scientific terminology. In Scandinavia, fjord is used for a narrow inlet of the sea in Norway, Denmark and western Sweden, but this is not its only application. In Norway and Iceland, the usage is closest to the Old Norse, with fjord used for both a firth and for a long, narrow inlet. In eastern Norway, the term is also applied to long narrow freshwater lakes (for instance Mjøsa [commonly referred to as fjorden], Randsfjorden and Tyrifjorden) and sometimes even to rivers (in local usage, for instance in Flå in Hallingdal, the Hallingdal river is referred to as fjorden). In east Sweden, the name fjärd is used in a synonymous manner for bays, bights and narrow inlets on the Swedish Baltic Sea coast, and in most Swedish lakes. This latter term is also used for bodies of water off the coast of Finland where Finland Swedish is spoken. In Danish, the word may even apply to shallow lagoons. In modern Icelandic, fjörður is still used with the broader meaning of firth or inlet. In Faroese fjørður is used both about inlets and about broader sounds, whereas a narrower sound is called sund. In the Finnish language, a word vuono is used although there is only one fjord in Finland. Small waterfalls within these fjords are also used as freshwater resources for the people of Scandinavia and, in particular, Norway.		The German use of the word Förde for long narrow bays on their Baltic Sea coastline, indicates a common Germanic origin of the word. The landscape consists mainly of moraine heaps. The "Förden" and some "fjords" on the east side of Jutland, Denmark are also of glacial origin. But while the glaciers digging "real" fjords moved from the mountains to the sea, in Denmark and Germany they were tongues of a huge glacier covering the basin of which is now the Baltic Sea. See Förden and East Jutland Fjorde.		Whereas fjord names mostly describe bays (though not always geological fjords), straits in the same regions typically are named Sund, in Scandinavian languages as well as in German. The word is related to "to sunder" in the meaning of "to separate". So the use of Sound to name fjords in North America and New Zealand differs from the European meaning of that word.		The name of Wexford in Ireland is originally derived from Veisafjǫrðr ("inlet of the mud flats") in Old Norse, as used by the Viking settlers—though the inlet at that place in modern terms is an estuary, not a fjord.		Before or in the early phase of Old Norse "angr" was another common noun for fjords and other inlets of the ocean. This word has survived only as a suffix in names of some Scandinavian fjords and has in same cases also been transferred to adjacent settlements or surrounding areas for instance Hardanger, Stavanger and Geiranger.[17][18]		The differences in usage between the English and the Scandinavian languages have contributed to confusion in the use of the term fjord. Bodies of water that are clearly fjords in Scandinavian languages are not considered fjords in English; similarly bodies of water that would clearly not be fjords in the Scandinavian sense have been named or suggested to be fjords. Examples of this confused usage follow.		The Bay of Kotor in Montenegro has been suggested by some to be a fjord, but is in fact a drowned river canyon or ria. Similarly the Lim bay in Istria, Croatia, is sometimes called "Lim fjord" although it was not carved by glacial erosion but instead is a ria dug by the river Pazinčica. The Croats call it Limski kanal, which does not translate precisely to the English equivalent either.		In the Danish language any inlet is called a fjord, but none of the fjords of Denmark may be considered a fjord in the geological sense. Limfjord in English terminology is a sound, since it separates the North Jutlandic Island (Vendsyssel-Thy) from the rest of Jutland. Ringkøbing Fjord on the western coast of Jutland is a lagoon. The long narrow fjords of Denmark's Baltic Sea coast like the German Förden were dug by ice moving from the sea upon land, while fjords in the geological sense were dug by ice moving from the mountains down to the sea.		The fjords in Finnmark (Norway), which are fjords in the Scandinavian sense of the term, are not universally considered to be fjords by the scientific community.[19] Although glacially formed, most Finnmark fjords lack the steep-sided valleys of the more southerly Norwegian fjords since the glacial pack was deep enough to cover even the high grounds when they were formed. The Oslofjord on the other hand is a rift valley, and not glacially formed.		In Acapulco, Mexico, the calanques—narrow, rocky inlets—on the western side of the city, where the famous cliff-divers perform daily, are described in the city's tourist literature as being fjords.		Some Norwegian freshwater lakes that have formed in long glacially carved valleys with terminal moraines blocking the outlet follow the Norwegian naming convention; they are named fjords. Such moraines blocking the outlet form isthmuses between the lake and the saltwater fjord, in Norwegian called "eid" as in placename Eidfjord or Nordfjordeid.[20] Eidfjord village sits on the moraine forming an eid between Eidfjordvatnet lake and Eidfjorden branch of Hardangerfjord.[21] Nordfjordeid is the isthmus with a village between Hornindalsvatnet lake and Nordfjord.[22][23]		One of Norway's largest is Tyrifjorden at 63 meters above sea level and an average depth at 97 meters most of the lake is under sea level. Norway's largest lake, Mjøsa, is also referred to as "the fjord" by locals.[20] Another example is the freshwater fjord Movatnet (Mo lake) that until 1743 was separated from Romarheimsfjorden by an isthmus and connected by a short river. During a flood in November 1743 the river bed eroded and sea water could flow into the lake at high tide. Eventually Movatnet became a saltwater fjord and renamed Mofjorden (Mofjorden[no]).[24] Like fjords, freshwater lakes are often deep. For instance Hornindalsvatnet is at least 500 meters deep and water takes an average of 16 years to flow through the lake.[25] Such lakes created by glacial action are also called fjord lakes or moraine-dammed lakes.[26]		Some of these lakes were salt after the ice age but later cut off from the ocean during the post-glacial rebound.[8] At the end of the ice age Eastern Norway was about 200 meters lower (the marine limit). When the ice cap receded and allowed the ocean to fill valleys and lowlands, and lakes like Mjøsa and Tyrifjorden were part of the ocean while Drammen valley was a narrow fjord. At the time of the Vikings Drammensfjord was still 4 or 5 meters higher than today and reached the town of Hokksund, while parts of what is now the city of Drammen was under water.[27] After the ice age the ocean was about 150 meter at Notodden. The ocean stretched like a fjord through Heddalsvatnet all the way to Hjartdal. Post-glacial rebound eventually separated Heddalsvatnet from the ocean and turned it into a freshwater lake.[28][29] In neolithic times Heddalsvatnet was still a saltwater fjord connected to the ocean, and was cut off from the ocean around 1500 BC.[30]		Some salt water fish got trapped in lakes that originally were part of the salt fjord and gradually became freshwater fish such as the arctic char.[31] Some freshwater fjords such as Slidrefjord are above the marine limit.		Outside of Norway, the three western arms of New Zealand's Lake Te Anau are named North Fiord, Middle Fiord and South Fiord. Another freshwater "fjord" in a larger lake is Western Brook Pond, in Newfoundland's Gros Morne National Park; it is also often described as a fjord, but is actually a freshwater lake cut off from the sea, so is not a fjord in the English sense of the term. Locally they refer to it as a "landlocked fjord". Such lakes are sometimes called "fjord lakes". Okanagan Lake was the first North American lake to be so described, in 1962.[32] The bedrock there has been eroded up to 650 m (2,133 ft) below sea level, which is 2,000 m (6,562 ft) below the surrounding regional topography.[33] Fjord lakes are common on the inland lea of the Coast Mountains and Cascade Range; notable ones include Lake Chelan, Seton Lake, Chilko Lake, and Atlin Lake. Kootenay Lake, Slocan Lake and others in the basin of the Columbia River are also fjord-like in nature, and created by glaciation in the same way. Along the British Columbia Coast, a notable fjord-lake is Owikeno Lake, which is a freshwater extension of Rivers Inlet. Quesnel Lake, located in central British Columbia, is claimed to be the deepest fjord formed lake on Earth.		A unique family of freshwater fjords are the embayments of the North American Great Lakes. Baie Fine is located on the northwestern coast of Georgian Bay of Lake Huron in Ontario, and Huron Bay is located on the southern shore of Lake Superior in Michigan.		The principal mountainous regions where fjords have formed are in the higher middle latitudes and the high latitudes reaching to 80°N (Svalbard, Greenland), where, during the glacial period, many valley glaciers descended to the then-lower sea level. The fjords develop best in mountain ranges against which the prevailing westerly marine winds are orographically lifted over the mountainous regions, resulting in abundant snowfall to feed the glaciers. Hence coasts having the most pronounced fjords include the west coast of Norway, the west coast of North America from Puget Sound to Alaska, the southwest coast of New Zealand, and the west and to south-western coasts of South America, for example in Chile.		Other regions have fjords, but many of these are less pronounced due to more limited exposure to westerly winds and less pronounced relief. Areas include:		The longest fjords in the world are:		Deep fjords include:		
In biology, a pathogen (Greek: πάθος pathos "suffering, passion" and -γενής -genēs "producer of") in the oldest and broadest sense is anything that can produce disease; the term came into use in the 1880s.[1][2] Typically the term is used to describe an infectious agent such as a virus, bacterium, protozoa, prion, a fungus, or other micro-organism.[3][4]		There are several substrates including pathways where the pathogens can invade a host. The principal pathways have different episodic time frames, but soil contamination has the longest or most persistent potential for harboring a pathogen. Diseases caused by organisms in humans are known as pathogenic diseases.						Pathogenicity is the potential disease-causing capacity of pathogens. Pathogenicity is related to virulence in meaning, but some authorities have come to distinguish it as a qualitative term, whereas the latter is quantitative. By this standard, an organism may be said to be pathogenic or non-pathogenic in a particular context, but not "more pathogenic" than another. Such comparisons are described instead in terms of relative virulence. Pathogenicity is also distinct from the transmissibility of the virus, which quantifies the risk of infection.[5]		A pathogen may be described in terms of its ability to produce toxins, enter tissue, colonize, hijack nutrients, and its ability to immunosuppress the host.		It is common to speak of an entire species of bacteria as pathogenic when it is identified as the cause of a disease (cf. Koch's postulates). However, the modern view is that pathogenicity depends on the microbial ecosystem as a whole. A bacterium may participate in opportunistic infections in immunocompromised hosts, acquire virulence factors by plasmid infection, become transferred to a different site within the host, or respond to changes in the overall numbers of other bacteria present. For example, infection of mesenteric lymph glands of mice with Yersinia can clear the way for continuing infection of these sites by Lactobacillus, possibly by a mechanism of "immunological scarring".[6]		Virulence (the tendency of a pathogen to cause damage to a host's fitness) evolves when that pathogen can spread from a diseased host, despite that host being very debilitated. Horizontal transmission occurs between hosts of the same species, in contrast to vertical transmission, which tends to evolve symbiosis (after a period of high morbidity and mortality in the population) by linking the pathogen's evolutionary success to the evolutionary success of the host organism.		Evolutionary medicine has found that under horizontal transmission, the host population might never develop tolerance to the pathogen.[citation needed]		Transmission of pathogens occurs through many different routes, including airborne, direct or indirect contact, sexual contact, through blood, breast milk, or other body fluids, and through the fecal-oral route.		Although the vast majority of bacteria are harmless or beneficial, a relatively small list of pathogenic bacteria can cause infectious diseases. One of the bacterial diseases with the highest disease burden is tuberculosis, caused by the bacterium Mycobacterium tuberculosis, which kills about 2 million people a year, mostly in sub-Saharan Africa. Pathogenic bacteria contribute to other globally important diseases, such as pneumonia, which can be caused by bacteria such as Streptococcus and Pseudomonas, and foodborne illnesses, which can be caused by bacteria such as Shigella, Campylobacter, and Salmonella. Pathogenic bacteria also cause infections such as tetanus, typhoid fever, diphtheria, syphilis, and leprosy.		Bacteria can often be killed by antibiotics: the cell wall on the outside is destroyed, expelling the DNA out of the body of the pathogen, therefore making the pathogen incapable of producing proteins, or of surviving. Bacteria typically range between 1 and 5 micrometers in length. A class of bacteria without cell walls is mycoplasma (a cause of lung infections). A class of bacteria which must live within other cells (obligate intracellular parasitic) is chlamydia (genus), the world leader in causing sexually transmitted infection (STD).		Some of the diseases that are caused by viral pathogens include smallpox, influenza, mumps, measles, chickenpox, ebola, and rubella.		Pathogenic viruses are diseases mainly of the families of: Adenoviridae, Picornaviridae, Herpesviridae, Hepadnaviridae, Flaviviridae, Retroviridae, Orthomyxoviridae, Paramyxoviridae, Papovaviridae, Polyomavirus, Rhabdoviridae, Togaviridae. Viruses typically range between 20 and 300 nanometers in length.[7]		Fungi comprise a eukaryotic kingdom of microbes that are usually saprophytes (consume dead organisms) but can cause diseases in humans, animals and plants. Fungi are the most common cause of diseases in crops and other plants. The typical fungal spore size is 1-40 micrometers in length.		According to the prion theory, prions are infectious pathogens that do not contain nucleic acids. These abnormally folded proteins are found characteristically in some diseases such as scrapie, bovine spongiform encephalopathy (mad cow disease) and Creutzfeldt–Jakob disease.[8]		Some eukaryotic organisms, such as protists and helminths, cause disease.		Examples of algae acting as a mammalian pathogen are known as well, notably the disease protothecosis. Protothecosis is a disease found in dogs, cats, cattle, and humans caused by a type of green alga known as prototheca that lacks chlorophyll.		Bacteria are usually treated with antibiotics while viruses are treated with antiviral compounds. Eukaryotic pathogens are typically not susceptible to antibiotics and thus need specific drugs. Infection with many pathogens can be prevented by immunization. A small amount of pathogens are used in vaccines to make immunity stay alert and strengthen defense on the insides to prepare for a larger quantity of the virus ever getting inside. Hygiene is critical for the prevention of infection by pathogens.		
Padre Island is the largest of the Texas barrier islands and is the world's longest barrier island. It is part of the U.S. state of Texas. The island is located along Texas' southern coast of the Gulf of Mexico and is noted for its white sandy beaches at the south end. Meaning father in Spanish, it was named after Father José Nicolás Ballí (c.1770-1829), who owned the island and served as a missionary priest and collector of finances for all the churches in the Rio Grande Valley. He also founded the first mission in present-day Cameron County.[1]		Padre Island is the second-largest island by area in the contiguous United States, after Long Island in New York on the Atlantic Coast. It is about 113 miles (182 km) long[2] and 1.8 miles (3 km) wide,[3] stretching from the city of Corpus Christi, in the north, to the resort community of South Padre Island in the south. The island is oriented north-south, bordered by the Gulf of Mexico on the east, and Laguna Madre on the west. The island's northern end connects to Mustang Island by roadway. The southern end of the island is separated from Brazos Island by the Brazos Santiago Pass.		The town of South Padre Island is located on its southern end, but the island as a whole is sparsely populated. The central part of the island is preserved in a natural wild state as Padre Island National Seashore and part of the lower island is protected as part of the Laguna Atascosa National Wildlife Refuge. Since 1964, the island has been divided by the artificial Port Mansfield Channel. The terms "North Padre Island" and "South Padre Island" are often used to refer to the separated portions of the island. Padre Island is included within the jurisdictions of Cameron, Kenedy, Kleberg, Nueces, and Willacy counties in Texas.						The island was used and occupied seasonally by the Karankawa Indians at the time of European encounter. During Spanish rule, Father José Nicolás Ballí (also known as Padre Ballí), owned the island in the 19th century, when it was known as the Isla de Santiago land grant.[1] Padre Island had been granted in 1759 to his Spanish colonist grandfather, Nicolás Ballí, by King Charles III of Spain. The younger Ballí's parents were both Spanish immigrants to Mexico and owned vast amounts of land by royal grants.		José Nicolás Ballí served as a secular priest and missionary; he also managed large amounts of land where he ran a ranching operation. In 1804 he founded the first ethnic Mexican settlement on the island as the town of "El Rancho Santa Cruz de Buena Vista" (later known as Lost City).[1] In 1827 after Mexico achieved independence, Father Ballí requested a clear title to the property of Padre Island.[1] His mother Rosa María Hinojosa de Ballí had made a joint application with him for eleven leagues of the island, but when reapplication was required in 1800, she withdrew her name in favor of him.[4]		After Ballí died in 1829, the government granted title to the island to him posthumously, issued jointly in his name and that of his nephew Juan José Ballí. He had bequeathed half the island to his nephew, who had worked with him on his ranch.[1]		During World War II, United States scientists considered Padre Island as one of eight candidate sites for the first test of an atomic bomb but chose White Sands Missile Range in New Mexico for the detonation.[5]		Geologically speaking, Padre Island is a young island, having formed in just the last several thousand years. It is one of 300 barrier islands stretching from Maine to Mexico. These natural barrier islands act to protect the mainland from the direct onslaught of storms.		Padre Island began forming as a submerged sand bar some 4500 years ago, as shown by radiocarbon dating of shells. Geologic speculation indicates the emerged island may be 1000 to 1500 years younger.[citation needed] Barrier island origins have been debated for many years by geologists, but it is agreed they are formed and modified by such factors as sediment type and supply, sea-level directional changes, current and wave strength and direction, and tide magnitude.		It is theorized that Padre Island formed from offshore shoals, with later growth aided by spit accretion. (A spit is a long, narrow tongue of sand extending from a mainland shoreline and formed by the shoreline drifting of sediments.) After a history of shifting, abandonment and reestablishment by storm breaches, many tidal inlets were slowly closed. Short islands were joined to form today's longer islands.[citation needed]		Padre Island graphically illustrates the life and sequences of a barrier shoreline: accretionary or building phase, equilibrium or stability phase, and erosion or destructional state. The northern half of Padre Island's shoreline is in equilibrium; the southern half (and much of the remaining Texas coastline) is in an erosional stage. Wind, wave and current action continue to rework and shape the island. South Padre Island has been in a destructive phase for a long time, probably having retreated landward (along with the lagoon and mainland shoreline).		All of Padre Island will probably retreat landward through long-term erosion due to three causes: interruption and decrease in sediment supply, relative sea level rise, and tropical storm activity. Today, hurricane washovers and wind-carried sand deposited in the Laguna Madre build Padre Island's landward side at the expense of the Laguna Madre.[citation needed]		On September 2007, Corpus Christi, Texas wildlife officials found a record 128 Kemp's Ridley sea turtle nests on Texas beaches, including 81 in the Padre Island National Seashore and 4 on nearby Mustang Island. Wildlife officials had released 10,594 Kemp's Ridleys hatchlings along the Texas coast in 2007. The turtles are endangered due to getting caught in shrimpers' nets; they are widely hunted in Mexico as popular sources of boot material and food.[6]		Coordinates: 26°50′40″N 97°22′04″W﻿ / ﻿26.84444°N 97.36778°W﻿ / 26.84444; -97.36778		
The Jersey Shore is the coastal region of the state of New Jersey. Geographically, the term encompasses about 141 miles (227 km)[1] of oceanfront from Perth Amboy in the north to Cape May Point in the south. The Jersey Shore area includes Middlesex, Monmouth, Atlantic County, Cape May, and Ocean counties. While there is no defined border between North Jersey and South Jersey, the Raritan River, Manasquan River or I-195 are often mentioned as the border, with most of the shore region being located in South Jersey.[2] Many New Jersey residents refer to it as "The Shore."[3] A common phrase within New Jersey is to go "down the shore", or to have done something "down the shore".		Famous for its many boardwalks with arcades, water parks, and amusement parks boasting hundreds of rides and attractions, the Jersey Shore is a popular vacation spot for New Jerseyans, New Yorkers, and Pennsylvanians, and various other states in the Middle Atlantic portion of the United States. Certain communities are also popular with visitors from the nearby states of Virginia and Maryland.						The Jersey Shore is lined with over 40 communities, each with a different character and flavor. Some cater to summer tourists and visitors, others are completely full-year residential communities, others still are a mix of both. Below are some of the most notable shore points.		There are several "Gateway towns" that are part of the Jersey Shore, and on the way to the main towns. They are also historically part of the Jersey Shore, for several reasons, including the fact that there used to be boardwalks along the Raritan River, and the fact that there are several historical sights in the area, including the Thomas Edison memorial and Menlo Park building in Edison, and several waterfront parks, including one in Metuchen. In Middlesex County, these towns include Woodbridge Township, Metuchen, Carteret, Edison, and New Brunswick.		The two towns that make up The Amboys are Perth Amboy and South Amboy. Perth Amboy's history dates back to 1651 when August Herman bought a point of land from the Lenni Lenape Native Americans. The land, which was called "Ompoge" by the Indians, gradually changed its name to "Emboyle", then "Amboyle". When the city was incorporated in 1683, settlers began to call the land "Ambo" or "Amboy Point", and finally "Amboy." The name means "place resembling a bowl."		In 1686, when the settlement became the capital of East Jersey, Perth was added to the name in honor of one of the Proprietors under the Royal grant, James Drummond, 1st Duke of Perth.		This town mostly caters to year-round residents, and has a beach, a few fishing piers, and a few marinas, therefore making it part of the Jersey Shore.		Keansburg is one of the most tourism-oriented towns along the Raritan Bayshore region, Keansburg is home to the Keansburg Amusement Park and the Runaway Rapids Waterpark. Keansburg is also home to a small boardwalk that runs along the Raritan Bay, sometimes offering views of the New York City skyline.		Keyport, nicknamed the "Pearl of the Bayshore", is located along the coast of the Raritan Bay and is known for its iconic waterfront and fishing pier, traditional downtown and local restaurants and bars. Many boaters utilize Keyport's marinas that give ideal access to fishing, crabbing and watersports.		Atlantic Highlands, which overlooks where the Atlantic Ocean and Raritan Bay meet at Sandy Hook, contains Mount Mitchill, the highest point on the eastern seaboard south of Maine, rising 266 feet (81 m) above sea level.[4]		The New York City skyline can be seen from the borough's ridges and its shoreline. Pleasure, fishing and commuter boats sail from its harbor. The municipal harbor was built from 1938 through 1940 with municipal, state, and federal funds. It is the largest on the East Coast, home to 715 craft, including high-speed ferry service to New York City, which was introduced in 1986.[5] In 1966, the Central Railroad of New Jersey pier was destroyed by fire. Its rail route is now used by the Henry Hudson Trail.[6]		Sandy Hook is a long, narrow peninsula managed by the National Park Service as a unit of the Gateway National Recreation Area. The eastern shoreline consists of various public and fishing beaches, including North Beach and Gunnison Beach. The peninsula's ocean-facing beaches are considered among the finest in New Jersey and are a popular destination for recreation in summer when seasonal ferries[7] bring beachgoers. Gunnison Beach is one of the largest clothing optional beaches on the East Coast.[8][9] The northern end of the island is home to the Sandy Hook Lighthouse, the Marine Academy of Science and Technology, and restored buildings of the former Fort Hancock Coast Guard Station. Spread across the peninsula are former military installations, including four ammunitions bunkers, two gun stations, and a Nike Missile Base.		Sea Bright is bordered by the Navesink and Shrewsbury Rivers on one side and the Atlantic Ocean on the other.[10] The area was first settled in 1840s by a fishing community called "Nauvoo". The origin of the word is Shephardic Hebrew and means "beautiful or pleasant place". Sea bright has several small boutiques, bars, restaurants, and other small stores. In addition, there are seven members-only beach clubs: Ship Ahoy, Surfrider, Sea Bright Beach Club, Chapel Beach Club, Driftwood and Edgewater. There are also two public beaches with free parking and life guards that charge an entrance fee.[11][better source needed] Some of the restaurants include Woody's Ocean Grille Sea Bright, McLoone's Rum Runner, EvenTide Grille, Yumi, and Tommy’s Tavern + Tap.[12] The Sea Bright-Monmouth Beach Seawall has been rebuilt several times.		Red Bank, overlooking the Navesink River, is a noted social and commercial destination, filled with boutiques, designer clothing and home stores, parks, and restaurants. Special events are scheduled throughout the summer, such as the KaBoomFest fireworks on July 3, which attracted as many as 150,000 spectators at its 51st annual event in 2010.[13]		Red Bank consists of an eclectic mix of businesses, including entertainment, retail, professional, medical and hospitality. It offers luxury stores, like Garmany and Tiffany, and trendy clothing stores including Greene Street,[14] Urban Outfitters. Coffee shops include Starbucks and Rook[15] and eateries range from the "Pay It Forward" style, like the Bonjovi Soul Kitchen, to pubs like the Dublin House[16] or vegetarian fare like the Good Karma Cafe.[17] Garmany of Red Bank has been expanded from a men's store into a luxury department store with 40,000 square feet (3,700 m2) of high-end retail space.[18] Store openings have included Tiffany & Co. in November 2007.[19][20]		Boating, sculling, sailing, and fishing are popular outdoor activities in and near Red Bank; in the winter, ice boats sail on the Navesink when it freezes over, as it did in 2009.[21] The Monmouth Boat Club, Marine Park, and the slips of the Molly Pitcher Inn provide access to the Navesink and, from there, Sandy Hook and the Gateway National Recreation Area, the Jersey Shore and the Atlantic Ocean.[22]		In years past, Long Branch was a major destination for beachgoers, along with Asbury Park, and enjoyed an upscale connotation with tourists. Long Branch is home to Seven Presidents Oceanfront Park, named for the United States presidents who visited the fashionable resort town, including Ulysses S. Grant, Chester A. Arthur, Rutherford Hayes, Benjamin Harrison, William McKinley, Woodrow Wilson and James A. Garfield.[23]		Pier Village is a Victorian-inspired, mixed-use community consisting of 536 rental residences sitting atop more than 100,000 square feet (9,300 m2) of retail space. A public grassy area called Festival Plaza is the site of regular events, including concerts, arts & crafts fairs, outdoor movies and holiday events. The first story of Pier Village is filled with shops, restaurants, lounges, a salon, and a gym, while the upper floors are filled with ocean-view Apartments. Long Branch is also home to the original WindMill Hot Dogs restaurant, located in a windmill-shaped building since 1963.[24]		Asbury Park was developed through the 1920s and 1930s as a resort destination for the New York Metro Area, and it remained that way through World War II. The post-war era of the 1950s and 1960s saw the construction of the Garden State Parkway and the Monmouth Mall, taking visitors away from Asbury Park. Race riots on July 4, 1970 resulted in the destruction of various buildings across the city. Since the early 2000s, a burgeoning crowd of artists along with local political leaders have helped push the town through major redevelopment which is still ongoing. Asbury Park has emerged as a prime LGBT destination and still retains its lively music scene which made it famous, with locales such as the Stone Pony, a music bar which is frequented by artists such as Bruce Springsteen and Southside Johnny.		Ocean Grove was originally developed as a religious summer camp meeting site,[25] and is referred to as "God's Square Mile at the Jersey Shore".[26] Listed on the National Register of Historic Places, Ocean Grove is noted for its abundant examples of Victorian architecture. It is home to The Great Auditorium, a 5,500-seat indoor arena constructed in 1894 on bridge-like iron trusses laid on stone foundations. The Auditorium contains a pipe organ that is one of the 25 largest in the world.[27] Surrounding the Auditorium are 114 tents, which are occupied from May to September, just as they have been since 1869. These rustic throwbacks adjoin to rear sheds containing a kitchen and bathroom. The tents are stored in the sheds during the winter. They are in such demand that there is a waiting list of some ten years for summer rentals.[25] Ocean Grove also had the honor of being named one of the top 15 best beaches by Fodor's in 2014.[28]		Belmar is a popular vacation destination due to its natural and recreational resources. Its boardwalk and town offer shops, restaurants, an active arts scene, sporting events, festivals, and a variety of family-oriented activities. Belmar is among the most popular surf spots on the East Coast, frequently hosting surfing events and competitions.		Spring Lake is home to many old homes and tree-lined streets, in contrast to many tourist-oriented towns at the Jersey Shore. During the "Gilded Age" of the late 19th and early 20th centuries, Spring Lake developed into a coastal resort for members of New York City and Philadelphia high society, in similar fashion to the settlements of Newport, Rhode Island and Bar Harbor, Maine.[29] A surviving example of architecture constructed during this era is the Martin Maloney Cottage on Morris Avenue next to the tycoon's former and no longer existent Ballingarry Estate.[30] Another fine example of period architecture listed on the National Register of Historic Places is the Audenried Cottage on Tuttle Avenue.[31]		Manasquan has a downtown area with many small businesses. Algonquin Arts Theatre has shows and movies that play throughout the year. It is a historic 540-seat theatre, built in 1938 as a movie house but converted to a professional live performance space in May 1994.[32][33]		The Manasquan Inlet provides surfers with waves that are corralled, refracted and enlarged by the jetty protruding out into the Atlantic Ocean. The Manasquan Inlet, reopened in 1931, is the northern terminus of the inland portion of the Intracoastal Waterway.[34]		The Point Pleasant boardwalk is approximately one mile long, spanning the coastline from the Manasquan Inlet at the north to New Jersey Avenue in the south. The central third of the boardwalk contains amusement rides, arcades, pizzerias, ice cream parlors, and miniature golf courses. Point Pleasant Beach is also the northern terminus of the East Coast's Intracoastal Waterway. The town is home to Jenkinson's Aquarium, Jenkinson's Boardwalk amusement park, and Jenkinson's Beach. Jenkinson’s Boardwalk has many different attractions, food vendors, and stores. The attractions include a ride park geared towards children. There are also three arcades on the boardwalk: Jenkinson’s South Arcade, Jenkinson’s South Beach Arcade, and Frank’s Fun Center. There are many restaurants ranging from pizza joints, to grills, to ice cream parlors.[35]		Seaside Heights is famous for its amusement-oriented boardwalk and numerous clubs and bars.[36] Casino Pier and Funtown Piers are amusement parks, each situated on a pier extending approximately 300 feet (100 m) into the Atlantic Ocean. Each of the two piers is part of a boardwalk that stretches for 2 miles (3.2 km), which offers many family-friendly attractions from arcades to a wide variety of foods and desserts, all within walking distance. Breakwater Beach is a Water Park situated across the street from Casino Pier. Seaside Heights was boosted into the national spotlight by MTV with shows such as Jersey Shore.		Long Beach Island is a barrier island and collection of several shore communities. Long Beach Island is approximately 18 miles (29 km) in length, which includes three miles (5 km) of nature reserve located on the southern tip.[37] Bisecting the middle of the island is the sole access point for road vehicles, via Route 72, which consists of the Dorland J. Henderson Memorial Bridge (locally known as "The Causeway"). The bridge is known for its "String of Pearls", a row of lights mounted on the railings lining the length of the bridge. This beach is popular spot for people who want to relax in the sun all day and don't particularly like the boardwalk. Most places are in walking distance and there is a downtown area with stores and restaurants.		The region is often split into two parts, with "The Island" referring to LBI, and "The Mainland" referring to the towns on the mainland opposite of the islad, which are also part of the region.		The presence of the bisecting causeway, located in Ship Bottom, results in the division of the island into a northern portion and a southern portion. From the bridge northward, the island includes the communities of Surf City, North Beach, Harvey Cedars, Loveladies (the northernmost section of Long Beach), High Bar Harbor, and Barnegat Light. From the bridge southward, the island includes the communities of Long Beach (including the census-designated place of North Beach Haven) and Beach Haven, with the Holgate section of Long Beach at the southernmost tip of the island. The island is home to attractions such as Barnegat Light, the Fantasy Island amusement park, the Bay Village shopping complex near Bay Village, Bayfront Park in Surf City, one of two Lucille's Candies locations in Brant Beach, as well as the original Ron Jon Surf Shop location.		The mainland includes the towns of Waretown, Barnegat Township, Manahawkin, Beach Haven West, and Tuckerton. Big attractions on the mainland include Albert Music Hall in Waretown, Mud City Crab House in Manahawkin, and Tuckerton Seaport in Tuckerton.		Additionally, when crossing the "causeway", one will see Cedar Bonnet Island, which include the Bonnet Island estate. It has a Manahawkin address.		Brigantine is an island community, the northernmost in Atlantic County. The Brigantine Lighthouse is a central identifying symbol of the city.[38] Brigantine is home to the Marine Mammal Stranding Center, the state's only marine stranding center. The center rehabilitates and releases stranded marine mammals and sea turtles, rescuing more than 3,900 whales, dolphins, seals and sea turtles since it was formed.[39] Part of the Edwin B. Forsythe National Wildlife Refuge is located on the northern end of Brigantine Island.		Atlantic City is a nationally renowned resort city for gambling, shopping and fine dining. The city also served as the inspiration for the board game Monopoly. Atlantic City is considered the "Gambling Capital of the East Coast" and is second to Las Vegas in number of casinos, yearly gaming revenue, and number of rooms. The Atlantic City Skyline has been transformed by construction of new casino hotels and condominia. Atlantic City is also home to numerous shopping malls and districts.		The Atlantic City Boardwalk was one of the first boardwalks of its type in the United States, having opened on June 26, 1870.[40] The Boardwalk starts at Absecon Inlet and runs along the beach for four miles (six kilometers) to the city limit. An additional one and one half miles (two kilometers) of the Boardwalk extend into Ventnor City. Casino/hotels front the boardwalk, as well as retail stores, restaurants, and amusements. Notable attractions include the Boardwalk Hall, the Steel Pier, and the Ripley's Believe It or Not! museum. Home of the Miss America pageant, Atlantic City has been featured in numerous films and television series, most notably the setting of the 1980 film Atlantic City starring Burt Lancaster and Susan Sarandon and the HBO series Boardwalk Empire.		Ocean City is home to a boardwalk with several shops and amusement areas. Known as a family-oriented seaside resort, Ocean City has prohibited the sale of alcoholic beverages within its limits since its founding in 1879. Ocean City has miles of guarded beaches, a 2.5-mile boardwalk, and a downtown shopping and dining district. The Travel Channel rated Ocean City as the Best Family Beach of 2005.[41] It was ranked the third best beach in New Jersey in the 2008 Top 10 Beaches Contest sponsored by the New Jersey Marine Sciences Consortium.[42] In the 2009 Top 10 Beaches Contest, Ocean City ranked first.[43]		The Wildwoods is used as a collective term for the four communities that have "Wildwood" as part of the municipality name — the Borough of Wildwood Crest, City of Wildwood, Borough of West Wildwood and the City of North Wildwood — together with Diamond Beach, a portion of Lower Township situated on the island. Its most notable features are its beach and 1.8 miles (2.9 km) boardwalk, home to the Morey's Piers amusement complex and Raging Waters and Ocean Oasis Waterparks owned by Morey's Piers. The boardwalk features a trolley called the "Tramcar", which runs from end to end.		The Wildwoods is home to over 200 motels, built during the Doo-Wop era of the 1950s and 1960s,[44] in an area recognized by the state of New Jersey, known as the Wildwoods Shore Resort Historic District'[45] The term doo-wop was coined by Cape May's Mid-Atlantic Center For The Arts in the early 1990s to describe the unique, space-age architectural style, which is also referred to as the Googie or populuxe style.[46] The motels are unique in appearance, with Vegas-like neon signs and fantastic architecture.[47]		Cape May is at the southern tip of Cape May Peninsula where the Delaware Bay meets the Atlantic Ocean and is one of the country's oldest vacation resort destinations.[48] With a rich history, award-winning beaches, designation as a top birding location, and many Victorian structures, Cape May is a seaside resort drawing visitors from around the world. The Cape May – Lewes Ferry connects the town to Lewes, Delaware.		The following is a list of all the towns within the state of New Jersey that have a beach either along the Raritan Bay or Atlantic Ocean, listed north to south		Middlesex County		Monmouth County		Ocean County		Atlantic County		Cape May County		The entirety of the Jersey Shore region was significantly affected by Hurricane Sandy in October 2012. The devastating effect of the storm surge on property adjacent to the beach resulted in substantial cost to the reinsurance industry which has since advocated avoidance of rebuilding closely packed middle-class residences or flimsy commercial structures adjacent to the beach. It is felt insuring property in the area may be impossible if a configuration of buildings is constructed which have a high probability of suffering massive damage in future storms. The hurricane reached up to 74 mph. Hurricane Sandy's pure kinetic energy for storm surge and wave destruction potential reached a 5.8 out of 6 on the National Oceanic and Atmospheric Administration's scale. Storm surges reached 14 ft above average low tide. The storm left an estimated 7.5 million people without power. However, many citizens in NJ did not expect the storm to be as bad as it was. Most of the people who were affected by the storm expected it to be like the previous storm, Hurricane Irene. The Barrier Islands were especially damaged, leaving dozens of homes completely washed away. Many iconic places from "The Shore" were also damaged due to Hurricane Sandy, such as: the Belmar boardwalk, Casino Pier and Funtown Pier. The night of the hurricane, families were told to evacuate the Barrier Island and to leave behind their homes, little did they know, some of them would be losing their entire home and even some loved ones. Even though its only been four years since the hurricane hit, many neighborhoods will never be rebuilt .[49]		The Jersey Shore is home to numerous rock and roll clubs, most famously in Asbury Park, where Bruce Springsteen honed his skills at now defunct clubs like The Upstage and the Student Prince. He still makes periodic live appearances at The Stone Pony bar or at Convention Hall as either a solo act, with the E Street Band, or with other artists. Furthermore, Bill Haley and the Comets performed "Rock Around the Clock" for the first time live at the Hoff Brau in Wildwood.[citation needed]		A style of music known as the Jersey Shore sound evolved from this scene. The Bruce Springsteen song "4th of July, Asbury Park (Sandy)" is one of several Springsteen songs that contains references to the Jersey shore scene of the early 1970s.[citation needed]		The Jersey Shore area gained international fame in 2009 after MTV started airing the reality series Jersey Shore. The popular show, filmed mostly in Seaside Heights, debuted amid large amounts of controversy regarding the use of the words "Guido/Guidette", portrayals of Italian-American stereotypes, and scrutiny from locals because the cast members, with the exception of three, are not New Jersey residents.[50][51][52]		MTV also used Seaside Heights as the location of their Summer Beach House in 1998 and again in 2002, and for two episodes of True Life about adults in their 20's and 30's living "down the shore" for the summer.[citation needed] In 1999, the music video "Summer Girls" by LFO was filmed in Seaside Heights.[citation needed] The 1992 Fox TV series Down the Shore, starring Louis Mandylor and Anna Gunn, was set in Belmar.		The 2011 film New Year's Eve was filmed in Seaside Heights.[citation needed]		Some episodes of The Real Housewives of New Jersey, season four, took place at the Jersey Shore. As discussed on the show, the families of cast members Teresa Giudice and Melissa Gorga have houses in Toms River, and Kathy Wakile's family also rented a house at the shore.		Stronger than the Storm was media campaign, and title of a jingle made for it, to promote tourism in New Jersey, especially the Shore, in 2013.[53][54][55]		Unlike areas in the interior of the state, which has many big box stores and malls, small businesses make a significant portion of the economy of barrier island Jersey Shore towns. This is because small businesses can more easily adapt to the seasonal nature of business in shore towns. Stores that are located at the shore are all unique ranging from psychics and accessories at Ocean City to home-made chocolates in Long Beach Island. In addition many shore towns deliberately stymie the entry of big box stores because they want to reduce traffic. In addition, many tourists visit shore towns in order to be in an environment without big box stores. In some shore towns Wawa Inc. designs its stores to match the aesthetic and changes its operating procedures to adapt to the shore culture. It is the only retailer on the island of Cape May to have a significant number of stores.[56]		Coordinates: 40°02′53″N 74°03′07″W﻿ / ﻿40.048°N 74.052°W﻿ / 40.048; -74.052		
A storm beach is a beach affected by particularly fierce waves, usually with a very long fetch. The resultant landform is often a very steep beach (up to 45°) composed of rounded cobbles, shingle and occasionally sand. The stones usually have an obvious grading of pebbles, from large to small, with the larger diameter stones typically arrayed at the highest beach elevations. It may also contain many small parts of shipwrecked boats.[1]		A noted textbook example is the 18-mile (29 km) long Chesil Beach in Dorset, one of three major shingle structures in Britain. It is also connects the Isle of Portland to the mainland at Abbotsbury, west of the resort of Weymouth. Other examples appear in the Shetland and Orkney Islands, as well as the Scottish mainland at Caithness. The beaches of Lakshdweep Islands are also storm beaches.		These boulders, thrown up by the waves to form a storm beach 30 metres above the sea, demonstrate the power of the sea		Shingly storm beach below a low cliff. The line of seaweed marks the high-water mark.		The whole length of the beach here is backed by a berm of stones, some of considerable size, which have presumably been piled up by winter storms.		Laggan Sands at Lochbuie has a sandy beach behind a storm beach of boulders.		Storm beach connecting Garbh Eilean and Eilean an Tigh. The narrow neck of pebbles is covered at spring tides and during storms.		
Edward VII (Albert Edward; 9 November 1841 – 6 May 1910) was King of the United Kingdom and the British Dominions and Emperor of India from 22 January 1901 until his death in 1910.		The eldest son of Queen Victoria and Prince Albert of Saxe-Coburg and Gotha, Edward was related to royalty throughout Europe. Before his accession to the throne, he served as heir apparent and held the title of Prince of Wales for longer than any of his predecessors. During the long reign of his mother, he was largely excluded from political power, and came to personify the fashionable, leisured elite. He travelled throughout Britain performing ceremonial public duties, and represented Britain on visits abroad. His tours of North America in 1860 and the Indian subcontinent in 1875 were popular successes, but despite public approval his reputation as a playboy prince soured his relationship with his mother.		As king, Edward played a role in the modernisation of the British Home Fleet and the reorganisation of the British Army after the Second Boer War. He reinstituted traditional ceremonies as public displays and broadened the range of people with whom royalty socialised. He fostered good relations between Britain and other European countries, especially France, for which he was popularly called "Peacemaker", but his relationship with his nephew, the German Emperor Wilhelm II, was poor. The Edwardian era, which covered Edward's reign and was named after him, coincided with the start of a new century and heralded significant changes in technology and society, including steam turbine propulsion and the rise of socialism. He died in 1910 in the midst of a constitutional crisis that was resolved the following year by the Parliament Act 1911, which restricted the power of the unelected House of Lords.						Edward was born at 10:48 in the morning on 9 November 1841 in Buckingham Palace.[1] He was the eldest son and second child of Queen Victoria and her husband (and first cousin) Prince Albert of Saxe-Coburg and Gotha. He was christened Albert Edward at St George's Chapel, Windsor Castle, on 25 January 1842.[a] He was named Albert after his father and Edward after his maternal grandfather Prince Edward, Duke of Kent and Strathearn. He was known as Bertie to the royal family throughout his life.[3]		As the eldest son of the British sovereign, he was automatically Duke of Cornwall and Duke of Rothesay at birth. As a son of Prince Albert, he also held the titles of Prince of Saxe-Coburg and Gotha and Duke of Saxony. He was created Prince of Wales and Earl of Chester on 8 December 1841, Earl of Dublin on 17 January 1850, a Knight of the Garter on 9 November 1858, and a Knight of the Thistle on 24 May 1867.[4] In 1863, he renounced his succession rights to the Duchy of Saxe-Coburg and Gotha in favour of his younger brother, Prince Alfred.[5]		Queen Victoria and Prince Albert were determined that their eldest son should have an education that would prepare him to be a model constitutional monarch. At age seven, Edward embarked on a rigorous educational programme devised by Prince Albert, and supervised by several tutors. Unlike his elder sister Victoria, Edward did not excel in his studies.[6] He tried to meet the expectations of his parents, but to no avail. Although Edward was not a diligent student—his true talents were those of charm, sociability and tact—Benjamin Disraeli described him as informed, intelligent and of sweet manner.[7] After the completion of his secondary-level studies, his tutor was replaced by a personal governor, Robert Bruce.		After an educational trip to Rome, undertaken in the first few months of 1859, he spent the summer of that year studying at the University of Edinburgh under, among others, the chemist Lyon Playfair. In October, he matriculated as an undergraduate at Christ Church, Oxford.[8] Now released from the educational strictures imposed by his parents, he enjoyed studying for the first time and performed satisfactorily in examinations.[9] In 1861, he transferred to Trinity College, Cambridge,[10] where he was tutored in history by Charles Kingsley, Regius Professor of Modern History.[11] Kingsley's efforts brought forth the best academic performances of Edward's life, and Edward actually looked forward to his lectures.[12]		In 1860, Edward undertook the first tour of North America by an heir to the British throne. His genial good humour and confident bonhomie made the tour a great success.[13] He inaugurated the Victoria Bridge, Montreal, across the St Lawrence River, and laid the cornerstone of Parliament Hill, Ottawa. He watched Charles Blondin traverse Niagara Falls by highwire, and stayed for three days with President James Buchanan at the White House. Buchanan accompanied the Prince to Mount Vernon, to pay his respects at the tomb of George Washington. Vast crowds greeted him everywhere. He met Henry Wadsworth Longfellow, Ralph Waldo Emerson and Oliver Wendell Holmes. Prayers for the royal family were said in Trinity Church, New York, for the first time since 1776.[13] The four-month tour throughout Canada and the United States considerably boosted Edward's confidence and self-esteem, and had many diplomatic benefits for Great Britain.[14]		Edward had hoped to pursue a career in the British Army, but his mother vetoed an active military career.[15] He had been gazetted colonel on 9 November 1858[16]—to his disappointment, as he had wanted to earn his commission by examination.[9] In September 1861, Edward was sent to Germany, supposedly to watch military manoeuvres, but actually in order to engineer a meeting between him and Princess Alexandra of Denmark, the eldest daughter of Prince Christian of Denmark and his wife Louise. Queen Victoria and Prince Albert had already decided that Edward and Alexandra should marry. They met at Speyer on 24 September under the auspices of his elder sister, Victoria, who had married the Crown Prince of Prussia in 1858.[17] Edward's elder sister, acting upon instructions from their mother, had met Princess Alexandra at Strelitz in June; the young Danish princess made a very favourable impression. Edward and Alexandra were friendly from the start; the meeting went well for both sides, and marriage plans advanced.[18]		From this time, Edward gained a reputation as a playboy. Determined to get some army experience, Edward attended manoeuvres in Ireland, during which he spent three nights with an actress, Nellie Clifden, who was hidden in the camp by his fellow officers.[19] Prince Albert, though ill, was appalled and visited Edward at Cambridge to issue a reprimand. Albert died in December 1861 just two weeks after the visit. Queen Victoria was inconsolable, wore mourning clothes for the rest of her life and blamed Edward for his father's death.[20] At first, she regarded her son with distaste as frivolous, indiscreet and irresponsible. She wrote to her eldest daughter, "I never can, or shall, look at him without a shudder."[21]		Once widowed, Queen Victoria effectively withdrew from public life. Shortly after Prince Albert's death, she arranged for Edward to embark on an extensive tour of the Middle East, visiting Egypt, Jerusalem, Damascus, Beirut and Constantinople.[22] The British Government wanted Edward to secure the friendship of Egypt's ruler, Said Pasha, to prevent French control of the Suez Canal if the Ottoman Empire collapsed. It was the first royal tour on which an official photographer, Francis Bedford, was in attendance.[23] As soon as Edward returned to Britain, preparations were made for his engagement, which was sealed at Laeken in Belgium on 9 September 1862.[24] Edward married Alexandra at St George's Chapel, Windsor Castle, on 10 March 1863. He was 21; she was 18.		The couple established Marlborough House as their London residence and Sandringham House in Norfolk as their country retreat. They entertained on a lavish scale. Their marriage met with disapproval in certain circles because most of Queen Victoria's relations were German, and Denmark was at loggerheads with Germany over the territories of Schleswig and Holstein. When Alexandra's father inherited the throne of Denmark in November 1863, the German Confederation took the opportunity to invade and annex Schleswig-Holstein. Queen Victoria was of two minds whether it was a suitable match given the political climate.[25] After the marriage, she expressed anxiety about their socialite lifestyle and attempted to dictate to them on various matters, including the names of their children.[26]		Edward had mistresses throughout his married life. He socialised with actress Lillie Langtry; Lady Randolph Churchill (born Jennie Jerome, she was the mother of Winston Churchill);[b] Daisy Greville, Countess of Warwick; actress Sarah Bernhardt; noblewoman Lady Susan Vane-Tempest; singer Hortense Schneider; prostitute Giulia Beneni (known as "La Barucci"); wealthy humanitarian Agnes Keyser; and Alice Keppel. At least fifty-five liaisons are conjectured.[28] How far these relationships went is not always clear. Edward always strove to be discreet, but this did not prevent society gossip or press speculation.[29] One of Alice Keppel's great-granddaughters, Camilla Parker Bowles, became the mistress and subsequently wife of Charles, Prince of Wales, one of Edward's great-great-grandsons. It was rumoured that Camilla's grandmother, Sonia Keppel (born in May 1900), was the illegitimate daughter of Edward, but she was "almost certainly" the daughter of George Keppel, whom she resembled.[30] Edward never acknowledged any illegitimate children.[31] Alexandra is believed to have been aware of many of his affairs and to have accepted them.[32]		In 1869, Sir Charles Mordaunt, a British Member of Parliament, threatened to name Edward as co-respondent in his divorce suit. Ultimately, he did not do so but Edward was called as a witness in the case in early 1870. It was shown that Edward had visited the Mordaunts' house while Sir Charles was away sitting in the House of Commons. Although nothing further was proven and Edward denied he had committed adultery, the suggestion of impropriety was damaging.[9][33]		In the 1880s, Edward was a regular habitué of Parisian brothels, most notably Le Chabanais, which was regarded as the top establishment in Paris where brothels were legal. One room contained a custom made bath which was sometimes filled with champagne; and a specially designed and crafted siège d'amour (love seat) that allowed easy access for oral and other forms of sex for two or three people. It is now a museum piece.[34][35][36]		During Queen Victoria's widowhood, Edward pioneered the idea of royal public appearances as we understand them today—for example, opening the Thames Embankment in 1871, the Mersey Tunnel in 1886, and Tower Bridge in 1894[37]—but his mother did not allow Edward an active role in the running of the country until 1898.[38][39] He was sent summaries of important government documents, but she refused to give him access to the originals.[9] He annoyed his mother by siding with Denmark on the Schleswig-Holstein Question in 1864 (she was pro-German) and in the same year annoyed her again by making a special effort to meet Giuseppe Garibaldi.[40] Liberal Prime Minister William Ewart Gladstone sent him papers secretly.[9] From 1886, Foreign Secretary Lord Rosebery sent him Foreign Office despatches, and from 1892 some Cabinet papers were opened to him.[9]		In 1870 republican sentiment in Britain was given a boost when the French Emperor, Napoleon III, was defeated in the Franco-Prussian War and the French Third Republic was declared.[41] However, in the winter of 1871, a brush with death led to an improvement in both Edward's popularity with the public and his relationship with his mother. While staying at Londesborough Lodge, near Scarborough, North Yorkshire, Edward contracted typhoid, the disease that was believed to have killed his father. There was great national concern, and one of his fellow guests (Lord Chesterfield) died. Edward's recovery was greeted with almost universal relief.[9] Public celebrations included the composition of Arthur Sullivan's Festival Te Deum. Edward cultivated politicians from all parties, including republicans, as his friends, and thereby largely dissipated any residual feelings against him.[42]		In October 1875 Edward set off for India on an extensive eight-month tour of the sub-continent. His advisors remarked on his habit of treating all people the same, regardless of their social station or colour. In letters home, he complained of the treatment of the native Indians by the British officials: "Because a man has a black face and a different religion from our own, there is no reason why he should be treated as a brute."[43] Consequently, Lord Salisbury, the Secretary of State for India, issued new guidance and at least one resident was removed from office.[9] At the end of the tour, Queen Victoria was given the title Empress of India by Parliament, in part as a result of the tour's success.[44]		He was regarded worldwide as an arbiter of men's fashions.[45][46] He made wearing tweed, Homburg hats and Norfolk jackets fashionable, and popularised the wearing of black ties with dinner jackets, instead of white tie and tails.[47] He pioneered the pressing of trouser legs from side to side in preference to the now normal front and back creases,[48] and was thought to have introduced the stand-up turn-down shirt collar.[49] A stickler for proper dress, he is said to have admonished Lord Salisbury for wearing the trousers of an Elder Brother of Trinity House with a Privy Councillor's coat. Deep in an international crisis, Salisbury informed the Prince that it had been a dark morning, and that "my mind must have been occupied by some subject of less importance."[50] The tradition of men not buttoning the bottom button of waistcoats is said to be linked to Edward, who supposedly left his undone because of his large girth.[9][51] His waist measured 48 inches (122 cm) shortly before his coronation.[52] He introduced the practice of eating roast beef and potatoes with horseradish sauce and yorkshire pudding on Sundays, a meal that remains a staple British favourite for Sunday lunch.[53][c]		Edward was a patron of the arts and sciences and helped found the Royal College of Music. He opened the college in 1883 with the words, "Class can no longer stand apart from class ... I claim for music that it produces that union of feeling which I much desire to promote."[44] At the same time, he enjoyed gambling and country sports and was an enthusiastic hunter. He ordered all the clocks at Sandringham to run half an hour ahead to provide more daylight time for shooting. This so-called tradition of Sandringham Time continued until 1936, when it was abolished by Edward VIII.[55] He also laid out a golf course at Windsor. By the 1870s the future king had taken a keen interest in horseracing and steeplechasing. In 1896, his horse Persimmon won both the Derby Stakes and the St Leger Stakes. In 1900, Persimmon's brother, Diamond Jubilee, won five races (Derby, St Leger, 2,000 Guineas Stakes, Newmarket Stakes and Eclipse Stakes)[56] and another of Edward's horses, Ambush II, won the Grand National.[57]		In 1891 Edward was embroiled in the royal baccarat scandal, when it was revealed he had played an illegal card game for money the previous year. The Prince was forced to appear as a witness in court for a second time when one of the participants unsuccessfully sued his fellow players for slander after being accused of cheating.[58] In the same year Edward was involved in a personal conflict, when Lord Charles Beresford threatened to reveal details of Edward's private life to the press, as a protest against Edward interfering with Beresford's affair with Daisy Greville, Countess of Warwick. The friendship between the two men was irreversibly damaged and their bitterness would last for the remainder of their lives.[59] Usually, Edward's outbursts of temper were short-lived, and "after he had let himself go ... [he would] smooth matters by being especially nice".[60]		In late 1891 Edward's eldest son, Albert Victor, was engaged to Princess Victoria Mary of Teck. Just a few weeks later, in early 1892, Albert Victor died of pneumonia. Edward was grief-stricken. "To lose our eldest son", he wrote, "is one of those calamities one can never really get over". Edward told Queen Victoria, "[I would] have given my life for him, as I put no value on mine".[61] Albert Victor was the second of Edward's children to die. In 1871, his youngest son, Alexander John, had died just 24 hours after being born. Edward had insisted on placing Alexander John in a coffin personally with "the tears rolling down his cheeks".[62]		On his way to Denmark through Belgium on 4 April 1900 Edward was the victim of an attempted assassination, when fifteen-year-old Jean-Baptiste Sipido shot at him in protest over the Boer War. Sipido, though obviously guilty, was acquitted by a Belgian court because he was underage.[63] The perceived laxity of the Belgian authorities, combined with British disgust at Belgian atrocities in the Congo, worsened the already poor relations between the United Kingdom and the Continent. However, in the next ten years, Edward's affability and popularity, as well as his use of family connections, assisted Britain in building European alliances.[64]		When Queen Victoria died on 22 January 1901, Edward became King of the United Kingdom, Emperor of India and, in an innovation, King of the British Dominions.[65] He chose to reign under the name Edward VII, instead of Albert Edward—the name his mother had intended for him to use[d]—declaring that he did not wish to "undervalue the name of Albert" and diminish the status of his father with whom the "name should stand alone".[66] The numeral VII was occasionally omitted in Scotland, even by the national church, in deference to protests that the previous Edwards were English kings who had "been excluded from Scotland by battle".[9] J. B. Priestley recalled, "I was only a child when he succeeded Victoria in 1901, but I can testify to his extraordinary popularity. He was in fact the most popular king England had known since the earlier 1660s."[67]		He donated his parents' house, Osborne on the Isle of Wight, to the state and continued to live at Sandringham.[68] He could afford to be magnanimous; his private secretary, Sir Francis Knollys, claimed that he was the first heir to succeed to the throne in credit.[69] Edward's finances had been ably managed by Sir Dighton Probyn, Comptroller of the Household, and had benefited from advice from Edward's Jewish financier friends, such as Ernest Cassel, Maurice de Hirsch and the Rothschild family.[70] At a time of widespread anti-Semitism, Edward attracted criticism for openly socialising with Jews.[71][72]		Edward's coronation had originally been scheduled for 26 June 1902. However, two days before, on 24 June, he was diagnosed with appendicitis.[73] Appendicitis was generally not treated operatively and carried a high mortality rate, but developments in anaesthesia and antisepsis in the preceding 50 years made life-saving surgery possible.[74] Sir Frederick Treves, with the support of Lord Lister, performed a then-radical operation of draining a pint of pus from the infected abscess through a small incision (through  4 1⁄2-inch thickness of belly fat and abdomen wall); this outcome showed thankfully that the cause was not cancer.[75] The next day, Edward was sitting up in bed, smoking a cigar.[76] Two weeks later, it was announced that the King was out of danger. Treves was honoured with a baronetcy (which Edward had arranged before the operation)[77] and appendix surgery entered the medical mainstream.[74] Edward was crowned at Westminster Abbey on 9 August 1902 by the 80-year-old Archbishop of Canterbury, Frederick Temple, who died only four months later.[73]		Edward refurbished the royal palaces, reintroduced the traditional ceremonies, such as the State Opening of Parliament, that his mother had forgone, and founded new honours, such as the Order of Merit, to recognise contributions to the arts and sciences.[78] In 1902, the Shah of Persia, Mozzafar-al-Din, visited England expecting to receive the Order of the Garter. Edward refused to bestow the honour on the Shah because the order was meant to be in his personal gift and the Foreign Secretary, Lord Lansdowne, had promised it without his consent. Edward also objected to inducting a Muslim into a Christian order of chivalry. His refusal threatened to damage British attempts to gain influence in Persia,[79] but Edward resented his ministers' attempts to reduce the King's traditional powers.[80] Eventually, he relented and Britain sent a special embassy to the Shah with a full Order of the Garter the following year.[81]		As king, Edward's main interests lay in the fields of foreign affairs and naval and military matters. Fluent in French and German, he reinvented royal diplomacy by numerous state visits across Europe.[82] He took annual holidays in Biarritz and Marienbad.[55] One of his most important foreign trips was an official visit to France in May 1903 as the guest of President Émile Loubet. Following a visit to the Pope in Rome, this trip helped create the atmosphere for the Anglo-French Entente Cordiale, an agreement delineating British and French colonies in North Africa, and ruling out any future war between the two countries. The Entente was negotiated in 1904 between the French foreign minister, Théophile Delcassé, and the British foreign secretary, Lord Lansdowne. It marked the end of centuries of Anglo-French rivalry and Britain's splendid isolation from Continental affairs, and attempted to counterbalance the growing dominance of the German Empire and its ally, Austria-Hungary.[83]		Edward was related to nearly every other European monarch and came to be known as the "uncle of Europe".[38] Kaiser Wilhelm II was his nephew; Tsar Nicholas II was his nephew-by-marriage; Queen Victoria Eugenia of Spain, Crown Princess Margaret of Sweden, Crown Princess Marie of Romania, Crown Princess Sophia of Greece, and Empress Alexandra of Russia were his nieces; Haakon VII of Norway was both his nephew by marriage and his son-in-law; Frederick VIII of Denmark and George I of Greece were his brothers-in-law; Albert I of Belgium, Ferdinand of Bulgaria, and Charles I and Manuel II of Portugal were his second cousins. Edward doted on his grandchildren, and indulged them, to the consternation of their governesses.[84] However, there was one relation whom Edward did not like: Wilhelm II. Edward's difficult relationship with his nephew exacerbated the tensions between Germany and Britain.[85]		In April 1908, during Edward's annual stay at Biarritz, he accepted the resignation of British Prime Minister Sir Henry Campbell-Bannerman. In a break with precedent, Edward asked Campbell-Bannerman's successor, H. H. Asquith, to travel to Biarritz to kiss hands. Asquith complied, but the press criticised the action of the King in appointing a prime minister on foreign soil instead of returning to Britain.[86] In June 1908, Edward became the first reigning British monarch to visit the Russian Empire, despite refusing to visit in 1906, when Anglo-Russian relations were strained in the aftermath of the Russo-Japanese War, the Dogger Bank incident, and the Tsar's dissolution of the Duma.[87] The previous month, Edward visited the Scandinavian countries, becoming the first British monarch to visit Sweden.[88]		While Prince of Wales, Edward had to be dissuaded from breaking with constitutional precedent by openly voting for Gladstone's Representation of the People Bill (1884) in the House of Lords.[9][89] On other matters he was less progressive: he did not, for example, favour giving votes to women,[9][90] although he did suggest that the social reformer Octavia Hill serve on the Commission for Working Class Housing.[91] He was also opposed to Irish Home Rule, instead preferring a form of dual monarchy.[9]		As Prince of Wales, he had come to enjoy warm and mutually respectful relations with W. E. Gladstone, whom his mother detested.[92] But Gladstone's son, Home Secretary Herbert Gladstone, angered the King by planning to permit Roman Catholic priests in vestments to carry the Host through the streets of London, and by appointing two ladies, Lady Frances Balfour and Mrs H. J. Tennant, to serve on a Royal Commission on reforming divorce law – Edward thought divorce could not be discussed with "delicacy or even decency" before ladies. Edward's biographer Philip Magnus suggests that Gladstone may have become a whipping-boy for the King's general irritation with the Liberal government. Gladstone was sacked in the reshuffle the following year and the King agreed, with some reluctance, to appoint him Governor-General of South Africa.[93]		Edward involved himself heavily in discussions over army reform, the need for which had become apparent with the failings of the Boer War.[94] He supported the redesign of army command, the creation of the Territorial Force, and the decision to provide an Expeditionary Force supporting France in the event of war with Germany.[95] Reform of the Royal Navy was also suggested, partly due to the ever-increasing Naval Estimates, and because of the emergence of the Imperial German Navy as a new strategic threat.[96] Ultimately a dispute arose between Admiral Lord Charles Beresford, who favoured increased spending and a broad deployment, and the First Sea Lord Admiral Sir John Fisher, who favoured efficiency savings, scrapping obsolete vessels, and a strategic realignment of the Royal Navy relying on torpedo craft for home defence backed by the new dreadnoughts.[97]		The King lent support to Fisher, in part because he disliked Beresford, and eventually Beresford was dismissed. Beresford continued his campaign outside of the navy and Fisher ultimately announced his resignation in late 1909, although the bulk of his policies were retained.[98] The King was intimately involved in the appointment of Fisher's successor as the Fisher-Beresford feud had split the service, and the only truly qualified figure known to be outside of both camps was Sir Arthur Knyvet Wilson, who had retired in 1907.[99] Wilson was reluctant to return to active duty, but Edward persuaded him to do so, and Wilson became First Sea Lord on 25 January 1910.[100]		Edward was rarely interested in politics, although his views on some issues were notably liberal for the time. During his reign he said use of the word nigger was "disgraceful" despite it then being in common parlance.[101] In 1904, during an Anglo-German summit in Kiel between Wilhelm II and Edward, Wilhelm with the Russo-Japanese War in mind started to go on about the "Yellow Peril", which he called "the greatest peril menacing ... Christendom and European civilisation. If the Russians went on giving ground, the yellow race would, in twenty years time, be in Moscow and Posen".[102] Wilhelm went on to attack his British guests for supporting Japan against Russia, suggesting that the British were committing "race treason". In response, Edward stated that he "could not see it. The Japanese were an intelligent, brave and chivalrous nation, quite as civilised as the Europeans, from whom they only differed by the pigmentation of their skin".[102]		Edward lived a life of luxury that was often far removed from that of the majority of his subjects. However, his personal charm with people at all levels of society and his strong condemnation of prejudice went some way to assuage republican and racial tensions building during his lifetime.[9]		In the last year of his life, Edward became embroiled in a constitutional crisis when the Conservative majority in the House of Lords refused to pass the "People's Budget" proposed by the Liberal government of Prime Minister H. H. Asquith. The crisis eventually led – after Edward's death – to the removal of the Lords' right to veto legislation.		The King was displeased at Liberal attacks on the peers, which included a polemical speech by David Lloyd George at Limehouse.[103] Cabinet minister Winston Churchill publicly demanded a general election, for which Asquith apologised to the King's adviser Lord Knollys and rebuked Churchill at a Cabinet meeting. Edward was so dispirited at the tone of class warfare – although Asquith told him that party rancour had been just as bad over the First Home Rule Bill in 1886 – that he introduced his son to Secretary of State for War Richard Haldane as "the last King of England".[104] After the King's horse Minoru won the Derby on 26 July 1909, he returned to the racetrack the following day, and laughed when a man shouted: "Now, King. You've won the Derby. Go back home and dissolve this bloody Parliament!"[105]		In vain, the King urged Conservative leaders Arthur Balfour and Lord Lansdowne to pass the Budget, which Lord Esher had advised him was not unusual, as Queen Victoria had helped to broker agreements between the two Houses over Irish disestablishment in 1869 and the Third Reform Act in 1884.[106] On Asquith's advice, however, he did not offer them an election (at which, to judge from recent by-elections, they were likely to gain seats) as a reward for doing so.[107]		The Finance Bill passed the Commons on 5 November 1909 but was rejected by the Lords on 30 November; they instead passed a resolution of Lord Lansdowne's stating that they were entitled to oppose the bill as it lacked an electoral mandate. The King was annoyed that his efforts to urge passage of the budget had become public knowledge[108] and had forbidden his adviser Lord Knollys, who was an active Liberal peer, from voting for the budget, although Knollys had suggested that this would be a suitable gesture to indicate royal desire to see the Budget pass.[109] In December 1909, a proposal to create peers (to give the Liberals a majority in the Lords) or give the prime minister the right to do so was considered "outrageous" by Knollys, who thought the King should abdicate rather than agree to it.[110]		The January 1910 election was dominated by talk of removing the Lords' veto. During the election campaign Lloyd George talked of "guarantees" and Asquith of "safeguards" that would be necessary before forming another Liberal government, but the King informed Asquith that he would not be willing to contemplate creating peers until after a second general election.[9][111] Balfour refused to be drawn on whether or not he would be willing to form a Conservative government, but advised the King not to promise to create peers until he had seen the terms of any proposed constitutional change.[112] During the campaign the leading Conservative Walter Long had asked Knollys for permission to state that the King did not favour Irish Home Rule, but Knollys refused on the grounds that it was not appropriate for the monarch's views to be known in public.[113]		The election resulted in a hung parliament, with the Liberal government dependent on the support of the third largest party, the Irish nationalists. The King suggested a compromise whereby only 50 peers from each side would be allowed to vote, which would also redress the large Conservative majority in the Lords, but Lord Crewe, Liberal leader in the Lords, advised that this would reduce the Lords' independence as only peers who were loyal party supporters would be picked.[113] Pressure to remove the Lords' veto now came from the Irish nationalist MPs, who wanted to remove the Lords' ability to block the introduction of Irish Home Rule. They threatened to vote against the Budget unless they had their way (an attempt by Lloyd George to win their support by amending whisky duties was abandoned as the Cabinet felt this would recast the Budget too much). Asquith now revealed that there were no "guarantees" for the creation of peers. The Cabinet considered resigning and leaving it up to Balfour to try to form a Conservative government.[114]		The King's Speech from the Throne on 21 February made reference to introducing measures restricting the Lords' power of veto to one of delay, but Asquith inserted a phrase "in the opinion of my advisers" so the King could be seen to be distancing himself from the planned legislation.[115]		The Commons passed resolutions on 14 April that would form the basis for the Parliament Act: to remove the power of the Lords to veto money bills, to replace their veto of other bills with a power to delay, and to reduce the term of Parliament from seven years to five (the King would have preferred four[112]). But in that debate Asquith hinted – to ensure the support of the nationalist MPs – that he would ask the King to break the deadlock "in that Parliament" (i.e. contrary to Edward's earlier stipulation that there be a second election). The Budget was passed by both Commons and Lords in April.[116]		By April the Palace was having secret talks with Balfour and the Archbishop of Canterbury, who both advised that the Liberals did not have sufficient mandate to demand the creation of peers. The King thought the whole proposal "simply disgusting" and that the government was "in the hands of Redmond & Co". Lord Crewe announced publicly that the government's wish to create peers should be treated as formal "ministerial advice" (which, by convention, the monarch must obey) although Lord Esher argued that the monarch was entitled in extremis to dismiss the government rather than take their "advice".[117] Esher's view has been called "obsolete and unhelpful".[118]		Edward habitually smoked twenty cigarettes and twelve cigars a day. In 1907, a rodent ulcer, a type of cancer affecting the skin next to his nose, was cured with radium.[119] Towards the end of his life he increasingly suffered from bronchitis.[9] He suffered a momentary loss of consciousness during a state visit to Berlin in February 1909.[120] In March 1910, he was staying at Biarritz when he collapsed. He remained there to convalesce, while in London Asquith tried to get the Finance Bill passed. The King's continued ill health was unreported and he attracted criticism for staying in France while political tensions were so high.[9] On 27 April he returned to Buckingham Palace, still suffering from severe bronchitis. Alexandra returned from visiting her brother, King George I of Greece, in Corfu a week later on 5 May.		The following day, the King suffered several heart attacks, but refused to go to bed, saying, "No, I shall not give in; I shall go on; I shall work to the end."[121] Between moments of faintness, his son the Prince of Wales (shortly to be King George V) told him that his horse, Witch of the Air, had won at Kempton Park that afternoon. The King replied, "Yes, I have heard of it. I am very glad": his final words.[9] At 11:30 p.m. he lost consciousness for the last time and was put to bed. He died 15 minutes later.[121]		Alexandra refused to allow the King's body to be moved for eight days afterwards, though she allowed small groups of visitors to enter his room.[122] On 11 May, the late King was dressed in his uniform and placed in a massive oak coffin, which was moved on 14 May to the throne room, where it was sealed and lay in state, with four guardsmen standing at each corner of the bier. Despite the time that had elapsed since his death, Alexandra noted the King's body remained "wonderfully preserved".[123] On the morning of 17 May, the coffin was placed on a gun carriage and drawn by black horses to Westminster Hall, with the new King and his family walking behind. Following a brief service, the royal family left, and the hall was opened to the public; over 400,000 people filed past the coffin over the next two days.[124]		As Barbara Tuchman noted in The Guns of August, his funeral, held on 20 May 1910, marked "the greatest assemblage of royalty and rank ever gathered in one place and, of its kind, the last." A royal train conveyed the King's coffin from London to Windsor Castle, where Edward VII was buried at St George's Chapel.[125]		Before his accession to the throne, Edward was the longest-serving heir apparent in British history. He was surpassed by his great-great-grandson Charles, Prince of Wales, on 20 April 2011.[126] The title Prince of Wales is not automatically held by the heir apparent; it is bestowed by the reigning monarch at a time of his or her choosing.[127] Edward is the longest-serving holder of that title; he was Prince of Wales for 59 years. Charles has held the title since 1958.[128][e]		As king, Edward VII proved a greater success than anyone had expected,[129] but he was already past the average life expectancy and had little time left to fulfil the role. In his short reign, he ensured that his second son and heir, George V, was better prepared to take the throne. Contemporaries described their relationship as more like affectionate brothers than father and son,[130] and on Edward's death George wrote in his diary that he had lost his "best friend and the best of fathers ... I never had a [cross] word with him in my life. I am heart-broken and overwhelmed with grief".[131]		Edward has been recognised as the first truly constitutional British sovereign and the last sovereign to wield effective political power.[132] Though lauded as "Peacemaker",[133] he had been afraid his nephew, the German Emperor Wilhelm II, would tip Europe into war.[134] Four years after Edward's death, World War I broke out. The naval reforms he had supported and his part in securing the Triple Entente between Britain, France and Russia, as well as his relationships with his extended family, fed the paranoia of the German Emperor, who blamed Edward for the war.[135] Publication of the official biography of Edward was delayed until 1927 by its author, Sidney Lee, who feared German propagandists would select material to portray Edward as an anti-German warmonger.[136] Lee was also hampered by the extensive destruction of Edward's personal papers; Edward had left orders that all his letters should be burned on his death.[137] Subsequent biographers have been able to construct a more rounded picture of Edward by using material and sources that were unavailable to Lee.[138]		Historian R. C. K. Ensor, writing in 1936, praised the King's political personality:		Ensor rejects the widespread notion that the King exerted important influence on British foreign policy. Ensor believed Edward gained that reputation by making frequent trips abroad, with many highly publicized visits to foreign courts, but surviving documents paint a different picture of "how comparatively crude his views on foreign policy were, how little he read, and of what naïve indiscretions he was capable."[140]		Edward received criticism for his apparent pursuit of self-indulgent pleasure, but he received great praise for his affable and kind good manners, and his diplomatic tact. As his grandson Edward VIII wrote, "his lighter side ... obscured the fact that he had both insight and influence."[141] "He had a tremendous zest for pleasure but he also had a real sense of duty", wrote J. B. Priestley.[142] Lord Esher wrote that Edward was "kind and debonair and not undignified – but too human".[143]		As Prince of Wales, Edward's coat of arms was the royal arms differenced by a label of three points argent, and an inescutcheon of the shield of Saxony, representing his father. When he acceded as King, he gained the royal arms undifferenced.[158]				
At a flat coast or flat shoreline, the land descends gradually into the sea. Flat coasts can be formed either as a result of the sea advancing into gently-sloping terrain or through the abrasion of loose rock. They may be basically divided into two parallel strips: the shoreface and the beach.		Flat coasts consist of loose material such as sand and gravel. Wind transports finer grains of sand inland over the dunes. The sea washes pebbles and sand away from the coast and dumps it at other locations.						The typical sequence of landforms created by the sea is described as a "littoral series".		The littoral series of a flat coast starts in the permanently flooded shallow water region, or shoreface, with a sand or gravel reef (also called a bar). The longshore bar is an elongated ridge of sand found parallel to the shore in the surf zone on many flat coasts. It consists mainly of sand or gravel, depending on the material available along the coast. The sides of the sandbar fall gently away. The basin between a sandbar and the shore zone is called the runnel or swale. The presence of a bar clearly indicates that the movement of waves is transporting and depositing material on the seabed. There may be several bars whose longitudinal axes all run parallel to the beach and which are separated by equally parallel runnels or creeks. The drainage troughs in areas of tidal flats also run parallel to the coast.		The shoreface (or underwater platform) on flat coasts encompasses in its narrow sense that area which is subject to the constant action of moving water. This means that the landward boundary between shoreface and beach is the line of the average low-water mark. However this definition is not universal and frequently varies from author to author in the literature. Whilst some define the beach as the landward transition to the shoreface that extends from the low-water mark to the highest high-water mark, i.e. the zone that is only periodically or episodically (after a storm surge) flooded by water; other authors do not use the term "beach" for the landward element of a flat coast at all. They describe the region between the mean low-water mark and the mean high-water mark of the tides as the intertidal zone or foreshore and that area above the average high-water mark as the supratidal zone or backshore that is only directly attacked by water during storms. Because the backshore is often considerably flatter in appearance than the foreshore, which slopes clearly down towards the sea, it is also often referred to as a beach platform, which is why this part of the shore can be considered in practice to be the actual beach. The farthest point inland that is reached by storm surges is bounded by a belt of dunes, where floods can form a dune cliff.		On the beach (the beach platform) there is very often a bank of sand or a gravel ridge parallel to the shoreline and a few tens of centimetres high, known as the berm. On its landward side there is often a shallow runnel. The berm is formed by material transported by the breaking waves that is thrown beyond the average level of the sea. The coarse-grained material that can no longer be washed away by the backwash remains behind. The location and size of the berm is subject to seasonal changes. For example, a winter bern that has been thrown up by storm surges in winter is usually much more prominent and higher up the beach than berms formed by summer high tides.		Beaches are usually heavily eroded during storm surges and the beach profile steepened, whereas normal wave action on flat coasts tends to raise the beach. Not infrequently a whole series of parallel berms is formed, one behind the other. There is a consequent gradual increase in height with the result that, over time, the shoreline advances seawards. A striking example of land-forming system of berms is Skagen Odde on the northern tip of Vendsyssel in the extreme north of Denmark. This headland is still growing today as more berms are added.		Coastal defences against erosion are groynes, stone walls, or tetrapods of concrete, which act as breakwaters. The first plants to colonise the dunes include sea buckthorn or beach grass which prevent wind erosion.		
In geology, a boulder is a rock fragment with size greater than 25.6 centimetres (10.1 in) in diameter.[1] Smaller pieces are called cobbles and pebbles. While a boulder may be small enough to move or roll manually, others are extremely massive.[2] In common usage, a boulder is too large for a person to move. Smaller boulders are usually just called rocks or stones. The word boulder is short for boulder stone, from Middle English bulderston or Swedish bullersten.[3]		In places covered by ice sheets during Ice Ages, such as Scandinavia, northern North America, and Siberia, glacial erratics are common. Erratics are boulders picked up by ice sheets during their advance, and deposited when they melt.[2] They are called "erratic" because they typically are of a different rock type than the bedrock on which they are deposited. One of them is used as the pedestal of the Bronze Horseman in Saint Petersburg, Russia.		Some noted rock formations involve giant boulders exposed by erosion, such as the Devil's Marbles in Australia's Northern Territory, the Horeke basalts in New Zealand, where an entire valley contains only boulders, and The Baths on the island of Virgin Gorda in the British Virgin Islands.		Boulder sized clasts are found in some sedimentary rocks, such as coarse conglomerate and boulder clay.		The climbing of large boulders is called bouldering.		Media related to Boulders at Wikimedia Commons		
A concordant, longitudinal, or Pacific type coastline occurs where beds, or layers, of differing rock types are folded into ridges that run parallel to the coast.[1] The outer hard rock (for example, granite) provides a protective barrier to erosion of the softer rocks (for example, clays) further inland. Sometimes the outer hard rock is punctured, allowing the sea to erode the softer rocks behind. This creates a cove, a circular area of water with a relatively narrow entrance from the sea.		Lulworth Cove in Dorset is situated on a concordant coastline. The outer hard rock is Portland limestone. The sea has broken through this barrier and easily eroded the clays behind it. A chalk cliff face at the back of the cove slows further erosion. Erosion is just starting to the west, where the sea has again broken through the Portland limestone barrier at Stair Hole.		The concordant coast may take one of two landform types. The Dalmatian type, named from Dalmatia on the Adriatic Sea, features long offshore islands and coastal inlets that are parallel to the coastline. The Adriatic Sea itself is a concordant landform, consisting of a body of water between parallel ranges. The second landform is the Haff type as in the Haffs, or lagoons, of the southern shore of the Baltic Sea, which are enclosed by long spits of sand parallel to the low coast.[2]		The converse of concordant coastline is a discordant coastline.		
Tourism in Bangladesh		Cox's Bazar sea beach · Kuakata Patenga St. Martin's Island · Nijhum Dwip		Bandarban · Khagrachari · Rangamati Jaflong · Sripur · Srimongol		Chhera island · Bhola · Hatiya Kutubdia · Manpura · Nijhum Dwip Sandwip · Sonadia · St. Martin's Island		Sundarbans · Bhawal · Lawachara forest		Hum Hum · Madhabkunda · Nafa-khum Jadipai		Bhitagarh · Choto Katra Jagaddala Mahavihara Mahasthangarh · Mainamati Mosque City of Bagerhat Noapara-Ishanchandranagar  · Sonargaon  · Somapura Mahavihara  · Wari-Bateshwar		Lalbagh Fort · Northbrook Hall		Mosques Sixty Dome Mosque		Hindu Temples Kantaji Temple		Buddhist Temples Buddha Dhatu Jadi		Churches Armenian Church (Dhaka)		International mother language day Pohela Boishakh		Jatiyo Smriti Soudho Shaheed Minar		Gardens · Lakes · Museums Palaces · Parks · Rivers World Heritage Sites · Zoos		Cox's Bazar (Bengali: কক্সবাজার অথবা ৭৫ মাইল বীচ, Koksbajar, Koksbazar or Kokshbajar) is a town, a fishing port and district headquarters in Bangladesh. The beach in Cox's Bazar is an unbroken 120 km (75 mi) sandy sea beach with a gentle slope, is the world's longest.[2][3][4] It is located 150 km (93 mi) south of the industrial port Chittagong. Cox's Bazar is also known by the name Panowa, whose literal translation means "yellow flower." Its other old name was "Palongkee".		The modern Cox's Bazar derives its name from Captain Hiram Cox (died 1799), an officer of the British East India Company. Cox was appointed Superintendent of Palongkee outpost after Warren Hastings became Governor of Bengal. Captain Cox was specially mobilised to deal with a century-long conflict between Arakan refugees and local Rakhains. He embarked upon the task of rehabilitating refugees in the area and made significant progress. Captain Cox died in 1799 before he could finish his work. To commemorate his role in rehabilitation work, a market was established and named Cox's Bazar ("Cox's Market") after him.		Today, Cox's Bazar is one of the most-visited tourist destinations in Bangladesh, though it is not a major international tourist destination. In 2013, the Bangladesh Government formed the Tourist Police unit to better protect local and foreign tourists, as well as to look after the nature and wildlife in the tourist spots of Cox's Bazar.[5]						Cox's Bazar (Town), Cox's Bazar municipality, was constituted in 1869, eventually becoming a B-grade municipality in 1989. Located along the Bay of Bengal in South Eastern Bangladesh, Cox's Bazar Town is a large port and health resort. But it is famous mostly for its long natural sandy beach. The municipality covers an area of 6.85 km2 (2.64 sq mi) with 27 mahallas and 9 wards and has a population of 51,918.[6] Cox's Bazar is connected by road and air with Chittagong.[7]		The greater Chittagong area, including Cox's Bazar, was under the rule of Arakan kings from the early 9th century until its conquest by the Mughals in 1666 AD.[8] When the Mughal Prince Shah Shuja was passing through the hilly terrain of the present-day Cox's Bazar on his way to Arakan, he was attracted to its scenic and captivating beauty. He commanded his forces to camp there. His retinue of one thousand palanquins stopped there for some time. A place named Dulahazara, meaning "one thousand palanquins," still exists in the area. After the Mughals, the place came under the control of the Tipras and the Arakanese, followed by the Portuguese and then the British.		The name Cox's Bazar/Bazaar originated from the name of a British East India Company officer, Captain Hiram Cox, who was appointed as the Superintendent of Palonki (today's Cox's Bazar) outpost. He succeeded Warren Hastings, who became the Governor of Bengal following the British East India Company Act in 1773. Cox was mobilised to deal with a century-long conflict between Arakan refugees and local Rakhine people at Palonki. The Captain had rehabilitated many refugees in the area, but had died (in 1799) before he could finish his work. To commemorate that, a market was established and named after him, called Cox's Bazar (market of Cox). Cox's Bazar then was first established in 1854 and became a municipality in 1869.[8]		After the Sepoy Mutiny (Indian Rebellion of 1857) in 1857, the British East India Company was highly criticised and questioned on humanitarian grounds, specially for its opium trade monopoly over the Indian Sub-Continent. However, after its dissolution on 1 January 1874, all of the company's assets including its Armed Forces were acquired by the British Crown. After this historic take over, Cox's Bazar was declared a district of the Bengal Province under the British Crown.		After the end of British rule in 1947, Cox's Bazar became part of East Pakistan. Captain Advocate Fazlul Karim, the first chairman (after independence from the British) of Cox's Bazar Municipality, established the Tamarisk Forest along the beach. He wanted to attract tourists as well as to protect the beach from tsunami. He donated much of his father-in-law's and his own lands as sites for constructing a Public Library and a Town Hall. He was inspired to build Cox's Bazar as a tourist spot after seeing beaches of Bombay and Karachi, and was a resort pioneer in developing Cox's Bazar as a destination. He founded a Maternity Hospital, the Stadium and the drainage system by procuring grants from the Ford Foundation and Rockefeller Foundation through correspondence. T. H. Matthews, the principal of the Dacca Engineering College (1949~1954), was a friend who had helped him in these fundraising efforts. Engineer Chandi Charan Das was the government civil engineer who had worked on all these projects. In 1959 the municipality was turned into a town committee.[8]		In 1961 the Geological Survey of Pakistan initiated investigation of radioactive minerals like monazite around the Cox's Bazar sea-beach area.[9]		In 1971, Cox's Bazar wharf was used as a naval port by the Pakistan Navy's gunboats. This and the nearby airstrip of the Pakistan Air Force were the scene of intense shelling by the Indian Navy during the Bangladesh Liberation War. During the war, Pakistani soldiers killed many people in the town, including eminent lawyer Jnanendralal Chowdhury. The killing of two freedom fighters named Farhad and Subhash at Badar Mokam area is also recorded in history.[6]		After the independence of Bangladesh, Cox's Bazar started to get administrative attention. In 1972 the town committee of Cox's Bazar was turned into a municipality. In 1975, The Government of Bangladesh established a pilot plant at Kalatali.[9] Later, in 1984 Cox's Bazar subdivision was promoted to a district, and five years later (in 1989) the Cox's Bazar municipality was elevated to B-grade.[8] In 1994 (jobs) the Marine Fisheries and Technology Station (MFTS) was established at Cox's Bazar. MFTS is a research station of Bangladesh Fisheries Research Institute (BFRI) headquartered in Mymensingh. The station covers a land area of four hectares and contains five laboratories.[10] In April 2007 Bangladesh got connected to the submarine cable network as a member of the SEA-ME-WE-4 Consortium, as Cox's Bazar was selected as the landing station of the submarine cable.[11] In September 2012 the municipality was the site of the Cox's Bazar and Ramu riots, where local Muslims attacked the Buddhist community over an alleged Quran desecration posted to Facebook.[12]		Cox's Bazar town with an area of 6.85 km2 (2.64 sq mi), is located at 21°35′0″N 92°01′0″E﻿ / ﻿21.58333°N 92.01667°E﻿ / 21.58333; 92.01667 and bounded by Bakkhali River on the north and East, Bay of Bengal in the West, and Jhilwanj Union in the south.		The climate of Bangladesh is mostly determined by its location in the tropical monsoon region: high temperature, heavy rainfall, generally excessive humidity, and distinct seasonal variations.[13] The climate of Cox's bazar is mostly similar to the rest of the country. It is further characterised by the location in the coastal area. The annual average temperature in Cox's Bazar remains at about a maximum of 34.8 °C (94.6 °F) and a minimum of 16.1 °C (61.0 °F). The average amount of rainfall remains at 3,524 mm (138.7 in).		1962: Cox's Bazar Govt. College is the earliest Secondary and bachelor's degree offering college founded in Cox's Bazar. 1985: Cox's Bazar Law College is the first profession based college founded in this district. 1991: Cox's Bazar Govt. Women's College is the first Secondary and bachelor's degree offering college in this district solely for women. 2008: Cox's Bazar Medical College is the first medical college in this district.		Other Colleges in this area: Cox's Bazar City College, Ramu Degree College, Ukhiya Degree College, Teknaf Degree College, Moheskhali degree college		High Schools: Cox's Bazar Govt. High School, Cox's Bazar Govt. Girls High School, Cox's Bazar Model High School, Kishalaya Model High School, Chokoria, Korak Bidda-pith, Chokoria, Chokoria Govt. High School, Palong Model High School, Shilkhali High School, Pekua.		As one of the most beautiful and famous tourist spots in Bangladesh, the major source of economy in Cox's Bazar is tourism. Millions of foreigners and Bangladeshi natives visit this city every year. As a result, a large number of hotels, guest houses and motels have been built in the city and coastal region. Many people are involved in hospitality and customer service orientated businesses. The number of high-end hotels in the city was about 2 or 3 about 5 years ago, but today there are dozens and counting. A few international hotel chains now operate in the city, but others are planning to build hotels here.		People are also involved in fishing and collecting seafood and sea products for their livelihood. Oysters, snails, pearls and their ornaments are very popular with tourists. Some people are involved in the transportation business for tourists. Cox's Bazar is one of the few major spots for aquaculture in Bangladesh.[22] Along with Khulna, it is considered a major source of revenue from foreign exchanges. Beside a mix of small-scale agriculture, marine and inland fishing and salt production are other industrial sources that play important roles in the national economy.		The beach is the main attraction of the town. Larger hotels provide exclusive beachside area with accessories for the hotel guests. Visitors in other hotels visit the Laboni beach which is the area of the beach closest to the town. Other than the beach there are several places of interest near the town which can easily be visited from town centre.		Coordinates: 21°26′30″N 91°58′30″E﻿ / ﻿21.44167°N 91.97500°E﻿ / 21.44167; 91.97500		
A gat (German: Seegatt, Seegat or diminutive Gatje) is a strait that is constantly eroded by currents flowing back and forth, such as tidal currents. It is usually a relatively narrow but deep (up to 100 feet (30 m)) passage between land masses (such as an island and a peninsula) or shallow bars in an area of mudflats. A gat is sometimes a shallower passage on lagoon coasts, including those without any tidal range.		According to Whittow a gat is either an inshore channel or strait dividing offshore islands from the mainland e.g. the Frisian Islands, or it is an opening in a line of sea cliffs allowing access to the coast from inland. It is similar, but not identical, to a gut, which is a narrow river channel or strait prior to joining an open ocean or estuary.[1] Leser restricts its use to deep, but relatively narrow inlets in the Wadden Sea that are scoured out by currents, giving the example of the gap between the Frisian islands of Juist and Nordeney.[2]						The comparatively large quantities of water that flow quite quickly through a gat cause heavy erosion that results in a channel deeper than the rest of the surrounding seabed and also endangers neighbouring islands. When the water masses from mud flats behind the islands surge out again into the sea as ebb currents, they flow rapidly again through the narrow gat. But as these water masses break out into the open sea, they spread out and slow down. As a result, on this seaward side of the gat, the particles of sand and mud carried with the water settle and form an ebb delta with its shallower waters between the islands. The sandbanks so formed are often known in Germany as plate (pronounced "plah-ter", see Kachelotplate). The point where the water pouring out of the gat runs over these banks, which often lie in an arc between the islands, is the sand bar (German: Barre). This is the shallowest part of the gat for shipping, but also the deepest point on the shallowest line between the islands. A flood delta is formed in a similar way on the landward side of the gat.		A navigation channel to the open sea is usually marked out in the gats by the waterway and shipping authorities. The area of the bar is usually the most dangerous spot; this is where rip tides and, especially when the current flows against the wind, very dangerous ground swells may occur.		Passages between inner and outer coastal waters, such as at the ends of spits of lagoons or along bodden coasts are also referred to as gats.[3]		The term "gat" is primarily (though not exclusively) applied to waterways of the North Sea and Baltic Sea coasts of Europe. A similar term of related but not identical meaning, gut, is mainly applied to channels of the coastal waters of the Atlantic coast of North America.		The name comes from the Low German and Dutch word "gat" which means "gap". "Gat" is incorporated into some Dutch or Dutch-derived proper names of passages (e. g. Kattegat, Veerse Gat) which may or may not be proper gats.[4] In English names, both "gat" (e. g. Fisherman's Gat) and "gut" (e. g. Digby Gut, Hull Gut, Gut of Canso) are seen.		In German, "Gat" (as well as "Seegatt" and the diminutive "Gatje") can refer to an arm of the sea which is not necessarily subject to strong tidal currents; for instance, the Prerower Strom ("Prerow Stream"), which is a regressive delta, is a gat.[5] Seegatt (also "Neues [Pillauer] Tief" [New {Pillau} Deep]) is the German proper name of the Strait of Baltiysk (Pillau) which connects the Vistula Lagoon to the Baltic Sea.[6]		The name of Hell Gate, a gat (or gut) in the East River of New York City, is derived from archaic Dutch Hellegat (meaning possibly "clear opening"),[7] a fairly common toponym (place name) for waterways in the Low Countries.[8]		The following is a list of gats, including named gats that may or may not be true gats as defined above:		
Beach cusps are shoreline formations made up of various grades of sediment in an arc pattern. The horns are made up of coarser material and the embayment contains finer sediment.		They can be found all over the world and are most noticeable on shorelines with coarser sediment such as pebble beaches. However, they can occur with sediment of any size. They nearly always occur in a regular pattern with cusps of equal size and spacing appearing along stretches of the shoreline. These cusps are most often a few metres long. However, they may reach 60 m (200 ft) across. Although the origin of beach cusps has yet to be proven, once cusps have been created they are a self-sustaining formation. This is because when an oncoming wave hits the horn of a beach cusp, it is split and forced into two directions. The crashing of the wave into the cusps slows its velocity, causing coarser sediment to fall out of suspension and be deposited on the horns. The waves then flow along the embayments (picking up finer sediment) and run into one another in the middle. After this collision these waves attempt to flow back out to sea where they are met by incoming waves. Therefore, once the cusp is established, coarser sediment is constantly being deposited on the horn and finer sediment is being eroded away from the embayments.[1] This process causes the horners and embayments to at least maintain their size, if not grow larger.						There are a number of theories as to why beach cusps are formed but currently, there are only two explanations with any real credibility.		The standing edge wave theory is based on an interaction, near the shoreline, between the waves that are approaching the shore and waves that have been set up perpendicular to the shoreline called 'edge waves'. The regular arrival of incoming waves in the near shore waters causes the development of waves perpendicular to the direction of the incoming waves; these are termed 'edge waves'. These edge waves become trapped near the shoreline and when two of them come together from opposite directions, a standing edge wave is formed. The movement patterns of these waves are fixed and so can be defined as two regions of interest, the nodal and antinodal points.		The antinodal point is where all the movement takes place as the water rises and falls, creating a series of peaks and troughs. Between these antinodal points are the nodal points where no vertical movement takes place. An incoming wave has an almost uniform height but when it collides with a standing edge wave, this is changed. If it collides with a peak, then the wave height is increased and if it collides with a trough, then its height is decreased. In the diagram on the right, the two waves cancel each other out, creating a flat surface. However, this is a highly simplified version of events. The incoming wave has the same wave period as the edge wave, so the incoming wave changes from a peak to a trough over the same period as it takes the standing wave to change so they keep the same pattern. These are known as synchronous waves and are very uncommon.		The more common standing edge waves are subharmonic and these can have a wave period twice that of the incoming wave. This produces a far more complex system of waves as by the time the incoming wave has completed one cycle from peak to trough, the standing edge waves have done two. So what started as the peak of a standing edge wave within the trough of the incoming wave will change to a trough before the incoming wave has changed so what was initially being given a boost in height now experiences a drop. Essentially what this means is that there are a regularly spaced series of peaks and troughs along the length on the incoming wave that are caused by its interaction with the standing edge waves and it is these that caused the development of beach cusps.		In areas where the wave height has been increased, the wave now has more power and so can erode more and in areas where the wave height has been decreased, the wave now has less power and so will not erode as much. This is what forms the cusps as the areas with high erosion become the embayments of the cusp and the areas with low erosion become the horns.		The problem with the standing edge wave theory is that it would only account for the initial formation of the cusp and not their continued growth afterwards because as the cusp increases in size the amplitude of the edge wave decreases to the point where it is no longer a factor.		This theory was initially dismissed due to complications with it but by using more advanced computer simulations, it has been developed to the point where it now provides a reasonable alternative to the standing edge wave theory. The theory has two main points that seek to explain the formation of regularly spaced beach cusps.		The first is that positive feedback between the morphology of the beach and the flow of the water creates relief patterns. On a flat beach, surface areas will develop with a slightly lower relief than their surroundings. Areas with lower relief attract and accelerate water particles, which means they have more energy and the area is eroded further. Through positive feedback, the area becomes more and more eroded, and this creates the embayment. The development of these areas of lower relief causes mean beach level to be lowered and so areas that were initially on the level are now below the average and as such, are now areas of higher relief. Areas of higher relief slow the water down and sediment is deposited on top of them, which increases their impact. This creates the horns.		The uniform spacing of cusps is caused by the communication of surface gradients along the beach by the smoothing of the beach surface as the beach tries to rearrange itself to reduce variations in the plane.		The second main point about the regular spacing of cusps is that negative feedback will decrease the amount of net erosion and deposition within a well-formed cusp. As the wave strikes the beach, it will first come into contact with the cusp horns, which will slow the water down. This causes it to lose energy and some of the heavier sediment that it is carrying will be deposited. The loss of this sediment, however, gives the water extra energy, and it uses this to remove sediment from the embayment on the backwash.		The problem with this theory is that this method of cusp formation would take time and if you were observing their formation, then you would see a number of random cusps form along the beach, which then slowly spread along the shore as they even out in size, with small cusps joining together and larger cusps being separated in two. But in the field, cusps form a regular pattern almost instantly and they all appear at the same time.		In recent years, there has been considerable debate about whether beach cusp formation is associated with the presence of standing edge waves (standing edge wave theory), results from self-organizing feedback between changing topography and swash motion (self-organization theory) or is attributable to a number of other less popular mechanisms.		The National Centre of Scientific Research in France, collected a large amount of data from laboratory experiments and field studies, published over the last 50 years to test the predictions of the two main cusp forming hypotheses. These analyses, using more data than previous attempts, confirm that there is a possible link between cusp development and both edge waves and swash-sediment feedback, and that it is not possible to produce conclusive support for one theory above the other with the simple measurements that have been made previously.[2]		The Naval Research Laboratory, the corporate research laboratory for the United States Navy and Marine Corps carried out nearly nine years of video imagery from Duck, North Carolina to determine the timing of cusp formation (to within half a day) and the distances separating consecutive cusp horns (to within half a metre). Supplementary data provided by nearshore instrumentation and surveying vehicles was used to document the environmental conditions during cusp development.		These extensive observations conclusively demonstrate that cusps at this location develop, following storms during the transition from high energy to low energy wave conditions as the wave angle approaches normal incidence. A peculiar suggestion of hysteresis within the cusp spacing time series was observed and may suggest that existing theories of cusp formation need to be reformulated.[3]		
Sanditon (1817) is an unfinished novel by the English writer Jane Austen. In January 1817, Austen began work on a new novel she called The Brothers, later titled Sanditon upon its first publication in 1925, and completed twelve chapters before stopping work in mid-March 1817, probably because her illness prevented her from continuing.[1]						The novel centers on Charlotte Heywood, the eldest of the daughters still at home in the large family of a country gentleman from Willingden, Sussex. The narrative opens when the carriage of Mr. and Mrs. Parker of Sanditon topples over on a hill near the Heywood home. Because Mr. Parker is injured in the crash, and the carriage needs repairs, the Parkers stay with the Heywood family for a fortnight. During this time, Mr. Parker talks fondly of Sanditon, a town which until a few years before had been a small, unpretentious fishing village. With his business partner, Lady Denham, Mr. Parker hopes to make Sanditon into a fashionable seaside resort. Mr. Parker's enormous enthusiasm for his plans to improve and modernise Sanditon has resulted in the installation of bathing machines and the construction of a new home for himself and his family near the seashore. Upon repair of the carriage and improvement to Mr. Parker's foot, the Parkers return to Sanditon, bringing Charlotte with them as their summer guest.		Upon arrival in Sanditon, Charlotte meets the inhabitants of the town. Prominent among them is Lady Denham, a twice-widowed woman who received a fortune from her first husband and a title from her second. Lady Denham lives with her poor niece Clara Brereton, who is a sweet and beautiful, yet impoverished, young lady. Also living in Sanditon are Sir Edward Denham and his sister Esther, Lady Denham's nephew and niece by her second husband. The siblings are poor and are thought to be seeking Lady Denham's fortune. Sir Edward is described as a silly and very florid man, though handsome.		After settling in with the Parkers and encountering the various neighbours, Charlotte and Mr. and Mrs. Parker are surprised by a visit from Mr. Parker's two sisters and younger brother, all of whom are self-declared invalids. However, given their level of activity and seeming strength, Charlotte quickly surmises that their complaints are invented. Diana Parker has come on a mission to secure a house for a wealthy family from the West Indies, although she has not specifically been asked for her aid. She also brings word of a second large party, a girls' school, which is intending to summer at Sanditon. This news causes a stir in the small town, especially for Mr. Parker, whose fondest wish is the promotion of tourism in the town.		With the arrival of Mrs. Griffiths to Sanditon, it soon becomes apparent that the family from the West Indies and the girls' school group are one and the same. The visitors consist of Miss Lambe, a "half mulatto" [2] rich young woman of about seventeen from the West Indies, and the two Miss Beauforts, common English girls. In short order, Lady Denham calls on Mrs. Griffiths to be introduced to Miss Lambe, the very sickly and very rich heiress that she intends her nephew Sir Edward to marry.		A carriage unexpectedly arrives bearing Sidney Parker, the second eldest Parker brother. He will be staying in town for a few days with two friends who will join him shortly. Sidney Parker is around 27 or 28 and Charlotte finds him very good looking with a decided air of fashion.		The book fragment ends when Mrs. Parker and Charlotte visit Sanditon House, Lady Denham's residence. There Charlotte spots Clara Brereton seated with Sir Edward Denham at her side having an intimate conversation in the garden and surmises that they must have a secret understanding. When they arrive inside, Charlotte observes that a large portrait of Sir Henry Denham hangs over the fireplace, whereas Lady Denham's first husband, who owned Sanditon House, only gets a miniature in the corner—obliged to sit back in his own house and see the best place by the fire constantly occupied by Sir Henry Denham.		The people of "modern Sanditon", as Austen calls it, have moved out of the "old house – the house of [their] forefathers" and are busily constructing a new world in the form of a modern seaside commercial town. The town of Sanditon is probably based on Worthing, where Austen stayed in late 1805 when the resort was first being developed;[3][4] or on Eastbourne;[5] or on Bognor Regis, whose founder Richard Hotham was the inspiration for Mr Parker (and the town contained a library at that time as described in the book).[6][7] The town is less of an actual reality than it is an ideal of the inhabitants – one that they express in their descriptions. These inhabitants have a conception of the town's identity and of the way in which this identity should be spread to, and appreciated by, the world:		Because Austen completed setting the scene for Sanditon, it has been a favourite of "continuators" – later writers who try to complete the novel within Austen's vision while emulating her style. Such "completed" versions of Sanditon include:		
A stack or sea stack is a geological landform consisting of a steep and often vertical column or columns of rock in the sea near a coast, formed by wave erosion.[1] Stacks are formed over time by wind and water, processes of coastal geomorphology.[2] They are formed when part of a headland is eroded by hydraulic action, which is the force of the sea or water crashing against the rock. The force of the water weakens cracks in the headland, causing them to later collapse, forming free-standing stacks and even a small island. Without the constant presence of water, stacks also form when a natural arch collapses under gravity, due to sub-aerial processes like wind erosion. Erosion causes the arch to collapse, leaving the pillar of hard rock standing away from the coast—the stack. Eventually, erosion will cause the stack to collapse, leaving a stump. Stacks can provide important nesting locations for seabirds, and many are popular for rock climbing.		Isolated steep-sided, rocky oceanic islets, typically of volcanic origin, are also loosely called "stacks" or "volcanic stacks".		Stacks typically form in horizontally-bedded sedimentary or volcanic rocks, particularly on limestone cliffs. These rock types' medium hardness means medium resistance to abrasive and attritive erosion. A more resistant layer may form a capstone. (Cliffs with weaker rock—such as clay—tend to slump and erode too quickly to form stacks, while harder rocks such as granite erode in different ways.)		The formation process usually begins when the sea attacks small cracks in a headland and opens them. The cracks then gradually get larger and turn into a small cave. When the cave wears through the headland, an arch forms. Further erosion causes the arch to collapse, leaving the pillar of hard rock standing away from the coast—the stack. Eventually, erosion will cause the stack to collapse, leaving a stump. This stump usually forms a small rock island, low enough for a high tide to submerge.		Some stacks last for a very long time—possibly because they do not get submerged easily.		
A volcanic arc is a chain of volcanoes formed above a subducting plate,[1] positioned in an arc shape as seen from above. Offshore volcanoes form islands, resulting in a volcanic island arc. Generally, volcanic arcs result from the subduction of an oceanic tectonic plate under another tectonic plate, and often parallel an oceanic trench. The oceanic plate is saturated with water, and volatiles such as water drastically lower the melting point of the mantle. As the oceanic plate is subducted, it is subjected to greater and greater pressures with increasing depth. This pressure squeezes water out of the plate and introduces it to the mantle. Here the mantle melts and forms magma at depth under the overriding plate. The magma ascends to form an arc of volcanoes parallel to the subduction zone.		These should not be confused with hotspot volcanic chains, where volcanoes often form one after another in the middle of a tectonic plate, as the plate moves over the hotspot, and so the volcanoes progress in age from one end of the chain to the other. The Hawaiian Islands form a typical hotspot chain; the older islands (tens of millions of years old) to the northwest are smaller and more lush than the recently created (400,000 years ago) Hawaii island itself, which is more rocky. Hotspot volcanoes are also known as "intra-plate" volcanoes, and the islands they create are known as Volcanic Ocean Islands. Volcanic arcs do not generally exhibit such a simple age-pattern.		There are two types of volcanic arcs:		In some situations, a single subduction zone may show both aspects along its length, as part of a plate subducts beneath a continent and part beneath adjacent oceanic crust.		(The term "volcanic arc" is often confused with the term "island arc". The former is a series of volcanoes, but not necessarily offshore. The latter is a series of islands, not necessarily composed solely of volcanoes.)		Volcanoes are present in almost any mountain belt, but this does not make it a volcanic arc. Often there are isolated, but impressively huge volcanoes in a mountain belt. For instance, Vesuvius and the Etna volcanoes in Italy are part of separate but different kinds of mountainous volcanic ensembles.		The active front of a volcanic arc is the belt where volcanism develops at a given time. Active fronts may move over time (millions of years), changing their distance from the oceanic trench as well as their width.						In the subduction zone, loss of water from the subducted slab induces partial melting of the overriding mantle and generates low-density, calc-alkaline magma that buoyantly rises to intrude and be extruded through the lithosphere of the overriding plate. This loss of water is due to the destabilization of the mineral chlorite at approximately 40–60 km depth.[2][3] This is the reason for island arc volcanism at consistent distances from the subducting slab: because the temperature-pressure conditions for flux-melting volcanism due to chlorite destabilization will always occur at the same depth, the distance from the trench to the arc volcanoes is determined only by the dip angle of the subducting slab.		On the subducting side of the island arc is a deep and narrow oceanic trench, which is the trace at the Earth’s surface of the boundary between the downgoing and overriding plates. This trench is created by the gravitational pull of the relatively dense subducting plate pulling the leading edge of the plate downward. Multiple earthquakes occur along this subduction boundary with the seismic hypocenters located at increasing depth under the island arc: these quakes define the Wadati–Benioff zones. The volcanic arc forms when the subducting plate reaches a depth of about 100 km.		Ocean basins that are being reduced by subduction are called 'remnant oceans' as they will slowly be shrunken out of existence and crushed in the subsequent orogenic collision. This process has happened over and over in the geologic history of the Earth.		In the rock record, volcanic arcs can be seen as the volcanic rocks themselves, but because volcanic rock is easily weathered and eroded, it is more typical that they are seen as plutonic rocks, the rocks that formed underneath the arc (e.g. the Sierra Nevada batholith), or in the sedimentary record as lithic sandstones.		Cascade Volcanic Arc, a continental volcanic arc		The Aleutian Arc, with both oceanic and continental parts.		Two classic examples of oceanic island arcs are the Mariana Islands in the western Pacific Ocean and the Lesser Antilles in the western Atlantic Ocean. The Cascade Volcanic Arc in western North America and the Andes along the western edge of South America are examples of continental volcanic arcs. The best examples of volcanic arcs with both sets of characteristics are in the North Pacific, with the Aleutian Arc consisting of the Aleutian Islands and their extension the Aleutian Range on the Alaska Peninsula, and the Kuril-Kamchatka Arc comprising the Kuril Islands and southern Kamchatka Peninsula.		
Cobblestone is a natural building material based on cobble-sized stones, and is used for pavement roads, streets, and buildings.		In England, it was commonplace since ancient times for flat stones with a flat narrow edge to be set on edge to provide an even paved surface. This was known as a 'pitched' surface and was common all over Britain, as it did not require rounded pebbles. Pitched surfaces predate the use of regularly-sized granite setts by more than a thousand years. Such pitched paving is quite distinct from that formed from rounded stones, although both forms are commonly referred to as 'cobbled' surfaces. Most surviving genuinely old 'cobbled' areas are in reality pitched surfaces. A cobbled area is known as a "causey", "cassay" or "cassie" in Scots (probably from causeway).[1]		Setts are often idiomatically[2] referred to as "cobbles", although a sett is distinct from a cobblestone by being quarried or shaped to a regular form, whereas cobblestone is generally of a naturally occurring form.[3]						Cobblestones are typically either set in sand or similar material, or are bound together with mortar. Paving with cobblestones allows a road to be heavily used all year long. It prevents the build-up of ruts often found in dirt roads. It has the additional advantage of not getting muddy in wet weather or dusty in dry weather. Shod horses are also able to get better traction on stone cobbles, pitches or setts than tarmac/asphalt. The fact that carriage wheels, horse hooves and even modern automobiles make a lot of noise when rolling over cobblestone paving might be thought a disadvantage, but it has the advantage of warning pedestrians of their approach. In England, the custom was to strew the cobbles outside the house of a sick or dying person with straw to dampen the sound.		Cobblestones set in sand have the environmental advantage of being permeable paving, and of moving rather than cracking with movements in the ground.		Cobblestones were largely replaced by quarried granite setts (also known as Belgian block[4]) in the nineteenth century. The word cobblestone is often wrongly used to describe such treatment. Setts were relatively even and roughly rectangular stones that were laid in regular patterns. They gave a smoother ride for carts than cobbles, although in heavily used sections, such as in yards and the like, the usual practice was to replace the setts by parallel granite slabs set apart by the standard axle length of the time.		Cobblestoned and "setted" streets gradually gave way to macadam roads, and later to tarmac, and finally to asphalt concrete at the beginning of the 20th century. However, cobble­stones are often retained in historic areas, even for streets with modern vehicular traffic. Many older villages and cities in Europe are still paved with cobblestones or pitched. In recent decades, cobblestones have become a popular material for paving newly pedestrianised streets in Europe. In this case, the noisy nature of the surface is an advantage as pedestrians can hear approaching vehicles. The visual cues of the cobblestones also clarify that the area is more than just a normal street.[5] The use of cobblestones/setts is also considered to be a more "upmarket" roadway solution, having been described as "unique and artistic" compared to the normal asphalt road environment.[6]		In older U.S. cities such as Philadelphia, Boston, Pittsburgh,[4] New York City, Chicago, San Francisco, New Castle, Portland (Maine), Baltimore, Charleston, and New Orleans, many of the older streets are paved in cobblestones and setts (mostly setts); however, many such streets have been paved over with asphalt, which can crack and erode away due to heavy traffic, thus revealing the original stone pavement.		In some places such as Saskatoon, Saskatchewan, Canada, as late as the 1990s some busy intersections still showed cobblestones through worn down sections of pavement. In Toronto streets using setts were used by streetcar routes and disappeared by the 1980s, but are still found in the Distillery District.		Many cities in Latin America, such as Buenos Aires, Argentina; Zacatecas and Guanajuato, in Mexico; Old San Juan, Puerto Rico; Philippines, Vigan; and Montevideo, Uruguay, are well known for their many cobblestone streets, which are still operational and in good condition. They are still maintained and repaired the traditional manner, by placing and arranging granite stones by hand.		In the Czech Republic, there are old cobblestone paths with colored marbles and limestones. The design with three colors (red/limestone, black/limestone, white/marble) has a long tradition in Bohemia. The cubes of the old ways are handmade.		In the Finger Lakes Region of New York State, the retreat of the glaciers during the last ice age left numerous small, rounded cobblestones available for building. Pre-Civil War architecture in the region made heavy use of cobblestones for walls. Today, the fewer than 600 remaining cobblestone buildings are prized as historic locations, most of them private homes. They are clustered south of Lake Ontario, between Buffalo and Syracuse. There is also a cluster of cobblestone buildings in the Town of Paris, Ontario. In addition to homes, cobblestones were used to build barns, stagecoach taverns, smokehouses, stores, churches, schools, factories, and cemetery markers. The history of building with cobblestones and 17 driving tours to see the remaining structures are found in "Cobblestone Quest - Road Tours of New York's Historic Buildings".		The only public cobblestone building is the Alexander Classical School, located in Alexander, New York.		In cycling road races, cobblestones are used as an additional difficulty for the riders. It requires a certain skill to ride cobblestones efficiently, without falling or getting a flat tire. Tour of Flanders and Paris–Roubaix are notable cobbled classics.		Detail of cobblestone west wall of 1834 Universalist Church in Cobblestone Historic District, Childs, New York.		Cobblestone road from Guzów to Oryszew, Poland				
Jane Austen (/ˈdʒeɪn ˈɒstɪn/; 16 December 1775 – 18 July 1817) was an English novelist known primarily for her six major novels, which interpret, critique and comment upon the British landed gentry at the end of the 18th century. Austen's plots often explore the dependence of women on marriage in the pursuit of favourable social standing and economic security. Her works critique the novels of sensibility of the second half of the 18th century and are part of the transition to 19th-century literary realism.[2][b]		With the publications of Sense and Sensibility (1811), Pride and Prejudice (1813), Mansfield Park (1814) and Emma (1815), she achieved success as a published writer. She wrote two additional novels, Northanger Abbey and Persuasion, both published posthumously in 1818, and began another, eventually titled Sanditon, but died before its completion. Her novels have rarely been out of print, although they were published anonymously and brought her little fame during her lifetime.		A significant transition in her posthumous reputation occurred in 1833, when her novels were republished in Richard Bentley's Standard Novels series, illustrated by Ferdinand Pickering, and sold as a set.[4] They gradually gained wider acclaim and popular readership. In 1869, fifty-two years after her death, her nephew's publication of A Memoir of Jane Austen introduced a compelling version of her writing career and supposedly uneventful life to an eager audience.		Austen has inspired a large number of critical essays and literary anthologies. Her novels have inspired many films, from 1940's Pride and Prejudice to more recent productions like Sense and Sensibility (1995) and Love & Friendship (2016).		Jane Austen's use of biting irony, along with her realism and social commentary have earned her great and historical importance to critics and scholars.						There is little biographical information about Jane Austen's life except the few letters that survive and the biographical notes her family members wrote.[5] During her lifetime Austen wrote approximately 3,000 letters but only about 160 survive.[6] Many of the letters were written to Austen's older sister Cassandra, who in 1843 burned the greater part of them and cut pieces out of those she kept. Ostensibly Cassandra destroyed or censored her sister's letters to prevent their falling into the hands of relatives and ensuring that "younger nieces did not read any of Jane Austen's sometimes acid or forthright comments on neighbors or family members".[7][c] Cassandra believed that in the interest of tact and Jane's penchant for forthrightness, these details should be destroyed. The paucity of record of Austen's life leaves modern biographers little to work with.[8]		The situation was compounded as successive generations of the family expunged and sanitized the already opaque details of Austen's biography. The heirs of Jane's brother, Admiral Francis Austen, destroyed more letters; details were excised from the "Biographical Notice" her brother wrote in 1818; and family details continued to be elided or embellished in her nephew's A Memoir of Jane Austen, published in 1869, and in William and Richard Arthur Austen-Leigh's biography Jane Austen: Her Life and Letters, published in 1913.[9] The legend the family and relatives created reflects their biases in favour of "good quiet Aunt Jane", portraying a woman whose domestic situation was happy and whose family was the mainstay of her life.[5] Austen scholar Jan Fergus explains that modern biographies tend to include details excised from the letters and family biographical materials, but that the challenge is to avoid the polarising view that Austen experienced periods of deep unhappiness and was "an embittered, disappointed woman trapped in a thoroughly unpleasant family."[10]		Jane Austen was born in Steventon, Hampshire, on 16 December 1775. She was born a month later than her parents expected; her father wrote of her arrival in a letter that her mother "certainly expected to have been brought to bed a month ago". He added that her arrival was particularly welcome as "a future companion to her sister".[11] The winter of 1776 was particularly harsh and it was not until 5 April that she was baptised at the local church with the single name Jane.[12]		For much of Jane's life, her father, George Austen (1731–1805) served as the rector of the Anglican parishes at Steventon, and a nearby Deane.[13][d] He came from an old, respected, and wealthy family of wool merchants. Over the centuries as each generation of eldest sons received inheritances their wealth was consolidated, and George's branch of the family fell into poverty. He and his two sisters were orphaned as children and had to be taken in by relatives. His sister Philadelphia went to India to find a husband and George entered St John's College, Oxford on a fellowship, where he most likely met Cassandra Leigh (1739–1827).[15] She came from the prominent Leigh family; her father was rector at All Souls College, Oxford, where she grew up among the gentry. Her eldest brother James inherited a fortune and large estate from his great-aunt Perrot, with the only condition that he change his name to Leigh-Perrot.[16]		George and Cassandra exchanged miniatures in 1763 and probably were engaged around that time.[18] George received the living for the Steventon parish from the wealthy husband of his second cousin, Thomas Knight, who owned Steventon and its associated farms, one of which the Austen family rented to live in.[19] Two months after Cassandra's father died they married on 26 April 1764 at St Swithin's Church in Bath, by license, in a simple ceremony. They left for Hampshire the same day.[20]		Their income was modest, with George's small per annum living; Cassandra brought the expectation of a small inheritance at the time of her mother's death to the marriage.[21] They took up temporary residence at the nearby Deane rectory until Steventon, a 16th century house in disrepair, underwent necessary renovations. Cassandra gave birth to three children while living at Deane: James in 1765, George in 1766, and Edward in 1767.[22] Her custom was to keep an infant at home for several months and then placed it with Elizabeth Littlewood, a woman living nearby to nurse and raise for twelve to eighteen months.[23]		In 1768 the family finally took up residence in Steventon. Henry was the first child to born there, in 1771.[24] At about this time Cassandra could no longer ignore that George was developmentally disabled. He was subject to seizures, may have been deaf and dumb, and she chose to send him out to be fostered.[25] In 1773, Cassandra was born, followed by Francis in 1774, and Jane in 1775.[26]		According to Honan, life in the Austen home was lived in "an open, amused, easy intellectual atmosphere" where the ideas of those with whom the Austens might disagree politically or socially were considered and discussed.[27] The family relied on the patronage of their kin and hosted visits from numerous family members.[28] Cassandra Austen spent the summer of 1770 in London with George's sister, Philadelphia and her daughter Eliza, accompanied by his other sister, Mrs Walter and her daughter Philly.[29][e] Philadelphia and Eliza Hancock were, according to Le Faye, "the bright comets flashing into an otherwise placid solar system of clerical life in rural Hampshire, and the news of their foreign travels and fashionable London life, together with their sudden descents upon the Steventon household in between times, all helped to widen Jane's youthful horizon and influence her later life and works."[30]		Cassandra Austen's cousin Thomas Leigh visited a number of times in the 1770s and '80s, inviting young Cassie to visit them in Bath in 1781. The first mention of Jane occurs in family documents on her return, "... and almost home they were when they met Jane & Charles, the two little ones of the family, who had to go as far as New Down to meet the chaise, & have the pleasure of riding home in it."[31] Le Faye writes that, "Mr Austen's predictions for his younger daughter were fully justified. Never were sisters more to each other than Cassandra and Jane; while in a particularly affectionate family there seems to have been a special link between Cassandra and Edward on the one hand, and between Henry and Jane on the other."[32]		From 1773 until 1796, George Austen supplemented this income by farming and by teaching three or four boys at a time, who boarded at his home.[33]		In 1783 Jane and Cassandra were sent to Oxford to be educated by Mrs Ann Cawley who took them with her to Southampton when she moved there later in the year. In the autumn both girls were sent home when they caught typhus and Jane nearly died.[34] Austen was from then home educated, until she attended boarding school in Reading with her sister from early in 1785 at the Abbey School House, ruled by Mrs La Tournelle, who possessed a cork leg and a passion for theatre.[35] The school curriculum probably included some French, spelling, needlework, dancing and music and, perhaps, drama. The sisters returned home before December 1786 because the school fees for the two girls were too high for the Austens family.[36] After 1786, Austen "never again lived anywhere beyond the bounds of her immediate family environment".[37]		The remainder of her education came from reading, guided by her father and brothers James and Henry.[38] Irene Collins believes that Austen "used some of the same school books as the boys" her father tutored.[39] Austen apparently had unfettered access both to her father's library and that of a family friend, Warren Hastings. Together these collections amounted to a large and varied library. Her father was also tolerant of Austen's sometimes risqué experiments in writing, and provided both sisters with expensive paper and other materials for their writing and drawing.[40]		Private theatricals were an essential part of Austen's education. From her early childhood, the family and friends staged a series of plays in the rectory barn, including Richard Sheridan's The Rivals (1775) and David Garrick's Bon Ton. Jane's eldest brother James wrote the prologues and epilogues and Jane probably joined in these activities, first as a spectator and later as a participant.[41] Most of the plays were comedies, which suggests how Austen's satirical gifts were cultivated.[42] At the age of 12, Jane tried her own hand at dramatic writing; she wrote three short plays during her teenage years.[43]		Beginning at age 11, perhaps earlier, Austen wrote poems and stories for her own and her family's amusement.[44] In these works the details of daily life are exaggerated, common plot devices are parodied, and the "stories are full of anarchic fantasies of female power, licence, illicit behaviour, and general high spirits", according to Janet Todd.[45] Austen later compiled "fair copies" of 29 early works into three bound notebooks, now referred to as the Juvenilia, containing work written between 1787 and 1793. She titled the three notebooks – Volume the First, Volume the Second and Volume the Third – which preserve 90,000 words she wrote during those years.[46] The Juvenilia are often, according to scholar Richard Jenkyns, "boisterous" and "anarchic"; he compares them to the work of 18th-century novelist Laurence Sterne.[47]		Among these works are a satirical novel in letters titled Love and Freindship [sic], written at age 14 in 1790,[48] where she mocked popular novels of sensibility,[49] and The History of England, a manuscript of 34 pages accompanied by 13 watercolour miniatures by her sister, Cassandra. Austen's History parodied popular historical writing, particularly Oliver Goldsmith's History of England (1764).[50] Honan speculates that not long after writing Love and Freindship [sic] in 1789, Austen decided to "write for profit, to make stories her central effort", that is, to become a professional writer. Whenever she made that decision, beginning in about 1793, Austen began to write longer, more sophisticated works.[51]		In August 1792 she started Catharine or the Bower, which presaged her mature work, especially Northanger Abbey; it was left unfinished and the story picked up in Lady Susan, which Todd describes as less prefiguring than Catharine.[52] A year later, she began but abandoned a short play, later titled Sir Charles Grandison or the happy Man, a comedy in 6 acts, which she returned to and completed around 1800. This was a short parody of various school textbook abridgments of Austen's favourite contemporary novel, The History of Sir Charles Grandison (1753), by Samuel Richardson.[53]		Between 1793 and 1795 Austen wrote Lady Susan, a short epistolary novel, usually described as her most ambitious and sophisticated early work.[54] It is unlike any of Austen's other works. Austen biographer Claire Tomalin describes the novella's heroine as a sexual predator who uses her intelligence and charm to manipulate, betray and abuse her lovers, friends and family. Tomalin writes:		Told in letters, it is as neatly plotted as a play, and as cynical in tone as any of the most outrageous of the Restoration dramatists who may have provided some of her inspiration ... It stands alone in Austen's work as a study of an adult woman whose intelligence and force of character are greater than those of anyone she encounters.[55]		According to Janet Todd, the model for the title character may have been Eliza de Feuillide, who inspired Austen with stories of her glamorous life and various adventures. Eliza's French husband was guillotined in 1794; she married Jane's brother Henry Austen in 1797.[28]		Austen sent short pieces of writing to her newborn nieces Fanny Catherine and Jane Anna Elizabeth.[56] There is manuscript evidence that Austen continued to work on these pieces as late as 1809–1811, and that her niece and nephew, Anna and James Edward Austen, made further additions as late as 1814.[57]		She also attended church regularly, socialized frequently with friends and neighbours,[f] and read novels – often of her own composition – aloud with her family in the evenings. Socialising with the neighbours often meant dancing, either impromptu in someone's home after supper or at the balls held regularly at the assembly rooms in the town hall.[58] Her brother Henry later said that "Jane was fond of dancing, and excelled in it".[59]		When Austen was twenty, Tom Lefroy, a neighbour, visited Steventon from December 1795 to January 1796. He had just finished a university degree and was moving to London for training as a barrister. Lefroy and Austen would have been introduced at a ball or other neighbourhood social gathering, and it is clear from Austen's letters to Cassandra that they spent considerable time together: "I am almost afraid to tell you how my Irish friend and I behaved. Imagine to yourself everything most profligate and shocking in the way of dancing and sitting down together."[60]		Austen wrote in her first surviving letter to her sister Cassandra that Lefroy was "very gentlemanlike, good-looking, pleasant young man".[62] She called him her "friend" and explained that on this account Cassandra must be anxious to know more about her new "friend". Five days later in another letter, Austen wrote she expected an "offer" from her "friend" and that "I shall refuse him, however, unless he promises to give away his white coat", going on to write "I will confide myself in the future to Mr Tom Lefroy, for whom I don't give a sixpence" and refuse all others.[62] The next day, Austen wrote: "The day will come on which I flirt my last with Tom Lefroy and when you receive this it will be all over. My tears flow as I write at this melancholy idea".[62]		Halperin cautioned that Austen often satirised popular sentimental romantic fiction in her letters, and some of the statements about Lefroy may have been ironic. However, it is clear that Austen was genuinely attracted to Lefroy and subsequently none of her other suitors ever quite measured up to him.[62] The Lefroy family intervened and sent him away at the end of January. Marriage was impractical, as both Lefroy and Austen must have known. Neither had any money, and he was dependent on a great-uncle in Ireland to finance his education and establish his legal career. If Tom Lefroy later visited Hampshire, he was carefully kept away from the Austens, and Jane Austen never saw him again.[63] In November 1798, Lefroy was still on Austen's mind as she wrote to her sister she had tea with one of his relatives, wanted desperately to ask about him, but could not bring herself to raise the subject.[64]		After finishing Lady Susan, Austen began her first full-length novel Elinor and Marianne. Her sister remembered that it was read to the family "before 1796" and was told through a series of letters. Without surviving original manuscripts, there is no way to know how much of the original draft survived in the novel published anonymously in 1811 as Sense and Sensibility.[65]		Austen began a second novel, First Impressions, in 1796. She completed the initial draft in August 1797, aged 21, (later published as Pride and Prejudice); as with all of her novels, Austen read the work aloud to her family as she was working on it and it became an "established favourite".[66] At this time, her father made the first attempt to publish one of her novels. In November 1797, George Austen wrote to Thomas Cadell, an established publisher in London, to ask if he would consider publishing First Impressions. Cadell returned Mr. Austen's letter, marking it "Declined by Return of Post". Austen may not have known of her father's efforts.[67] Following the completion of First Impressions, Austen returned to Elinor and Marianne and from November 1797 until mid-1798, revised it heavily; she eliminated the epistolary format in favour of third-person narration and produced something close to Sense and Sensibility.[68] In 1797, Austen met her cousin (and future sister-in-law), Eliza de Feullide, a French aristocrat whose first husband the Comte de Feullide had been guillotined, causing her to flee to Britain, where she married Henry Austen.[69] The description of the execution of the Comte de Feullide related by his widow left Austen with an intense horror of the French Revolution that lasted for the rest of her life.[69]		During the middle of 1798, after finishing revisions of Elinor and Marianne, Austen began writing a third novel with the working title Susan – later Northanger Abbey – a satire on the popular Gothic novel.[70] Austen completed her work about a year later. In early 1803, Henry Austen offered Susan to Benjamin Crosby, a London publisher, who paid £10 for the copyright. Crosby promised early publication and went so far as to advertise the book publicly as being "in the press", but did nothing more.[71] The manuscript remained in Crosby's hands, unpublished, until Austen repurchased the copyright from him in 1816.[72]		In December 1800 George Austen unexpectedly announced his decision to retire from the ministry, leave Steventon, and move the family to 4, Sydney Place in Bath.[73] While retirement and travel were good for the elder Austens, Jane Austen was shocked to be told she was moving from the only home she had ever known.[74] An indication of her state of mind is her lack of productivity as a writer during the time she lived at Bath. She was able to make some revisions to Susan, and she began and then abandoned a new novel, The Watsons, but there was nothing like the productivity of the years 1795–1799.[75] Tomalin suggests this reflects a deep depression disabling her as a writer, but Honan disagrees, arguing Austen wrote or revised her manuscripts throughout her creative life, except for a few months after her father died.[76][g]		The years from 1801 to 1804 are something of a blank space for Austen scholars as Cassandra destroyed all of her letters from her sister in this period for unknown reasons.[77] In December 1802 Austen received her only known proposal of marriage. She and her sister visited Alethea and Catherine Bigg, old friends who lived near Basingstoke. Their younger brother, Harris Bigg-Wither, had recently finished his education at Oxford and was also at home. Bigg-Wither proposed and Austen accepted. As described by Caroline Austen, Jane's niece, and Reginald Bigg-Wither, a descendant, Harris was not attractive – he was a large, plain-looking man who spoke little, stuttered when he did speak, was aggressive in conversation, and almost completely tactless. However, Austen had known him since both were young and the marriage offered many practical advantages to Austen and her family. He was the heir to extensive family estates located in the area where the sisters had grown up. With these resources, Austen could provide her parents a comfortable old age, give Cassandra a permanent home and, perhaps, assist her brothers in their careers. By the next morning, Austen realised she had made a mistake and withdrew her acceptance.[78] No contemporary letters or diaries describe how Austen felt about this proposal.[79] In 1814, Austen wrote a letter to her niece, Fanny Knight, who had asked for advice about a serious relationship, telling her that "having written so much on one side of the question, I shall now turn around & entreat you not to commit yourself farther, & not to think of accepting him unless you really do like him. Anything is to be preferred or endured rather than marrying without Affection".[80] The English scholar Douglas Bush wrote that Austen had "had a very high ideal of the love that should unite a husband and wife ... All of her heroines ... know in proportion to their maturity, the meaning of ardent love".[81] A possible autobiographical element in Sense and Sensibility occurs when Elinor Dashwood contemplates that "the worse and most irremediable of all evils, a connection for life" with an unsuitable man.[81]		In 1804, while living in Bath, Austen started but did not complete her novel, The Watsons. The story centres on an invalid and impoverished clergyman and his four unmarried daughters. Sutherland describes the novel as "a study in the harsh economic realities of dependent women's lives".[83] Honan suggests, and Tomalin agrees, that Austen chose to stop work on the novel after her father died on 21 January 1805 and her personal circumstances resembled those of her characters too closely for her comfort.[84]		Her father's relatively sudden death left Jane, Cassandra, and their mother in a precarious financial situation. Edward, James, Henry, and Francis Austen pledged to make annual contributions to support their mother and sisters.[85] For the next four years, the family's living arrangements reflected their financial insecurity. They spent part of the time in rented quarters in Bath before leaving the city in June 1805 for a family visit to Steventon and Godmersham. They moved for the autumn months to the newly fashionable seaside resort of Worthing, on the Sussex coast, where they resided at Stanford Cottage.[h] It was here that Austen is thought to have written her fair copy of Lady Susan and added its "Conclusion". In 1806 the family moved to Southampton, where they shared a house with Frank Austen and his new wife. A large part of this time they spent visiting various branches of the family.[86]		On 5 April 1809, about three months before the family's move to Chawton, Austen wrote an angry letter to Richard Crosby, offering him a new manuscript of Susan if needed to secure the immediate publication of the novel, and requesting the return of the original so she could find another publisher. Crosby replied that he had not agreed to publish the book by any particular time, or at all, and that Austen could repurchase the manuscript for the £10 he had paid her and find another publisher. She did not have the resources to buy the copyright back at that time,[87] but was able to purchase it in 1816.[88]		Around early 1809 Austen's brother Edward offered his mother and sisters a more settled life – the use of a large cottage in Chawton village[i] that was part of Edward's nearby estate, Chawton House. Jane, Cassandra and their mother moved into Chawton cottage on 7 July 1809.[90] Life was quieter in Chawton than it had been since the family's move to Bath in 1800. The Austens did not socialise with gentry and entertained only when family visited. Her niece Anna described the family's life in Chawton as "a very quiet life, according to our ideas, but they were great readers, and besides the housekeeping our aunts occupied themselves in working with the poor and in teaching some girl or boy to read or write."[91]		During her time at Chawton, Jane Austen published four generally well received novels. Through her brother Henry, the publisher Thomas Egerton agreed to publish Sense and Sensibility,[j] which appeared in October 1811. Reviews were favourable and the novel became fashionable among young aristocratic opinion-makers;[93] the edition sold out by mid-1813.[k] Austen's earnings from Sense and Sensibility provided her with some financial and psychological independence.[95] Egerton then published Pride and Prejudice, a revision of First Impressions, in January 1813. He advertised the book widely and it was an immediate success, garnering three favourable reviews and selling well. By October 1813 Egerton was able to begin selling a second edition.[96] Mansfield Park was published by Egerton in May 1814. While Mansfield Park was ignored by reviewers, it was very popular with readers. All copies were sold within six months, and Austen's earnings on this novel were larger than for any of her other novels.[97] Unknown to Austen, her novels were translated into French and published in cheaply produced, pirated editions in France.[98] The literary critic Noel King commented that given the prevailing rage in France at the time was for lush romantic fantasies, it is remarkable that her novels with the emphasis on everyday English life had any sort of a market in France.[99] However, King cautioned that Austen's chief translator in France, Madame Isabelle de Montolieu, had only the most rudimentary knowledge of English, and her translations were more of "imitations" than translations proper, as Montolieu depended upon assistants to provide a summary, which she then translated into an embellished French that often radically altered Austen's plots and characters.[100] The first of the Austen novels to be published that credited her as the author was in France, when Persuasion was published in 1821 as La Famille Elliot ou L'Ancienne Inclination.[101]		Austen learned that the Prince Regent admired her novels and kept a set at each of his residences.[l] In November 1815, the Prince Regent's librarian James Stanier Clarke invited Austen to visit the Prince's London residence and hinted Austen should dedicate the forthcoming Emma to the Prince. Though Austen disliked the Prince Regent, she could scarcely refuse the request.[103] Austen disapproved of the Prince Regent on the account of his womanising, gambling, drinking, spendthrift ways and generally disreputable behaviour.[104] She later wrote Plan of a Novel, according to hints from various quarters (fr), a satiric outline of the "perfect novel" based on the librarian's many suggestions for a future Austen novel.[105] Austen was greatly annoyed by Clarke's often pompous literary advice, and the Plan of A Novel parodying Clarke was intended as her revenge for all of the unwanted letters she had received from the royal librarian.[104]		In mid-1815 Austen moved her work from Egerton to John Murray, a better known London publisher,[m] who published Emma in December 1815 and a second edition of Mansfield Park in February 1816. Emma sold well but the new edition of Mansfield Park did poorly, and this failure offset most of the income from Emma. These were the last of Austen's novels to be published during her lifetime.[107]		While Murray prepared Emma for publication, Austen began The Elliots, later published as Persuasion. She completed her first draft in July 1816. In addition, shortly after the publication of Emma, Henry Austen repurchased the copyright for Susan from Crosby. Austen was forced to postpone publishing either of these completed novels by family financial troubles. Henry Austen's bank failed in March 1816, depriving him of all of his assets, leaving him deeply in debt and losing Edward, James, and Frank Austen large sums. Henry and Frank could no longer afford the contributions they had made to support their mother and sisters.[108]		Austen was feeling unwell by early 1816, but ignored the warning signs. By the middle of that year, her decline was unmistakable, and she began a slow, irregular deterioration.[109] The majority of biographers rely on Dr. Vincent Cope's 1964 retrospective diagnosis and list her cause of death as Addison's disease, although her final illness has also been described as resulting from Hodgkin's lymphoma.[110][n] When her uncle died and left his entire fortune to his wife, effectively disinheriting his relatives, she suffered a relapse, writing, "I am ashamed to say that the shock of my Uncle's Will brought on a relapse ... but a weak Body must excuse weak Nerves".[112]		She continued to work in spite of her illness. Dissatisfied with the ending of The Elliots, she rewrote the final two chapters, which she finished on 6 August 1816.[o] In January 1817 Austen began The Brothers (titled Sanditon when published in 1925), and completed twelve chapters before stopping work in mid-March 1817, probably due to illness.[114] Todd describes Sanditon's heroine, Diana Parker, as an "energetic invalid". In the novel, Austen mocked hypochondriacs and though she describes the heroine as "bilious", five days after abandoning the novel she wrote of herself that she was turning "every wrong colour" and living "chiefly on the sofa".[112] She put down her pen on 18 March 1817, making a note of it.[112]		Austen made light of her condition, describing it as "bile" and rheumatism. As her illness progressed, she experienced difficulty walking and lacked energy; by mid-April she was confined to bed. In May Cassandra and Henry brought her to Winchester for treatment, by which time she suffered agonising pain and welcomed death.[112] Austen died in Winchester on 18 July 1817, at the age of 41. Henry, through his clerical connections, arranged for his sister to be buried in the north aisle of the nave of Winchester Cathedral. The epitaph composed by her brother James praises Austen's personal qualities, expresses hope for her salvation and mentions the "extraordinary endowments of her mind", but does not explicitly mention her achievements as a writer.[115]		After Austen's death, Cassandra, Henry Austen and Murray arranged for the publication of Persuasion and Northanger Abbey as a set.[p] Henry Austen contributed a Biographical Note which for the first time identified his sister as the author of the novels. Tomalin describes it as "a loving and polished eulogy".[117] Sales were good for a year – only 321 copies remained unsold at the end of 1818.[118]		In 1832 Richard Bentley purchased the remaining copyrights to all of her novels, and over the following winter published five illustrated volumes as part of his Standard Novels series. In October 1833, Bentley released the first collected edition of her works. Since then, Austen's novels have been continuously in print.[119]		Austen's works critique the sentimental novels of the second half of the 18th century and are part of the transition to 19th-century literary realism.[120][q] The earliest English novelists, Richardson, Henry Fielding and Tobias Smollett, were followed by the school of sentimentalists and romantics such as Walter Scott, Horace Walpole, Clara Reeve, Ann Radcliffe, Laurence Sterne and Oliver Goldsmith, whose style and genre Austen rejected, returning the novel on a "slender thread" to the tradition of Richardson and Fielding for a "realistic study of manners".[121] In the mid-20 century, literary critics F. R. Leavis and Ian Watt placed her in the tradition of Richardson and Fielding; both believe that she used their tradition of "irony, realism and satire to form an author superior to both".[122]		Walter Scott noted Austen's "resistance to the trashy sensationalism of much of modern fiction – 'the ephemeral productions which supply the regular demand of watering places and circulating libraries'".[123] Yet her rejection of these genres is complex, as evidenced by Northanger Abbey and Emma.[123] Similar to William Wordsworth, who excoriated the modern frantic novel in the "Preface" to his Lyrical Ballads (1800), Austen distances herself from escapist novels; the discipline and innovation she demonstrates is similar to his, and she shows "that rhetorically less is artistically more."[123] She eschewed popular Gothic fiction, stories of terror in which a heroine typically was stranded in a remote location, a castle or abbey (32 novels between 1784 and 1818 contain the word "abbey" in their title). Yet in Northanger Abbey she alludes to the trope, with the heroine, Catherine, anticipating a move to a remote locale. Rather than full-scale rejection or parody, Austen transforms the genre, juxtaposing reality, with descriptions of elegant rooms and modern comforts, against the heroine's "novel-fueled" desires.[124] Nor does she completely denigrate Gothic fiction: instead she transforms settings and situations, such that the heroine is still imprisoned, yet her imprisonment is mundane and real – regulated manners and the strict rules of the ballroom.[125] In Sense and Sensibility Austen presents characters who are more complex than in staple sentimental fiction, according to critic Keymer, who notes that although it is a parody of popular sentimental fiction, "Marianne in her sentimental histrionics responds to the calculating world ... with a quite justifiable scream of female distress."[126]		Richardson's Pamela, the prototype for the sentimental novel, is a didactic love story with a happy ending, written at a time women were beginning to have the right to choose husbands and yet were restricted by social conventions.[128] Austen attempted Richardson's epistolary style, but found the flexibility of narrative more conducive to her realism, a realism in which each conversation and gesture carries a weight of significance. The narrative style utilises free indirect speech – she was the first English novelist to do so extensively – through which she had the ability to present a character's thoughts directly to the reader and yet still retain narrative control. The style allows an author to vary discourse between the narrator's voice and values and those of the characters.[129]		Austen had a natural ear for speech and dialogue, according to scholar Mary Lascelles "Few novelists can be more scrupulous than Jane Austen as to the phrasing and thoughts of their characters."[130] Techniques such as fragmentary speech suggest a character's traits and their tone; "syntax and phrasing rather than vocabulary" is utilised to indicate social variants.[131] Dialogue reveals a character's mood – frustration, anger, happiness – each treated differently and often through varying patterns of sentence structures. When Elizabeth Bennett rejects Darcy, her stilted speech and the convoluted sentence structure reveals that he has wounded her:[132]		From the very beginning, from the first moment I may almost say, of my acquaintance with you, your manners impressing me with the fullest belief of your arrogance, your conceit, and your selfish disdain of the feelings of others, were such as to form that the groundwork of disapprobation, on which succeeding events have built so immovable a dislike. And I had not known you a month before I felt that you were the last man in the world whom I could ever be prevailed on to marry.[133]		Austen's plots highlight women's traditional dependence on marriage to secure social standing and economic security.[134] As an art form, the 18th-century novel lacked the seriousness of its equivalents from the 19th century, when novels were treated as "the natural vehicle for discussion and ventilation of what mattered in life".[135] Rather than delving too deeply into the psyche of her characters, Austen enjoys them and imbues them with humour, according to critic John Bayley. He believes that the well-spring of her wit and irony is her own attitude that comedy "is the saving grace of life".[136] Part of Austen's fame rests on the historical and literary significance that she was the first woman to write great comic novels. Samuel Johnson's influence is evident, in that she follows his advice to write "a representation of life as may excite mirth".[137]		Her humour comes from her modesty and lack of superiority, allowing her most successful characters, such as Elizabeth Bennet, to transcend the trivialities of life, which the more foolish characters are overly absorbed in.[136] Austen used comedy to explore the individualism of women's lives and gender relations, and she appears to have used it to find the goodness in life, often fusing it with "ethical sensibility", creating artistic tension. Critic Robert Polhemus writes, "To appreciate the drama and achievement of Austen, we need to realize how deep was her passion for both reverence and ridicule ... and her comic imagination reveals both the harmonies and the telling contradictions of her mind and vision as she tries to reconcile her satirical bias with her sense of the good."[137]		As Austen's works were published anonymously, they brought her little personal renown. They were fashionable among opinion-makers, but were rarely reviewed.[93] Most of the reviews were short and on balance favourable, although superficial and cautious.[138][139] They most often focused on the moral lessons of the novels.[140] Sir Walter Scott, a leading novelist of the day, contributed one anonymously. Using the review as a platform to defend the then-disreputable genre of the novel, he praised Austen's realism.[141] The other important early review was attributed to Richard Whately in 1821. However, Whately denied having authored the review, which drew favourable comparisons between Austen and such acknowledged greats as Homer and Shakespeare, and praised the dramatic qualities of her narrative. Scott and Whately set the tone for almost all subsequent 19th-century Austen criticism.[142]		Because Austen's novels did not to conform to Romantic and Victorian expectations that "powerful emotion [be] authenticated by an egregious display of sound and colour in the writing",[144] 19th-century critics and audiences preferred the works of Charles Dickens and George Eliot.[145] In a rare sympathetic review, in this case of Emma in 1815, Sir Walter Scott wrote that book displayed "the art of copying from nature as she really exists in the common walks of life, and presenting to the reader, instead of the splendid scenes from an imaginary world, a correct and striking representation of that which is daily taking place around him".[146] Though Scott was positive, Austen's work did not match the prevailing aesthetic values of the Romantic zeitgeist.[146] Her novels were republished in Britain from the 1830s and sold at a steady rate, but they were not bestsellers.[147] The first French critic who paid notice to Austen was Philarète Chasles who completely dismissed her as a writer, giving her two sentences in an 1842 essay on the influence of Sir Walter Scott, calling her a boring, imitative writer who wrote nothing of substance.[148] Apart from Chasles, Austen was almost completely ignored in France until 1878.[148]		Austen had many admiring readers in the 19th century who considered themselves part of a literary elite. Philosopher and literary critic George Henry Lewes expressed this viewpoint in a series of enthusiastic articles published in the 1840s and 1850s.[149] This theme continued later in the century with novelist Henry James, who referred to Austen several times with approval and on one occasion ranked her with Shakespeare, Cervantes, and Henry Fielding as among "the fine painters of life".[150]		The publication of James Edward Austen-Leigh's A Memoir of Jane Austen in 1869 introduced Austen to a wider public as "dear aunt Jane", the respectable maiden aunt. Publication of the Memoir spurred the reissue of Austen's novels – the first popular editions were released in 1883 and fancy illustrated editions and collectors' sets quickly followed.[151] Author and critic Leslie Stephen described the popular mania that started to develop for Austen in the 1880s as "Austenolatry". In 1878, the French critic Léon Boucher published the essay Le Roman Classique en Angleterre, where he called Austen a "genius", which was the first time that epithet had been used in France to describe Austen.[152] The first proper translation of Austen into French that was completely faithful to the original occurred in 1899 when Félix Fénéon translated Northanger Abbey into French as Catherine Moreland.[152] Around the start of the 20th century, members of the literary elite reacted against the popularisation of Austen. They referred to themselves as Janeites in order to distinguish themselves from the masses who did not properly understand her works. For example, Henry James responded negatively to what he described as "a beguiled infatuation" with Austen, a rising tide of public interest that exceeded Austen's "intrinsic merit and interest".[153] The American literary critic A. Walton Litz noted that the "anti-Janites" in the 19th and 20th centuries comprise a formidable literary squad of Mark Twain, Henry James, Charlotte Bronte, D.H. Lawrence and Kingsley Amis, but in "every case the adverse judgement merely reveals the special limitations or eccentricities of the critic, leaving Jane Austen relativity untouched".[154]		Several of Austen's works have been subject to academic study. The first dissertation on Austen was published in 1883, by George Pellew, a student at Harvard University. [155] The first examination came from a 1911 essay by Oxford Shakespearean scholar A. C. Bradley.[156] In his essay, Bradley groups of Austen's novels into "early" and "late" works, a distinction still used by scholars today.[157] The first academic books devoted to Austen in France was Jane Austen by Paul and Kate Rague published in 1914, where the Ragues set out to explain why French critics and readers should take Austen seriously.[152] The same year, Léonie Villard published Jane Austen, Sa Vie et Ses Oeuvres, which was originally her PhD thesis, marking the first time that Austen had subjected to a serious academic study in France.[152] The second examination in English was R. W. Chapman's 1923 edition of Austen's collected works. Not only was it the first scholarly edition of Austen's works, it was also the first scholarly edition of any English novelist. The Chapman text has remained the basis for all subsequent published editions of Austen's works.[158]		With the publication in 1939 of Mary Lascelles's Jane Austen and Her Art, the academic study of Austen took hold.[159] Lascelles's innovative work included an analysis of the books Austen read and the effect of her reading on her work, an extended analysis of Austen's style, and her "narrative art". Concern arose that academics were taking over Austen criticism and that it was becoming increasingly esoteric, a debate that has continued since.[160]		The period since World War II has seen more scholarship on Austen using a diversity of critical approaches, including feminist theory, and perhaps most controversially, postcolonial theory. The continuing disconnection between the popular appreciation of Austen, particularly by modern Janeites, and the academic appreciation of Austen has widened considerably.[161] After the founding of the People's Republic of China in 1949, Austen was in disfavor with the authorities who only wanted Western authors to be published in translation whose work could be presented as representing the West in a negative light, and Austen was regarded as too "frivolous" for this purpose.[162] As hostile as the treatment of Austen was in the 1950s, it paled besides the treatment of her books during the "Great Proletarian Cultural Revolution" in China between 1966–69, when Austen was banned as a "British bourgeois imperialist" author.[163] In the late 1970s, Austen was allowed to be published in China, where her popularity with readers confounded the authorities who had trouble understanding that people sometimes want to read books for enjoyment instead of dialectical purposes.[164] A sign of the way that Austen can still spark debate can be seen when the American English professor Gene Koppel mentioned in a lecture that Austen and her family were "Tories of the deepest dye" [the Tories were the conservative party while the Whigs were the liberal party], a statement which greatly upset many of Koppel's liberal students, who much to his amusement, complained to him how was it possible that Austen was a conservative?.[165] The conservative Koppel noted several feminist authors such as Claudia Johnson and Mollie Sandock were claiming Austen for their own cause.[165] Citing the work of Hans-Georg Gadamer, Koppel argued that different people can and do react to the same work of literature in different ways as art is always a subjective discipline as various people have their standards for evaluating literature.[165] As such, Koppel argued that competing interpretations of Austen's work, provided that they are grounded in readings of her work are all equally valid, and so it is equally possible to see Austen as a feminist critiquing Regency society and as a conservative upholding the values of Regency society.[165]		Austen's novels have resulted in sequels, prequels and adaptations of almost every type, from soft-core pornography to fantasy. From the 19th century, her family members published conclusions to her incomplete novels, and by 2000 there were over 100 printed adaptations.[166] The first dramatic adaptation of Austen was published in 1895, Rosina Filippi's Duologues and Scenes from the Novels of Jane Austen: Arranged and Adapted for Drawing-Room Performance, and Filippi was also responsible for the first professional stage adaptation, The Bennets (1901). [167] The first film adaptation was the 1940 MGM production of Pride and Prejudice starring Laurence Olivier and Greer Garson.[168] BBC television dramatisations since the 1970s have attempted to adhere meticulously to Austen's plots, characterisations and settings.[169] The British critic Robert Irvine noted that in American film adaptations of Austen's novels, starting with the 1940 version of Pride and Prejudice and continuing on to today, class is subtly downplayed as the United States is officially an egalitarian nation where all people are equal and the society of Regency England depicted by Austen that is grounded in a hierarchy based upon the ownership of land and the antiquity of the family name is one that Americans cannot embrace in its entirety.[170]		From 1995 a large number of Austen adaptations began to appear, with Ang Lee's film of Sense and Sensibility, for which screenwriter and star Emma Thompson won an Academy Award, and the BBC's immensely popular TV mini-series Pride and Prejudice, starring Jennifer Ehle and Colin Firth.[171] A 2005 British production of Pride and Prejudice, directed by Joe Wright and starring Keira Knightley and Matthew Macfadyen,[172] was followed in 2007 by ITV's Mansfield Park, Northanger Abbey and Persuasion,[173] and in 2016 by Love & Friendship, a film version of Lady Susan that borrowed the title of Austen's Love and Freindship [sic].[174]		On 19 July 2017 a new £10 banknote was officially issued by the Bank of England, at Winchester Cathedral, but caused "outrage" that the portrait of Austen used on it had been "airbrushed".[175] The note features a quote from the character Caroline Bingley in Pride and Prejudice: "I declare after all there is no enjoyment like reading!"[176] Austen also appears as a 5mm picture on four current £5 notes, as engraved by microartist Graham Short.[177]		Novels		Unfinished fiction		Other works		Juvenilia – Volume the First (1787–1793)[s]		Juvenilia – Volume the Second (1787–1793)		Juvenilia – Volume the Third (1787–1793)		
Charles III (8 December 1818 – 10 September 1889) was Prince of Monaco and Duke of Valentinois from 20 June 1856 to his death. He was the founder of the famous casino in Monte Carlo, as his title in Monegasque and Italian was Carlo III.[1]		He was born in Paris Charles Honoré Grimaldi, the only son of Florestan I of Monaco and Maria Caroline Gibert de Lametz.						Charles was married on 28 September 1846 in Brussels to Countess Antoinette de Mérode-Westerloo. He was succeeded by his son Albert I of Monaco. During his reign, the towns of Menton and Roquebrune, constituting some 80 percent of Monegasque territory, were formally ceded to France, paving the way for formal French recognition of Monaco's independence.		Under Charles III, the Principality of Monaco increased its diplomatic activities; for example, in 1864, Charles III concluded a Treaty of Friendship with the Bey of Tunis, Muhammad III as-Sadiq, which also regulated trade and maritime issues.		He was the 182nd Grand Cross of the Order of the Tower and Sword.		Monte Carlo is named after Charles III. It stands for the "Mount Charles" in Italian.		In his middle years his sight greatly weakened, and by the last decade of his life he had become almost totally blind. He died at Château de Marchais.		On the 1st June 2016, fifteen thousand 2 euro coins were issued by Monaco; commemorating the 150th anniversary of the foundation of Monte Carlo by Charles III[2]		
Silica Silicic oxide Silicon(IV) oxide		Germanium dioxide Tin dioxide Lead dioxide		Silicon sulfide		Silicon dioxide, also known as silica (from the Latin silex), is an oxide of silicon with the chemical formula SiO2, most commonly found in nature as quartz and in various living organisms.[5][6] In many parts of the world, silica is the major constituent of sand. Silica is one of the most complex and most abundant families of materials, existing as a compound of several minerals and as synthetic product. Notable examples include fused quartz, fumed silica, silica gel, and aerogels. It is used in structural materials, microelectronics as component in the food and pharmaceutical industry.		Inhaling finely divided crystalline silica is toxic and can lead to silicosis, bronchitis, lung cancer and systemic autoimmune diseases, such as lupus and rheumatoid arthritis.						In the majority of silicates, the Si atom shows tetrahedral coordination, with four oxygen atoms surrounding a central Si atom. The most common example is seen in the quartzite polymorph.		For example, in the unit cell of α-quartz, the central tetrahedron shares all four of its corner O atoms, the two face-centered tetrahedra share two of their corner O atoms, and the four edge-centered tetrahedra share just one of their O atoms with other SiO4 tetrahedra. This leaves a net average of 12 out of 24 total vertices for that portion of the seven SiO4 tetrahedra that are considered to be a part of the unit cell for silica (see 3-D Unit Cell).		SiO2 has a number of distinct crystalline forms (polymorphs) in addition to amorphous forms. With the exception of stishovite and fibrous silica, all of the crystalline forms involve tetrahedral SiO4 units linked together by shared vertices in different arrangements. Silicon–oxygen bond lengths vary between the different crystal forms, for example in α-quartz the bond length is 161 pm, whereas in α-tridymite it is in the range 154–171 pm. The Si-O-Si angle also varies between a low value of 140° in α-tridymite, up to 180° in β-tridymite. In α-quartz, the Si-O-Si angle is 144°.[8]		Fibrous silica has a structure similar to that of SiS2 with chains of edge-sharing SiO4 tetrahedra. Stishovite, the higher-pressure form, in contrast, has a rutile-like structure where silicon is 6-coordinate. The density of stishovite is 4.287 g/cm3, which compares to α-quartz, the densest of the low-pressure forms, which has a density of 2.648 g/cm3.[9] The difference in density can be ascribed to the increase in coordination as the six shortest Si-O bond lengths in stishovite (four Si-O bond lengths of 176 pm and two others of 181 pm) are greater than the Si-O bond length (161 pm) in α-quartz.[10] The change in the coordination increases the ionicity of the Si-O bond.[11] More importantly, any deviations from these standard parameters constitute microstructural differences or variations, which represent an approach to an amorphous, vitreous, or glassy solid.		The only stable form under normal conditions is alpha quartz, in which crystalline silicon dioxide is usually encountered. In nature, impurities in crystalline α-quartz can give rise to colors (see list). The high-temperature minerals, cristobalite and tridymite, have both lower densities and indices of refraction than quartz. Since the composition is identical, the reason for the discrepancies must be in the increased spacing in the high-temperature minerals. As is common with many substances, the higher the temperature, the farther apart the atoms are, due to the increased vibration energy.[citation needed]		The transformation from α-quartz to beta-quartz takes place abruptly at 573°C. Since the transformation is accompanied by a significant change in volume, it can easily induce fracturing of ceramics or rocks passing through this temperature limit.[citation needed]		The high-pressure minerals, seifertite, stishovite, and coesite, though, have higher densities and indices of refraction than quartz. This is probably due to the intense compression of the atoms occurring during their formation, resulting in more condensed structure.[citation needed]		Faujasite silica is another form of crystalline silica. It is obtained by dealumination of a low-sodium, ultra-stable Y zeolite with combined acid and thermal treatment. The resulting product contains over 99% silica, and has high crystallinity and surface area (over 800 m2/g). Faujasite-silica has very high thermal and acid stability. For example, it maintains a high degree of long-range molecular order or crystallinity even after boiling in concentrated hydrochloric acid.[12]		Molten silica exhibits several peculiar physical characteristics that are similar to those observed in liquid water: negative temperature expansion, density maximum at temperatures ~5000°C, and a heat capacity minimum.[13] Its density decreases from 2.08 g/cm3 at 1950 °C to 2.03 g/cm3 at 2200 °C.[14]		Molecular SiO2 with a linear structure is produced when molecular silicon monoxide, SiO, is condensed in an argon matrix cooled with helium along with oxygen atoms generated by microwave discharge. Dimeric silicon dioxide, (SiO2)2 has been prepared by reacting O2 with matrix isolated dimeric silicon monoxide, (Si2O2). In dimeric silicon dioxide there are two oxygen atoms bridging between the silicon atoms with an Si-O-Si angle of 94° and bond length of 164.6 pm and the terminal Si-O bond length is 150.2 pm. The Si-O bond length is 148.3 pm, which compares with the length of 161 pm in α-quartz. The bond energy is estimated at 621.7 kJ/mol.[15][undue weight? – discuss]		Silica with the chemical formula SiO2 is most commonly found in nature as quartz SiO4, which comprises more than 10% by mass of the earth's crust.[16] In many parts of the world, silica is the major constituent of sand.[citation needed]		Even though it is poorly soluble, silica occurs in many plants. Plant materials with high silica phytolith content appear to be of importance to grazing animals, from chewing insects to ungulates. Silica accelerates tooth wear, and high levels of silica in plants frequently eaten by herbivores may have developed as a defense mechanism against predation.[17][18]		Silica is also the primary component of rice husk ash, which is used, for example, in filtration and cement manufacturing.		For well over a billion years, silicification in and by cells has been common in the biological world. In the modern world it occurs in bacteria, single-celled organisms, plants, and animals (invertebrates and vertebrates). Prominent examples include:		Crystalline minerals formed in the physiological environment often show exceptional physical properties (e.g., strength, hardness, fracture toughness) and tend to form hierarchical structures that exhibit microstructural order over a range of scales. The minerals are crystallized from an environment that is undersaturated with respect to silicon, and under conditions of neutral pH and low temperature (0–40 °C).		Formation of the mineral may occur either within the cell wall of an organism (such as with phytoliths), or outside the cell wall, as typically happens with tests.[clarification needed] Specific biochemical reactions exist for mineral deposition. Such reactions include those that involve lipids, proteins, and carbohydrates.		It is unclear in what ways silica is important in the nutrition of animals. This field of research is challenging because silica is ubiquitous and in most circumstances dissolves in trace quantities only. All the same it certainly does occur in the living body, leaving us with the problem that it is hard to create proper silica-free controls for purposes of research. This makes it difficult to be sure when the silica present has had operative beneficial effects, and when its presence is coincidental, or even harmful. The current consensus is that it certainly seems important in the growth, strength, and management of many connective tissues. This is true not only for hard connective tissues such as bone and tooth but possibly in the biochemistry of the subcellular enzyme-containing structures as well.[19]		An estimated 95% of silicon dioxide produced is consumed in the construction industry, e.g. for the production of Portland cement.[16]		Silica, in the form of sand is used as the main ingredient in sand casting for the manufacture of metallic components in engineering and other applications. The high melting point of silica enables it to be used in such applications.		Crystalline silica is used in hydraulic fracturing of formations which contain tight oil and shale gas.[20]		Silica is the primary ingredient in the production of most glass. The glass transition temperature of pure SiO2 is about 1475 K.[21] When molten silicon dioxide SiO2 is rapidly cooled, it does not crystallize, but solidifies as a glass.		The structural geometry of silicon and oxygen in glass is similar to that in quartz and most other crystalline forms of silicon and oxygen with silicon surrounded by regular tetrahedra of oxygen centers. The difference between the glass and crystalline forms arises from the connectivity of the tetrahedral units: Although there is no long range periodicity in the glassy network ordering remains at length scales well beyond the SiO bond length. One example of this ordering is the preference to form rings of 6-tetrahedra.[22]		Fumed silica also known as pyrogenic silica is a very fine particulate or colloidal form of silicon dioxide. It is prepared by burning SiCl4 in an oxygen-rich hydrogen flame to produce a "smoke" of SiO2.[9]		The majority of optical fibers for telecommunication are also made from silica. It is a primary raw material for many ceramics such as earthenware, stoneware, and porcelain.		Silicon dioxide is used to produce elemental silicon. The process involves carbothermic reduction in an electric arc furnace:[23]		Silica is a common additive in food production, where it is used primarily as a flow agent in powdered foods, or to adsorb water in hygroscopic applications. It is the primary component of diatomaceous earth. Colloidal silica is also used as a wine, beer, and juice fining agent.[16][page needed]		In pharmaceutical products, silica aids powder flow when tablets are formed.[citation needed]		In cosmetics, its useful for its light-diffusing properties and natural absorbency.[citation needed]		Hydrated silica is used in toothpaste as a hard abrasive to remove tooth plaque.		Hydrophobic silica is used as a defoamer component.[where?][citation needed]		In its capacity as a refractory, it is useful in fiber form as a high-temperature thermal protection fabric.[citation needed]		It is used as a thermal enhancement[further explanation needed] compound in the ground source heat pump industry.[citation needed]		Silica is used in the extraction of DNA and RNA due to its ability to bind to the nucleic acids under the presence of chaotropes.[citation needed]		A silica-based aerogel was used in the Stardust spacecraft to collect extraterrestrial particles.[citation needed]		Silicon dioxide is mostly obtained by mining including sand mining and purification of quartz. Quartz is suitable for many purposes, while chemical processing is required to make a purer or otherwise more suitable (e.g. more reactive or fine-grained) product.[citation needed]		Silica fume is obtained as byproduct from hot processes like ferro-silicon production. It is less pure than fumed silica and should not be confused with that product. The production process, particle characteristics and fields of application of fumed silica are all different from those of silica fume.		Precipitated silica or amorphous silica is produced by the acidification of solutions of sodium silicate. The gelatinous precipitate or silica gel,is first washed and then dehydrated to produce colorless microporous silica.[9] Idealized equation involving a trisilicate and sulfuric acid is shown:		Approximately one billion kilograms/year (1999) of silica was produced in this manner, mainly for use for polymer composites – tires and shoe soles.[16]		Thin films of silica grow spontaneously on Silicon Wafers via thermal oxidation, producing a very shallow layer of about 1 nm or 10 Å of so-called native oxide.[24] Higher temperatures and alternative environments are used to grow well-controlled layers of silicon dioxide on silicon, for example at temperatures between 600 and 1200 °C, using so-called dry or wet oxidation with O2		or H2O, respectively.[25][26]		The depth of the layer of silicon which dioxide replaces is 44% of the depth of the silicon dioxide layer produced.[25]		The native oxide layer is beneficial in microelectronics, where it acts as electric insulator with high chemical stability. It can protect the silicon, store charge, block current, and even act as a controlled pathway to limit current flow.[27]		Many routes to silicon dioxide start with silicate esters, the best known being tetraethyl orthosilicate (TEOS). Simply heating TEOS at 680–730 °C gives the dioxide:		Similarly TEOS combusts around 400 °C:		TEOS undergoes hydrolysis via the so-called sol-gel process. The course of the reaction and nature of the product are affected by catalysts, but the idealized equation is:[28]		Being highly stable, silicon dioxide arises from many methods. Conceptually simple, but of little practical value, combustion of silane gives silicon dioxide. This reaction is analogous to the combustion of methane:		However the chemical vapor deposition of silicon dioxide onto crystal surface from silane had been used using nitrogen as a carrier gas at 200-500oC.[29]		Silica is converted to silicon by reduction with carbon.		Fluorine reacts with silicon dioxide to form SiF4 and O2 whereas the other halogen gases (Cl2, Br2, I2) are essentially unreactive.[9]		Silicon dioxide is attacked by hydrofluoric acid (HF) to produce hexafluorosilicic acid:[8]		HF is used to remove or pattern silicon dioxide in the semiconductor industry.		Silicon dioxide acts as a Lux-Flood acid, being able to react with bases under certain conditions. As it does not contain any hydrogen, it cannot act as a Brønsted–Lowry acid. While not soluble in water, some strong bases will react with glass and have to be stored in plastic bottles as a result.[30]		Silicon dioxide dissolves in hot concentrated alkali or fused hydroxide, as described in this idealized equation:[9]		Silicon dioxide will neutralise basic metal oxides (e.g. sodium oxide, potassium oxide, lead(II) oxide, zinc oxide, or mixtures of oxides, forming silicates and glasses as the Si-O-Si bonds in silica are broken successively).[8] As an example the reaction of sodium oxide and SiO2 can produce sodium orthosilicate, sodium silicate, and glasses, dependent on the proportions of reactants:[9]		Examples of such glasses have commercial significance, e.g. soda-lime glass, borosilicate glass, lead glass. In these glasses, silica is termed the network former or lattice former.[8] The reaction is also used in blast furnaces to remove sand impurities in the ore by neutralisation with calcium oxide, forming calcium silicate slag.		Silicon dioxide reacts in heated reflux under dinitrogen with ethylene glycol and an alkali metal base to produce highly reactive, pentacoordinate silicates which provide access to a wide variety of new silicon compounds.[31] The silicates are essentially insoluble in all polar solvent except methanol.		Silicon dioxide reacts with elemental silicon at high temperatures to produce SiO:[8]		The solubility of silicon dioxide in water strongly depends on its crystalline form and is three-four times higher for silica than quartz; as a function of temperature, it peaks around 340°C.[32] This property is used to grow single crystals of quartz in a hydrothermal process where natural quartz is dissolved in superheated water in a pressure vessel that is cooler at the top. Crystals of 0.5–1 kg can be grown over a period of 1–2 months.[8] These crystals are a source of very pure quartz for use in electronic applications.[9]		Silica ingested orally is essentially nontoxic, with an LD50 of 5000 mg/kg (5 g/kg).[16] A 2008 study following subjects for 15 years found that higher levels of silica in water appeared to decrease the risk of dementia. An increase of 10 milligram-per-day of silica in drinking water was associated with a decreased risk of dementia of 11%.[33]		Inhaling finely divided crystalline silica dust can lead to silicosis, bronchitis, or lung cancer, as the dust becomes lodged in the lungs and continuously irritates the tissue, reducing lung capacities.[34] It increases the risk of of systemic autoimmune diseases such as lupus[35] and rheumatoid arthritis compared to expected rates in the general population.[36]		Silica is an occupational hazard for people who do sandblasting, work with products that contain powdered crystalline silica. Amorphous silica, such as fumed silica, may cause irreversible lung damage in some cases, but is not associated with development of silicosis. Children, asthmatics of any age, those with allergies, and the elderly (all of whom have reduced lung capacity) can be affected in less time.[37]		Crystalline silica is an occupational hazard for those working with stone countertops, because the process of cutting and installing the countertops creates large amounts of airborne silica.[38] Crystalline silica used in hydraulic fracturing presents a health hazard to workers.[20]		In the body, crystalline silica particles do not dissolve over clinically relevant periods. Silica crystals inside the lungs can activate the NLRP3 inflammasome inside macrophages and dendritic cells and thereby result in production of interleukin , a highly pro-inflammatory cytokine in the immune system.[39][40][41]		Regulations restricting silica exposure 'with respect to the silicosis hazard' specify that they are concerned only with silica, which is both crystalline and dust-forming.[42][43][44][45][46]		In 2013, the U.S. Occupational Safety and Health Administration reduced the exposure limit to 50µg per cubic meter of air. Prior to 2013 it had allowed 100  µg/m3 and in construction workers even 250 µg/m3.[20] In 2013, OSHA also required "green completion" of fracked wells to reduce exposure to crystalline silica besides restricting the limit of exposure.[20]		SiO2, more so than almost any material, exists in many crystalline forms. It is called polymorphs.		Media related to Silicon dioxide at Wikimedia Commons		
A skerry is a small rocky island, usually defined to be too small for human habitation; it may simply be a rocky reef. A skerry can also be called a low sea stack.[1]		The term skerry is derived from the Old Norse sker, which means a rock in the sea. The Old Norse term sker was brought into the English language via the Scots language word spelled skerrie or skerry. It is a cognate of the Scandinavian languages' words for skerry – Icelandic, Faroese: sker, Danish: skær, Swedish: skär, Norwegian: skjær / skjer, found also in German: Schäre, Finnish: kari, Estonian: skäär, Latvian: šēra, Lithuanian: Šcheras and Russian: шхеры (shkhery). In Scottish Gaelic, it appears as sgeir, e.g. Sula Sgeir, in Irish as sceir, in Welsh as sgeri, and in Manx as skeyr.						Skerries are most commonly formed at the outlet of fjords where submerged glacially formed valleys at right angles to the coast join with other cross valleys in a complex array. In some places near the seaward margins of fjorded areas, the ice-scoured channels are so numerous and varied in direction that the rocky coast is divided into thousands of island blocks, some large and mountainous while others are merely rocky points or rock reefs that menace navigation.		The island fringe of Norway is such a group of glacially formed skerries (called a skjærgård); many of the cross fjords are so arranged that they parallel the coast and provide a protected channel behind an almost unbroken succession of mountainous islands and skerries. By this channel one can travel through a protected passage almost the entire 1,600 km route from Stavanger to North Cape, Norway. The Blindleia is a skerry-protected waterway that starts near Kristiansand in southern Norway, and continues past Lillesand.		The "inside passage" provides a similar route from Seattle, Washington to Skagway, Alaska. Yet another such skerry-protected passage extends from the Straits of Magellan north for 800 km (500 mi) along the west coast of the South American continent.		The Swedish coast along Bohuslän is likewise guarded by skerries. Even the east coast of Sweden, in the Baltic Sea, has many big skärgårdar (archipelagos), notably Stockholm archipelago - Stockholms skärgård.		The southwestern coast of Finland also has a great many skerries; so many, in fact, that they form an archipelago. This area is experiencing post-glacial rebound that connects the rising islands as they break sea level, revealing till deposits and eventually clay bottoms. The skerries exist as small rocky islands before uplift of adjacent terrain changes the classification of this landform into a tombolo.[2]		In the Russian Federation, the best examples are the Minina Skerries, located in the Kara Sea, in the western shores of the Taymyr Peninsula, and the Sumsky Skerries (Sumskiye Shkhery) 64°24′N 35°30′E﻿ / ﻿64.400°N 35.500°E﻿ / 64.400; 35.500, located in the White Sea.		The United Kingdom has a large number of skerries including Staple Island (an Outer Farne Island) in England, a small rocky outcrop near the Fowlsheugh in northeast Scotland and numerous reefs in the Hebrides such as Dubh Artach and Skerryvore.		The most southerly skerries are perhaps the Skrap Skerries off South Georgia.		
A coastal plain is flat, low-lying land adjacent to a seacoast. One of the world's largest coastal plains is located in eastern South America.[1] The Gulf Coastal Plain of North America extends northwards from the Gulf of Mexico along the Lower Mississippi River to the Ohio River, which is a distance of about 500 miles (800 km).		During the Cretaceous time, the central area of the United States was covered by a shallow sea, the Western Interior Seaway, which disappeared as the land rose. Large fossilized aquatic birds called Hesperornis and Ichthyornis, found in western Kansas, indicate that the shallow sea was live with fish so this is known as the coastal plains		Coastal plain				
The Florida East Coast Railway (reporting mark FEC) is a Class II railroad operating in the U.S. state of Florida and since 2007 has been a subsidiary of Railroad Acquisition Holdings, LLC, itself a subsidiary of Fortress Investment Group, LLC.		The FEC was historically a Class I railroad owned by Florida East Coast Industries (FECI) from 2000-2006, FOXX Holdings from 1983-2000, and the St. Joseph Paper Company prior to 1983.		Built primarily in the last quarter of the 19th century and the first decade of the 20th century, the FEC was a project of Standard Oil principal Henry Morrison Flagler. Flagler originally visited Florida to aid with the health issues faced by his first wife, Mary. A key strategist who worked closely with John D. Rockefeller building the Standard Oil Trust, Henry Flagler noted both a lack of services and great potential during his stay at St. Augustine. He subsequently began what amounted to his second career developing resorts, industries, and communities all along Florida's shores abutting the Atlantic Ocean.		The FEC is possibly best known for building the railroad to Key West, completed in 1912. When the FEC's line from the mainland to Key West was heavily damaged by the Labor Day Hurricane of 1935, the State of Florida purchased the remaining right-of-way and bridges south of Dade County, and they were rebuilt into road bridges for vehicle traffic and became known as the Overseas Highway. However, a greater and lasting Flagler legacy was the developments along Florida's eastern coast.		During the Great Depression, control was purchased by heirs of the du Pont family. After 30 years of fragile financial condition, the FEC, under leadership of a new president, Ed Ball, took on the labor unions. Ball claimed the company could not afford the same costs as larger Class 1 railroads and needed to invest saved funds in its infrastructure, fast becoming a safety issue. Using replacement workers, the company, and some of its employees, engaged in one of the longest and more violent labor conflicts of the 20th century, from 1963 until 1977. Ultimately, federal authorities had to intervene to stop the violence, which included bombings, shootings and vandalism. However, the courts ruled in the FEC's favor with regard to the right to employ strikebreakers. During this time, Ball invested heavily in numerous steps to improve its physical plant, installed various forms of automation, was the first US Railroad to operate two man train crews, eliminate cabooses and end all of its passenger services (which were unprofitable) by 1968.		In modern times, the company's primary rail revenues come from its intermodal and rock trains. Since 2007, it has been owned by Fortress Investment Group,[citation needed] which acquired it for over US$3 billion (including non-rail assets). Fortress previously owned conglomerate short line railroad operator RailAmerica, which for a time operated FEC but the two companies never merged; Fortress no longer owns RailAmerica and RailAmerica no longer operates FEC. A former CSX official, James Hertwig, was named as President and Chief Executive Officer of the company effective July 1, 2010.						The Florida East Coast Railway (FEC) was developed by Henry Morrison Flagler, an American tycoon, real estate promoter, railroad developer and John D. Rockefeller's partner in Standard Oil. Formed at Cleveland, Ohio as Rockefeller, Andrews & Flagler in 1867, Standard Oil moved its headquarters in 1877 to New York City. Flagler and his family relocated there as well. He was joined by Henry H. Rogers, another leader of Standard Oil who also became involved in the development of America's railroads, including those on nearby Staten Island, the Union Pacific, and later in West Virginia, where he eventually built the remarkable Virginian Railway to transport coal to Hampton Roads, Virginia.		Flagler's non-Standard Oil interests went in a different direction, however, when in 1878, on the advice of his physician, he traveled to Jacksonville, Florida for the winter with his first wife, Mary, who was quite ill. Two years after she died in 1881, he married Mary's former caregiver, Ida Alice Shourds. After their wedding, the couple traveled to St. Augustine, Florida in 1883. Flagler found the city charming, but the hotel facilities and transportation systems inadequate. He recognized Florida's potential to attract out-of-state visitors. Though Flagler remained on the Board of Directors of Standard Oil, he gave up his day-to-day involvement in the firm in order to pursue his Florida interests.		When Flagler returned to Florida, in 1885 he began building a grand St. Augustine hotel, the Ponce de Leon Hotel. Flagler realized that the key to developing Florida was a solid transportation system, and consequently purchased the 3 ft (914 mm) narrow gauge Jacksonville, St. Augustine and Halifax River Railway (JStA&HR) on December 31, 1885. He also discovered that a major problem facing the existing Florida railway systems was that each operated on different gauge systems, making interconnection impossible. He converted the line to 4 ft 8 1⁄2 in (1,435 mm) standard gauge in 1890 and the small operation was incorporated in 1892.		The earliest predecessor of the FEC was the narrow gauge St. John's Railway, incorporated in 1858, which constructed a now-abandoned line between St. Augustine and Tocoi, a small settlement on the east bank of the St. Johns River, midway between Palatka and Green Cove Springs. In 1883, Henry M. Flagler, now retired from Standard Oil, moved to St. Augustine and built the previously mentioned Ponce de Leon and the Alcazar Hotels and purchased the Casa Monica, just east of the Alcazar, changing the name to Cordova. The East Coast of Florida was relatively undeveloped at that time, and Flagler found it difficult to obtain the construction materials he needed. His purchase of the JStA&HR Railway was intended to make it faster and easier to supply his building projects.		The JStA&HR Railway served the northeastern portion of the state and was the first operation in the Flagler Railroad system. Before Flagler bought the line, the railroad stretched only between South Jacksonville and St. Augustine and lacked a depot sufficient to accommodate travelers to his St. Augustine resorts. Flagler built a modern depot facility as well as schools, hospitals and churches, systematically revitalizing the largely abandoned historic city.		Flagler next purchased three additional existing railroads: the St. John's Railway, the St. Augustine and Palatka Railway, and the St. Johns and Halifax River Railway so that he could provide extended rail service on standard gauge tracks. Through the operation of these three railroads, by spring 1889 Flagler's system offered service from Jacksonville to Daytona. Continuing to develop hotel facilities to entice northern tourists to visit Florida, Flagler bought and expanded the Ormond Hotel, located along the railroad's route north of Daytona in Ormond Beach.		Beginning in 1892, when landowners south of Daytona petitioned him to extend the railroad 80 miles (130 km) south, Flagler began laying new railroad tracks; no longer did he follow his traditional practice of purchasing existing railroads and merging them into his growing rail system. Flagler obtained a charter from the state of Florida authorizing him to build a railroad along the Indian River to Miami, and as the railroad progressed southward, cities such as New Smyrna and Titusville began to develop along the tracks.		By 1894, Flagler's railroad system reached what is today known as West Palm Beach. Flagler constructed the Royal Poinciana Hotel in Palm Beach overlooking the Lake Worth Lagoon. He also built The Breakers Hotel on the ocean side of Palm Beach, and Whitehall, his private 55-room, 60,000 square foot (5,600 m²) winter home. The development of these three structures, coupled with railroad access to them, established Palm Beach as a winter resort for the wealthy members of America's Gilded Age.		Palm Beach was to be the terminus of the Flagler railroad, but during 1894 and 1895, severe freezes hit all of Central Florida, whereas the Miami area remained unaffected, causing Flagler to rethink his original decision not to move the railroad south of Palm Beach. The fable that Julia Tuttle, one of two main landowners in the Miami area along with the Brickell family, sent orange blossoms to Flagler to prove to him that Miami, unlike the rest of the state, was unaffected by the frost is untrue. The fact is, that Mrs. Tuttle wired Mr. Flagler to advise him that "the region around the shores of Biscayne Bay is untouched by the freezes." Mr. Flagler sent his two now famous in Florida history lieutenants, James E. Ingraham and Joseph R. Parrott, to investigate and they brought boxes of truck (produce) and citrus back to Mr. Flagler, who then wired Mrs. Tuttle, asking, "Madam, what is it that you propose?" To convince Flagler to continue the railroad to Miami, both Julia Tuttle and William Brickell offered half of their holdings north and south of the Miami River to Mr. Flagler. Mrs. Tuttle added 50 acres (200,000 m2) for shops and yards if Mr. Flagler would extend his railroad to the shores of Biscayne Bay and build one of his great hotels. An agreement was made and contracts were signed. On September 7, 1895, the name of Flagler's system was changed from the Jacksonville, St. Augustine and Indian River Railway Company to the Florida East Coast Railway Company and incorporated.[1] On April 15, 1896, track reached Biscayne Bay, the site of present-day downtown Miami. At the time, it was a small settlement of less than 50 inhabitants. When the town incorporated, on July 28, 1896, its citizens wanted to honor the man responsible for the city's development by naming it Flagler. He declined the honor, persuading them to retain its old Indian name, Miami. The area was actually previously known as Fort Dallas after the fort built there in 1836 during the Second Seminole War. To further develop the area surrounding the Miami railroad station, Flagler dredged a channel, built streets and The Royal Palm Hotel, instituted the first water and power systems, and financed the town's first newspaper, the Metropolis. Flagler was a great visionary and he can be credited for the development of the entire east coast of Florida. Yet he lacked vision on at least one issue: he felt that Miami would never be more than a fishing village.		As of 1904, Flagler started what everybody considered a folly: the extension of the FEC to Key West which would later be known as the Overseas Railway, at the time considered the eighth wonder of the world and surely the most daring infrastructure ever built exclusively with private funds. The first train—a construction engineers train—arrived in Key West on January 21, 1912, while Mr. Flagler's special train and other passenger trains arrived the next day, January 22, 1912, and that is considered the first day of service on the new route.		The railroad south of West Palm Beach was constructed in phases by the FEC and the predecessor systems. Flagler began his railroad building in 1892. Under Florida's generous land-grant laws passed in 1893, 8,000 acres (3,200 ha) could be claimed from the state for every mile (1.6 km) built. Flagler would eventually claim a total in excess of two million acres (8,000 km²) for building the FEC, and land development and trading would become one of his most profitable endeavors.		Before it became the FEC, the Jacksonville, St. Augustine & Indian River was constructing a line southwards from Daytona Beach in 1894. Fort Pierce was reached on January 29, and West Palm Beach on March 22. Further extension southwards did not begin until June 1895, when a favorable deal was signed with Miami-area business interests. Fort Lauderdale was reached on March 3 of the following year. By April, the construction reached Biscayne Bay, the largest and most accessible harbor on Florida's east coast. Flagler announced in 1904 that the FEC would be extended 128 miles (206 km) to Key West over the ocean. However, in 1906, a powerful hurricane killed 135 of Flagler's workers.[2] The Over-the-Sea Extension was completed in 1912, a mere 16 months prior to Flagler's death, at a cost of $50 million and lives of hundreds of workmen.		Never one to rest on his laurels, Flagler next sought perhaps his greatest challenge: the extension of the Florida East Coast Railway to Key West, a city of almost 20,000 inhabitants located 128 miles (206 km) beyond the end of the Florida peninsula. Flagler became particularly interested in linking Key West to the mainland after the United States announced in 1905 the construction of the Panama Canal. Key West, the United States' closest deep-water port to the canal, could not only take advantage of Cuban and Latin America trade, but the opening of the canal would allow significant trade possibilities with the west.		The construction of the Overseas Railroad required many engineering innovations as well as vast amounts of labor and monetary resources. At one time during construction, four thousand men were employed. During the seven-year construction, three hurricanes threatened to halt the project.		Despite the hardships, the final link of the Florida East Coast Railway to Trumbo Point in Key West was completed in 1912. On January 22 of that year, a proud Henry Flagler rode the first passenger train into Key West, marking the completion of the railroad's oversea connection to Key West and the linkage by railway of the entire east coast of Florida.		One of the reasons Flagler built the Key West Extension was at the time of its conception, Key West was a major coaling station for ship traffic between South America and New York. Flagler thought it would be profitable for coal to be brought by railroad to Key West for coaling those ships. By the time the railroad was finished in 1912 though, the range had been extended on the ships to such a degree that Key West was no longer a stopover for coal.		The Florida Overseas Railroad, also known as the "Key West Extension of the Florida East Coast Railway" was heavily damaged and partially destroyed in the Labor Day Hurricane of 1935. The Florida East Coast Railway was financially unable to rebuild the destroyed sections, and the line was cut back to Florida City. The roadbed and remaining bridges of the extension were sold to the state of Florida, which built the Overseas Highway to Key West, using much of the remaining railway infrastructure. A rebuilt Overseas Highway (U.S. Route 1) taking an alignment that closely follows the Overseas Railroad's original routing, continues to provide a highway link to Key West, ending at the southernmost point in the continental United States.[3]		The Florida East Coast Railway benefitted greatly from the Florida land boom of the 1920s, which led to increased traffic. The Moultrie cutoff was constructed in 1925 which shortened the distance between St. Augustine and Ormond Beach by avoiding the main line's turn towards Palatka (the Moultrie cutoff has since become part of the main line). The main line was also expanded to double track from Jacksonville to Miami in 1926, along with the installation of automatic block signaling (although, a vast majority of the main line would be restored to single track in the early 1970s due to changing rail operations and the absence of passenger operations).[4][5]		The Stock Market Crash of 1929 and Great Depression were harsh on the FEC. The railroad declared bankruptcy and was in receivership by September 1931, 18 years after Flagler's death. Bus service began to be substituted for trains on the branches in 1932. Streamliners plied the rails between 1939 and 1963, including "The Champion" and "The Florida Special" jointly operated with the Atlantic Coast Line. Adding to the woes was the Cuban embargo.		During the Great Depression Edward Ball, who controlled the Alfred I. duPont Testamentary Trust, bought a majority ownership of FEC, buying its bonds on the open market, allowing the FEC to emerge from bankruptcy following protracted litigation with a group of the company's other bondholders, led by S.A. Lynch and associated with the Atlantic Coast Line which had proposed an alternate plan of reorganization. That same year, a labor contract negotiation turned sour. Ball was determined to save the railroad from the bankruptcy that had continued for more than a decade. Ball was certain that if the company didn't become profitable, the equipment and track would deteriorate to the point where some lines would become unsafe or unusable and require partial abandonment.		Ball fought ferociously for the company's right to engage in its own contract negotiations with the railroad unions rather than accept an industry-wide settlement that would traditionally contain featherbedding and wasteful work rules. This led to a prolonged work stoppage by non-operating unions beginning January 23, 1963, and whose picket lines were honored by the operating unions (the train crews).		Because the strike was by the non-operating unions, a Federal judge ordered the railroad to continue observing their work rules, while the railroad was free to change the work rules for the operating unions, who were technically not on strike and thus had no standing in the federal court regarding the strike.		Ball's use of replacement workers to keep the railroad running during the strike led to violence by strikers that included shootings and bombings. Eventually, federal intervention helped quell the violence, and the railroad's right to operate during the strike with replacement workers was affirmed by the United States Supreme Court. As the strike continued, the FEC took numerous steps to improve its physical plant, installed various forms of automation, and drastically cut labor costs. Most of the nation's other railroads did not match these achievements for several years; some still had not as of 2010.[6]		Passenger service became an issue in Florida during the early years of the labor strike, which essentially lasted 14 years, from 1963 to 1977. At the insistence of the City of Miami – which had long fought to get rid of the tracks in the downtown section just north of the county courthouse – Miami's wooden-constructed downtown passenger terminal was demolished by November 1963.[7] Although a new station was planned at NE 36th Street and NE 2nd Avenue,[8] it was never built. Further, while freight trains were operated with non-union and supervisory crews, passenger runs were not reinstated until August 2, 1965, after the City of Miami sued and the Florida courts ruled that the FEC corporate charter required both coach and first class passenger services to be offered. In response, FEC sold "parlour car seating" for first class accommodations in the rear lounge section of a tavern-lounge-observation car. This new state-mandated passenger service consisted of a single diesel locomotive and two streamlined passenger cars, which, in addition to the operating crew, were staffed by a passenger service agent and a coach attendant, who were "non-operating." The mini-streamliner operated all of the way across three previously observed crew districts (Jacksonville to New Smyrna Beach to Fort Pierce to Miami). Following the letter of the law, the train carried no baggage, remains, mail or express; honoured no inter-line tickets or passes; and the only food service was a box lunch (at Cocoa-Rockledge in 1966). On-board beverage service was limited to soft drinks and coffee. Without a station in Miami, the 1950s era station in North Miami became the southern terminus. The service operated six days a week until it was finally discontinued on July 31, 1968.		In 1979, the FEC's mainline was cut back to its current terminus in downtown Miami when a 9.5 mile segment of the mainline between there and Kendall was sold to Miami-Dade Transit, who then built the southern half of Miami's elevated Metrorail system on the former right-of-way.[9] The rest of the former mainline from Kendall south to Homestead and Florida City would remain until 1989, which could still be accessed via the freight bypass through Hialeah (Little River Branch). That segment of the former mainline has since become the South Miami-Dade Busway and the South Dade Rail Trail.		After 23 years under Ball, Raymond Wyckoff took the helm on May 30, 1984. In March 2005, Robert Anestis stepped down as CEO of Florida East Coast Industries after a 4-year stint, allowing Adolfo Henriquez to assume that position, with John D. McPherson, a long-time railroad man, continuing as president of the railway itself. By this time, the railroad had long since made peace with its workers.		In late 2007, in a move surprising to many employees and railroad industry observers alike, the FEC was purchased by the principal investors who also control short line railroad operator RailAmerica. John Giles was named chairman, and David Rohal was named president. Both men were also principals with major responsibilities at RailAmerica as well, although the ownership of FEC and RailAmerica were not linked corporately, and the spinoff of RailAmerica as a publicly traded company did not include FEC.		In May, 2010, James Hertwig was named as President and Chief Executive Officer of the company effective July 1, 2010. Hertwig had recently retired from CSX, most recently having served as president of CSX Intermodal, one of CSX's major operating units.[10]		The Florida East Coast Railway operates from its relocated headquarters in Jacksonville after selling the original General Office Building in St. Augustine to Flagler College in late 2006. Its trains run over nearly the same route developed by Henry Flagler; notably, the Moultrie Cutoff was built in 1925 to shorten the distance south of St. Augustine.		The FEC operations today are dominated by "intermodal" trains and unit rock (limestone) trains. Passenger service was discontinued in 1968 after labor unrest that resulted in considerable incidents of violence.		The company's major income-earning sources are its rock trains, transporting primarily limestone, and intermodal trains. FEC freight trains operate on precise schedules. Trains are not held for missed connections or late loadings. Most of the trains are paired so that they leave simultaneously from their starting points and meet halfway through the run and swap crews, so they are back home at the end of their runs. The FEC pioneered operation with 2 man crews with no crew districts, which they were able to start doing after the 1963 strike. The entire railroad adopted positive train control (PTC) after a fatal 1987 collision caused by a crew not obeying signaling. (PTC is a safety feature long-sought by federal safety officials for all railroads).		FEC has what is called by some a "prime" railroad right-of-way. The heavy weight of the rock trains required very good trackage and bridges. The railroad has mostly 136 pound-per-yard (66 kg/m) continuous-welded rail attached to concrete ties, which sits on a high quality granite roadbed. The entire railroad is controlled by centralized traffic control with constant radio communication. Because the railroad has only minor grades, it takes very little horsepower to pull very long trains at speed. 60 mph (97 km/h) trains are a normal FEC operating standard.		The FEC was already in the freight business only when Amtrak was created and assumed passenger operations of many other U.S. railroads in 1971. Periodically, there has been speculation that the southern end of the FEC line might be used for a commuter rail service to complement the existing Tri-Rail line (which follows former CSX tracks to the west). There has also been some discussion about Amtrak or the State of Florida using FEC lines for a more direct route between Jacksonville and Miami.		In March 2012 the FEC proposed a privately owned and operated service between Miami and Orlando along its route named All Aboard Florida. New high speed trackage would be built between Brevard County and Orlando International Airport. In addition to the new track, the main line is once again being expanded to double track from Brevard County to Miami (some of the bridges still have adequate width from the previous double track). In 2014 the very first beginnings of All Aboard Florida commenced with studies and actual construction of the first phase, and construction began in November 2014. In 2015, AAF announced they will operate the service under the name Brightline, and service between Miami and West Palm Beach is slated to be operational at mid-2017, with the extension to Orlando be operational by 2020.		A lifeblood of the FEC is its transportation of high-grade limestone, which is used in the formulation for concrete and other construction purposes. The limestone is quarried near Miami in the "Lake Belt" area of Dade County and Broward County just west of Hialeah. The rock trains come out of the FEC yard at Medley in Miami-Dade County and the southern end of the FEC service area. Shipments currently are principally for materials dealers Titan and Rinker.		Rinker has since been sold and is now part of the multi-national Cemex. Rock train traffic dropped dramatically in 2008 with the elimination of all but one dedicated rock train. Other rock loads are now added onto other regular trains. The only rock train left, called the "unit train" operates between Miami and City Point.		The intermodal traffic includes interchanged shipments with CSX and Norfolk Southern, participation in EMP container service operated by UP and Norfolk Southern, United Parcel Service (UPS) piggyback trailers, trailers going to the Wal-Mart distribution center at Fort Pierce, and intermodal shipping container traffic through the ports of Miami, Port Everglades (adjacent to Ft. Lauderdale, Florida and the principal source of imports), Port of Palm Beach/Lake Worth Inlet, and Port Canaveral.		Additionally FEC offers "Hurricane Service" offering trucking companies the opportunity of having their trailers piggybacked out of Jacksonville to save the expensive cost of back-hauling empty trailers.		Starting in 2012 the FEC began an aggressive project to reopen direct rail service to the ports of Miami, and Port Everglades. This is in anticipation of the expansion of the Panama Canal and the expected increase of intermodal traffic. In 2013 the drawbridge at the Port of Miami was repaired and reactivated and trains began to roll. In 2014 a new container shuttle was put into operation between Hialeah Yard and the Port of Miami. Also in 2014, the new rail lines into Port Everglades were opened allowing direct access for FEC trains into the port. Further a new transfer facility in Hialeah Yard will add additional intermodal transfer between trains, trucks, and planes. This facility will open by 2015. Additional capacity improvements are planned at other ports as well as the FEC's mainline.		The FEC also hauls normal "manifest" freight to and from points along its right of way. These cars are hauled on whatever train is going that way, so intermodal and rock trains routinely have some manifest cars in their consists.		Additionally, the FEC currently transports Tropicana Products "Juice Train" cars to and from one of the company's processing facilities located on the "K" Line. The Juice Train concept was developed by Tropicana founder Anthony T. Rossi in conjunction with Seaboard Coast Line Railroad (a CSX predecessor) beginning in 1970.		The FEC completed its "second generation" dieselisation with the purchase of 49 GP40s and GP40-2s and 11 GP38-2s, ranging in the 400's. Most of these locomotives have been extensively rebuilt with others being retired. In 2002, the FEC acquired 20 ex-UP SD40-2s, which were numbered in 700s. These ex UP locomotives remained in their original colors with FEC markings, however as of 2014 seven of them have been repainted into the "retro" Champion scheme. As of 2015 the majority of these were leased to CSXT. In 2006 The FEC leased four SD70M-2's numbered in the 100 series (100-103) in a blue and yellow livery known by fans as the "Classic" or the "Alaskan" schemes. In 2009 when RailAmerica came into the picture, they added four more SD70M-2's (104-107) in the Red, Pearl & Blue scheme which was the standard RailAmerica scheme. That brought the total SD70M-2 count to eight. Seeking further power improvements, in 2009, the FEC leased three CITX SD70M-2's making the count now of 11 of the big EMD's. These locomotives were numbered 140, 141 and 142, all are big blue and white striped units. All of the SD70M-2's served on the railway until the end of 2014 when they were replaced with new power. The fleet GP38-2s are used principally for yard and road switching as well as the occasional local. The others are used as available in road service. Some test runs have been made to observe the effect on fuel consumption of dynamic braking and combinations of new and old power. In 2014 the railway purchased 24 GE ES44C4's, the first GE power to be owned by the FEC. All of the GE's have been delivered by the end of 2014 with the first run on November 21, 2014. In 2015 the railway will begin to experiment with LNG fuel that will help with costs and efficiency. With the arrival of the GE's the majority of the FEC's SD40-2's and a number of the SD70M-2's have been temporarily leased to CSXT. Two SD40-2's remain numbers 711 and 715 usually assigned to the Port of Miami jobs. Eventually, all the SD70M-2's will be returned to their respective leasing companies by the end of 2015 and the SD40-2's will remain on the FEC with the exception of leases to other companies.		In 2005 FEC owned and operated:[11]		Flagler Development owned and operated:		In 1925 FEC carried 979 million ton-miles of revenue freight and 261 million passenger miles on (at year-end) 849 miles of road and 1411 miles of track; corresponding numbers for 1970 were 1345, 0, 554 and 1058.		On May 16, 2006, FEC was the recipient of the Gold E. H. Harriman Award for safety in Group C (line-haul railroad companies with fewer than 4 million employee hours per year).[14]		The Jacksonville, St. Augustine and Indian River Railway Company was incorporated under the general incorporation laws of Florida to own and operate a railroad from Jacksonville in Duval county, through the counties of Duval, St. Johns, Putnam, Volusia, Brevard, Orange, Osceola, Dade, Polk and Hillsborough.		Florida state law chapter 4260, approved May 31, 1893, granted land to the railroad. At that time, it was already in operation from Jacksonville to Rockledge, the part south of Daytona having been constructed by them. The company had just filed a certificate changing and extending its lines on and across the Florida Keys to Key West in Monroe County.		The name was changed to the Florida East Coast Railway Company on September 7, 1895.		Florida East Coast Industries (FECI) incorporated in 1983[11] and was made the holding company for the Railway and the Commercial Realty/Flagler Development Company in 1984. The other subsidiaries are Orlando-based carrier, "EPIK Communication" and the logistics firm, "International Transit".[15]		FECI began operating independently of the St. Joe Company on October 9, 2000[11] when St. Joe shareholders were given FECI stock.		On May 8, 2007, Florida East Coast Railway Company's parent, Florida East Coast Industries (FECI), announced that FECI would be purchased with private equity funds managed by Fortress Investment Group in a transaction valued at $3.5 billion.[16][17] Fortress Investment acquired Florida East Coast Railway from Florida East Coast Industries in March, 2008.[17][clarification needed]		Historical listing of main line stations (north to south)		FEC Kissimmee Valley Extension Map		Stations (north to south)		South of Holopaw, the line roughly parallels US 441.		The Little River Branch connects to the mainline near Little River and heads south west toward Hialeah, where it turns south towards an FEC freight yard and Miami International Airport. The branch ends just south of the airport at Oleander Junction, where it connects with CSX's Homestead Subdivision and the South Florida Rail Corridor.[19]		The Little River Branch was historically a freight bypass around downtown Miami when the FEC mainline continued south to Homestead and Florida City. The branch continued south past the airport and reconnected with the mainline at Kendall. Part of the abandoned segment south of the airport is currently planned to become the Ludlam Trail linear park.[20]		The former Palm Beach branch once extended from the mainline in West Palm Beach east a short distance over Lake Worth Lagoon onto Palm Beach Island. Henry Flagler built the spur to deliver passengers to his two hotels on the island: the Royal Poinciana and The Breakers. The branch’s wooden trestle over Lake Worth Lagoon also included a pedestrian walkway.[21]		The spur was removed in 1902 at the insistence of Flagler’s wife, Mary, who complained about the noise and smoke coming from trains affecting them at their nearby mansion Whitehall. The trestle would become a toll bridge, which would be replaced by the Flagler Memorial Bridge in 1938 (which today carries State Road A1A).[22]		See http://www.taplines.net/tfc/tfc01.html for the story of the Fellsmere Branch.		The Lake Harbor Branch runs from Fort Pierce in St. Lucie County to Lake Harbor in Palm Beach County. It basically serves the sugar farms in Palm Beach and Hendry Counties. It branches off the main line in Fort Pierce and heads southwest to Marcy, where it turns south along Lake Okeechobee. At Lake Harbor, it connects to the South Cental Florida Express's main line (a former CSX branch). Though still owned by the Florida East Coast Railway, the South Central Florida Express has a car haulage arrangement with FEC, allowing SCFE to use the branch and the mainline to interchange with CSX and Norfolk Southern at Jacksonville.		The Lake Harbor Branch was once part of the Kissimmee Valley Branch until 1947, when the cutoff from Marcy to Fort Pierce was built and the rest of the Kissimmee Valley Branch was abandoned.[23]		The Enterprise Branch (E-branch) was built in 1885 by the Atlantic Coast, St. Johns and Indian River Railroad and leased to the Jacksonville, Tampa and Key West Railroad, part of the Plant System. Initially, the westernmost five miles (8 km) served as a connection from Enterprise Junction to Enterprise, a port for steamboat traffic down the St. Johns River. Later, the line was built through Osteen, Kalamazoo, and Mims to Titusville. The Enterprise Branch also crossed the Kissimmee Valley Branch at a location known as Maytown.		A steam locomotive pulled the first train over the line onto the wharf on the Indian River at Titusville on the afternoon of December 30, 1885, and greatly accelerated the transportation of passengers, produce, seafood, and supplies to and from central Florida. While Titusville thrived thanks to this new transportation connection, Enterprise lost stature as a steamboat port, since Henry Plant's railroad paralleled the St. Johns River and greatly reduced travel times to Jacksonville.		During the winter of 1894–95, a widespread freeze hit twice, decimating the citrus crop and ruining that part of Florida's economy. This allowed Henry Flagler to acquire the line at a discount to piece together what became the Florida East Coast Railway.		The track of the E-branch at one time had been uprooted as far as Aurantia, about five miles (8 km) northwest of Mims, ending directly under the Interstate 95 overpass and has been abandoned. The crossing gates and signals were removed before the summer 2004 hurricanes and the track is being removed by a steel salvage company. As of 2008 the track has been completely removed up to the connection with the current FEC mainline in Titusville.		The Florida Department of Environmental Protection took ownership of the rail bed on December 31, 2007. The corridor will become Florida's longest rails-to-trails project.[24][25] This rail line would have been suited to recreational railroad use by such groups as the North American Rail Passenger Car Owners' Association assuming a representative who is local to the area could have been located.		This branch, from Blue Spring on the St. Johns River via Orange City to the main line in New Smyrna Beach, was built by the Blue Spring, Orange City and Atlantic Railroad. In the mid-1880s it became the Atlantic and Western Branch of the Jacksonville, St. Augustine and Indian River Railway, which changed its name to the Florida East Coast Railway in 1895. It may have been the Atlantic and Western Railroad in between. The line was in use until 1930.		The railroad from Tocoi to Tocoi Junction, outside St. Augustine, was built by the St. Johns Railway. The Jacksonville, St. Augustine and Indian River Railway took it over by 1894, and changed its name to the Florida East Coast Railway in 1895. The line was abandoned by 1917; it was later used for SR 95, which became SR 214 at some time after the 1945 Florida State Road renumbering, and is now CR 214.		The almost arrow-straight Moultrie Cutoff was built in 1925 to cut the distance on the main line, avoiding the swing inland to East Palatka. It runs from just north of Bunnell to Moultrie Junction in St. Augustine. In 2005 the entire route had its mileposts redone to match the rest on the main line.		The railroad from Flagler Beach to Dorena, north of Bunnell, was built by the Lehigh Portland Cement Company in 1953. The line connected to the Lehigh Portland Cement Company Plant located near Flagler Beach. The line was abandoned in 1963, after a deadly strike erupted in that year that closed the massive plant. The site of the old plant was where some of the monorail beams were assembled for Walt Disney World in the early 1970s. The route is now part of the rails to trails system. The plant has been demolished outside of one smokestack that will become a "lighthouse" for a new development. Some remains of the yard can be found in the woods near the eastern end of the current Lehigh rail trail.		The railroad from Palatka to Moultrie Junction, outside St. Augustine, was built by the Jacksonville, St. Augustine and Halifax River Railway. The Jacksonville, St. Augustine and Indian River Railway took it over by 1894, and changed its name to the Florida East Coast Railway in 1895. The line was the main route until the construction of the Moultrie Cutoff in 1925. There was also a spur with a bridge across the St. Johns River into Palatka, where there was a junction with the Jacksonville, Tampa and Key West Railway and the Florida Southern Railroad.[26] The bridge over the river was removed in 1950, and the rest of the line was later abandoned in 1988 and all rail was removed to a point just west of I-95. In 2001, rail service resumed up to this point and track was rehabilitated when new industries were located there. A daily local serves the eastern end of the line today known as the Wilber Wright Industrial Lead.		This was originally built by the Jacksonville and Atlantic Railroad, a 3 ft (914 mm) narrow gauge line from Jacksonville to Pablo Beach (now Jacksonville Beach). In late 1899 it was bought by Henry Flagler, who had the line converted to 4 ft 8 1⁄2 in (1,435 mm) standard gauge and extended it north along the coast to Mayport. The new branch opened in March 1900 and was abandoned in October 1932.		Notable passenger trains operated over FEC rails:		
A berm is a level space, shelf, or raised barrier separating two areas. It can serve as a border barrier. The word berm originates in the Middle Dutch and German berme and came into usage in English via French.[1]						In medieval military engineering, a berm (or berme) was a level space between a parapet or defensive wall and an adjacent steep-walled ditch or moat.[1] It was intended to reduce soil pressure on the walls of the excavated part to prevent its collapse. It also meant that debris dislodged from fortifications would not fall into (and fill) a ditch or moat.		In the trench warfare of World War I, the name was applied to a similar feature at the lip of a trench, which served mainly as an elbow-rest for riflemen.		In modern military engineering, berm has come to mean the earthen or sod wall or parapet itself. The term especially refers to a low earthen wall adjacent to a ditch. The digging of the ditch (often by a bulldozer or military engineering vehicle) can provide the soil from which the berm is constructed. Walls constructed in this manner are an effective obstacle to vehicles, including most armoured fighting vehicles, but are easily crossed by infantry. Because of the ease of construction, such walls can be made hundreds or thousands of kilometres long.		Berms are also used to control erosion and sedimentation by reducing the rate of surface runoff. The berms either reduce the velocity of the water, or direct water to areas that are not susceptible to erosion, thereby reducing the adverse effects of running water on exposed topsoil. Following the 2010 Deepwater Horizon oil spill in the Gulf of Mexico, the construction of berms designed to prevent oil from reaching the fragile Louisiana wetlands (which would result in massive erosion) was proposed early on, and was officially approved by the federal government in mid-June, 2010, after numerous failures to stop and contain the oil leak with more advanced technologies.[2]		In coastal geography, a berm is a bank of sand or gravel ridge parallel to the shoreline and a few tens of centimetres high, created by wave action throwing material beyond the average level of the sea.		Earth is piled up against exterior walls and packed, sloping down away from the house. The roof may or may not be fully earth covered, and windows/openings may occur on one or more sides of the shelter. Due to the building being above ground, fewer moisture problems are associated with earth berming in comparison to underground/fully recessed construction.		Berm has been adopted as a wider term usually used to describe a physical, stationary barrier of some kind. For example, in modern highway construction, a berm is a noise barrier constructed of earth, often landscaped, running along a highway to protect adjacent land users from noise pollution. The shoulder of a road is also called a berm and in New Zealand the word describes a publicly owned grassed nature strip sometimes planted with trees alongside urban roads.[3] [1] In Snowboard Cross, a berm is a wall of snow built up in a corner.[4] In Mountain biking, a berm is a banked turn formed by soil, commonly dug from the track, being deposited on the outer rim of the turn. In coastal systems, a berm is a raised ridge of pebbles or sand found at high tide or storm tide marks on a beach. In snow removal, a berm or windrow refers to the linear accumulation of snow cast aside by a plow.[5] In open-pit mining, a berm refers to dirt and rock piled alongside a haulage road or along the edge of a dump point. Intended as a safety measure, they are commonly required by government organizations to be at least half as tall as the wheels of the largest mining machine on-site.[6][7]		Physical security systems employ berms to exclude hostile vehicles and slow attackers on foot (similar to the military application without the trench). Security berms are common around military and nuclear facilities. An example is the berm proposed for Vermont Yankee nuclear power plant in Vermont.[8] At Baylor Ballpark, a baseball stadium on the campus of Baylor University, a berm is constructed down the right field line. The berm replaces bleachers, and general admission tickets are sold for fans who wish to sit on the grass or watch the game from the top of the hill.		Berms are also used as a method of environmental spill containment and liquid spill control. Bunding is the construction of a secondary impermeable barrier around and beneath storage or processing plant, sufficient to contain the plant's volume after a spill. This is often achieved on large sites by surrounding the plant with a berm. The EPA requires that oils and fuels stored over certain volume levels be placed in secondary spill containment. Berms for spill containment are typically manufactured from PVC or geomembrane fabric that provide a barrier to keep spills from reaching the ground or navigable waterways. Most berms have sidewalls to keep liquids contained for future capture and safe disposal.		Media related to Berms at Wikimedia Commons		
A current, in a river or stream, is the flow of water influenced by gravity as the water moves downhill to reduce its potential energy. The current varies spatially as well as temporally within the stream, dependent upon the flow volume of water, stream gradient, and channel geometrics. In tidal zones, the current in rivers and streams may reverse on the flood tide before resuming on the ebb tide.		
In physical geography, a dune is a hill of loose sand built by wind or the flow of water.[1] Dunes occur in different shapes and sizes, formed by interaction with the flow of air or water. Most kinds of dunes are longer on the windward side where the sand is pushed up the dune and have a shorter "slip face" in the lee of the wind. The valley or trough between dunes is called a slack. A "dune field" is an area covered by extensive sand dunes. Dunes occur, for example, in some deserts and along some coasts.		Some coastal areas have one or more sets of dunes running parallel to the shoreline directly inland from the beach. In most cases, the dunes are important in protecting the land against potential ravages by storm waves from the sea. Although the most widely distributed dunes are those associated with coastal regions, the largest complexes of dunes are found inland in dry regions and associated with ancient lake or sea beds.		Dunes can form under the action of water flow (fluvial processes), and on sand or gravel beds of rivers, estuaries and the sea-bed.		The modern word "dune" came into English from French c. 1790,[2] which in turn came from Middle Dutch dūne.[1]						Crescent-shaped mounds are generally wider than they are long. The slipfaces are on the concave sides of the dunes. These dunes form under winds that blow consistently from one direction, and they also are known as barchans, or transverse dunes. Some types of crescentic dunes move more quickly over desert surfaces than any other type of dune. A group of dunes moved more than 100 metres per year between 1954 and 1959 in China's Ningxia Province, and similar speeds have been recorded in the Western Desert of Egypt. The largest crescentic dunes on Earth, with mean crest-to-crest widths of more than three kilometres, are in China's Taklamakan Desert.[3]		Fixed crescentic dunes that form on the leeward margins of playas and river valleys in arid and semiarid regions in response to the direction(s) of prevailing winds, are known as lunettes, source-bordering dunes, bourrelets and clay dunes. They may be composed of clay, silt, sand, or gypsum, eroded from the basin floor or shore, transported up the concave side of the dune, and deposited on the convex side. Examples in Australia are up to 6.5 km long, 1 km wide, and up to 50 metres high. They also occur in southern and West Africa, and in parts of the western United States, especially Texas.[4]		Straight or slightly sinuous sand ridges typically much longer than they are wide are known as linear dunes. They may be more than 160 kilometres (100 miles) long. Some linear dunes merge to form Y-shaped compound dunes. Many form in bidirectional wind regimes. The long axes of these dunes extend in the resultant direction of sand movement.[5]		Linear loess hills known as pahas are superficially similar. These hills appear to have been formed during the last ice age under permafrost conditions dominated by sparse tundra vegetation.		Radially symmetrical, star dunes are pyramidal sand mounds with slipfaces on three or more arms that radiate from the high center of the mound. They tend to accumulate in areas with multidirectional wind regimes. Star dunes grow upward rather than laterally. They dominate the Grand Erg Oriental of the Sahara. In other deserts, they occur around the margins of the sand seas, particularly near topographic barriers. In the southeast Badain Jaran Desert of China, the star dunes are up to 500 metres tall and may be the tallest dunes on Earth.		Oval or circular mounds that generally lack a slipface. Dome dunes are rare and occur at the far upwind margins of sand seas.		U-shaped mounds of sand with convex noses trailed by elongated arms are parabolic dunes. These dunes are formed from blowout dunes where the erosion of vegetated sand leads to a U-shaped depression. The elongated arms are held in place by vegetation; the largest arm known on Earth reaches 12 km. Sometimes these dunes are called U-shaped, blowout, or hairpin dunes, and they are well known in coastal deserts. Unlike crescent shaped dunes, their crests point upwind. The bulk of the sand in the dune migrates forward.		In plan view, these are U-shaped or V-shaped mounds of well-sorted, very fine to medium sand with elongated arms that extend upwind behind the central part of the dune. There are slipfaces that often occur on the outer side of the nose and on the outer slopes of the arms.		These dunes often occur in semiarid areas where the precipitation is retained in the lower parts of the dune and underlying soils. The stability of the dunes was once attributed to the vegetative cover but recent research has pointed to water as the main source of parabolic dune stability. The vegetation that covers them—grasses, shrubs, and trees—help anchor the trailing arms. In inland deserts, parabolic dunes commonly originate and extend downwind from blowouts in sand sheets only partly anchored by vegetation. They can also originate from beach sands and extend inland into vegetated areas in coastal zones and on shores of large lakes.		Most parabolic dunes do not reach heights higher than a few tens of metres except at their nose, where vegetation stops or slows the advance of accumulating sand.		Simple parabolic dunes have only one set of arms that trail upwind, behind the leading nose. Compound parabolic dunes are coalesced features with several sets of trailing arms. Complex parabolic dunes include subsidiary superposed or coalesced forms, usually of barchanoid or linear shapes.		Parabolic dunes, like crescent dunes, occur in areas where very strong winds are mostly unidirectional. Although these dunes are found in areas now characterized by variable wind speeds, the effective winds associated with the growth and migration of both the parabolic and crescent dunes probably are the most consistent in wind direction.		The grain size for these well-sorted, very fine to medium sands is about 0.06 to 0.5 mm. Parabolic dunes have loose sand and steep slopes only on their outer flanks. The inner slopes are mostly well packed and anchored by vegetation, as are the corridors between individual dunes. Because all dune arms are oriented in the same direction, and, the inter-dune corridors are generally swept clear of loose sand, the corridors can usually be traversed in between the trailing arms of the dune. However to cross straight over the dune by going over the trailing arms, can be very difficult. Also, traversing the nose is very difficult as well because the nose is usually made up of loose sand without much if any vegetation.		A type of extensive parabolic dune that lacks discernible slipfaces and has mostly coarse grained sand is known as a zibar.[6] The term zibar comes from the Arabic word to describe "rolling transverse ridges ... with a hard surface".[7] The dunes are small, have low relief, and can be found in many places across the planet from Wyoming (United States) to Saudi Arabia to Australia. Spacing between zibars ranges from 50 to 400 metres and they don't become more than 10 metres high.[8] The dunes form at about ninety degrees to the prevailing wind which blows away the small, fine-grained sand leaving behind the coarser grained sand to form the crest.[9]		Longitudinal dunes (also called Seif dunes, after the Arabic word for "sword"), elongate parallel to the prevailing wind, possibly caused by a larger dune having its smaller sides blown away. Seif dunes are sharp-crested and are common in the Sahara. They range up to 300 m (980 ft) in height and 300 km (190 mi) in length. In the southern third of the Arabian Peninsula, a vast erg called the Rub' al Khali or the Empty Quarter, contains seif dunes that stretch for almost 200 km and reach heights of over 300 m.		Seif dunes are thought to develop from barchans if a change of the usual wind direction occurs. The new wind direction will lead to the development of a new wing and the over development of one of the original wings. If the prevailing wind then becomes dominant for a lengthy period of time the dune will revert to its barchan form, with one exaggerated wing. Should the strong wind then return the exaggerated wing will further extend so that eventually it will be supplied with sand when the prevailing wind returns. The wing will continue to grow under both wind conditions, thus producing a seif dune. On a seif dune the slipface develops on the side facing away from the strong wind, while the slipface of a barchan faces the direction of movement. In the sheltered troughs between highly developed seif dunes barchans may be formed because the wind is unidirectional.		A transverse dune is perpendicular to the prevailing wind, probably caused by a steady build-up of sand on an already existing minuscule mound.		Occurring wherever winds periodically reverse direction, reversing dunes are varieties of any of the above shapes. These dunes typically have major and minor slipfaces oriented in opposite directions.		All these dune shapes may occur in three forms: simple, compound, and complex. Simple dunes are basic forms with a minimum number of slipfaces that define the geometric type. Compound dunes are large dunes on which smaller dunes of similar type and slipface orientation are superimposed, and complex dunes are combinations of two or more dune types. A crescentic dune with a star dune superimposed on its crest is the most common complex dune. Simple dunes represent a wind regime that has not changed in intensity or direction since the formation of the dune, while compound and complex dunes suggest that the intensity and direction of the wind has changed.		The sand mass of dunes can move either windward or leeward, depending on if the wind is making contact with the dune from below or above its apogee. If wind hits from above, the sand particles move leeward. If sand hits from below, sand particles move windward. The leeward flux of sand is greater than the windward flux. Further, when the wind carrying sand particles when it hits the dune, the dune’s sand particles will saltate more than if the wind had hit the dune without carrying sand particles.[10]		Dunes form where the beach is wide enough to allow for the accumulation of wind-blown sand, and where prevailing onshore winds tend to blow sand inland. Obstacles—for example, vegetation, pebbles and so on—tend to slow down the wind and lead to the deposition of sand grains.[11] These small "incipient dunes or "shadow dunes" tend to grow in the vertical direction if the obstacle slowing the wind can also grow vertically (i.e., vegetation). Models of coastal dunes suggest that their final equilibrium height is related to the distance between the water line and where vegetation can grow.[12] Additionally the height of coastal dunes is impacted by storm events, which can erode dunes. Recent work has suggested that coastal dunes tend to evolve toward a high or low morphology depending on the growth rate of dunes relative to storm frequency. In certain conditions, both low and high dunes are possible — dunes are a system that shows bistable dynamics.[13][14]		Dunes provide privacy and shelter from the wind.		As a dune forms, plant succession occurs. The conditions on an embryo dune are harsh, with salt spray from the sea carried on strong winds. The dune is well drained and often dry, and composed of calcium carbonate from seashells. Rotting seaweed, brought in by storm waves adds nutrients to allow pioneer species to colonize the dune. These pioneer species are marram grass, sea wort grass and other sea grasses in the United Kingdom. These plants are well adapted to the harsh conditions of the foredune typically having deep roots which reach the water table, root nodules that produce nitrogen compounds, and protected stoma, reducing transpiration. Also, the deep roots bind the sand together, and the dune grows into a foredune as more sand is blown over the grasses. The grasses add nitrogen to the soil, meaning other, less hardy plants can then colonize the dunes. Typically these are heather, heaths and gorses. These too are adapted to the low soil water content and have small, prickly leaves which reduce transpiration. Heather adds humus to the soil and is usually replaced by coniferous trees, which can tolerate low soil pH, caused by the accumulation and decomposition of organic matter with nitrate leaching.[15] Coniferous forests and heathland are common climax communities for sand dune systems.		Young dunes are called yellow dunes and dunes which have high humus content are called grey dunes. Leaching occurs on the dunes, washing humus into the slacks, and the slacks may be much more developed than the exposed tops of the dunes. It is usually in the slacks that more rare species are developed and there is a tendency for the dune slacks soil to be waterlogged and where only marsh plants can survive. These plants would include: creeping willow, cotton grass, yellow iris, reeds, and rushes. As for the species, there is a tendency for natterjack toads to breed here.		Dune ecosystems are extremely difficult places for plants to survive. This is due to a number of pressures related to their proximity to the ocean and confinement to growth on sandy substrates.  These include:		There are many adaptations plants have evolved to cope with these pressures:		A nabkha, or coppice dune, is a small dune anchored by vegetation. They usually indicate desertification or soil erosion, and serve as nesting and burrow sites for animals.		Sub-aqueous (underwater) dunes form on a bed of sand or gravel under the actions of water flow. They are ubiquitous in natural channels such as rivers and estuaries, and also form in engineered canals and pipelines. Dunes move downstream as the upstream slope is eroded and the sediment deposited on the downstream or lee slope in typical bedform construction.[16]		These dunes most often form as a continuous 'train' of dunes, showing remarkable similarity in wavelength and height.		Dunes on the bed of a channel significantly increase flow resistance, their presence and growth playing a major part in river flooding.		A lithified (consolidated) sand dune is a type of sandstone that is formed when a marine or aeolian sand dune becomes compacted and hardened. Once in this form, water passing through the rock can carry and deposit minerals, which can alter the color of the rock. Cross-bedded layers of stacks of lithified dunes can produce the cross-hatching patterns, such as those seen in the Zion National Park in the western United States.		A slang term, used in the southwest US, for consolidated and hardened sand dunes is "slickrock", a name that was introduced by pioneers of the Old West because their steel-rimmed wagon wheels could not gain traction on the rock.		Sand dunes can have a negative impact on humans when they encroach on human habitats. Sand dunes move via a few different means, all of them helped along by wind. One way that dunes can move is by saltation, where sand particles skip along the ground like a bouncing ball. When these skipping particles land, they may knock into other particles and cause them to move as well, in a process known as creep. With slightly stronger winds, particles collide in mid-air, causing sheet flows. In a major dust storm, dunes may move tens of metres through such sheet flows. Also as in the case of snow, sand avalanches, falling down the slipface of the dunes—that face away from the winds—also move the dunes forward.		Sand threatens buildings and crops in Africa, the Middle East, and China. Drenching sand dunes with oil stops their migration, but this approach is quite destructive to the dunes' animal habitats and uses a valuable resource. Sand fences might also slow their movement to a crawl, but geologists are still analyzing results for the optimum fence designs.[citation needed] Preventing sand dunes from overwhelming towns, villages, and agricultural areas has become a priority for the United Nations Environment Programme. Planting dunes with vegetation also helps to stabilise them.		Dune habitats provide niches for highly specialized plants and animals, including numerous rare species and some endangered species. Due to widespread human population expansion, dunes face destruction through land development and recreational usages, as well as alteration to prevent the encroachment of sand onto inhabited areas. Some countries, notably the United States, Australia, Canada, New Zealand, the United Kingdom, Netherlands, and Sri Lanka have developed significant programs of dune protection through the use of sand dune stabilization. In the U.K., a Biodiversity Action Plan has been developed to assess dunes loss and to prevent future dunes destruction.		Dunes can likely be found in any environment where there is a substantial atmosphere, winds, and dust to be blown. Dunes are common on Mars and in the equatorial regions of Titan.		Titan's dunes include large expanses with modal lengths of about 20–30 km. The regions are not topographically confined, resembling sand seas. These dunes are interpreted to be longitudinal dunes whose crests are oriented parallel to the dominant wind direction, which generally indicates west-to-east wind flow. The sand is likely composed of hydrocarbon particles, possibly with some water ice mixed in.[25]		
Ramsgate is a seaside town in the district of Thanet in east Kent, England. It was one of the great English seaside towns of the 19th century. In 2001 it had a population of around 40,000. Ramsgate’s main attraction is its coastline, and its main industries are tourism and fishing. The town has one of the largest marinas on the English south coast, and the Port of Ramsgate has provided cross-channel ferries for many years.						Ramsgate began as a fishing and farming hamlet.		The Christian missionary St Augustine, sent by Pope Gregory the Great, landed near Ramsgate in 597AD.[2] The town is home to the Shrine of St Augustine.		The earliest reference to the town is in the Kent Hundred Rolls of 1274-5, both as Remmesgate (in the local personal name of ‘Christina de Remmesgate’) and Remisgat (with reference to the town).[3] The names Ramisgate and Raunsgate appear in the parish of St. Laurence records circa 1290.[4][5] These are all derived from late Anglo-Saxon ‘Hremmes’ from earlier ‘Hræfnes’ (raven’s) and ‘geat’ (gate), with reference to the gap in the cliffs.[6] In 1357, the area became known as Ramesgate.[7][8][9]		Ramsgate was a member of the Confederation of Cinque Ports, under the 'Limb' of Sandwich, Kent.[10]		The construction of Ramsgate Harbour began in 1749 and was completed in about 1850. The harbour has the distinction of being the only Royal Harbour in the United Kingdom. Because of its proximity to mainland Europe, Ramsgate was a chief embarkation point both during the Napoleonic Wars and for the Dunkirk evacuation in 1940.		The Official Illustrated Guide to South-Eastern and North and Mid-Kent Railways (June 1863) by George Measom from describes Ramsgate thusly: 'It is impossible to speak too favourably of this first rate town, its glorious sands, its bathing, its hotels, libraries, churches,etc. etc. not forgetting its bracing climate...The streets of Ramsgate are well paved or macadamed and brilliantly lighted with gas.'		The architect A W Pugin and his sons lived in Ramsgate and built several important buildings there, including St Augustine's Church, The Grange, St Augustine's Abbey, and The Granville Hotel.		The artist Vincent Van Gogh moved to Ramsgate in April 1876, at age 23. He boarded at 11 Spencer Square, which is identified by a blue plaque. He obtained work as a teacher at a local school in Royal Road, where he received his post.[11] In one of his letters [12][13] to his brother Theo, he described his surroundings: "There’s a harbour full of all kinds of ships, closed in by stone jetties running into the sea on which one can walk. And further out one sees the sea in its natural state, and that’s beautiful."		In 1901, an electric tram service, one of the few inter-urban tramways in Britain, was introduced on the Isle of Thanet. The towns of Ramsgate, Margate and Broadstairs were linked by 11 miles of track.		In 1915–1916, early aircraft began to use the open farmland at Manston as a site for emergency landings. The location near the Kent coast gave Manston some advantages over the other previously established aerodromes. During the First World War, Ramsgate was the target of bombing raids by Zeppelin airships. By 1917 the Royal Flying Corps was well established and taking an active part in the defence of Britain. As RAF Manston, the aerodrome played an important role in the Second World War. It is now called Kent International Airport.		As the Second World War approached, Ramsgate Borough Council embarked on plans to create a network of Deep Shelter tunnels linking to a former railway tunnel which would provide shelter for 60,000 people. The tunnels were opened on 1 June 1939. 75 years later, in 2014, a part of this network was opened to visitors. [2]		In October 1939, the Royal Navy established a Coastal Forces base at Ramsgate called HMS Fervent, which operated Motor Torpedo Boats, Motor Gun Boats and Motor Launches until September 1945. From 27 May 1940, Ramsgate harbour was the main assembly point for the build-up of small craft needed for Operation Dynamo, the evacuation of the British Expeditionary Force from Dunkirk.[14] Once the evacuation was under way, Ramsgate became the second-busiest port after Dover, and just under 43,000 men passed through the port, transported onwards by 82 special trains.[15]		Ramsgate is located 78 miles from central London in an east south-easterly direction at one of the most easterly points of the United Kingdom (the furthest point east is Lowestoft in Suffolk).		The town is an amalgamation of two settlements: a fishing community on the coast in the shallow valley between two chalk cliffs, and an inland farming community that is now the Parish of St Lawrence. The cliffs are known as the East Cliff and the West Cliff and are predominantly residential areas. There are promenades along both cliff tops with parks at either end and sandy beaches on the coast.		Ramsgate has an oceanic climate (Köppen climate classification Cfb) as is typical in the United Kingdom; the nearest Met Office weather station for which data is available is Manston Airport, about two miles west of the town centre.		The highest temperature ever recorded is 34.6 °C (94.3 °F)[16] in August 2003, though typically the warmest day of the year averages 28.5 °C (83.3 °F)[17] and 8.8 days[18] will record a temperature of 25.1 °C (77.2 °F) or above.		The lowest recorded temperature is -14.5 °C (5.9 °F),[19] in February 1986, though typically the coldest night of the year averages -6.2 °C (20.8 °F).[20] A total of 28.9 days[21] of the year should record an air frost.		Rainfall averages around 550 mm[22] per year, a figure similar to that for the driest parts of England. Over 1 mm of rain can be expected on 102.9 days.[23] All averages refer to the 1971-00 period.		Being close to the coast, and in Southern England, sunshine compares favourably with most of the United Kingdom, at over 1700 hours[24] a year. Only the Sussex coast tends to be notably sunnier, although much of the remainder of the south coast receives a similar amount of sunshine as Ramsgate.		Ramsgate is in the parliamentary constituency of Thanet South, which is represented by Conservative MP Craig Mackinlay. He won the seat in the 2015 general election, representing a Conservative hold after Laura Sandys won the seat for the Conservatives in the 2010 General Election.		Before 6 May 2010, the MP for Ramsgate was Stephen Ladyman, a Labour minister; he was preceded by Jonathan Aitken.		Ramsgate was incorporated as a municipal borough in 1884. This was abolished in 1974, since when Ramsgate has been part of the Thanet local government district. The town is made up of seven electoral wards: Central Harbour, Cliffsend and Pegwell, Eastcliff, Nethercourt, Newington, Northwood, and Sir Moses Montefiore. These wards have seventeen of the fifty-six seats on the Thanet District Council; since the 2011 local elections fifteen of those seats have been held by Labour and two by the Conservative Party.[27] Currently the council is run by a UKIP majority.		Following a successful campaign by local activist Gerry O'Donnell, a town council was established for Ramsgate in June 2009.[citation needed] The Town Mayor of Ramsgate is currently Councillor Trevor Shonk.[28]		Ramsgate's main industries are tourism and fishing. The town has a thriving marina with over 800 moorings and a range of marine-related businesses that operate in the renovated arches under Royal Parade. Colleges in the town also cater for students of English as a foreign language.		Although Ramsgate has the most valuable fish landings in Kent (~£700,000 in 2003), the fishing industry is in decline.[29]		The Port of Ramsgate has provided cross-channel ferries for many years. Previously, Sally Ferries UK provided a passenger and car ferry service to Dunkirk. Until April 2013, Transeuropa Ferries operated a freight and car ferry between Ramsgate and Oostende.		Unemployment in Thanet stands at 4.1%; this is higher than the national average (2.5%).[30]		There is some light industry in the town. An emerging industry is power generation, with 800 jobs expected to be created by the Thanet offshore wind project, a wind farm just off the coast.		Ramsgate market is held in High Street, King Street and Queen Street every Friday and Saturday between 8:00 a.m. and 4:00 p.m.[31]		Ramsgate has a LETS scheme (RAMLETS) which was set up in 2014 enabling residents to trade goods and services using the virtual currency RAMs. It is working with the Newington Wellbeing Network to improve the lives of people living in the Newington ward of Ramsgate.[32]		According to the 2001 UK census, Ramsgate has a population of 39,639.[33]		The ethnicity of the town was 98.0% white, 0.8% mixed race, 0.3% black, 0.3% Chinese, 0.4% other Asian and 0.1% other ethnicity.[33]		The place of birth of residents was 95.6% United Kingdom, 0.7% Republic of Ireland, 0.6% Germany, 0.6% other Western European countries, 0.3% Eastern Europe, 0.6% Far East, 0.5% Africa, 0.3% North America, 0.3% South Asia, 0.2% Middle East, 0.2% Oceania and 0.1% South America.[33]		Religion was recorded as 71.6% Christian, 0.3% Muslim, 0.1% Hindu, 0.3% Buddhist, 0.1% Sikh and 0.1% Jewish. 17.9% were recorded as having no religion, 0.3% had an alternative religion and 7.1% didn't state their religion.[33]		For every 100 women, there were 91.2 men. The age distribution was 6% aged 0–4 years, 16% aged 5–15 years, 5% aged 16–19 years, 31% aged 20–44 years, 24% aged 45–64 years and 18% aged 65 years and over.[33]		Ramsgate's main attraction is its coastline, particularly Ramsgate Main Sands, which was awarded a Blue Flag in 2015.[34][35]		Ramsgate's wartime deep shelter tunnels are open to the public for tours, which have been running since 2014.[36]		The local council publishes a website specifically aimed at tourists visiting Ramsgate and neighbouring towns.[37]		There is an annual regatta event based at Ramsgate during the summer.[38]		Ramsgate has developed a continental café style culture with bars and restaurants on its seafront parade.[citation needed]		Ramsgate carnival is an annual parade that takes place during the summer.[39] Other events include the annual Addington Street Fair and the French Market.[citation needed]		Ramsgate’s main football club, Ramsgate FC, plays in the Isthmian League Division One South. The local rivals of the club are Margate FC, situated 4 miles away. When the two teams meet, it is known as the Thanet derby. Ramsgate also runs a reserves team, which plays in the Kent Football League Second Division, and a women’s team, which plays in the South East Counties Women’s League Kent County Division. Ramsgate FC also runs five youth teams; the under-13 to under-18 teams compete in the Valley Express Kent Youth League, and the club also runs Ramsgate Youth U7 to U16, which play in the Molten East Kent Youth League. Two other popular youth teams in Ramsgate are Trinity and Hugin Vikings; both play in The Molten East Kent Youth League.		Thanet Wanderers is the island’s only rugby team and has enjoyed recent success at London Division 1 level, achieving its best result by defeating Doncaster at Twickenham in the final of the Intermediate Cup in 1997. The club runs five senior sides and many junior teams, all of which play at St Peter's.		Cliftonville Hockey Club plays its home matches at St Lawrence College and has a clubhouse that it shares with Broadstairs Cricket Club.[40]		Thanet Galaxy is a Pan Disability Football Club that provides structured coaching for male and female footballers of all ages who qualify within the nationally and internationally recognised Pan Disability categories. The club trains at Chatham House Grammar School and plays in Kent Disability Football League in three age bands: U-11, U-16, and 16+. In their first season (2008/2009), the adult A team won the Kent Disability League Adult Championship.		Ramsgate’s sports facilities include a public swimming pool,[41][42] and a fitness centre[43] with a gym and sports hall. Tennis clubs can be found at Spencer Square and St Laurence. Ramsgate has three golf clubs: St Augustine's,[44] Stonelees,[45] and Manston.[46] There is also a sailing club, the Royal Temple Yacht Club, which is steeped in yacht-racing history and hosts racing throughout the year for a variety of historic trophies. The highlight of the season is the annual international sailing regatta, known as 'Ramsgate Week', which is usually held in August.[47]		The Gallery IOTA (Isle Of Thanet Arts) was based on the towns west cliff but is now on the harbour front.[48] Ramsgate Maritime Museum near the harbour quayside has exhibits showing the evolution of Ramsgate Harbour and east Kent maritime history. One of Ramsgate's cinemas and theatres is the Granville Cinema, situated on Victoria Parade, in the town's Eastcliff area. The King's Theatre is situated near the town centre and offers shows, community events and a seniors' club every Monday. Talks on Ramsgate's history are frequently held there.		Ramsgate has two paid-for newspapers, the Isle of Thanet Gazette and Thanet Times, both of which are owned by Northcliffe Media.[49] Free newspapers covering the town include the Thanet Extra, part of the KM Group; and yourthanet, belonging to KOS Media.		The local radio stations are KMFM Thanet, owned by the KM Group, community radio station Academy FM (Thanet), and the county-wide stations Heart Kent, Gold and BBC Radio Kent. Thanet Community Radio (TCR [50] offers an online arts- and features-based service for Thanet District and the surrounding area where people can listen to podcasts of local interest. The service works closely with Dover Community Radio.		The Hugin is a reconstructed Viking longship located at Pegwell Bay in Ramsgate. It was a gift from the Danish government in commemoration of the 1500th anniversary of the legendary arrival of Hengist and Horsa to England in the year 449.		There are many Regency and Victorian buildings in Ramsgate. In all, there are 900 listed buildings in the town with more than 200 in the vicinity of the harbour.[51] One of the town's most notable buildings is the 18th century Townley House designed by Mary Townley.[52]		The town has three notable churches. The first building used for worship in the Thanet parish of 'St Lawrence' was at St Laurence-in-Thanet; it was built in 1062 and rebuilt during the following centuries with the most significant changes made in the 16th century. Note the difference in spelling between the village of St Lawrence and its church, which is dedicated to the Roman Martyr Laurence.		The second notable church is St Augustine's, which is situated on the town's West Cliff. It was designed by Augustus Pugin in 1847 in the Gothic Revival style. Its dedication commemorates Augustine, the first Archbishop of Canterbury, who landed at Ramsgate in AD 597 bringing Christianity to Britain. In March 2012 the church was designated a shrine to St Augustine of Canterbury; this ended a five-century absence of a shrine to St Augustine, as the original (at St Augustine's Abbey, Canterbury) had been destroyed during the Reformation.		Thirdly, the town's parish church of St George is situated just off the High Street. Its lantern tower was added at the request of Trinity House as a navigational aid to passing ships and looks over the town. The ground was consecrated on 23 October 1827.		St Augustine's is part of the Roman Catholic Archdiocese of Southwark, whilst St Laurence and St George are both Church of England and serve the Anglican community as part of the Diocese of Canterbury. Christ Church, built in 1847, also serves the Anglican community.		Ramsgate library was originally built and paid for by Andrew Carnegie in 1904. On the evening of Friday 13 August 2004, it was destroyed by fire just two months short of its 100th anniversary.[53] Though suspicions were raised about the causes of the fire, due to a similarly timed fire at the town's registry office, an investigation was unable to establish how the fire had started.		Shortly after the blaze, planning permission was granted for a new library. The library has now been fully restored, and was officially re-opened on 20 February 2009.[54]		The Port of Ramsgate has a 700 berth marina, Royal Harbour Marina, and a ferry terminal built on reclaimed land. The harbour provides shelter from the effects of storms. The Goodwin Sands are nearby. In 2005, the marina had 12,000 visiting boats.[citation needed] Transeuropa Ferries passenger (with vehicle only) and freight ferries sailed until April 2013 to the Port of Ostend in Ostend, Belgium. The Port of Ramsgate has its own road access tunnel from outside the town, avoiding town centre congestion. The RNLI Ramsgate Lifeboat Station is in Ramsgate Harbour.		Ramsgate is connected to the national road network primarily through the A299 Thanet Way, which continues on to the M2/A2 for the M25 (approx 1 hour) and London. The A256 provides a link to Dover and onwards to the A20 for the Channel Tunnel. Bus services are provided by Stagecoach East Kent and also serve Broadstairs, Canterbury, Dover, Margate and Manston Airport, Kent's International Airport.		Ramsgate railway station is situated at the top of the town near the parish of St Lawrence.		A new high-speed service to London started in December 2009, running on High Speed 1 (HS1), the UK’s first high-speed rail line, between London’s St Pancras station and Kent. The journey time from Ramsgate to the new St Pancras terminal, with excellent transport links, is 1 hour 16 minutes.[55]		In March 2015, it was announced that journey times between Ramsgate and London St. Pancras are expected to be reduced to 63 minutes in 2019, due to infrastructure enhancements.[56]		Other trains run from Ramsgate to London Charing Cross and London Victoria. Commuting time to the capital on these lines is approximately 1 hour 50 minutes.		Trains from Ramsgate are routed via Margate, Chatham and Bromley South, or via Canterbury West or Dover Priory and Ashford International. Ramsgate railway station is operated by Southeastern.		A municipal airport was opened on 1 July 1935, operating until the Second World War broke out in 1939. Following a short spell as a satellite of RAF Manston, it closed in 1940. The airport was re-opened in 1952 and operated until closure in 1968.		The town is situated directly under the flight path of Kent International Airport at Manston. From September 2004 to August 2005 a low-cost airline EUjet operated frequent flights to many European destinations, replacing a large freight operator. However, flights were suspended after the collapse of its parent company, PlaneStation Group plc.[57]		Manston was sold to Infratil (owner of Glasgow Prestwick International Airport) on 26 August 2005. Until May 2014, KLM Cityhopper operated two daily passenger flights from the airport to Schiphol airport in the Netherlands. The airport was regularly used by freight operators such as Cargolux and Meridian.		The Airport was sold to Ann Gloag in November 2013. She was reported to be seeking a buyer, but her spokesman reported that a buyer had not been found, and the airport closed on 15 May 2014.		Infant schools		Junior schools		Primary schools		Secondary schools		Colleges and further education		
An ingression coast or depressed coast is a generally level coastline that is shaped by the penetration of the sea as a result of crustal movements or a rise in the sea level.		Such coasts are characterised by a subaerially formed relief that has previously experienced little deformation by littoral (tidal) processes, because the sea level, which had fallen by more than 100 metres during the last glacial period, did not reach its current level until about 6,000 years ago.		Depending on the geomorphological shaping of the flooded landform – e. g. glacially or fluvially formed relief – various types of ingression coast emerge, such as rias, skerry and fjard coasts as well as förde and bodden coasts.[1]		
The East Coast Railway (ECoR) is one of the seventeen railway zones of Indian Railways. It came into existence on 1 April 2003. As the name suggests, most of the railway routes of the zone are near the east coast of India.A new railway zone has to be formed with headquarters in visakhapatnam for the state of andhra pradesh as promised inA.P reorganisation act 2014.A wide range of protests took place for railway zone in public social media like twitter etc and the issue has taken center stage of andhra pradesh politics.						Consequent upon the parliament’s approval, East Coast Railway was the first of the seven new zones to be inaugurated by the then Prime Minister of India H. D. Deve Gowda on 8 August 1996. The Officer-on-Special Duty took over charge of the newly declared Zone on 16 September 1996. Initially, only one division namely Khurda Road was attached to this railway.		Subsequently, the zone became fully operational with effect from 1 April 2003.		The geographical jurisdiction of East Coast Railway zone extends over three states encompassing almost all of Odisha along with parts of Srikakulam, Vizianagaram and Visakhapatnam districts of northeastern Andhra Pradesh and Bastar and Dantewada districts of Chhattisgarh state. The zonal headquarters is at Bhubaneswar in Odisha.		The zone has three divisions: Sambalpur, Khurda Road and Waltair.		The East Coast Railway line integrated with the commissioned Howrah-Chennai electrified trunk route on 29 November 2005. There was a missing link between Kharagpur and Visakhapatnam stations and all trains from Howrah towards Chennai side had to undergo a locomotive change from electric to diesel at Kharagpur and vice versa at Visakhapatnam in order to pass through Odisha. Even trains from New Delhi such as the Bhubaneswar Rajdhani had to undergo the change at Kharagpur. This frequent loco change on a trunk route became a time consuming & inconvenient process. With electrification along the 765 km Kharagpur-Visakhapatnam stretch, trains got speeded up and the need for double headed diesels for high speed express trains was eliminated thus saving on diesel consumption and a cleaner travel. Additionally the line branching off Khurda road towards Puri was also electrified. Gradually the Cuttack-Angul line, Cuttack-Paradeep line and branch line from Jakhapura towards Barbil got electrified too.		The major railway stations in the entire zone are Bhubaneswar, Cuttack, Puri, Khurda Road, Bhadrak, Jajpur Keonjhar Road, Brahmapur, Angul, Sambalpur, Balangir, Titlagarh, Bargarh Road, Kantabanji, Rayagada, Palasa, Visakhapatnam, srikakulam road\amudavalasa and Vizianagaram.		Most of the major stations fall in the state of Odisha and Andhra Pradesh .		East Coast Railway zone has about 273 railway stations with a track length of 5214 km spread as follows:-		ECoR zone has below tracks. All are (1,676 mm (5 ft 6 in)) broad gauge. The sections are:-		
Praia do Cassino (Portuguese for Casino Beach) is the southernmost beach of the Brazilian coast (33°07′34″S 52°38′22″W﻿ / ﻿33.126080°S 52.639327°W﻿ / -33.126080; -52.639327), on the South Atlantic Ocean, in the state of Rio Grande do Sul. It is thought to be the longest uninterrupted sandy seashore in the world, with various sources measuring it from 212 kilometres (132 mi)[1] to 254 kilometres (158 mi),[2][3] stretching from the Molhes (breakwaters) at the entrance of the Rio Grande seaport in the north to the mouth of the Chuí Stream, on the border with Uruguay, in the south.		
A regressive delta is a body of sediment that forms at the landward end of a gut.[1]		In contrast to river deltas, regressive deltas are not caused by fluvial sedimentation but by marine sedimentation. During storm events, sediment-bearing sea water is pressed through the gut into the adjacent lagoon. Sedimentation takes place immediately after the water has passed the gut because the velocity of the current strongly decreases. The surplus water will leave the lagoon at leeward guts.		Well-known regressive deltas on the Baltic Sea coast are those of the Prerower Strom in northeast Germany and the Świna in northwest Poland.[2]		
This is a list of beaches in Singapore. Although Singapore is a nation composed of islands, the physical state and extent of its beaches today pales in comparison to their proliferation and quality two centuries ago. Rapid urbanisation and land use pressures necessitated the disappearance of most of these natural beaches as a result of land reclamation.[1][citation needed]		Today, most of the beaches still in existence are man-made, formed at the edges of newly reclaimed land, the longest being the one along the East Coast Park.[2][citation needed] There is currently (June 2009) plans for a further man-made beach in dedication to Jorge Toomer, Ian Curnow and Ben Smith, due to their efforts in sea turtle cultivation.[citation needed] One of the oldest naturally existing stretches of beach is at the northern end of Changi Beach.						
Headlands and bays are two related coastal features. Headlands and bays are often found on the same coastline. A bay is a body of water, either seawater (salt water) or fresh water, surrounded by land on three sides, whereas a headland is land surrounded by water on three sides. Headlands are characterized by high, breaking waves, rocky shores, intense erosion, and steep sea cliffs. Bays generally have less wave activity, and often less wind activity than the areas of water outside the bay, and typically have sandy beaches. Headlands and bays form on discordant coastlines, where the land consists of bands of rock of alternating resistance that run perpendicular to the coast.						Bays form where weak, or less resistant rocks, such as sands and clays, are eroded, leaving bands of stronger, or more resistant rocks, such as chalk, limestone, and granite), which form a headland or peninsula. Refraction of waves occurs on headlands concentrating wave energy on them, so many other landforms, such as caves, natural arches, and stacks, form on headlands. Wave energy is directed at right angles to the wave crest, and lines drawn at right angles to the wave crest (orthogonals) represent the direction of energy expenditure. Orthogonals converge on headlands and diverge in bays, which concentrates wave energy on the headlands and dissipates wave energy in the bays.[1]		In the formation of sea cliffs, wave erosion undercuts the slopes at the shoreline, which retreat landward. This increases the shear stress in the cliff-forming material and accelerates mass movement.[1] The debris from these landslides collects at the base of the cliff and is also removed by the waves, usually during storms, when wave energy is greatest. This debris provides sediment, which is transported through longshore current for the nearby bay. Joints in the headlands are eroded back to form caves, which erode further to form arches. These gaps eventually collapse and leave tall stacks at the ends of the headlands. Eventually these too are eroded by the waves.[2]		Wave refraction disperses wave energy through the bay, and along with the sheltering effect of the headlands this protects bays from storms. This effect means that the waves reaching the shore in a bay are weaker than the waves reaching the headland, and the bay is thus a safer place for water activities like surfing or swimming. Through the deposition of sediment within the bay and the erosion of the headlands, coastlines eventually straighten out. But then the same process starts all over again.		Beaches are dynamic geologic features that can fluctuate between advancement and retreat of sediment. The natural agents of fluctuation include waves, tides, currents, and winds. Man-made elements such as the interruption of sediment supply, such as a dam, and withdrawal of fluid can also affect beach stabilization.[3] A headland bay beach can be classified as being in three different states of sedimentation. Static equilibrium refers to a beach that is stable and does not experience littoral drift or sediment deposition or erosion.[4] Waves generally diffract around the headland(s) and near the beach when the beach is in a state of static equilibrium. Dynamic equilibrium occurs when the beach sediments are deposited and eroded at approximately equal rates.[4] Beaches that have dynamic equilibrium are usually near a river that supplies sediment and would otherwise erode away without the river supply. Unstable beaches are usually a result of human interaction, such as a breakwater or dammed river.[4] Unstable beaches are reshaped by continual erosion or deposition and will continue to erode or deposit until a state of equilibrium is reached in the bay.		
A raised beach, marine terrace, coastal terrace,[1] or perched coastline is a relatively flat, horizontal or gently inclined surface of marine origin,[2] mostly an old abrasion platform which has been lifted out of the sphere of wave activity (sometimes called "tread"). Thus, it lies above or under the current sea level, depending on the time of its formation.[3][4] It is bounded by a steeper ascending slope on the landward side and a steeper descending slope on the seaward side[2] (sometimes called "riser"). Due to its generally flat shape it is often used for anthropogenic structures such as settlements and infrastructure.[3]		A raised beach is an emergent coastal landform. Raised beaches and marine terraces are beaches or wave-cut platforms raised above the shoreline by a relative fall in the sea level.[5]		Around the world, a combination of tectonic coastal uplift and Quaternary sea-level fluctuations has resulted in the formation of marine terrace sequences, most of which were formed during separate interglacial highstands that can be correlated to marine isotope stages (MIS).[6]		A marine terrace commonly retains a shoreline angle or inner edge, the slope inflection between the marine abrasion platform and the associated paleo sea-cliff. The shoreline angle represents the maximum shoreline of a transgression and therefore a paleo-sea level.						The platform of a marine terrace usually has a gradient between 1°–5° depending on the former tidal range with, commonly, a linear to concave profile. The width is quite variable, reaching up to 1,000 metres (3,300 ft), and seems to differ between the northern and southern hemispheres.[9] The cliff faces that delimit the platform can vary in steepness depending on the relative roles of marine and subaerial processes.[10] At the intersection of the former shore (wave-cut/abrasion-) platform and the rising cliff face the platform commonly retains a shoreline angle or inner edge (notch) that indicates the location of the shoreline at the time of maximum sea ingression and therefore a paleo-sea level.[11] Sub-horizontal platforms usually terminate in a low tide cliff, and it is believed that the occurrence of these platforms depends on tidal activity.[10] Marine terraces can extend for several tens of kilometers parallel to the coast.[3]		Older terraces are covered by marine and/or alluvial or colluvial materials while the uppermost terrace levels usually are less well preserved.[12] While marine terraces in areas of relatively rapid uplift rates (> 1 mm/year) can often be correlated to individual interglacial periods or stages, those in areas of slower uplift rates may have a polycyclic origin with stages of returning sea levels following periods of exposure to weathering.[2]		Marine terraces can be covered by a wide variety of soils with complex histories and different ages. In protected areas, allochtonous sandy parent materials from tsunami deposits may be found. Common soil types found on marine terraces include planosols and solonetz.[13]		It is now widely thought that marine terraces are formed during the separated highstands of interglacial stages correlated to marine isotope stages (MIS).[14][15][16][17][18]		The formation of marine terraces is controlled by changes in environmental conditions and by tectonic activity during recent geological times. Changes in climatic conditions have led to eustatic sea-level oscillations and isostatic movements of the Earth’s crust, especially with the changes between glacial and interglacial periods.		Processes of eustasy lead to glacioeustatic sea level fluctuations due to changes of the water volume in the oceans and hence to regressions and transgressions of the shoreline. At times of maximum glacial extent during the last glacial period, the sea level was about 100 metres (330 ft) lower compared to today. Eustatic sea level changes can also be caused by changes in the void volume of the oceans, either through sedimento-eustasy or tectono-eustasy.[19]		Processes of isostasy involve the uplift of continental crusts along with their shorelines. Today, the process of glacial isostatic adjustment mainly applies to Pleistocene glaciated areas.[19] In Scandinavia, for instance, the present rate of uplift reaches up to 10 millimetres (0.39 in)/year.[20]		In general, eustatic marine terraces were formed during separate sea level highstands of interglacial stages[19][21] and can be correlated to marine oxygene isotopic stages (MIS).[22][23] Glacioisostatic marine terraces were mainly created during stillstands of the isostatic uplift.[19] When eustasy was the main factor for the formation of marine terraces, derived sea level fluctuations can indicate former climate changes. This conclusion has to be treated with care, as isostatic adjustments and tectonic activities can be extensively overcompensated by a eustatic sea level rise. Thus, in areas of both eustatic and isostatic or tectonic influences, the course of the relative sea level curve can be complicated.[24] Hence, most of today's marine terrace sequences were formed by a combination of tectonic coastal uplift and Quaternary sea level fluctuations.		Jerky tectonic uplifts can also lead to marked terrace steps while smooth relative sea level changes may not result in obvious terraces, and their formations are often not referred to as marine terraces.[11]		Marine terraces often result from marine erosion along rocky coast lines[2] in temperate regions due to wave attack and sediment carried in the waves. Erosion also takes place in connection with weathering and cavitation. The speed of erosion is highly dependent on the shoreline material (hardness of rock[10]), the bathymetry, and the bedrock properties and can be between only a few millimeters per year for granitic rocks and more than 10 metres (33 ft) per year for volcanic ejecta.[10][25] The retreat of the sea cliff generates a shore (wave-cut/abrasion-) platform through the process of abrasion. A relative change of the sea level leads to regressions or transgressions and eventually forms another terrace (marine-cut terrace) at a different altitude while notches in the cliff face indicate short stillstands.[25]		It is believed that the terrace gradient increases with tidal range and decreases with rock resistance. In addition, the relationship between terrace width and the strength of the rock is inverse, and higher rates of uplift and subsidence as well as a higher slope of the hinterland increases the number of terraces formed during a certain time.[26]		Furthermore, shore platforms are formed by denudation and marine-built terraces arise from accumulations of materials removed by shore erosion.[2] Thus a marine terrace can be formed by both erosion and accumulation. However, there is an ongoing debate about the roles of wave erosion and weathering in the formation of shore platforms.[10]		Reef flats or uplifted coral reefs are another kind of marine terrace found in intertropical regions. They are a result of biological activity, shoreline advance and accumulation of reef materials.[2]		While a terrace sequence can date back hundreds of thousands of years, its degradation is a rather fast process. On the one hand a deeper transgression of cliffs into the shoreline may completely destroy previous terraces; on the other hand older terraces might be decayed[25] or covered by deposits, colluvia or alluvial fans.[3] Erosion and backwearing of slopes caused by incisive streams play another important role in this degradation process.[25]		The total displacement of the shoreline relative to the age of the associated interglacial stage allows calculation of a mean uplift rate or the calculation of eustatic level at a particular time if the uplift is known.		In order to estimate vertical uplift, the eustatic position of the considered paleo sea levels relative to the present one must be known as precisely as possible. Our chronology relies principally on relative dating based on geomorphologic criteria but in all cases we associated the shoreline angle of the marine terraces with numerical ages. The best-represented terrace worldwide is the one correlated to the last interglacial maximum (MISS 5e) (Hearty and Kindler, 1995; Johnson and Libbey, 1997, Pedoja et al., 2006 a,[27] b,[28] c[29]). Age of MISS 5e is arbitrarily fixed to range from 130 to 116 ka (Kukla et al., 2002[30]) but is demonstrated to range from 134 to 113 ka in Hawaii and Barbados (Muhs et al., 2002) with a peak from 128 to 116 ka on tectonically stable coastlines (Muhs, 2002). Older marine terraces well represented in worldwide sequences are those related to MIS 9 (~303-339 ka) and 11 (~362-423 ka) (Imbrie et al., 1984[31]). Compilations show that sea level was 3 ± 3 meters higher during MISS 5e, MIS 9 and 11 than during the present one and –1 ± 1 m to the present one during MIS 7 (Hearty and Kindler, 1995,[32] Zazo, 1999[33]). Consequently, MIS 7 (~180-240 ka; Imbrie et al., 1984) marine terraces are less pronounced and sometimes absent (Zazo, 1999). When the elevations of these terraces are higher than the uncertainties in paleo-eustatic sea level mentioned for the Holocene and Late Pleistocene, these uncertainties have no effect on overall interpretation.		Sequence can also occurs where the accumulation of ice sheets have depressed the land so that when the ice sheets melts the land readjusts with time thus raising the height of the beaches (glacio-isostatic rebound)and in places where co-seismic uplift occur. In the latter case, the terrace are not correlated with sea level highstand even if co-seismic terrace are known only for the Holocene.		For exact interpretations of the morphology extensive datings, surveying and mapping of marine terraces is applied. This includes stereoscopic aerial photographic interpretation (ca. 1 : 10,000 - 25,000[11]), on-site inspections with topographic maps (ca. 1 : 10,000) and analysis of eroded and accumulated material. Moreover, the exact altitude can be determined with an aneroid barometer or preferably with a levelling instrument mounted on a tripod. It should be measured with the accuracy of 1 cm and at about every 50 – 100 m, depending on the topography. In remote areas technics of photogrammetry and tacheometry can be applied.[24]		Different methods for dating and correlation of marine terraces can be used and combined.		The morphostratigraphic approach focuses especially in regions of marine regression on the altitude as the most important criterion to distinguish coast lines of different ages. Moreover, individual marine terraces can be correlated based on their size and continuity. Also paleo-soils as well as glacial, fluvial, eolian and periglacial landforms and sediments may be used to find correlations between terraces.[24] On New Zealand’s North Island, for instance, tephra and loess were used to date and correlate marine terraces.[34] At the terminus advance of former glaciers marine terraces can be correlated by their size, as their width decreases with age due to the slowly thawing glaciers along the coast line.[24]		The lithostratigraphic approach uses typical sequences of sediment and rock strata to prove sea level fluctuations on the basis of an alternation of terrestrial and marine sediments or littoral and shallow marine sediments. Those strata show typical layers of transgressive and regressive patterns.[24] However, an unconformity in the sediment sequence might make this analysis difficult.[35]		The biostratigraphic approach uses remains of organisms which can indicate the age of a marine terrace. For that often mollusc shells, foraminifera or pollen are used. Especially Mollusca can show specific properties depending on their depth of sedimentation. Thus they can be used to estimate former water depths.[24]		Marine terraces are often correlated to marine oxygene isotopic stages (MIS) (e.g. Johnson, M. E.; Libbey, L. K. 1997[22]) and can also be roughly dated using their stratigraphic position.[24]		There are various methods for the direct dating of marine terraces and their related materials including 14C radiocarbon dating, which is the most common one.[36] E.g. this method has been used on the North Island of New Zealand to date several marine terraces.[37] It utilizes terrestrial biogenic materials in coastal sediments such as mollusc shells analyzing the 14C isotope.[24] In some cases dating based on the 230Th/234U ratio was applied though in case of detrital contamination or low uranium concentrations a high resolution dating was found to be difficult.[38] In a study in southern Italy paleomagnetism was used to carry out paleomagnetic datings[39] and luminescence dating (OSL) was used in different studies on the San Andreas Fault[40] and on the Quaternary Eupcheon Fault in South Korea.[41] In the last decennia, the dating of marine terraces has been enhanced since the arrival of terrestrial cosmogenic nuclides method, and particularly through the use of 10Be and 26Al cosmogenic isotopes produced in-situ.[42][43][44] These isotopes record the duration of surface exposure to cosmic rays.[45] and this exposure age reflects the age of abandonment of a marine terrace by the sea.		In order to calculate the eustatic sea level for each dated terrace it is assumed that the eustatic sea-level position corresponding to at least one marine terrace is known and that the uplift rate has remained essentially constant in each section.[2]		Marine terraces play an important role in the research on tectonics and earthquakes. They may show patterns and rates of tectonic uplift[40][44][46] and thus may be used to estimate the tectonic activity in a certain region.[41] In some cases the exposed secondary landforms can be correlated with known seismic events such as the 1855 Wairarapa earthquake on the Wairarapa Fault near Wellington, New Zealand which produced a 2.7 m uplift.[47] This figure can be estimated from the vertical offset between raised shorelines in the area.[48]		Furthermore, with the knowledge of eustatic sea level fluctuations the speed of isostatic uplift can be estimated[49] and eventually the change of relative sea levels for certain regions can be reconstructed. Thus marine terraces also provide information for the research on climate change and trends in future sea level changes.[10][50]		When analyzing the morphology of marine terraces it must be considered, that both eustasy and isostasy can have an influence on the formation process. This way can be assessed, whether there were changes in sea level or whether tectonic activities took place.		Raised beaches are found in a wide variety of coast and geodynamical background such as subduction on the pacific coast of South America (Pedoja et al., 2006), of North America, passive margin of the Atlantic coast of South America (Rostami et al., 2000[51]), collision context on the Pacific coast of Kamchatka (Pedoja et al., 2006), Papua New Guinea, New Zealand, Japan (Ota and Yamaguchi, 2004), passive margin of the South China sea coast (Pedoja et al., in press), on west-facing Atlantic coasts, such as Donegal Bay, County Cork and County Kerry in Ireland; Bude, Widemouth Bay, Crackington Haven, Tintagel, Perranporth and St Ives in Cornwall, the Vale of Glamorgan, Gower Peninsula, Pembrokeshire and Cardigan Bay in Wales, the Isle of Jura and Isle of Arran in Scotland, Finistère in Brittany and Galicia in Northern Spain and at Squally Point in Eatonville, Nova Scotia within the Cape Chignecto Provincial Park.		Other important sites include various coasts of New Zealand, e.g. Turakirae Head near Wellington being one of the world’s best and most thoroughly studied examples.[47][48][52] Also along the Cook Strait in New Zealand there is a well-defined sequence of uplifted marine terraces from the late Quaternary at Tongue Point. It features a well preserved lower terrace from the last interglacial, a widely eroded higher terrace from the penultimate interglacial and another still higher terrace, which is nearly completely decayed.[47] Furthermore, on New Zealand’s North Island at the eastern Bay of Plenty a sequence of seven marine terraces has been studied.[12][37]		Along many coasts of mainland and islands around the Pacific, marine terraces are typical coastal features. An especially prominent marine terraced coastline can be found north of Santa Cruz, near Davenport, California, where terraces probably have been raised by repeated slip earthquakes on the San Andreas Fault.[40][53] Hans Jenny (pedologist) famously researched the pygmy forests of the Mendocino and Sonoma county marine terraces. The marine terrace's "ecological staircase" of Salt Point State Park is also bound by the San Andreas Fault.		Along the coasts of South America marine terraces are present,[44][54] where the highest ones are situated where plate margins lie above subducted oceanic ridges and the highest and most rapid rates of uplift occur.[7][46] At Cape Laundi, Sumba Island, Indonesia an ancient patch reef can be found at 475 m above sea level as part of a sequence of coral reef terraces with eleven terraces being wider than 100 m.[55] The coral marine terraces at Huon Peninsula, New Guinea, which extend over 80 km and rise over 600 m above present sea level[56] are currently on UNESCO’s tentative list for world heritage sites under the name Houn Terraces - Stairway to the Past.[57]		Other considerable examples include marine terraces rising up to 360 m on some Philippine Islands[58] and along the Mediterranean Coast of North Africa, especially in Tunisia, rising up to 400 m.[59]		Uplift can also be registered through tidal notch sequences. Notches are often portrayed as lying at sea level; however notch types actually form a continuum from wave notches formed in quiet conditions at sea level to surf notches formed in more turbulent conditions and as much as 2 m (6.6 ft) above sea level (Pirazzoli et al., 1996 in Rust and Kershaw, 2000[60]). As stated above, there was at least one higher sea level during the Holocene, so that some notches may not contain a tectonic component in their formation.		
A steep coast[1] is a stretch of coastline where the mainland descends abruptly into the sea. There is a sharp transition from the land to sea as opposed to that on a flat coast where the land descends gradually seawards. The height of the land on a steep coast is well above sea level.		Most steep coast are rocky cliffed coasts (also called abrasion coasts), where the erosion processes of wave action result in a steep declivity. Another type of steep coast is the fjord which is formed when a glacial valley lies partially under water as a result of a rise in sea levels. In Norway, New Zealand or Alaska there are fjords whose almost vertical sides tower over 1,000 metres above the water and plunge 300 metres below it.		On volcanic islands the sea can enter the caldera and the face of the volcanic pipe can form a steep coastline. The best-known example of that is Santorini in the archipelago of the Cyclades in Greeces. The main town of Thira lies on the rim of the caldera which is around 300 metres above the sea and drops below it for another 200 metres.		
A rip current, often referred to simply as a rip, or by the misnomer rip tide, is a specific kind of water current which can occur near beaches with breaking waves. However, a rip can often be hard to see and absent from breaking waves, and only recognised by a ripple on the top of the water that heads out to sea.[citation needed] A rip is a strong, localized, and narrow current of water which moves directly away from the shore, cutting through the lines of breaking waves like a river running out to sea, and is strongest near the surface of the water.[1]		Rip currents can be hazardous to people in the water. Swimmers who are caught in a rip and who do not understand what is going on, and who may not have the necessary water skills, may panic, or exhaust themselves by trying to swim directly against the flow of water. Because of these factors, rips are the leading cause of rescues by lifeguards at beaches, and in the US rips are the cause of an average of 46 deaths by drowning per year.		A rip current is not the same thing as undertow, although some people use the latter term incorrectly when they mean a rip current. Contrary to popular belief, neither rip nor undertow can pull a person down and hold them under the water. A rip simply carries floating objects, including people, out beyond the zone of the breaking waves.						A rip current forms because wind and breaking waves push surface water towards the land, and this causes a slight rise in the water level along the shore, which will tend to flow back to the open water by the route of least resistance. When there is a local area which is slightly deeper or a break in an offshore bar or reef, this can allow water to flow offshore more easily, and this will initiate a rip current through that gap. Water that has been pushed up near the beach flows along shore towards the outgoing rip as feeder currents, and then flows out at approximately a right angle to the beach in a tight current called the "neck" of the rip, where the flow is most rapid. When the water in the rip current reaches outside of the lines of breaking waves, the flow disperses sideways, loses power, and dissipates in what is known as the "head" of the rip.		Rip currents can occur on a gently shelving shore where breaking waves approach near perpendicular to the average shoreline, or where underwater topography encourages outflow at a specific area. They can form at the coasts of oceans, seas, and large lakes when there are waves with sufficient energy. The location of rip currents can be difficult to predict. While some tend to recur always in the same place, others can appear and disappear suddenly at various locations along the beach. This will depend on the bottom topography and the direction of the waves.[2]		Rip currents can potentially occur wherever there is strong longshore variability in wave breaking. This variability may be caused by such features as sandbars (as shown in the animated diagram), by piers and jetties, and even by crossing wave trains, and are often located in places such as where there is a gap in a reef or low area on a sandbar, and may deepen the channel through a sandbar once formed. Rip currents are usually quite narrow, but tend to be more common, wider and faster, when and where breaking waves are large and powerful. Local underwater topography makes some beaches more likely to have rip currents; a few beaches are notorious in this respect.[3]		Although rip tide is a misnomer, in areas of significant tidal range, rip currents may only occur at certain stages of the tide, when the water is shallow enough to cause the waves to break over the bar, and deep enough for the broken wave to flow over the bar. If the shoreline shelves gently, in parts of the world with a big difference between high tide and low tide, the distance between the bar and the shoreline may vary from a few feet to a mile or more over the rise or fall of the tide.		A fairly common misconception is that rip currents can pull a swimmer down, under the surface of the water. This is not true, and in reality a rip current is strongest close to the surface, as the flow near the bottom is slowed by friction. The rip current generally flows in a deeper channel, where waves are less likely to break, or where the waves break further offshore due to the effect of current against waves, leading to the illusion of a calmer area of water inshore, without waves, which may attract some swimmers to that area.[4]		A more detailed description involves radiation stress. This is the force (or momentum flux) exerted on the water column by the presence of the wave. As a wave shoals and increases in height prior to breaking, radiation stress increases.[clarification needed] To balance this, the local mean surface level (the water level with the wave averaged out) drops — this is known as setdown. As the wave breaks and continues to reduce in height, the radiation stress decreases.[clarification needed] To balance this force,[clarification needed] the mean surface increases—this is known as setup. As a wave propagates over a sandbar with a gap (as shown in the lead image), the wave breaks on the bar, leading to setup. However, the part of the wave that propagates over the gap does not break, and thus setdown will continue. Thus, the mean surface over the bars is higher than that over the gap, and a strong flow issues outward through the gap.[clarification needed]		Rip currents have a characteristic appearance, so they can be visually identified from the shore. This is useful to lifeguards, swimmers, surfers, boaters, divers and other water users, who may need to avoid or make use of the current flow. Rip currents often look a bit like a road or a river running straight out to sea, and are easiest to notice and identify when the zone of breaking waves is viewed from a high vantage point. The following are some characteristics that can be used to visually identify a rip:[5]		These characteristics are helpful in learning to recognize and understand the nature of rip currents so that a person can recognize the presence of rips before entering the water. In the US, some beaches have signs created by NOAA and USLA, explaining what a rip current is and how to escape one. These signs are entitled, "Rip Currents; Break the Grip of the Rip".[6] Beachgoers can get information from lifeguards, who are always watching for rip currents, and who will move their safety flags so that swimmers can avoid rips.		Rip currents are a potential source of danger for people in shallow water with breaking waves in seas, oceans and lakes.[5] Rip currents are the proximate cause of 80% of rescues carried out by beach lifeguards.[7]		Rip currents typically flow at about 0.5 metres per second (1–2 feet per second), but they can be as fast as 2.5 metres per second (8 feet per second), which is faster than any human can swim. However, most rip currents are fairly narrow, and even the widest rip currents are not very wide; swimmers can easily exit the rip by swimming at a right angle to the flow, parallel to the beach. Swimmers who are unaware of this fact may exhaust themselves trying unsuccessfully to swim against the flow.[2] The flow of the current also fades out completely at the head of the rip, outside the zone of the breaking waves, so there is a definite limit to how far the swimmer will be taken out to sea by the flow of a rip current.		In a rip current, death by drowning occurs when a person has limited water skills and panics, or when a swimmer persists in trying to swim to shore against a strong rip current, thus eventually becoming exhausted and unable to stay afloat.		According to NOAA, over a 10-year average, rip currents cause 46 deaths annually in the United States, and 64 people died in rip currents in 2013.[8] However, the United States Lifesaving Association "estimates that the annual number of deaths due to rip currents on our nation's beaches exceeds 100.”[6]		A study published in 2013 in Australia revealed that rips killed more people on Australian territory than bushfires, floods, cyclones and shark attacks combined.[9]		A person caught in a rip current may notice that he or she is moving away from the shore quite rapidly. It is often not possible to swim directly back to shore against a rip current, so this is not recommended. Contrary to popular misunderstanding, a rip does not pull a swimmer under the water, it simply carries the swimmer away from the shore in a narrow band of moving water.[1] The rip is like a moving treadmill, which the swimmer can get out of by swimming across the current, parallel to the shore, in either direction, until out of the rip current, which is usually not very wide. Once out of the rip, swimming back to shore is relatively easy in areas where waves are breaking and where floating objects (including swimmers) are being pushed towards the shore.[10]		As an alternative, swimmers or who are caught in a strong rip can relax and go with the flow (either floating or treading water) until the current dissipates beyond the surf line, and then they can signal for help, or swim back through the surf diagonally away from the rip and towards the shore.[11]		It is necessary for coastal swimmers to understand the danger of rip currents, to learn how to recognize them and how to deal with them, and if possible to swim in only those areas where lifeguards are on duty.[5]		Experienced and knowledgeable water users, including surfers, body boarders, divers, surf lifesavers and kayakers, will sometimes use rip currents as a rapid and effortless means of transportation when they wish to get out beyond the breaking waves. [12]		
in Europe  (green & dark grey)		Monaco (/ˈmɒnəkoʊ/ ( listen); French pronunciation: ​[mɔnako]), officially the Principality of Monaco (French: Principauté de Monaco),[a] is a sovereign city-state, country and microstate located on the French Riviera in Western Europe. France borders the country on three sides while the other side borders the Mediterranean Sea. Monaco has an area of 2.02 km2 (0.78 sq mi) and a population of about 38,400 according to the last census of 2016.[6] With 19,009 inhabitants per km², it is the second smallest and second most densely populated country in the world. Monaco has a land border of 5.47 km (3.40 mi),[6] a coastline of 3.83 km (2.38 mi), and a width that varies between 1,700 and 349 m (1,859 and 382 yd). The highest point in the country is a narrow pathway named Chemin des Révoires on the slopes of Mont Agel, in the Les Révoires Ward, which is 161 metres (528 feet) above sea level. Monaco's most populous Quartier is Monte Carlo and the most populous Ward is Larvotto/Bas Moulins. Through land reclamation, Monaco's land mass has expanded by twenty percent; in 2005, it had an area of only 1.974 km2 (0.762 sq mi). Monaco is known as a playground for the rich and famous, due to its tax laws. In 2014, it was noted about 30% of the population was made up of millionaires, more than in Zürich or Geneva.[10]		Monaco is a principality governed under a form of constitutional monarchy, with Prince Albert II as head of state. Although Prince Albert II is a constitutional monarch, he wields immense political power. The House of Grimaldi have ruled Monaco, with brief interruptions, since 1297.[11] The official language is French, but Monégasque, Italian, and English are widely spoken and understood.[b] The state's sovereignty was officially recognized by the Franco-Monegasque Treaty of 1861, with Monaco becoming a full United Nations voting member in 1993. Despite Monaco's independence and separate foreign policy, its defense is the responsibility of France. However, Monaco does maintain two small military units.		Economic development was spurred in the late 19th century with the opening of the country's first casino, Monte Carlo, and a railway connection to Paris.[12] Since then, Monaco's mild climate, scenery, and gambling facilities have contributed to the principality's status as a tourist destination and recreation center for the rich. In more recent years, Monaco has become a major banking center and has sought to diversify its economy into services and small, high-value-added, non-polluting industries. The state has no income tax, low business taxes, and is well known for being a tax haven. It is also the host of the annual street circuit motor race Monaco Grand Prix, one of the original Grands Prix of Formula One.		Monaco is not formally a part of the European Union (EU), but it participates in certain EU policies, including customs and border controls. Through its relationship with France, Monaco uses the euro as its sole currency (prior to this it used the Monégasque franc). Monaco joined the Council of Europe in 2004. It is a member of the Organisation Internationale de la Francophonie (OIF).						Monaco's name comes from the nearby 6th-century BC Phocaean Greek colony. Referred to by the Ligurians as Monoikos, from the Greek "μόνοικος", "single house", from "μόνος" (monos) "alone, single"[13] + "οἶκος" (oikos) "house",[14] which bears the sense of a people either settled in a "single habitation" or of "living apart" from others. According to an ancient myth, Hercules passed through the Monaco area and turned away the previous gods.[15] As a result, a temple was constructed there, the temple of Hercules Monoikos. Because the only temple of this area was the "House" of Hercules, the city was called Monoikos.[16][17] It ended up in the hands of the Holy Roman Empire, which gave it to the Genoese. An ousted branch of a Genoese family, the Grimaldi, contested it for a hundred years before actually gaining control. Though the Republic of Genoa would last until the 19th century, they allowed the Grimaldi family to keep Monaco, and, likewise, both France and Spain left it alone for hundreds of years. France did not annex it until the French Revolution, but after the defeat of Napoleon it was put under the care of the Kingdom of Sardinia. In the 19th century, when Sardinia became a part of Italy, the region came under French influence again but France allowed it to remain independent. Like France, Monaco was over-run by the Axis powers during the Second World War and for a short time was administered by Italy, then the Third Reich, before finally being liberated. Although the occupation lasted for just a short time, it meant the deportation of the Jewish population and execution of several resistance members from Monaco. Since then Monaco has been independent. It has taken some steps towards integration with the European Union.		Following a land grant from Emperor Henry VI in 1191, Monaco was refounded in 1215 as a colony of Genoa.[18][19] Monaco was first ruled by a member of the House of Grimaldi in 1297, when Francesco Grimaldi, known as "Il Malizia" (translated from Italian either as "The Malicious One" or "The Cunning One"), and his men captured the fortress protecting the Rock of Monaco while dressed as Franciscan monks – a monaco in Italian, although this is a coincidence as the area was already known by this name.[20] Francesco, however, was evicted only a few years afterwards by the Genovese forces, and the struggle over "the Rock" continued for another century.[21] The Grimaldi family was Genoese and the struggle was something of a family feud. However, the Genoese became engaged in other conflicts, and in the late 1300s Genoa became involved in a conflict with the Crown of Aragon over Corsica.[22] The Crown of Aragon eventually became a part of Spain through marriage (see modern day Catalonia) and other parts drifted into various pieces of other kingdoms and nations.[22]		In 1419, the Grimaldi family purchased Monaco from the Crown of Aragon and became the official and undisputed rulers of "the Rock of Monaco". In 1612 Honoré II began to style himself "Prince" of Monaco.[23] In the 1630s, he sought French protection against the Spanish forces and, in 1642, was received at the court of Louis XIII "Duc et Pair Etranger".[24] The princes of Monaco thus became vassals of the French kings while at the same time remaining sovereign princes.[25] Though successive princes and their families spent most of their lives in Paris, and intermarried with French and Italian nobilities, the House of Grimaldi is Italian. The principality continued its existence as a protectorate of France until the French Revolution.[26]		In 1793, Revolutionary forces captured Monaco and it remained under direct French control until 1814, when the Grimaldi family returned to the throne.[24][27]		Between 1793 and 1814 Monaco was occupied by the French (in this period much of Europe had been overrun by the French under command of Napoleon).[24][27] The principality was reestablished in 1814 only to be designated a protectorate of the Kingdom of Sardinia by the Congress of Vienna in 1815.[27] Monaco remained in this position until 1860 when, by the Treaty of Turin, the Sardinian forces pulled out of the principality and the surrounding county of Nice (as well as Savoy) was ceded to France.[28] Monaco became a French protectorate once again. Before this time there was unrest in Menton and Roquebrune, where the townspeople had become weary of heavy taxation by the Grimaldi family. They declared their independence, hoping for annexation by Sardinia. France protested. The unrest continued until Charles III gave up his claim to the two mainland towns (some 95% of the principality at the time) that had been ruled by the Grimaldi family for over 500 years.[29] These were ceded to France in return for 4,100,000 francs.[30] The transfer and Monaco's sovereignty were recognized by the Franco-Monegasque Treaty of 1861. In 1869, the principality stopped collecting income tax from its residents—an indulgence the Grimaldi family could afford to entertain thanks solely to the extraordinary success of the casino.[31] This made Monaco not only a playground for the rich, but a favored place for them to live.[32]		Until the Monegasque Revolution of 1910 forced the adoption of the 1911 constitution, the princes of Monaco were absolute rulers.[33] The new constitution, however, barely reduced the autocratic rule of the Grimaldi family and Prince Albert I soon suspended it during the First World War.		In July 1918, the Franco-Monegasque Treaty was signed, providing for limited French protection over Monaco. The treaty, endorsed in 1919 by the Treaty of Versailles, established that Monegasque international policy would be aligned with French political, military, and economic interests, and resolved the Monaco Succession Crisis.[34]		In 1943, the Italian Army invaded and occupied Monaco, forming a fascist administration.[35] Shortly thereafter, following the collapse of Mussolini, the German Wehrmacht occupied Monaco and the Nazi deportation of the Jewish population began. René Blum, the prominent French Jew who founded the Ballet de l'Opera in Monte Carlo, was arrested in his Paris home and held in the Drancy deportation camp outside the French capital before being transported to the Auschwitz concentration camp, where he was later killed.[36] Blum's colleague Raoul Gunsbourg, the director of the Opéra de Monte-Carlo, helped by the French Resistance, escaped arrest and fled to Switzerland.[37] In August 1944, the Germans executed René Borghini, Joseph-Henri Lajoux and Esther Poggio, who were Resistance leaders.		Rainier III, who ruled until 2005, succeeded to the throne following the death of his grandfather, Prince Louis II, in 1949. On 19 April 1956, Prince Rainier married the American actress Grace Kelly; the event was widely televised and covered in the popular press, focusing the world's attention on the tiny principality.[38]		A 1962 amendment to the constitution abolished capital punishment, provided for women's suffrage, and established a Supreme Court of Monaco to guarantee fundamental liberties.		In 1963, a crisis developed when Charles de Gaulle blockaded Monaco, angered by its status as a tax haven for wealthy French. The 2014 film Grace of Monaco is loosely based on this crisis.[39]		In 1993, the Principality of Monaco became a member of the United Nations, with full voting rights.[28][40]		In 2002, a new treaty between France and Monaco specified that, should there be no heirs to carry on the Grimaldi dynasty, the principality would still remain an independent nation rather than revert to France. Monaco's military defence, however, is still the responsibility of France.[41][42]		On 31 March 2005, Rainier III, who was too ill to exercise his duties, relinquished them to his only son and heir, Albert.[43] He died six days later, after a reign of 56 years, with his son succeeding him as Albert II, Sovereign Prince of Monaco.		Following a period of official mourning, Prince Albert II formally assumed the princely crown on 12 July 2005,[44] in a celebration that began with a solemn Mass at Saint Nicholas Cathedral, where his father had been buried three months earlier. His accession to the Monégasque throne was a two-step event with a further ceremony, drawing heads of state for an elaborate reception, held on 18 November 2005, at the historic Prince's Palace in Monaco-Ville.[45]		On 27 August 2015, Albert II apologised for Monaco's role during World War II in facilitating the deportation of a total of 90 Jews and resistance fighters, of whom only nine survived. "We committed the irreparable in handing over to the neighbouring authorities women, men and a child who had taken refuge with us to escape the persecutions they had suffered in France," Albert said at a ceremony in which a monument to the victims was unveiled at the Monaco cemetery. "In distress, they came specifically to take shelter with us, thinking they would find neutrality."[46]		In 2015, Monaco unanimously approved a modest land reclamation expansion intended primarily for some desperately needed housing and a small green/park area.[47] Monaco had previously considered an expansion in 2008, but called it off.[47] The plan is for about six hectares of apartment buildings, parks, shops and offices for about 1 billion euros for the land.[48] The development will be adjacent to the Larvotto district and also will include a small marina.[48][49] There were four main proposals, and the final mix of use will be finalised as the development progresses.[50] The name for the new district is Anse du Portier.[49]		Monaco has been governed under a constitutional monarchy since 1911, with the Sovereign Prince of Monaco as head of state.[51] The executive branch consists of a Minister of State as the head of government, who presides over a five-member Council of Government.[52] Until 2002, the Minister of State was a French citizen appointed by the prince from among candidates proposed by the French government; since a constitutional amendment in 2002, the Minister of State can be French or Monegasque.[18] However, Prince Albert II appointed, on 3 March 2010, the Frenchman Michel Roger as Minister of State.[53]		Under the 1962 constitution, the prince shares his veto power with the unicameral National Council.[54] The 24 members of the National Council are elected for five-year terms; 16 are chosen through a majority electoral system and 8 by proportional representation.[55] All legislation requires the approval of the National Council, which is currently dominated by the conservative Rally and Issues for Monaco (REM) party which holds twenty seats.[55] Union Monégasque holds three seats[55] while Renaissance holds one seat. The principality's city affairs are directed by the Communal Council,[56] which consists of fourteen elected members and is presided over by a mayor.[57] Unlike the National Council, councillors are elected for four-year terms,[58] and are strictly non-partisan, however, oppositions inside the council frequently form.[56][59]		Monaco is the second smallest country by area in the world; only Vatican City is smaller.[60] Monaco is also the world's second smallest monarchy,[61] and is the most densely populated country in the world.[62] The state consists of only one municipality (commune). There is no geographical distinction between the State and City of Monaco, although responsibilities of the government (state-level) and of the municipality (city-level) are different.[53] According to the constitution of 1911, the principality was subdivided into three municipalities:[63]		The municipalities were merged into one in 1917, after accusations that the government was acting according to the motto "divide and conquer," and they were accorded the status of Wards or Quartiers thereafter.		Subsequently, three additional wards were created:		An additional ward was planned by new land reclamation to be settled beginning in 2014[64] but Prince Albert II announced in his 2009 New Year Speech that he had ended plans due to the current economic climate.[65] However, Prince Albert II in mid-2010 firmly restarted the program.[66][67] In 2015, a new development called Anse du Portier was announced.[49]		The four traditional Quartiers of Monaco are: Monaco-Ville, La Condamine, Monte Carlo and Fontvieille.[68][69] However, the suburb of Moneghetti, the high-level part of La Condamine, is generally seen today as an effective fifth Quartier of the Monaco, having a very distinct atmosphere and topography when compared with low-level La Condamine.[70]		Currently Monaco is subdivided into ten wards, with their official numbers; either Fontvieille II or Le Portier, would become the effective eleventh ward, if built:[67][71][72]		Note: for statistical purposes, the Wards of Monaco are further subdivided into 178 city blocks (îlots), which are comparable to the census blocks in the United States.[73]		The wider defence of the nation is provided by France. Monaco has no navy or air force, but on both a per-capita and per-area basis, Monaco has one of the largest police forces (515 police officers for about 36,000 people) and police presences in the world.[77] Its police includes a special unit which operates patrol and surveillance boats.[78]		There is also a small military force. This consists of a bodyguard unit for the Prince and the palace in Monaco-Ville called the Compagnie des Carabiniers du Prince (Prince's Company of Carabiniers), which is equipped with weapons such as M16A2 rifles and 9 mm pistols (Glock 17),[79] and which together with the militarized, armed fire and civil defence Corps (Sapeurs-Pompiers) forms Monaco's total public forces.[80] The Compagnie des Carabiniers du Prince was created by Prince Honoré IV in 1817 for the protection of the Principality and the Princely family. The company numbers exactly 116 officers and men; while the NCOs and soldiers are local, the officers have generally served in the French Army. In addition to their guard duties as described, the Carabiniers patrol the Principality's beaches and coastal waters.[81]		Monaco is a sovereign city state, with 5 Quartiers and 10 Wards,[82] located on the French Riviera in Western Europe. It is bordered by France's Alpes-Maritimes département on three sides, with one side bordering the Mediterranean Sea. Its center is about 16 km (9.9 mi) from Italy and only 13 km (8.1 mi) northeast of Nice, France.[40] It has an area of 2.02 km2 (0.78 sq mi) or 202 hectares (500 acres) and a population of 38,400,[83] making Monaco the second smallest and the most densely populated country in the world.[40] The country has a land border of only 5.47 km (3.40 mi),[83] a coastline of 3.83 km (2.38 mi), a maritime claim that extends 22.2 kilometres (13.8 mi), and a width that varies between 1,700 and 349 m (5,577 and 1,145 ft).[84][85]		The highest point in the country is at the access to the Patio Palace residential building on the Chemin des Révoires (ward Les Révoires) from the D6007 (Moyenne Corniche street) at 164.4 metres (539 feet) above sea level.[86] The lowest point in the country is the Mediterranean Sea.[87] Saint-Jean is the longest flowing body of water, around 0.19 km (0.12 miles) in length, and Fontvieille is the largest lake, approximately 0.5 ha (1.24 acres) in size.[88] Monaco's most populated Quartier is Monte Carlo, and the most populated Ward is Larvotto/Bas Moulins.[73] After a recent expansion of Port Hercules,[89] Monaco's total area grew to 2.02 km2 (0.78 sq mi) or 202 hectares (500 acres);[73] consequently, new plans have been approved to extend the district of Fontvieille by 0.08 km2 (0.031 sq mi) or 8 hectares (20 acres), with land reclaimed from the Mediterranean Sea. Current land reclamation projects include extending the district of Fontvieille.[90][91][92][89][93] There are two ports in Monaco, Hercules and Port Fontvieille.[94] Monaco's only natural resource is fishing;[95] with almost the entire country being an urban area, Monaco lacks any sort of commercial agriculture industry. There is a neighboring French port called Cap d'Ail that is near Monaco.[94]		Monaco exhibits a wide range of architecture, but the principality's signature style, particularly in Monte-Carlo, is that of the Belle Epoque. It finds its most florid expression in the 1878-9 Casino and Grand Concert Hall created by Charles Garnier and Jules Dutrou. Decorative elements including turrets, balconies, pinnacles, multi-coloured ceramics and caryatids and borrowed and blended to create a picturesque fantasy of pleasure and luxury, and an alluring expression of how Monaco sought, and still seeks, to portray itself.[96] This capriccio of French, Italian and Spanish elements was incorporated into hacienda villas and apartments. Following major development in the 1970s, Prince Rainier III banned high rise development in the principality. However his successor, Prince Albert II, overturned this Sovereign Order.[97] In recent years the accelerating demolition of Monaco's architectural heritage, including its single-family villas, has created dismay.[98] The principality currently has no heritage protection legislation.[99]		Monaco has a hot-summer Mediterranean climate (Köppen climate classification: Csa), which is influenced by the oceanic climate and the humid subtropical climate. As a result, it has warm, dry summers and mild, rainy winters.[100] Cool and rainy interludes can interrupt the dry summer season, the average length of which is also shorter. Summer afternoons are infrequently hot (indeed, temperatures greater than 30 °C or 86 °F are rare) as the atmosphere is temperate because of constant sea breezes. On the other hand, the nights are very mild, due to the fairly high temperature of the sea in summer. Generally, temperatures do not drop below 20 °C (68 °F) in this season. In the winter, frosts and snowfalls are extremely rare and generally occur once or twice every ten years.[101][102]		Monaco has the world's second highest GDP nominal per capita at US$153,177, GDP PPP per capita at $132,571 and GNI per capita at $183,150.[7][105][106] It also has an unemployment rate of 2%,[107] with over 48,000 workers who commute from France and Italy each day.[73] According to the CIA World Factbook, Monaco has the world's lowest poverty rate[108] and the highest number of millionaires and billionaires per capita in the world.[109][110] For the fourth year in a row, Monaco in 2012 had the world's most expensive real estate market, at $58,300 per square metre.[111][112][113]		One of Monaco's main sources of income is tourism. Each year many foreigners are attracted to its casino (where citizens are denied entry[citation needed] ) and pleasant climate.[85][114] It has also become a major banking center, holding over €100 billion worth of funds.[115] The principality has successfully sought to diversify its economic base into services and small, high-value-added, non-polluting industries, such as cosmetics and biothermics.[108]		The state retains monopolies in numerous sectors, including tobacco and the postal service. The telephone network (Monaco Telecom) used to be fully owned by the state; it now owns only 45%, while the remaining 55% is owned by both Cable & Wireless Communications (49%) and Compagnie Monégasque de Banque (6%). It is still, however, a monopoly. Living standards are high, roughly comparable to those in prosperous French metropolitan areas.[116]		Monaco is not a member of the European Union. However, it is very closely linked via a customs union with France and, as such, its currency is the same as that of France, the euro. Before 2002, Monaco minted its own coins, the Monegasque franc. Monaco has acquired the right to mint euro coins with Monegasque designs on its national side.		The plan for casino gambling was drafted during the reign of Florestan I in 1846. Under Louis-Philippe's petite-bourgeois regime, however, a dignitary such as the Prince of Monaco was not allowed to operate a gambling house.[18] All this changed in the dissolute Second French Empire under Napoleon III. The House of Grimaldi was in dire need of money. The towns of Menton and Roquebrune, which had been the main sources of income for the Grimaldi family for centuries, were now accustomed to a much improved standard of living and lenient taxation thanks to Sardinian intervention and clamored for financial and political concession, even for separation. The Grimaldi family hoped the newly legal industry would help alleviate the difficulties they faced, above all the crushing debt the family had incurred, but Monaco's first casino would not be ready to operate until after Charles III assumed the throne in 1856.		The grantee of the princely concession (licence) was unable to attract enough business to sustain the operation and, after relocating the casino several times, sold the concession to French casino magnates François and Louis Blanc for 1.7 million francs. The Blancs had already set up a highly successful casino (in fact the largest in Europe) in Bad-Homburg in the Grand Duchy of Hesse-Homburg, a small German principality comparable to Monaco, and quickly petitioned Charles III to rename a depressed seaside area known as "Les Spelegures (Den of Thieves)" to "Monte Carlo (Mount Charles)."[117] They then constructed their casino in the newly dubbed "Monte Carlo" and cleared out the area's less-than-savory elements to make the neighborhood surrounding the establishment more conducive to tourism.		The Blancs opened Le Grand Casino de Monte Carlo in 1858 and the casino benefited from the tourist traffic the newly built French railway system created.[118] Due to the combination of the casino and the railroads, Monaco finally recovered from the previous half-century of economic slump and the principality's success attracted other businesses.[119] In the years following the casino's opening, Monaco founded its Oceanographic Museum and the Monte Carlo Opera House, 46 hotels were built and the number of jewelers operating in Monaco increased by nearly five-fold. By 1869, the casino was making such a vast sum of money that the principality could afford to end tax collection from the Monegasques — a master stroke that was to attract affluent residents from all over Europe.		Today, Société des bains de mer de Monaco, which owns Le Grand Casino, still operates in the original building that the Blancs constructed and has since been joined by several other casinos, including the Le Casino Café de Paris, the Monte Carlo Sporting Club & Casino and the Sun Casino. The most recent addition in Monte Carlo is the Monte Carlo Bay Casino, which sits on 4 hectares of the Mediterranean Sea and, among other things, offers 145 slot machines, all equipped with "ticket-in, ticket-out" (TITO); it is the first Mediterranean casino to use this technology.[120]		People use Monaco as a "tax haven" from their own country's taxes because Monaco as an independent country is not obligated to pay taxes to other countries. Monaco levies no income tax on individuals subject to some conditions.[121][122] The absence of a personal income tax in the principality has attracted to it a considerable number of wealthy "tax refugee" residents from European countries who derive the majority of their income from activity outside Monaco; celebrities such as Formula One drivers attract most of the attention, but the vast majority of them are lesser-known business people.[110][123] However, due to a bilateral treaty with France, French citizens are still required to pay applicable income and wealth taxes to the French state even if they are resident in Monaco.[124]		In 1998 the Centre for Tax Policy and Administration, part of the Organisation for Economic Co-operation and Development (OECD), issued a first report on the consequences of the tax havens' financial systems.[125] Monaco did not appear in the list of these territories until 2004, when OECD became indignant regarding the Monegasque situation and denounced it in its last report, as well as Andorra, Liechtenstein, Liberia and the Marshall Islands, underlining its lack of co-operation regarding financial information disclosure and availability.[126][127]		In 2000, a report by the French parliamentarians, Arnaud Montebourg and Vincent Peillon, alleged that Monaco had relaxed policies with respect to money laundering, including within its famed casino, and that the government of Monaco had been placing political pressure on the judiciary, so that alleged crimes were not being properly investigated.[128]		In 2000, the Financial Action Task Force on Money Laundering (FATF) stated: "The anti-money laundering system in Monaco is comprehensive. However, difficulties have been encountered with Monaco by countries in international investigations on serious crimes that appear to be linked also with tax matters. In addition, the FIU of Monaco (SICCFIN) suffers a great lack of adequate resources. The authorities of Monaco have stated that they will provide additional resources to SICCFIN."[129] The Principality is no longer blamed in the 2005 FATF report, as well as all other territories.[130][131] However, since 2003, the International Monetary Fund (IMF) has identified Monaco, along with 36 other territories, as a tax haven.[132]		The Council of Europe also decided to issue reports naming tax havens. Twenty-two territories, including Monaco, were thus evaluated between 1998 and 2000 on a first round. Monaco was the only territory that refused to perform the second round, between 2001 and 2003, whereas the 21 other territories had planned implementing the third and final round, planned between 2005 and 2007.[133]		Monaco has high social insurance taxes payable by both employers and employees. The employers' contributions are between 28%–40% (averaging 35%) of gross salary including benefits, and employees pay a further 10%–14% (averaging 13%).[134]		Of interest to numismatists, in Monaco the euro was introduced in 2002, having been preceded by the Monégasque franc.[135] In preparation for this date, the minting of the new euro coins started as early as 2001. Like Belgium, Finland, France, the Netherlands, and Spain, Monaco decided to put the minting date on its coins. This is why the first euro coins from Monaco have the year 2001 on them, instead of 2002, like the other countries of the Eurozone that decided to put the year of first circulation (2002) on their coins.[136][137] Three different designs were selected for the Monégasque coins.[138] However, in 2006, the design was changed after the death of ruling Prince Rainier to have the effigy of Prince Albert.[138][139]		Monaco also has a rich and valuable collection of collectors' coins, with face value ranging from €5 to €100.[140] These coins are a legacy of an old national practice of minting silver and gold commemorative coins.[141][142] Unlike normal issues, these coins are not legal tender in all the Eurozone.[143] The same practice concerning commemorative coins is exercised by all eurozone countries.		Monaco's total population was 38,400 in 2015.[144] Monaco's population is unusual in that the native Monegasques are a minority in their own country: the largest group are French nationals at 28.4%, followed by Monegasque (21.6%), Italian (18.7%), British (7.5%), Belgian (2.8%), German (2.5%), Swiss (2.5%) and U.S. nationals (1.2%).[145]		Citizens of Monaco, whether born in the country or naturalised, are called Monegasque.[146] Monaco has the world's highest life expectancy at nearly 90 years.[147]		Monaco's Population		The official language of Monaco is French, while Italian is spoken by the principality's sizeable community from Italy. Thus, French and Italian supplants the Occitan language, the vernacular language of the Monegasques, which is not recognized as an official language ; English is used by American, British, Canadian and Irish residents.		The Grimaldi, princes of Monaco, have Ligurian origin, thus, the traditional national language is Monégasque, a variety of Ligurian, now spoken by only a minority of residents and as a common second language by many native residents. In Monaco-Ville, street signs are printed in both French and Monégasque.[148][149]		The official religion is Roman Catholicism, with freedom of other religions guaranteed by the constitution.[150] There are five Roman Catholic parish churches in Monaco and one cathedral, which is the see of the archbishop of Monaco.		The diocese, which has existed since the mid-19th century, was raised to a non-metropolitan archbishopric in 1981 as the Archdiocese of Monaco and remains exempt (i.e. immediately subject to the Holy See). The patron saint is Saint Devota.		Christians comprise a total of 83.2% of Monaco's population.[150]		According to Monaco 2012 International Religious Freedom Report, Protestants are the second largest group after Roman Catholics. There are various Evangelical Protestant communities that gather periodically. The report states that there are two Protestant churches, including the local Anglican church and a Reformed church.		There is one Anglican church (St. Paul's Church), located in the Avenue de Grande Bretagne in Monte Carlo. In 2007 this had a formal membership of 135 Anglicans resident in the principality, but was also serving a considerably larger number of Anglicans temporarily in the country, mostly as tourists. The church site also accommodates an English language library of over 3,000 books.[151] The church is part of the Anglican Diocese in Europe.		Monaco's 2012 International Religious Freedom Report states that there is one Greek Orthodox Church in Monaco.		The Association Culturelle Israélite de Monaco (founded in 1948) is a converted house containing a synagogue, a community Hebrew school, and a kosher food shop, located in Monte Carlo.[152] The community mainly consists of retired Jews from Britain (40%) and North Africa. Two-thirds of the Jewish population is Sephardic, mainly from North Africa, while the other third is Ashkenazi.[153]		The Muslim population of Monaco consists of about 280 people, most of whom are exclusively residents, not citizens.[154] The majority of the Muslim population of Monaco are Arabs, though there are smaller Turkish minorities as well.[155] Monaco does not have any official mosques.[156] There is a Muslim mosque in nearby Beausoleil, France, within easy walking distance of Monaco.		Since 1929, the Monaco Grand Prix has been held annually in the streets of Monaco.[157] It is widely considered to be one of the most prestigious automobile races in the world. The erection of the Circuit de Monaco takes six weeks to complete and the removal after the race takes another three weeks.[157] The circuit is incredibly narrow and tight and its tunnel, tight corners and many elevation changes make it perhaps the most demanding Formula One track.[158] Driver Nelson Piquet compared driving the circuit to "riding a bicycle around your living room".		Despite the challenging nature of the course it has only had one fatality, Lorenzo Bandini, who crashed, burned and died three days later from his injuries in 1967.[159] Two other drivers had lucky escapes after they crashed into the harbour, the most famous being Alberto Ascari in the 1955 Monaco Grand Prix and Paul Hawkins, during the 1965 race.[157]		Since 1911 part of the Monte Carlo Rally has been held in the principality, originally held at the behest of Prince Albert I. Like the Grand Prix, the rally is organised by Automobile Club de Monaco. It has long been considered to be one of the toughest and most prestigious events in rallying and from 1973 to 2008 was the opening round of the World Rally Championship (WRC).[160] From 2009 until 2011, the rally served as the opening round of the Intercontinental Rally Challenge.[161] The rally returned to the WRC calendar in 2012 and has been held annually since.[162] Due to Monaco's limited size, all but the whole rally is held in French territory.		Monaco hosts two major football teams in the principality: the men's football club, AS Monaco FC, and the women's football club, OS Monaco. AS Monaco plays at the Stade Louis II and competes in Ligue 1 the first division of French football and are reigning champions, The club is historically one of the most successful clubs in the French league, having won Ligue 1 eight times (most recently in 2016–17) and competed at the top level for all but six seasons since 1953. The club reached the 2004 UEFA Champions League Final, with a team that included Dado Pršo, Fernando Morientes, Jérôme Rothen, Akis Zikos and Ludovic Giuly, but lost 3–0 to Portuguese team FC Porto. Many international stars have played for the club, such as French World Cup-winners Thierry Henry, Fabien Barthez and David Trezeguet. The Stade Louis II also played host to the annual UEFA Super Cup (1998–2012) between the winners of the UEFA Champions League and the UEFA Europa League.		The women's team, OS Monaco, competes in the women's French football league system. The club currently plays in the local regional league, deep down in the league system. It once played in the Division 1 Féminine, in the 1994–95 season, but was quickly relegated. Current French women's international goalkeeper Sarah Bouhaddi had a short stint at the club before going to the Clairefontaine academy.		The Monaco national football team represents the nation in association football and is controlled by the Monégasque Football Federation, the governing body for football in Monaco. However, Monaco is one of only two sovereign states in Europe (along with Vatican City) that is not a member of UEFA and so does not take part in any UEFA European Football Championship or FIFA World Cup competitions. The team plays its home matches in the Stade Louis II.		Monaco's national rugby team, as of October 2013, is 91st in the International Rugby Board rankings.[163]		The Monte-Carlo Masters is held annually in neighbouring Roquebrune-Cap-Martin, France, as a professional tournament for men as part of tennis' ATP Masters Series.[164] The tournament has been held since 1897. Golf's Monte Carlo Open was also held at the Monte Carlo Golf Club at Mont Agel in France between 1984 and 1992. Monaco has also competed in the Olympic Games, although, as of 2012[update],[needs update] no athlete from Monaco has ever won an Olympic medal.		The 2009 Tour de France, the world's premier cycle race, started from Monaco with a 15 kilometres (9 miles) closed-circuit individual time trial starting and finishing there on the first day, and the 182 kilometres (113 miles) second leg starting there on the following day and ending in Brignoles, France.[165]		Monaco also stage part of the Global Champions Tour (International Show-jumping). Acknowledged as the most glamorous of the series, Monaco will be hosting the world's most celebrated riders, including Monaco's own Charlotte Casiraghi, in a setting facing out over the world's most beautiful yachts, and framed by the Port Hercules and Prince's palace.[166] In 2009, the Monaco stage of the Global Champions tour took place between 25–27 June.		The Monaco Marathon is the only marathon in the world to pass through three separate countries, those of Monaco, France and Italy, before the finish at the Stade Louis II.		The Monaco Ironman 70.3 triathlon race is an annual event with over 1,000 athletes competing and attracts top professional athletes from around the world. The race includes a 1.9-kilometre (1.2-mile) swim, 90-kilometre (56-mile) bike ride and 21.1-kilometre (13.1-mile) run.		Since 1993, the headquarters of the International Association of Athletics Federations,[167] the world governing body of athletics, is located in Monaco.[168] An IAAF Diamond League meet is annually held at Stade Louis II.[169]		A municipal sports complex, the Rainier III Nautical Stadium in the Port Hercules district consists of a heated saltwater Olympic-size swimming pool, diving boards and a slide.[170] The pool is converted into an ice rink from December to March.[170]		From 10–12 July 2014 Monaco inaugurated the Solar1 Monte Carlo Cup, a series of ocean races exclusively for solar powered boats.[171],[172]		Monaco has an opera house, a symphony orchestra and a classical ballet company.[173]		The Principality of Monaco hosts major international events such as :		Monaco has a national museum of contemporary visual art at the New National Museum of Monaco. The country also has numerous works of public art, statues, and memorials (see list of public art in Monaco).		Monaco has ten state-operated schools, including: seven nursery and primary schools; one secondary school, Collège Charles III;[175] one lycée that provides general and technological training, Lycée Albert 1er;[176] and one lycée that provides vocational and hotel training, Lycée technique et hôtelier de Monte-Carlo.[177] There are also two grant-aided denominational private schools, Institution François d'Assise Nicolas Barré and Ecole des Sœurs Dominicaines, and one international school, the International School of Monaco,[178][179] founded in 1994.[180]		There is one university located in Monaco, namely the International University of Monaco (IUM), an English-language school specializing in business education and operated by the Institut des hautes études économiques et commerciales (INSEEC) group of schools.		The flag of Monaco is one of the world's oldest national flag designs.[181] The flag of Monaco is almost identical to the flag of Indonesia, except for the ratio of height to width.[182]		The Monaco-Monte Carlo station is served by the SNCF, the French national rail system. The Monaco Heliport provides helicopter service to the closest airport, Côte d'Azur Airport in Nice, France.		There is also a Monaco bus company (CAM) which offers you the possibility to move easily. The network covers all the tourist attractions, Museums, Exotic garden, business centres, and even the Casino or the Louis II Stadium.[183]		Monaco is so old that it has outlived many of the nations and institutions that it has had relations with. The Crown of Aragon and Republic of Genoa became a part of other countries, as did the Kingdom of Sardinia. Honoré II, Prince of Monaco secured recognition of his independent sovereignty from Spain in 1633, and then from Louis XIII of France by the Treaty of Péronne (1641).		Monaco made a special agreement with France in 1963 in which French customs laws apply in Monaco and its territorial waters.[124] Monaco uses the euro but is not a member of the European Union.[124] Monaco shares a 6-kilometre (3.7-mile) border with France but also has about 2-kilometre (1.2-mile) of coastline with the Mediterranean sea.[184] Two important agreements that support Monaco's independence from France include the Franco-Monegasque Treaty of 1861 and the French Treaty of 1918 (see also Kingdom of Sardinia The United States CIA Factbook records 1419 as the year of Monaco's independence).[184]		There are two "full" embassies in Monaco; France and Italy.[185] There are about another thirty or so consulates.[185] By the 21st century Monaco maintained embassies in Belgium (Brussels), France (Paris), Germany (Berlin), the Vatican, Italy (Rome), Spain (Madrid), Switzerland (Bern), United Kingdom (London) and the United States (Washington).[185]		In the year 2000 nearly two thirds of the residents of Monaco were foreigners[186] In 2015 the immigrant population was estimated at 60%[184] However, it is reported to be difficult to gain citizenship in Monaco, or at least in relative number there is not many people who do so.[173] In 2015 an immigration rate of about 4 people per 1,000 was noted, which works out to something like 100–150 people a year.[187] The population of Monaco went from 35,000 in 2008 to 36,000 in 2013, and of that about 20 percent were native Monegasque[188] (see also Nationality law of Monaco).		The common issue Monaco has with other countries is if the foreigner tries to use Monaco to avoid paying taxes in their own country.[184] Monaco actually collects a number of taxes including a 20% VAT and 33% on companies unless they make over 75% of their income inside Monaco.[184] Monaco does not allow dual-citizenship, but does have multiple paths to citizenship including by declaration and naturalisation.[189] In many cases the key issues for citizens is not attaining residency in Monaco, but their ties to their departure country.[189] For example, French citizens must still pay taxes to France even if they live full-time in Monaco unless they resided in the country before 1962 for at least 5 years.[189] In the early 1960s there was some tension between France and Monaco over taxation.[190]		There are no border formalities entering or leaving to France. For visitors a souvenir passport stamp is available on request at Monaco's tourist office. This is located on the far side of the gardens that face the Casino.		Coordinates: 43°44′N 7°25′E﻿ / ﻿43.733°N 7.417°E﻿ / 43.733; 7.417		
A salt marsh or saltmarsh, also known as a coastal salt marsh or a tidal marsh, is a coastal ecosystem in the upper coastal intertidal zone between land and open salt water or brackish water that is regularly flooded by the tides. It is dominated by dense stands of salt-tolerant plants such as herbs, grasses, or low shrubs.[1][2] These plants are terrestrial in origin and are essential to the stability of the salt marsh in trapping and binding sediments. Salt marshes play a large role in the aquatic food web and the delivery of nutrients to coastal waters. They also support terrestrial animals and provide coastal protection.[2]						Salt marshes occur on low-energy shorelines in temperate and high-latitudes[3] which can be stable or emerging, or submerging if the sedimentation rate exceeds the subsidence rate. Commonly these shorelines consist of mud or sand flats (known also as tidal flats or abbreviated to mudflats) which are nourished with sediment from inflowing rivers and streams.[4] These typically include sheltered environments such as embankments, estuaries and the leeward side of barrier islands and spits. In the tropics and sub-tropics they are replaced by mangroves; an area that differs from a salt marsh in that instead of herbaceous plants, they are dominated by salt-tolerant trees.[1]		Most salt marshes have a low topography with low elevations but a vast wide area, making them hugely popular for human populations.[5] Salt marshes are located among different landforms based on their physical and geomorphological settings. Such marsh landforms include deltaic marshes, estuarine, back-barrier, open coast, embayments and drowned-valley marshes. Deltaic marshes are associated with large rivers where many occur in Southern Europe such as the Camargue, France in the Rhone delta or the Ebro delta in Spain. They are also extensive within the rivers of the Mississippi Delta in the United States.[2] In New Zealand, most salt marshes occur at the head of estuaries in areas where there is little wave action and high sedimentation.[6] Such marshes are located in Awhitu Regional Park in Auckland, the Manawatu Estuary, and the Avon-Heathcote Estuary in Christchurch. Back-barrier marshes are sensitive to the reshaping of barriers in the landward side of which they have been formed.[2] They are common along much of the eastern coast of the United States and the Frisian Islands. Large, shallow coastal embayments can hold salt marshes with examples including Morecambe Bay and Portsmouth in Britain and the Bay of Fundy in North America.[2]		Salt marshes are sometimes included in lagoons, and the difference is not very marked; the Venetian Lagoon in Italy, for example, is made up of these sorts of animals and or living organisms belonging to this ecosystem. They have a big impact on the biodiversity of the area. Salt marsh ecology involves complex food webs which include primary producers (vascular plants, macroalgae, diatoms, epiphytes, and phytoplankton), primary consumers (zooplankton, macrozoa, molluscs, insects), and secondary consumers.[7]		The low physical energy and high grasses provide a refuge for animals. Many marine fish use salt marshes as nursery grounds for their young before they move to open waters. Birds may raise their young among the high grasses, because the marsh provides both sanctuary from predators and abundant food sources which include fish trapped in pools, insects, shellfish, and worms.[8]		Saltmarshes across 99 countries (essentially worldwide) were mapped by Mcowen et al. 2017.[9] A total of 5,495,089 hectares of mapped saltmarsh across 43 countries and territories are represented in a Geographic Information Systems polygon shapefile. This estimate is at the relatively low end of previous estimates (2.2-40 Mha). The most extensive saltmarsh worldwide are found outside the tropics, notably including the low-lying, ice-free coasts, bays and estuaries of the North Atlantic which are well represented in their global polygon dataset.[9]		The formation begins as tidal flats gain elevation relative to sea level by sediment accretion, and subsequently the rate and duration of tidal flooding decreases so that vegetation can colonize on the exposed surface.[10] The arrival of propagules of pioneer species such as seeds or rhizome portions are combined with the development of suitable conditions for their germination and establishment in the process of colonisation.[11] When rivers and streams arrive at the low gradient of the tidal flats, the discharge rate reduces and suspended sediment settles onto the tidal flat surface, helped by the backwater effect of the rising tide.[4] Mats of filamentous blue-green algae can fix silt and clay sized sediment particles to their sticky sheaths on contact [12] which can also increase the erosion resistance of the sediments.[13] This assists the process of sediment accretion to allow colonising species (e.g., Salicornia spp.) to grow. These species retain sediment washed in from the rising tide around their stems and leaves and form low muddy mounds which eventually coalesce to form depositional terraces, whose upward growth is aided by a sub-surface root network which binds the sediment.[14] Once vegetation is established on depositional terraces further sediment trapping and accretion can allow rapid upward growth of the marsh surface such that there is an associated rapid decrease in the depth and duration of tidal flooding. As a result, competitive species that prefer higher elevations relative to sea level can inhabit the area and often a succession of plant communities develops.[10]		Coastal salt marshes can be distinguished from terrestrial habitats by the daily tidal flow that occurs and continuously floods the area.[1] It is an important process in delivering sediments, nutrients and plant water supply to the marsh.[5] At higher elevations in the upper marsh zone, there is much less tidal inflow, resulting in lower salinity levels.[1] Soil salinity in the lower marsh zone is fairly constant due to everyday annual tidal flow. However, in the upper marsh, variability in salinity is shown as a result of less frequent flooding and climate variations. Rainfall can reduce salinity and evapotranspiration can increase levels during dry periods.[1] As a result, there are microhabitats populated by different species of flora and fauna dependant on their physiological abilities. The flora of a salt marsh is differentiated into levels according to the plants' individual tolerance of salinity and water table levels. Vegetation found at the water must be able to survive high salt concentrations, periodical submersion, and a certain amount of water movement, while plants further inland in the marsh can sometimes experience dry, low-nutrient conditions. It has been found that the upper marsh zones limit species through competition and the lack of habitat protection, while lower marsh zones are determined through the ability of plants to tolerate physiological stresses such as salinity, water submergence and low oxygen levels.[15][16]		The New England salt marsh is subject to strong tidal influences and shows distinct patterns of zonation.[16] In low marsh areas with high tidal flooding, a monoculture of the smooth cordgrass, Spartina alterniflora dominate, then heading landwards, zones of the salt hay, Spartina patens, black rush, Juncus gerardii and the shrub Iva frutescens are seen respectively.[15] These species all have different tolerances that make the different zones along the marsh best suited for each individual.		Plant species diversity is relatively low, since the flora must be tolerant of salt, complete or partial submersion, and anoxic mud substrate. The most common salt marsh plants are glassworts (Salicornia spp.) and the cordgrass (Spartina spp.), which have worldwide distribution. They are often the first plants to take hold in a mudflat and begin its ecological succession into a salt marsh. Their shoots lift the main flow of the tide above the mud surface while their roots spread into the substrate and stabilize the sticky mud and carry oxygen into it so that other plants can establish themselves as well. Plants such as sea lavenders (Limonium spp.), plantains (Plantago spp.), and varied sedges and rushes grow once the mud has been vegetated by the pioneer species.		Salt marshes are quite photosynthetically active and are extremely productive habitats. They serve as depositories for a large amount of organic matter and are full of decomposition, which feeds a broad food chain of organisms from bacteria to mammals. Many of the halophytic plants such as cordgrass are not grazed at all by higher animals but die off and decompose to become food for micro-organisms, which in turn become food for fish and birds.		The factors and processes that influence the rate and spatial distribution of sediment accretion within the salt marsh are numerous. Sediment deposition can occur when marsh species provide a surface for the sediment to adhere to, followed by deposition onto the marsh surface when the sediment flakes off at low tide.[10] The amount of sediment adhering to salt marsh species is dependent on the type of marsh species, the proximity of the species to the sediment supply, the amount of plant biomass, and the elevation of the species.[17] For example, in a study of the Eastern Chongming Island and Jiuduansha Island tidal marshes at the mouth of the Yangtze River, China, the amount of sediment adhering to the species Spartina alterniflora, Phragmites australis, and Scirpus mariqueter decreased with distance from the highest levels of suspended sediment concentrations (found at the marsh edge bordering tidal creeks or the mudflats); decreased with those species at the highest elevations, which experienced the lowest frequency and depth of tidal inundations; and increased with increasing plant biomass. Spartina alterniflora, which had the most sediment adhering to it, may contribute >10% of the total marsh surface sediment accretion by this process.[17]		Salt marsh species also facilitate sediment accretion by decreasing current velocities and encouraging sediment to settle out of suspension.[10] Current velocities can be reduced as the stems of tall marsh species induce hydraulic drag, with the effect of minimising re-suspension of sediment and encouraging deposition.[18] Measured concentrations of suspended sediment in the water column have been shown to decrease from the open water or tidal creeks adjacent to the marsh edge, to the marsh interior,[17][18][19] probably as a result of direct settling to the marsh surface by the influence of the marsh canopy.[18][19]		Inundation and sediment deposition on the marsh surface is also assisted by tidal creeks [19] which are a common feature of salt marshes.[4][10][14][19][20] Their typically dendritic and meandering forms provide avenues for the tide to rise and flood the marsh surface, as well as to drain water,[14] and they may facilitate higher amounts of sediment deposition than salt marsh bordering open ocean.[20] Sediment deposition is correlated with sediment size: coarser sediments will deposit at higher elevations (closer to the creek) than finer sediments (further from the creek). Sediment size is also often correlated with particular trace metals, and can thus tidal creeks can affect metal distributions and concentrations in salt marshes, in turn affecting the biota.[21] Salt marshes do not however require tidal creeks to facilitate sediment flux over their surface [18] although salt marshes with this morphology seem to be rarely studied.		The elevation of marsh species is important; those species at lower elevations experience longer and more frequent tidal floods and therefore have the opportunity for more sediment deposition to occur.[17][22] Species at higher elevations can benefit from a greater chance of inundation at the highest tides when increased water depths and marsh surface flows can penetrate into the marsh interior.[19]		The coast is a highly attractive natural feature to humans through its beauty, resources, and accessibility. As of 2002, over half of the world's population was estimated to being living within 60 km of the coastal shoreline,[2] making coastlines highly vulnerable to human impacts from daily activities that put pressure on these surrounding natural environments. In the past, salt marshes were perceived as coastal 'wastelands,' causing considerable loss and change of these ecosystems through land reclamation for agriculture, urban development, salt production and recreation.[5][23][24] The indirect effects of human activities such as nitrogen loading also play a major role in the salt marsh area. Salt marshes can suffer from dieback in the high marsh and die-off in the low marsh.		Reclamation of land for agriculture by converting marshland to upland was historically a common practice.[5] Dikes were often built to allow for this shift in land change and to provide flood protection further inland. In recent times intertidal flats have also been reclaimed.[25] For centuries, livestock such as sheep and cattle grazed on the highly fertile salt marsh land.[1][26] Land reclamation for agriculture has resulted in many changes such as shifts in vegetation structure, sedimentation, salinity, water flow, biodiversity loss and high nutrient inputs. There have been many attempts made to eradicate these problems for example, in New Zealand, the cordgrass Spartina anglica was introduced from England into the Manawatu River mouth in 1913 to try and reclaim the estuary land for farming.[6] A shift in structure from bare tidal flat to pastureland resulted from increased sedimentation and the cordgrass extended out into other estuaries around New Zealand. Native plants and animals struggled to survive as non-natives out competed them. Efforts are now being made to remove these cordgrass species, as the damages are slowly being recognised.		In the Blyth estuary in Suffolk in eastern England, the mid-estuary reclamations (Angel and Bulcamp marshes) that were abandoned in the 1940s have been replaced by tidal flats with compacted soils from agricultural use overlain with a thin veneer of mud. Little vegetation colonisation has occurred in the last 60–75 years and has been attributed to a combination of surface elevations too low for pioneer species to develop, and poor drainage from the compacted agricultural soils acting as an aquaclude.[27] Terrestrial soils of this nature need to adjust from fresh to saline interstitial water by a change in the chemistry and the structure of the soil, accompanied with fresh deposition of estuarine sediment, before salt marsh vegetation can establish.[11] The vegetation structure, species richness, and plant community composition of salt marshes naturally regenerated on reclaimed agricultural land can be compared to adjacent reference salt marshes to assess the success of marsh regeneration.[28]		Cultivation of land upstream from the salt marsh can introduce increased silt inputs and raise the rate of primary sediment accretion on the tidal flats, so that pioneer species can spread further onto the flats and grow rapidly upwards out of the level of tidal inundation. As a result, marsh surfaces in this regime may have an extensive cliff at their seaward edge.[29] At the Plum Island estuary, Massachusetts (U.S.A), stratigraphic cores revealed that during the 18th and 19th century the marsh prograded over subtidal and mudflat environments to increase in area from 6 km2 to 9 km2 after European settlers deforested the land uptream and increased the rate of sediment supply.[30]		The conversion of marshland to upland for agriculture has in the past century been overshadowed by conversion for urban development. Coastal cities worldwide have encroached onto former salt marshes and in the U.S. the growth of cities looked to salt marshes for waste disposal sites. Estuarine pollution from organic, inorganic, and toxic substances from urban development or industrialisation is a worldwide problem [25] and the sediment in salt marshes may entrain this pollution with toxic effects on floral and faunal species.[29] Urban development of salt marshes has slowed since about 1970 owing to growing awareness by environmental groups that they provide beneficial ecosystem services.[5] They are highly productive ecosystems, and when net productivity is measured in g m−2 yr−1 they are equalled only by tropical rainforests.[25] Additionally, they can help reduce wave erosion on sea walls designed to protect low-lying areas of land from wave erosion.[11]		De-naturalisation of the landward boundaries of salt marshes from urban or industrial enchroachment can have negative effects. In the Avon-Heathcote estuary/Ihutai, New Zealand, species abundance and the physical properties of the surrounding margins were strongly linked, and the majority of salt marsh was found to be living along areas with natural margins in the Avon and Heathcote river outlets; conversely, artificial margins contained little marsh vegetation and restricted landward retreat.[31] The remaining marshes surrounding these urban areas are also under immense pressure from the human population as human-induced nitrogen enrichment enters these habitats. Nitrogen loading through human-use indirectly affects salt marshes causing shifts in vegetation structure and the invasion of non-native species.[15]		Human impacts such as sewage, urban run-off, agricultural and industrial wastes are running into the marshes from nearby sources. Salt marshes are nitrogen limited[15][32] and with an increasing level of nutrients entering the system from anthropogenic effects, the plant species associated with salt marshes are being restructured through change in competition.[5] For example, the New England salt marsh is experiencing a shift in vegetation structure where S. alterniflora is spreading from the lower marsh where it predominately resides up into the upper marsh zone.[15] Additionally, in the same marshes, the reed Phragmites australis has been invading the area expanding to lower marshes and becoming a dominant species. P. australis is an aggressive halophyte that can invade disturbed areas in large numbers outcompeting native plants.[5][33][34] This loss in biodiversity is not only seen in flora assemblages but also in many animals such as insects and birds as their habitat and food resources are altered.		Due to the melting of Arctic sea ice and thermal expansion of the oceans, as a result of global warming, sea levels have begun to rise. As with all coastlines, this rise in water levels are predicted to negatively affect salt marshes, by flooding and eroding them.[8] The sea level rise causes more open water zones within the salt marsh. These zones cause erosion along their edges, further eroding the marsh into open water until the whole marsh disintegrates.[35]		Earlier in the 20th century, it was believed that draining salt marshes would help reduce mosquito populations. In many locations, particularly in the northeastern United States, residents and local and state agencies dug straight-lined ditches deep into the marsh flats. The end result, however, was a depletion of killifish habitat. The killifish is a mosquito predator, so the loss of habitat actually led to higher mosquito populations, and adversely affected wading birds that preyed on the killifish. These ditches can still be seen, despite some efforts to refill the ditches.[36]		Increased nitrogen uptake by marsh species into their leaves can prompt greater rates of length-specific leaf growth, and increase the herbivory rates of crabs. The burrowing crab Neohelice granulata frequents SW Atlantic salt marshes where high density populations can be found among populations of the marsh species Spartina densiflora and Sarcocornia perennis. In Mar Chiquita lagoon, north of Mar del Plata, Argentina, Neohelice granulata herbivory increased as a likely response to the increased nutrient value of the leaves of fertilised Spartina densiflora plots, compared to non-fertilised plots. Regardless of whether the plots were fertilised or not, grazing by Neohelice granulata also reduced the length specific leaf growth rates of the leaves in summer, while increasing their length-specific senescence rates. This may have been assisted by the increased fungal effectiveness on the wounds left by the crabs.[37]		The salt marshes of Cape Cod, Massachusetts (U.S.A), are experiencing creek bank die-offs of Spartina spp. (cordgrass) that has been attributed to herbivory by the crab Sesarma reticulatum. At 12 surveyed Cape Cod salt marsh sites, 10% - 90% of creek banks experienced die-off of cordgrass in association with a highly denuded substrate and high density of crab burrows. Populations of Sesarma reticulatum are increasing, possibly as a result of the degradation of the coastal food web in the region.[38] The bare areas left by the intense grazing of cordgrass by Sesarma reticulatum at Cape Cod are suitable for occupation by another burrowing crab, Uca pugnax, which are not known to consume live macrophytes. The intense bioturbation of salt marsh sediments from this crab's burrowing activity has been shown to dramatically reduce the success of Spartina alterniflora and Suaeda maritima seed germination and established seedling survival, either by burial or exposure of seeds, or uprooting or burial of established seedlings.[39] However, bioturbation by crabs may also have a positive effect. In New Zealand, the tunnelling mud crab Helice crassa has been given the stately name of an 'ecosystem engineer' for its ability to construct new habitats and alter the access of nutrients to other species. Their burrows provide an avenue for the transport of dissolved oxygen in the burrow water through the oxic sediment of the burrow walls and into the surrounding anoxic sediment, which creates the perfect habitat for special nitrogen cycling bacteria. These nitrate reducing (denitrifying) bacteria quickly consume the dissolved oxygen entering into the burrow walls to create the oxic mud layer that is thinner than that at the mud surface. This allows a more direct diffusion path for the export of nitrogen (in the form of gaseous nitrogen (N2)) into the flushing tidal water.[40]		The perception of bay salt marshes as a coastal 'wasteland' has since changed, acknowledging that they are one of the most biologically productive habitats on earth, rivalling tropical rainforests. Salt marshes are ecologically important providing habitats for native migratory fish and acting as sheltered feeding and nursery grounds.[24] They are now protected by legislation in many countries to look after these ecologically important habitats.[41] In the United States and Europe, they are now accorded to a high level of protection by the Clean Water Act and the Habitats Directive respectively. With the impacts of this habitat and its importance now realised, a growing interest in restoring salt marshes, through managed retreat or the reclamation of land has been established. However, many Asian countries such as China are still to recognise the value of marshlands. With their ever-growing populations and intense development along the coast, the value of salt marshes tends to be ignored and the land continues to be reclaimed.[5]		Bakker et al. (1997)[42] suggests two options available for restoring salt marshes. The first is to abandon all human interference and leave the salt marsh to complete its natural development. These types of restoration projects are often unsuccessful as vegetation tends to struggle to revert to its original structure and the natural tidal cycles are shifted due to land changes. The second option suggested by Bakker et al. (1997)[42] is to restore the destroyed habitat into its natural state either at the original site or as a replacement at a different site. Under natural conditions, recovery can take 2–10 years or even longer depending on the nature and degree of the disturbance and the relative maturity of the marsh involved.[41] Marshes in their pioneer stages of development will recover more rapidly than mature marshes[41] as they are often first to colonize the land. It is important to note, that restoration can often be sped up through the replanting of native vegetation.		This last approach is often the most practiced and generally more successful than allowing the area to naturally recover on its own. The salt marshes in the state of Connecticut in the United States have long been an area lost to fill and dredging. As of 1969, the Tidal Wetland Act was introduced that ceased this practice,[34] but despite the introduction of the act, the system was still degrading due to alterations in tidal flow. One area in Connecticut is the marshes on Barn Island. These marshes were diked then impounded with salt and brackish marsh during 1946-1966.[34] As a result, the marsh shifted to a freshwater state and became dominated by the invasive species P. australis, Typha angustifolia and T. latifolia that have little ecological connection to the area.[34]		By 1980, a restoration programme was put in place that has now been running for over 20 years.[34] This programme has aimed to reconnect the marshes by returning tidal flow along with the ecological functions and characteristics of the marshes back to their original state. In the case of Barn Island, declines in the invasive species have initiated, re-establishing the tidal-marsh vegetation along with animal species such as fish and insects. This example highlights that considerable time and effort is needed to effectively restore salt marsh systems. Times in marsh recovery can depend on the development stage of the marsh; type and extent of the disturbance; geographical location; and the environmental and physiological stress factors to the marsh-associated flora and fauna.		Although much effort has gone into restoring salt marshes worldwide, further research is needed. There are many setbacks and problems associated with marsh restoration that requires careful long-term monitoring. Information on all components of the salt marsh ecosystem should be understood and monitored from sedimentation, nutrient, and tidal influences, to behaviour patterns and tolerances of both flora and fauna species.[41] Once we have a better understanding of these processes and not just locally, but over a global scale, we can then suggest more sound and practical management and restoration efforts that can be used to preserve our valuable marshes and put them back to their original state.		While humans are situated along coastlines, there will always be the possibility of human-induced disturbances despite the number of restoration efforts we plan to implement. Dredging, pipelines for offshore petroleum resources, highway construction, accidental toxic spills or just plain carelessness are examples that will for some time now and into the future be the major influences of salt marsh degradation.[41]		In addition to restoring and managing salt marsh systems based on scientific principles, the opportunity should be taken to educate public audiences of their importance biologically and their purpose as serving as a natural buffer for flood protection.[24] Because salt marshes are often located next to urban areas, they are likely to receive more visitors than remote wetlands. By physically seeing the marsh, people are more likely to take notice and be more aware of the environment around them. An example of public involvement occurred at the Famosa Slough State Marine Conservation Area in San Diego, where a "friends" group worked for over a decade in trying to prevent the area from being developed.[43] Eventually, the 5 hectare site was bought by the City and the group worked together to restore the area. The project involved removing invasive species and replanting with natives, along with public talks to other locals, frequent bird walks and clean-up events.[43]		There is a diverse range and combination of methodologies employed to understand the hydrological dynamics in salt marshes and their ability to trap and accrete sediment. Sediment traps are often used to measure rates of marsh surface accretion when short term deployments (e.g. less than one month) are required. These circular traps consist of pre-weighed filters that are anchored to the marsh surface, then dried in a laboratory and re-weighed to determine the total deposited sediment.[19][20] For longer term studies (e.g. more than one year) researchers may prefer to measure sediment accretion with marker horizon plots. Marker horizons consist of a mineral such as feldspar that is buried at a known depth within wetland substrates to record the increase in overlying substrate over long time periods.[22] In order to gauge the amount of sediment suspended in the water column, manual or automated samples of tidal water can be poured through pre-weighed filters in a laboratory then dried to determine the amount of sediment per volume of water.[20] Another method for estimating suspended sediment concentrations is by measuring the turbidity of the water using optical backscatter probes, which can be calibrated against water samples containing a known suspended sediment concentration to establish a regression relationship between the two.[17] Marsh surface elevations may be measured with a stadia rod and transit,[20] electronic theodolite,[19] Real-Time Kinematic Global Positioning System,[17] laser level [22] or electronic distance meter (total station). Hydrological dynamics include water depth, measured automatically with a pressure transducer,[19][20][22] or with a marked wooden stake,[18] and water velocity, often using electromagnetic current meters.[18][20]		
A shore or a shoreline is the fringe of land at the edge of a large body of water, such as an ocean, sea, or lake. In physical oceanography, a shore is the wider fringe that is geologically modified by the action of the body of water past and present, while the beach is at the edge of the shore, representing the intertidal zone where there is one.[1] In contrast to a coast, a shore can border any body of water, while the coast must border an ocean; in that sense a coast is a type of shore; however, coast often refers to an area far wider than the shore, often streaching miles into the interior.		Shores are influenced by the topography of the surrounding landscape, as well as by water induced erosion, such as waves. The geological composition of rock and soil dictates the type of shore which is created.						Riviera is an Italian word for "shoreline",[2][3][4] ultimately derived from Latin ripa ("riverbank"). It came to be applied as a proper name to the coast of the Ligurian Sea, in the form riviera ligure, then shortened to riviera. Historically, the Ligurian Riviera extended from Capo Corvo (Punta Bianca) south of Genoa, north and west into what is now French territory past Monoco and sometimes as far as Marseilles.[2][5][6] Now it is divided into the Italian Riviera and the French Riviera. Although the French use the term "Riviera" to refer to the Italian Riviera, and call the French portion the "Côte d'Azur".[3]		As a result of the fame of the Ligurian rivieras, the term came into English to refer to any shoreline, especially one that is sunny, topographically diverse and popular with tourists.[2] Such places using the term include the Australian Riviera in Queensland and the Turkish Riviera along the Aegean Sea.[3]		
The Blackpool branch lines run from Preston to Blackpool. The lines split at Kirkham and Wesham junction - a double track branch runs to Blackpool North station (Blackpool's main passenger station) through Poulton-le-Fylde, while a single track branch runs via Lytham to Blackpool South station.						The route is used by the bulk of Blackpool's passenger trains, providing services to Manchester, Liverpool and Leeds as well as other destinations. The planned electrification of the Manchester to Blackpool North route was announced in December 2009.[1][2]		At Poulton junction, the freight-only Burn Naze branch diverges. This serves the industrial areas and ports around Fleetwood and used to carry passenger traffic to the town until 1970, but the line has now been lifted from Burn Naze onward. Proposals exist to reopen the line in the future, as a large amount of track still remains and volunteers have begun to clear the line of the vegetation with which it was previously overgrown.[3]		As of December 2014 Virgin Trains run one train per weekday between Blackpool North and London Euston using Class 221s.		Northern operate frequent services on the line. First TransPennine Express formerly ran hourly services to Manchester Airport, but responsibility for these passed to the new Northern franchise as from the beginning of April 2016.[4]		This branch serves Lytham St Annes as well as Blackpool Pleasure Beach, each with their own station. It follows the Preston to Blackpool North line as far as Kirkham Junction. Currently one service per hour runs along this branch, with most trains running beyond Preston to Colne via the East Lancashire line. The line from Kirkham to Blackpool South was reduced from double to single track in stages between 1982 & 1986. Until 1964 it ran further north into Blackpool to serve Blackpool Central station.		As well as the line via Blackpool South, a flyover junction at Kirkham and Wesham provided direct access to Blackpool Central station. Blackpool Central station closed in 1964 and its site is now where the Central Car Park stands; the trackbed and embankment has been used for the road Yeadon Way (built in the 1980s), which provides direct access from the M55. The first 2 miles of the M55 also occupy the former trackbed, until the Blackpool North line travels under the motorway at the point where the lines used to merge.		The electrification of the Manchester to Blackpool North route was announced in December 2009. The main work of piling etc. to accomplish this commenced in early 2017. Bridgeworks along the route to raise and rebuild those that had insufficient clearance for overhead wires has been completed. The line will be re-signalled in conjunction with electrification and the expected completion date is early 2018.[5][6]		
Native languages as of 2007		California (/ˌkælᵻˈfɔːrnjə, -ni.ə/ ( listen) KAL-ə-FORN-yə, KAL-ə-FORN-ee-ə) is the most populous state in the United States and the third most extensive by area. Located on the western (Pacific Ocean) coast of the U.S., California is bordered by Oregon to the north, Nevada, to the east and northeast, Arizona to the southeast and it shares an international border with the Mexican state of Baja California to the south. The state capital is Sacramento. Los Angeles is California's most populous city, and the country's second largest after New York City. The Greater Los Angeles Area and the San Francisco Bay Area are the nation's second- and fifth-most populous urban regions, respectively. California also has the nation's most populous county, Los Angeles County, and its largest county by area, San Bernardino County.		California's diverse geography ranges from the Pacific Coast in the west to the Sierra Nevada mountain range in the east; and from the redwood–Douglas fir forests in the northwest to the Mojave Desert in the southeast. The Central Valley, a major agricultural area, dominates the state's center. Though California is well-known for its warm Mediterranean climate, the large size of the state means it can vary from moist temperate rainforest in the north, to arid desert in the interior, as well as snowy alpine in the mountains.		What is now California was first settled by various Native American tribes before being explored by a number of European expeditions during the 16th and 17th centuries. The Spanish Empire then claimed it as part of Alta California in their New Spain colony. The area became a part of Mexico in 1821 following its successful war for independence, but was ceded to the United States in 1848 after the Mexican–American War. The western portion of Alta California then was organized as the State of California, and admitted as the 31st state on September 9, 1850. The California Gold Rush starting in 1848 led to dramatic social and demographic changes, with large-scale emigration from the east and abroad with an accompanying economic boom.		If it were a country, California would be the 6th largest economy in the world[13] and the 35th most populous. It is also regarded as a global trendsetter in both popular culture and politics, and is the origin of the film industry, the hippie counterculture, the Internet,[14] and the personal computer, among others. Fifty-eight percent of the state's economy is centered on finance, government, real estate services, technology, and professional, scientific and technical business services.[15] The San Francisco Bay Area has the nation's highest median household income by metropolitan area, and is the headquarters of three of the world's largest 40 firms by revenue, Chevron, Apple, and McKesson.[16] Although it accounts for only 1.5 percent of the state's economy,[15] California's agriculture industry has the highest output of any U.S. state.[17]		The word California originally referred to the Baja California Peninsula of Mexico; it was later extended to the entire region composed of the current United States states of California, Nevada, and Utah, and parts of Arizona, New Mexico, Texas and Wyoming.[18]		The name California is surmised by some writers to have derived from the fictional paradise peopled by Black Amazons and ruled by Queen Calafia,[19][20] who fought alongside Muslims and whose name was chosen to echo the title of a Muslim leader, the Caliph, fictionally implying that California was the Caliphate.[21] The story of Calafia is recorded in a 1510 work The Adventures of Esplandián, written as a sequel to Amadis de Gaula by Spanish adventure writer Garci Rodríguez de Montalvo.[22][23][24] The kingdom of Queen Calafia, according to Montalvo, was said to be a remote land inhabited by griffins and other strange beasts, and rich in gold.		Know ye that at the right hand of the Indies there is an island called California, very close to that part of the Terrestrial Paradise, which was inhabited by black women without a single man among them, and they lived in the manner of Amazons. They were robust of body with strong passionate hearts and great virtue. The island itself is one of the wildest in the world on account of the bold and craggy rocks.		When Spanish explorer Francisco de Ulloa was exploring the western coast of North America, his initial surveys of the Baja California Peninsula led him to believe that it was an island rather than part of the larger continent, so he dubbed the "island" after the mythical island in Montalvo's writing.[26] This conventional wisdom that California was an island, with maps drawn to reflect this belief, lasted as late as the 18th century.[27]		Shortened forms of the state's name include CA, Cal., Calif. and US-CA.		Settled by successive waves of arrivals during the last 10,000 years, California was one of the most culturally and linguistically diverse areas in pre-Columbian North America. Various estimates of the native population range from 100,000 to 300,000.[28] The Indigenous peoples of California included more than 70 distinct groups of Native Americans, ranging from large, settled populations living on the coast to groups in the interior. California groups also were diverse in their political organization with bands, tribes, villages, and on the resource-rich coasts, large chiefdoms, such as the Chumash, Pomo and Salinan. Trade, intermarriage and military alliances fostered many social and economic relationships among the diverse groups.		The first European effort to explore the coast as far north as the Russian River was a Spanish sailing expedition, led by Portuguese captain Juan Rodríguez Cabrillo, in 1542. Some 37 years later English explorer Francis Drake also explored and claimed an undefined portion of the California coast in 1579. Spanish traders made unintended visits with the Manila galleons on their return trips from the Philippines beginning in 1565.[29] The first Asians to set foot on what would be the United States occurred in 1587, when Filipino sailors arrived in Spanish ships at Morro Bay.[30] Sebastián Vizcaíno explored and mapped the coast of California in 1602 for New Spain.		Despite the on-the-ground explorations of California in the 16th century, Rodríguez's idea of California as an island persisted. That depiction appeared on many European maps well into the 18th century.[31]		After the Portolà expedition of 1769–70, Spanish missionaries began setting up 21 California Missions on or near the coast of Alta (Upper) California, beginning in San Diego. During the same period, Spanish military forces built several forts (presidios) and three small towns (pueblos). Two of the pueblos grew into the cities of Los Angeles and San Jose. The Spanish colonization brought the genocide of the indigenous Californian peoples.		Imperial Russia explored the California coast and established a trading post at Fort Ross. Its early 19th-century coastal settlements north of San Francisco Bay constituted the southernmost Russian colony in North America and were spread over an area stretching from Point Arena to Tomales Bay.[33]		In 1821, the Mexican War of Independence gave Mexico (including California) independence from Spain; for the next 25 years, Alta California remained a remote northern province of the nation of Mexico.		Cattle ranches, or ranchos, emerged as the dominant institutions of Mexican California. After Mexican independence from Spain, the chain of missions became the property of the Mexican government and were secularized by 1834.[34] The ranchos developed under ownership by Californios (Spanish-speaking Californians) who had received land grants, and traded cowhides and tallow with Boston merchants.		From the 1820s, trappers and settlers from the United States and the future Canada arrived in Northern California. These new arrivals used the Siskiyou Trail, California Trail, Oregon Trail and Old Spanish Trail to cross the rugged mountains and harsh deserts in and surrounding California.		Between 1831 and 1836, California experienced a series of revolts against Mexico;[35] this culminated in the 1836 California revolt led by Juan Bautista Alvarado, which ended after Mexico appointed him governor of the department.[36] The revolt, which had momentarily declared California an independent state, was successful with the assistance of American and British residents of California,[37] including Isaac Graham;[38] after 1840, 100 of those residents who did not have passports were arrested, leading to the Graham affair in 1840.[37]		One of the largest ranchers in California was John Marsh. After failing to obtain justice against squatters on his land from the Mexican courts, he determined that California should become part of the United States. Marsh conducted a letter-writing campaign espousing the California climate, soil and other reasons to settle there, as well as the best route to follow, which became known as "Marsh's route." His letters were read, reread, passed around, and printed in newspapers throughout the country, and started the first wagon trains rolling to California.[39] He invited immigrants to stay on his ranch until they could get settled, and assisted in their obtaining passports.[40]		After ushering in the period of organized emigration to California, Marsh helped end the rule of the last Mexican governor of California, thereby paving the way to California's ultimate acquisition by the United States.[41]		In 1846, settlers rebelled against Mexican rule during the Bear Flag Revolt. Afterwards, rebels raised the Bear Flag (featuring a bear, a star, a red stripe and the words "California Republic") at Sonoma. The Republic's only president was William B. Ide,[42] who played a pivotal role during the Bear Flag Revolt.		The California Republic was short lived;[43] the same year marked the outbreak of the Mexican–American War (1846–48).[44] When Commodore John D. Sloat of the United States Navy sailed into Monterey Bay and began the military occupation of California by the United States, Northern California capitulated in less than a month to the United States forces.[45] After a series of defensive battles in Southern California, the Treaty of Cahuenga was signed by the Californios on January 13, 1847, securing American control in California.[46]		Following the Treaty of Guadalupe Hidalgo that ended the war, the western territory of Alta California, became the United States state of California, and Arizona, Nevada, Colorado and Utah became United States Territories. The lightly populated lower region of California, the Baja Peninsula, remained in the possession of Mexico.		In 1846, the non-native population of California was estimated to be no more than 8,000, plus about 100,000 Native Americans down from about 300,000 before Hispanic settlement in 1769.[47] After gold was discovered in 1848, the population burgeoned with United States citizens, Europeans, Chinese and other immigrants during the great California Gold Rush. By 1854 over 300,000 settlers had come.[48] Between 1847 and 1870, the population of San Francisco increased from 500 to 150,000.[49] On September 9, 1850, as part of the Compromise of 1850, California was admitted to the United States undivided as a free state, denying the expansion of slavery to the Pacific Coast.		California's native population precipitously declined, above all, from Eurasian diseases to which they had no natural immunity.[50] As in other states, the native inhabitants were forcibly removed from their lands by incoming miners, ranchers, and farmers. And although California entered the union as a free state, the "loitering or orphaned Indians" were de facto enslaved by Mexican and Anglo-American masters under the 1853 Act for the Government and Protection of Indians.[51] There were massacres in which hundreds of indigenous people were killed. Between 1850 and 1860, California paid around 1.5 million dollars (some 250,000 of which was reimbursed by the federal government)[52] to hire militias whose purpose was to protect settlers from the indigenous populations. In later decades, the native population was placed in reservations and rancherias, which were often small and isolated and without enough natural resources or funding from the government to sustain the populations living on them.[51] As a result, the rise of California was a calamity for the native inhabitants. Several scholars and Native American activists, including Benjamin Madley and Ed Castillo, have described the actions of the California government as a genocide.[53]		The seat of government for California under Spanish and later Mexican rule was located at Monterey from 1777 until 1845.[34] Pio Pico, last Mexican governor of Alta California, moved the capital to Los Angeles in 1845. The United States consulate was also located in Monterey, under consul Thomas O. Larkin.		In 1849, the Constitutional Convention was first held in Monterey. Among the tasks was a decision on a location for the new state capital. The first legislative sessions were held in San Jose (1850–1851). Subsequent locations included Vallejo (1852–1853), and nearby Benicia (1853–1854); these locations eventually proved to be inadequate as well. The capital has been located in Sacramento since 1854[54] with only a short break in 1862 when legislative sessions were held in San Francisco due to flooding in Sacramento.		Initially, travel between California and the rest of the continental United States was time consuming and dangerous. A more direct connection came in 1869 with the completion of the First Transcontinental Railroad through Donner Pass in the Sierra Nevada mountains. Once completed, hundreds of thousands of United States citizens came west, where new Californians were discovering that land in the state, if irrigated during the dry summer months, was extremely well suited to fruit cultivation and agriculture in general. Vast expanses of wheat, other cereal crops, vegetable crops, cotton, and nut and fruit trees were grown (including oranges in Southern California), and the foundation was laid for the state's prodigious agricultural production in the Central Valley and elsewhere.		Migration to California accelerated during the early 20th century with the completion of major transcontinental highways like the Lincoln Highway and Route 66. In the period from 1900 to 1965, the population grew from fewer than one million to become the most populous state in the Union. In 1940, the Census Bureau reported California's population as 6.0% Hispanic, 2.4% Asian, and 89.5% non-Hispanic white.[55]		To meet the population's needs, major engineering feats like the California and Los Angeles Aqueducts; the Oroville and Shasta Dams; and the Bay and Golden Gate Bridges were built across the state. The state government also adopted the California Master Plan for Higher Education in 1960 to develop a highly efficient system of public education.		Meanwhile, attracted to the mild Mediterranean climate, cheap land, and the state's wide variety of geography, filmmakers established the studio system in Hollywood in the 1920s. California manufactured 8.7 percent of total United States military armaments produced during World War II, ranking third (behind New York and Michigan) among the 48 states.[56] California however easily ranked 1st, in production of Military Ships during the war (transport, cargo, [Merchant Ships] such as Liberty ships, Victory ships, and Warships) at drydock facilities in San Diego, Los Angeles, and the San Francisco Bay Area.[57][58][59][60] After World War II, California's economy greatly expanded due to strong aerospace and defense industries,[61] whose size decreased following the end of the Cold War.[61][62] Stanford University and its Dean of Engineering Frederick Terman began encouraging faculty and graduates to stay in California instead of leaving the state, and develop a high-tech region in the area now known as Silicon Valley.[63] As a result of these efforts, California is regarded as a world center of the entertainment and music industries, of technology, engineering, and the aerospace industry, and as the United States center of agricultural production.[64] Just before the "Dot Com Bust" California had the 5th largest economy in the world among nations.[65] Yet since 1991, and starting in the late 1980s in Southern California, California has seen a net loss of domestic migrants most years. This is often referred to by the media as the California exodus.[66]		During the 20th century, two great disasters happened in California. The 1906 San Francisco earthquake and 1928 St. Francis Dam flood remain the deadliest in U.S history.[67]		California is the 3rd largest state in the United States in area, after Alaska and Texas.[69] California is often geographically bisected into two regions, Southern California, comprising the 10 southernmost counties,[70][71] and Northern California, comprising the 48 northernmost counties.[72][73] It is bordered by Oregon to the north, Nevada to the east and northeast, Arizona to the southeast, the Pacific Ocean to the west and it shares an international border with the Mexican state of Baja California to the south.		In the middle of the state lies the California Central Valley, bounded by the Sierra Nevada in the east, the coastal mountain ranges in the west, the Cascade Range to the north and by the Tehachapi Mountains in the south. The Central Valley is California's productive agricultural heartland.		Divided in two by the Sacramento-San Joaquin River Delta, the northern portion, the Sacramento Valley serves as the watershed of the Sacramento River, while the southern portion, the San Joaquin Valley is the watershed for the San Joaquin River. Both valleys derive their names from the rivers that flow through them. With dredging, the Sacramento and the San Joaquin Rivers have remained deep enough for several inland cities to be seaports.		The Sacramento-San Joaquin River Delta is a critical water supply hub for the state. Water is diverted from the delta and through an extensive network of pumps and canals that traverse nearly the length of the state, to the Central Valley and the State Water Projects and other needs. Water from the Delta provides drinking water for nearly 23 million people, almost two-thirds of the state's population as well as water for farmers on the west side of the San Joaquin Valley.		Suisun Bay lies at the confluence of the Sacramento and San Joaquin Rivers. The water is drained by the Carquinez Strait, which flows into San Pablo Bay, a northern extension of San Francisco Bay, which then connects to the Pacific Ocean via the Golden Gate strait.		The Channel Islands are located off the Southern coast, while the Farallon Islands lie west of San Francisco.		The Sierra Nevada (Spanish for "snowy range") includes the highest peak in the contiguous 48 states, Mount Whitney, at 14,505 feet (4,421 m).[6][7][8] The range embraces Yosemite Valley, famous for its glacially carved domes, and Sequoia National Park, home to the giant sequoia trees, the largest living organisms on Earth, and the deep freshwater lake, Lake Tahoe, the largest lake in the state by volume.		To the east of the Sierra Nevada are Owens Valley and Mono Lake, an essential migratory bird habitat. In the western part of the state is Clear Lake, the largest freshwater lake by area entirely in California. Though Lake Tahoe is larger, it is divided by the California/Nevada border. The Sierra Nevada falls to Arctic temperatures in winter and has several dozen small glaciers, including Palisade Glacier, the southernmost glacier in the United States.		About 45 percent of the state's total surface area is covered by forests,[74] and California's diversity of pine species is unmatched by any other state. California contains more forestland than any other state except Alaska. Many of the trees in the California White Mountains are the oldest in the world; an individual bristlecone pine is over 5,000 years old.[75][76]		In the south is a large inland salt lake, the Salton Sea. The south-central desert is called the Mojave; to the northeast of the Mojave lies Death Valley, which contains the lowest and hottest place in North America, the Badwater Basin at −279 feet (−85 m).[10] The horizontal distance from the bottom of Death Valley to the top of Mount Whitney is less than 90 miles (140 km). Indeed, almost all of southeastern California is arid, hot desert, with routine extreme high temperatures during the summer. The southeastern border of California with Arizona is entirely formed by the Colorado River, from which the southern part of the state gets about half of its water.		A majority of California's cities are located in either the San Francisco Bay Area or the Sacramento metropolitan area in Northern California; or the Los Angeles area, the Riverside-San Bernardino-Inland Empire, or the San Diego metropolitan area in Southern California. The Los Angeles Area, the Bay Area, and the San Diego metropolitan area are among several major metropolitan areas along the California coast.		As part of the Ring of Fire, California is subject to tsunamis, floods, droughts, Santa Ana winds, wildfires, landslides on steep terrain, and has several volcanoes. It has many earthquakes due to several faults running through the state, in particular the San Andreas Fault. About 37,000 earthquakes are recorded each year, but most are too small to be felt.[77]		Although most of the state has a Mediterranean climate, due to the state's large size, the climate ranges from subarctic to subtropical. The cool California Current offshore often creates summer fog near the coast. Farther inland, there are colder winters and hotter summers. The maritime moderation results in the shoreline summertime temperatures of Los Angeles and San Francisco being the coolest of all major metropolitan areas of the United States and uniquely cool compared to areas on the same latitude in the interior and on the east coast of the North American continent. Even the San Diego shoreline bordering Mexico is cooler in summer than most areas in the contiguous United States. Just a few miles inland, summer temperature extremes are significantly higher, with downtown Los Angeles being several degrees warmer than at the coast. The same microclimate phenomenon is seen in the climate of the Bay Area, where areas sheltered from the sea experience significantly hotter summers than nearby areas that are close to the ocean.		Northern parts of the state have more rain than the south. California's mountain ranges also influence the climate: some of the rainiest parts of the state are west-facing mountain slopes. Northwestern California has a temperate climate, and the Central Valley has a Mediterranean climate but with greater temperature extremes than the coast. The high mountains, including the Sierra Nevada, have an alpine climate with snow in winter and mild to moderate heat in summer.		California's mountains produce rain shadows on the eastern side, creating extensive deserts. The higher elevation deserts of eastern California have hot summers and cold winters, while the low deserts east of the Southern California mountains have hot summers and nearly frostless mild winters. Death Valley, a desert with large expanses below sea level, is considered the hottest location in the world; the highest temperature in the world,[78][79] 134 °F (56.7 °C), was recorded there on July 10, 1913. The lowest temperature in California was −45 °F (−43 °C) in 1937 in Boca.		The table below lists average temperatures for August and December in a selection of places throughout the state; some highly populated and some not. This includes the relatively cool summers of the Humboldt Bay region around Eureka, the extreme heat of Death Valley, and the mountain climate of Mammoth in the Sierra Nevadas.		California is one of the richest and most diverse parts of the world, and includes some of the most endangered ecological communities. California is part of the Nearctic ecozone and spans a number of terrestrial ecoregions.[81]		California's large number of endemic species includes relict species, which have died out elsewhere, such as the Catalina ironwood (Lyonothamnus floribundus). Many other endemics originated through differentiation or adaptive radiation, whereby multiple species develop from a common ancestor to take advantage of diverse ecological conditions such as the California lilac (Ceanothus). Many California endemics have become endangered, as urbanization, logging, overgrazing, and the introduction of exotic species have encroached on their habitat.		California boasts several superlatives in its collection of flora: the largest trees, the tallest trees, and the oldest trees. California's native grasses are perennial plants.[82] After European contact, these were generally replaced by invasive species of European annual grasses; and, in modern times, California's hills turn a characteristic golden-brown in summer.[83]		Because California has the greatest diversity of climate and terrain, the state has six life zones which are the lower Sonoran (desert); upper Sonoran (foothill regions and some coastal lands), transition (coastal areas and moist northeastern counties); and the Canadian, Hudsonian, and Arctic Zones, comprising the state's highest elevations.[84]		Plant life in the dry climate of the lower Sonoran zone contains a diversity of native cactus, mesquite, and paloverde. The Joshua tree is found in the Mojave Desert. Flowering plants include the dwarf desert poppy and a variety of asters. Fremont cottonwood and valley oak thrive in the Central Valley. The upper Sonoran zone includes the chaparral belt, characterized by forests of small shrubs, stunted trees, and herbaceous plants. Nemophila, mint, Phacelia, Viola, and the California poppy (Eschscholzia californica) – the state flower – also flourish in this zone, along with the lupine, more species of which occur here than anywhere else in the world.[84]		The transition zone includes most of California's forests with the redwood (Sequoia sempervirens) and the "big tree" or giant sequoia (Sequoiadendron giganteum), among the oldest living things on earth (some are said to have lived at least 4,000 years). Tanbark oak, California laurel, sugar pine, madrona, broad-leaved maple, and Douglas-fir also grow here. Forest floors are covered with swordfern, alumnroot, barrenwort, and trillium, and there are thickets of huckleberry, azalea, elder, and wild currant. Characteristic wild flowers include varieties of mariposa, tulip, and tiger and leopard lilies.[85]		The high elevations of the Canadian zone allow the Jeffrey pine, red fir, and lodgepole pine to thrive. Brushy areas are abundant with dwarf manzanita and ceanothus; the unique Sierra puffball is also found here. Right below the timberline, in the Hudsonian zone, the whitebark, foxtail, and silver pines grow. At about 10,500 feet (3,200 m), begins the Arctic zone, a treeless region whose flora include a number of wildflowers, including Sierra primrose, yellow columbine, alpine buttercup, and alpine shooting star.[84][86]		Common plants that have been introduced to the state include the eucalyptus, acacia, pepper tree, geranium, and Scotch broom. The species that are federally classified as endangered are the Contra Costa wallflower, Antioch Dunes evening primrose, Solano grass, San Clemente Island larkspur, salt marsh bird's beak, McDonald's rock-cress, and Santa Barbara Island liveforever. As of December 1997[update], 85 plant species were listed as threatened or endangered.[84]		In the deserts of the lower Sonoran zone, the mammals include the jackrabbit, kangaroo rat, squirrel, and opossum. Common birds include the owl, roadrunner, cactus wren, and various species of hawk. The area's reptilian life include the sidewinder viper, desert tortoise, and horned toad. The upper Sonoran zone boasts mammals such as the antelope, brown-footed woodrat, and ring-tailed cat. Birds unique to this zone are the California thrasher, bushtit, and California condor.[84][87][88][89]		In the transition zone, there are Colombian black-tailed deer, black bears, gray foxes, cougars, bobcats, and Roosevelt elk. Reptiles such as the garter snakes and rattlesnakes inhabit the zone. In addition, amphibians such as the water puppy and redwood salamander are common too. Birds such as the kingfisher, chickadee, towhee, and hummingbird thrive here as well.[84][90]		The Canadian zone mammals include the mountain weasel, snowshoe hare, and several species of chipmunks. Conspicuous birds include the blue-fronted jay, Sierra chickadee. Sierra hermit thrush, water ouzel, and Townsend's solitaire. As one ascends into the Hudsonian zone, birds become scarcer. While the Sierra rosy finch is the only bird native to the high Arctic region, other bird species such as the hummingbird and Clark's nutcracker. Principal mammals found in this region include the Sierra coney, white-tailed jackrabbit, and the bighorn sheep. As of April 2003[update], the bighorn sheep was listed as endangered by the US Fish and Wildlife Service. The fauna found throughout several zones are the mule deer, coyote, mountain lion, northern flicker, and several species of hawk and sparrow.[84]		Aquatic life in California thrives, from the state's mountain lakes and streams to the rocky Pacific coastline. Numerous trout species are found, among them rainbow, golden, and cutthroat. Migratory species of salmon are common as well. Deep-sea life forms include sea bass, yellowfin tuna, barracuda, and several types of whale. Native to the cliffs of northern California are seals, sea lions, and many types of shorebirds, including migratory species.[84]		As of April 2003, 118 California animals were on the federal endangered list; 181 plants were listed as endangered or threatened. Endangered animals include the San Joaquin kitfox, Point Arena mountain beaver, Pacific pocket mouse, salt marsh harvest mouse, Morro Bay kangaroo rat (and five other species of kangaroo rat), Amargosa vole, California least tern, California condor, loggerhead shrike, San Clemente sage sparrow, San Francisco garter snake, five species of salamander, three species of chub, and two species of pupfish. Eleven butterflies are also endangered[91] and two that are threatened are on the federal list.[92][93] Among threatened animals are the coastal California gnatcatcher, Paiute cutthroat trout, southern sea otter, and northern spotted owl. California has a total of 290,821 acres (1,176.91 km2) of National Wildlife Refuges.[84] As of September 2010[update], 123 California animals were listed as either endangered or threatened on the federal list provided by the US Fish & Wildlife Service.[94] Also, as of the same year[update], 178 species of California plants were listed either as endangered or threatened on this federal list.[94]		The vast majority of rivers in California are dammed as part of two massive water projects: the Central Valley Project, providing water to the agricultural central valley, and the California State Water Project diverting water from northern to southern California. The state's coasts, rivers, and other bodies of water are regulated by the California Coastal Commission.		The two most prominent rivers within California are the Sacramento River and the San Joaquin River, which drain the Central Valley and the west slope of the Sierra Nevada and flow to the Pacific Ocean through San Francisco Bay. Several major tributaries feed into the Sacramento and the San Joaquin, including the Pit River, the Tuolumne River, and the Feather River.		The Eel River and Salinas River each drain portions of the California coast, north and south of San Francisco Bay, respectively, and the Eel River is the largest river in the state to remain in its natural un-dammed state. The Mojave River is the primary watercourse in the Mojave Desert, and the Santa Ana River drains much of the Transverse Ranges as it bisects Southern California. Some other important rivers are the Klamath River and the Trinity River in the far north coast, and the Colorado River on the southeast border with Arizona.		The United States Census Bureau estimates that the population of California was 39,250,017 on July 1, 2016, a 5.4% increase since the 2010 United States Census. Between 2000 and 2009, there was a natural increase of 3,090,016 (5,058,440 births minus 2,179,958 deaths).[99] During this time period, international migration produced a net increase of 1,816,633 people while domestic migration produced a net decrease of 1,509,708, resulting in a net in-migration of 306,925 people.[99] The state of California's own statistics show a population of 38,292,687 for January 1, 2009.[100] However, according to the Manhattan Institute for Policy Research, since 1990 almost 3.4 million Californians have moved to other states, with most leaving to Texas, Nevada, and Arizona.[101]		California is the 2nd-most populous subnational entity in the Western Hemisphere and the Americas, with a population second to that of the state of São Paulo in Brazil.[102] California's population is greater than that of all but 34 countries of the world.[103][104] The Greater Los Angeles Area is the 2nd-largest metropolitan area in the United States, after the New York metropolitan area, while Los Angeles, with nearly half the population of New York City, is the second-largest city in the United States. Also, Los Angeles County has held the title of most populous United States county for decades, and it alone is more populous than 42 United States states.[105][106] Including Los Angeles, four of the top 15 most populous cities in the U.S. are in California: Los Angeles (2nd), San Diego (8th), San Jose (10th), and San Francisco (13th). The center of population of California is located in the town of Buttonwillow, Kern County.[note 1]		The state has 482 incorporated cities and towns, of which 460 are cities and 22 are towns. Under California law, the terms "city" and "town" are explicitly interchangeable; the name of an incorporated municipality in the state can either be "City of (Name)" or "Town of (Name)".[108]		Sacramento became California's first incorporated city on February 27, 1850.[109] San Jose, San Diego and Benicia tied for California's second incorporated city, each receiving incorporation on March 27, 1850.[110][111][112] Jurupa Valley became the state's most recent and 482nd incorporated municipality on July 1, 2011.[113][114]		The majority of these cities and towns are within one of five metropolitan areas: the Los Angeles Metropolitan Area, the San Francisco Bay Area, the Riverside-San Bernardino Area, the San Diego metropolitan area, or the Sacramento metropolitan area.		Starting in the year 2010, for the first time since the California Gold Rush, California-born residents make up the majority of the state's population.[116] Along with the rest of the United States, California's immigration pattern has also shifted over the course of the late 2000s-early 2010s.[117] Immigration from Latin American countries has dropped significantly with most immigrants now coming from Asia.[118] In total for 2011, there were 277,304 immigrants. 57% came from Asian countries vs. 22% from Latin American countries.[118] Net immigration from Mexico, previously the most common country of origin for new immigrants has dropped to zero/less than zero, since more Mexican nationals are departing for their home country than immigrating.[117] As a result it is estimated that Hispanic citizens will constitute 49% of the population by 2060, instead of the previously projected 2050, due primarily to domestic births.[117][119]		The state's population of undocumented immigrants has been shrinking in recent years, due to increased enforcement and decreased job opportunities for lower-skilled workers.[120] The number of migrants arrested attempting to cross the Mexican border in the Southwest decreased from a high of 1.1 million in 2005 to 367,000 in 2011.[121] Despite these recent trends, illegal aliens constituted an estimated 7.3 percent of the state's population, the third highest percentage of any state in the country,[122][note 2] totaling nearly 2.6 million.[123] In particular, illegal immigrants tended to be concentrated in Los Angeles, Monterey, San Benito, Imperial, and Napa Counties – the latter four of which have significant agricultural industries that depend on manual labor.[124] More than half of illegal immigrants originate from Mexico.[123]		According to the United States Census Bureau in 2015 the population self-identifies as (alone or in combination):[125]		By ethnicity, in 2015 the population was 61.2% non-Hispanic (of any race) and 38.8% Hispanic or Latino (of any race).[125]		As of 2011, 75.1% of California's population younger than age 1 were minorities, meaning that they had at least one parent who was not non-Hispanic white (white Hispanics are counted as minorities).[126]		In terms of total numbers, California has the largest population of White Americans in the United States, an estimated 22,200,000 residents. The state has the 5th largest population of African Americans in the United States, an estimated 2,250,000 residents. California's Asian American population is estimated at 4.4 million, constituting a third of the nation's total. California's Native American population of 285,000 is the most of any state.[127]		According to estimates from 2011, California has the largest minority population in the United States by numbers, making up 60% of the state population.[97] Over the past 25 years, the population of non-Hispanic whites has declined, while Hispanic and Asian populations have grown. Between 1970 and 2011, non-Hispanic whites declined from 80% of the State's population to 40%, while Hispanics grew from 32% in 2000 to 38% in 2011.[128] It is currently projected that Hispanics will rise to 49% of the population by 2060, primarily due to domestic births rather than immigration.[119] With the decline of immigration from Latin America, Asian Americans now constitute the fastest growing racial/ethnic group in California; this growth primarily driven by immigration from China, India and the Philippines, respectively.[129]		English serves as California's de jure and de facto official language. In 2010, the Modern Language Association of America estimated that 57.02% (19,429,309) of California residents age 5 and older spoke only English at home, while 42.98% spoke another primary language at home. According to the 2007 American Community Survey, 73% of people who speak a language other than English at home are able to speak English well or very well, with 9.8% not speaking English at all.[2] Like most U.S. states (32 out of 50), California law enshrines English as its official language, and has done so since the passage of Proposition 63 by California voters. Various government agencies do, and are often required to, furnish documents in the various languages needed to reach their intended audiences.[136][137][138]		In total, 16 languages other than English were spoken as primary languages at home by more than 100,000 persons, more than any other state in the nation. New York State, in second place, had 9 languages other than English spoken by more than 100,000 persons.[139] The most common language spoken besides English was Spanish, spoken by 28.46% (9,696,638) of the population.[119][117] With Asia contributing most of California's new immigrants, California had the highest concentration nationwide of Vietnamese and Chinese speakers, the second highest concentration of Korean, and the third highest concentration of Tagalog speakers.[2]		California has historically been one of the most linguistically diverse areas in the world, with more than 70 indigenous languages derived from 64 root languages in 6 language families.[140][141] A survey conducted between 2007 and 2009 identified 23 different indigenous languages of Mexico that are spoken among California farmworkers.[142] All of California's indigenous languages are endangered, although there are now efforts toward language revitalization.[note 3]		As a result of the state's increasing diversity and migration from other areas across the country and around the globe, linguists began noticing a noteworthy set of emerging characteristics of spoken American English in California since the late 20th century. This variety, known as California English, has a vowel shift and several other phonological processes that are different from varieties of American English used in other regions of the United States.[143]		The culture of California is a Western culture and most clearly has its modern roots in the culture of the United States, but also, historically, many Hispanic influences. As a border and coastal state, Californian culture has been greatly influenced by several large immigrant populations, especially those from Latin America and Asia.[144]		California has long been a subject of interest in the public mind and has often been promoted by its boosters as a kind of paradise. In the early 20th century, fueled by the efforts of state and local boosters, many Americans saw the Golden State as an ideal resort destination, sunny and dry all year round with easy access to the ocean and mountains. In the 1960s, popular music groups such as The Beach Boys promoted the image of Californians as laid-back, tanned beach-goers.		The California Gold Rush of the 1850s is still seen as a symbol of California's economic style, which tends to generate technology, social, entertainment, and economic fads and booms and related busts.		The largest religious denominations by number of adherents as a percentage of California's population in 2014 were the Catholic Church with 28 percent, Evangelical Protestants with 20 percent, and Mainline Protestants with 10 percent. Together, all kinds of Protestants accounted for 32 percent. Those unaffiliated with any religion represented 27 percent of the population. The breakdown of other religions is 1% Muslim, 2% Hindu and 2% Buddhist.[145] This is a change from 2008, when the population identified their religion with the Catholic Church with 31 percent; Evangelical Protestants with 18 percent; and Mainline Protestants with 14 percent. In 2008, those unaffiliated with any religion represented 21 percent of the population. The breakdown of other religions in 2008 was 0.5% Muslim, 1% Hindu and 2% Buddhist.[146] The American Jewish Year Book placed the total Jewish population of California at about 1,194,190 in 2006.[147] According to the Association of Religion Data Archives (ARDA) the largest denominations by adherents in 2010 were the Roman Catholic Church with 10,233,334; The Church of Jesus Christ of Latter-day Saints with 763,818; and the Southern Baptist Convention with 489,953.[148]		The first priests to come to California were Roman Catholic missionaries from Spain. Roman Catholics founded 21 missions along the California coast, as well as the cities of Los Angeles and San Francisco. California continues to have a large Roman Catholic population due to the large numbers of Mexicans and Central Americans living within its borders. California has twelve dioceses and two archdioceses, the Archdiocese of Los Angeles and the Archdiocese of San Francisco, the former being the largest archdiocese in the United States.		A Pew Research Center survey revealed that California is somewhat less religious than the rest of the US: 62 percent of Californians say they are "absolutely certain" of their belief in God, while in the nation 71 percent say so. The survey also revealed 48 percent of Californians say religion is "very important", compared to 56 percent nationally.[149]		California has twenty major professional sports league franchises, far more than any other state. The San Francisco Bay Area has seven major league teams spread in its three major cities: San Francisco, San Jose, and Oakland. While the Greater Los Angeles Area is home to ten major league franchises. San Diego and Sacramento each have one major league team. The NFL Super Bowl has been hosted in California 11 times at four different stadiums: Los Angeles Memorial Coliseum, the Rose Bowl, Stanford Stadium, and San Diego's Qualcomm Stadium. A twelfth, Super Bowl 50, was held at Levi's Stadium in Santa Clara on February 7, 2016.[150]		California has long had many respected collegiate sports programs. California is home to the oldest college bowl game, the annual Rose Bowl, among others.		California is the only US state to have hosted both the Summer and Winter Olympics. The 1932 and 1984 Summer Olympics were held in Los Angeles. Squaw Valley Ski Resort in the Lake Tahoe region hosted the 1960 Winter Olympics. Los Angeles will host the 2028 Summer Olympics, marking the fourth time California hosts the Olympic Games.[151] Multiple games during the 1994 FIFA World Cup took place in California, with the Rose Bowl hosting eight matches including the final, while Stanford Stadium hosted six matches.		Below is a list of major league sports teams in California:		Public secondary education consists of high schools that teach elective courses in trades, languages, and liberal arts with tracks for gifted, college-bound and industrial arts students. California's public educational system is supported by a unique constitutional amendment that requires a minimum annual funding level for grades K–12 and community colleges that grows with the economy and student enrollment figures.[152]		California had over 6.2 million school students in the 2005–06 school year. Funding and staffing levels in California schools lag behind other states. In expenditure per pupil, California ranked 29th (of the 50 states and the District of Columbia) in 2005–06. In teaching staff expenditure per pupil, California ranked 49th of 51. In overall teacher-pupil ratio, California was also 49th, with 21 students per teacher. Only Arizona and Utah were lower.[153]		A 2007 study concluded that California's public school system was "broken" in that it suffered from over-regulation.[154]		California's public postsecondary education offers three separate systems:		California is also home to such notable private universities as Stanford University, the University of Southern California, the California Institute of Technology, and the Claremont Colleges. California has hundreds of other private colleges and universities, including many religious and special-purpose institutions.		California has a twinning arrangement with the region of Catalonia in Spain[160] Catalonia is made up of four Spanish provinces: Barcelona, Girona, Lleida, and Tarragona.		The economy of California is large enough to be comparable to that of the largest of countries. As of 2016[update], the gross state product (GSP) is about $2.514 trillion, the largest in the United States.[161] California is responsible for 13.9 percent of the United States' approximate $18.1 trillion gross domestic product (GDP).[161] California's GSP is larger than the GDP of all but 5 countries in dollar terms (the United States, China, Japan, Germany, and the United Kingdom),[162][163] larger than Brazil, France, Russia, Italy, India, Canada, Australia, Spain and Turkey. In Purchasing Power Parity,[164] it is larger than all but 10 countries (the United States, China, India, Japan, Germany, Russia, Brazil, France, the United Kingdom, and Indonesia), larger than Italy, Mexico, Spain, South Korea, Saudi Arabia, Canada and Turkey.[165]		The five largest sectors of employment in California are trade, transportation, and utilities; government; professional and business services; education and health services; and leisure and hospitality. In output, the five largest sectors are financial services, followed by trade, transportation, and utilities; education and health services; government; and manufacturing.[166] As of September 2016[update], California has an unemployment rate of 5.5%.		California's economy is dependent on trade and international related commerce accounts for about one-quarter of the state's economy. In 2008, California exported $144 billion worth of goods, up from $134 billion in 2007 and $127 billion in 2006.[167] Computers and electronic products are California's top export, accounting for 42 percent of all the state's exports in 2008.[167]		Agriculture is an important sector in California's economy. Farming-related sales more than quadrupled over the past three decades, from $7.3 billion in 1974 to nearly $31 billion in 2004.[168] This increase has occurred despite a 15 percent decline in acreage devoted to farming during the period, and water supply suffering from chronic instability. Factors contributing to the growth in sales-per-acre include more intensive use of active farmlands and technological improvements in crop production.[168] In 2008, California's 81,500 farms and ranches generated $36.2 billion products revenue.[169] In 2011, that number grew to $43.5 billion products revenue.[170] The Agriculture sector accounts for two percent of the state's GDP and employs around three percent of its total workforce.[171] According to the USDA in 2011, the three largest California agricultural products by value were milk and cream, shelled almonds, and grapes.[172]		Per capita GDP in 2007 was $38,956, ranking eleventh in the nation.[173] Per capita income varies widely by geographic region and profession. The Central Valley is the most impoverished, with migrant farm workers making less than minimum wage. According to a 2005 report by the Congressional Research Service, the San Joaquin Valley was characterized as one of the most economically depressed regions in the United States, on par with the region of Appalachia.[174] California has a poverty rate of 23.5%, the highest of any state in the country.[175] Many coastal cities include some of the wealthiest per-capita areas in the United States The high-technology sectors in Northern California, specifically Silicon Valley, in Santa Clara and San Mateo counties, have emerged from the economic downturn caused by the dot-com bust.		In 2010, there were more than 663,000 millionaires in the state, more than any other state in the nation.[176] In 2010, California residents were ranked first among the states with the best average credit score of 754.[177]		State spending increased from $56 billion in 1998 to $127 billion in 2011.[181][182] California, with 12% of the United States population, has one-third of the nation's welfare recipients.[183] California has the third highest per capita spending on welfare among the states, as well as the highest spending on welfare at $6.67 billion.[184] In January 2011 the California's total debt was at least $265 billion.[185] On June 27, 2013, Governor Jerry Brown signed a balanced budget (no deficit) for the state, its first in decades; however the state's debt remains at $132 billion.[186][187]		With the passage of Proposition 30 in 2012, California now levies a 13.3% maximum marginal income tax rate with ten tax brackets, ranging from 1% at the bottom tax bracket of $0 annual individual income to 13.3% for annual individual income over $1,000,000. California has a state sales tax of 7.5%, though local governments can and do levy additional sales taxes. Many of these taxes are temporary for a seven-year period (as stipulated in Proposition 30) and afterwards will revert to a previous maximum marginal income tax bracket of 10.3% and state sales tax rate of 7.25%.[188]		All real property is taxable annually; the tax is based on the property's fair market value at the time of purchase or new construction. Property tax increases are capped at 2% per year (see Proposition 13).		Because it is the most populous United States state, California is one of the country's largest users of energy. However because of its high energy rates, conservation mandates, mild weather in the largest population centers and strong environmental movement, its per capita energy use is one of the smallest of any United States state.[189] Due to the high electricity demand, California imports more electricity than any other state, primarily hydroelectric power from states in the Pacific Northwest (via Path 15 and Path 66) and coal- and natural gas-fired production from the desert Southwest via Path 46.[190]		As a result of the state's strong environmental movement, California has some of the most aggressive renewable energy goals in the United States, with a target for California to obtain a third of its electricity from renewables by 2020.[191] Currently, several solar power plants such as the Solar Energy Generating Systems facility are located in the Mojave Desert. California's wind farms include Altamont Pass, San Gorgonio Pass, and Tehachapi Pass. Several dams across the state provide hydro-electric power. It would be possible to convert the total supply to 100% renewable energy, including heating, cooling and mobility, by 2050.[192]		The state's crude oil and natural gas deposits are located in the Central Valley and along the coast, including the large Midway-Sunset Oil Field. Natural gas-fired power plants typically account for more than one-half of state electricity generation.		California is also home to two major nuclear power plants: Diablo Canyon and San Onofre, the latter having been shut down in 2013. Also voters banned the approval of new nuclear power plants since the late 1970s because of concerns over radioactive waste disposal.[193][note 4] In addition, several cities such as Oakland, Berkeley and Davis have declared themselves as nuclear-free zones.		California's vast terrain is connected by an extensive system of controlled-access highways ('freeways'), limited-access roads ('expressways'), and highways. California is known for its car culture, giving California's cities a reputation for severe traffic congestion. Construction and maintenance of state roads and statewide transportation planning are primarily the responsibility of the California Department of Transportation, nicknamed "Caltrans". The rapidly growing population of the state is straining all of its transportation networks, and California has some of the worst roads in the United States.[195][196] The Reason Foundation's 19th Annual Report on the Performance of State Highway Systems ranked California's highways the third-worst of any state, with Alaska second, and Rhode Island first.[197]		The state has been a pioneer in road construction. One of the state's more visible landmarks, the Golden Gate Bridge, was once the longest suspension bridge main span in the world at 4,200 feet (1,300 m) when it opened in 1937. With its orange paint and panoramic views of the bay, this highway bridge is a popular tourist attraction and also accommodates pedestrians and bicyclists. The San Francisco–Oakland Bay Bridge (often abbreviated the "Bay Bridge"), completed in 1936, transports about 280,000 vehicles per day on two-decks. Its two sections meet at Yerba Buena Island through the world's largest diameter transportation bore tunnel, at 76 feet (23 m) wide by 58 feet (18 m) high.[198] The Arroyo Seco Parkway, connecting Los Angeles and Pasadena, opened in 1940 as the first freeway in the Western United States.[199] It was later extended south to the Four Level Interchange in downtown Los Angeles, regarded as the first stack interchange ever built.[200]		Los Angeles International Airport (LAX), the 6th busiest airport in the world, and San Francisco International Airport (SFO), the 23rd busiest airport in the world, are major hubs for trans-Pacific and transcontinental traffic. There are about a dozen important commercial airports and many more general aviation airports throughout the state.		California also has several important seaports. The giant seaport complex formed by the Port of Los Angeles and the Port of Long Beach in Southern California is the largest in the country and responsible for handling about a fourth of all container cargo traffic in the United States. The Port of Oakland, fourth largest in the nation, also handles trade entering from the Pacific Rim to the rest of the country. The Port of Stockton is the easternmost port on the west coast of the United States.[201]		The California Highway Patrol is the largest statewide police agency in the United States in employment with over 10,000 employees. They are responsible for providing any police-sanctioned service to anyone on California's state maintained highways and on state property.		The California Department of Motor Vehicles is by far the largest in North America. By the end of 2009, the California DMV had 26,555,006 driver's licenses and ID cards on file.[202] In 2010, there were 1.17 million new vehicle registrations in force.[203]		Inter-city rail travel is provided by Amtrak California; the three routes, the Capitol Corridor, Pacific Surfliner, and San Joaquin, are funded by Caltrans. These services are the busiest intercity rail lines in the United States outside the Northeast Corridor and ridership is continuing to set records. The routes are becoming increasingly popular over flying, especially on the LAX-SFO route.[204] Integrated subway and light rail networks are found in Los Angeles (Metro Rail) and San Francisco (MUNI Metro). Light rail systems are also found in San Jose (VTA), San Diego (San Diego Trolley), Sacramento (RT Light Rail), and Northern San Diego County (Sprinter). Furthermore, commuter rail networks serve the San Francisco Bay Area (ACE, BART, Caltrain, SMART), Greater Los Angeles (Metrolink), and San Diego County (Coaster).		The California High-Speed Rail Authority was created in 1996 by the state to implement an extensive 800-mile (1,300 km) rail system. Construction was approved by the voters during the November 2008 general election,[205] with the first phase of construction estimated to cost $64.2 billion.[206]		Nearly all counties operate bus lines, and many cities operate their own city bus lines as well. Intercity bus travel is provided by Greyhound, Megabus, and Amtrak Thruway Motorcoach.		California's interconnected water system is the world's largest, managing over 40,000,000 acre feet (49 km3) of water per year, centered on six main systems of aqueducts and infrastructure projects.[207] Water use and conservation in California is a politically divisive issue, as the state experiences periodic droughts and has to balance the demands of its large agricultural and urban sectors, especially in the arid southern portion of the state. The state's widespread redistribution of water also invites the frequent scorn of environmentalists.		The California Water Wars, a conflict between Los Angeles and the Owens Valley over water rights, is one of the most well-known examples of the struggle to secure adequate water supplies.[208] Former California Governor Arnold Schwarzenegger said: "We've been in crisis for quite some time because we're now 38 million people and not anymore 18 million people like we were in the late 60s. So it developed into a battle between environmentalists and farmers and between the south and the north and between rural and urban. And everyone has been fighting for the last four decades about water."[209]		The state's capital is Sacramento.		California is organized into three branches of government – the executive branch consisting of the Governor and the other independently elected constitutional officers; the legislative branch consisting of the Assembly and Senate; and the judicial branch consisting of the Supreme Court of California and lower courts. The state also allows ballot propositions: direct participation of the electorate by initiative, referendum, recall, and ratification. Before the passage of California Proposition 14 (2010), California allowed each political party to choose whether to have a closed primary or a primary where only party members and independents vote. After June 8, 2010 when Proposition 14 was approved, excepting only the United States President and county central committee offices,[210] all candidates in the primary elections are listed on the ballot with their preferred party affiliation, but they are not the official nominee of that party.[211] At the primary election, the two candidates with the top votes will advance to the general election regardless of party affiliation.[211] If at a special primary election, one candidate receives more than 50% of all the votes cast, they are elected to fill the vacancy and no special general election will be held.[211]		The California executive branch consists of the Governor of California and seven other elected constitutional officers: Lieutenant Governor, Attorney General, Secretary of State, State Controller, State Treasurer, Insurance Commissioner, and State Superintendent of Public Instruction. They serve four-year terms and may be re-elected only once.[212]		The California State Legislature consists of a 40-member Senate and 80-member Assembly. Senators serve four-year terms and Assembly members two. Members of the Assembly are subject to term limits of three terms, and members of the Senate are subject to term limits of two terms.		California's legal system is explicitly based upon English common law[213] (as is the case with all other states except Louisiana) but carries a few features from Spanish civil law, such as community property. California's prison population grew from 25,000 in 1980 to over 170,000 in 2007.[214] Capital punishment is a legal form of punishment and the state has the largest "Death Row" population in the country (though Oklahoma and Texas are far more active in carrying out executions).[215][216]		California's judiciary system is the largest in the United States (with a total of 1,600 judges, while the federal system has only about 840). At the apex is the seven Justices of the Supreme Court of California, while the California Courts of Appeal serve as the primary appellate courts and the California Superior Courts serve as the primary trial courts. Justices of the Supreme Court and Courts of Appeal are appointed by the Governor, but are subject to retention by the electorate every 12 years. The administration of the state's court system is controlled by the Judicial Council, composed of the Chief Justice of the California Supreme Court, 14 judicial officers, four representatives from the State Bar of California, and one member from each house of the state legislature.		California is divided into 58 counties. Per Article 11, Section 1, of the Constitution of California, they are the legal subdivisions of the state. The county government provides countywide services such as law enforcement, jails, elections and voter registration, vital records, property assessment and records, tax collection, public health, health care, social services, libraries, flood control, fire protection, animal control, agricultural regulations, building inspections, ambulance services, and education departments in charge of maintaining statewide standards.[217][218] In addition, the county serves as the local government for all unincorporated areas. Each county is governed by an elected board of supervisors.[219]		Incorporated cities and towns in California are either charter or general-law municipalities.[108] General-law municipalities owe their existence to state law and are consequently governed by it; charter municipalities are governed by their own city or town charters. Municipalities incorporated in the 19th century tend to be charter municipalities. All ten of the state's most populous cities are charter cities. Most small cities have a council-manager form of government, where the elected city council appoints a city manager to supervise the operations of the city. Some larger cities have a directly-elected mayor who oversees the city government. In many council-manager cities, the city council selects one of its members as a mayor, sometimes rotating through the council membership—but this type of mayoral position is primarily ceremonial.		The Government of San Francisco is the only consolidated city-county in California, where both the city and county governments have been merged into one unified jurisdiction. The San Francisco Board of Supervisors also acts as the city council and the Mayor of San Francisco also serves as the county administrative officer.		About 1,102 school districts, independent of cities and counties, handle California's public education.[220] California school districts may be organized as elementary districts, high school districts, unified school districts combining elementary and high school grades, or community college districts.[220]		There are about 3,400 special districts in California.[221] A special district, defined by California Government Code § 16271(d) as "any agency of the state for the local performance of governmental or proprietary functions within limited boundaries", provides a limited range of services within a defined geographic area. The geographic area of a special district can spread across multiple cities or counties, or could consist of only a portion of one. Most of California's special districts are single-purpose districts, and provide one service.		The state of California sends 53 members to the House of Representatives,[222] the nation's largest congressional state delegation. Consequently California also has the largest number of electoral votes in national presidential elections, with 55. California's U.S. Senators are Dianne Feinstein, a native and former mayor of San Francisco, and Kamala Harris, a native, former District Attorney from San Francisco and former Attorney General of California. In 1992, California became the first state to have a Senate delegation entirely composed of women.		In California, as of 2009[update], the U.S. Department of Defense had a total of 117,806 active duty servicemembers of which 88,370 were Sailors or Marines, 18,339 were Airmen, and 11,097 were Soldiers, with 61,365 Department of Defense civilian employees. Additionally, there were a total of 57,792 Reservists and Guardsman in California.[223]		In 2010, Los Angeles County was the largest origin of military recruits in the United States by county, with 1,437 individuals enlisting in the military.[224] However, as of 2002, Californians were relatively under-represented in the military as a proportion to its population.[225]		In 2000, California, had 2,569,340 veterans of United States military service: 504,010 served in World War II, 301,034 in the Korean War, 754,682 during the Vietnam War, and 278,003 during 1990–2000 (including the Persian Gulf War).[226] As of 2010[update], there were 1,942,775 veterans living in California, of which 1,457,875 served during a period of armed conflict, and just over four thousand served before World War II (the largest population of this group of any state).[227]		California's military forces consist of the Army and Air National Guard, the naval and state military reserve (militia), and the California Cadet Corps.		California has an idiosyncratic political culture compared to the rest of the country, and is sometimes regarded as a trendsetter.[230] In socio-cultural mores and national politics, Californians are perceived as more liberal than other Americans, especially those who live in the inland states.		Among the political idiosyncrasies and trendsetting, California was the second state to recall their state governor, the second state to legalize abortion, and the only state to ban marriage for gay couples twice by voters (including Proposition 8 in 2008). Voters also passed Proposition 71 in 2004 to fund stem cell research, and Proposition 14 in 2010 to completely change the state's primary election process. California has also experienced disputes over water rights; and a tax revolt, culminating with the passage of Proposition 13 in 1978, limiting state property taxes.		The state's trend towards the Democratic Party and away from the Republican Party can be seen in state elections. From 1899 to 1939, California had Republican governors. Since 1990, California has generally elected Democratic candidates to federal, state and local offices, including current Governor Jerry Brown; however, the state has elected Republican Governors, though many of its Republican Governors, such as Arnold Schwarzenegger, tend to be considered moderate Republicans and more centrist than the national party.		The Democrats also now hold a majority in both houses of the state legislature. There are 56 Democrats and 24 Republicans in the Assembly; and 26 Democrats and 12 Republicans in the Senate.		The trend towards the Democratic Party is most obvious in presidential elections; Republicans have not won California's electoral votes since 1988.		In the United States House, the Democrats held a 34–19 edge in the CA delegation of the 110th United States Congress in 2007. As the result of gerrymandering, the districts in California were usually dominated by one or the other party, and few districts were considered competitive. In 2008, Californians passed Proposition 20 to empower a 14-member independent citizen commission to redraw districts for both local politicians and Congress. After the 2012 elections, when the new system took effect, Democrats gained 4 seats and held a 38–15 majority in the delegation.		In general, Democratic strength is centered in the populous coastal regions of the Los Angeles metropolitan area and the San Francisco Bay Area. Republican strength is still greatest in eastern parts of the state. Orange County also remains mostly Republican. One study ranked Berkeley, Oakland, Inglewood and San Francisco in the top 20 most liberal American cities; and Bakersfield, Orange, Escondido, Garden Grove, and Simi Valley in the top 20 most conservative cities.[231]		In October 2012, out of the 23,802,577 people eligible to vote, 18,245,970 people were registered to vote.[232] Of the people registered, the three largest registered groups were Democrats (7,966,422), Republicans (5,356,608), and Decline to State (3,820,545).[232] Los Angeles County had the largest number of registered Democrats (2,430,612) and Republicans (1,037,031) of any county in the state.[232]		Coordinates: 37°N 120°W﻿ / ﻿37°N 120°W﻿ / 37; -120		
An emergent coastline is a stretch along the coast that has been exposed by the sea by a relative fall in sea levels by either isostasy or eustasy.[not verified in body]		Emergent coastline are the opposite of submergent coastlines, which have experienced a relative rise in sea levels.		The emergent coastline may have several specific landforms:		The Scottish Gaelic word machair or machar refers to a fertile low-lying raised beach found on some of the coastlines of Ireland and Scotland (especially the Outer Hebrides.		Hudson Bay, in Canada's north, is an example of an emergent coastline. It is still emerging by as much as 1 cm per year.[citation needed] Another example of emergent coastline is the Eastern Coastal Plains of the Indian Subcontinent.		
The mollusc (or mollusk[spelling 1]) shell is typically a calcareous exoskeleton which encloses, supports and protects the soft parts of an animal in the phylum Mollusca, which includes snails, clams, tusk shells, and several other classes. Not all shelled molluscs live in the sea; many live on the land and in freshwater.		The ancestral mollusc is thought to have had a shell, but this has subsequently been lost or reduced on some families, such as the squid, octopus, and some smaller groups such as the caudofoveata and solenogastres,[1] and the highly derived Xenoturbella.[2] Today, over 100,000 living species bear a shell; there is some dispute as to whether these shell-bearing molluscs form a monophyletic group (conchifera) or whether shell-less molluscs are interleaved into their family tree.[3]		Malacology, the scientific study of molluscs as living organisms, has a branch devoted to the study of shells, and this is called conchology—although these terms used to be, and to a minor extent still are, used interchangeably, even by scientists (this is more common in Europe).		Within some species of molluscs, there is often a wide degree of variation in the exact shape, pattern, ornamentation, and color of the shell.						A mollusc shell is formed, repaired and maintained by a part of the anatomy called the mantle. Any injuries to or abnormal conditions of the mantle are usually reflected in the shape and form and even color of the shell. When the animal encounters harsh conditions that limit its food supply, or otherwise cause it to become dormant for a while, the mantle often ceases to produce the shell substance. When conditions improve again and the mantle resumes its task, a "growth line" is produced.[verification needed]		The mantle edge secretes a shell which has two components. The organic constituent is mainly made up of polysaccharides and glycoproteins;[4] its composition may vary widely: some molluscs employ a wide range of chitin-control genes to create their matrix, whereas others express just one, suggesting that the role of chitin in the shell framework is highly variable;[5] it may even be absent in monoplacophora.[6] This organic framework controls the formation of calcium carbonate crystals[7][8] (never phosphate,[9] with the questionable exception of Cobcrephora[10]), and dictates when and where crystals start and stop growing, and how fast they expand; it even controls the polymorph of the crystal deposited,[5][11] controlling positioning and elongation of crystals and preventing their growth where appropriate.[4]		The shell formation requires certain biological machinery. The shell is deposited within a small compartment, the extrapallial space, which is sealed from the environment by the periostracum, a leathery outer layer around the rim of the shell, where growth occurs. This caps off the extrapallial space, which is bounded on its other surfaces by the existing shell and the mantle.[3]:475 The periostracum acts as a framework from which the outer layer of carbonate can be suspended, but also, in sealing the compartment, allows the accumulation of ions in concentrations sufficient for crystallization to occur. The accumulation of ions is driven by ion pumps packed within the calcifying epithelium.[3] Calcium ions are obtained from the organism's environment through the gills, gut and epithelium, transported by the haemolymph ("blood") to the calcifying epithelium, and stored as granules within or in-between cells ready to be dissolved and pumped into the extrapallial space when they are required.[3] The organic matrix forms the scaffold that directs crystallization, and the deposition and rate of crystals is also controlled by hormones produced by the mollusc.[3]:475 Because the extrapallial space is supersaturated, the matrix could be thought of as impeding, rather than encouraging, carbonate deposition; although it does act as a nucleating point for the crystals and controls their shape, orientation and polymorph, it also terminates their growth once they reach the necessary size.[3] Nucleation is endoepithelial in Neopilina and Nautilus, but exoepithelial in the bivalves and gastropods.[12]		The formation of the shell involves a number of genes and transcription factors. On the whole, the transcription factors and signalling genes are deeply conserved, but the proteins in the secretome are highly derived and rapidly evolving.[13] engrailed serves to demark the edge of the shell field; dpp controls the shape of the shell, and Hox1 and Hox4 have been implicated in the onset of mineralization.[14] In gastropod embryos, Hox1 is expressed where the shell is being accreted;[15] however no association has been observed between Hox genes and cephalopod shell formation.[16] Perlucin increases the rate at which calcium carbonate precipitates to form a shell when in saturated seawater;[17] this protein is from the same group of proteins (C-type lectins) as those responsible for the formation of eggshell and pancreatic stone crystals, but the role of C-type lectins in mineralization is unclear.[17] Perlucin operates in association with Perlustrin,[17] a smaller relative of lustrin A, a protein responsible for the elasticity of organic layers that makes nacre so resistant to cracking.[18] Lustrin A bears remarkable structural similarity to the proteins involved in mineralization in diatoms – even though diatoms use silica, not calcite, to form their tests![19]		The shell-secreting area is differentiated very early in embryonic development. An area of the ectoderm thickens, then invaginates to become a "shell gland". The shape of this gland is tied to the form of the adult shell; in gastropods, it is a simple pit, whereas in bivalves, it forms a groove which will eventually become the hinge line between the two shells, where they are connected by a ligament.[3] The gland subsequently evaginates in molluscs that produce an external shell.[3] Whilst invaginated, a periostracum - which will form a scaffold for the developing shell - is formed around the opening of the invagination, allowing the deposition of the shell when the gland is everted.[3] A wide range of enzymes are expressed during the formation of the shell, including carbonic anhydrase, alkaline phosphatase, and DOPA-oxidase (tyrosinase)/peroxidase.[3]		The form of the molluscan shell is constrained by the organism's ecology. In molluscs whose ecology changes from the larval to adult form, the morphology of the shell also undergoes a pronounced modification at metamorphosis.[13] The larval shell may have a completely different mineralogy to the adult conch, perhaps formed from amorphous calcite as opposed to an aragonite adult conch.[3]		In those shelled molluscs that have indeterminate growth, the shell grows steadily over the lifetime of the mollusc by the addition of calcium carbonate to the leading edge or opening. Thus the shell gradually becomes longer and wider, in an increasing spiral shape, to better accommodate the growing animal inside. The shell thickens as it grows, so that it stays proportionately strong for its size.		The loss of a shell in the adult form of some gastropods is achieved by the discarding of the larval shell; in other gastropods and in cephalopods, the shell is lost or demineralized by the resorption of its carbonate component by the mantle tissue.[20]		Hundreds[13] of soluble[21] and insoluble[22] proteins control shell formation. They are secreted into the extrapallial space by the mantle, which also secretes the glycoproteins, proteoglycans, polysaccharides and chitin that make up the organic shell matrix.[3] Insoluble proteins tend to be thought of as playing a more important/major role in crystallization control.[21] The organic matrix of shells tends to consist of β-chitin and silk fibroin.[23] Perlucin encourages carbonate deposition, and is found at the interface of the chitinous and aragonitic layer in some shells.[17] An acidic shell matrix appears to be essential to shell formation, in the cephalopods at least; the matrix in the non-mineralized squid gladius is basic.[24]		In oysters and potentially most molluscs, the nacreous layer has an organic framework of the protein MSI60, which has a structure a little like spider silk and forms sheets;[22] the prismatic layer uses MSI31 to construct its framework. This too forms beta-pleated sheets.[22] Since acidic amino acids, such as aspartic acid and glutamic acid, are important mediators of biomineralization, shell proteins tend to be rich in these amino acids.[25] Aspartic acid, which can make up up to 50% of shell framework proteins, is most abundant in calcitic layers, and also heavily present in aragonitic layers. Proteins with high proportions of glutamic acid are usually associated with amorphous calcium carbonate.[23]		The soluble component of the shell matrix acts to inhibit crystallization when in its soluble form, but when it attaches to an insoluble substrate, it permits the nucleation of crystals. By switching from a dissolved to an attached form and back again, the proteins can produce bursts of growth, producing the brick-wall structure of the shell.[3]		The formation of a shell in molluscs appears to be related to the secretion of ammonia, which originates from urea. The presence of an ammonium ion raises the pH of the extrapallial fluid, favouring the deposition of calcium carbonate. This mechanism has been proposed not only for molluscs, but also for other unrelated mineralizing lineages.[26]		The calcium carbonate layers in a shell are generally of two types: an outer, chalk-like prismatic layer and an inner pearly, lamellar or nacreous layer. The layers usually incorporate a substance called conchiolin, often in order to help bind the calcium carbonate crystals together. Conchiolin is composed largely of quinone-tanned proteins.		The periostracum and prismatic layer are secreted by a marginal band of cells, so that the shell grows at its outer edge. Conversely, the nacreous layer is derived from the main surface of the mantle.[27]		Some shells contain pigments which are incorporated into the structure. This is what accounts for the striking colors and patterns that can be seen in some species of seashells, and the shells of some tropical land snails. These shell pigments sometimes include compounds such as pyrroles and porphyrins.		Shells are almost always composed of polymorphs of calcium carbonate - either calcite or aragonite. In many cases, such as the shells of many of the marine gastropods, different layers of the shell are composed of calcite and aragonite. In a few species which dwell near hydrothermal vents, iron sulfide is used to construct the shell. Phosphate is never utilised by molluscs,[9] with the exception of Cobcrephora, whose molluscan affinity is uncertain.[10]		Shells are composite materials of calcium carbonate (found either as calcite or aragonite) and organic macromolecules (mainly proteins and polysaccharides). Shells can have numerous ultrastructural motifs, the most common being crossed-lamellar (aragonite), prismatic (aragonite or calcite), homogeneous (aragonite), foliated (aragonite) and nacre (aragonite). Although not the most common, nacre is the most studied type of layer.		In most shelled molluscs, the shell is large enough for all of the soft parts to be retracted inside when necessary, for protection from predation or from desiccation. However, there are many species of gastropod mollusc in which the shell is somewhat reduced or considerably reduced, such that it offers some degree of protection only to the visceral mass, but is not large enough to allow the retraction of the other soft parts. This is particularly common in the opisthobranchs and in some of the pulmonates, for example in the semi-slugs.		Some gastropods have no shell at all, or only an internal shell or internal calcareous granules, and these species are often known as slugs. Semislugs are pulmonate slugs with a greatly reduced external shell which is in some cases partly covered by the mantle.		The shape of the molluscan shell is controlled both by transcription factors (such as engrailed and decapentaplegic) and by developmental rate. The simplification of a shell form is thought to be relatively easily evolved, and many gastropod lineages have independently lost the complex coiled shape. However, re-gaining the coiling requires many morphological modifications and is much rarer. Despite this, it can still be accomplished; it is known from one lineage that was uncoiled for at least 20 million years, before modifying its developmental timing to restore the coiled morphology.[28]		In bivalves at least, the shape does change through growth, but the pattern of growth is constant. At each point around the aperture of the shell, the rate of growth remains constant. This results in different areas growing at different rates, and thus a coiling of the shell and a change in its shape - its convexity, and the shape of the opening - in a predictable and consistent fashion.[29]		The shape of the shell has an environmental as well as a genetic component; clones of gastropods can exert different shell morphologies. Indeed, intra-species variation can be many times larger than inter-species variation.[30]		A number of terms are used to describe molluscan shell shape; in the univalved molluscs, endogastric shells coil backwards (away from the head), whereas exogastric shells coil forwards;[31] the equivalent terms in bivalved molluscs are opisthogyrate and prosogyrate respectively.[32]		Nacre, commonly known as mother of pearl, forms the inner layer of the shell structure in some groups of gastropod and bivalve molluscs, mostly in the more ancient families such as top snails (Trochidae), and pearl oysters (Pteriidae). Like the other calcareous layers of the shell, the nacre is created by the epithelial cells (formed by the germ layer ectoderm) of the mantle tissue. However, nacre does not seem to represent a modification of other shell types, as it uses a distinct set of proteins.[33]		The fossil record shows that all molluscan classes evolved some 500 million years ago [34] from a shelled ancestor looking something like a modern monoplacophoran, and that modifications of the shell form ultimately led to the formation of new classes and lifestyles.[35] However, a growing body of molecular and biological data indicate that at least certain shell features have evolved many times, independently.[36] The nacreous layer of shells is a complex structure, but rather than being difficult to evolve, it has in fact arisen many times convergently.[36] The genes used to control its formation vary greatly between taxa: under 10% of the (non-housekeeping) genes expressed in the shells that produce gastropod nacre are also found in the equivalent shells of bivalves: and most of these shared genes are also found in mineralizing organs in the deuterostome lineage.[5] The independent origins of this trait are further supported by crystallographic differences between clades: the orientation of the axes of the deposited aragonite 'bricks' that make up the nacreous layer is different in each of the monoplacophora, gastropods and bivalves.[5]		Mollusc shells (especially those formed by marine species) are very durable and outlast the otherwise soft-bodied animals that produce them by a very long time (sometimes thousands of years even without being fossilized). Most shells of marine molluscs fossilize rather easily, and fossil mollusc shells date all the way back to the Cambrian period. Large amounts of shells sometimes form sediment, and over a geological time span can become compressed into limestone deposits.		Most of the fossil record of molluscs consists of their shells, since the shell is often the only mineralised part of a mollusc (however also see Aptychus and operculum). The shells are usually preserved as calcium carbonate – usually any aragonite is pseudomorphed with calcite.[37] Aragonite can be protected from recrystalization if water is kept away by carbonaceous material, but this did not accumulate in sufficient quantity until the Carboniferous; consequently aragonite older than the Carboniferous is practically unknown: but the original crystal structure can sometimes be deduced in fortunate circumstances, such as if an alga closely encrusts the surface of a shell, or if a phosphatic mould quickly forms during diagenesis.[37]		The shell-less aplacophora have a chitinous cuticle that has been likened to the shell framework; it has been suggested that tanning of this cuticle, in conjunction with the expression of additional proteins, could have set the evolutionary stage for the secretion of a calcareous shell in an aplacophoran-like ancestral mollusc.[38]		The molluscan shell has been internalized in a number of lineages, including the coleoid cephalopods and many gastropod lineages. Detorsion of gastropods results in an internal shell, and can be triggered by relatively minor developmental modifications such as those induced by exposure to high platinum concentrations.[39]		The nacreous layer of monoplacophoran shells appears to have undergone some modification. Whilst normal nacre, and indeed part of the nacreous layer of one monoplacophoran species (Veleropilina zografi), consists of "brick-like" crystals of aragonite, in monoplacophora these bricks are more like layered sheets.[6] The c-axis is perpendicular to the shell wall, and the a-axis parallel to the growth direction. This foliated aragonite is presumed to have evolved from the nacreous layer, with which it has historically been confused, but represents a novelty within the molluscs.[6]		Shells of chitons are made up of eight overlapping calcareous valves, surrounded by a girdle.		In some marine genera, during the course of normal growth the animal undergoes periodic resting stages where the shell does not increase in overall size, but a greatly thickened and strengthened lip is produced instead. When these structures are formed repeatedly with normal growth between the stages, evidence of this pattern of growth is visible on the outside of the shell, and these unusual thickened vertical areas are called varices, singular "varix". Varices are typical in some marine gastropod families, including the Bursidae, Muricidae, and Ranellidae.		Finally, gastropods with a determinate growth pattern may create a single and terminal lip structure when approaching maturity, after which growth ceases. These include the cowries (Cypraeidae) and helmet shells (Cassidae), both with in-turned lips, the true conchs (Strombidae) that develop flaring lips, and many land snails that develop tooth structures or constricted apertures upon reaching full size.		Nautiluses are the only extant cephalopods which have an external shell. (For information on a very large extinct subclass of shelled cephalopods, please see Ammonites.) Cuttlefish, squid, spirula, vampire squid, and cirrate octopuses have small internal shells. Females of the octopus genus Argonauta secrete a specialised paper-thin eggcase in which they partially reside, and this is popularly regarded as a "shell", although it is not attached to the body of the animal.		The shell of the Bivalvia is composed of two parts, two valves which are hinged together and joined by a ligament.		The shell of many of the scaphopods ("tusk shells") resembles a miniature elephant's tusk in overall shape, except that it is hollow, and is open at both ends.		As a structure made primarily of calcium carbonate, mollusc shells are vulnerable to attack by acidic fumes. This can become a problem when shells are in storage or on display and are in the proximity of non-archival materials, see Byne's disease.		
A peninsula (Latin: paeninsula from paene "almost" and insula "island") is a piece of land surrounded by water on the majority of its border, while being connected to a mainland from which it extends. Examples are the Upper and Lower peninsulas of the U.S. state of Michigan, the Scandinavian Peninsula and the Niagara peninsula.[1][2][3][4] The surrounding water is usually understood to be continuous, though not necessarily named as a single body of water. Peninsulas are not always named as such; one can also be a headland, cape, island promontory, bill, point, or spit.[5] A point is generally considered a tapering piece of land projecting into a body of water that is less prominent than a cape.[6] A river which courses through a very tight meander is also sometimes said to form a "peninsula" within the (almost closed) loop of water. In English, the plural of peninsula is peninsulas or, less commonly, peninsulae.						Peninsulas can be found on coastlines and in smaller bodies of water throughout the world, ranging in scale from square meters to millions of square kilometers. Some major peninsulas are:		
A ria (/riːə/ or /riə/)[1] is a coastal inlet formed by the partial submergence of an unglaciated river valley. It is a drowned river valley that remains open to the sea. Typically, rias have a dendritic, treelike outline although they can be straight and without significant branches. This pattern is inherited from the dendritic drainage pattern of the flooded river valley. The drowning of river valleys along a stretch of coast and formation of rias results in an extremely irregular and indented coastline. Often, there are islands, which are summits of partly submerged, pre-existing hill peaks.		A ria coast is a coastline having several parallel rias separated by prominent ridges, extending a distance inland.[2][3][4] The sea level change that caused the submergence of a river valley may be either eustatic (where global sea levels rise), or isostatic (where the local land sinks). The result is often a very large estuary at the mouth of a relatively insignificant river (or else sediments would quickly fill the ria). The Kingsbridge Estuary in Devon, England, is an extreme example of a ria forming an estuary disproportionate to the size of its river; no significant river flows into it at all, only a number of small streams.[4]						The word ria comes from Portuguese ria or Galician ría, which is related to Spanish and Galician río and Portuguese rio (river). Rias are present all along the Galician coast in Spain. As originally defined, the term was restricted to drowned river valleys cut parallel to the structure of the country rock that was at right angles to the coastline. However, the definition of ria was later expanded to other flooded river valleys regardless of the structure of the country rock.		For a period of time, European geomorphologists[5] regarded rias to include any broad estuarine river mouth, including fjords. These are long, narrow inlets with steep sides or cliffs, created in a valley carved by glacial activity. In the 21st century, however, the preferred usage of ria by geologists and geomorphologists is to refer solely to drowned unglaciated river valleys. It therefore excludes fjords by definition, since fjords are products of glaciation.[2][3][4]		Ria can amplify the effects of tsunami, as demonstrated in the seismicity of the Sanriku coast, most recently in the 2011 Tōhoku earthquake and tsunami.		
A sand cleaning machine, beach cleaner, or (colloquially) sandboni is a vehicle that drags a raking or sifting device over beach sand to remove rubbish and other foreign matter. They are manually self-pulled vehicles on tracks or wheels or pulled by quad-bike or tractor. Seaside cities use beach cleaning machines to combat the problems of litter left by beach patrons and other pollution washed up on their shores. A chief task in beach cleaning strategies is finding the best way to handle waste matter on the beaches, taking into consideration beach erosion and changing terrain. Beach cleaning machines work by collecting sand by way of a scoop or drag mechanism and then raking or sifting anything large enough to be considered foreign matter, including sticks, stones, litter and other items. Similar applications include lake beaches, sandfields for beach volleyball and kindergarten and playing field sandpits. The word "sandboni" is a back-formation referencing the ice-surfacing machine Zamboni.[1]						Raking technology can be used on dry or wet sand. When using this method, a rotating conveyor belt containing hundreds of tines combs through the sand and removes surface and buried debris while leaving the sand on the beach. Raking machines can remove materials ranging in size from small pebbles, shards of glass, and cigarette butts to larger debris, like seaweed and driftwood. By keeping the sand on the beach and only lifting the debris, raking machines can travel at high speeds.		Sifting technology is practiced on dry sand and soft surfaces. The sand and waste are collected via the pick-up blade of the vehicle onto a vibrating screening belt, which leaves the sand behind. The waste is gathered in a collecting tray which is often situated at the back of the vehicle. Because sand and waste are lifted onto the screening belt, sifters must allow time for the sand to sift through the screen and back onto the beach. The size of the materials removed is governed by the size of the holes in the installed screen.		Combined raking and sifting technology differs from pure sifters in that it uses rotating tines to scoop sand and debris onto a vibrating screen instead of relying simply on the pick-up blade. The tines' position can be adjusted to more effectively guide different-sized materials onto the screen. Once on the screen, combined raking and sifting machines use the same technology as normal sifters to remove unwanted debris from the sand.		Sand sifting by hand is used for smaller areas or sensitive habitat. Sand and debris is collected into a windrow or pile and manually shoveled onto screened sifting trays to separate the debris from the sand. While effective, it requires the movement of sand to the site of the tray, and then redistribution of the sand after sifting. A more efficient method is the use of a screened fork at the place where the debris is located. The effort to manually agitate the sand can become tiresome; however, a recent development of a battery-powered sand rake combines the spot cleaning effectiveness of manual screening with the ease of an auto-sifting hand tool.		Sand cleaning machines are used all over the world to ensure the safety and happiness of beach-goers. By removing litter, unwanted seaweed, and other debris from the beach, municipalities and resorts are able to maintain their beaches with fewer invested hours.		In addition to their regular litter-removing uses, beach and sand cleaners have been used to clean up after natural disasters. For example:		In Galveston, Texas, low oxygen levels in the water resulted in thousands of dead fish washing ashore. Raking sand cleaners were then used to remove the rotting fish off the beach before they released excessive toxins into the air, sand, and water.[2]		The Olympic Games 2008 saw the first remote-control Sandbonis for the beach volleyball fields in Beijing Chaoyang Park.[3]		The cleanup after the Deepwater Horizon oil spill saw large applications of sand cleaners to the area.[1] Similarly, the Rena oil spill in New Zealand also saw beach cleaners deployed in an effort to remove the affected sand.[4]		The major manufacturers of large beach-sand cleaning machines are considered to be H Barber & Sons, Cherrington, Beach Tech, Rockland, Qingzhou Rio and Tirrenia Srl.		There are many other manufacturers of sand cleaners being used for other purposes. For example, a smaller 4-wheel and halftrack sand cleaning machine is used for sandpits in Kindergarten and municipality playing fields and for beach volleyball.[5][6] When environmental or spot-cleaning requires hand operations, an auto-sifting, lightweight, screened rake can be the best choice[7]		
A shingle beach is a beach which is armoured with pebbles or small- to medium-sized cobbles (as opposed to fine sand). Typically, the stone composition may grade from characteristic sizes ranging from 2 to 200 millimetres (0.1 to 7.9 in) diameter.		While this beach landform is most commonly found in Europe, examples are found in Bahrain, North America and in a number of other world regions, such as the east coast of New Zealand's South Island, where they are associated with the shingle fans of braided rivers. Though created at shorelines, post-glacial rebound can raise shingle beaches as high as 200 metres (660 ft) above sea level, at the High Coast in Sweden.		The ecosystems formed by this unique association of rock and sand allow colonization by a variety of rare and endangered species.[1]						Shingle beaches are typically steep, because the waves easily flow through the coarse, porous surface of the beach, decreasing the effect of backwash erosion and increasing the formation of sediment into a steeply sloping beach.[2]		Shingle beaches are often criticized as undesirable for visitors. Canterbury City Council notes that the nearby shingle beach at Whitstable is uncomfortable to walk and lie on.[3] Also, at least one advertiser has replaced an image of a shingle beach with sand in promotional material.[4] However, shingle beaches are popular among rock collectors for the varying rock types that can be found.		
A headland (or simply head) is a coastal landform, a point of land usually high and often with a sheer drop, that extends out into a body of water. It is a type of promontory. A headland of considerable size often is called a cape.[1] Headlands are characterised by high, breaking waves, rocky shores, intense erosion, and steep sea cliffs.		Headlands and bays are often found on the same coastline. A bay is flanked by land on three sides, whereas a headland is flanked by water on three sides. Headlands and bays form on discordant coastlines, where bands of rock of alternating resistance run perpendicular to the coast. Bays form where weak (less resistant) rocks (such as sands and clays) are eroded, leaving bands of stronger (more resistant) rocks (such as chalk, limestone, granite) forming a headland, or peninsula. Through the deposition of sediment within the bay and the erosion of the headlands, coastlines eventually straighten out then start the same process all over again.						
A cotton mill is a factory housing powered spinning or weaving machinery for the production of yarn or cloth from cotton,[1] an important product during the Industrial Revolution when the early mills were important in the development of the factory system.[2]		Although some were driven by animal power, most early mills were built in rural locations near to fast-flowing rivers and streams and had water wheels to power them.[3] The development of viable rotative steam engines by Boulton and Watt led from 1781 to the growth of larger, steam-powered mills and allowed them to be concentrated in urban mill towns, most notably Manchester, which with neighbouring Salford had more than 50 mills by 1802.[4]		The mechanisation of the spinning process in the early factories was instrumental in the growth of the machine tool industry, enabling the construction of larger cotton mills. Limited companies were developed to construct mills, and the trading floors of the cotton exchange in Manchester, created a vast commercial city. Mills generated employment, drawing workers from largely rural areas and expanding urban populations. They provided incomes for girls and women. Child labour was used in the mills, and the factory system led to organised labour. Poor conditions became the subject of exposés, and in England, the Factory Acts were written to regulate them.		The cotton mill, originally a Lancashire phenomenon, was copied in New England and later in the southern states of America. In the 20th century, North West England lost its supremacy to the United States,[5][6] then to India and subsequently to China.						In the mid-16th century Manchester was an important manufacturing centre for woollens and linen and market for textiles made elsewhere.[7] The fustian district of Lancashire, from Blackburn to Bolton, west to Wigan and Leigh and south towards Manchester, used flax and raw cotton imported along the Mersey and Irwell Navigation.		During the Industrial Revolution cotton manufacture changed from a domestic to a mechanised industry, made possible by inventions and advances in technology. The weaving process was the first to be mechanised by the invention of John Kay's flying shuttle in 1733. The manually-operated spinning jenny was developed by James Hargreaves in about 1764 speeded up the spinning process.[8] The roller spinning principle of Paul and Bourne became the basis of Richard Arkwright's spinning frame and water frame, patented in 1769.[9] The principles of the spinning jenny and water frame were combined by Samuel Crompton in his spinning mule of 1779, but water power was not applied to it until 1792.[10] Many mills were built after Arkwright's patent expired in 1783 and by 1788, there were about 210 mills in Great Britain.[11] The development of cotton mills was linked to the development of the machinery they contained. By 1774, 30,000 people in Manchester were employed using the domestic system in cotton manufacture. Handloom weaving lingered into the mid-19th century but cotton spinning in mills relying on water power and subsequently steam power using fuel from the Lancashire Coalfield began to develop before 1800.[12]		The first cotton mills were established in the 1740s to house roller spinning machinery invented by Lewis Paul and John Wyatt.[14][15][16][17] The machines were the first to spin cotton mechanically "without the intervention of human fingers".[18] They were driven by a single non-human power source which allowed the use of larger machinery and made it possible to concentrate production into organised factories.[19] Four mills were set up to house Paul and Wyatt's machinery in the decade following its patent in 1738: the short-lived, animal-powered Upper Priory Cotton Mill in Birmingham in 1741;[20] Marvel's Mill in Northampton operated from 1742 until 1764 and was the first to be powered by a water wheel;[21] Pinsley Mill in Leominster probably opened in 1744 and operated until it burned down in 1754;[22] and a second mill in Birmingham set up by Samuel Touchet in 1744, about which little is known, but which was sufficiently successful for Touchet later to seek the lease on the mill in Northampton.[23] The Paul-Wyatt mills spun cotton for several decades but were not very profitable,[24][25] becoming the ancestors of the cotton mills that followed.[15][26]		Richard Arkwright obtained a patent for his water frame spinning machinery in 1769.[27] Although its technology was similar to that of Lewis Paul, John Wyatt, James Hargreaves and Thomas Highs, Arkwright's powers of organisation, business acumen and ambition established the cotton mill as a successful business model and revolutionary example of the factory system.[28][27][29] Arkwright's first mill – powered by horses in Nottingham in 1768 – was similar to Paul and Wyatt's first Birmingham mill although by 1772 it had expanded to four storeys and employed 300 workers.[28][27] In 1771, while the Nottingham mill was at an experimental stage, Arkwright and his partners started work on Cromford Mill in Derbyshire, which "was to prove a major turning point in the history of the factory system".[30] It resembled the Paul-Wyatt water-powered mill at Northampton in many respects,[31] but was built on a different scale, influenced by John Lombe's Old Silk Mill in Derby[32] and Matthew Boulton's Soho Manufactory in Birmingham.[33] Constructed as a five-storey masonry box; high, long and narrow, with ranges of windows along each side and large relatively unbroken internal spaces, it provided the basic architectural prototype that was followed by cotton mills and English industrial architecture through to the end of the 19th century.[34]		Arkwright recruited large, highly disciplined workforces for his mills, managed credit and supplies and cultivated mass consumer markets for his products.[35] By 1782 his annual profits exceeded £40,000,[36] and by 1784 he had opened 10 more mills.[37] He licensed his technology to other entrepreneurs[38] and in 1782 boasted that his machinery was being used by "numbers of adventurers residing in the different counties of Derby, Leicester, Nottingham, Worcester, Stafford, York, Hertford and Lancashire"[39] and by 1788 there were 143 Arkwright-type mills nationwide.[40] The early mills were of light construction, narrow – about 9 feet (2.7 m) wide – and low in height, with ceiling heights of only 6–8 ft.[41] The mills were powered by water wheels and lit by daylight. Mills were made by millwrights, builders and iron founders.[42] By the end of the 18th century there were about 900 cotton mills in Britain, of which approximately 300 were large Arkwright-type factories employing 300 to 400 workers, the rest, smaller mills using jennies or mules, were hand- or horse-driven and employed as few as 10 workers.[43]		Before 1780, only water power was available to drive large mills,[44] but they were dependent on a constant flow of water and built in rural locations, causing problems of labour supply, transportation of materials and access to urban merchants for large mill-owners.[45] Steam engines had been used to pump water since the invention of the atmospheric engine by Thomas Newcomen in 1712[46] and, starting with the engine installed at Arkwright's Haarlem Mill in Wirksworth, Derbyshire in 1780, were used to supplement the supply of water to the water wheels of cotton mills.[47]		In 1781 James Watt registered a patent for the first rotative steam engine designed to "give motion to the wheels of mills or other machines".[48] Concerns remained over the smoothness of the power supplied by a steam engine to cotton mills, where the regularity of the yarn produced was dependent on the regularity of the power supply,[49] and it was not until 1785 at Papplewick, in Robinson's Mill near Nottingham that a steam engine was successfully used to drive a cotton mill directly.[50] Boulton and Watt's engines enabled mills to be built in urban contexts and transformed the economy of Manchester, whose importance had previously been as a centre of pre-industrial spinning and weaving[51] based on the domestic system.[4] Manchester had no cotton mills until the opening of Arkwright's Shudehill Mill in 1783 and in 1789 Peter Drinkwater opened the Piccadilly Mill – the town's first mill to be directly powered by steam – and by 1800 Manchester had 42 mills, having eclipsed all rival textile centres to become the heart of the cotton manufacturing trade.[52]		Water continued to be used to drive rural mills but mills, driven by steam, were built in towns alongside streams or canals to provide water for the engine. Murrays' Mills alongside the Rochdale Canal, in Ancoats were powered by 40 hp Boulton and Watt beam engines.[53]b Some were built as room and power mills, which let space to entrepreneurs. The mills, often 'L' or U-shaped, were narrow and multi-storeyed. The engine house, warehousing and the office were inside the mill, although stair towers were external. Windows were square and smaller than in later mills. The walls were of unadorned rough brick. Construction was sometimes to fireproof designs. The mills are distinguished from warehouses in that warehouses had taking-in doors on each storey with an external hoist beam.[54] Only the larger mills have survived.		Mills of this period were from 25 to 68 m long and 11.5 m to 14 m wide. They could be eight storeys high and had basements and attics. Floor height varied from 3.3 to 2.75 m on the upper storeys.		Boilers were of the wagon type; chimneys were square or rectangular, attached to the mill, and in some cases part of the stair column. The steam engines were typically low-pressure single-cylinder condensing beam engines.[55] The average power in 1835 was 48 hp.[56] Power was transmitted by a main vertical shaft with bevel gears to the horizontal shafts. The later mills had gas lighting using gas produced on site.[57] The mules with 250–350 spindles were placed transversely to get as much light as possible.		The development of mills to mechanise the weaving process was more gradual partly because of the success of John Kay's 1733 invention of the flying shuttle, which increased the productivity of domestic hand loom weavers.[58] Kay took out a patent for the application of water power to a Dutch loom in 1745 and opened a weaving factory in Keighley in 1750, but nothing is known of its success.[58] A further attempt to mechanise the weaving process took place at Garrett Hall in Manchester in 1750 but was unsuccessful in enabling one worker to operate more than a single loom.[58] The first feasible power loom was patented by Edmund Cartwright in 1785, although it was initially a primitive device it established the basic principle that would be used in powered weaving until the 20th century.[59] In 1788 Cartwright opened Revolution Mill in Doncaster which was powered by a Boulton and Watt steam engine and had 108 power looms on three floors as well as spinning machinery, but it was not a commercial success and closed in 1790.[60] A second mill using Cartwright's machinery, opened in Manchester in 1790 but was burned to the ground by hand loom weavers within two years.[61] By 1803 there were only 2,400 power looms operating in Britain.[62]		In the United States, the early horse-powered Beverly Cotton Manufactory was designed by Thomas Somers, who started construction and testing of the facility in 1787, finishing the factory's equipment in 1788. Experience from this factory led Moses Brown of Providence to request the assistance of a person skilled in water-powered spinning. Samuel Slater, an immigrant and trained textile worker from England, accepted Brown's proposal, and assisted with the design and construction of Slater Mill, built in 1790 on the Blackstone River in Pawtucket, Rhode Island. Slater evaded restrictions on emigration put in place to allow England to maintain its monopoly on cotton mills. Slater Mill resembled the Beverly Cotton Manufactory and a mill in Derbyshire in which he had worked.[63][64]		From 1825 the steam engine was able to power larger machines constructed from iron using improved machine tools. Mills from 1825 to 1865 were generally constructed with wooden beamed floors and lath and plaster ceilings. William Fairbairn experimented with cast iron beams and concrete floors. Mills were of red brick or sometimes local stone with a greater attention to decoration and the main gate was often highlighted with stone decoration. The stair columns were exterior to the main floors.[65] During this period the mules got wider and the width of the bays increased. Specialised mill architects appeared.		Mills of this period were tall, narrow, and wide. They were commonly built with one or two wings to form an 'L' or 'U' shape. Brunswick Mill was a 28-bay mill, 6 storeys of 16 m by 92 m. Each self-acting spinning mule had 500 spindles.[65] Single-storey north light weaving sheds were sometimes added to the mills. The looms caused vibrations that damaged the structure of multi-storey buildings,[66] and specialised weaving mills became common. They were single-storey sheds with an engine house and offices, and preparation and warehousing in a two-storey ancillary building.[citation needed]		Large mills remained the exception during this period. In 1833 the largest mill was that of McConnel and Company in Ancoats, Manchester with 1,545 workers, but in 1841 there were still only 25 mills in Lancashire with 1,000 workers or more, and the number of workers in the average mill was 193.[67]		The Lancashire boiler was patented in 1844, and the economiser in 1845. This can been seen as a square brick structure between the boiler house and the chimney. The engines were double compound upright beam engines of the type patented by McNaught in 1845. Each room in the mill would have line shafts suitable for the type of frame, connected by belt drives or gearing.[68]		In 1860, there were 2650 cotton mills in the Lancashire region, employing 440,000 people. The workers, 90 per cent of whom were adults and 56 per cent females, were paid a total of ₤11.5 million per annum. The mills used 300,000 hp of power, of which 18,500 was generated by waterpower. The mills had 30,387,467 spindles and 350,000 power looms. The industry imported 1,390,938,752 lb of raw cotton a year. It exported 2,776,218,427 yards of cotton cloth and 197,343,655 pounds (89,513,576 kg) of twist and yarn. The total value of its exports was ₤32,012,380.		1860 saw the end of this period of rapid growth. The Cotton Famine of 1861–1865 was a period when American long staple cotton became unavailable due to an American Civil War. After the war, the economics of the industry had changed, and a new larger mill was required.		In 1814 the Boston Manufacturing Company of New England established a "fully integrated" mill on the Charles River at Waltham, Massachusetts. Despite the ban on exporting technology from the UK, one of its proprietors, Francis Cabot Lowell, had travelled to Manchester to study the mill system and memorised some of its details. In the same year, Paul Moody built the first successful power loom in the US. Moody used a system of overhead pulleys and leather belting, rather than bevel gearing, to power his machines.[69] The group devised the Waltham System of working, which was duplicated at Lowell, Massachusetts and several other new cities throughout the state. Mill girls, some as young as ten, were paid less than men, but received a fixed wage for their 73-hour week. They lived in company-owned boarding houses, and attended churches supported by the companies.[70][71]		In the 1840s George Henry Corliss of Providence, Rhode Island improved the reliability of stationary steam engines. He replaced slide valves with valves that used cams. These Corliss valves were more efficient and more reliable than their predecessors. Initially, steam engines pumped water into a nearby reservoir that powered the water wheel, but were later used as the mill's primary power source. The Corliss valve was adopted in the UK, where in 1868 more than 60 mill engines were fitted with them.[72]		The large steam-powered Bowreah Cotton Mills opened at Fort Gloster near Calcutta by British interests in the 1820s, using British women to impart machine-spinning skills to the local workforce.[73] They closed down in 1837 but reopened with Dwarkanath Tagore as a major shareholder, and by 1840 lay at the centre of a major industrial complex powered by five steam engines, that included a twist mill, foundry and a rum distillery.[73]		Just before 1870, a mill was built by a joint-stock spinning company and this financial structure led to a new wave of mill construction. The phrase Oldham Limiteds describes these companies. Family-run firms continued to build, but grouped into associations such as the Fine Spinners' and Doublers' Association. Joseph Stott of Oldham perfected a method of fireproof floor construction using steel beams supporting brick vaults that in turn supported concrete floors that would support heavier equipment. Ring frames replaced mule frames; they were heavier and larger and were placed transversely, the floors became larger (up to 130 feet (40 m) wide) and higher to provide light. The bay size in a mill was defined by the positioning of machines. In an 1870 mill the bay was typically 10 feet 6 inches (3.20 m), and the brick vaults 5 feet 3 inches (1.60 m) though there were variations.[74]		Engines were run at higher pressures and from 1875, powered horizontal shafts on each floor by means of ropes. This was a prominent change as a rope race had to be built running the height of the mill. The engine needed more space and the engine house, boiler house and economiser were external to the main mill.[75] Mills continued to get bigger, and were sometimes paired; two mills being driven by one engine. Another change was the trend of having carding on one floor. To achieve this, the ground floor was extended outwards behind the mill often a full mill width.[76] In a single mill, the crosswall divided the blowing room from the rest, as it was here that there was greatest risk of fire.		Mills became wider, Houldsworth Mill, Reddish (1865) was 35 m wide and accommodated 1200 spindle mules. It was of four storeys and had sixteen bays on each side of a central engine house; a double mill. The central block provided offices and warehousing. A mill had a range of ancillary buildings.[76] Stair columns often extending above the mill and housed a water tank for the sprinkler system. The floors were higher allowing for taller windows. Accrington brick was used from 1890, decorated with yellow sandstone with moulded brick and terracotta features. Etched and stained glass was used in the offices. Mills were designed by specialist architects and architectural quality became a major consideration.[77]		The power needed and provided to drive these mills was increasing. Beam engines were installed until the 1870s when horizontal engines took over. Abbey Mill Oldham (1876) needed 700 hp, Nile Mill (1896) needed 2500 hp. By the 1890, boilers produced 160 psi, and the triple expansion horizontals became standard. Chimneys were octagonal.[78]		Following the American Civil War, mills grew larger. They were built in the southern states of South Carolina, Alabama, and Mississippi where cheap labour and plentiful water power made operations profitable. Cotton could be processed into fabric where it grew, saving transportation costs. The mills were usually combination mills, (spinning and weaving) that were water powered and used a slow burn design technique. They used a belt and pulley drive system, and heavier ring frames rather than mules. At this point they only spun and wove coarse counts. The mills were mainly in open country and mill towns were formed to support them. New England mills found it increasingly difficult to compete, and as in Lancashire, went into gradual decline until bankrupted during the Great Depression. Cotton mills and their owners dominated the economy and politics of the Piedmont well into the 20th century.		The modern Indian mechanised textile industry was born in 1854, when a steam-powered mill was opened in Bombay by Cowasjee N. Davar.[79] More followed: there were 10 by 1865 and 47 by 1875.[79] By 1880 there were 58 mills in India employing 40,000 workers, with over 80% of them in the cities of Bombay and Ahmedabad.[80] From the 1870s India's own markets for finished yarn and cloth ceased to be dominated by imports from Lancashire, and during the 1870s and 1880s the Bombay cotton industry began to replace exports of yarn from Britain to China.[81]		The cotton industry was subject to cycles of boom and slump, which caused waves of mill building. There was an optimism that dictated that slumps had to be endured and then there would be a period of even greater prosperity. The limited companies took control of spinning, while the room and power system was the norm for the weaving sheds. One point of view in the 1880s was that vertically integrating the weaving sheds into new mills would reduce costs and lead to greater profits. This route had been followed in New England, where it was successful, but not in Lancashire. The industry peaked in 1907. There was a severe slump in 1908, which endured until 1918, but the years 1919 and 1920 were more profitable than the peak year of 1907 had been.[82]		Production peaked in 1912. The war of 1914–1918 put the Lancashire industry into reverse. The British government, starved of raw cotton, established mills in south Asia exporting the spinning technology - which was copied, and became a low-labour cost competitor. In Germany, Flanders and Brazil, mills were built to the designs of the Oldham architects. The only new mills were very large to benefit from the economies of scale. Older mills were re-equipped with rings, and machines were powered by individual electric motors.		Mills of this period were large, their decoration was lavish reflecting Edwardian taste and prosperity.[83] Most mills were built for mules. Kent Mill Chadderton (1908) was a five storey, 11 bay mill, 84.6m x 43.9m. It had 90,000 spindles. Ring frames were smaller and heavier than mules so the mills were narrower with fewer storeys. Pear Mill Bredbury (1912) was planned to be a 210,000 spindle double mill.[84] Only the first mill was completed, it had 137,000 spindles. They had more stair columns than earlier mills, it had dust flues often built into the rope race. There were two or three windows per bay. Decoration was often in terracotta and the mill name displayed in white brick on the stir tower or chimney.[85] Stott and Sons employed Byzantine styling in Broadstone Mill, Reddish. Specialist architects built new mills and then created extensions. The last steam-powered mill, Elk Mill, was built by Arthur Turner		Mules were built with 1300 spindles, but were gradually replaced by rings.		The increasingly powerful engines required more boilers with economisers and superheaters.[86] Mills needed reservoirs to supply the boilers and condense the steam. The chimneys were round and taller. Three types of engines were used: triple expansion horizontal cross compound engines, Inverted marine type compounds which were more compact, and Manhattans with vertical and horizontal cylinders such as the 3500 hp engine at New Pear Mill. Rope drives were used exclusively. Electricity was gradually introduced firstly on group drives driving a shaft (Little Mill, 1908), and then later on individual machines.[87]		Mills constructed in South Carolina increased in size. At Rutledge Ford the Saluda River was dammed and a power plant constructed. It was completed in 1904 before the construction of a state-of-the-art textile mill in 1906. That power plant provided for 4,800 horse power. The mill contained 30,000 spindles. By 1916 a new mill was constructed, containing 70,200 spindles and 1,300 looms. The town was named Ware Shoals. Between 1904 and 1916, the population of Ware Shoals grew from 2 men employed to maintain the newly constructed power plant, to 2,000. By the 1960s the mill employed 5,000 people. It closed in 1985.		Though business revived in 1919, a shortage of building materials restricted the building of new mills, and activity was financial with the mills seeking recapitalisation. There is no clear concession on the reason for the final decline. Some say that the cotton men concentrated on making easy money ignoring the possibility of foreign competition best countered by larger mills by re-equipping the mills with more modern ring frames. Daniels and Jewkes argued the fundamental cause of the depression was a change in demand for cotton goods. J. M. Keynes suggested that there was over capacity, and the industry should be reorganised into larger units that would scrap the excess capacity.[88]		The Lancashire Cotton Corporation was a company set up by the Bank of England in 1929, to rescue the Lancashire spinning industry by means of consolidation. In merged 105 companies, ending up in 1950 with 53 operating mills. These were the later larger mills. It was bought up by Courtaulds in August 1964.		The later mills were on the fringe of the spinning area in Wigan and Stockport, Availability of labour was cited as a reason.The last mills were completed in 1926, these were Holden Mill (Astley Bridge Mill)[89] and Elk Mill.[90]		In 1929, for the first time there were more spindles in the USA than in the UK. In 1972, India had greater spindleage than the USA, and it was in turn surpassed by China in 1977.[91]		Though there was a slight revival after 1945, mills closed. The most efficient mills had abandoned their steam engines, and were working the frames with individual electric motors. Broadstone Mills Stockport, was built as a double mill with 265,000 mule spindles, but by 1959 it was running 37,500 mule spindles and 70,000 ring spindles. It closed in 1959 taking advantage of the Cotton Industry Act 1959 and was then used by the John Myers mail order company. One mill was later demolished leaving the other to be used as a Shopping Outlet Centre and Craft Village. The reduction of capacity led to a legacy of redundant mills, which were readily reused for other industrial purposes.		Ring spinning technology had successfully replaced the spinning mule, with mills having been converted mules to rings. However in the 1970s, the depleted industry was challenged by a new technology open-end or break spinning. In 1978 Carrington Viyella opened a factory to do open-end spinning in Atherton. This was the first new textile production facility in Lancashire since 1929. Immediately Pear Mill, Stockport and Alder Mill, Leigh were closed. These were both Edwardian mills designed by Stott and Sons.[90] The mill built in 1978 was built on the Howe Bridge mills site and was named Unit One. It was not an open end mill but a combed cotton ring mill.		Modern spinning mills are mainly built around open end spinning techniques using rotors or ring spinning techniques using spindles. In 2009 there were 202,979,000 ring spinning spindles installed worldwide, with 82% of these being in Asia or Oceania and 44% being within China. In the same year there were 7,975,000 open end spinning rotors installed, with 44% of these being within Asia or Oceania and 29% within Eastern Europe.[92] The average age of installed rotors is much lower than that of spindles and as rotors are between 7 and 10 times more productive they are responsible for 20% of the cotton spun worldwide.[92]		Modern cotton mills are increasingly automated. One large mill in Virginia in the United States employs 140 workers in 2013 to produce an output that would have required more than 2,000 workers in 1980.[93]		Cotton mills were not confined to Lancashire but were built in northeast Cheshire, Derbyshire, Nottingham, the West Riding of Yorkshire, Bristol, Durham and the west of Scotland.[12] The availability of streams or rivers to provide power determined the location of the early mills some of which were in isolated areas. In Lancashire they were built on the rivers and streams descending from the Pennines and Rossendale moorland. In some places quite small streams powered a string of small mills such as in the Cheesden Valley between Ramsbottom and Heywood.[94] where 14 mills and their associated leats and ponds were concentrated along a four-mile stretch of the brook. Mills were built around Rochdale and Littleborough. North of Bury, ten mills occupied a mile long stretch of a stream in the Shuttleworth Valley.[95] Other mills were built north of the River Ribble and a cluster of five mills in Caton near the port at Lancaster, one of which belonged to Samuel Greg who built Quarry Bank Mill at Styal in Cheshire. Not all water-powered mills were in rural areas, after 1780 mills were built in Blackburn and Burnley.[96]		In Scotland, four cotton mills were built in Rothsay on the Isle of Bute using labour that had experience of the linen industry.[97] By 1800 there were two water-powered mills at Gatehouse of Fleet employing 200 children and 100 adults.[98] Robert Owen who had worked for Peter Drinkwater in Manchester, developed the mills at New Lanark built by his father-in-law, David Dale under licence from Arkwright.[99]		Cotton mills were huge fire risks, cotton fibres in the air could form an explosive mixture in their gas-lit interiors. The first mills using fireproof construction were built in Shropshire and Derbyshire in the 1790s and Philips & Lee's mill built in Salford in 1801-2. Fireproofing took the form of cast iron columns and beams from which sprang jack arches that were infilled with ash or sand and covered with stone flags or floorboards. In some mills timber was also eliminated from the roof structure which was supported by cast or wrought iron trusses.[101] Until the properties of cast iron were properly understood some mills constructed using the early technology collapsed. In Manchester extensive testing of cast iron as a structural material was carried out by Eaton Hodgkinson and William Fairbairn in the early 1820s.[102] Fireproof construction was expensive and timber, sometimes clad in plaster or metal continued to be used throughout the 19th century. Rolled steel beams and reinforced concrete flooring was introduced in a limited way in the 1880s but not widely adopted in Lancashire mills until the 20th century.[101]		Cotton is sensitive to temperature and humidity. Heating systems used wrought iron pipes suspended at a height of 7 feet (2.1 m) to carry steam under pressure. In summer the system was barely used but in winter the boilers would be fired up two hours before the shift started to warm up the mill. As heat was applied the humidity dropped and system of humidifiers, either atomisers which played an air jet against a jet of water or ones that injected a stream/air mixture into the room.[103]		Early fire fighting systems used sprinklers supplied by water captured on flat roofs in shallow tanks. Later mills had a water tank at the top of the stair tower. Water for the sprinklers had to be protected from freezing and evaporation. Water pressure needed to be above 7 psi, and the header tank at least 15 feet (4.6 m) above the highest sprinkler.[104] The provision of light, water tanks and heating system defined the structure and shape of the mill.		The earliest cotton mills were driven by water, so needed to be situated on fast flowing streams. From about 1820, the stationary steam engine became the normal form of power for a cotton mill, water was still needed to produce the steam and to condense it, to maintain the humidity, for many of the finishing processes and for firefighting. Water was extracted from rivers and canals, then later mills requiring ever more water, built and maintained their own reservoirs.		In 1781 James Watt marketed a rotary-motion steam engine that could be adapted to drive all sorts of machinery, Richard Arkwright pioneered its use in his cotton mills. Possibly the first steam engine to be used in a cotton mill was a Newcomen engine which was used at Shudehill Mill in 1783 to raise water between storage ponds so it could drive a water wheel. By 1795 most similar engines around Manchester had been replaced by Boulton and Watt or Bateman and Sherratt engines.[105]		Electricity was introduced in 1877. Steam engine drove generators to provide electric lighting. By the 1890s this was common.[106] Electricity was used to drive the mills machinery by 1906. It was generated in the engine house, and one group-drive electric motor was placed on each floor to drive the shafts. Generators were placed exterior to the mill as it was thought that they were a fire risk. Mains driven mills started about 1907. Later mills used individual electric motors to power the machinery.		The early mills had a vertical shaft to take the power from the flywheel. On each floor horizontal shafts engaged with the main shaft using bevel gearing. American mills used thick leather bands instead of shafts. A new approach was to use thick cotton ropes. A rope drum was attached to the flywheel with a channel cut for each rope. The profile was such to give maximum adherence.[107]		A spinning mill opened raw cotton bales and cleaned the cotton in the blowing room. The cotton staples are carded into lap and straightened and drawn into roving which is spun using either a mule or ring frame. The yarn can be doubled and processed into thread, or prepared for weaving.		Minerva Mill, Ashton-under-Lyne was designed by P. S. Stott and equipped by John Hetherington and Son, it produced 40's twists and 65 wefts. It was typical of a mill of the 1890s.		[109]		Self acting mule frame (Roberts 1830) was an improvement on Crompton's Mule (1779) which derived from earlier inventions.[110] Mules were used in the 19th century mills for the finest counts, these needed skilled workers to operate them.		Ring frame (1929) developed out of the Throstle frame (19th century) an improvement on the Arkwright's Water frame. Originally rings were only suitable for coarse counts, they were lower and heavier than mules so needed stronger floors but lower rooms. Over time, rings became suitable for finer counts and because of cheaper labour costs they replaced mules. By 1950 all mills had converted to the Ring frame. The Hawk mill in Shaw near Oldham was still operating cotton mule frames in 1964/65. [111]		A weaving mill needed yarn suitable for the warp and the weft. The warp had to delivered on the beam, or was wound on the beam from cheeses by a beamer. To obtain the extra strength needed, the yarn was sized on a sizer. The weft was wound onto the pirns for the shuttle on a pirner. These preparatory processes completed the yarn was woven on a loom. One weaver would operate 4 or six looms. A self-acting loom would stop when any thread broke, and the thread had to be retied or pieced. The process required greater levels of light than spinning, and weaving sheds would often be single storey, with overhead north facing lights. Placing a loom onto the ground also reduced the problems caused by the vibrations of operation.		The Cartwright's powerloom (1785) was made reliable by Robert's cast iron power loom (1822) and became perfected by the Kenworthy and Bullough Lancashire Loom (1854). The Northrop or Draper Loom (1895) replaced these older designs.[66]		The mills were notable in employing women, giving them an independent income. In Lancashire and Piedmont, South Carolina child labour is well documented.		The Lancashire and Derbyshire mills needed a pool of cheap labour. Pauper children were boys and girls between the ages of 7 and 21, who were dependent on the Poor Law Guardians. Mill owners made contracts with the guardians in London and the southern counties to supply them paupers, in batches of 50 or more, to be apprenticed. Living condition were poor in 'Prentice Houses', and the children who were paid 2d a day worked 15-hour shifts, hot bedding with children on the other shift.[citation needed]		Robert Owen was a millowner in New Lanark. He never employed children under the age of ten, and opposed physical punishment in schools and factories. He lobbied for parliamentary action, resulting in The Health and Morals of Apprentices Act 1802.		Regulation was ineffective until the mills were subject to inspection in 1833 with the establishment of a factory inspectorate consisting of four factory inspectors who had the power of magistrates.[113]:41–42 [114] This did not reduce the number of children, half-timers worked mornings in the mill and spend the afternoon in the school room. While the number of children working in spinning as tenters did decline, more were employed in weaving because weavers were expected to tenter extra looms.		From the Factory Act of 1844, until 1878 records do not distinguish between full-time and half-times. In 1851 a sizeable number of children were working the mills. For Example, In Glossop, there were 931 children (out of 3562) between 5 and thirteen working in cotton mills. In one mill in 1859, 50.2% of the workforce were women, 24.2% were girls, 19% were men and 6.6% were boys.[116]		The Carolinas mills developed from 1880, and would employ children in preference to adults. At Newton Mill, North Carolina, in 1909, twenty of the 150 workers observed, appeared to be twelve years old or less. As well as the usual report of hands and fingers getting severed by the machinery, and insufferable heat- the dust inhaled caused a fatal condition known as brown lung.[117] Laws were rarely enforced, and the presence of small children in the factory was explained away to the inspectors saying they were visiting the mill to bring meals to their parents (meal totters), or helping but not on the payroll (helpers).[118] Wages were good for the workers who could earn $2 a day in the mill against $0.75 on a farm. In the segregated south, 'Blacks' were not allowed to work inside a mill; had they been the need for child labour would have been eliminated.[119] Child labour stopped here not only because of new laws but the change in the type of machinery caused by the Great Depression, which required greater height and skill.[120]		In 1926 when it was at its peak, the Lancashire cotton industry worked 57.3 million spindles and 767,500 looms. It imported 3.3 million bales and exported 80% of its production. 61% of the 575,000 cotton operatives in Lancashire were women, of which 61% were unionised in 167 different unions[121]		The 18th-century woollen industry of small producers in southern England was far different from the Yorkshire-based worsted industry where the clothier imported and owned the raw material and sold the cloth. He put out work to small weavers, in effect, employing them. Worsted was more capital intensive. The small weavers banded together to form self-help guilds. When Lancashire adopted cotton, the same process occurred. But in Lancashire cotton mills, spinning became a male occupation, and the tradition of unions passed into the factory. As spinners were 'assisted' by several 'piecers' there was a pool of trained labour to replace any spinner the owner cared to dismiss. The well paid mule spinners were the 'barefoot aristocrats' of labour and became organised in the 19th century. They paid union dues, and were well placed to finance themselves should a strike be needed. The Yorkshire worsted industry, adopted the ring frame which required less skill. Worsted spinning was an occupation for young girls. Unionism did not develop in Yorkshire until 1914. In, 1913 figures show 50% of cotton operatives were unionised while only 10% of wool and worsted workers.		In Lancashire there were:		The spinners union, the Amalgamated Association of Operative Cotton Spinners had a federal structure with strong central leadership where control was in the hands of a small group of paid officials. Their dues were high, so the fighting fund was large and the officials were skilled in defending the complex wage structures.[122]		A cotton mill was not a healthy place to work. The air in the mill had to be hot and humid to prevent the thread from breaking: 18 °C to 26 °C and 85% humidity was normal. The air in the mill was thick with cotton dust, which could lead to byssinosis – a lung disease.		Protective masks were introduced after the war, but few workers wore them as they made them uncomfortable in the stifling conditions. The same applied to ear protectors. The air led to skin infections, eye infections, bronchitus and tuberculosis. The noise levels in a weaving shop, where the shuttles in 500 plus looms were being thumped 200 times a minute led to levels of deafness in all who worked there. The lubrication was carcinogenic and led to cancers of the mouth and cancer of the scrotum; known as mule-spinners cancer.[123]		A mill worker could expect to work a thirteen-hour day, six days a week with two weeks off for the wakes week holidays in summer. Unsurprisingly, a series of Factory Acts were passed to attempt to ameliorate these conditions.		In the early days when the cotton towns were expanding rapidly, living conditions for the workers were poor. Badly planned housing was seriously overcrowded. Open sewers and shared privies led to diseases such as cholera; Manchester was hit by an epidemic in 1831 that claimed hundreds of lives.[123]		Notes		Footnotes		Bibliography		
In fluid dynamics, wave shoaling is the effect by which surface waves entering shallower water change in wave height. It is caused by the fact that the group velocity, which is also the wave-energy transport velocity, changes with water depth. Under stationary conditions, a decrease in transport speed must be compensated by an increase in energy density in order to maintain a constant energy flux.[2] Shoaling waves will also exhibit a reduction in wavelength while the frequency remains constant.		In shallow water and parallel depth contours, non-breaking waves will increase in wave height as the wave packet enters shallower water.[3] This is particularly evident for tsunamis as they wax in height when approaching a coastline, with devastating results.						Waves nearing the coast change wave height through different effects. Some of the important wave processes are refraction, diffraction, reflection, wave breaking, wave–current interaction, friction, wave growth due to the wind, and wave shoaling. In the absence of the other effects, wave shoaling is the change of wave height that occurs solely due to changes in mean water depth – without changes in wave propagation direction and dissipation. Pure wave shoaling occurs for long-crested waves propagating perpendicular to the parallel depth contour lines of a mildly sloping sea-bed.[4]		For non-breaking waves, the energy flux associated with the wave motion, which is the product of the wave energy density with the group velocity, between two wave rays is a conserved quantity (i.e. a constant when following the energy of a wave packet from one location to another). Under stationary conditions the total energy transport must be constant along the wave ray – as first shown by William Burnside in 1915.[6] For waves affected by refraction and shoaling (i.e. within the geometric optics approximation), the rate of change of the wave energy transport is:[5]		where s {\displaystyle s} is the co-ordinate along the wave ray and b c g E {\displaystyle bc_{g}E} is the energy flux per unit crest length. A decrease in group speed c g {\displaystyle c_{g}} and distance between the wave rays b {\displaystyle b} must be compensated by an increase in energy density E {\displaystyle E} . This can be formulated as a shoaling coefficient relative to the wave height in deep water.[5][4]		For shallow water, when the wavelength is much larger than the water depth, wave shoaling satisfies Green's law:		with h {\displaystyle h} the mean water depth, H {\displaystyle H} the wave height and h 4 {\displaystyle {\sqrt[{4}]{h}}} the fourth root of h . {\displaystyle h.}		Following Phillips (1977) and Mei (1989),[7][8] denote the phase of a wave ray as		The local wave number vector is the gradient of the phase function,		and the angular frequency is proportional to its local rate of change,		Simplifying to one dimension and cross-differentiating it is now easily seen that the above definitions indicate simply that the rate of change of wavenumber is balanced by the convergence of the frequency along a ray;		Assuming stationary conditions ( ∂ / ∂ t = 0 {\displaystyle \partial /\partial t=0} ), this implies that wave crests are conserved and the frequency must remain constant along a wave ray as ∂ ω / ∂ x = 0 {\displaystyle \partial \omega /\partial x=0} . As waves enter shallower waters, the decrease in group velocity caused by the reduction in water depth leads to a reduction in wave length λ = 2 π / k {\displaystyle \lambda =2\pi /k} because the nondispersive shallow water limit of the dispersion relation for the wave phase speed,		dictates that		i.e., a steady increase in k (decrease in λ {\displaystyle \lambda } ) as the phase speed decreases under constant ω {\displaystyle \omega } .		
Scree is a collection of broken rock fragments at the base of crags, mountain cliffs, volcanoes or valley shoulders that has accumulated through periodic rockfall from adjacent cliff faces. Landforms associated with these materials are often called talus deposits. Talus deposits typically have a concave upwards form, while the maximum inclination corresponds to the angle of repose of the mean debris size.		The term scree comes from the Old Norse term for landslide, skriða,[1] while the term talus is a French word meaning a slope or embankment.[2][3]		Formation of scree or talus deposits the results of physical and chemical weathering and erosion acting on a rock face. The predominant processes that degrade a rock slope depend largely on the regional climate (temperature, amount of rainfall, etc.) Examples are:		Scree formation is commonly attributed to the formation of ice within mountain rock slopes. During the day, water can flow into joints and discontinuities in the rock wall. If the temperature drops enough, for example in the evening, this water may freeze. Since water expands by 9% when it freezes, it can generate large forces that either create new cracks or wedge blocks into an unstable position. Special boundary conditions (rapid freezing and water confinement) may be required for this to happen.[4] Freeze-thaw scree production is thought to be most common during the spring and fall, when the daily temperatures fluctuate around the freezing point of water, and snow melt produces ample free water.		The efficiency of freeze/thaw processes in scree production is debated by scientists. Many researchers believe that ice formation in large open crack systems cannot generate high pressures, and instead suggest that the water and ice simply flow out of the cracks as pressure builds.[5] Many argue that frost heaving, like that known to act in soil in permafrost areas, may play an important role in cliff degradation in cold places.[6][7]		Scree can conceal a glacier. For example, Lech dl Dragon, in the Sella Group of the Dolomites, derives from the melting waters of a glacier, hidden under a thick layer of scree. The melting process of the underlying glacier is slowed by the protective layer of scree.		Eventually a rock slope may be completely covered by its own scree, so that production of new material ceases. The slope is then said to be "mantled" with debris.		
Santa Eulària des Riu (Catalan pronunciation: [ˈsantə əwˈɫaɾiə ðəz ˈriw], Spanish: Santa Eulalia del Río) is a coastal town on the south eastern seaboard of the Spanish island of Ibiza. The town is located on the designated road PM 810.[1] Santa Eulària is the third largest town on the island and also has the only river on the island which flows into the sea at the western end of the town.						The town is 9.3 miles (15.0 km) north east of Ibiza Town and 13.6 miles (21.9 km) of Ibiza Airport.[1] The town sits next to a wide bay with the promontory of Punta Arabí at the east end of the Bay. Also at the eastern end of the bay is new harbour, mariner called Port Esportiu which is full of restaurants, shops and bars. The town has two beaches which are kept clean and tidy[2] and have gently sloping sands and are ideal for young families. At the western end of the bay is the prominent hill of ‘Puig d’ en Fita’ which dominates the landscape. The hill is dotted with apartments, hotels and private houses, and at night is dotted with the dwellings lights.		At the centre of the town on the ‘Plaça d’Espanya’ is the Ajuntament (town hall) which is now one of the last historical buildings[2] of the town. The present building, which has been renovated, dates from 1795[2] and reflects the typical architecture of the period on the island. Nowadays the building is less functional as a town hall and is used with a civic representative purpose. In front of the Ajuntament is a small square which has a fountain with a stone surround which faces the busy main street of ‘Carrer Saint Jaume’. Behind the fountain is a stone monument, erected by the city of Palma, Mallorca to thank and honour the local fishermen who, On 17 January 1913,[2] rescued victims of the shipwrecked steamboat ‘Mallorca’ which had run aground on a reef near the rocky inlet of Redona at Punta Arabí. The town streets run grid like from the ‘Plaça d’Espanya’ with the ‘Carrer Saint Jaume’ running west to east. The ‘Carrer da Sant Vincent’ runs parallel, one street back from ‘Carrer Saint Jaume’ with the western end of ‘Plaça d’Espanya’. This street is pedestrianized and is filled with typical Tavernas and restaurants.[3] There are also one or two lively bars. The ‘Carrer Saint Jaume’ is full of stores, banks, bars and restaurants.[2] The ‘Passeig de s’Alamera’ is an attractive thoroughfare which runs south from the ‘Plaça d’Espanya’ down to the seafront. This boulevard has a tree lined central pedestrianized area with gardens.[2] In the summer this shady ‘Ramblas’[3] is lined with market stalls selling jewellery, sarongs, tie-dye Thai garb and trinkets of all kinds.[3] At the southern end of ‘Passeig de s’Alamera’ is Santa Eulalia’s harbour front with views of the bay. Running in either direction is a paved and landscaped promenade. Below the promenade are the resorts two sandy beaches which have safe designated bathing areas which in the season are patrolled by lifeguards. Behind the promenade the bay is ringed by concrete apartment blocks, some of which have shops, bars, café and restaurants opening on to the promenade.		The river is called Riu de Santa Eulalia, it is more of a small stream and only ever becomes a raging torrent following very heavy rainfall. The source of the river is below the 342 metres high Puig d’en Sopes close to Sant Miquel. The river then meanders for 17 kilometres (11 mi) through the countryside to the sea at the western end of the town. A small way inland from the mouth of the river there is a small triple arched bridge, the Pont Vell, the bridge crosses the rocky valley and is claimed to have been built by the Romans as part of the imperial road building schemes on the island between 200 BC and AD 400, although the bridge’s earlist mention is in a document of 1720. The river is also the only one of its kind in the Balearic Islands, and is fed by several small tributaries, notably the Torrent de Labritja, which originates at the northern village of Sant Joan de Labritja.[4]		To the west of the town centre is the hill called ‘Puig de Missa’. The hill is 52[4] metres above sea level and its summit is dominated by the Església de Puig de Missa. The church is dedicated to Saint Eulalia.[4] The Path to the church spirals up around the hillside before arriving in a courtyard beside the church come Fortress. The Church is thought to have been built in 1568[4] although it is recorded that there was a chapel dedicated to the saint as far back as 1302.[4] Despite the huge natural advantage of constructing the church on this hilltop, the small community of Santa Eulària, employed the skills of military designer Giovanni Calvi[4] to fortify the church you see here today. Calvi[4] had a rounded bastion constructed in the style of the islands many watchtower although the church’s bastion is solid and has no internal guardrooms. The churches nave roof is higher than the Bastion which restricted the range and scope of any cannon placed on the bastion, although it is thought that at one time the roof may have been lower than the bastion. The Porch of the church, added in the eighteenth century,[4] is larger than most on the island and stands separate from the main church building. It has multiple pillars and rounded arches which has been compared to the Moorish style of architecture, and this does compare well with a mosque and its prayer halls still seen on main land Spain.[4] The porch is probably[4] the newest part of this church. On the west elevation of the church there is a small chapel which is topped with a plain stone dome complete with a lantern. This chapel is an addition to the original church, and is entered through a ponderous arch bored through the massively thick walls. The interior is square and rather small with the dome above supported on squat arches over each corner. The lantern above has stained glass lights. There is another similar chapel on the opposite wall which gives the nave a footprint in the shape of the crucifix. There is a gilded altarpiece which was brought and installed from Segovia in 1967.[4] the rest of the church is very sparse and has been heavily restored due to the extreme damage done to the church by iconoclast Republicans during the Spanish Civil War of 1936[4] who viewed the church as a hotbed of sedition.		THE DANCES		The roles of men and women are clearly differentiated in our dances. The woman, indifferent, holds her arms close to her body, walking with short and rapid steps, circling around a central point. The man, however, does not have previously determined steps. He tries to show his force and manliness by taking great leaps, in order to win the favour of the woman. The dances and the popular culture are part of rural, or country, society. The people who lived in and from the countryside did not have many opportunities for socialising or parties. The songs have a decidedly Oriental sound. The words have to be guessed, with syllables cut off so they fit into the monotonous and unvarying melody. Christian influence is perhaps the strongest. In 1235, Catalan men during the reign of Jaime I took the island from the Arabs. Its influence is seen in the jewels, the men’s dress and the language we speak. In spite of the Christianisation of the dances and the inclusion of music in the liturgy, the profane nature of the same can be easily recognised.		LA CURTA This is a short dance. The steps and the rhythm are suitable for the elderly. Generally, the elderly, the well owner with the heir to the house, or the in-laws of the couple marrying – depending on the occasion – started and finished the party with this dance, granting permission to the rest to continue.		LA LLARGA Young people display their energy with this much faster dance. In almost all the dances, the dancer selects his partner with a bang on the castanets. This gesture, a quite rude way to issue an invitation to a woman, is forgiven at the end of the dance when the man kneels before her. The woman reciprocates with a small curtsy.		SA FILERA A man dances with three women in a line. It seems like a wedding dance where the recently married bride is accompanied by two friends or ladies. The rhythm is the same as the Llarga.		SES NOU RODADES This may be the prettiest and most important dance in our repertoire. Parties culminate with this dance and it is a nuptial ceremony. The newly married couple dance in a series of circles, separating and then meeting again in the centre, where they link elbows. After the sixth turn, the wife flashes her rings (twenty-four in total) that her husband has presented her.		THE INSTRUMENTS The basic rhythm of our music is percussion and wind. It may seem surprising that such a Mediterranean island does not include string instruments in their music. The drum, the flute, the espasí (a metal sword-shaped piece) and the castanets always accompany our dances and fiestas.		THE DRUM A hollowed pine trunk. The outsides are adorned with carvings or paint, with red and green colours predominating here. The motifs are vegetal or geometric. The skin is made from rabbit.		THE FLUTE An oleander branch hollowed out with fire. With only three holes, it is also adorned with vegetable and geometric shapes. This instrument requires greater skill, even though composers do not have a conventional knowledge of musical theory or other disciplines and play accompanied by the drum.		THE ESPASÍ A piece of metal in the shape of a sword. The stridency of the metal backs up the music.		THE CASTANETS This may possibly be the strangest instrument, due to both its size and its sound. Created from juniper wood, they are carved with vegetable or geometric shapes using knives. While castanets are widely used throughout the Mediterranean, we use the largest ones available. The sound resembles a trotting horse.		THE XEREMIA Another wind instrument, which was used principally by shepherds. It is created with two young bamboo shoots, with a vibrating reed. You can see an instrument identical to the xeremia at the British Museum in London, which is the Egyptian maid. Besides accompanying our dances, some of these instruments can be heard at religious celebrations and other solemn occasions. Ses Caramelles is the song played on Christmas Eve. Sa Pujadeta and Sa Calera are songs that are already classics and enjoy great popularity amongst the Ibizans.		THE DRESS The originality and authenticity of some of the native dress styles offer some samples that are over three hundred years old. In the different villages of the island, similar to how the exact dance style varies, there are also small variations in dress. We can distinguish between three different types of dress, both for men and women, in accordance with their function and age.		THE BLACK GONELLA This is the oldest dress for women, probably dating from the 18th century. It is a tunic of knitted wool, consisting of an underskirt, a serge jerkin with embroidered satin sleeves, silver buttons and coloured ribbons. This is topped with an apron, a yellow silk shawl and a cambuix, a lace scarf tied under the neck. It is usually worn with a black, felt, wide-brimmed hat. Jewels on the dress are silver and red coral. Gold, which was traditionally used, became scarce during this time. The jewels are affixed to the body with coloured, embroidered ribbons.		THE WHITE GONELLA OR WHITE DRESS A luminous white colour, consisting of the same garments as the gonella (underskirts, jerkin, apron, shawl and scarf), but with some particularities. A hat is never worn. The bride layered on underskirts until their width no longer allowed her to pass through the door of her bedroom. The jewels are made from gold. This was generally the dowry that her family contributed to the wedding. The cross, la joia, hung with eighteen spans of golden braid (6 or 7 times over the chest) and two or three necklaces. The sleeves were adorned with gold buttons. The rings could be in different shapes - the family seal, the heart and key to the house, etc. These were gifts from her fiancee, with a total of twenty-four rings.		COLOURED GONELLA OR COLOURED DRESS Old women that still wear this dress on a daily basis can be seen in isolated villages. On the day of the town festival, they wear their best dresses adorned with jewellery and then go to the church, following a long tradition. They have essentially the same clothing items, but the apron is normally long, short if undergarments are worn. It can be accompanied with a wide-brimmed hat made from pita fibres (capell de floc), with a yellow scarf, but never together with the undergarments. There are also three types of dress for the men. Recognised as the oldest, it seems to have come from a military uniform, and we can place it next to the gonella. Black holds prominence over white. A large rosary with silver and ebony beads is worn at the neck. The following is possibly the most popular. Worn for summer festivals, it is made with luminous white cloth and a highly embroidered shirt. The sash has bright colours and the waistcoat has silver button work: 14 or 24 buttons, depending on the man’s wealth. Lastly, the most modern outfit that disappeared only quite recently, was worn by the elderly. All signs of ostentation have been suppressed here: there is no button work or adornments. It consists of a loose-fitting shirt closed only at the neck that goes over the inside shirt. Dark-coloured, and worn with a silk scarf, generally yellow. Topped by a black felt hat. All these dresses were worn with handmade pita-fibre espadrilles. The most common colours for men were red and white. Women put much more imagination into the colouring of their clothing. The jewels merit special mention. S'emprendada, a set of gold, silver and coral jewels, has an artistic and historical value much greater than their economic value. And we could not finish without mentioning the importance that dance, music and dress play within our culture and as an extremely relevant part of our entity.		There are two Hippy Markets which attract large numbers of tourists and locals: Punta Arabi, located in Es Canar runs all day every Wednesday from April through October. Las Dalias, near Sant Carles, runs all day every Saturday, throughout the year. Las Dalias also has a "Night Market" which runs Monday and Tuesday evenings from June through September.		The town was depicted, in the time before and up to the outbreak of the Spanish Civil War, in Elliot Paul's Life and Death of a Spanish Town (1937).[5]		The Ajuntament (Town Hall)		Port and town of Santa Eulària des Riu from NE.		Seafront and beach with the hill 'Puig d’ en Fita' in the background.		View from Es Canar, north of the town.		Puig de Missa, a former mosque, now a church on a hill above the town.		Marina of Santa Eulària des Riu.		Cemetery.		The SS Mallorca which sank on the 17th January 1913 after running aground on a reef around Illa Rodona		View of Santa Eulària (1943) by Rigoberto Soler		One of the statues dedicated Ibizan Hounds		Fountain with mill		Playa de Es Figueral		Media related to Santa Eulària des Riu at Wikimedia Commons		
Cliff-top dunes, also known as perched dunes, are dunes that occur on the tops of cliffs. They are uncommon in most parts of the world, because they only develop under unusual geomorphological conditions. Processes by which they may be formed include:		They are most often seen as coastal landforms, but can also occur along lakes and rivers, and in deserts. Places where they are relatively common include the west coat of Jutland, Denmark. They can also be found in certain places along the shores of the Great Lakes in Michigan, including the Grand Sable Dunes in Pictured Rocks National Lakeshore and in the Sleeping Bear Dunes National Lakeshore, most dramatically on South Manitou Island.				
Monte Carlo /ˈmɒnti ˈkɑːrloʊ/ (Italian pronunciation: [ˈmonte ˈkarlo]; French: Monte-Carlo, pronounced [mɔ̃te kaʁlo], or colloquially Monte-Carl, pronounced [mɔ̃te kaʁl]; Monégasque: Monte-Carlu) officially refers to an administrative area of the Principality of Monaco, specifically the ward of Monte Carlo/Spélugues, where the Monte Carlo Casino is located. Informally the name also refers to a larger district, the Monte Carlo Quarter (corresponding to the former municipality of Monte Carlo), which besides Monte Carlo/Spélugues also includes the wards of La Rousse/Saint Roman, Larvotto/Bas Moulins, and Saint Michel. The permanent population of the ward of Monte Carlo is about 3,500, while that of the quarter is about 15,000. Monaco has four traditional quarters. From west to east they are: Fontvieille (the newest), Monaco-Ville (the oldest), La Condamine, and Monte Carlo.		Monte Carlo (literally "Mount Charles") is situated on a prominent escarpment at the base of the Maritime Alps along the French Riviera. Near the western end of the quarter is the world-famous Place du Casino, the gambling center which has made Monte Carlo "an international byword for the extravagant display and reckless dispersal of wealth".[1] It is also the location of the Hôtel de Paris, the Café de Paris, and the Salle Garnier (the casino theatre which is the home of the Opéra de Monte-Carlo).		The eastern part of the quarter includes the community of Larvotto with Monaco's only public beach, as well as its new convention center (the Grimaldi Forum), and the Monte-Carlo Bay Hotel & Resort. At the quarter's eastern border, one crosses into the French town of Beausoleil (sometimes referred to as Monte-Carlo-Supérieur), and just 8 kilometres (5 mi) to its east is the western border of Italy.						By the 1850s Monaco's reigning family was almost bankrupt; this was a result of the loss of two towns, Menton and Roquebrune, which had provided most of the principality’s revenues with their lemon, orange and olive crops.[2] At the time, a number of small towns in Europe were growing prosperous from the establishment of casinos, notably in German towns such as Baden-Baden and Homburg.		In 1856 Charles III of Monaco granted a concession to Napoleon Langlois and Albert Aubert to establish a sea-bathing facility for the treatment of various diseases, and to build a German-style casino in Monaco.[2] The initial casino was opened in La Condamine in 1862, but was not a success; its present location in the area called "Les Spélugues" (The Caves) of Monte Carlo, came only after several relocations in the years that followed. The success of the casino grew slowly, largely due to the area's inaccessibility from much of Europe. The installation of the railway in 1868, however, brought with it an influx of people into Monte Carlo and saw it grow in wealth.[2]		Saint-Charles Church on Monte Carlo's Avenue Sainte-Charles was completed in 1883. It was restored in its centenary year.[3][4]		In 1911 when the Constitution divided the principality of Monaco in three municipalities, the municipality of Monte Carlo was created covering the existing neighborhoods of La Rousse/Saint Roman, Larvotto/Bas Moulins and Saint Michel. The municipalities were merged into one in 1917, after accusations that the government was acting according to the motto "divide and conquer" and they were accorded the status of wards (quartiers) thereafter. Today, Monaco is divided into 10 wards, with an eleventh ward planned (but currently postponed) to encompass land reclaimed from the sea (see the "Administrative Divisions" section of Monaco for additional details).		The quarter of Monte Carlo was served by tramways from 1900 to 1953, linking all parts of Monaco (see transportation in Monaco). In 2003 a new cruise ship pier was completed in the harbour at Monte Carlo.		Monte Carlo is host to most of the Circuit de Monaco, on which the Formula One Monaco Grand Prix takes place. It also hosts world championship boxing bouts, the European Poker Tour Grand Final and the World Backgammon Championship as well as the Monaco International Auto Show (Fr: Salon International de l'Automobile de Monaco[8]), fashion shows and other events. Although the Monte Carlo Masters tennis tournament is billed as taking place in the community, its actual location is in the adjacent French commune of Roquebrune-Cap-Martin. Monte Carlo has been visited by royalty as well as the general public and movie stars for decades. The Monte Carlo Rally is one of the longest running and most respected car rallies; from 1973 to 2008 and again from 2012, it marks the start of World Rally Championship season, having also served as the curtain-raiser for the Intercontinental Rally Challenge between 2009 and 2011. The rally, however, takes place outside the Monte Carlo quarter and is run mostly on French roads.		Monte Carlo is one of Europe's leading tourist resorts, although many of the key tourist destinations are located in other parts of Monaco, including such attractions as Monaco Cathedral, the Napoleon Museum, the Oceanographic Museum and aquarium, and the Prince's Palace, all of which are located in Monaco-Ville.		The Opéra de Monte-Carlo or Salle Garnier was built to designs of the architect Charles Garnier, who also designed the Paris opera house now known as the Palais Garnier. Although much smaller, the Salle Garnier is very similar in style with decorations in red and gold, and frescoes and sculptures all around the auditorium. It was inaugurated on 25 January 1879 with a performance by Sarah Bernhardt dressed as a nymph. The first opera performed there was Robert Planquette's Le Chevalier Gaston on 8 February 1879, and that was followed by three more in the first season.		With the influence of the first director, Jules Cohen (who was instrumental in bringing Adelina Patti) and the fortunate combination of Raoul Gunsbourg, the new director from 1883, and Princess Alice, the opera-loving American wife of Charles III's successor, Albert I, the company was thrust onto the world's opera community stage. Gunsbourg had remained for sixty years.		By the early years of the twentieth century, the Salle Garnier was to see such great performers as Nellie Melba and Enrico Caruso in La Bohème and Rigoletto (in 1902), and Feodor Chaliapin in the premiere of Jules Massenet's Don Quichotte (1910). This production formed part of a long association between the company and Massenet and his operas, two of which were presented there posthumously.		Other famous twentieth-century singers to appear at Monte Carlo included Titta Ruffo, Geraldine Farrar, Mary Garden, Tito Schipa, Beniamino Gigli, Claudia Muzio, Georges Thill, and Lily Pons.		Apart from Massenet, composers whose works had their first performances at Monte Carlo included: Saint-Saëns (Hélène, 1904); Mascagni (Amica, 1905); and Puccini (La rondine, 1917). Indeed, since its inauguration, the theatre has hosted 45 world premiere productions of operas. René Blum was retained to found the Ballet de l'Opéra. The "Golden Age" of the Salle Garnier is gone, as small companies with small houses are not able to mount productions that cost astronomical sums. Nonetheless, the present day company still presents a season containing five or six operas.		Campagna, Italy and Ceuta, Spain are Monte Carlo's twin cities.		The Hôtel de Paris, established in 1864 by Charles III of Monaco, is located on the west side of the Place du Casino in the heart of Monte Carlo. It belongs to the Société des bains de mer de Monaco (SBM), and is part of the elite Palace Grand Hotels in Monaco with the Hotel Hermitage, the Monte-Carlo Beach Hotel on Monte-Carlo Bay Hotel & Resort, the Metropole Hotel and Fairmont hotel.		The hotel has 106 rooms divided into four groups based on type of view, decoration and luxury.[9] The Exclusive City View offers 20 rooms, the Superior Courtyard has 29 large rooms, the Exclusive Sea View 59 and the Exclusive Casino has six.		Additionally there are 74 suites and junior suites which are grouped similarly, offering more luxury than the rooms. There are single and double suites as well as courtyard junior suites and Sea/Casino Junior suites.[9] There is also one Presidential suite.[10]		Monte Carlo has featured in numerous films and television series, most recently in the 2011 movie of the same name. Monte Carlo was the setting for the 1922 Erich von Stroheim silent film Foolish Wives although it was filmed in California.		The casino featured in the James Bond films Never Say Never Again (1983), and GoldenEye (1995). To Catch a Thief (1954) was an Alfred Hitchcock film with Monte Carlo and its famous casino as the setting and featured Cary Grant and Grace Kelly, the future Princess Grace of Monaco, as the stars. There is a scene in the movie where the-then Grace Kelly drives a car very quickly—and dangerously—along the steep winding roads of Monaco that surround the heights of Monte Carlo; an interesting coincidence to her actual fate in 1982. Monte Carlo was even a location for the late 1960s British London based series Randall and Hopkirk (Deceased) where in the eleventh episode of the series, "The Ghost who Saved the Bank at Monte Carlo", Mike Pratt, Kenneth Cope and Annette Andre went to Monte Carlo to accompany a highly talented elderly woman to gamble inside the casino and waylay a group of thugs (amongst them Brian Blessed). And Grand Prix (1966) was filmed here, which starred James Garner, Eva M. Saint, and Yves Montand. Herbie Goes to Monte Carlo (1977) starring Dean Jones & Don Knotts. The motor race Monaco World Prix 1 in Monte Carlo also featured in the 2010 film Iron Man 2. Other films such as I Spy, Cars 2 and Monte Carlo use the city as a setting. The video game series Gran Turismo often features Monte Carlo as a location, and the Indie game Monaco: What's Yours is Mine features Monte Carlo as a setting. There are two difficult heists in the endgame that take place in the Casino. The hotel in Monte Carlo, Monaco also made an appearance in the 2012 DreamWorks Animation SKG film Madagascar 3: Europe's Most Wanted.		In 2016 and again in 2017, The Bold and the Beautiful featured a number of episodes filmed on location in the city. Monte Carlo is the location for the annual Spencer Summit hosted by the Spencer family.		
Mudflats or mud flats, also known as tidal flats, are coastal wetlands that form when mud is deposited by tides or rivers. They are found in sheltered areas such as bays, bayous, lagoons, and estuaries. Mudflats may be viewed geologically as exposed layers of bay mud, resulting from deposition of estuarine silts, clays and marine animal detritus. Most of the sediment within a mudflat is within the intertidal zone, and thus the flat is submerged and exposed approximately twice daily.		In the past tidal flats were considered unhealthy, economically unimportant areas and were often dredged and developed into agricultural land.[1] Several especially shallow mudflat areas, such as the Wadden Sea, are now popular among those practising the sport of mudflat hiking.		On the Baltic Sea coast of Germany in places, mudflats are exposed not by tidal action, but by wind-action driving water away from the shallows into the sea. These wind-affected mudflats are called windwatts in German.						Tidal flats, along with intertidal salt marshes and mangrove forests, are important ecosystems.[2] They usually support a large population of wildlife, and are a key habitat that allows tens of millions of migratory shorebirds to migrate from breeding sites in the northern hemisphere to non-breeding areas in the southern hemisphere. They are often of vital importance to migratory birds, as well as certain species of crabs,[3] mollusks and fish.[4] In the United Kingdom mudflats have been classified as a Biodiversity Action Plan priority habitat.		The maintenance of mudflats is important in preventing coastal erosion. However, mudflats worldwide are under threat from predicted sea level rises, land claims for development, dredging due to shipping purposes, and chemical pollution. In some parts of the world, such as East and South-East Asia, mudflats have been reclaimed for aquaculture, agriculture, and industrial development. For example, around the Yellow Sea region of East Asia, more than 65% of mudflats present in the early 1950s had been destroyed by the late 2000s.[5][6]		Mudflat sediment deposits are focused into the intertidal zone which is composed of a barren zone, marsh and salt pan. Within these areas are various ratios of sand and mud that make up the sedimentary layers.[7] The associated growth of coastal sediment deposits can be attributed to rates of subsidence along with rates of deposition (example: silt transported via river) and changes in sea level.[7]		Barren zones extend from the lowest portion of the intertidal zone to the marsh areas. Beginning in close proximity to the tidal bars, sand dominated layers are prominent and become increasingly muddy throughout the tidal channels. Common bedding types include laminated sand, ripple bedding, and bay mud. Bioturbation also has a strong presence in barren zones.		Marshes contain an abundance of herbaceous plants while the sediment layers consist of thin sand and mud layers. Mudcracks are a common as well as wavy bedding planes.[7] Marshes are also the origins of coal/peat layers because of the abundant decaying plant life.[7]		Salt pans can be distinguished in that they contain thinly laminated layers of clayey silt. The main source of the silt comes from rivers. Dried up mud along with wind erosion forms silt dunes. When flooding, rain or tides come in, the dried sediment is then re-distributed.[7]		
Honolulu (/ˌhɒnəˈluːluː/ or /ˌhoʊnoʊˈluːluː/;[6][7] Hawaiian pronunciation: [honoˈlulu]) is the capital and largest city of the U.S. state of Hawaii. It is an unincorporated part of and the county seat of the City and County of Honolulu on the island of Oahu.[a] The city is the main gateway to Hawaii and a major portal into the United States. The city is also a major hub for international business, military defense, as well as famously being host to a diverse variety of east-west and Pacific culture, cuisine, and traditions.		Honolulu is the most remote city of its size in the world[9] and is both the westernmost and the southernmost major U.S. city. For statistical purposes, the U.S. Census Bureau recognizes the approximate area commonly referred to as "City of Honolulu" (not to be confused with the "City and County") as a census county division (CCD).[10] Honolulu is a major financial center of the islands and of the Pacific Ocean. The population of the city of Honolulu was 337,256 as of the 2010 census,[4] while the Honolulu CCD was 390,738[11] and the population of the consolidated city and county was 953,207.		Honolulu means "sheltered harbor"[12] or "calm port".[13] The old name is said to be Kou, a district roughly encompassing the area from Nuuanu Avenue to Alakea Street and from Hotel Street to Queen Street which is the heart of the present downtown district.[14] The city has been the capital of the Hawaiian Islands since 1845 and gained historical recognition following the attack on Pearl Harbor by Japan near the city on December 7, 1941.		As of 2015[update], Honolulu was ranked high on world livability rankings, and was also ranked as the 2nd safest city in the U.S.[15][16] It is also the most populated Oceanian city outside Australasia and ranks second to Auckland as the most populous city in Polynesia.[17][18]						Evidence of the first settlement of Honolulu by the original Polynesian migrants to the archipelago comes from oral histories and artifacts. These indicate that there was a settlement where Honolulu now stands in the 11th century.[19] However, after Kamehameha I conquered Oʻahu in the Battle of Nuʻuanu at Nuʻuanu Pali, he moved his royal court from the Island of Hawaiʻi to Waikīkī in 1804. His court relocated in 1809 to what is now downtown Honolulu. The capital was moved back to Kailua-Kona in 1812.		In 1794, Captain William Brown of Great Britain was the first foreigner to sail into what is now Honolulu Harbor.[20] More foreign ships followed, making the port of Honolulu a focal point for merchant ships traveling between North America and Asia.		In 1845, Kamehameha III moved the permanent capital of the Hawaiian Kingdom from Lahaina on Maui to Honolulu. He and the kings that followed him transformed Honolulu into a modern capital,[21] erecting buildings such as St. Andrew's Cathedral, ʻIolani Palace, and Aliʻiōlani Hale. At the same time, Honolulu became the center of commerce in the islands, with descendants of American missionaries establishing major businesses in downtown Honolulu.[22]		Despite the turbulent history of the late 19th century and early 20th century, such as the overthrow of the Hawaiian monarchy in 1893, Hawaiʻi's subsequent annexation by the United States in 1898, followed by a large fire in 1900, and the Japanese attack on Pearl Harbor in 1941, Honolulu remained the capital, largest city, and main airport and seaport of the Hawaiian Islands.[23]		An economic and tourism boom following statehood brought rapid economic growth to Honolulu and Hawaiʻi. Modern air travel brings, as of 2007[update], 7.6 million visitors annually to the islands, with 62.3% entering at Honolulu International Airport.[24] Today, Honolulu is a modern city with numerous high-rise buildings, and Waikīkī is the center of the tourism industry in Hawaiʻi, with thousands of hotel rooms. The UK consulting firm Mercer, in a 2009 assessment "conducted to help governments and major companies place employees on international assignments", ranked Honolulu 29th worldwide in quality of living; the survey factored in political stability, personal freedom, sanitation, crime, housing, the natural environment, recreation, banking facilities, availability of consumer goods, education, and public services including transportation.[25]		According to the United States Census Bureau, the CDP has a total area of 68.4 square miles (177.2 km2). 60.5 square miles (156.7 km2) of it (88.44%) is land, and 7.9 square miles (20.5 km2) of it (11.56%) is water.[26]		Honolulu is the most remote major city in the world.[9] The closest location on the mainland to Honolulu is the Point Arena Lighthouse in California, at 2,045 nautical miles (3,787 km).[27] (Nautical vessels require some additional distance to circumnavigate Makapuʻu Point.) However, islands off the Mexican coast, and part of the Aleutian Islands of Alaska are slightly closer to Honolulu than the mainland.		Honolulu experiences a tropical hot semi-arid climate (Köppen classification BSh), with a mostly dry summer season, due to a rain shadow effect.[30] Temperatures vary little throughout the months, with average high temperatures of 80–90 °F (27–32 °C) and average lows of 65–75 °F (18–24 °C) throughout the year. Temperatures reach or exceed 90 °F (32 °C) on an average 38 days annually,[31] with lows in the upper 50s °F (14–15 °C) occurring once or twice a year. The highest recorded temperature was 95 °F (35 °C) during a heat wave in September 1998. The highest recorded temperature in the state was also recorded later that day in Ni'ihau. The lowest recorded temperature was 52 °F (11 °C) on February 16, 1902, and January 20, 1969. With high temperatures and humidity there is a vast tropical influence on the climate, although rainfall falls short of that classification.		Annual average rainfall is 17.05 in (433 mm), which mainly occurs during the winter months of October through early April, with very little rainfall during the summer; similar to California's mediterranean climates. However, both seasons experience a similar number of rainy days. Light showers occur in summer while heavier rain falls during winter. Honolulu has an average of 278 sunny days and 90 rainy days per year.		Although the city is situated in the tropics, hurricanes are quite rare. The last recorded hurricane that hit the area was Category 4 Hurricane Iniki in 1992. Tornadoes are also uncommon and usually strike once every 15 years. Waterspouts off the coast are also uncommon, hitting about once every five years.[32]		Honolulu falls under the USDA 12a Plant Hardiness zone.[33]		The average temperature of the sea ranges from 24.3 °C (75.7 °F) in March to 26.9 °C (80.4 °F) in September.[34]		The population of Honolulu was 390,738 according to the 2010 U.S. Census. Of those, 192,781 (49.3%) were male and 197,957 (50.7%) were female. The median age for males was 40.0 and 43.0 for females; the overall median age was 41.3. Approximately 84.7% of the total population was 16 years and over; 82.6% were 18 years and over, 78.8% were 21 years and over, 21.4% were 62 years and over, and 17.8% were 65 years and over.[11]		In terms of race and ethnicity, 54.8% were Asian, 17.9% were White, 1.5% were Black or African American, 0.2% were American Indian or Alaska Native, 8.4% were Native Hawaiian and Other Pacific Islander, 0.8% were from "some other race", and 16.3% were from two or more races. Hispanics and Latinos of any race made up 5.4% of the population.[11] In 1970, the Census Bureau reported Honolulu's population as 33.9% white and 53.7% Asian and Pacific Islander.[42]		Asian Americans represent the majority of Honolulu's population. The Asian ethnic groups are Japanese (19.9%), Filipinos (13.2%), Chinese (10.4%), Koreans (4.3%), Vietnamese (2.0%), Asian Indians (0.3%), Laotians (0.3%), Thais (0.2%), Cambodians (0.1%), and Indonesians (0.1%). People solely of Native Hawaiian ancestry made up 3.2% of the population. Samoan Americans made up 1.5% of the population, Marshallese people make up 0.5% of the city's population, and Tongan people comprise 0.3% of its population. People of Guamanian or Chamorro descent made up 0.2% of the population and numbered 841 residents.[11]		Honolulu's urban area was the fourth densest[9] in the United States according to the 2010 U.S. Census.		The largest city and airport in the Hawaiian Islands, Honolulu acts as a natural gateway to the islands' large tourism industry, which brings millions of visitors and contributes $10 billion annually to the local economy. Honolulu's location in the Pacific also makes it a large business and trading hub, particularly between the East and the West. Other important aspects of the city's economy include military defense, research and development, and manufacturing.[43]		Among the companies based in Honolulu are:		Hawaiian Airlines,[44] Island Air,[45] and Aloha Air Cargo are headquartered in the city.[46][47] Prior to its dissolution, Aloha Airlines was headquartered in the city.[48] At one time Mid-Pacific Airlines had its headquarters on the property of Honolulu International Airport.[49]		In 2009, Honolulu had a 4.5% increase in the average price of rent, maintaining it in the second most expensive rental market ranking among 210 U.S. metropolitan areas.[50]		Since no national bank chains have any branches in Hawaii, many visitors and new residents use different banks. First Hawaiian Bank is the largest and oldest bank in Hawaii and their headquarters are at the First Hawaiian Center, the tallest building in the State of Hawaii.		The Bishop Museum is the largest of Honolulu's museums. It is endowed with the state's largest collection of natural history specimens and the world's largest collection of Hawaiiana and Pacific culture artifacts.[51] The Honolulu Zoo is the main zoological institution in Hawaii while the Waikiki Aquarium is a working marine biology laboratory. The Waikiki Aquarium is partnered with the University of Hawaii and other universities worldwide. Established for appreciation and botany, Honolulu is home to several gardens: Foster Botanical Garden, Liliʻuokalani Botanical Garden, Walker Estate, among others.		Established in 1900, the Honolulu Symphony is the second oldest US symphony orchestra west of the Rocky Mountains. Other classical music ensembles include the Hawaii Opera Theatre. Honolulu is also a center for Hawaiian music. The main music venues include the Hawaii Theatre, the Neal Blaisdell Center Concert Hall and Arena, and the Waikiki Shell.		Honolulu also includes several venues for live theater, including the Diamond Head Theatre.		Various institutions for the visual arts are located in Honolulu.		The Honolulu Museum of Art is endowed with the largest collection of Asian and Western art in Hawaii. It also has the largest collection of Islamic art, housed at the Shangri La estate. Since the merger of the Honolulu Academy of Arts and The Contemporary Museum, Honolulu (now called the Honolulu Museum of Art Spalding House) in 2011, the museum is also the only contemporary art museum in the state. The contemporary collections are housed at main campus (Spalding House) in Makiki and a multi-level gallery in downtown Honolulu at the First Hawaiian Center. The museum hosts a film and video program dedicated to arthouse and world cinema in the museum's Doris Duke Theatre, named for the museum's historic patroness Doris Duke.[citation needed]		The Hawaii State Art Museum (also downtown) boasts pieces by local artists as well as traditional Hawaiian art. The museum is administered by the Hawaii State Foundation on Culture and the Arts.		Honolulu also annually holds the Hawaii International Film Festival (HIFF). It showcases some of the best films from producers all across the Pacific Rim and is the largest "East meets West" style film festival of its sort in the United States.		Honolulu's climate lends itself to year-round activities. In 2004, Men's Fitness magazine named Honolulu the fittest city in the United States.[52] Honolulu has three large road races:		Ironman Hawaii was first held in Honolulu. It was the first ever Ironman triathlon event and is also the world championship.		Fans of spectator sports in Honolulu generally support the football, volleyball, basketball, rugby union, rugby league and baseball programs of the University of Hawaii at Manoa.[53] High school sporting events, especially football, are especially popular.		Honolulu has no professional sports teams. It was the home of the Hawaii Islanders (Pacific Coast League, 1961–87), The Hawaiians (World Football League, 1974–75), Team Hawaii (North American Soccer League, 1977), and the Hawaiian Islanders (af2, 2002–04).		The NCAA football Hawaii Bowl is played in Honolulu. Honolulu has also hosted the NFL's annual Pro Bowl each February from 1980 to 2009. After the 2010 and 2015 games were played in Miami Gardens and Glendale, respectively, the Pro Bowl was once again in Honolulu from 2011 to 2014 with 2016 the most recent.[54][55] From 1993 to 2008, Honolulu hosted Hawaii Winter Baseball, featuring minor league players from Major League Baseball, Nippon Professional Baseball, Korea Baseball Organization, and independent leagues.		Venues for spectator sports in Honolulu include:		Aloha Stadium, a venue for American football and soccer, is located in Halawa near Pearl Harbor, just outside Honolulu.[56]		Kirk Caldwell was elected mayor of Honolulu County on November 6, 2012, and began serving as the county's 14th mayor on January 2, 2013. The municipal offices of the City and County of Honolulu, including Honolulu Hale, the seat of the city and county, are located in the Capitol District, as are the Hawaii state government buildings.[57]		The Capitol District is within the Honolulu census county division (CCD), the urban area commonly regarded as the "City" of Honolulu. The Honolulu CCD is located on the southeast coast of Oahu between Makapuu and Halawa. The division boundary follows the Koolau crestline, so Makapuʻu Beach is in the Koolaupoko District. On the west, the division boundary follows Halawa Stream, then crosses Red Hill and runs just west of Aliamanu Crater, so that Aloha Stadium, Pearl Harbor (with the USS Arizona Memorial), and Hickam Air Force Base are actually all located in the island's Ewa CCD.[58]		The Hawaii Department of Public Safety operates the Oahu Community Correctional Center, the jail for the island of Oahu, in Honolulu CCD.[59]		The United States Postal Service operates post offices in Honolulu. The main Honolulu Post Office is located by the international airport at 3600 Aolele Street.[60] Federal Detention Center, Honolulu, operated by the Federal Bureau of Prisons, is in the CDP.[61]		Several countries have consular facilities in Honolulu, due to its strategically important position in the mid-Pacific. They include consulates of Japan,[62] South Korea,[63] Philippines,[64] Federated States of Micronesia,[65] Australia,[66] and the Marshall Islands.[67]		Colleges and universities in Honolulu include Honolulu Community College, Kapiolani Community College, the University of Hawaii at Manoa, Chaminade University, and Hawaii Pacific University.[47] UH Manoa houses the main offices of the University of Hawaii System.[68]		Hawaii Department of Education operates public schools in Honolulu. Public high schools within the CDP area include Wallace Rider Farrington, Kaiser, Kaimuki, Kalani, Moanalua, William McKinley, and Theodore Roosevelt.[47]		Private schools include Academy of the Pacific, Damien Memorial School, Hawaii Baptist Academy, Iolani School, Lutheran High School of Hawaii, Kamehameha Schools, Maryknoll School, Mid-Pacific Institute, La Pietra, Punahou School, Sacred Hearts Academy, St. Andrew's Priory School, Saint Francis School, Saint Louis School, the Education Laboratory School, Saint Patrick School, Trinity Christian School, and Varsity International School.		Hawaii State Public Library System operates public libraries. The Hawaii State Library in the CDP serves as the main library of the system,[69] while the Library for the Blind and Physically Handicapped, also in the CDP area, serves handicapped and blind people.[70]		Branches in the CDP area include Aiea, Aina Haina, Ewa Beach, Hawaii Kai, Kahuku, Kailua, Kaimuki, Kalihi-Palama, Kaneohe, Kapolei, Liliha, Manoa, McCully-Moiliili, Mililani, Moanalua, Wahiawa, Waialua, Waianae, Waikiki-Kapahulu, Waimanalo, and Waipahu.[71]		The Hawaii Japanese School – Rainbow Gakuen (ハワイレインボー学園 Hawai Rainbō Gakuen), a supplementary weekend Japanese school, holds its classes in Kaimuki Middle School in Honolulu and has its offices in another building in Honolulu.[72] The school serves overseas Japanese nationals.[73] In addition Honolulu has other weekend programs for the Japanese, Chinese, and Spanish languages.[74]		Honolulu is served by one daily newspaper (the Honolulu Star-Advertiser), Honolulu Magazine, several radio stations and television stations, among other media. Local news agency and CNN-affiliate Hawaii News Now broadcasts and is headquartered out of Honolulu.		Honolulu and the island of Oahu has also been the location for many film and television projects, including Hawaii Five-0 and Lost.		Located at the western end of the CDP, Daniel K. Inouye International Airport (HNL) is the principal aviation gateway to the state of Hawaii. Kalaeloa Airport is primarily a commuter facility used by unscheduled air taxis, general aviation and transient and locally based military aircraft.		Honolulu has been ranked as having the nation's worst traffic congestion, beating former record holder Los Angeles. Drivers waste on average over 58 hours per year on congested roadways.[75] The following freeways, part of the Interstate Highway System serve Honolulu:		Other major highways that link Honolulu CCD with other parts of the Island of Oahu are:		Like most major American cities, the Honolulu metropolitan area experiences heavy traffic congestion during rush hours, especially to and from the western suburbs of Kapolei, 'Ewa Beach, Aiea, Pearl City, Waipahu, and Mililani.		There is a Hawaii Electric Vehicle Demonstration Project (HEVDP).[76]		In November 2010, voters approved a charter amendment to create a public transit authority to oversee the planning, construction, operation and future extensions to Honolulu's future rail system. The Honolulu Authority for Rapid Transportation (HART) currently includes a 10-member board of directors; three members appointed by the mayor, three members selected by the Honolulu City Council, and the city and state transportation directors.[77] The opening of the Honolulu Rail Transit is delayed until approximately 2018, as HART canceled the initial bids for the first nine stations and intends to rebid the work as three packages of three stations each, and allow more time for construction in the hope that increased competition on smaller contracts will drive down costs;[78] initial bids ranged from $294.5 million to $320.8 million, far surpassing HART's budget of $184 million.[79]		Established by former Mayor Frank F. Fasi as the replacement for the Honolulu Rapid Transit Company (HRT), Honolulu's TheBus system was honored in 1994–1995 and 2000–2001 by the American Public Transportation Association as "America's Best Transit System". TheBus operates 107 routes serving Honolulu and most major cities and towns on Oahu. TheBus comprises a fleet of 531 buses, and is run by the non-profit corporation Oahu Transit Services in conjunction with the city Department of Transportation Services. Honolulu is ranked 4th for highest per-capita use of mass transit in the United States.[80]		Currently, there is no urban rail transit system in Honolulu, although electric street railways were operated in Honolulu by the now-defunct Honolulu Rapid Transit Company prior to World War II. Predecessors to the Honolulu Rapid Transit Company were the Honolulu Rapid Transit and Land Company (began 1903) and Hawaiian Tramways (began 1888).[81]		The City and County of Honolulu is currently constructing a 20-mile (32 km) rail transit line that will connect Honolulu with cities and suburban areas near Pearl Harbor and in the Leeward and West Oahu regions. The Honolulu High-Capacity Transit Corridor Project is aimed at alleviating traffic congestion for West Oahu commuters while being integral in the westward expansion of the metropolitan area. The project, however, has been criticized by opponents of rail for its cost, delays, and potential environmental impacts, but the line is expected to have large ridership.		Honolulu currently has 29 sister cities:[82]		Local		International		Nation:		States:		Territories:		
Deposition is the geological process in which sediments, soil and rocks are added to a landform or land mass. Wind, ice, water, and gravity transport previously weathered surface material, which, at the loss of enough kinetic energy in the fluid, is deposited, building up layers of sediment.		Deposition occurs when the forces responsible for sediment transportation are no longer sufficient to overcome the forces of gravity and friction, creating a resistance to motion, this is known as the null-point hypothesis. Deposition can also refer to the buildup of sediment from organically derived matter or chemical processes. For example, chalk is made up partly of the microscopic calcium carbonate skeletons of marine plankton, the deposition of which has induced chemical processes (diagenesis) to deposit further calcium carbonate. Similarly, the formation of coal begins with deposition of organic material, mainly from plants, in anaerobic conditions.						The null-point hypothesis explains how sediment is deposited throughout a shore profile according to its grain size. This is due to the influence of hydraulic energy, resulting in a seaward-fining of sediment particle size, or where fluid forcing equals gravity for each grain size.[2] The concept can also be explained as "sediment of a particular size may move across the profile to a position where it is in equilibrium with the wave and flows acting on that sediment grain".[3] This sorting mechanism combines the influence of the down-slope gravitational force of the profile and forces due to flow asymmetry, the position where there is zero net transport is known as the null point and was first proposed by Cornaglia in 1889.[3] Figure 1 illustrates this relationship between sediment grain size and the depth of the marine environment.		The first principle underlying the null point theory is due to the gravitational force; finer sediments remain in the water column for longer durations allowing transportation outside the surf zone to deposit under calmer conditions. The gravitational effect, or settling velocity determines the location of deposition for finer sediments, whereas a grain's internal angle of friction determines the deposition of larger grains on a shore profile.[3] The secondary principle to the creation of seaward sediment fining is known as the hypothesis of asymmetrical thresholds under waves; this describes the interaction between the oscillatory flow of waves and tides flowing over the wave ripple bedforms in an asymmetric pattern.[4] "The relatively strong onshore stroke of the wave forms an eddy or vortex on the lee side of the ripple, provided the onshore flow persists, this eddy remains trapped in the lee of the ripple. When the flow reverses, the eddy is thrown upwards off the bottom and a small cloud of suspended sediment generated by the eddy is ejected into the water column above the ripple, the sediment cloud is then moved seaward by the offshore stroke of the wave." [4] Where there is symmetry in ripple shape the vortex is neutralised, the eddy and its associated sediment cloud develops on both sides of the ripple.[4] This creates a cloudy water column which travels under tidal influence as the wave orbital motion is in equilibrium.		The Null-point hypothesis has been quantitatively proven in Akaroa Harbour, New Zealand, The Wash, U.K., Bohai Bay and West Huang Sera, Mainland China, and in numerous other studies; Ippen and Eagleson (1955), Eagleson and Dean (1959, 1961) and Miller and Zeigler (1958, 1964).		Large grain sediments transported by either bed load or suspended load will come to rest when there is insufficient bed shear stress and fluid turbulence to keep the sediment moving,[4] with the suspended load this can be some distance as the particles need to fall through the water column. This is determined by the grains downward acting weight force being matched by a combined buoyancy and fluid drag force [4] and can be expressed by:		Downward acting weight force = Upward-acting buoyancy force + Upward-acting fluid drag force [4]		where:		In order to calculate the drag coefficient, the grain's Reynolds number needs to be discovered, which is based on the type of fluid through which the sediment particle is flowing; laminar flow, turbulent flow or a hybrid of both. When the fluid becomes more viscous due to smaller grain sizes or larger settling velocities, prediction is less straight forward and it is applicable to incorporate Stokes Law (also known as the frictional force, or drag force) of settling.[4]		Cohesion of sediment occurs with the small grain sizes associated with silts and clays, or particles smaller than 4ϕ on the phi scale.[4] If these fine particles remain dispersed in the water column, Stokes law applies to the settling velocity of the individual grains,[4] although due to sea water being a strong electrolyte bonding agent, flocculation occurs where individual particles create an electrical bond adhering each other together to form flocs.[4] "The face of a clay platelet has a slight negative charge where the edge has a slight positive charge, when two platelets come into close proximity with each other the face of one particle and the edge of the other are electrostatically attracted."[4] Flocs then have a higher combined mass which leads to quicker deposition through a higher fall velocity, and deposition in a more shoreward direction than they would have as the individual fine grains of clay or silt.		Akaroa Harbour is located on Banks Peninsula, Canterbury, New Zealand, 43°48′S 172°56′E﻿ / ﻿43.800°S 172.933°E﻿ / -43.800; 172.933. The formation of this harbour has occurred due to active erosional processes on an extinct shield volcano, whereby the sea has flooded the caldera creating an inlet 16 km in length, with an average width of 2 km and a depth of -13 m relative to mean sea level at the 9 km point down the transect of the central axis.[5] The predominant storm wave energy has unlimited fetch for the outer harbour from a southerly direction, with a calmer environment within the inner harbour, though localised harbour breezes create surface currents and chop influencing the marine sedimentation processes.[6] Deposits of loess from subsequent glacial periods have in filled volcanic fissures over millennia,[7] resulting in volcanic basalt and loess as the main sediment types available for deposition in Akaroa Harbour		Hart et al. (2009)[5] discovered through bathymetric survey, sieve and pipette analysis of subtidal sediments, that sediment textures were related to three main factors: depth; distance from shoreline; and distance along the central axis of the harbour. Resulting in the fining of sediment textures with increasing depth and towards the central axis of the harbour, or if classified into grain class sizes, “the plotted transect for the central axis goes from silty sands in the intertidal zone, to sandy silts in the inner nearshore, to silts in the outer reaches of the bays to mud at depths of 6 m or more”.[5] See figure 2 for detail.		Other studies have shown this process of the winnowing of sediment grain size from the effect of hydrodynamic forcing; Wang, Collins and Zhu (1988)[8] qualitatively correlated increasing intensity of fluid forcing with increasing grain size. "This correlation was demonstrated at the low energy clayey tidal flats of Bohai Bay (China), the moderate environment of the Jiangsu coast (China) where the bottom material is silty, and the sandy flats of the high energy coast of The Wash (U.K.)." This research shows conclusive evidence for the null point theory existing on tidal flats with differing hydrodynamic energy levels and also on flats that are both erosional and accretional.		Kirby R. (2002)[9] takes this concept further explaining that the fines are suspended and reworked aerially offshore leaving behind lag deposits of mainly bivalve and gastropod shells separated out from the finer substrate beneath, waves and currents then heap these deposits to form chenier ridges throughout the tidal zone which tend to be forced up the foreshore profile but also along the foreshore. Cheniers can be found at any level on the foreshore and predominantly characterise an erosion-dominated regime.[9]		The null point theory has been controversial in its acceptance into mainstream coastal science as the theory operates in dynamic equilibrium or unstable equilibrium, and many field and laboratory observations have failed to replicate the state of a null point at each grain size throughout the profile.[3] The interaction of variables and processes over time within the environmental context causes issues; "the large number of variables, the complexity of the processes, and the difficulty in observation, all place serious obstacles in the way of systematisation, therefore in certain narrow fields the basic physical theory may be sound and reliable but the gaps are large"[10]		Geomorphologists, engineers, governments and planners should be aware of the processes and outcomes involved with the null point hypothesis when performing tasks such as beach nourishment, issuing building consents or building coastal defence structures. This is because sediment grain size analysis throughout a profile allows inference into the erosion or accretion rates possible if shore dynamics are modified. Planners and managers should also be aware that the coastal environment is dynamic and contextual science should be evaluated before implementation of any shore profile modification. Thus theoretical studies, laboratory experiments, numerical and hydraulic modelling seek to answer questions pertaining to littoral drift and sediment deposition, the results should not be viewed in isolation and a substantial body of purely qualitative observational data should supplement any planning or management decision.[2]		
George IV (George Augustus Frederick; 12 August 1762 – 26 June 1830) was King of the United Kingdom of Great Britain and Ireland and of Hanover following the death of his father, George III, on 29 January 1820, until his own death ten years later. From 1811 until his accession, he served as Prince Regent during his father's final mental illness.		George IV led an extravagant lifestyle that contributed to the fashions of the Regency era. He was a patron of new forms of leisure, style and taste. He commissioned John Nash to build the Royal Pavilion in Brighton and remodel Buckingham Palace, and Sir Jeffry Wyattville to rebuild Windsor Castle.		His charm and culture earned him the title "the first gentleman of England", but his poor relationship with both his father and his wife, Caroline of Brunswick, and his dissolute way of life, earned him the contempt of the people and dimmed the prestige of the monarchy. He even forbade Caroline to attend his coronation and asked the government to introduce the unpopular Pains and Penalties Bill in a desperate, unsuccessful attempt to divorce her.		For most of George's regency and reign, Lord Liverpool controlled the government as Prime Minister, with little help from George. His ministers found his behaviour selfish, unreliable and irresponsible. At all times he was much under the influence of favourites.[1] Taxpayers were angry at his wasteful spending at a time when Britons were fighting in the Napoleonic Wars. He did not provide national leadership in time of crisis, nor act as a role model for his people. Liverpool's government presided over Britain's ultimate victory, negotiated the peace settlement, and attempted to deal with the social and economic malaise that followed. After Liverpool's retirement, George was forced to accept Catholic emancipation despite opposing it. His only legitimate child, Princess Charlotte, died before him in 1817 and so he was succeeded by his younger brother, William.						George was born at St James's Palace, London, on 12 August 1762, the first child of King George III of the United Kingdom and Queen Charlotte. As the eldest son of a British sovereign, he automatically became Duke of Cornwall and Duke of Rothesay at birth; he was created Prince of Wales and Earl of Chester a few days later.[2] On 18 September of the same year, he was baptised by Thomas Secker, Archbishop of Canterbury.[3] His godparents were the Duke of Mecklenburg-Strelitz (his maternal uncle, for whom the Duke of Devonshire, Lord Chamberlain, stood proxy), the Duke of Cumberland (his paternal great-uncle) and the Dowager Princess of Wales (his paternal grandmother).[4] George was a talented student, and quickly learned to speak French, German and Italian, in addition to his native English.[5]		At the age of 18 he was given a separate establishment, and in dramatic contrast with his prosaic, scandal-free father, threw himself with zest into a life of dissipation and wild extravagance involving heavy drinking and numerous mistresses and escapades. He was a witty conversationalist, drunk or sober, and showed good, but grossly expensive, taste in decorating his palace. The Prince of Wales turned 21 in 1783, and obtained a grant of £60,000 (equivalent to £6,514,000 today[6]) from Parliament and an annual income of £50,000 (equivalent to £5,429,000 today[6]) from his father. It was far too little for his needs – the stables alone cost £31,000 a year. He then established his residence in Carlton House, where he lived a profligate life.[7] Animosity developed between the prince and his father, who desired more frugal behaviour on the part of the heir apparent. The King, a political conservative, was also alienated by the prince's adherence to Charles James Fox and other radically inclined politicians.[8]		Soon after he reached the age of 21, the prince became infatuated with Maria Fitzherbert. She was a commoner, six years his elder, twice widowed, and a Roman Catholic.[9] Despite her complete unsuitability, the prince was determined to marry her. This was in spite of the Act of Settlement 1701, which barred the spouse of a Catholic from succeeding to the throne, and the Royal Marriages Act 1772, which prohibited his marriage without the King's consent, which would never have been granted.		Nevertheless, the couple went through a marriage ceremony on 15 December 1785 at her house in Park Street, Mayfair. Legally the union was void, as the King's consent was not granted (and never even requested).[10] However, Fitzherbert believed that she was the prince's canonical and true wife, holding the law of the Church to be superior to the law of the State. For political reasons, the union remained secret and Fitzherbert promised not to reveal it.[11]		The prince was plunged into debt by his exorbitant lifestyle. His father refused to assist him, forcing him to quit Carlton House and live at Fitzherbert's residence. In 1787, the prince's political allies proposed to relieve his debts with a parliamentary grant. The prince's relationship with Fitzherbert was suspected, and revelation of the illegal marriage would have scandalised the nation and doomed any parliamentary proposal to aid him. Acting on the prince's authority, the Whig leader Charles James Fox declared that the story was a calumny.[12] Fitzherbert was not pleased with the public denial of the marriage in such vehement terms and contemplated severing her ties to the prince. He appeased her by asking another Whig, Richard Brinsley Sheridan, to restate Fox's forceful declaration in more careful words. Parliament, meanwhile, granted the prince £161,000 (equivalent to £18,450,000 today[6]) to pay his debts and £60,000 (equivalent to £6,876,000 today[6]) for improvements to Carlton House.[5][13][14]		In the summer of 1788 the King's mental health deteriorated, possibly as the result of the hereditary disease porphyria.[15][16] He was nonetheless able to discharge some of his duties and to declare Parliament prorogued from 25 September to 20 November. During the prorogation he became deranged, posing a threat to his own life, and when Parliament reconvened in November the King could not deliver the customary speech from the throne during the State Opening of Parliament. Parliament found itself in an untenable position: according to long-established law it could not proceed to any business until the delivery of the King's Speech at a State Opening.[12][17]		Although arguably barred from doing so, Parliament began debating a regency. In the House of Commons, Charles James Fox declared his opinion that the Prince of Wales was automatically entitled to exercise sovereignty during the King's incapacity. A contrasting opinion was held by the prime minister, William Pitt the Younger, who argued that, in the absence of a statute to the contrary, the right to choose a regent belonged to Parliament alone.[18] He even stated that, without parliamentary authority "the Prince of Wales had no more right ... to assume the government, than any other individual subject of the country."[19] Though disagreeing on the principle underlying a regency, Pitt agreed with Fox that the Prince of Wales would be the most convenient choice for a regent.[12][17]		The Prince of Wales—though offended by Pitt's boldness—did not lend his full support to Fox's approach. The Prince of Wales's brother, Prince Frederick, Duke of York, declared that George would not attempt to exercise any power without previously obtaining the consent of Parliament.[20] Following the passage of preliminary resolutions Pitt outlined a formal plan for the regency, suggesting that the powers of the Prince of Wales be greatly limited. Among other things, the Prince of Wales would not be able either to sell the King's property or to grant a peerage to anyone other than a child of the King. The Prince of Wales denounced Pitt's scheme, declaring it a "project for producing weakness, disorder, and insecurity in every branch of the administration of affairs."[21] In the interests of the nation, both factions agreed to compromise.[17]		A significant technical impediment to any Regency Bill involved the lack of a speech from the throne, which was necessary before Parliament could proceed to any debates or votes. The speech was normally delivered by the King, but could also be delivered by royal representatives known as Lords Commissioners; but no document could empower the Lords Commissioners to act unless the Great Seal of the Realm was affixed to it. The seal could not be legally affixed without the prior authorisation of the sovereign. Pitt and his fellow ministers ignored the last requirement and instructed the Lord Chancellor to affix the Great Seal without the King's consent, as the act of affixing the Great Seal in itself gave legal force to the bill. This legal fiction was denounced by Edmund Burke as a "glaring falsehood",[22] as a "palpable absurdity",[22] and even as a "forgery, fraud".[23] The Duke of York described the plan as "unconstitutional and illegal."[21] Nevertheless, others in Parliament felt that such a scheme was necessary to preserve an effective government. Consequently, on 3 February 1789, more than two months after it had convened, Parliament was formally opened by an "illegal" group of Lords Commissioners. The Regency Bill was introduced, but before it could be passed the King recovered. The King declared retroactively that the instrument authorising the Lords Commissioners to act was valid.[12][17]		The Prince of Wales's debts continued to climb, and his father refused to aid him unless he married his cousin Princess Caroline of Brunswick.[24] In 1795, the prince acquiesced; and they were married on 8 April 1795 at the Chapel Royal, St James's Palace. The marriage, however, was disastrous; each party was unsuited to the other. The two were formally separated after the birth of their only child, Princess Charlotte, in 1796, and remained separated thereafter. The Prince remained attached to Maria Fitzherbert for the rest of his life, despite several periods of estrangement.[25]		George's mistresses included Mary Robinson, an actress who was bought off with a generous pension when she threatened to sell his letters to the newspapers;[26] Grace Elliott, the divorced wife of a physician;[27] and Frances Villiers, Countess of Jersey, who dominated his life for some years.[25] In later life, his mistresses were the Marchioness of Hertford and the Marchioness Conyngham, who were both married to aristocrats.[28]		George was rumoured to have fathered several illegitimate children. James Ord (born 1786)—who moved to the United States and became a Jesuit priest—was reportedly his son by Fitzherbert.[29] The King, late in life, told a friend that he had a son who was a naval officer in the West Indies, whose identity has been tentatively established as Captain Henry A. F. Hervey (1786–1824), reportedly George's child by the songwriter Lady Anne Lindsay (later Barnard), a daughter of the 5th Earl of Balcarres.[30] Other reported offspring include Major George Seymour Crole, the son of theatre manager's daughter Eliza Crole or Fox; William Hampshire, the son of publican's daughter Sarah Brown; and Charles "Beau" Candy, the son of a Frenchwoman with that surname.[31] Anthony Camp, Director of Research at the Society of Genealogists, has dismissed the claims that George IV was the father of Ord, Hervey, Hampshire and Candy as fictitious.[32]		The problem of the Prince of Wales's debts, which amounted to the extraordinary sum of £630,000 (equivalent to £58,700,000 today[6]) in 1795,[33] was solved (at least temporarily) by Parliament. Being unwilling to make an outright grant to relieve these debts, it provided him an additional sum of £65,000 (equivalent to £6,056,000 today[6]) per annum.[34] In 1803, a further £60,000 (equivalent to £4,941,000 today[6]) was added, and George's debts of 1795 were finally cleared in 1806, although the debts he had incurred since 1795 remained.[14]		In 1804, a dispute arose over the custody of Princess Charlotte, which led to her being placed in the care of the King, George III. It also led to a Parliamentary Commission of Enquiry into Princess Caroline's conduct after the Prince of Wales accused her of having an illegitimate son. The investigation cleared Caroline of the charge but still revealed her behaviour to have been extraordinarily indiscreet.[35]		In late 1810, George III was once again overcome by his malady following the death of his youngest daughter, Princess Amelia. Parliament agreed to follow the precedent of 1788; without the King's consent, the Lord Chancellor affixed the Great Seal of the Realm to letters patent naming Lords Commissioners. The letters patent lacked the Royal Sign Manual, but were sealed by request of resolutions passed by both Houses of Parliament. The Lords Commissioners appointed by the letters patent, in the name of the King, then signified the granting of Royal Assent to a bill that became the Regency Act of 1811. Parliament restricted some of the powers of the Prince Regent (as the Prince of Wales became known). The constraints expired one year after the passage of the Act.[36] The Prince of Wales became Prince Regent on 5 February 1811.[37]		The Regent let his ministers take full charge of government affairs, playing a far lesser role than his father. The principle that the prime minister was the person supported by a majority in the House of Commons, whether the king personally favoured him or not, became established.[38] His governments, with little help from the Regent, presided over British policy. One of the most important political conflicts facing the country concerned Catholic emancipation, the movement to relieve Roman Catholics of various political disabilities. The Tories, led by the Prime Minister, Spencer Perceval, were opposed to Catholic emancipation, while the Whigs supported it. At the beginning of the Regency, the Prince of Wales was expected to support the Whig leader, William Grenville, 1st Baron Grenville. He did not, however, immediately put Lord Grenville and the Whigs into office. Influenced by his mother, he claimed that a sudden dismissal of the Tory government would exact too great a toll on the health of the King (a steadfast supporter of the Tories), thereby eliminating any chance of a recovery.[39]		In 1812, when it appeared highly unlikely that the King would recover, the Prince of Wales again failed to appoint a new Whig administration. Instead, he asked the Whigs to join the existing ministry under Perceval. The Whigs, however, refused to co-operate because of disagreements over Catholic emancipation. Grudgingly, the Prince of Wales allowed Perceval to continue as Prime Minister.[40]		On 10 May 1812, Perceval was assassinated by John Bellingham. The Prince Regent was prepared to reappoint all the members of the Perceval ministry under a new leader. The House of Commons formally declared its desire for a "strong and efficient administration",[41] so the Prince Regent then offered leadership of the government to Richard Wellesley, 1st Marquess Wellesley, and afterwards to Francis Rawdon-Hastings, 2nd Earl of Moira. He doomed the attempts of both to failure, however, by forcing each to construct an all party ministry at a time when neither party wished to share power with the other. Possibly using the failure of the two peers as a pretext, the Prince Regent immediately reappointed the Perceval administration, with Robert Jenkinson, 2nd Earl of Liverpool, as Prime Minister.[42]		The Tories, unlike Whigs such as Earl Grey, sought to continue the vigorous prosecution of the war in Continental Europe against the powerful and aggressive Emperor of the French, Napoleon I.[43] An anti-French alliance, which included Russia, Prussia, Austria, Britain and several smaller countries, defeated Napoleon in 1814. In the subsequent Congress of Vienna, it was decided that the Electorate of Hanover, a state that had shared a monarch with Britain since 1714, would be raised to a kingdom, known as the Kingdom of Hanover. On 30 December 1814, the Prince Regent signed and ratified the Treaty of Ghent which ended the War of 1812 with the United States. Napoleon returned from exile in 1815, but was defeated at the Battle of Waterloo by Arthur Wellesley, 1st Duke of Wellington, brother of Marquess Wellesley.		During this period George took an active interest in matters of style and taste, and his associates such as the dandy Beau Brummell and the architect John Nash created the Regency style. In London Nash designed the Regency terraces of Regent's Park and Regent Street. George took up the new idea of the seaside spa and had the Brighton Pavilion developed as a fantastical seaside palace, adapted by Nash in the "Indian Gothic" style inspired loosely by the Taj Mahal, with extravagant "Indian" and "Chinese" interiors.[44]		When George III died in 1820, the Prince Regent, then aged 57, ascended the throne as George IV, with no real change in his powers.[45] By the time of his accession, he was obese and possibly addicted to laudanum.[5]		George IV's relationship with his wife Caroline had deteriorated by the time of his accession. They had lived separately since 1796, and both were having affairs. In 1814, Caroline left the United Kingdom for continental Europe, but she chose to return for her husband's coronation, and to publicly assert her rights as queen consort. However, George IV refused to recognise Caroline as Queen, and commanded British ambassadors to ensure that monarchs in foreign courts did the same. By royal command, Caroline's name was omitted from the Book of Common Prayer, the liturgy of the Church of England.		The King sought a divorce, but his advisors suggested that any divorce proceedings might involve the publication of details relating to the King's own adulterous relationships. Therefore, he requested and ensured the introduction of the Pains and Penalties Bill, under which Parliament could have imposed legal penalties without a trial in a court of law. The bill would have annulled the marriage and stripped Caroline of the title of Queen. The bill proved extremely unpopular with the public, and was withdrawn from Parliament. George IV decided, nonetheless, to exclude his wife from his coronation at Westminster Abbey, on 19 July 1821. Caroline fell ill that day and died on 7 August; during her final illness she often stated that she thought she had been poisoned.[46]		George's coronation was a magnificent and expensive affair, costing about £243,000 (approximately £19,970,000 in 2017;[6] for comparison, his father's coronation had only cost about £10,000, less than a twentieth of George IV's). Despite the enormous cost, it was a popular event.[5] In 1821 the King became the first monarch to pay a state visit to Ireland since Richard II of England.[47] The following year he visited Edinburgh for "one and twenty daft days".[48] His visit to Scotland, organised by Sir Walter Scott, was the first by a reigning British monarch since the mid-17th century.		George IV spent most of his later reign in seclusion at Windsor Castle,[49] but he continued to intervene in politics. At first it was believed that he would support Catholic emancipation, as he had proposed a Catholic Emancipation Bill for Ireland in 1797, but his anti-Catholic views became clear in 1813 when he privately canvassed against the ultimately defeated Catholic Relief Bill of 1813. By 1824 he was denouncing Catholic emancipation in public.[50] Having taken the coronation oath on his accession, George now argued that he had sworn to uphold the Protestant faith, and could not support any pro-Catholic measures.[51] The influence of the Crown was so great, and the will of the Tories under Prime Minister Lord Liverpool so strong, that Catholic emancipation seemed hopeless. In 1827, however, Lord Liverpool retired, to be replaced by the pro-emancipation Tory George Canning. When Canning entered office, the King, hitherto content with privately instructing his ministers on the Catholic Question, thought it fit to make a public declaration to the effect that his sentiments on the question were those of his revered father, George III.[52]		Canning's views on the Catholic Question were not well received by the most conservative Tories, including the Duke of Wellington. As a result, the ministry was forced to include Whigs.[53] Canning died later in that year, leaving Frederick Robinson, 1st Viscount Goderich, to lead the tenuous Tory-Whig coalition. Lord Goderich left office in 1828, to be succeeded by the Duke of Wellington, who had by that time accepted that the denial of some measure of relief to Roman Catholics was politically untenable.[54][55] George was never as friendly with Wellington as he had been with Canning and chose to annoy the Duke by pretending to have fought at Waterloo disguised as a German general. With great difficulty Wellington obtained the King's consent to the introduction of a Catholic Relief Bill on 29 January 1829. Under pressure from his fanatically anti-Catholic brother, the Duke of Cumberland, the King withdrew his approval and in protest the Cabinet resigned en masse on 4 March. The next day the King, now under intense political pressure, reluctantly agreed to the Bill and the ministry remained in power.[5] Royal Assent was finally granted to the Catholic Relief Act on 13 April.[56]		George's heavy drinking and indulgent lifestyle had taken their toll on his health by the late 1820s. While still Prince of Wales, he had become obese through his huge banquets and copious consumption of alcohol, making him the target of ridicule on the rare occasions that he appeared in public;[57] by 1797 his weight had reached 17 stone 7 pounds (111 kg; 245 lb).[58] By 1824, his corset was made for a waist of 50 inches (130 cm).[59] He suffered from gout, arteriosclerosis, peripheral edema ("dropsy"), and possibly porphyria. In his last years, he spent whole days in bed and suffered spasms of breathlessness that would leave him half-asphyxiated.[5]		By December 1828, like his father, George was almost completely blind from cataracts, and was suffering from such severe gout in his right hand and arm that he could no longer sign documents.[60] In mid-1829, Sir David Wilkie reported the King "was wasting away frightfully day after day", and had become so obese that he looked "like a great sausage stuffed into the covering".[61] The King took laudanum to counteract severe bladder pains, which left him in a drugged and mentally handicapped state for days on end.[62] He underwent surgery to remove a cataract in September 1829. In 1830 his weight was recorded to be 20 stone (130 kg; 280 lb).[63]		By the spring of 1830, George's imminent end was apparent. Attacks of breathlessness due to dropsy forced him to sleep upright in a chair, and doctors frequently tapped his abdomen to drain excess fluid.[62] He was admired for clinging doggedly to life despite his obvious decline.[64] He dictated his will in May and became very devout in his final months, confessing to an archdeacon that he repented of his early dissolute life, but hoped mercy would be shown to him as he had always tried to do the best for his subjects.[62] At about half-past three in the morning of 26 June 1830 at Windsor Castle, he reportedly called out "Good God, what is this?", clasped his page's hand, said "my boy, this is death", and died.[65] An autopsy conducted by his physicians revealed he had died from upper gastrointestinal bleeding resulting from the rupture of a blood vessel in his stomach.[66] A large tumour "the size of an orange" was found attached to his bladder; his heart was enlarged, had heavily calcified valves and was surrounded by a large fat deposit.[66] He was buried in St George's Chapel, Windsor Castle, on 15 July.[67]		His only legitimate child, Princess Charlotte of Wales, had died from post-partum complications in 1817, after delivering a stillborn son. The second son of George III, Prince Frederick, Duke of York and Albany, had died childless in 1827, so the succession passed to the third son of George III, Prince William, Duke of Clarence, who reigned as William IV.[68]		George's last years were marked by increasing physical and mental decay and withdrawal from public affairs. Privately a senior aide to the King confided to his diary: "A more contemptible, cowardly, selfish, unfeeling dog does not exist ... There have been good and wise kings but not many of them ... and this I believe to be one of the worst."[1] On his death The Times captured elite opinion succinctly: "There never was an individual less regretted by his fellow-creatures than this deceased king. What eye has wept for him? What heart has heaved one throb of unmercenary sorrow? ... If he ever had a friend – a devoted friend in any rank of life – we protest that the name of him or her never reached us."[69] George IV was described as the "First Gentleman of England" on account of his style and manners.[70] He possessed many good qualities; he was bright, clever, and knowledgeable. However, his laziness and gluttony led him to squander much of his talent. The Times wrote, he would always prefer "a girl and a bottle to politics and a sermon".[71]		The Regency period saw a shift in fashion that was largely determined by George. After political opponents put a tax on wig powder, he abandoned wearing a powdered wig in favour of natural hair.[72] He wore darker colours than had been previously fashionable as they helped to disguise his size, favoured pantaloons and trousers over knee breeches because they were looser, and popularised a high collar with neck cloth because it hid his double chin.[73] His visit to Scotland in 1822 led to the revival, if not the creation, of Scottish tartan dress as it is known today.[74]		During the political crisis caused by Catholic emancipation, the Duke of Wellington said that George was "the worst man he ever fell in with his whole life, the most selfish, the most false, the most ill-natured, the most entirely without one redeeming quality",[75] but his eulogy delivered in the House of Lords called George "the most accomplished man of his age" and praised his knowledge and talent.[76] Wellington's true feelings probably lie somewhere between these two extremes; as he said later, George was "a magnificent patron of the arts ... the most extraordinary compound of talent, wit, buffoonery, obstinacy, and good feeling—in short a medley of the most opposite qualities, with a great preponderance of good—that I ever saw in any character in my life."[76]		There are many statues of George IV, a large number of which were erected during his reign. In the United Kingdom, they include a bronze statue of him on horseback by Sir Francis Chantrey in Trafalgar Square and another outside the Royal Pavilion in Brighton.		In Edinburgh, "George IV Bridge" is a main street linking the Old Town High Street to the north over the ravine of the Cowgate, designed by the architect Thomas Hamilton in 1829 and completed in 1835. King's Cross, now a major transport hub sitting on the border of Camden and Islington in north London, takes its name from a short-lived monument erected to George IV in the early 1830s.[77] A square and a neighbouring park in St Luke's, Islington, are also named after George IV.[78]		At birth, he was also entitled to the dignities Prince of Great Britain, Electoral Prince of Brunswick-Lüneburg and Duke of Rothesay.[79] Under the Act of Parliament that instituted the regency, the prince's formal title as regent was "Regent of the United Kingdom of Great Britain and Ireland".[80]		As Prince of Wales, George Augustus bore the royal arms (with an inescutcheon of Gules plain in the Hanoverian quarter), differenced by a label of three points Argent.[83] The arms included the royal crest and supporters but with the single arched coronet of his rank, all charged on the shoulder with a similar label. His arms followed the change in the royal arms in 1801, when the Hanoverian quarter became an inescutcheon and the French quarter was dropped altogether.[84] The 1816 alteration did not affect him as it only applied to the arms of the King.[85]		As king his arms were those of his two kingdoms, the United Kingdom and Hanover, superimposed: Quarterly, I and IV Gules three lions passant guardant in pale Or (for England); II Or a lion rampant within a double tressure flory-counter-flory Gules (for Scotland); III Azure a harp Or stringed Argent (for Ireland); overall an escutcheon tierced in pall reversed (for Hanover), I Gules two lions passant guardant Or (for Brunswick), II Or a semy of hearts Gules a lion rampant Azure (for Lüneburg), III Gules a horse courant Argent (for Westphalia), overall an inescutcheon Gules charged with the crown of Charlemagne Or, the whole escutcheon surmounted by a crown.[86]		
A steamship, often referred to as a steamer, is a vessel, typically ocean-faring and seaworthy, that is propelled by one or more steam engines[1] that typically drive (turn) propellers or paddlewheels. The first steamships came into practical usage during the early 1800s; however, there were exceptions that came before. Steamships usually use the prefix designations of "PS" for paddle steamer or "SS" for screw steamer (using a propeller or screw). As paddle steamers became less common, "SS" is assumed by many to stand for "steam ship". Ships powered by internal combustion engines use a prefix such as "MV" for motor vessel, so it is not correct to use "SS" for most modern vessels.						The steamship was preceded by smaller vessels designed for insular transportation, called steamboats. Once the technology of steam was mastered at this level, steam engines were mounted on larger, and eventually, ocean-going vessels. Becoming reliable, and propelled by screw rather than paddlewheels, the technology changed the design of ships for faster, more economic propulsion.		Paddlewheels as the main motive source became standard on these early vessels (see Paddle steamer). It was an effective means of propulsion under ideal conditions but otherwise had serious drawbacks. The paddle-wheel performed best when it operated at a certain depth, however when the depth of the ship changed from added weight it further submerged the paddle wheel causing a substantial decrease in performance.[2]		Within a few decades of the development of the river and canal steamboat, the first steamships began to cross the Atlantic Ocean. The first sea-going steamboat was Richard Wright's first steamboat "Experiment", an ex-French lugger; she steamed from Leeds to Yarmouth in July 1813.[3][4]		The first iron steamship to go to sea was the 116-ton Aaron Manby, built in 1821 by Aaron Manby at the Horseley Ironworks, and became the first iron-built vessel to put to sea when she crossed the English Channel in 1822, arriving in Paris on 22 June.[5] She carried passengers and freight to Paris in 1822 at an average speed of 8 knots (9 mph, 14 km/h).		The American ship SS Savannah first crossed the Atlantic Ocean. The title of the first ship to make the transatlantic trip substantially under steam power is possibly the British-built Dutch-owned Curaçao, a wooden 438 ton vessel built in Dover and powered by two 50 hp engines, which crossed from Hellevoetsluis, near Rotterdam on 26 April 1827 to Paramaribo, Surinam on 24 May, spending 11 days under steam on the way out and more on the return. Another claimant is the Canadian ship SS Royal William in 1833.[6]		The SS Archimedes, built in Britain in 1839 by Francis Pettit Smith, was the world's first steamship[notes 1] to be driven by a screw propeller. It had considerable influence on ship development, encouraging the adoption of screw propulsion by the Royal Navy, in addition to her influence on commercial vessels.		The first steamship purpose-built for regularly scheduled trans-Atlantic crossings was the British side-wheel paddle steamer SS Great Western built by Isambard Kingdom Brunel in 1838, which inaugurated the era of the trans-Atlantic ocean liner.		The key innovation that made ocean-going steamers viable was the change from the paddle-wheel to the screw-propeller as the mechanism of propulsion. These steamships quickly became more popular, because the propeller's efficiency was consistent regardless of the depth at which it operated. Being smaller in size and mass and being completely submerged, it was also far less prone to damage.		James Watt of Scotland is widely given credit for applying the first screw propeller to an engine at his Birmingham works, an early steam engine, beginning the use of an hydrodynamic screw for propulsion.		The development of screw propulsion relied on the following technological innovations.		Steam engines had to be designed with the power delivered at the bottom of the machinery, to give direct drive to the propeller shaft. A paddle steamer's engines drive a shaft that is positioned above the waterline, with the cylinders positioned below the shaft. SS Great Britain used chain drive to transmit power from a paddler's engine to the propeller shaft - the result of a late design change to propeller propulsion.		An effective stern tube and associated bearings were required. The stern tube contains the propeller shaft where it passes through the hull structure. It should provide an unrestricted delivery of power by the propeller shaft. The combination of hull and stern tube must avoid any flexing that will bend the shaft or cause uneven wear. The inboard end has a stuffing box that prevents water from entering the hull along the tube. Some early stern tubes were made of brass and operated as a water lubricated bearing along the entire length. In other instances a long bush of soft metal was fitted in the after end of the stern tube. The Great Eastern had this arrangement fail on her first transatlantic voyage, with very large amounts of uneven wear. The problem was solved with a lignum vitae water-lubricated bearing, patented in 1858. This became standard practice and is in use today.		Since the motive power of screw propulsion is delivered along the shaft, a thrust bearing is needed to transfer that load to the hull without excessive friction. SS Great Britain had a 2 ft diameter gunmetal plate on the forward end of the shaft which bore against a steel plate attached to the engine beds. Water at 200 psi was injected between these two surfaces to lubricate and separate them. This arrangement was not sufficient for higher engine powers and oil lubricated "collar" thrust bearings became standard from the early 1850s. This was superseded at the beginning of the 20th century by floating pad bearing which automatically built up wedges of oil which could withstand bearing pressures of 500 psi or more.[7]		Steam-powered ships were named with a prefix designating their propeller configuration i.e. single, twin, triple-screw. Single-screw Steamship SS, Twin-Screw Steamship TSS, Triple-Screw Steamship TrSS. Steam turbine-driven ships had the prefix TS. In the UK the prefix RMS for Royal Mail Steamship overruled the screw configuration prefix. See Ship prefix[8]		The first steamship credited with crossing the Atlantic Ocean between North America and Europe was the American ship SS Savannah, though she was actually a hybrid between a steamship and a sailing ship, with the first half of the journey making use of the steam engine. Savannah left the port of Savannah, Georgia, on May 22, 1819, arriving in Liverpool, England, on June 20, 1819; her steam engine having been in use for part of the time on 18 days (estimates vary from 8 to 80 hours).[9] A claimant to the title of the first ship to make the transatlantic trip substantially under steam power is the British-built Dutch-owned Curaçao, a wooden 438 ton vessel built in Dover and powered by two 50 hp engines, which crossed from Hellevoetsluis, near Rotterdam on 26 April 1827 to Paramaribo, Surinam on 24 May, spending 11 days under steam on the way out and more on the return. Another claimant is the Canadian ship SS Royal William in 1833.[10]		The British side-wheel paddle steamer SS Great Western was the first steamship purpose-built for regularly scheduled trans-Atlantic crossings, starting in 1838. In 1836 Isambard Kingdom Brunel and a group of Bristol investors formed the Great Western Steamship Company to build a line of steamships for the Bristol-New York route.[11] The idea of regular scheduled transatlantic service was under discussion by several groups and the rival British and American Steam Navigation Company was established at the same time.[12] Great Western's design sparked controversy from critics that contended that she was too big.[11] The principle that Brunel understood was that the carrying capacity of a hull increases as the cube of its dimensions, whilst the water resistance only increases as the square of its dimensions. This meant that large ships were more fuel efficient, something very important for long voyages across the Atlantic.[13]		Great Western was an iron-strapped, wooden, side-wheel paddle steamer, with four masts to hoist the auxiliary sails. The sails were not just to provide auxiliary propulsion, but also were used in rough seas to keep the ship on an even keel and ensure that both paddle wheels remained in the water, driving the ship in a straight line. The hull was built of oak by traditional methods. She was the largest steamship for one year, until the British and American's British Queen went into service. Built at the shipyard of Patterson & Mercer in Bristol, Great Western was launched on 19 July 1837 and then sailed to London, where she was fitted with two side-lever steam engines from the firm of Maudslay, Sons & Field, producing 750 indicated horsepower between them.[11] The ship proved satisfactory in service and initiated the transatlantic route, acting as a model for all following Atlantic paddle-steamers.		The Cunard Line's RMS Britannia began her first regular passenger and cargo service by a steamship in 1840, sailing from Liverpool to Boston.[14]		In 1847 the revolutionary SS Great Britain, also built by Brunel, became the first iron-hulled screw-driven ship to cross the Atlantic.[15] The SS Great Britain was the first ship to combine these two innovations. After the initial success of its first liner, SS Great Western of 1838, the Great Western Steamship Company assembled the same engineering team that had collaborated so successfully before. This time however, Brunel, whose reputation was at its height, came to assert overall control over design of the ship—a state of affairs that would have far-reaching consequences for the company. Construction was carried out in a specially adapted dry dock in Bristol, England.[16]		Brunel was given a chance to inspect John Laird's 213-foot (65 m) (English) channel packet ship Rainbow—the largest iron-hulled ship then in service— in 1838, and was soon converted to iron-hulled technology. He scrapped his plans to build a wooden ship and persuaded the company directors to build an iron-hulled ship.[17] Iron's advantages included being much cheaper than wood, not being subject to dry rot or woodworm, and its much greater structural strength. The practical limit on the length of a wooden-hulled ship is about 300 feet, after which hogging—the flexing of the hull as waves pass beneath it—become too great. Iron hulls are far less subject to hogging, so that the potential size of an iron-hulled ship is much greater.[18]		In the spring of 1840 Brunel also had the opportunity to inspect the SS Archimedes, the first screw-propelled steamship, completed only a few months before by F. P. Smith's Propeller Steamship Company. Brunel had been looking into methods of improving the performance of Great Britain's paddlewheels, and took an immediate interest in the new technology, and Smith, sensing a prestigious new customer for his own company, agreed to lend Archimedes to Brunel for extended tests.[17] Over several months, Smith and Brunel tested a number of different propellers on Archimedes in order to find the most efficient design, a four-bladed model submitted by Smith.[17] When launched in 1843, Great Britain was by far the largest vessel afloat.		Brunel's last major project, the SS Great Eastern, was built in 1854–57 with the intent of linking Great Britain with India, via the Cape of Good Hope, without any coaling stops. This ship was arguably more revolutionary than her predecessors. She was one of the first ships to be built with a double hull with watertight compartments and was the first liner to have four funnels. She was the biggest liner throughout the rest of the 19th century with a gross tonnage of almost 20,000 tons and had a passenger-carrying capacity of thousands. The ship was ahead of her time and went through a turbulent history, never being put to her intended use. The first transatlantic steamer built of steel was SS Buenos Ayrean, built by Allan Line Royal Mail Steamers and entering service in 1879.[citation needed]		The first regular steamship service from the East Coast to the West Coast of the United States began on February 28, 1849, with the arrival of the SS California in San Francisco Bay. The California left New York Harbor on October 6, 1848, rounded Cape Horn at the tip of South America, and arrived at San Francisco, California, after a four-month and 21-day journey. The first steamship to operate on the Pacific Ocean was the paddle steamer Beaver, launched in 1836 to service Hudson's Bay Company trading posts between Puget Sound Washington and Alaska.[19]		The most testing route for steam was from Britain or the East Coast of the USA to the Far East. The distance from either is roughly the same, between 14,000 to 15,000 nautical miles (26,000 to 28,000 km; 16,000 to 17,000 mi), traveling down the Atlantic, round the southern tip of Africa and across the Indian Ocean.[20] Before 1866, no steamship could carry enough coal to make this voyage and have enough space left to carry a commercial cargo.		A partial solution to this problem was adopted by the Peninsular and Oriental Steam Navigation Company (P&O), using an overland section between Alexandria and Suez, with connecting steamship routes along the Mediterranean and then through the Red Sea. Whilst this worked for passengers and some high value cargo, sail was still the only solution for virtually all trade between China and Western Europe or East Coast America. Most notable of these cargoes was tea, typically carried in clippers.[21]		Another partial solution was the Steam Auxiliary Ship - a vessel with a steam engine, but also rigged as a sailing vessel. The steam engine would only be used when conditions were unsuitable for sailing - in light or contrary winds. Some of this type (for instance Erl King) were built with propellers that could be lifted clear of the water to reduce drag when under sail power alone. These ships struggled to be successful on the route to China, as the standing rigging required when sailing was a handicap when steaming into a head wind, most notably against the southwest monsoon when returning with a cargo of new tea.[22] Though the auxiliary steamers persisted in competing in far eastern trade for a few years (and it was Erl King that carried the first cargo of tea through the Suez Canal), they soon moved on to other routes.		What was needed was a big improvement in fuel efficiency. Whilst the boilers for steam engines on land were allowed to run at high pressures, the Board of Trade (under the authority of the Merchant Shipping Act 1854) would not allow ships to exceed 20 or 25 pounds per square inch (140 or 170 kPa). Compound engines were a known source of improved efficiency - but generally not used at sea due to the low pressures available. Carnatic (1863), a P&O ship, had a compound engine - and achieved better efficiency than other ships of the time. Her boilers ran at 26 pounds per square inch (180 kPa) but relied on a substantial amount of superheat.[21]		Alfred Holt, who had entered marine engineering and ship management after an apprenticeship in railway engineering, experimented with boiler pressures of 60 pounds per square inch (410 kPa) in Cleator. Holt was able to persuade the Board of Trade to allow these boiler pressures and, in partnership with his brother Phillip launched Agamemnon in 1865. Holt had designed a particularly compact compound engine and taken great care with the hull design, producing a light, strong, easily driven hull.[21]		The efficiency of Holt's package of boiler pressure, compound engine and hull design gave a ship that could steam at 10 knots on 20 long tons of coal a day. This fuel consumption was a saving from between 23 and 14 long tons a day, compared to other contemporary steamers. Not only did less coal need to be carried to travel a given distance, but fewer firemen were needed to fuel the boilers, so crew costs and their accommodation space were reduced. Agamemnon was able to sail from London to China with a coaling stop at Mauritius on the outward and return journey, with a time on passage substantially less than the competing sailing vessels. Holt had already ordered two sister ships to Agamemnon by the time she had returned from her first trip to China in 1866, operating these ships in the newly formed Blue Funnel Line. His competitors rapidly copied his ideas for their own new ships.[21]		The opening of the Suez Canal in 1869 gave a distance saving of 3,300 nautical miles (6,100 km; 3,800 mi) on the route from China to London.[23] The canal was not a practical option for sailing vessels, as using a tug was difficult and expensive - so this distance saving was not available to them.[21] Steamships immediately made use of this new waterway and found themselves in high demand in China for the start of the 1870 tea season. The steamships were able to obtain a much higher rate of freight than sailing ships and the insurance premium for the cargo was less. So successful were the steamers using the Suez Canal that, in 1871, 45 were built in Clyde shipyards alone for Far Eastern trade.[20]		By 1870 a number of inventions such as the screw propeller, the compound engine,[24] and the triple-expansion engine made trans-oceanic shipping on a large scale economically viable. In 1870 the White Star Line’s RMS Oceanic set a new standard for ocean travel by having its first-class cabins amidships, with the added amenity of large portholes, electricity and running water.[25] The size of ocean liners increased from 1880 to meet the needs of the human migration to the United States and Australia.		RMS Umbria[26] and her sister ship RMS Etruria were the last two Cunard liners of the period to be fitted with auxiliary sails. Both ships were built by John Elder & Co. of Glasgow, Scotland, in 1884. They were record breakers by the standards of the time, and were the largest liners then in service, plying the Liverpool to New York route.		RMS Titanic was the largest steamship in the world when she sank in 1912; a subsequent major sinking of a steamer was that of the RMS Lusitania, as an act of World War I.		Launched in 1938, RMS Queen Elizabeth was the largest passenger steamship ever built. Launched in 1969, RMS Queen Elizabeth 2 (QE2) was the last passenger steamship to cross the Atlantic Ocean on a scheduled liner voyage before she was converted to diesels in 1986. The last major passenger ship built with steam turbines was the Fairsky, launched in 1984[citation needed], later Atlantic Star, reportedly sold to Turkish shipbreakers in 2013.		Most luxury yachts at the end of the 19th and early 20th centuries were steam driven (see luxury yacht; also Cox & King yachts). Thomas Assheton Smith was an English aristocrat who forwarded the design of the steam yacht in conjunction with the Scottish marine engineer Robert Napier.[27]		The decline of the steamship began after the World War Two. Many had been lost in the war, and marine diesel engine had finally matured as an economical and viable alternative to steam power. The diesel engine has far better thermal efficiency than reciprocating steam engine, and was far easier to control. Diesel engine also requires far less supervision and maintenance than steam engine, and as an internal combustion engine it does not need boilers nor water supply, being therefore more space efficient.		The Liberty ships were the last major steamship class equipped with reciprocating engine. The last Victory ships had already been equipped with marine diesels, and diesel engine superseded both steamers and windjammers soon after the World War Two. Most steamers were used up to their maximum economical life span, and no commercial ocean-going steamers with reciprocating engines have been built after the 1960s.		Most steamships today are powered by steam turbines. After the demonstration by British engineer Charles Parsons of his steam turbine-driven yacht, Turbinia, in 1897, the use of steam turbines for propulsion quickly spread. The Cunard RMS Mauretania, built in 1906 was one of the first ocean liners to use the steam turbine (with a late design change shortly before her keel was laid down) and was soon followed by all subsequent liners.[28]		Most capital ships of the major navies were propelled by steam turbines burning bunker fuel in both World Wars. Large naval vessels and submarines continue to be operated with steam turbines, using nuclear reactors to boil the water. NS Savannah, was the first nuclear-powered cargo-passenger ship, and was built in the late 1950s as a demonstration project for the potential use of nuclear energy.[29]		Thousands of Liberty Ships (powered by steam piston engines) and Victory Ships (powered by steam turbine engines) were built in World War II. A few of these survive as floating museums and sail occasionally: SS Jeremiah O'Brien, SS John W. Brown, SS American Victory, SS Lane Victory, and SS Red Oak Victory.		A steam turbine ship can be either direct propulsion (the turbines, equipped with a reduction gear, rotate directly the propellers), or turboelectric (the turbines rotate electric generators, which in turn feed electric motors operating the propellers).		While steam turbine-driven merchant ships such as the Algol-class cargo ships (1972–1973), ALP Pacesetter-class container ships (1973–1974)[30][31] and very large crude carriers were built until the 1970s, the use of steam for marine propulsion in the commercial market has declined dramatically due to the development of more efficient diesel engines. One notable exception are LNG carriers which use boil-off gas from the cargo tanks as fuel. However, even there the development of dual-fuel engines as pushed steam turbines into a niche market with about 10% market share in newbuildings in 2013. Lately, there has been some development in hybrid power plants where the steam turbine is used together with gas engines.[32] As of August 2017 the newest class of Steam Turbine ships are the Seri Camellia-class LNG carriers built by Hyundai Heavy Industries (HHI) starting in 2016 and comprising five units. [33]		Nuclear powered ships are basically steam turbine vessels. The boiler is heated, not by heat of combustion, but by the heat generated by nuclear reactor. Most atomic-powered ships today are either aircraft carriers or submarines.		Media related to Steamships at Wikimedia Commons		
Sanitary sewer overflow (SSO) is a condition in which untreated sewage is discharged from a sanitary sewer into the environment prior to reaching sewage treatment facilities. When caused by rainfall it is also known as wet weather overflow. It is primarily meaningful in developed countries, which have extensive treatment facilities. Frequent causes of SSO spills include:		SSOs can cause gastrointestinal illnesses, beach closures and restrictions on fish and shellfish consumption.						Developed countries such as the United States, Canada, most Western European nations (e.g. Italy and France), Australia, Singapore, South Korea and Japan are struggling with public health problems of SSO prevention. However, the magnitude of the problem is much greater in most developing countries.		The U.S. Environmental Protection Agency (EPA) estimates that at least 23,000 to 75,000 SSO events occur in the United States each year.[1] EPA estimated that upgrading every municipal treatment and collection system to reduce the frequency of overflow events to no more than once every five years would cost about $88 billion as of 2004.[2] This cost would be in addition to approximately $10 billion already invested. Although the volume of untreated sewage discharged to the environment is less than 0.01 percent of all treated sewage in the United States, the total volume amounts to several billion gallons per annum and accounts for thousands of cases of gastrointestinal illness each year.[2]:Ch. 6		Advanced European countries and Japan have similar or somewhat larger percentages of SSO events compared to the U.S.[citation needed]		In developing countries, most wastewater is still not treated when discharged into the environment. The People's Republic of China discharged about 55 percent of all sewage without treatment of any type, as of 2001.[3] In a relatively developed Middle Eastern country such as Iran, the majority of Tehran's population has totally untreated sewage injected to the city’s groundwater.[4] In Venezuela, a below-average country in South America with respect to wastewater treatment, 97 percent of the country’s sewage is discharged untreated into the environment.[5]		In many countries there are obligations to measure and report SSO occurrence using real-time telemetry to warn the public, bathers and shellfishery operators.[citation needed]		Sewers that were built in the early stages of urbanization were usually built before sewage treatment was implemented.[6] Early sewers were simple drainage systems to remove surface runoff with any waste material it might contain. These drainage systems became combined sewers when sewage from kitchens, baths, and toilets was added; and the discharge became offensive. Early sewage treatment plants were built to treat the sewage during dry weather; but it was infeasible to treat the larger volume of mixed sewage and precipitation runoff from combined sewers during wet weather. Sanitary sewers were built to keep sewage from being mixed with surface runoff so the sewage could be efficiently treated during both wet and dry weather.[7]		Decentralized failures in dry weather mainly occur from collection sewer line blockages, which can arise from a debris clog or tree root intrusion into the line itself. Approximately half of SSOs in the United States are caused by blockage.[2]:p. 4–26 Grease is the blocking agent in approximately half of U.S. SSOs attributed to blockage, and solid debris is the blocking agent for another 25 percent. Roots are a contributing factor in approximately one-quarter of United States SSOs attributed to blockage. Grease deposits are caused by cooking fats liquified with hot water for discharge to sanitary sewers. These fats congeal as solid deposits in the cooler sewer. Solid debris includes soiled clothing, diapers, and sanitary napkins flushed into toilets.[2]:p. 4–28		One of the main problems of a decentralized line failure is the difficulty of defining the location of overflow, since a typical urban system contains thousands of miles of collection pipes, and the central treatment plant has no way of communicating with all the lines, unless expensive monitoring equipment has been installed. Companies in the UK have widely deployed bulk dielectric transducers suspended in the sewers to detect high levels and to report the events back over fixed wireless data networks. In certain locations this practice has permitted the reduction of pollution events by up to 60 percent.[citation needed]		Dry weather blockage is less likely within combined sewers; because combined sewers designed for the additional volume of surface runoff are much larger than sanitary sewers. Combined sewer storm water regulators may be vulnerable to blockage by debris, but overflow from such blockage typically enters the diversion outfall to avoid flooding private or public property.		Approximately one-quarter of United States SSOs occur during heavy rainfall events, which can cause inflow of stormwater into sanitary sewers through damage, improper connections, or flooding buildings and lift stations in low-lying areas of the collection system. The combined flow of sewage and stormwater exceeds the capacity of the sanitary sewer system and sewage is released into homes, businesses and streets.[2]:p. 4–26 This circumstance is most prevalent in older cities whose subsurface infrastructure is quite old; Paris, London, Stockholm,[8] New York City, Washington, DC, and Oakland, California[9] are typical examples of such locations. Inflow into the sanitary lines can be caused by tree root rupture of subsurface lines or by mechanical fracture due to age and overpressure from trucks and buildings.		Another mode of system failure can include power outages, which may disable lift station pumps and cause sewage overflow from the lift station wet well. Lift station mechanical or power failure causes approximately ten percent of United States SSOs. This type of discharge is uncommon from combined sewers, because the combined volume of sewage and storm water discourages use of lift stations. Broken sewer lines are responsible for approximately ten percent of U.S. SSOs.[2]:p. 4–27		Power failure, human error, or mechanical failure may cause similar discharge of untreated or partially treated sewage from a sewage treatment plant; but this is typically regarded as a sewage treatment plant malfunction rather than a sanitary sewer overflow. Sewage treatment plants may be designed to capture overflow from malfunctioning units and discharge it to alternative treatment facilities. Flooding of private or public property is typically avoided by discharging the overflow to an outfall designed for discharge of treated sewage.[2]:p. ES–3		Human health impacts include significant numbers of gastrointestinal illness each year, although death from one overflow event is uncommon. Additional human impacts include beach closures, swimming restrictions and prohibition of the consumption of certain aquatic animals (particularly certain molluscs) after overflow events. Ecological consequences include fish kills, harm to plankton and other aquatic microflora and microfauna. Turbidity increase and dissolved oxygen decrease in receiving waters can lead to accentuated effects beyond the obvious pathogenic induced damage to aquatic ecosystems. It is possible that higher life forms such as marine mammals can be affected since certain seals and sea lions are known to experience peaks in pathogenic harm.[10]		The concept of SSO containment valves has been pioneered in the UK and they are installed to mitigate dry spills, by correlating rainfall data with SSO spill activity.[citation needed]		Since medieval times rulers have been aware of the impact of raw sewage improperly discharged to the environment. Before treatment systems existed in 16th century England, King Henry VIII decreed that sewage troughs should be kept flowing so that they would not stagnate in London prior to reaching the River Thames (London sewer system).[citation needed]		In the 19th century, sewage treatment plants were first developed and installed in the U.S. and parts of Europe, and the concept of SSO was identified. However, SSOs were not recognized as a widespread environmental problem until the rise of environmental awareness in the 1960s. Around that time government agencies in the U.S. began identifying locations and frequencies of SSOs in a systematic way. Local governments heard complaints of citizens, and beach closure protocols were systematised to reduce risks to public health.		After passage of the Clean Water Act in 1972, the U.S. spent billions of dollars on upgrades to sewage treatment plants, with some associated repairs and improvements to the associated collection systems, where the overflows occur. EPA continues to provide funding for low-interest loans to communities for addressing SSO problems, through the Clean Water State Revolving Fund.[11]		In the 1990s Japan, the UK and a number of other European countries began earnest investigation of some of their countries’ overflow issues.[citation needed]		
Waders are birds commonly found along shorelines and mudflats that wade in order to forage for food (such as insects or crustaceans) in the mud or sand. They are called shorebirds in North America (where wader is used to refer to long-legged wading birds such as storks and herons). Waders are members of the order Charadriiformes, which includes gulls, auks and their allies.		There are about 210[verification needed] species of wader, most of which are associated with wetland or coastal environments. Many species of Arctic and temperate regions are strongly migratory, but tropical birds are often resident, or move only in response to rainfall patterns. Some of the Arctic species, such as the little stint, are amongst the longest distance migrants, spending the non-breeding season in the southern hemisphere.		Many of the smaller species found in coastal habitats, particularly but not exclusively the calidrids, are often named as "sandpipers", but this term does not have a strict meaning, since the upland sandpiper is a grassland species.		The smallest member of this group is the least sandpiper, small adults of which can weigh as little as 15.5 grams and measure just over 13 cm (5.1 in). The largest species is believed to be the Far Eastern curlew, at about 63 cm (25 in) and 860 grams (1.90 pounds), although the beach thick-knee is the heaviest at about 1 kg (2.2 lb).		In the Sibley-Ahlquist taxonomy, waders and many other groups are subsumed into a greatly enlarged Ciconiiformes order. However, the classification of the Charadriiformes is one of the weakest points of the Sibley-Ahlquist taxonomy, as DNA–DNA hybridization has turned out to be incapable of properly resolving the interrelationships of the group. Formerly, the waders were united in a single suborder Charadrii, but this has turned out to be a "wastebasket taxon", uniting no less than four charadriiform lineages in a paraphyletic assemblage. However, it indicated that the plains wanderer actually belonged into one of them. Following recent studies (Ericson et al., 2003; Paton et al., 2003; Thomas et al., 2004a, b; van Tuinen et al., 2004; Paton & Baker, 2006), the waders may be more accurately subdivided as follows:		In keeping more in line with the traditional grouping, the Thinocori could be included in the Scolopaci, and the Chionidi in the Charadrii. However, the increasing knowledge about the early evolutionary history of modern birds suggests that the assumption of Paton et al. (2003) and Thomas et al. (2004b) of 4 distinct "wader" lineages (= suborders) already being present around the Cretaceous–Paleogene boundary is correct.						Shorebirds is a blanket term used to refer to multiple species of birds that live in wet, coastal environments. Because most these species spend much of their time near bodies of water, many have long legs suitable for wading (hence the name ‘Waders’). Some species prefer locations with rocks		The majority of species eat small invertebrates picked out of mud or exposed soil. Different lengths of bills enable different species to feed in the same habitat, particularly on the coast, without direct competition for food. Many waders have sensitive nerve endings at the end of their bills which enable them to detect prey items hidden in mud or soft soil. Some larger species, particularly those adapted to drier habitats will take larger prey including insects and small reptiles.		Shorebirds, like many other animals, exhibit phenotypic differences between males and females, also known as sexual dimorphism. In shorebirds, various sexual dimorphisms are seen, including, but not limited to, size (e.g. body size, bill size), color, and agility. In polygynous species, where one male individual mates with multiple female partners over his lifetime, dimorphisms tend to be more diverse.[1] In monogamous species, where male individuals mate with a single female partner, males typically do not have distinctive dimorphic characteristics such as colored feathers, but they still tend to be larger in size compared to females. The suborder of Charadrii displays the widest range of sexual dimorphisms seen in the Charadriiformes order.[2] However, cases of sexual monomorphism, where there are no distinguishing physical features besides external genitalia, are also seen in this order.[3]		One of the biggest factors that leads to the development of sexual dimorphism in shorebirds is sexual selection.[4] Males with ideal characteristics favored by females are more likely to reproduce and pass on their genetic information to their offspring better than the males who lack such characteristics. Mentioned earlier, male shorebirds are typically larger in size compared to their female counterparts. Competition between males tends to lead to sexual selection toward larger males and as a result, an increase in dimorphism. Bigger males tend to have greater access (and appeal) to female mates because their larger size aids them in defeating other competitors.[4] Likewise, if the species exhibits gender role reversal (where males take on roles traditionally done by females such as childcare and feeding), then males will select female mates based on traits that are the most appealing. In the Jacana species, females compete with each other for access to male mates, so females are larger in size. Males choose female mates based on who presents herself as the strongest and who 'owns' the most territory.[3]		Another factor that leads to the development of dimorphisms in species is natural selection. Natural selection focuses on traits and the environment's response to the traits in question; if the said trait increases the overall fitness of the individual possessing it, then it will be 'selected' and eventually become a permanent part of the population's gene pool. For example, depending on the food available in a shorebird specie's respective niche, bigger bill sizes may be favored in all individuals.[4] This would essentially lead to monomorphism within the species but is subject to change once sexual selection acts on the trait. Sexual selection could give rise to males with relatively larger bills than females if males used their bills to compete with other males. If larger bill size assisted the male in gathering resources, it would also make him more attractive to female mates.[1]		
Tied islands, or land-tied islands as they are often known, are landforms consisting of an island that is connected to land only by a tombolo: a spit of beach materials connected to land at both ends. St Ninian's Isle, in the Shetland Islands off the north coast of Scotland, is an example of this; it was once an island but is now linked to the Mainland. Other examples include: Maury Island, Washington in the Puget Sound, Coronado, California and Nahant, Massachusetts in the U.S.; Barrenjoey, New South Wales in Australia; and Wedge Island in Western Australia.		The Isle of Portland is also referred to as a tied island, although geographers now believe that Chesil Beach (which connects the island to the mainland) is a barrier beach that has moved eastwards, rather than a tombolo, which would have been formed by the effect of the island on waves.				
Beach nourishment (also referred to as beach renourishment,[1] beach replenishment, or sand replenishment) describes a process by which sediment, usually sand, lost through longshore drift or erosion is replaced from other sources. A wider beach can reduce storm damage to coastal structures by dissipating energy across the surf zone, protecting upland structures and infrastructure from storm surges, tsunamis and unusually high tides.[citation needed] Beach nourishment is typically part of a larger coastal defense scheme. Nourishment is typically a repetitive process since it does not remove the physical forces that cause erosion but simply mitigates their effects.		The first nourishment project in the United States was at Coney Island, New York in 1922 and 1923. It is now a common shore protection measure used by public and private entities.[2][3]		Nourishment is one of three commonly accepted methods for protecting shorelines. The structural alternative involves constructing a seawall, revetment, groyne or breakwater. Alternatively, with managed retreat the shoreline is left to erode, while relocating buildings and infrastructure further inland. Nourishment gained popularity because it preserved beach resources and avoided the negative effects of hard structures. Instead, nourishment creates a “soft” (i.e., non-permanent) structure by creating a larger sand reservoir, pushing the shoreline seaward.		Beaches can erode both naturally and due to human impacts (beach theft/sand mining).[4]		Erosion is a natural response to storm activity. During storms, sand from the visible beach submerges to form sand bars that protect the beach. Submersion is only part of the cycle. During calm weather smaller waves return sand from bars to the visible beach surface in a process called accretion.		Some beaches do not have enough sand available to coastal processes to respond naturally to storms. When not enough sand is available, the beach cannot recover following storms.		Many areas of high erosion are due to human activities. Reasons can include: seawalls locking up sand dunes, coastal structures like ports and harbors that prevent longshore transport, dams and other river management structures. Continuous, long-term renourishment efforts, especially in cuspate-cape coastlines, can play a role in longshore transport inhibition and downdrift erosion.[5] These activities interfere with the natural sediment flows either through dam construction (thereby reducing riverine sediment sources) or construction of littoral barriers such as jetties, or by deepening of inlets; thus preventing longshore transport of sediment.[6]		The proportion of total sand in a beach that lies below the waterline (submersion fraction) critically impacts beach nourishment. Two beaches with the same amount of visible sand may be much different below the surface. An eroded beach with substantial submerged sand surrounding it may recover without nourishment. Nourishing a beach that has little submerged sand requires understanding of the reason that the submerged sand is missing. The same forces that stripped the submerged sand once are likely to do so again. The amount of submerged sand eroded is typically much greater than the amount of missing sand on shore. Replacing only the visible sand is insufficient unless the submerged sand is also replaced. Otherwise, the beach is unstable and the replenished sand quickly erodes. If human activity is a major cause of the erosion, mitigating that activity may be more cost effective over both short and long term periods than direct nourishment.[citation needed]		Sand fill must be compatible with native beach sand.		Beach Profile Nourishment describes programs that nourish the full beach profile. In this instance, "profile" means the slope of the uneroded beach from above the water out to sea. The Gold Coast profile nourishment program placed 75% of its total sand volume below low water level. Some coastal authorities overnourish the below water beach (aka "nearshore nourishment") so that over time the natural beach increases in size. These approaches do not permanently protect beaches eroded by human activity, which requires that activity to be mitigated.[citation needed]		The selection of suitable material for a particular project depends upon the design needs, environmental factors and transport costs, considering both short and long-term implications.[7]		The most important material characteristic is the sediment grain size, which must closely match the native material. Excess silt and clay fraction (mud) versus the natural turbidity in the nourishment area disqualifies some materials. Projects with unmatched grain sizes performed relatively poorly. Nourishment sand that is only slightly smaller than native sand can result in significantly narrower equilibrated dry beach widths compared to sand the same size as (or larger than) native sand. Evaluating material fit requires a sand survey that usually includes geophysical profiles and surface and core samples.[7]		Some beaches were nourished using a finer sand than the original. Thermoluminescence monitoring reveals that storms can erode such beaches far more quickly. This was observed at a Waikiki nourishment project in Hawaii.[8]		Advantages:		Disadvantages:		Beach nourishment has significant impacts on local ecosystems. Nourishment may cause direct mortality to sessile organisms in the target area by burying them under the new sand. Seafloor habitat in both source and target areas are disrupted, e.g., when sand is deposited on coral reefs or when deposited sand hardens. Imported sand may differ in character (chemical makeup, grain size, non-native species) from that of the target environment. Light availability may be reduced, affecting nearby reefs and submerged aquatic vegetation. Imported sand may contain material toxic to local species. Removing material from near-shore environments may destabilize the shoreline, in part by steepening its submerged slope. Related attempts to reduce future erosion may provide a false sense of security that increases development pressure.[citation needed]		Newly deposited sand can harden and complicate nest-digging for turtles. However, nourishment can provide more/better habitat for them, as well as for sea birds and beach flora. Florida addressed the concern that dredge pipes would suck turtles into the pumps by adding a special grill to the dredge pipes.[9]		Nourishment is not the only technique used to address eroding beaches. Others can be used singly or in combination with nourishment, driven by economic, environmental and political considerations.		Human activities such as dam construction can interfere with natural sediment flows (thereby reducing riverine sediment sources.) Construction of littoral barriers such as jetties and deepening of inlets can prevent longshore sediment transport.		The structural approach attempts to prevent erosion. Armoring involves building revetments, seawalls, detached breakwaters, groins, etc. Structures that run parallel to the shore (seawalls or revetments) prevent erosion. While this protects structures, it doesn't protect the beach that is outside the wall. The beach generally disappears over a period that ranges from months to decades.[citation needed]		Groynes and breakwaters that run perpendicular to the shore protect it from erosion. Filling a breakwater with imported sand can stop the breakwater from trapping sand from the littoral stream (the ocean running along the shore.) Otherwise the breakwater may deprive downstream beaches of sand and accelerate erosion there.[citation needed]		Armoring may restrict beach/ocean access, enhance erosion of adjacent shorelines, and requires long-term maintenance.[citation needed]		Managed retreat moves structures and other infrastructure inland as the shoreline erodes. Retreat is more often chosen in areas of rapid erosion and in the presence of little or obsolete development.		Appropriately constructed and sited fences can capture blowing sand, building/restoring sand dunes, and progressively protecting the beach from the wind, and the shore from blowing sand.[citation needed]		All beaches grow and shrink depending on tides, precipitation, wind, waves and current. Wet beaches tend to lose sand. Waves infiltrate dry beaches easily and deposit sandy sediment. Generally a beach is wet during falling tide, because the sea sinks faster than the beach drains. As a result, most erosion happens during falling tide. Beach drainage (beach dewatering) using Pressure Equalizing Modules (PEMs) allow the beach to drain more effectively during falling tide. Fewer hours of wet beach translate to less erosion. Permeable PEM tubes inserted vertically into the foreshore connect the different layers of groundwater. The groundwater enters the PEM tube allowing gravity to conduct it to a coarser sand layer, where it can drain more quickly. The PEM modules are placed in a row from the dune to the mean low waterline. Distance between rows is typically 300 feet (91 m) but this is project-specific. PEM systems come in different sizes. Modules connect layers with varying hydraulic conductivity. Air/water can enter and equalize pressure.[citation needed]		PEMs are minimially invasive, typically covering approximately 0.00005% of the beach.[citation needed] The tubes are below the beach surface, with no visible presence. PEM installations have been installed on beaches in Denmark, Sweden, Malaysia and Florida[citation needed]. The effectiveness of beach dewatering, however, is debatable and has not been proven convincingly on life-sized beaches.[10]		Nourishment is typically a repetitive process, since nourishment mitigates the effects of erosion, but does not remove the causes. A benign environment increases the interval between nourishment projects, reducing costs. Conversely, high erosion rates may render nourishment financially impractical.[11][12]		In many coastal areas, the economic impacts of a wide beach can be substantial. The 10 miles (16 km)–long shoreline fronting Miami Beach, Florida was replenished over the period 1976–1981. The project cost approximately $64,000,000 and revitalized the area's economy. Prior to nourishment, in many places the beach was too narrow to walk along, especially during high tide.[citation needed]		The first nourishment project in the U.S. was constructed at Coney Island, New York in 1922–1923.[13][14]		The setting of a beach nourishment project is key to design and potential performance. Possible settings include a long straight beach, an inlet that may be either natural or modified and a pocket beach. Rocky or seawalled shorelines, that otherwise have no sediment, present unique problems.[citation needed]		Federal and state governments in Mexico have invested about $71 million ($957 million pesos) throughout the state of Quintana Roo in restoring the beaches along Cancun, Playa del Carmen and Cozumel.		Hurricane Wilma hit the beaches of Cancun and the Riviera Maya in 2005. The initial nourishment project was unsuccessful, leading to a second round that began in September 2009 and was scheduled to complete in early 2010. The project designers and the government committed to invest in beach maintenance to address future erosion. Project designers considered factors such as the time of year and sand characteristics such as density. Restoration in Cancun was expected to deliver 1.3 billion US gallons (4,900,000 m3) of sand to replenish 450 meters (1,480 ft) of coastline.		Gold Coast beaches in Queensland, Australia have experienced periods of severe erosion. In 1967 a series of 11 cyclones removed most of the sand from Gold Coast beaches. The Government of Queensland engaged engineers from Delft University in the Netherlands to advise them. The 1971 Delft Report outlined a series of works for Gold Coast Beaches, including beach nourishment and an artificial reef. By 2005 most of the recommendations had been implemented.		The Northern Gold Coast Beach Protection Strategy (NGCBPS) was an A$10 million investment. NGCBPS was implemented between 1992 and 1999 and the works were completed between 1999 and 2003. The project included dredging 3,500,000 cubic metres (4,600,000 cu yd) of compatible sand from the Gold Coast Broadwater and delivering it through a pipeline to nourish 5 kilometers (3.1 mi) of beach between Surfers Paradise and Main Beach. The new sand was stabilized by an artificial reef constructed at Narrowneck out of huge geotextile sand bags. The new reef was designed to improve wave conditions for surfing. A key monitoring program for the NGCBPS is the ARGUS coastal camera system.		The cost/benefit ratio for NGCBPS was conservatively estimated at 75:1 for a A$10 million investment into beach replenishment. The benefits were estimated from a model of lost visitor nights in hotels following previous erosion events. NGCBPS so improved beach health that recovery following minor and moderate storms occurred within weeks. Additional unquantified benefits included lifestyle benefits for residents, additional public open space and improved fishing, diving and surfing conditions.		More than one-quarter of the Netherlands is below sea level and about 81% of the coast consists of sand dune or beach. The shoreline is closely monitored by yearly recording of the cross section at points 250 meters (820 ft) apart, to ensure adequate protection. Where long-term erosion is identified, beach nourishment using high-capacity suction dredgers is deployed.[15][16][17]		Hawaii planned to replenish Waikiki beach in 2010. Budgeted at $2.5 million, the project covered 1,700 feet (520 m) in an attempt to return the beach to its 1985 width. Prior opponents supported this project, because the sand was to come from nearby shoals, reopening a blocked channel and leaving the overall local sand volume unchanged, while closely matching the "new" sand to existing materials. The project planned to apply up to 24,000 cubic yards (18,000 m3) of sand from deposits located 1,500 to 3,000 feet (460 to 910 m) offshore at a depth of 10 to 20 feet (3.0 to 6.1 m). The project was larger than the prior recycling effort in 2006-07, which moved 10,000 cubic yards (7,600 m3).[18]		Maui, Hawaii illustrated the complexities of even small-scale nourishment projects. A project at Sugar Cove transported upland sand to the beach. The sand allegedly was finer than the original sand and contained excess silt that enveloped coral, smothering it and killing the small animals that lived in and around it. As in other projects, on-shore sand availability was limited, forcing consideration of more expensive offshore sources.[19]		A second project, along Stable Road, that attempted to slow rather than halt erosion, was stopped halfway toward its goal of adding 10,000 cubic yards (7,600 m3) of sand. The beaches had been retreating at a "comparatively fast rate" for half a century. The restoration was complicated by the presence of old seawalls, groins, piles of rocks and other structures.[19]		This project used sand-filled geotextile tube groins that were originally to remain in place for up to 3 years. A pipe was to transport sand from deeper water to the beach. The pipe was anchored by concrete blocks attached by fibre straps. A video showed the blocks bouncing off the coral in the current, killing whatever they touched. In places the straps broke, allowing the pipe to move across the reef, "planing it down". Bad weather exacerbated the damaging movement and killed the project.[20] The smooth, cylindrical geotextile tubes could be difficult to climb over before they were covered by sand.[19]		Supporters claimed that 2010's seasonal summer erosion was less than in prior years, although the beach was narrower after the restoration ended than in 2008. Authorities were studying whether to require the project to remove the groins immediately. Potential alternatives to geotextile tubes for moving sand included floating dredges and/or trucking in sand dredged offshore.[19]		A final consideration was sea level rise and that Maui was sinking under its own weight. Both Maui and Hawaii Island surround massive mountains (Haleakala, Mauna Loa, and Mauna Kea) and were expanding a giant dimple in the ocean floor, some 30,000 feet (9,100 m) below the mountain summits.[19]		90 PEMs were Installed in February 2008 at Hillsboro Beach. After 18 months the beach had expanded significantly. Most of the PEMs were removed in 2011. Beach volume expanded by 38,500 cubic yards over 3 years compared to an average annual loss of 21,000.[21]		The beach in Gold Coast was built as an artificial beach in the 1990s with HK$60m. Sands are supplied periodically, especially after typhoons, to keep the beach viable.[22]		Nourishment projects usually involve physical, environmental and economic objectives.		Typical physical measures include dry beach width/height, post-storm sand volume, post-storm damage avoidance assessments and aqueous sand volume.		Environmental measures include marine life distribution, habitat and population counts.		Economic impacts include recreation, tourism, flood and "disaster" prevention.		Many nourishment projects are advocated via economic impact studies that rely on additional tourist expenditure. This approach is however unsatisfactory. First, nothing proves that these expenditures are incremental (they could shift expenditures from other nearby areas). Second, economic impact does not account for costs and benefits for all economic agents, as cost benefit analysis does.[23] Techniques for incorporating nourishment projects into flood insurance costs and disaster assistance remain controversial.[24]		The performance of a beach nourishment project is most predictable for a long, straight shoreline without the complications of inlets or engineered structures. In addition, predictability is better for overall performance, e.g., average shoreline change, rather than shoreline change at a specific location.[citation needed]		Nourishment can affect eligibility in the U.S. National Flood Insurance Program and federal disaster assistance.[citation needed]		Nourishment may have the unintended consequence of promoting coastal development, which increases risk of other coastal hazards.[25]		
An archipelago (/ɑːrkᵻˈpɛləɡoʊ/ ( listen) ark-i-PEL-ə-goh), sometimes called an island group or island chain, is a chain, cluster or collection of islands, or sometimes a sea containing a small number of scattered islands.		The word archipelago is derived from the Greek ἄρχι- – arkhi- ("chief") and πέλαγος – pélagos ("sea") through the Italian arcipelago. In Italian, possibly following a tradition of antiquity, the Archipelago (from medieval Greek *ἀρχιπέλαγος and Latin archipelagus) was the proper name for the Aegean Sea and, later, usage shifted to refer to the Aegean Islands (since the sea is remarkable for its large number of islands).						Archipelagos may be found isolated in large amounts of water or neighbouring a large land mass. For example, Scotland has more than 700 islands surrounding its mainland which form an archipelago. Archipelagos are often volcanic, forming along island arcs generated by subduction zones or hotspots, but may also be the result of erosion, deposition, and land elevation. Depending on their geological origin, islands forming archipelagos can be referred to as 'oceanic islands', 'continental fragments', and 'continental islands'.[1] Oceanic islands are mainly of volcanic origin. Continental fragments correspond to land masses that have separated from a continental mass due to tectonic displacement. Finally, sets of islands formed close to the coast of a continent are considered continental archipelagos when they form part of the same continental shelf so islands are just exposed continental shelf.		Indonesia, Japan, Taiwan, the Philippines, New Zealand, Maldives, the Bahamas, Greece, Hawaii, the Polynesian islands and the Azores are examples of well-known archipelagos. The largest archipelagic state in the world by area and population is Indonesia.[2] The archipelago with the most islands is the Swedish East Coast Archipelago, which contains the Stockholm archipelago, which, in turn, connects to the world's second largest archipelago, the Archipelago Sea in Finland.[3]		
The British Empire comprised the dominions, colonies, protectorates, mandates and other territories ruled or administered by the United Kingdom and its predecessor states. It originated with the overseas possessions and trading posts established by England between the late 16th and early 18th centuries. At its height, it was the largest empire in history and, for over a century, was the foremost global power.[1] By 1913, the British Empire held sway over 412 million people, 7001230000000000000♠23% of the world population at the time,[2] and by 1920, it covered 35,500,000 km2 (13,700,000 sq mi),[3] 7001240000000000000♠24% of the Earth's total land area.[4] As a result, its political, legal, linguistic and cultural legacy is widespread. At the peak of its power, the phrase "the empire on which the sun never sets" was often used to describe the British Empire, because its expanse around the globe meant that the sun was always shining on at least one of its territories.		During the Age of Discovery in the 15th and 16th centuries, Portugal and Spain pioneered European exploration of the globe, and in the process established large overseas empires. Envious of the great wealth these empires generated,[5] England, France, and the Netherlands began to establish colonies and trade networks of their own in the Americas and Asia.[6] A series of wars in the 17th and 18th centuries with the Netherlands and France left England and then, following union between England and Scotland in 1707, Great Britain, the dominant colonial power in North America. It then became the dominant power in the Indian subcontinent after the East India Company's conquest of Mughal Bengal at the Battle of Plassey in 1757.		The independence of the Thirteen Colonies in North America in 1783 after the American War of Independence caused Britain to lose some of its oldest and most populous colonies. British attention soon turned towards Asia, Africa, and the Pacific. After the defeat of France in the Revolutionary and Napoleonic Wars (1792–1815), Britain emerged as the principal naval and imperial power of the 19th century.[7] Unchallenged at sea, British dominance was later described as Pax Britannica ("British Peace"), a period of relative peace in Europe and the world (1815–1914) during which the British Empire became the global hegemon and adopted the role of global policeman.[8][9][10][11] In the early 19th century, the Industrial Revolution began to transform Britain; by the time of the Great Exhibition in 1851 the country was described as the "workshop of the world".[12] The British Empire expanded to include most of India, large parts of Africa and many other territories throughout the world. Alongside the formal control that Britain exerted over its own colonies, its dominance of much of world trade meant that it effectively controlled the economies of many regions, such as Asia and Latin America.[13][14]		In Britain, political attitudes favoured free trade and laissez-faire policies and a gradual widening of the voting franchise. During the 19th Century, Britain's population increased at a dramatic rate, accompanied by rapid urbanisation, which caused significant social and economic stresses.[15] To seek new markets and sources of raw materials, the Conservative Party under Benjamin Disraeli launched a period of imperialist expansion in Egypt, South Africa, and elsewhere. Canada, Australia, and New Zealand became self-governing dominions.[16]		By the start of the 20th century, Germany and the United States had begun to challenge Britain's economic lead. Subsequent military and economic tensions between Britain and Germany were major causes of the First World War, during which Britain relied heavily upon its empire. The conflict placed enormous strain on the military, financial and manpower resources of Britain. Although the British Empire achieved its largest territorial extent immediately after World War I, Britain was no longer the world's pre-eminent industrial or military power. In the Second World War, Britain's colonies in Southeast Asia were occupied by Imperial Japan. Despite the final victory of Britain and its allies, the damage to British prestige helped to accelerate the decline of the empire. India, Britain's most valuable and populous possession, achieved independence as part of a larger decolonisation movement in which Britain granted independence to most territories of the empire. The transfer of Hong Kong to China in 1997 marked for many the end of the British Empire.[17][18][19][20] Fourteen overseas territories remain under British sovereignty.		After independence, many former British colonies joined the Commonwealth of Nations, a free association of independent states. The United Kingdom is now one of 16 Commonwealth nations, a grouping known informally as the Commonwealth realms, that share a monarch, Queen Elizabeth II.						The foundations of the British Empire were laid when England and Scotland were separate kingdoms. In 1496, King Henry VII of England, following the successes of Spain and Portugal in overseas exploration, commissioned John Cabot to lead a voyage to discover a route to Asia via the North Atlantic.[6] Cabot sailed in 1497, five years after the European discovery of America, but he made landfall on the coast of Newfoundland, and, mistakenly believing (like Christopher Columbus) that he had reached Asia,[21] there was no attempt to found a colony. Cabot led another voyage to the Americas the following year but nothing was ever heard of his ships again.[22]		No further attempts to establish English colonies in the Americas were made until well into the reign of Queen Elizabeth I, during the last decades of the 16th century.[23] In the meantime the Protestant Reformation had turned England and Catholic Spain into implacable enemies.[6] In 1562, the English Crown encouraged the privateers John Hawkins and Francis Drake to engage in slave-raiding attacks against Spanish and Portuguese ships off the coast of West Africa[24] with the aim of breaking into the Atlantic slave trade. This effort was rebuffed and later, as the Anglo-Spanish Wars intensified, Elizabeth I gave her blessing to further privateering raids against Spanish ports in the Americas and shipping that was returning across the Atlantic, laden with treasure from the New World.[25] At the same time, influential writers such as Richard Hakluyt and John Dee (who was the first to use the term "British Empire")[26] were beginning to press for the establishment of England's own empire. By this time, Spain had become the dominant power in the Americas and was exploring the Pacific Ocean, Portugal had established trading posts and forts from the coasts of Africa and Brazil to China, and France had begun to settle the Saint Lawrence River area, later to become New France.[27]		Although England trailed behind other European powers in establishing overseas colonies, it had been engaged during the 16th century in the settlement of Ireland with Protestants from England and Scotland, drawing on precedents dating back to the Norman invasion of Ireland in 1169.[28][29] Several people who helped establish the Plantations of Ireland also played a part in the early colonisation of North America, particularly a group known as the West Country men.[30]		In 1578, Elizabeth I granted a patent to Humphrey Gilbert for discovery and overseas exploration.[31] That year, Gilbert sailed for the Caribbean with the intention of engaging in piracy and establishing a colony in North America, but the expedition was aborted before it had crossed the Atlantic.[32][33] In 1583 he embarked on a second attempt, on this occasion to the island of Newfoundland whose harbour he formally claimed for England, although no settlers were left behind. Gilbert did not survive the return journey to England, and was succeeded by his half-brother, Walter Raleigh, who was granted his own patent by Elizabeth in 1584. Later that year, Raleigh founded the Roanoke Colony on the coast of present-day North Carolina, but lack of supplies caused the colony to fail.[34]		In 1603, James VI, King of Scots, ascended (as James I) to the English throne and in 1604 negotiated the Treaty of London, ending hostilities with Spain. Now at peace with its main rival, English attention shifted from preying on other nations' colonial infrastructures to the business of establishing its own overseas colonies.[35] The British Empire began to take shape during the early 17th century, with the English settlement of North America and the smaller islands of the Caribbean, and the establishment of joint-stock companies, most notably the East India Company, to administer colonies and overseas trade. This period, until the loss of the Thirteen Colonies after the American War of Independence towards the end of the 18th century, has subsequently been referred to by some historians as the "First British Empire".[36]		The Caribbean initially provided England's most important and lucrative colonies,[37] but not before several attempts at colonisation failed. An attempt to establish a colony in Guiana in 1604 lasted only two years, and failed in its main objective to find gold deposits.[38] Colonies in St Lucia (1605) and Grenada (1609) also rapidly folded, but settlements were successfully established in St. Kitts (1624), Barbados (1627) and Nevis (1628).[39] The colonies soon adopted the system of sugar plantations successfully used by the Portuguese in Brazil, which depended on slave labour, and—at first—Dutch ships, to sell the slaves and buy the sugar.[40] To ensure that the increasingly healthy profits of this trade remained in English hands, Parliament decreed in 1651 that only English ships would be able to ply their trade in English colonies. This led to hostilities with the United Dutch Provinces—a series of Anglo-Dutch Wars—which would eventually strengthen England's position in the Americas at the expense of the Dutch.[41] In 1655, England annexed the island of Jamaica from the Spanish, and in 1666 succeeded in colonising the Bahamas.[42]		England's first permanent settlement in the Americas was founded in 1607 in Jamestown, led by Captain John Smith and managed by the Virginia Company. Bermuda was settled and claimed by England as a result of the 1609 shipwreck of the Virginia Company's flagship, and in 1615 was turned over to the newly formed Somers Isles Company.[43] The Virginia Company's charter was revoked in 1624 and direct control of Virginia was assumed by the crown, thereby founding the Colony of Virginia.[44] The London and Bristol Company was created in 1610 with the aim of creating a permanent settlement on Newfoundland, but was largely unsuccessful.[45] In 1620, Plymouth was founded as a haven for Puritan religious separatists, later known as the Pilgrims.[46] Fleeing from religious persecution would become the motive of many English would-be colonists to risk the arduous trans-Atlantic voyage: Maryland was founded as a haven for Roman Catholics (1634), Rhode Island (1636) as a colony tolerant of all religions and Connecticut (1639) for Congregationalists. The Province of Carolina was founded in 1663. With the surrender of Fort Amsterdam in 1664, England gained control of the Dutch colony of New Netherland, renaming it New York. This was formalised in negotiations following the Second Anglo-Dutch War, in exchange for Suriname.[47] In 1681, the colony of Pennsylvania was founded by William Penn. The American colonies were less financially successful than those of the Caribbean, but had large areas of good agricultural land and attracted far larger numbers of English emigrants who preferred their temperate climates.[48]		In 1670, Charles II incorporated by royal charter the Hudson's Bay Company (HBC), granting it a monopoly on the fur trade in the area known as Rupert's Land, which would later form a large proportion of the Dominion of Canada. Forts and trading posts established by the HBC were frequently the subject of attacks by the French, who had established their own fur trading colony in adjacent New France.[49]		Two years later, the Royal African Company was inaugurated, receiving from King Charles a monopoly of the trade to supply slaves to the British colonies of the Caribbean.[50] From the outset, slavery was the basis of the British Empire in the West Indies. Until the abolition of its slave trade in 1807, Britain was responsible for the transportation of 3.5 million African slaves to the Americas, a third of all slaves transported across the Atlantic.[51] To facilitate this trade, forts were established on the coast of West Africa, such as James Island, Accra and Bunce Island. In the British Caribbean, the percentage of the population of African descent rose from 25% in 1650 to around 80% in 1780, and in the Thirteen Colonies from 10% to 40% over the same period (the majority in the southern colonies).[52] For the slave traders, the trade was extremely profitable, and became a major economic mainstay for such western British cities as Bristol and Liverpool, which formed the third corner of the triangular trade with Africa and the Americas. For the transported, harsh and unhygienic conditions on the slaving ships and poor diets meant that the average mortality rate during the Middle Passage was one in seven.[53]		In 1695, the Parliament of Scotland granted a charter to the Company of Scotland, which established a settlement in 1698 on the Isthmus of Panama. Besieged by neighbouring Spanish colonists of New Granada, and afflicted by malaria, the colony was abandoned two years later. The Darien scheme was a financial disaster for Scotland — a quarter of Scottish capital[54] was lost in the enterprise — and ended Scottish hopes of establishing its own overseas empire. The episode also had major political consequences, persuading the governments of both England and Scotland of the merits of a union of countries, rather than just crowns.[55] This occurred in 1707 with the Treaty of Union, establishing the Kingdom of Great Britain.		At the end of the 16th century, England and the Netherlands began to challenge Portugal's monopoly of trade with Asia, forming private joint-stock companies to finance the voyages—the English, later British, East India Company and the Dutch East India Company, chartered in 1600 and 1602 respectively. The primary aim of these companies was to tap into the lucrative spice trade, an effort focused mainly on two regions; the East Indies archipelago, and an important hub in the trade network, India. There, they competed for trade supremacy with Portugal and with each other.[56] Although England ultimately eclipsed the Netherlands as a colonial power, in the short term the Netherlands' more advanced financial system[57] and the three Anglo-Dutch Wars of the 17th century left it with a stronger position in Asia. Hostilities ceased after the Glorious Revolution of 1688 when the Dutch William of Orange ascended the English throne, bringing peace between the Netherlands and England. A deal between the two nations left the spice trade of the East Indies archipelago to the Netherlands and the textiles industry of India to England, but textiles soon overtook spices in terms of profitability, and by 1720, in terms of sales, the British company had overtaken the Dutch.[57]		Peace between England and the Netherlands in 1688 meant that the two countries entered the Nine Years' War as allies, but the conflict—waged in Europe and overseas between France, Spain and the Anglo-Dutch alliance—left the English a stronger colonial power than the Dutch, who were forced to devote a larger proportion of their military budget on the costly land war in Europe.[58] The 18th century saw England (after 1707, Britain) rise to be the world's dominant colonial power, and France becoming its main rival on the imperial stage.[59]		The death of Charles II of Spain in 1700 and his bequeathal of Spain and its colonial empire to Philippe of Anjou, a grandson of the King of France, raised the prospect of the unification of France, Spain and their respective colonies, an unacceptable state of affairs for England and the other powers of Europe.[60] In 1701, England, Portugal and the Netherlands sided with the Holy Roman Empire against Spain and France in the War of the Spanish Succession, which lasted until 1714.		At the concluding Treaty of Utrecht, Philip renounced his and his descendants' right to the French throne and Spain lost its empire in Europe.[60] The British Empire was territorially enlarged: from France, Britain gained Newfoundland and Acadia, and from Spain, Gibraltar and Minorca. Gibraltar became a critical naval base and allowed Britain to control the Atlantic entry and exit point to the Mediterranean. Spain also ceded the rights to the lucrative asiento (permission to sell slaves in Spanish America) to Britain.[61]		During the middle decades of the 18th century, there were several outbreaks of military conflict on the Indian subcontinent, the Carnatic Wars, as the English East India Company (often known simply as "the Company") and its French counterpart, the French East India Company (Compagnie française des Indes orientales), struggled alongside local rulers to fill the vacuum that had been left by the decline of the Mughal Empire. The Battle of Plassey in 1757, in which the British, led by Robert Clive, defeated the Nawab of Bengal and his French allies, left the British East India Company in control of Bengal and as the major military and political power in India.[62] France was left control of its enclaves but with military restrictions and an obligation to support British client states, ending French hopes of controlling India.[63] In the following decades the British East India Company gradually increased the size of the territories under its control, either ruling directly or via local rulers under the threat of force from the British Indian Army, the vast majority of which was composed of Indian sepoys.[64]		The British and French struggles in India became but one theatre of the global Seven Years' War (1756–1763) involving France, Britain and the other major European powers. The signing of the Treaty of Paris (1763) had important consequences for the future of the British Empire. In North America, France's future as a colonial power effectively ended with the recognition of British claims to Rupert's Land,[49] and the ceding of New France to Britain (leaving a sizeable French-speaking population under British control) and Louisiana to Spain. Spain ceded Florida to Britain. Along with its victory over France in India, the Seven Years' War therefore left Britain as the world's most powerful maritime power.[65]		During the 1760s and early 1770s, relations between the Thirteen Colonies and Britain became increasingly strained, primarily because of resentment of the British Parliament's attempts to govern and tax American colonists without their consent.[66] This was summarised at the time by the slogan "No taxation without representation", a perceived violation of the guaranteed Rights of Englishmen. The American Revolution began with rejection of Parliamentary authority and moves towards self-government. In response Britain sent troops to reimpose direct rule, leading to the outbreak of war in 1775. The following year, in 1776, the United States declared independence. The entry of France into the war in 1778 tipped the military balance in the Americans' favour and after a decisive defeat at Yorktown in 1781, Britain began negotiating peace terms. American independence was acknowledged at the Peace of Paris in 1783.[67]		The loss of such a large portion of British America, at the time Britain's most populous overseas possession, is seen by some historians as the event defining the transition between the "first" and "second" empires,[68] in which Britain shifted its attention away from the Americas to Asia, the Pacific and later Africa. Adam Smith's Wealth of Nations, published in 1776, had argued that colonies were redundant, and that free trade should replace the old mercantilist policies that had characterised the first period of colonial expansion, dating back to the protectionism of Spain and Portugal.[65][69] The growth of trade between the newly independent United States and Britain after 1783 seemed to confirm Smith's view that political control was not necessary for economic success.[70][71]		The war to the south influenced British policy in Canada, where between 40,000 and 100,000[72] defeated Loyalists had migrated from the new United States following independence.[73] The 14,000 Loyalists who went to the Saint John and Saint Croix river valleys, then part of Nova Scotia, felt too far removed from the provincial government in Halifax, so London split off New Brunswick as a separate colony in 1784.[74] The Constitutional Act of 1791 created the provinces of Upper Canada (mainly English-speaking) and Lower Canada (mainly French-speaking) to defuse tensions between the French and British communities, and implemented governmental systems similar to those employed in Britain, with the intention of asserting imperial authority and not allowing the sort of popular control of government that was perceived to have led to the American Revolution.[75]		Tensions between Britain and the United States escalated again during the Napoleonic Wars, as Britain tried to cut off American trade with France and boarded American ships to impress men into the Royal Navy. The US declared war, the War of 1812, and invaded Canadian territory. In response Britain invaded the US, but the pre-war boundaries were reaffirmed by the 1814 Treaty of Ghent, ensuring Canada's future would be separate from that of the United States.[76][77]		Since 1718, transportation to the American colonies had been a penalty for various offences in Britain, with approximately one thousand convicts transported per year across the Atlantic.[78] Forced to find an alternative location after the loss of the Thirteen Colonies in 1783, the British government turned to the newly discovered lands of Australia.[79] The western coast of Australia had been discovered for Europeans by the Dutch explorer Willem Janszoon in 1606 and was later named New Holland by the Dutch East India Company,[80] but there was no attempt to colonise it. In 1770 James Cook discovered the eastern coast of Australia while on a scientific voyage to the South Pacific Ocean, claimed the continent for Britain, and named it New South Wales.[81] In 1778, Joseph Banks, Cook's botanist on the voyage, presented evidence to the government on the suitability of Botany Bay for the establishment of a penal settlement, and in 1787 the first shipment of convicts set sail, arriving in 1788.[82] Britain continued to transport convicts to New South Wales until 1840.[83] The Australian colonies became profitable exporters of wool and gold,[84] mainly because of gold rushes in the colony of Victoria, making its capital Melbourne for a time the richest city in the world[85] and the second largest city (after London) in the British Empire.[86]		During his voyage, Cook also visited New Zealand, first discovered by Dutch explorer Abel Tasman in 1642, and claimed the North and South islands for the British crown in 1769 and 1770 respectively. Initially, interaction between the indigenous Māori population and Europeans was limited to the trading of goods. European settlement increased through the early decades of the 19th century, with numerous trading stations established, especially in the North. In 1839, the New Zealand Company announced plans to buy large tracts of land and establish colonies in New Zealand. On 6 February 1840, Captain William Hobson and around 40 Maori chiefs signed the Treaty of Waitangi.[87] This treaty is considered by many to be New Zealand's founding document,[88] but differing interpretations of the Maori and English versions of the text[89] have meant that it continues to be a source of dispute.[90]		Britain was challenged again by France under Napoleon, in a struggle that, unlike previous wars, represented a contest of ideologies between the two nations.[91] It was not only Britain's position on the world stage that was at risk: Napoleon threatened to invade Britain itself, just as his armies had overrun many countries of continental Europe.		The Napoleonic Wars were therefore ones in which Britain invested large amounts of capital and resources to win. French ports were blockaded by the Royal Navy, which won a decisive victory over a Franco-Spanish fleet at Trafalgar in 1805. Overseas colonies were attacked and occupied, including those of the Netherlands, which was annexed by Napoleon in 1810. France was finally defeated by a coalition of European armies in 1815.[92] Britain was again the beneficiary of peace treaties: France ceded the Ionian Islands, Malta (which it had occupied in 1797 and 1798 respectively), Mauritius, Saint Lucia, and Tobago; Spain ceded Trinidad; the Netherlands Guyana, and the Cape Colony. Britain returned Guadeloupe, Martinique, French Guiana, and Réunion to France, and Java and Suriname to the Netherlands, while gaining control of Ceylon (1795–1815).[93]		With the advent of the Industrial Revolution, goods produced by slavery became less important to the British economy.[94] Added to this was the cost of suppressing regular slave rebellions. With support from the British abolitionist movement, Parliament enacted the Slave Trade Act in 1807, which abolished the slave trade in the empire. In 1808, Sierra Leone was designated an official British colony for freed slaves.[95] Parliamentary reform in 1832 saw the influence of the West India Committee decline. The Slavery Abolition Act, passed the following year, abolished slavery in the British Empire on 1 August 1834, finally bringing the Empire into line with the law in the UK (with the exception of St. Helena, Ceylon and the territories administered by the East India Company, though these exclusions were later repealed). Under the Act, slaves were granted full emancipation after a period of four to six years of "apprenticeship".[96] The British government compensated slave-owners.		Between 1815 and 1914, a period referred to as Britain's "imperial century" by some historians,[97][98] around 10,000,000 square miles (26,000,000 km2) of territory and roughly 400 million people were added to the British Empire.[99] Victory over Napoleon left Britain without any serious international rival, other than Russia in Central Asia.[100] Unchallenged at sea, Britain adopted the role of global policeman, a state of affairs later known as the Pax Britannica,[9] and a foreign policy of "splendid isolation".[101] Alongside the formal control it exerted over its own colonies, Britain's dominant position in world trade meant that it effectively controlled the economies of many countries, such as China, Argentina and Siam, which has been described by some historians as an "Informal Empire".[102][103]		British imperial strength was underpinned by the steamship and the telegraph, new technologies invented in the second half of the 19th century, allowing it to control and defend the empire. By 1902, the British Empire was linked together by a network of telegraph cables, called the All Red Line.[104]		The East India Company drove the expansion of the British Empire in Asia. The Company's army had first joined forces with the Royal Navy during the Seven Years' War, and the two continued to co-operate in arenas outside India: the eviction of the French from Egypt (1799),[105] the capture of Java from the Netherlands (1811), the acquisition of Penang Island (1786), Singapore (1819) and Malacca (1824), and the defeat of Burma (1826).[100]		From its base in India, the Company had also been engaged in an increasingly profitable opium export trade to China since the 1730s. This trade, illegal since it was outlawed by the Qing dynasty in 1729, helped reverse the trade imbalances resulting from the British imports of tea, which saw large outflows of silver from Britain to China.[106] In 1839, the confiscation by the Chinese authorities at Canton of 20,000 chests of opium led Britain to attack China in the First Opium War, and resulted in the seizure by Britain of Hong Kong Island, at that time a minor settlement.[107]		During the late 18th and early 19th centuries the British Crown began to assume an increasingly large role in the affairs of the Company. A series of Acts of Parliament were passed, including the Regulating Act of 1773, Pitt's India Act of 1784 and the Charter Act of 1813 which regulated the Company's affairs and established the sovereignty of the Crown over the territories that it had acquired.[108] The Company's eventual end was precipitated by the Indian Rebellion, a conflict that had begun with the mutiny of sepoys, Indian troops under British officers and discipline.[109] The rebellion took six months to suppress, with heavy loss of life on both sides. The following year the British government dissolved the Company and assumed direct control over India through the Government of India Act 1858, establishing the British Raj, where an appointed governor-general administered India and Queen Victoria was crowned the Empress of India.[110] India became the empire's most valuable possession, "the Jewel in the Crown", and was the most important source of Britain's strength.[111]		A series of serious crop failures in the late 19th century led to widespread famines on the subcontinent in which it is estimated that over 15 million people died. The East India Company had failed to implement any coordinated policy to deal with the famines during its period of rule. Later, under direct British rule, commissions were set up after each famine to investigate the causes and implement new policies, which took until the early 1900s to have an effect.[112]		During the 19th century, Britain and the Russian Empire vied to fill the power vacuums that had been left by the declining Ottoman Empire, Qajar dynasty and Qing Dynasty. This rivalry in Central Asia came to be known as the "Great Game".[113] As far as Britain was concerned, defeats inflicted by Russia on Persia and Turkey demonstrated its imperial ambitions and capabilities and stoked fears in Britain of an overland invasion of India.[114] In 1839, Britain moved to pre-empt this by invading Afghanistan, but the First Anglo-Afghan War was a disaster for Britain.[115]		When Russia invaded the Turkish Balkans in 1853, fears of Russian dominance in the Mediterranean and Middle East led Britain and France to invade the Crimean Peninsula to destroy Russian naval capabilities.[115] The ensuing Crimean War (1854–56), which involved new techniques of modern warfare,[116] was the only global war fought between Britain and another imperial power during the Pax Britannica and was a resounding defeat for Russia.[115] The situation remained unresolved in Central Asia for two more decades, with Britain annexing Baluchistan in 1876 and Russia annexing Kirghizia, Kazakhstan, and Turkmenistan. For a while it appeared that another war would be inevitable, but the two countries reached an agreement on their respective spheres of influence in the region in 1878 and on all outstanding matters in 1907 with the signing of the Anglo-Russian Entente.[117] The destruction of the Russian Navy by the Japanese at the Battle of Port Arthur during the Russo-Japanese War of 1904–05 also limited its threat to the British.[118]		The Dutch East India Company had founded the Cape Colony on the southern tip of Africa in 1652 as a way station for its ships travelling to and from its colonies in the East Indies. Britain formally acquired the colony, and its large Afrikaner (or Boer) population in 1806, having occupied it in 1795 to prevent its falling into French hands during the Flanders Campaign.[119] British immigration began to rise after 1820, and pushed thousands of Boers, resentful of British rule, northwards to found their own—mostly short-lived—independent republics, during the Great Trek of the late 1830s and early 1840s.[120] In the process the Voortrekkers clashed repeatedly with the British, who had their own agenda with regard to colonial expansion in South Africa and to the various native African polities, including those of the Sotho and the Zulu nations. Eventually the Boers established two republics which had a longer lifespan: the South African Republic or Transvaal Republic (1852–77; 1881–1902) and the Orange Free State (1854–1902).[121] In 1902 Britain occupied both republics, concluding a treaty with the two Boer Republics following the Second Boer War (1899–1902).[122]		In 1869 the Suez Canal opened under Napoleon III, linking the Mediterranean with the Indian Ocean. Initially the Canal was opposed by the British;[123] but once opened, its strategic value was quickly recognised and became the "jugular vein of the Empire".[124] In 1875, the Conservative government of Benjamin Disraeli bought the indebted Egyptian ruler Isma'il Pasha's 44% shareholding in the Suez Canal for £4 million (equivalent to £340 million in 2015). Although this did not grant outright control of the strategic waterway, it did give Britain leverage. Joint Anglo-French financial control over Egypt ended in outright British occupation in 1882.[125] The French were still majority shareholders and attempted to weaken the British position,[126] but a compromise was reached with the 1888 Convention of Constantinople, which made the Canal officially neutral territory.[127]		With competitive French, Belgian and Portuguese activity in the lower Congo River region undermining orderly colonisation of tropical Africa, the Berlin Conference of 1884–85 was held to regulate the competition between the European powers in what was called the "Scramble for Africa" by defining "effective occupation" as the criterion for international recognition of territorial claims.[128] The scramble continued into the 1890s, and caused Britain to reconsider its decision in 1885 to withdraw from Sudan. A joint force of British and Egyptian troops defeated the Mahdist Army in 1896, and rebuffed an attempted French invasion at Fashoda in 1898. Sudan was nominally made an Anglo-Egyptian condominium, but a British colony in reality.[129]		British gains in Southern and East Africa prompted Cecil Rhodes, pioneer of British expansion in Southern Africa, to urge a "Cape to Cairo" railway linking the strategically important Suez Canal to the mineral-rich south of the continent.[130] During the 1880s and 1890s, Rhodes, with his privately owned British South Africa Company, occupied and annexed territories subsequently named after him, Rhodesia.[131]		The path to independence for the white colonies of the British Empire began with the 1839 Durham Report, which proposed unification and self-government for Upper and Lower Canada, as a solution to political unrest which had erupted in armed rebellions in 1837.[132] This began with the passing of the Act of Union in 1840, which created the Province of Canada. Responsible government was first granted to Nova Scotia in 1848, and was soon extended to the other British North American colonies. With the passage of the British North America Act, 1867 by the British Parliament, Upper and Lower Canada, New Brunswick and Nova Scotia were formed into the Dominion of Canada, a confederation enjoying full self-government with the exception of international relations.[133] Australia and New Zealand achieved similar levels of self-government after 1900, with the Australian colonies federating in 1901.[134] The term "dominion status" was officially introduced at the Colonial Conference of 1907.[135]		The last decades of the 19th century saw concerted political campaigns for Irish home rule. Ireland had been united with Britain into the United Kingdom of Great Britain and Ireland with the Act of Union 1800 after the Irish Rebellion of 1798, and had suffered a severe famine between 1845 and 1852. Home rule was supported by the British Prime minister, William Gladstone, who hoped that Ireland might follow in Canada's footsteps as a Dominion within the empire, but his 1886 Home Rule bill was defeated in Parliament. Although the bill, if passed, would have granted Ireland less autonomy within the UK than the Canadian provinces had within their own federation,[136] many MPs feared that a partially independent Ireland might pose a security threat to Great Britain or mark the beginning of the break-up of the empire.[137] A second Home Rule bill was also defeated for similar reasons.[137] A third bill was passed by Parliament in 1914, but not implemented because of the outbreak of the First World War leading to the 1916 Easter Rising.[138]		By the turn of the 20th century, fears had begun to grow in Britain that it would no longer be able to defend the metropole and the entirety of the empire while at the same time maintaining the policy of "splendid isolation".[139] Germany was rapidly rising as a military and industrial power and was now seen as the most likely opponent in any future war. Recognising that it was overstretched in the Pacific[140] and threatened at home by the Imperial German Navy, Britain formed an alliance with Japan in 1902 and with its old enemies France and Russia in 1904 and 1907, respectively.[141]		Britain's fears of war with Germany were realised in 1914 with the outbreak of the First World War. Britain quickly invaded and occupied most of Germany's overseas colonies in Africa. In the Pacific, Australia and New Zealand occupied German New Guinea and Samoa respectively. Plans for a post-war division of the Ottoman Empire, which had joined the war on Germany's side, were secretly drawn up by Britain and France under the 1916 Sykes–Picot Agreement. This agreement was not divulged to the Sharif of Mecca, who the British had been encouraging to launch an Arab revolt against their Ottoman rulers, giving the impression that Britain was supporting the creation of an independent Arab state.[142]		The British declaration of war on Germany and its allies also committed the colonies and Dominions, which provided invaluable military, financial and material support. Over 2.5 million men served in the armies of the Dominions, as well as many thousands of volunteers from the Crown colonies.[143] The contributions of Australian and New Zealand troops during the 1915 Gallipoli Campaign against the Ottoman Empire had a great impact on the national consciousness at home, and marked a watershed in the transition of Australia and New Zealand from colonies to nations in their own right. The countries continue to commemorate this occasion on Anzac Day. Canadians viewed the Battle of Vimy Ridge in a similar light.[144] The important contribution of the Dominions to the war effort was recognised in 1917 by the British Prime Minister David Lloyd George when he invited each of the Dominion Prime Ministers to join an Imperial War Cabinet to co-ordinate imperial policy.[145]		Under the terms of the concluding Treaty of Versailles signed in 1919, the empire reached its greatest extent with the addition of 1,800,000 square miles (4,700,000 km2) and 13 million new subjects.[146] The colonies of Germany and the Ottoman Empire were distributed to the Allied powers as League of Nations mandates. Britain gained control of Palestine, Transjordan, Iraq, parts of Cameroon and Togoland, and Tanganyika. The Dominions themselves also acquired mandates of their own: the Union of South Africa gained South West Africa (modern-day Namibia), Australia gained New Guinea, and New Zealand Western Samoa. Nauru was made a combined mandate of Britain and the two Pacific Dominions.[147]		The changing world order that the war had brought about, in particular the growth of the United States and Japan as naval powers, and the rise of independence movements in India and Ireland, caused a major reassessment of British imperial policy.[148] Forced to choose between alignment with the United States or Japan, Britain opted not to renew its Japanese alliance and instead signed the 1922 Washington Naval Treaty, where Britain accepted naval parity with the United States.[149] This decision was the source of much debate in Britain during the 1930s[150] as militaristic governments took hold in Japan and Germany helped in part by the Great Depression, for it was feared that the empire could not survive a simultaneous attack by both nations.[151] The issue of the empire's security was a serious concern in Britain, as it was vital to the British economy.[152]		In 1919, the frustrations caused by delays to Irish home rule led the MPs of Sinn Féin, a pro-independence party that had won a majority of the Irish seats in the 1918 British general election, to establish an independent parliament in Dublin, at which Irish independence was declared. The Irish Republican Army simultaneously began a guerrilla war against the British administration.[153] The Anglo-Irish War ended in 1921 with a stalemate and the signing of the Anglo-Irish Treaty, creating the Irish Free State, a Dominion within the British Empire, with effective internal independence but still constitutionally linked with the British Crown.[154] Northern Ireland, consisting of six of the 32 Irish counties which had been established as a devolved region under the 1920 Government of Ireland Act, immediately exercised its option under the treaty to retain its existing status within the United Kingdom.[155]		A similar struggle began in India when the Government of India Act 1919 failed to satisfy demand for independence.[156] Concerns over communist and foreign plots following the Ghadar Conspiracy ensured that war-time strictures were renewed by the Rowlatt Acts. This led to tension,[157] particularly in the Punjab region, where repressive measures culminated in the Amritsar Massacre. In Britain public opinion was divided over the morality of the massacre, between those who saw it as having saved India from anarchy, and those who viewed it with revulsion.[157] The subsequent Non-Co-Operation movement was called off in March 1922 following the Chauri Chaura incident, and discontent continued to simmer for the next 25 years.[158]		In 1922, Egypt, which had been declared a British protectorate at the outbreak of the First World War, was granted formal independence, though it continued to be a British client state until 1954. British troops remained stationed in Egypt until the signing of the Anglo-Egyptian Treaty in 1936,[159] under which it was agreed that the troops would withdraw but continue to occupy and defend the Suez Canal zone. In return, Egypt was assisted in joining the League of Nations.[160] Iraq, a British mandate since 1920, also gained membership of the League in its own right after achieving independence from Britain in 1932.[161] In Palestine, Britain was presented with the problem of mediating between the Arabs and increasing numbers of Jews. The 1917 Balfour Declaration, which had been incorporated into the terms of the mandate, stated that a national home for the Jewish people would be established in Palestine, and Jewish immigration allowed up to a limit that would be determined by the mandatory power.[162] This led to increasing conflict with the Arab population, who openly revolted in 1936. As the threat of war with Germany increased during the 1930s, Britain judged the support of Arabs as more important than the establishment of a Jewish homeland, and shifted to a pro-Arab stance, limiting Jewish immigration and in turn triggering a Jewish insurgency.[142]		The right of the Dominions to set their own foreign policy, independent of Britain, was recognised at the 1923 Imperial Conference.[163] Britain's request for military assistance from the Dominions at the outbreak of the Chanak Crisis the previous year had been turned down by Canada and South Africa, and Canada had refused to be bound by the 1923 Treaty of Lausanne.[164][165] After pressure from the Irish Free State and South Africa, the 1926 Imperial Conference issued the Balfour Declaration of 1926, declaring the Dominions to be "autonomous Communities within the British Empire, equal in status, in no way subordinate one to another" within a "British Commonwealth of Nations".[166] This declaration was given legal substance under the 1931 Statute of Westminster.[135] The parliaments of Canada, Australia, New Zealand, the Union of South Africa, the Irish Free State and Newfoundland were now independent of British legislative control, they could nullify British laws and Britain could no longer pass laws for them without their consent.[167] Newfoundland reverted to colonial status in 1933, suffering from financial difficulties during the Great Depression.[168] The Irish Free State distanced itself further from the British state with the introduction of a new constitution in 1937, making it a republic in all but name.[169]		Britain's declaration of war against Nazi Germany in September 1939 included the Crown colonies and India but did not automatically commit the Dominions of Australia, Canada, New Zealand, Newfoundland and South Africa. All soon declared war on Germany, but Ireland chose to remain legally neutral throughout the war.[170]		After the German occupation of France in 1940, Britain and the empire stood alone against Germany, until the entry of the Soviet Union to the war in 1941. British Prime Minister Winston Churchill successfully lobbied President Franklin D. Roosevelt for military aid from the United States, but Roosevelt was not yet ready to ask Congress to commit the country to war.[171] In August 1941, Churchill and Roosevelt met and signed the Atlantic Charter, which included the statement that "the rights of all peoples to choose the form of government under which they live" should be respected. This wording was ambiguous as to whether it referred to European countries invaded by Germany, or the peoples colonised by European nations, and would later be interpreted differently by the British, Americans, and nationalist movements.[172][173]		In December 1941, Japan launched, in quick succession, attacks on British Malaya, the United States naval base at Pearl Harbor, and Hong Kong. Churchill's reaction to the entry of the United States into the war was that Britain was now assured of victory and the future of the empire was safe,[174] but the manner in which British forces were rapidly defeated in the Far East irreversibly harmed Britain's standing and prestige as an imperial power.[175][176] Most damaging of all was the fall of Singapore, which had previously been hailed as an impregnable fortress and the eastern equivalent of Gibraltar.[177] The realisation that Britain could not defend its entire empire pushed Australia and New Zealand, which now appeared threatened by Japanese forces, into closer ties with the United States. This resulted in the 1951 ANZUS Pact between Australia, New Zealand and the United States of America.[172]		Though Britain and the empire emerged victorious from the Second World War, the effects of the conflict were profound, both at home and abroad. Much of Europe, a continent that had dominated the world for several centuries, was in ruins, and host to the armies of the United States and the Soviet Union, who now held the balance of global power.[178] Britain was left essentially bankrupt, with insolvency only averted in 1946 after the negotiation of a $US 4.33 billion loan from the United States,[179] the last instalment of which was repaid in 2006.[180] At the same time, anti-colonial movements were on the rise in the colonies of European nations. The situation was complicated further by the increasing Cold War rivalry of the United States and the Soviet Union. In principle, both nations were opposed to European colonialism. In practice, however, American anti-communism prevailed over anti-imperialism, and therefore the United States supported the continued existence of the British Empire to keep Communist expansion in check.[181] The "wind of change" ultimately meant that the British Empire's days were numbered, and on the whole, Britain adopted a policy of peaceful disengagement from its colonies once stable, non-Communist governments were available to transfer power to. This was in contrast to other European powers such as France and Portugal,[182] which waged costly and ultimately unsuccessful wars to keep their empires intact. Between 1945 and 1965, the number of people under British rule outside the UK itself fell from 700 million to five million, three million of whom were in Hong Kong.[183]		The pro-decolonisation Labour government, elected at the 1945 general election and led by Clement Attlee, moved quickly to tackle the most pressing issue facing the empire: Indian independence.[184] India's two major political parties—the Indian National Congress (led by Mahatma Gandhi) and the Muslim League (led by Muhammad Ali Jinnah)—had been campaigning for independence for decades, but disagreed as to how it should be implemented. Congress favoured a unified secular Indian state, whereas the League, fearing domination by the Hindu majority, desired a separate Islamic state for Muslim-majority regions. Increasing civil unrest and the mutiny of the Royal Indian Navy during 1946 led Attlee to promise independence no later than June 30, 1948. When the urgency of the situation and risk of civil war became apparent, the newly appointed (and last) Viceroy, Lord Mountbatten, hastily brought forward the date to 15 August 1947.[185] The borders drawn by the British to broadly partition India into Hindu and Muslim areas left tens of millions as minorities in the newly independent states of India and Pakistan.[186] Millions of Muslims subsequently crossed from India to Pakistan and Hindus vice versa, and violence between the two communities cost hundreds of thousands of lives. Burma, which had been administered as part of the British Raj, and Sri Lanka gained their independence the following year in 1948. India, Pakistan and Sri Lanka became members of the Commonwealth, while Burma chose not to join.[187]		The British mandate in Palestine, where an Arab majority lived alongside a Jewish minority, presented the British with a similar problem to that of India.[188] The matter was complicated by large numbers of Jewish refugees seeking to be admitted to Palestine following the Holocaust, while Arabs were opposed to the creation of a Jewish state. Frustrated by the intractability of the problem, attacks by Jewish paramilitary organisations and the increasing cost of maintaining its military presence, Britain announced in 1947 that it would withdraw in 1948 and leave the matter to the United Nations to solve.[189] The UN General Assembly subsequently voted for a plan to partition Palestine into a Jewish and an Arab state.		Following the defeat of Japan in the Second World War, anti-Japanese resistance movements in Malaya turned their attention towards the British, who had moved to quickly retake control of the colony, valuing it as a source of rubber and tin.[190] The fact that the guerrillas were primarily Malayan-Chinese Communists meant that the British attempt to quell the uprising was supported by the Muslim Malay majority, on the understanding that once the insurgency had been quelled, independence would be granted.[190] The Malayan Emergency, as it was called, began in 1948 and lasted until 1960, but by 1957, Britain felt confident enough to grant independence to the Federation of Malaya within the Commonwealth. In 1963, the 11 states of the federation together with Singapore, Sarawak and North Borneo joined to form Malaysia, but in 1965 Chinese-majority Singapore was expelled from the union following tensions between the Malay and Chinese populations.[191] Brunei, which had been a British protectorate since 1888, declined to join the union[192] and maintained its status until independence in 1984.		In 1951, the Conservative Party returned to power in Britain, under the leadership of Winston Churchill. Churchill and the Conservatives believed that Britain's position as a world power relied on the continued existence of the empire, with the base at the Suez Canal allowing Britain to maintain its pre-eminent position in the Middle East in spite of the loss of India. However, Churchill could not ignore Gamal Abdul Nasser's new revolutionary government of Egypt that had taken power in 1952, and the following year it was agreed that British troops would withdraw from the Suez Canal zone and that Sudan would be granted self-determination by 1955, with independence to follow.[193] Sudan was granted independence on 1 January 1956.		In July 1956, Nasser unilaterally nationalised the Suez Canal. The response of Anthony Eden, who had succeeded Churchill as Prime Minister, was to collude with France to engineer an Israeli attack on Egypt that would give Britain and France an excuse to intervene militarily and retake the canal.[194] Eden infuriated US President Dwight D. Eisenhower, by his lack of consultation, and Eisenhower refused to back the invasion.[195] Another of Eisenhower's concerns was the possibility of a wider war with the Soviet Union after it threatened to intervene on the Egyptian side. Eisenhower applied financial leverage by threatening to sell US reserves of the British pound and thereby precipitate a collapse of the British currency.[196] Though the invasion force was militarily successful in its objectives,[197] UN intervention and US pressure forced Britain into a humiliating withdrawal of its forces, and Eden resigned.[198][199]		The Suez Crisis very publicly exposed Britain's limitations to the world and confirmed Britain's decline on the world stage, demonstrating that henceforth it could no longer act without at least the acquiescence, if not the full support, of the United States.[200][201][202] The events at Suez wounded British national pride, leading one MP to describe it as "Britain's Waterloo"[203] and another to suggest that the country had become an "American satellite".[204] Margaret Thatcher later described the mindset she believed had befallen Britain's political leaders as "Suez syndrome" where they “went from believing that Britain could do anything to an almost neurotic belief that Britain could do nothing”,[205] from which Britain did not recover until the successful recapture of the Falkland Islands from Argentina in 1982.[206]		While the Suez Crisis caused British power in the Middle East to weaken, it did not collapse.[207] Britain again deployed its armed forces to the region, intervening in Oman (1957), Jordan (1958) and Kuwait (1961), though on these occasions with American approval,[208] as the new Prime Minister Harold Macmillan's foreign policy was to remain firmly aligned with the United States.[203] Britain maintained a military presence in the Middle East for another decade. On 16 January 1968, a few weeks after the devaluation of the pound, Prime Minister Harold Wilson and his Defence Secretary Denis Healey announced that British troops would be withdrawn from major military bases East of Suez, which included the ones in the Middle East, and primarily from Malaysia and Singapore by the end of 1971, instead of 1975 as earlier planned.[209] By that time over 50,000 British military personnel were still stationed in the Far East, including 30,000 in Singapore.[210] The British withdrew from Aden in 1967, Bahrain in 1971, and the Maldives in 1976.[211]		Macmillan gave a speech in Cape Town, South Africa in February 1960 where he spoke of "the wind of change blowing through this continent".[212] Macmillan wished to avoid the same kind of colonial war that France was fighting in Algeria, and under his premiership decolonisation proceeded rapidly.[213] To the three colonies that had been granted independence in the 1950s—Sudan, the Gold Coast and Malaya—were added nearly ten times that number during the 1960s.[214]		Britain's remaining colonies in Africa, except for self-governing Southern Rhodesia, were all granted independence by 1968. British withdrawal from the southern and eastern parts of Africa was not a peaceful process. Kenyan independence was preceded by the eight-year Mau Mau Uprising. In Rhodesia, the 1965 Unilateral Declaration of Independence by the white minority resulted in a civil war that lasted until the Lancaster House Agreement of 1979, which set the terms for recognised independence in 1980, as the new nation of Zimbabwe.[215]		In the Mediterranean, a guerrilla war waged by Greek Cypriots ended in 1960 leading to an independent Cyprus, with the UK retaining the military bases of Akrotiri and Dhekelia. The Mediterranean islands of Malta and Gozo were amicably granted independence from the UK in 1964 and became the country of Malta, though the idea had been raised in 1955 of integration with Britain.[216]		Most of the UK's Caribbean territories achieved independence after the departure in 1961 and 1962 of Jamaica and Trinidad from the West Indies Federation, established in 1958 in an attempt to unite the British Caribbean colonies under one government, but which collapsed following the loss of its two largest members.[217] Barbados achieved independence in 1966 and the remainder of the eastern Caribbean islands in the 1970s and 1980s,[217] but Anguilla and the Turks and Caicos Islands opted to revert to British rule after they had already started on the path to independence.[218] The British Virgin Islands,[219] Cayman Islands and Montserrat opted to retain ties with Britain,[220] while Guyana achieved independence in 1966. Britain's last colony on the American mainland, British Honduras, became a self-governing colony in 1964 and was renamed Belize in 1973, achieving full independence in 1981. A dispute with Guatemala over claims to Belize was left unresolved.[221]		British territories in the Pacific acquired independence in the 1970s beginning with Fiji in 1970 and ending with Vanuatu in 1980. Vanuatu's independence was delayed because of political conflict between English and French-speaking communities, as the islands had been jointly administered as a condominium with France.[222] Fiji, Tuvalu, the Solomon Islands and Papua New Guinea chose to become Commonwealth realms.		In 1980, Southern Rhodesia, Britain's last African colony, became the independent nation of Zimbabwe. The New Hebrides achieved independence (as Vanuatu) in 1980, with Belize following suit in 1981. The passage of the British Nationality Act 1981, which reclassified the remaining Crown colonies as "British Dependent Territories" (renamed British Overseas Territories in 2002)[223] meant that, aside from a scattering of islands and outposts, the process of decolonisation that had begun after the Second World War was largely complete. In 1982, Britain's resolve in defending its remaining overseas territories was tested when Argentina invaded the Falkland Islands, acting on a long-standing claim that dated back to the Spanish Empire.[224] Britain's ultimately successful military response to retake the islands during the ensuing Falklands War was viewed by many to have contributed to reversing the downward trend in Britain's status as a world power.[225] The same year, the Canadian government severed its last legal link with Britain by patriating the Canadian constitution from Britain. The 1982 Canada Act passed by the British parliament ended the need for British involvement in changes to the Canadian constitution.[19] Similarly, the Constitution Act 1986 reformed the constitution of New Zealand to sever its constitutional link with Britain, and the Australia Act 1986 severed the constitutional link between Britain and the Australian states.[226] In 1984, Brunei, Britain's last remaining Asian protectorate, gained its independence.		In September 1982 the Prime Minister, Margaret Thatcher, travelled to Beijing to negotiate with the Chinese government, on the future of Britain's last major and most populous overseas territory, Hong Kong.[227] Under the terms of the 1842 Treaty of Nanking, Hong Kong Island itself had been ceded to Britain in perpetuity, but the vast majority of the colony was constituted by the New Territories, which had been acquired under a 99-year lease in 1898, due to expire in 1997.[228][229] Thatcher, seeing parallels with the Falkland Islands, initially wished to hold Hong Kong and proposed British administration with Chinese sovereignty, though this was rejected by China.[230] A deal was reached in 1984—under the terms of the Sino-British Joint Declaration, Hong Kong would become a special administrative region of the People's Republic of China, maintaining its way of life for at least 50 years.[231] The handover ceremony in 1997 marked for many,[17] including Charles, Prince of Wales,[18] who was in attendance, "the end of Empire".[19][20]		Territorial GDP distribution of the British Empire (1870)[232]		The following table gives the gross domestic product (GDP) of the British Empire and its territories in 1870 and 1913, as a percentage of the world economy and the empire's economy, along with comparisons to the United States and Russian Empire:[232]		The 1911 Encyclopædia Britannica gave the following figures for the "White" and "Native" populations in the British Empire and its territories:[233]		The 1911 Encyclopædia Britannica gave the following population figures for the religions in the British Empire:[233]		Britain retains sovereignty over 14 territories outside the British Isles, which were renamed the British Overseas Territories in 2002.[234] Four are uninhabited except for transient military or scientific personnel[citation needed]; the remaining ten are self-governing to varying degrees and are reliant on the UK for foreign relations and defence. The British government has stated its willingness to assist any Overseas Territory that wishes to proceed to independence, where that is an option,[235] and three territories have specifically voted to remain under British sovereignty (Bermuda in 1995, Gibraltar in 2002 and the Falkland Islands in 2013).[236]		British sovereignty of several of the overseas territories is disputed by their geographical neighbours: Gibraltar is claimed by Spain, the Falkland Islands and South Georgia and the South Sandwich Islands are claimed by Argentina, and the British Indian Ocean Territory is claimed by Mauritius and Seychelles.[237] The British Antarctic Territory is subject to overlapping claims by Argentina and Chile, while many countries do not recognise any territorial claims in Antarctica.[238]		Most former British colonies and protectorates are among the 52 member states of the Commonwealth of Nations, a non-political, voluntary association of equal members, comprising a population of around 2.2 billion people.[239] Sixteen Commonwealth realms voluntarily continue to share the British monarch, Queen Elizabeth II, as their head of state. These sixteen nations are distinct and equal legal entities – the United Kingdom, Australia, Canada, New Zealand, Papua New Guinea, Antigua and Barbuda, The Bahamas, Barbados, Belize, Grenada, Jamaica, Saint Kitts and Nevis, Saint Lucia, Saint Vincent and the Grenadines, Solomon Islands and Tuvalu.[240]		Decades, and in some cases centuries, of British rule and emigration have left their mark on the independent nations that arose from the British Empire. The empire established the use of English in regions around the world. Today it is the primary language of up to 400 million people and is spoken by about one and a half billion as a first, second or foreign language.[241]		The spread of English from the latter half of the 20th century has been helped in part by the cultural and economic influence of the United States, itself originally formed from British colonies. Except in Africa where nearly all the former colonies have adopted the presidential system, the English parliamentary system has served as the template for the governments for many former colonies, and English common law for legal systems.[242]		The British Judicial Committee of the Privy Council still serves as the highest court of appeal for several former colonies in the Caribbean and Pacific. British Protestant missionaries who travelled around the globe often in advance of soldiers and civil servants spread the Anglican Communion to all continents. British colonial architecture, such as in churches, railway stations and government buildings, can be seen in many cities that were once part of the British Empire.[243]		Individual and team sports developed in Britain — particularly golf, football, cricket, rugby, netball, lawn bowls, hockey and lawn tennis — were also exported.[244] The British choice of system of measurement, the imperial system, continues to be used in some countries in various ways. The convention of driving on the left hand side of the road has been retained in much of the former empire.[245]		Political boundaries drawn by the British did not always reflect homogeneous ethnicities or religions, contributing to conflicts in formerly colonised areas. The British Empire was also responsible for large migrations of peoples. Millions left the British Isles, with the founding settler populations of the United States, Canada, Australia and New Zealand coming mainly from Britain and Ireland. Tensions remain between the white settler populations of these countries and their indigenous minorities, and between white settler minorities and indigenous majorities in South Africa and Zimbabwe. Settlers in Ireland from Great Britain have left their mark in the form of divided nationalist and unionist communities in Northern Ireland. Millions of people moved to and from British colonies, with large numbers of Indians emigrating to other parts of the empire, such as Malaysia and Fiji, and Chinese people to Malaysia, Singapore and the Caribbean.[246] The demographics of Britain itself was changed after the Second World War owing to immigration to Britain from its former colonies.[247]				
A beach is a landform along a body of water. It usually consists of loose particles, which are often composed of rock, such as sand, gravel, shingle, pebbles, or cobblestones. The particles composing a beach are occasionally biological in origin, such as mollusc shells or coralline algae.		Some beaches have man-made infrastructure, such as lifeguard posts, changing rooms, and showers. They may also have hospitality venues (such as resorts, camps, hotels, and restaurants) nearby. Wild beaches, also known as undeveloped or undiscovered beaches, are not developed in this manner. Wild beaches can be valued for their untouched beauty and preserved nature.		Beaches typically occur in areas along the coast where wave or current action deposits and reworks sediments.						Although the seashore is most commonly associated with the word beach, beaches are also found by lakes and alongside large rivers.		Beach may refer to:		The former are described in detail below; the larger geological units are discussed elsewhere under bars.		There are several conspicuous parts to a beach that relate to the processes that form and shape it. The part mostly above water (depending upon tide), and more or less actively influenced by the waves at some point in the tide, is termed the beach berm. The berm is the deposit of material comprising the active shoreline. The berm has a crest (top) and a face—the latter being the slope leading down towards the water from the crest. At the very bottom of the face, there may be a trough, and further seaward one or more long shore bars: slightly raised, underwater embankments formed where the waves first start to break.		The sand deposit may extend well inland from the berm crest, where there may be evidence of one or more older crests (the storm beach) resulting from very large storm waves and beyond the influence of the normal waves. At some point the influence of the waves (even storm waves) on the material comprising the beach stops, and if the particles are small enough (sand size or smaller), winds shape the feature. Where wind is the force distributing the grains inland, the deposit behind the beach becomes a dune.		These geomorphic features compose what is called the beach profile. The beach profile changes seasonally due to the change in wave energy experienced during summer and winter months. In temperate areas where summer is characterised by calmer seas and longer periods between breaking wave crests, the beach profile is higher in summer. The gentle wave action during this season tends to transport sediment up the beach towards the berm where it is deposited and remains while the water recedes. Onshore winds carry it further inland forming and enhancing dunes.		Conversely, the beach profile is lower in the storm season (winter in temperate areas) due to the increased wave energy, and the shorter periods between breaking wave crests. Higher energy waves breaking in quick succession tend to mobilise sediment from the shallows, keeping it in suspension where it is prone to be carried along the beach by longshore currents, or carried out to sea to form longshore bars, especially if the longshore current meets an outflow from a river or flooding stream. The removal of sediment from the beach berm and dune thus decreases the beach profile.		In tropical areas, the storm season tends to be during the summer months, with calmer weather commonly associated with the winter season.		If storms coincide with unusually high tides, or with a freak wave event such as a tidal surge or tsunami which causes significant coastal flooding, substantial quantities of material may be eroded from the coastal plain or dunes behind the berm by receding water. This flow may alter the shape of the coastline, enlarge the mouths of rivers and create new deltas at the mouths of streams that had not been powerful enough to overcome longshore movement of sediment.		The line between beach and dune is difficult to define in the field. Over any significant period of time, sediment is always being exchanged between them. The drift line (the high point of material deposited by waves) is one potential demarcation. This would be the point at which significant wind movement of sand could occur, since the normal waves do not wet the sand beyond this area. However, the drift line is likely to move inland under assault by storm waves.[1]		The development of the beach as a popular leisure resort from the mid-19th century was the first manifestation of what is now the global tourist industry. The first seaside resorts were opened in the 18th century for the aristocracy, who began to frequent the seaside as well as the then fashionable spa towns, for recreation and health.[2] One of the earliest such seaside resorts, was Scarborough in Yorkshire during the 1720s; it had been a fashionable spa town since a stream of acidic water was discovered running from one of the cliffs to the south of the town in the 17th century.[2] The first rolling bathing machines were introduced by 1735.		The opening of the resort in Brighton and its reception of royal patronage from King George IV, extended the seaside as a resort for health and pleasure to the much larger London market, and the beach became a centre for upper-class pleasure and frivolity. This trend was praised and artistically elevated by the new romantic ideal of the picturesque landscape; Jane Austen's unfinished novel Sanditon is an example of that. Later, Queen Victoria's long-standing patronage of the Isle of Wight and Ramsgate in Kent ensured that a seaside residence was considered as a highly fashionable possession for those wealthy enough to afford more than one home.		The extension of this form of leisure to the middle and working class began with the development of the railways in the 1840s, which offered cheap and affordable fares to fast growing resort towns. In particular, the completion of a branch line to the small seaside town Blackpool from Poultron led to a sustained economic and demographic boom. A sudden influx of visitors, arriving by rail, provided the motivation for entrepreneurs to build accommodation and create new attractions, leading to more visitors and a rapid cycle of growth throughout the 1850s and 1860s.[3]		The growth was intensified by the practice among the Lancashire cotton mill owners of closing the factories for a week every year to service and repair machinery. These became known as wakes weeks. Each town's mills would close for a different week, allowing Blackpool to manage a steady and reliable stream of visitors over a prolonged period in the summer. A prominent feature of the resort was the promenade and the pleasure piers, where an eclectic variety of performances vied for the people's attention. In 1863, the North Pier in Blackpool was completed, rapidly becoming a centre of attraction for elite visitors. Central Pier was completed in 1868, with a theatre and a large open-air dance floor.[4]		Many of the popular beach resorts were equipped with bathing machines because even the all-covering beachwear of the period was considered immodest. By the end of the century the English coastline had over 100 large resort towns, some with populations exceeding 50,000.[5]		The development of the seaside resort abroad was stimulated by the well developed English love of the beach. The French Riviera alongside the Mediterranean had already become a popular destination for the British upper class by the end of the 18th century. In 1864, the first railway to Nice was completed, making the Riviera accessible to visitors from all over Europe. By 1874, residents of foreign enclaves in Nice, most of whom were British, numbered 25,000. The coastline became renowned for attracting the royalty of Europe, including Queen Victoria and King Edward VII.[6]		Continental European attitudes towards gambling and nakedness tended to be more lax than in Britain, so British and French entrepreneurs were quick to exploit the possibilities. In 1863, the Prince of Monaco, Charles III and François Blanc, a French businessman, arranged for steamships and carriages to take visitors from Nice to Monaco, where large luxury hotels, gardens and casinos were built. The place was renamed Monte Carlo.		Commercial sea bathing spread to the United States and parts of the British Empire by the end of the 19th century. By the late 1890s, Henry Flagler developed the Florida East Coast Railway, which linked the coastal sea resorts developing at St. Augustine, FL and Miami Beach, FL, to winter travelers from the northern United States and Canada on the East Coast Railway. By the early 20th century surfing was developed in Hawaii and Australia, and then moving to southern California by the early 1960s. By the 1970s cheap and affordable air travel was the catalyst for the growth of a truly global tourism market which benefited areas such as the Mediterranean, Australia, South Africa, and the coastal Sun Belt regions of the United States.		Beaches can be popular on warm sunny days. In the Victorian era, many popular beach resorts were equipped with bathing machines because even the all-covering beachwear of the period was considered immodest. This social standard still prevails in many Muslim countries. At the other end of the spectrum are topfree beaches and nude beaches where clothing is optional or not allowed. In most countries social norms are significantly different on a beach in hot weather, compared to adjacent areas where similar behavior might not be tolerated and might even be prosecuted.		In more than thirty countries in Europe, South Africa, New Zealand, Canada, Costa Rica, South America and the Caribbean, the best recreational beaches are awarded Blue Flag status, based on such criteria as water quality and safety provision. Subsequent loss of this status can have a severe effect on tourism revenues.		Beaches are often dumping grounds for waste and litter, necessitating the use of beach cleaners and other cleanup projects. More significantly, many beaches are a discharge zone for untreated sewage in most underdeveloped countries; even in developed countries beach closure is an occasional circumstance due to sanitary sewer overflow. In these cases of marine discharge, waterborne disease from fecal pathogens and contamination of certain marine species are a frequent outcome.		Some beaches are artificial; they are either permanent or temporary (For examples see Monaco, Paris, Copenhagen, Rotterdam, Nottingham, Toronto, Hong Kong, Singapore, and Tianjin).		The soothing qualities of a beach and the pleasant environment offered to the beachgoer are replicated in artificial beaches, such as "beach style" pools with zero-depth entry and wave pools that recreate the natural waves pounding upon a beach. In a zero-depth entry pool, the bottom surface slopes gradually from above water down to depth. Another approach involves so-called urban beaches, a form of public park becoming common in large cities. Urban beaches attempt to mimic natural beaches with fountains that imitate surf and mask city noises, and in some cases can be used as a play park.		Beach nourishment involves pumping sand onto beaches to improve their health. Beach nourishment is common for major beach cities around the world; however the beaches that have been nourished can still appear quite natural and often many visitors are unaware of the works undertaken to support the health of the beach. Such beaches are often not recognized by consumers as artificial. A famous example of beach nourishment came with the replenishment of Waikīkī Beach in Honolulu, Hawaii, where sand from Manhattan Beach, California was transported via ship and barge throughout most of the 20th century in order to combat Waikiki's erosion problems. The Surfrider Foundation has debated the merits of artificial reefs with members torn between their desire to support natural coastal environments and opportunities to enhance the quality of surfing waves. Similar debates surround beach nourishment and snow cannon in sensitive environments.		Public access to beaches is restricted in some parts of the world.[7][8] For example, most beaches on the Jersey Shore are restricted to people who can purchase beach tags.[9] Some beaches also restrict dogs for some periods of the year.[10]		Also, private beaches such as those along the shores, may belong to the neighborhood association nearby. Signs are usually posted the entrance. A permit or special use occasion event may be granted upon executing the proper channels to legally obtain one.		Public access to beaches is protected by law in the U.S. State of Oregon, thanks to a 1967 state law, the Oregon Beach Bill, which guaranteed public access from the Columbia River to the California state line, "so that the public may have the free and uninterrupted use".[11]		Beaches are the result of wave action by which waves or currents move sand or other loose sediments of which the beach is made as these particles are held in suspension. Alternatively, sand may be moved by saltation (a bouncing movement of large particles).		Beach materials come from erosion of rocks offshore, as well as from headland erosion and slumping producing deposits of scree. Some of the whitest sand in the world, along Florida's Emerald Coast, comes from the erosion of quartz in the Appalachian Mountains.		A coral reef offshore is a significant source of sand particles. Some species of fish that feed on algae attached to coral outcrops and rocks can create substantial quantities of sand particles over their lifetime as they nibble during feeding, digesting the organic matter, and discarding the rock and coral particles which pass through their digestive tracts.		The composition of the beach depends upon the nature and quantity of sediments upstream of the beach, and the speed of flow and turbidity of water and wind.		Sediments are moved by moving water and wind according to their particle size and state of compaction. Particles tend to settle and compact in still water. Once compacted, they are more resistant to erosion. Established vegetation (especially species with complex network root systems) will resist erosion by slowing the fluid flow at the surface layer.		When affected by moving water or wind, particles that are eroded and held in suspension will increase the erosive power of the fluid that holds them by increasing the average density, viscosity and volume of the moving fluid.		The nature of sediments found on a beach tends to indicate the energy of the waves and wind in the locality. Coastlines facing very energetic wind and wave systems will tend to hold only large rocks as smaller particles will be held in suspension in the turbid water column and carried to calmer areas by longshore currents and tides. Coastlines that are protected from waves and winds will tend to allow finer sediments such as clays and mud to precipitate creating mud flats and mangrove forests.		The shape of a beach depends on whether the waves are constructive or destructive, and whether the material is sand or shingle.		Waves are constructive if the period between their wave crests is long enough for the breaking water to recede and the sediment to settle before the succeeding wave arrives and breaks. Fine sediment transported from lower down the beach profile will compact if the receding water percolates or soaks into the beach. Compacted sediment is more resistant to movement by turbulent water from succeeding waves.		Conversely, waves are destructive if the period between the wave crests is short. Sediment that remains in suspension when the following wave crest arrives will not be able to settle and compact and will be more susceptible to erosion by longshore currents and receding tides.		Constructive waves move material up the beach while destructive waves move the material down the beach. During seasons when destructive waves are prevalent, the shallows will carry an increased load of sediment and organic matter in suspension.		On sandy beaches, the turbulent backwash of destructive waves removes material forming a gently sloping beach. On pebble and shingle beaches the swash is dissipated more quickly because the large particle size allows greater percolation, thereby reducing the power of the backwash, and the beach remains steep.		Compacted fine sediments will form a smooth beach surface that resists wind and water erosion. During hot calm seasons, a crust may form on the surface of ocean beaches as the heat of the sun evaporates the water leaving the salt which crystallises around the sand particles. This crust forms an additional protective layer that resists wind erosion unless disturbed by animals, or dissolved by the advancing tide.		Cusps and horns form where incoming waves divide, depositing sand as horns and scouring out sand to form cusps. This forms the uneven face on some sand shorelines.		Beaches are changed in shape chiefly by the movement of water and wind. Any weather event that is associated with turbid or fast flowing water, or high winds will erode exposed beaches. Longshore currents will tend to replenish beach sediments and repair storm damage. Tidal waterways generally change the shape of their adjacent beaches by small degrees with every tidal cycle. Over time these changes can become substantial leading to significant changes in the size and location of the beach.		Changes in the shape of the beach may undermine the roots of large trees and other flora. Many beach adapted species (such as coconut palms) have a fine root system and large root ball which tends to withstand wave and wind action and tends to stabilize beaches better than other trees with a lesser root ball.		Erosion of beaches can expose less resilient soils and rocks to wind and wave action leading to undermining of coastal headlands eventually resulting in catastrophic collapse of large quantities of overburden into the shallows. This material may be distributed along the beach front leading to a change in the habitat as sea grasses and corals in the shallows may be buried or deprived of light and nutrients.		Coastal areas settled by man inevitably become subject to the effects of man-made structures and processes. Over long periods of time these influences may substantially alter the shape of the coastline, and the character of the beach.		Beach front flora plays a major role in stabilizing the foredunes and preventing beach head erosion and inland movement of dunes. If flora with network root systems (creepers, grasses and palms) are able to become established, they provide an effective coastal defense as they trap sand particles and rainwater and enrich the surface layer of the dunes, allowing other plant species to become established. They also protect the berm from erosion by high winds, freak waves and subsiding flood waters.		Over long periods of time, well stabilized foreshore areas will tend to accrete, while unstabilized foreshores will tend to erode, leading to substantial changes in the shape of the coastline. These changes usually occur over periods of many years. Freak wave events such as tsunami, tidal waves, and storm surges may substantially alter the shape, profile and location of a beach within hours.		Destruction of flora on the berm by the use of herbicides, excessive pedestrian or vehicle traffic, or disruption to fresh water flows may lead to erosion of the berm and dunes. While the destruction of flora may be a gradual process that is imperceptible to regular beach users, it often becomes immediately apparent after storms associated with high winds and freak wave events that can rapidly move large volumes of exposed and unstable sand, depositing them further inland, or carrying them out into the permanent water forming offshore bars, lagoons or increasing the area of the beach exposed at low tide. Large and rapid movements of exposed sand can bury and smother flora in adjacent areas, aggravating the loss of habitat for fauna, and enlarging the area of instability. If there is an adequate supply of sand, and weather conditions do not allow vegetation to recover and stabilize the sediment, wind-blown sand can continue to advance, engulfing and permanently altering downwind landscapes.		Sediment moved by waves or receding flood waters can be deposited in coastal shallows, engulfing reed beds and changing the character of underwater flora and fauna in the coastal shallows.		Burning or clearance of vegetation on the land adjacent to the beach head, for farming and residential development, changes the surface wind patterns, and exposes the surface of the beach to wind erosion.		Farming and residential development are also commonly associated with changes in local surface water flows. If these flows are concentrated in storm water drains emptying onto the beach head, they may erode the beach creating a lagoon or delta.		Dense vegetation tends to absorb rainfall reducing the speed of runoff and releasing it over longer periods of time. Destruction by burning or clearance of the natural vegetation tends to increase the speed and erosive power of runoff from rainfall. This runoff will tend to carry more silt and organic matter from the land onto the beach and into the sea. If the flow is constant, runoff from cleared land arriving at the beach head will tend to deposit this material into the sand changing its color, odor and fauna.		The concentration of pedestrian and vehicular traffic accessing the beach for recreational purposes may cause increased erosion at the access points if measures are not taken to stabilize the beach surface above high-water mark. Recognition of the dangers of loss of beach front flora has caused many local authorities responsible for managing coastal areas to restrict beach access points by physical structures or legal sanctions, and fence off foredunes in an effort to protect the flora. These measures are often associated with the construction of structures at these access points to allow traffic to pass over or through the dunes without causing further damage.		Beaches provide a filter for runoff from the coastal plain. If the runoff is naturally dispersed along the beach, water borne silt and organic matter will be retained on the land and will feed the flora in the coastal area. Runoff that is dispersed along the beach will tend to percolate through the beach and may emerge from the beach at low tide.		The retention of the fresh water may also help to maintain underground water reserves and will resist salt water incursion. If the surface flow of the runoff is diverted and concentrated by drains that create constant flows over the beach above the sea or river level, the beach will be eroded and ultimately form an inlet unless longshore flows deposit sediments to repair the breach.		Once eroded, an inlet may allow tidal inflows of salt water to pollute areas inland from the beach and may also affect the quality of underground water supplies and the height of the water table.		Some flora naturally occurring on the beach head requires fresh water runoff from the land. Diversion of fresh water runoff into drains may deprive these plants of their water supplies and allow sea water incursion, increasing the saltiness of the ground water. Species that are not able to survive in salt water may die and be replaced by mangroves or other species adapted to salty environments.		Beach nourishment is the importing and deposition of sand or other sediments in an effort to restore a beach that has been damaged by erosion. Beach nourishment often involves excavation of sediments from riverbeds or sand quarries. This excavated sediment may be substantially different in size and appearance to the naturally occurring beach sand.		In extreme cases, beach nourishment may involve placement of large pebbles or rocks in an effort to permanently restore a shoreline subject to constant erosion and loss of foreshore. This is often required where the flow of new sediment caused by the longshore current has been disrupted by construction of harbors, breakwaters, causeways or boat ramps, creating new current flows that scour the sand from behind these structures, and deprive the beach of restorative sediments. If the causes of the erosion are not addressed, beach nourishment can become a necessary and permanent feature of beach maintenance.		During beach nourishment activities, care must be taken to place new sediments so that the new sediments compact and stabilize before aggressive wave or wind action can erode them. Material that is concentrated too far down the beach may form a temporary groyne that will encourage scouring behind it. Sediments that are too fine or too light may be eroded before they have compacted or been integrated into the established vegetation. Foreign unwashed sediments may introduce flora or fauna that are not usually found in that locality.		Brighton Beach, on the south coast of England, is a shingle beach that has been nourished with very large pebbles in an effort to withstand erosion of the upper area of the beach. These large pebbles made the beach unwelcoming for pedestrians for a period of time until natural processes integrated the naturally occurring shingle into the pebble base.		Beach access is an important consideration where substantial numbers of pedestrians or vehicles require access to the beach. Allowing random access across delicate foredunes is seldom considered good practice as it is likely to lead to destruction of flora and consequent erosion of the fore dunes.		A well designed beach access should:		A concrete ramp should follow the natural profile of the beach to prevent it from changing the normal flow of waves, longshore currents, water and wind. A ramp that is below the beach profile will tend to become buried and cease to provide a good surface for vehicular traffic. A ramp or stair that protrudes above the beach profile will tend to disrupt longshore currents creating deposits in front of the ramp, and scouring behind. Concrete ramps are the most expensive vehicular beach accesses to construct requiring use of a quick drying concrete or a coffer dam to protect them from tidal water during the concrete curing process. Concrete is favored where traffic flows are heavy and access is required by vehicles that are not adapted to soft sand (e.g. road registered passenger vehicles and boat trailers). Concrete stairs are commonly favored on beaches adjacent to population centers where beach users may arrive on the beach in street shoes, or where the foreshore roadway is substantially higher than the beach head and a ramp would be too steep for safe use by pedestrians. A composite stair ramp may incorporate a central or side stair with one or more ramps allowing pedestrians to lead buggies or small boat dollies onto the beach without the aid of a powered vehicle or winch. Concrete ramps and steps should be maintained to prevent buildup of moss or algae that may make their wet surfaces slippery and dangerous to pedestrians and vehicles.		A corduroy or beach ladder (or board and chain) is an array of planks (usually hardwood or treated timber) laid close together and perpendicular to the direction of traffic flow, and secured at each end by a chain or cable to form a pathway or ramp over the sand dune. Corduroys are cheap and easy to construct and quick to deploy or relocate. They are commonly used for pedestrian access paths and light duty vehicular access ways. They naturally conform to the shape of the underlying beach or dune profile, and adjust well to moderate erosion, especially longshore drift. However, they can cease to be an effective access surface if they become buried or undermined by erosion by surface runoff coming from the beach head. If the corduroy is not wide enough for vehicles using it, the sediment on either side may be displaced creating a spoon drain that accelerates surface run off and can quickly lead to serious erosion. Significant erosion of the sediment beside and under the corduroy can render it completely ineffective and make it dangerous to pedestrian users who may fall between the planks.		Fabric ramps are commonly employed by the military for temporary purposes where the underlying sediment is stable and hard enough to support the weight of the traffic. A sheet of porous fabric is laid over the sand to stabilize the surface and prevent vehicles from bogging. Fabric Ramps usually cease to be useful after one tidal cycle as they are easily washed away, or buried in sediment.		A foliage ramp is formed by planting resilient species of hardy plants such as grasses over a well formed sediment ramp. The plants may be supported while they become established by placement of layers of mesh, netting, or coarse organic material such as vines or branches. This type of ramp is ideally suited for intermittent use by vehicles with a low wheel loading such as dune buggies or agricultural vehicles with large tyres. A foliage ramp should require minimal maintenance if initially formed to follow the beach profile, and not overused.		A gravel ramp is formed by excavating the underlying loose sediment and filling the excavation with layers of gravel of graduated sizes as defined by John Loudon McAdam. The gravel is compacted to form a solid surface according to the needs of the traffic. Gravel ramps are less expensive to construct than concrete ramps and are able to carry heavy road traffic provided the excavation is deep enough to reach solid subsoil. Gravel ramps are subject to erosion by water. If the edges are retained with boards or walls and the profile matches the surrounding beach profile, a gravel ramp may become more stable as finer sediments are deposited by percolating water.		Amongst the world's longest beaches are:		A beach is an unstable environment that exposes plants and animals to changeable and potentially harsh conditions. Some animals burrow into the sand and feed on material deposited by the waves. Crabs, insects and shorebirds feed on these beach dwellers. The endangered piping plover and some tern species rely on beaches for nesting. Sea turtles also bury their eggs in ocean beaches. Seagrasses and other beach plants grow on undisturbed areas of the beach and dunes.		Ocean beaches are habitats with organisms adapted to salt spray, tidal overwash, and shifting sands. Some of these organisms are found only on beaches. Examples of these beach organisms in the southeast US include plants like sea oats, sea rocket, beach elder, beach morning glory (Ipomoea pes-caprae), and beach peanut, and animals such as mole crabs (Hippoidea), coquina clams (Donax), ghost crabs, and white beach tiger beetles.[1]		
Cakile arabica Cakile arctica Cakile constricta Cakile edentula Cakile geniculata Cakile lanceolata Cakile maritima Cakile euxina incomplete list		Cakile is a genus within the flowering plant family Brassicaceae. Species in this genus are commonly known as searockets, though this name on its own is applied particularly to whatever member of the species is native or most common in the region concerned, the European searocket Cakile maritima in Europe, and the American searocket C. edentula in North America. The genus is native to Europe, Asia and North America, but the European searocket has been introduced into North America and has spread widely on both east and west coasts; in many places it is replacing the native C. edentula, and is regarded as an undesirable invasive species.		Cakile species grow as annual plants with an erect or decumbent stem. The common species in Europe and North America grow close to the coast, often in dunes. Their leaves are fleshy. Flowers are typically pale mauve to white, with petals about 1 cm in length. Each fruit has two sections, one that remains attached to the adult, and the other which that falls off for dispersal by wind or water.[1]		They are rather similar to those of the wild radish (also in family Brassicaceae) which is found in the same regions, and careful attention to the leaves and stems is needed to tell the two plants apart.				
A river delta is a landform that forms from deposition of sediment carried by a river as the flow leaves its mouth and enters slower-moving or standing water.[1][2] This occurs where a river enters an ocean, sea, estuary, lake, reservoir, or (more rarely) another river that cannot transport away the supplied sediment. The size and shape of a delta is controlled by the balance between watershed processes that supply sediment and receiving basin processes that redistribute, sequester, and export that sediment.[3][4] The size, geometry, and location of the receiving basin also plays an important role in delta evolution. River deltas are important in human civilization, as they are major agricultural production centers and population centers. They can provide coastline defense and can impact drinking water supply.[5] They are also ecologically important, with different species assemblages depending on their landscape position.						River deltas form when a river carrying sediment reaches either (1) a body of water, such as a lake, ocean, or reservoir, (2) another river that cannot remove the sediment quickly enough to stop delta formation, or (3) an inland region where the water spreads out and deposits sediments. The tidal currents also cannot be too strong, as sediment would wash out into the water body faster than the river deposits it. Of course, the river must carry enough sediment to layer into deltas over time. The river's velocity decreases rapidly, causing it to deposit the majority, if not all, of its load. This alluvium builds up to form the river delta.[6] When the flow enters the standing water, it is no longer confined to its channel and expands in width. This flow expansion results in a decrease in the flow velocity, which diminishes the ability of the flow to transport sediment. As a result, sediment drops out of the flow and deposits. Over time, this single channel builds a deltaic lobe (such as the bird's-foot of the Mississippi or Ural river deltas), pushing its mouth into the standing water. As the deltaic lobe advances, the gradient of the river channel becomes lower because the river channel is longer but has the same change in elevation (see slope).		As the slope of the river channel decreases, it becomes unstable for two reasons. First, gravity makes the water flow in the most direct course down slope. If the river breaches its natural levees (i.e., during a flood), it spills out onto a new course with a shorter route to the ocean, thereby obtaining a more stable steeper slope.[7] Second, as its slope gets lower, the amount of shear stress on the bed decreases, which results in deposition of sediment within the channel and a rise in the channel bed relative to the floodplain. This makes it easier for the river to breach its levees and cut a new channel that enters the body of standing water at a steeper slope. Often when the channel does this, some of its flow remains in the abandoned channel. When these channel-switching events occur, a mature delta develops a distributary network.		Another way these distributary networks form is from deposition of mouth bars (mid-channel sand and/or gravel bars at the mouth of a river). When this mid-channel bar is deposited at the mouth of a river, the flow is routed around it. This results in additional deposition on the upstream end of the mouth-bar, which splits the river into two distributary channels. A good example of the result of this process is the Wax Lake Delta.		In both of these cases, depositional processes force redistribution of deposition from areas of high deposition to areas of low deposition. This results in the smoothing of the planform (or map-view) shape of the delta as the channels move across its surface and deposit sediment. Because the sediment is laid down in this fashion, the shape of these deltas approximates a fan. The more often the flow changes course, the shape develops as closer to an ideal fan, because more rapid changes in channel position results in more uniform deposition of sediment on the delta front. The Mississippi and Ural River deltas, with their bird's-feet, are examples of rivers that do not avulse often enough to form a symmetrical fan shape. Alluvial fan deltas, as seen by their name, avulse frequently and more closely approximate an ideal fan shape.		Deltas are typically classified according to the main control on deposition, which is a combination of river, wave, and tidal processes,[8] depending on the strength of each.[9] The other two factors that play a major role are landscape position and the grain size distribution of the source sediment entering the delta from the river.[10]		In wave dominated deltas, wave-driven sediment transport controls the shape of the delta, and much of the sediment emanating from the river mouth is deflected along the coast line.[8] The relationship between waves and river deltas is quite variable and largely influenced by the deepwater wave regimes of the receiving basin. With a high wave energy near shore and a steeper slope offshore, waves will make river deltas smoother. Waves can also be responsible for carrying sediments away from the river delta, causing the delta to retreat.[5] For deltas that form further upriver in an estuary, there are complex yet quantifiable linkages between winds, tides, river discharge, and delta water levels.[11][12]		Erosion is also an important control in tide dominated deltas, such as the Ganges Delta, which may be mainly submarine, with prominent sand bars and ridges. This tends to produce a "dendritic" structure.[13] Tidal deltas behave differently from river- and wave-dominated deltas, which tend to have a few main distributaries. Once a wave- or river- distributary silts up, it is abandoned, and a new channel forms elsewhere. In a tidal delta, new distributaries are formed during times when there's a lot of water around – such as floods or storm surges. These distributaries slowly silt up at a pretty constant rate until they fizzle out.[13]		A Gilbert delta (named after Grove Karl Gilbert) is a specific type of delta formed from coarse sediments, as opposed to gently-sloping muddy deltas such as that of the Mississippi. For example, a mountain river depositing sediment into a freshwater lake would form this kind of delta.[14] [15] While some authors describe both lacustrine and marine locations of Gilbert deltas,[14] others note that their formation is more characteristic of the freshwater lakes, where it is easier for the river water to mix with the lakewater faster (as opposed to the case of a river falling into the sea or a salt lake, where less dense fresh water brought by the river stays on top longer).[16]		G.K. Gilbert himself first described this type of delta on Lake Bonneville in 1885.[16] Elsewhere, similar structures occur, for example, at the mouths of several creeks that flow into Okanagan Lake in British Columbia and forming prominent peninsulas at Naramata (49°35′30″N 119°35′30″W﻿ / ﻿49.59167°N 119.59167°W﻿ / 49.59167; -119.59167), Summerland (49°34′23″N 119°37′45″W﻿ / ﻿49.57306°N 119.62917°W﻿ / 49.57306; -119.62917), or Peachland (49°47′00″N 119°42′45″W﻿ / ﻿49.78333°N 119.71250°W﻿ / 49.78333; -119.71250).		A tidal freshwater delta[17] is a sedimentary deposit formed at the boundary between an upland stream and an estuary, in the region known as the "subestuary".[18] Drowned coastal river valleys that were inundated by rising sea levels during the late Pleistocene and subsequent Holocene tend to have dendritic estuaries with many feeder tributaries. Each tributary mimics this salinity gradient from their brackish junction with the mainstem estuary up to the fresh stream feeding the head of tidal propagation. As a result, the tributaries are considered to be “subestuaries”.The origin and evolution of a tidal freshwater delta involves processes that are typical of all deltas[4] as well as processes that are unique to the tidal freshwater setting.[19][20] The combination of processes that create a tidal freshwater delta result in a distinct morphology and unique environmental characteristics. Many tidal freshwater deltas that exist today are directly caused by the onset of or changes in historical land use, especially deforestation, intensive agriculture, and urbanization.[21] These ideas are well illustrated by the many tidal freshwater deltas prograding into Chesapeake Bay along the east coastline of the United States. Research has demonstrated that the accumulating sediments in this estuary derive from post-European settlement deforestation, agriculture, and urban development.[22][23][24]		Other rivers, particularly those on coasts with significant tidal range, do not form a delta but enter into the sea in the form of an estuary. Notable examples include the Saint Lawrence River and the Tagus estuary.		In rare cases the river delta is located inside a large valley and is called an inverted river delta. Sometimes a river divides into multiple branches in an inland area, only to rejoin and continue to the sea. Such an area is called an inland delta, and often occurs on former lake beds. The Inner Niger Delta and Peace–Athabasca Delta are notable examples. The Amazon has also an inland delta before the island of Marajó.		In some cases, a river flowing into a flat arid area splits into channels that evaporate as it progresses into the desert. Okavango Delta in Botswana is one well-known example.		The generic term mega delta can be used to describe very large Asian river deltas, such as the Changjiang (Yangtze), Pearl, Red, Mekong, Irrawaddy, Ganges-Brahmaputra, and Indus.		The formation of a delta is complicated, multiple, and cross-cutting over time, but in a simple delta three main types of bedding may be distinguished: the bottomset beds, foreset/frontset beds, and topset beds. This three part structure may be seen in small scale by crossbedding.[14][25]		The Ganges/Brahmaputra combination delta, which spans most of Bangladesh and empties into the Bay of Bengal, is the world's largest delta.		The St. Clair River delta, between the Canadian province of Ontario and the U.S. state of Michigan, is the largest delta emptying into a body of fresh water.		Other rivers with notable deltas include the:		Human activities, such as the creation of dams for hydroelectric power or to create reservoirs can radically alter delta ecosystems. Dams block sedimentation, which can cause the delta to erode away. The use of water upstream can greatly increase salinity levels as less fresh water flows to meet the salty ocean water. While nearly all deltas have been impacted to some degree by humans, the Nile Delta and Colorado River Delta are some of the most extreme examples of the ecological devastation caused to deltas by damming and diversion of water. Construction, irrigation, and land alteration have impacted delta formation. As humans have altered surface roughness, runoff, and groundwater storage, studies have shown river delta retreat. However, historical data documents show that during the Roman Empire and Little Ice Age (times where there was considerable anthropogenic pressure), there were significant sediment accumulation in deltas. The industrial revolution has only amplified the impact of humans on delta growth and retreat.[28]		Ancient deltas are a benefit to the economy due to their well sorted sand and gravel. Sand and gravel is often quarried from these old deltas and used in concrete for highways, buildings, sidewalks, and even landscaping. More than 1 billion tons of sand and gravel are produced in the United States alone.[29] Not all sand and gravel quarries are former deltas, but for ones that are, a lot of the sorting is already done by the power of water.		As lowlands often adjacent to urban areas, deltas often comprise extensive industrial and commercial areas as well as agricultural land. These uses are often in conflict. The Fraser Delta in British Columbia, Canada, includes the Vancouver Airport and the Roberts Bank Superport and the Annacis Island industrial zone, and a mix of commercial, residential and agricultural land. Space is so limited in the Lower Mainland region, and in British Columbia in general, which is very mountainous, that the Agricultural Land Reserve was created to preserve agricultural land for food production.		Researchers have found a number of examples of deltas that formed in Martian lakes. Finding deltas is a major sign that Mars once had large amounts of water. Deltas have been found over a wide geographical range. Below are pictures of a few.[30]		Delta in Ismenius Lacus quadrangle, as seen by THEMIS.		Delta in Lunae Palus quadrangle, as seen by THEMIS.		Delta in Margaritifer Sinus quadrangle as seen by THEMIS.		Probable delta in Eberswalde crater, as seen by Mars Global Surveyor. Image in Margaritifer Sinus quadrangle.		
The Surfrider Foundation USA is a U.S. 501(c)(3) grassroots non-profit environmental organization that works to protect and preserve the world's oceans, waves and beaches. The Surfrider Foundation largely focuses its work on such issues as water quality, beach access, beach and surf spot preservation, and sustaining marine and coastal ecosystems.		Headquartered in San Clemente, California, the Surfrider Foundation maintains a small staff, which work to support the organization's network of grassroots chapters.		The current CEO is Chad Nelsen.[2]						The protection and enjoyment of oceans, waves and beaches through a powerful activist network.[3]		The Surfrider Foundation was started in Malibu, California in 1984 by a handful of surfers to protest threats to their local surf break at Malibu Point. The organization continued on for several years as a loose advocacy group until 1991, when the first chapters were founded. At that point the Surfrider Foundation transitioned into a grassroots activist organization. Today the Surfrider Foundation maintains over 50,000 members and 80 chapters worldwide.		Surfrider Foundation volunteers and staff utilize a number of programs in their efforts to protect the coast and raise awareness of environmental issues.		Surfrider Oahu Chapter hosts the annual John Kelly Environmental Awards in Waimea Valley on the North Shore of Oahu every year in November to coincide with the surf season kick-off, aka the Vans Triple Crown. Awards are dedicated to those who "have helped protect and enhance our coastal community and environment". Three awards are given each year; Lifetime achievement Award, Oahu-based Organization Award and Professional Surfer Award.[4]		Lifetime Achievement		Oahu-Based Company		Professional Surfer		There are 70 Surfrider chapters located along the US East, West, Gulf of Mexico, Hawaiian and Puerto Rico coasts.[7]		
An urban beach; or city beach and sometimes beach club, is defined by urban planners as an artificially-created environment in an urban setting which simulates a public beachfront, through the use of sand, beach umbrellas, and seating elements. It does not include swimming or any sort of natural sloping shoreline into the water (i.e., it is not a natural beach that happens to be in an urban area). The very point of the urban beach is to surprise and delight city residents, workers, and visitors by inserting a beach atmosphere into an urban area that would otherwise be typical cityscape.		There are many variations of urban beaches. Urban beaches are often found along waterways, though some are inserted into town squares or other spaces far from water. The beach may be a seasonal installation over a roadway or parking lot, or it may be permanent. It is not necessarily public land though it is always open to the general public (sometimes with a small admission fee). As river or ocean swimming is not possible, many urban beaches include water features -- for example fountains, wading pools or misting towers -- for cooling off. Some urban beaches feature entertainment and food/beverage areas. A few include sports facilities such as beach volleyball.		Most urban beaches are designed to appeal to a general population, from families to young singles to older citizens. Despite the absence of swimming, swimwear is commonly seen alongside the more usual attire seen in major urban centres.		The popularity of urban beaches has increased in the early 21st century as the concept has been championed by urban planners, landscape architects and local politicians.[1]						Natural urban beaches located at the sea have attracted tourists for a long time, such as the Copacabana of Rio, the central beach of San Sebastián or the City Beach in Stralsund.		Although many cities had experimented with temporary sand installations for various festivals and artistic projects, the modern urban beach concept as a summertime public amenity in the middle of the city was popularized by the Paris-Plages, a program of seasonal urban beach installations along the Seine that started in 2002 and has been enormously successful.[2] While some European urban beaches claim to predate Paris, all built since have been strongly influenced by its design elements and programming.[3]		Many waterfront restaurants and bars around the globe have beach-themed sections, and as these have grown larger and added size and features there has been some crossover with urban beaches. For example, the two artificial beaches in New York City and many of the manmade beaches in German cities feature enclosed beach areas open to visitors, but the spaces are managed by private entities as food and drinks venues and close frequently for concerts and events. Strictly speaking, such locations are private enterprises and not true urban beaches, which can include commercial ventures but should maintain an atmosphere of public space.		This list is only of urban beaches as defined above, open to the public on a free or admission basis. It does not include fully private artificial beaches, natural beaches that exist in urban areas, playgrounds, dedicated waterparks or hardscape fountain plazas.		
Waste and wastes are unwanted or unusable materials. Waste is any substance which is discarded after primary use, or it is worthless, defective and of no use.		Examples include municipal solid waste (household trash/refuse), hazardous waste, wastewater (such as sewage, which contains bodily wastes (feces and urine) and surface runoff), radioactive waste, and others.						According to the Basel Convention on the Control of Transboundary Movements of Hazardous Wastes and Their Disposal of 1989, Art. 2(1), "'Wastes' are substance or objects, which are disposed of or are intended to be disposed of or are required to be disposed of by the provisions of national law".[1]		The UNSD Glossary of Environment Statistics[2] describes waste as "materials that are not prime products (that is, products produced for the market) for which the generator has no further use in terms of his/her own purposes of production, transformation or consumption, and of which he/she wants to dispose. Wastes may be generated during the extraction of raw materials, the processing of raw materials into intermediate and final products, the consumption of final products, and other human activities. Residuals recycled or reused at the place of generation are excluded."		Under the Waste Framework Directive 2008/98/EC, Art. 3(1), the European Union defines waste as "an object the holder discards, intends to discard or is required to discard."[3] For a more structural description of the Waste Directive, see the European Commission's summary.		There are many waste types defined by modern systems of waste management, notably including:		There are many issues that surround reporting waste. It is most commonly measured by size or weight, and there is a stark difference between the two. For example, organic waste is much heavier when it is wet, and plastic or glass bottles can have different weights but be the same size.[4] On a global scale it is difficult to report waste because countries have different definitions of waste and what falls into waste categories, as well as different ways of reporting. Based on incomplete reports from its parties, the Basel Convention estimated 338 million tonnes of waste was generated in 2001.[5] For the same year, OECD estimated 4 billion tonnes from its member countries.[6] Despite these inconsistencies, waste reporting is still useful on a small and large scale to determine key causes and locations, and to find ways of preventing, minimizing, recovering, treating, and disposing waste.				Inappropriately managed waste can attract rodents and insects, which can harbour gastrointestinal parasites, yellow fever, worms, the plague and other conditions for humans, and exposure to hazardous wastes, particularly when they are burned, can cause various other diseases including cancers. Toxic waste materials can contaminate surface water, groundwater, soil, and air which causes more problems for humans, other species, and ecosystems.[7] Waste treatment and disposal produces significant green house gas (GHG) emissions, notably methane, which are contributing significantly to global warming.[5]		Waste management is a significant environmental justice issue. Many of the environmental burdens cited above are more often borne by marginalized groups, such as racial minorities, women, and residents of developing nations. NIMBY (not in my back yard) is the opposition of residents to a proposal for a new development because it is close to them.[8] However, the need for expansion and siting of waste treatment and disposal facilities is increasing worldwide. There is now a growing market in the transboundary movement of waste, and although most waste that flows between countries goes between developed nations, a significant amount of waste is moved from developed to developing nations.[9]		The economic costs of managing waste are high, and are often paid for by municipal governments;[10] money can often be saved with more efficiently designed collection routes, modifying vehicles, and with public education. Environmental policies such as pay as you throw can reduce the cost of management and reduce waste quantities. Waste recovery (that is, recycling, reuse) can curb economic costs because it avoids extracting raw materials and often cuts transportation costs. "Economic assessment of municipal waste management systems – case studies using a combination of life-cycle assessment (LCA) and life-cycle costing (LCC)".[11] The location of waste treatment and disposal facilities often reduces property values due to noise, dust, pollution, unsightliness, and negative stigma. The informal waste sector consists mostly of waste pickers who scavenge for metals, glass, plastic, textiles, and other materials and then trade them for a profit. This sector can significantly alter or reduce waste in a particular system, but other negative economic effects come with the disease, poverty, exploitation, and abuse of its workers.[12]		Resource recovery is the retrieval of recyclable waste, which was intended for disposal, for a specific next use.[13] It is the processing of recyclables to extract or recover materials and resources, or convert to energy. This process is carried out at a resource recovery facility.[14] Resource recovery is not only important to the environment, but it can be cost effective by decreasing the amount of waste sent to the disposal stream, reduce the amount of space needed for landfills, and protect limited natural resources.[15]		Energy recovery from waste is using non-recyclable waste materials and extracting from it heat, electricity, or energy through a variety of processes, including combustion, gasification, pyrolyzation, and anaerobic digestion.[16] This process is referred to as waste-to-energy.		There are several ways to recover energy from waste. Anaerobic digestion is a naturally occurring process of decomposition where organic matter is reduced to a simpler chemical component in the absence of oxygen.[16] Incineration or direct controlled burning of municipal solid waste to reduce waste and make energy. Secondary recovered fuel is the energy recovery from waste that cannot be reused or recycled from mechanical and biological treatment activities.[16] Pyrolysis involves heating of waste, with the absence of oxygen, to high temperatures to break down any carbon content into a mixture of gaseous and liquid fuels and solid residue.[16] Gasification is the conversion of carbon rich material through high temperature with partial oxidation into a gas stream.[16] Plasma arc heating is the very high heating of municipal solid waste to temperatures ranging from 3,000-10,000 °C, where energy is released by an electrical discharge in an inert atmosphere.[16]		Using waste as fuel can offer important environmental benefits. It can provide a safe and cost-effective option for wastes that would normally have to be dealt with through disposal.[16] It can help reduce carbon dioxide emissions by diverting energy use from fossil fuels, while also generating energy and using waste as fuel can reduce the methane emissions generated in landfills by averting waste from landfills.[16]		There is some debate in the classification of certain biomass feedstock as wastes. Crude Tall Oil (CTO), a co-product of the pulp and papermaking process, is defined as a waste or residue in some European countries when in fact it is produced “on purpose” and has significant value add potential in industrial applications. Several companies use CTO to produce fuel,[17] while the pine chemicals industry maximizes it as a feedstock “producing low-carbon, bio-based chemicals” through cascading use.[18]		Education and awareness in the area of waste and waste management is increasingly important from a global perspective of resource management. The Talloires Declaration is a declaration for sustainability concerned about the unprecedented scale and speed of environmental pollution and degradation, and the depletion of natural resources. Local, regional, and global air pollution; accumulation and distribution of toxic wastes; destruction and depletion of forests, soil, and water; depletion of the ozone layer and emission of "green house" gases threaten the survival of humans and thousands of other living species, the integrity of the earth and its biodiversity, the security of nations, and the heritage of future generations. Several universities have implemented the Talloires Declaration by establishing environmental management and waste management programs, e.g. the waste management university project. University and vocational education are promoted by various organizations, e.g. WAMITAB and Chartered Institution of Wastes Management.		Vegetable waste being dumped in a market in Hyderabad		Weapon scraps		Agobox; Bio-medical Waste		Hospital waste		Waste collected in a tricycle				
In oceanography, geomorphology, and earth sciences, a shoal is a natural submerged ridge, bank, or bar that consists of, or is covered by, sand or other unconsolidated material, and rises from the bed of a body of water to near the surface. Often it refers to those submerged ridges, banks, or bars that rise near enough to the surface of a body of water as to constitute a danger to navigation. Shoals are also known as sandbanks, sandbars, or gravelbars. Two or more shoals that are either separated by shared troughs or interconnected by past and or present sedimentary and hydrographic processes are referred to as a shoal complex.[1][2]		The term shoal is also used in a number of ways that can be either similar or quite different from how it is used in the geologic, geomorphic, and oceanographic literature. Sometimes, this terms refers to either (1) any relatively shallow place in a stream, lake, sea, or other body of water; (2) a rocky area on the sea floor within an area mapped for navigation purposes; (3) a growth of vegetation on the bottom of a deep lake that occurs at any depth; (4) and as a verb for the process of proceeding from a greater to a lesser depth of water. [2]						Shoals are characteristically long and narrow (linear) ridges. They can develop where a stream, river, or ocean current promotes deposition of sediment and granular material, resulting in localized shallowing (shoaling) of the water. Marine shoals also develop either by the in place drowning of barrier islands as the result of episodic sea level rise or by the erosion and submergence of inactive delta lobes.		Shoals can appear as a coastal landform in the sea, where they are classified as a type of ocean bank, or as fluvial landforms in rivers, streams, and lakes.		A shoal–sandbar may seasonally separate a smaller body of water from the sea, such as:		The term bar can apply to landform features spanning a considerable range in size, from a length of a few metres in a small stream to marine depositions stretching for hundreds of kilometers along a coastline, often called barrier islands.		They are typically composed of sand, although they could be of any granular matter that the moving water has access to and is capable of shifting around (for example, soil, silt, gravel, cobble, shingle, or even boulders). The grain size of the material comprising a bar is related to the size of the waves or the strength of the currents moving the material, but the availability of material to be worked by waves and currents is also important.		Wave shoaling is the process when surface waves move towards shallow water, such as a beach, they slow down, their wave height increases and the distance between waves decreases. This behavior is called shoaling, and the waves are said to shoal. The waves may or may not build to the point where they break, depending on how large they were to begin with, and how steep the slope of the beach is. In particular, waves shoal as they pass over submerged sandbanks or reefs. This can be treacherous for boats and ships.		Shoaling can also diffract waves, so the waves change direction. For example, if waves pass over a sloping bank which is shallower at one end than the other, then the shoaling effect will result in the waves slowing more at the shallow end. Thus the wave fronts will refract, changing direction like light passing through a prism. Refraction also occurs as waves move towards a beach if the waves come in at an angle to the beach, or if the beach slopes more gradually at one end than the other.		Sandbars, also known as a trough bars, form where the waves are breaking, because the breaking waves set up a shoreward current with a compensating counter-current along the bottom. Sometimes this occurs seaward of a trough (marine landform).		Sand carried by the offshore moving bottom current is deposited where the current reaches the wave break.[3] Other longshore bars may lie further offshore, representing the break point of even larger waves, or the break point at low tide.		A harbor or river bar is a sedimentary deposit formed at a harbor entrance or river mouth by: the deposition of freshwater sediment, or the action of waves on the sea floor or up—current beaches.		Where beaches are suitably mobile, or the river’s suspended and/or bed loads are large enough, deposition can build up a sandbar that completely blocks a river mouth and damming the river. It can be a seasonally natural process of aquatic ecology, causing the formation of estuaries and wetlands in the lower course of the river. This situation will persist until the bar is eroded by the sea, or the dammed river develops sufficient head to break through the bar.		The formation of harbor bars can prevent access for boats and shipping, can be the result of:		In a nautical sense, a bar is a shoal, similar to a reef: a shallow formation of (usually) sand that is a navigation or grounding hazard, with a depth of water of 6 fathoms (11 metres) or less. It therefore applies to a silt accumulation that shallows the entrance to or course of a river, or creek. A bar can form a dangerous obstacle to shipping, preventing access to the river or harbour in unfavourable weather conditions or at some states of the tide.		In addition to longshore bars discussed above that are relatively small features of a beach, the term shoal can be applied to larger geological units that form off a coastline as part of the process of coastal erosion. These include spits and baymouth bars that form across the front of embayments and rias. A tombolo is a bar that forms an isthmus between an island or offshore rock and a mainland shore.		In places of re-entrance along a coastline (such as inlets, coves, rias, and bays), sediments carried by a longshore current will fall out where the current dissipates, forming a spit. An area of water isolated behind a large bar is called a lagoon. Over time, lagoons may silt up, becoming salt marshes.		In some cases, shoals may be precursors to beach expansion and dunes formation, providing a source of windblown sediment to augment such beach or dunes landforms.[4]		Since prehistoric times humans have chosen some shoals as a site of habitation. In some early cases the locations provided easy access to exploit marine resources.[5] In modern times these sites are sometimes chosen for the water amenity or view, but many such locations are prone to storm damage.[6][7]		
The fundus is the seabed in a tidal river below low water mark.[1] This can be owned by the foreshore owner (area between high and low water mark) and may require permission and rent, if used for laying a mooring or putting down crab or lobster pots.				
Longshore drift is a geological process that consists of the transportation of sediments (clay, silt, sand and shingle) along a coast parallel to the shoreline, which is dependent on oblique incoming wind direction. Oblique incoming wind squeezes water along the coast, and so generates a water current which moves parallel to the coast. Longshore drift is simply the sediment moved by the longshore current. This current and sediment movement occurs within the surf zone.		Beach sand is also moved on such oblique wind days, due to the swash and backwash of water on the beach. Breaking surf sends water up the beach (swash) at an oblique angle and gravity then drains the water straight downslope (backwash) perpendicular to the shoreline. Thus beach sand can move downbeach in a zig zag fashion many tens of meters per day. This process is called "beach drift" but some workers regard it as simply part of "longshore drift" because of the overall movement of sand parallel to the coast.		Longshore drift affects numerous sediment sizes as it works in slightly different ways depending on the sediment (e.g. the difference in long shore drift of sediments from a sandy beach to that of sediments from a shingle beach). Sand is largely affected by the oscillatory force of breaking waves, the motion of sediment due to the impact of breaking waves and bed shear from long shore current.[1] Because shingle beaches are much steeper than sandy ones, plunging breakers are more likely to form, causing the majority of long shore transport to occur in the swash zone, due to a lack of an extended surf zone.[1]						There are numerous calculations that take into consideration the factors that produce longshore drift. These formulations are:		These formulas all provide a different view into the processes that generate longshore drift. The most common factors taken into consideration in these formulas are:		Longshore drift plays a large role in the evolution of a shoreline, as if there is a slight change of sediment supply, wind direction, or any other coastal influence longshore drift can change dramatically, impacting on the formation and evolution of a beach system or profile. These changes do not occur due to one factor within the coastal system, in fact there are numerous alterations that can occur within the coastal system that may affect the distribution and impact of longshore drift. Some of these are:		The sediment budget takes into consideration sediment sources and sinks within a system.[3] This sediment can come from any source with examples of sources and sinks consisting of:		This sediment then enters the coastal system and is transported by longshore drift. A good example of the sediment budget and longshore drift working together in the coastal system is inlet ebb-tidal shoals, which store sand that has been transported by long shore transport.[4] As well as storing sand these systems may also transfer or by pass sand into other beach systems, therefore inlet ebb-tidal (shoal) systems provide a good sources and sinks for the sediment budget.[4]		Sediment deposition throughout a shoreline profile conforms to the null point hypothesis; where gravitational and hydraulic forces determine the settling velocity of grains in a seaward fining sediment distribution. Long shore occurs in a 90 to 80 degree backwash so it would be presented as a right angle with the wave line.		This section consists of features of long shore drift that occur on a coast where long shore drift occurs uninterrupted by man-made structures.		Spits are formed when longshore drift travels past a point (e.g. river mouth or re-entrant) where the dominant drift direction and shoreline do not veer in the same direction.[5] As well as dominant drift direction, spits are affected by the strength of wave driven current, wave angle and the height of incoming waves.[6]		Spits are landforms that have two important features, with the first feature being the region at the up-drift end or proximal end (Hart et al., 2008). The proximal end is constantly attached to land (unless breached) and may form a slight “barrier” between the sea and an estuary or lagoon.[7] The second important spit feature is the down-drift end or distal end, which is detached from land and in some cases, may take a complex hook-shape or curve, due to the influence of varying wave directions.[7]		As an example, the New Brighton spit in Canterbury, New Zealand, was created by longshore drift of sediment from the Waimakariri River to the north.[5] This spit system is currently in equilibrium but undergoes phases of deposition and erosion.		Barrier systems are attached to the land at both the proximal and distal end and are generally widest at the down-drift end.[8] These barrier systems may enclose an estuary or lagoon system, like that of Lake Ellesmere enclosed by the Kaitorete Spit or hapua which form at river-coast interface such as at the mouth of the Rakaia River.		The Kaitorete Spit in Canterbury, New Zealand, is a barrier/spit system (which generally falls under the definition barrier, as both ends of the landform are attached to land, but has been named a spit) that has existed below Banks Peninsula for the last 8000 years.[9] This system has undergone numerous changes and fluctuations due to avulsion of the Waimakariri River (which now flows to the north or Banks Peninsula), erosion and phases of open marine conditions.[9] The system underwent further changes c.500 year BP, when longshore drift from the eastern end of the “spit” system created the barrier, which has been retained due to ongoing longshore transport.[9]		The majority of tidal inlets on longshore drift shores accumulate sediment in flood and ebb shoals.[3] Ebb-deltas may become stunted on highly exposed shores and in smaller spaces, whereas flood deltas are likely to increase in size when space is available in a bay or lagoon system.[3] Tidal inlets can act as sinks and sources for large amounts of material, which therefore impacts on adjacent parts of the coastline.[10]		The structuring of tidal inlets is also important for longshore drift as if an inlet is unstructured sediment may by pass the inlet and form bars at the down-drift part of the coast.[10] Although this may also depend on the inlet size, delta morphology, sediment rate and by passing mechanism.[3] Channel location variance and amount may also influence the impact of long shore drift on a tidal inlet as well.		For example, the Arcachon lagoon is a tidal inlet system in South west France, which provides large sources and sinks for longshore drift sediments. The impact of longshore drift sediments on this inlet system is highly influenced by the variation in the number of lagoon entrances and the location of these entrances.[10] Any change in these factors can cause severe down-drift erosion or down-drift accretion of large swash bars.[10]		This section consists of long shore drift features that occur unnaturally and in some cases (e.g. groynes, detached breakwaters) have been constructed to enhance the effects of longshore drift on the coastline but in other cases have a negative impact on long shore drift (ports and harbours).		Groynes are shore protection structures, placed at equal intervals along the coastline in order to stop coastal erosion and generally cross the intertidal zone.[1] Due to this, groyne structures are usually used on shores with low net and high annual longshore drift in order to retain the sediments lost in storm surges and further down the coast.[1]		There are numerous variations to groyne designs with the three most common designs consisting of:		Artificial headlands are also shore protection structures, which are created in order to provide a certain amount of protection to beaches or bays.[1] Although the creation of headlands involves accretion of sediments on the up-drift side of the headland and moderate erosion of the down-drift end of the headland, this is undertaken in order to design a stabilised system that allows material to accumulate in beaches further along the shore.[1]		Artificial headlands can occur due to natural accumulation or also through artificial nourishment.		Detached breakwaters are shore protection structures, created to build up sandy material in order to accommodate drawdown in storm conditions.[1] In order to accommodate drawdown in storm conditions detached breakwaters have no connection to the shoreline, which lets currents and sediment pass between the breakwater and the shore.[1] This then forms a region of reduced wave energy, which encourages the deposition of sand on the lee side of the structure.[1]		Detached breakwaters are generally used in the same way as groynes, to build up the volume of material between the coast and the breakwater structure in order to accommodate storm surges.[1]		The creation of ports and harbours throughout the world can seriously impact on the natural course of longshore drift. Not only do ports and harbours pose a threat to longshore drift in the short term, they also pose a threat to shoreline evolution.[1] The major influence the creation of a port or harbour can have on longshore drift is the alteration of sedimentation patterns, which in turn may lead to accretion and/or erosion of a beach or coastal system.[1]		As an example, the creation of a port in Timaru, New Zealand in the late 19th century led to a significant change in the longshore drift along the South Canterbury coastline.[5] Instead of longshore drift transporting sediment north up the coast towards the Waimataitai lagoon, the creation of the port blocked the drift of these (coarse) sediments and instead caused them to accrete to the south of the port at South beach in Timaru.[5] The accretion of this sediment to the south, therefore meant a lack of sediment being deposited on the coast near the Waimataitai lagoon (to the north of the port), which led to the loss of the barrier enclosing the lagoon in the 1930s and then shortly after, the loss of the lagoon itself.[5] As with the Waimataitai lagoon the Washdyke Lagoon, which currently lies to the north of the Timaru port is undergoing erosion and may eventually breach causing loss of another lagoon environment.		
Coralline algae are red algae in the order Corallinales. They are characterized by a thallus that is hard because of calcareous deposits contained within the cell walls. The colors of these algae are most typically pink, or some other shade of red, but other species can be purple, yellow, blue, white or gray-green. Coralline algae play an important role in the ecology of coral reefs. Sea urchins, parrot fish, limpets (mollusks), and chitons (mollusks), feed on coralline algae. In the temperate Mediterranean sea, coralline algae are the main builders of a typical algal reef, the Coralligène ("coralligenous").[5] Many are typically encrusting and rock-like, found in marine waters all over the world. Only one species lives in freshwater.[6] Unattached specimens (maerl, rhodoliths) may form relatively smooth compact balls to warty or fruticose thalli.		A close look at almost any intertidal rocky shore or coral reef will reveal an abundance of pink to pinkish-grey patches, splashed as though by a mad painter over rock surfaces. These patches of pink "paint" are actually living algae: crustose coralline red algae. The red algae belong to the division Rhodophyta, within which the coralline algae form the order Corallinales. There are over 1600 described species of nongeniculate coralline algae.[7]		The corallines are presently grouped into two families on the basis of their reproductive structures.[8]						Coralline algae are widespread in all of the world's oceans, where they often cover close to 100% of rocky substrata. Only one species, Pneophyllum cetinaensis, is found in freshwater.[6][9] Many are epiphytic (grow on other algae or marine angiosperms), or epizoic (grow on animals), and some are even parasitic on other corallines. Despite their ubiquity, the coralline algae are poorly known by ecologists, and even by specialist phycologists (people who study algae). For example, a recent book on the seaweeds of Hawaii does not include any crustose coralline algae, even though corallines are quite well studied there and dominate many marine areas.		Corallines have been divided into two groups, although this division does not constitute a taxonomic grouping:		Geniculate corallines are branching, tree-like organisms which are attached to the substratum by crustose or calcified, root-like holdfasts. The organisms are made flexible by having noncalcified sections (genicula) separating longer calcified sections (intergenicula). Nongeniculate corallines range from a few micrometres to several centimetres thick crusts. They are often very slow growing, and may occur on rock, coral skeletons, shells, other algae or seagrasses. Crusts may be thin and leafy to thick and strongly adherent. Some are parasitic or partly endophytic on other corallines. Many coralline crusts produce knobby protuberances ranging from a millimetre to several centimetres high. Some are free-living as rhodoliths (rounded, free-living specimens). The morphological complexity of rhodoliths enhances species diversity, and can be used as a non-taxonomic descriptor for monitoring.[10]		Thalli can be divided into three layers: the hypothallus, perithallus and epithallus.[11] The epithallus is periodically shed, either in sheets or piecemeal.[12]		Corallina officinalis		Lithothamnion sp.		Mesophyllum sp.		Unidentified encrusting species		idem		idem		Corallines live in varying depths of water, ranging from periodically exposed intertidal settings to 270 m water depth (around the maximum penetration of light).[13] Some species can tolerate brackish[13] or hypersaline[14] waters, and only one strictly freshwater coralline species exists.[6] (Some species of the morphologically similar, but non-calcifying, Hildenbrandia, however, can survive in freshwater.) A wide range of turbidities and nutrient concentrations can be tolerated.[13]		Corallines, especially encrusting forms, are slow growers, and expand by 0.1 to 80 mm annually.[13] All corallines begin with a crustose stage; some later become "frondose".[15]		As sessile encrusting organisms, the corallines are prone to overgrowth by other "fouling" algae. The group have many defences to such immuration, most of which depend on waves disturbing their thalli. However, the most relied-upon method involves waiting for herbivores to devour the potential encrusters.[16] This places them in the unusual position of requiring herbivory, rather than benefiting from its avoidance.[17] Many species periodically slough their surface epithallus – and anything attached to it.[16]		Some corallines slough off a surface layer of epithallial cells, which in a few cases may be an antifouling mechanism which serves the same function as enhancing herbivore recruitment. This also affects the community, as many algae recruit on the surface of a sloughing coralline, and are then lost with the surface layer of cells. This can also generate patchiness within the community. The common Indo-Pacific corallines, Neogoniolithon fosliei and Sporolithon ptychoides, slough epithallial cells in continuous sheets which often lie on the surface of the plants.		Not all sloughing serves an antifouling function. Epithallial shedding in most corallines is probably simply a means of getting rid of damaged cells whose metabolic function has become impaired. Morton and his students studied sloughing in the South African intertidal coralline alga, Spongites yendoi, a species which sloughs up to 50% of its thickness twice a year. This deep-layer sloughing, which is energetically costly, does not affect seaweed recruitment when herbivores are removed. The surface of these plants is usually kept clean by herbivores, particularly the pear limpet, Patella cochlear. Sloughing in this case is probably a means of eliminating old reproductive structures and grazer-damaged surface cells, and reducing the likelihood of surface penetration by burrowing organisms.		The corallines have an excellent fossil record from the Early Cretaceous onwards, consistent with molecular clocks that show the divergence of the modern taxa beginning in this period.[1] The fossil record of nonarticulated forms is better; the nonmineralized genuiculae of articulated forms break down quickly, scattering the mineralized portions, which decay more quickly.[1]		The earliest "corallines" known date from the Ordovician,[2][3] although modern forms radiated in the Cretaceous.[18] True corallines are found in rocks of Jurassic age onwards.[19] Stem group corallines are reported from the Ediacaran Doushantuo formation;[18] later stem-group forms include Arenigiphyllum, Petrophyton, Graticula, and Archaeolithophyllum. The corallines were thought to have evolved from within the Solenoporaceae,[20] a view that has been disputed.[3] Their fossil record matches their molecular history, and is complete and continuous.[1]		The Sporolithaceae tend to be more diverse in periods of high ocean temperatures; the opposite is true for the Corallinaceae.[13] The group's diversity has closely tracked the efficiency of grazing herbivores; for instance, the Eocene appearance of parrotfish marked a spike in coralline diversity, and the extinction of many delicately branched (and thus predation-prone) forms.[16]		The group's internal taxonomy is in a state of flux; molecular studies are proving more reliable than morphological methods in approximating relationships within the group.[21]		According to AlgaeBase :		According to WRMS :		According to ITIS :		Fresh surfaces are generally colonized by thin crusts, which are replaced by thicker or branched forms during succession over the course of one (in the tropics) to ten (in the Arctic) years.[16]		The corallines deposit calcite in their cell walls; the c-axis is perpendicular to the cell wall. The calcite sometimes contains magnesium; the Mg content varies from individual to individual.[22] High-magnesium content makes more soluble, making coralline algae depositing more vulnerable to ocean acidification, particularly in colder waters.[23]		The first coralline alga recognized as a living organism was probably Corallina in the 1st century AD.[24] In 1837 Rodolfo Amando Philippi recognized coralline algae were not animals, and he proposed the two generic names Lithophyllum and Lithothamnion as Lithothamnium.[24] For many years, they were included in the order Cryptonemiales as the family Corallinaceae until, in 1986, they were raised to the order Corallinales.		Many corallines produce chemicals which promote the settlement of the larvae of certain herbivorous invertebrates, particularly abalone. Larval settlement is adaptive for the corallines because the herbivores remove epiphytes which might otherwise smother the crusts and preempt available light. Settlement is also important for abalone aquaculture; corallines appear to enhance larval metamorphosis and the survival of larvae through the critical settlement period. It also has significance at the community level; the presence of herbivores associated with corallines can generate patchiness in the survival of young stages of dominant seaweeds. This has been seen this in eastern Canada, and it is suspected the same phenomenon occurs on Indo-Pacific coral reefs, yet nothing is known about the herbivore enhancement role of Indo-Pacific corallines, or whether this phenomenon is important in coral reef communities.[citation needed]		Some coralline algae develop into thick crusts which provide microhabitat for many invertebrates. For example, off eastern Canada, Morton found juvenile sea urchins, chitons, and limpets suffer nearly 100% mortality due to fish predation unless they are protected by knobby and undercut coralline algae. This is probably an important factor affecting the distribution and grazing effects of herbivores within marine communities. Nothing is known about the microhabitat role of Indo-Pacific corallines. However, the most common species in the region, Hydrolithon onkodes, often forms an intimate relationship with the chiton Cryptoplax larvaeformis. The chiton lives in burrows it makes in H. onkodes plants, and comes out at night to graze on the surface of the coralline. This combination of grazing and burrowing results in a peculiar growth form (called "castles") in H. onkodes, in which the coralline produces nearly vertical, irregularly curved lamellae. Coralline algae are part of the diet of shingle urchins (Colobocentrotus atratus).		Nongeniculate corallines are of particular significance in the ecology of coral reefs, where they provide calcareous material to the structure of the reef, help cement the reef together, and are important sources of primary production. Coralline algae are especially important in reef construction, as they lay down calcium carbonate as calcite. Although they contribute considerable bulk to the calcium carbonate structure of coral reefs, their more important role in most areas of the reef, is in acting as the cement which binds the reef materials into a sturdy structure.[25]		Corallines are particularly important in constructing the algal ridge's reef framework for surf-pounded reefs in both the Atlantic and Indo-Pacific regions. Algal ridges are carbonate frameworks constructed mainly by nongeniculate coralline algae (after Adey 1978). They require high and persistent wave action to form, so develop best on windward reefs with little or no seasonal change in wind direction. Algal ridges are one of the main reef structures that prevent oceanic waves from striking adjacent coastlines, helping to prevent coastal erosion.[citation needed]		Because of their calcified structure, coralline algae have a number of economic uses. The collection of unattached corallines (maërl) for use as soil conditioners dates to the 18th century. This is particularly significant in Britain and France, where more than 300,000 tonnes of Phymatolithon calcareum (Pallas) Adey & McKinnin and Lithothamnion corallioides are dredged annually. Some harvesting of maërl beds that span several thousand kilometres off the coast of Brazil takes place. These beds contain as-yet undetermined species belonging to the genera Lithothamnion and Lithophyllum. Maërl is also used as a food additive for cattle and pigs, as well as in the filtration of acidic drinking water.		The earliest use of corallines in medicine involved the preparation of a vermifuge from ground geniculate corallines of the genera Corallina and Jania. This use stopped towards the end of the 18th century. Medical science now uses corallines in the preparation of dental bone implants. The cell fusions provide the matrix for the regeneration of bone tissue.		Since coralline algae contain calcium carbonate, they fossilize fairly well. They are particularly significant as stratigraphic markers in petroleum geology. Coralline rock also functions as building stones, with the best examples being in Vienna, Austria.[26]		As a colorful component of live rock sold in the marine aquarium trade, and an important part of reef health, coralline algae are desired in home aquariums for their aesthetic qualities, and ostensible benefit to the tank ecosystem.[citation needed]		
Henry Morrison Flagler (January 2, 1830 – May 20, 1913) was an American industrialist and a founder of Standard Oil. He was also a key figure in the development of the Atlantic coast of Florida and founder of what became the Florida East Coast Railway. He is known as the father of St. Augustine, Miami and Palm Beach, Florida.[2]						Flagler was born in Hopewell, New York, the son of Isaac Flagler, a Presbyterian minister, and Elizabeth Caldwell Morrison Harkness Flagler. Henry had a step-brother: future tycoon Stephen V. Harkness, who had become Elizabeth's stepson when she married David Harkness of Milan, Ohio; and a half-brother, Daniel M. Harkness, Elizabeth's own son with David.[3] Widowed by David's death, Elizabeth had brought her family back to upstate New York and there married Isaac Flagler.		Flagler received an eighth-grade education before Daniel convinced him to leave school at 14 to work at Daniel's uncle's store, Lamon G. Harkness and Company, in Republic, Ohio, at a salary of US$5 per month plus room and board. By 1849, Flagler was promoted to the sales staff at a salary of $40 per month. He later joined Daniel in a grain business started with Lamon in Bellevue, Ohio. In 1862, Flagler and his brother-in-law Barney York founded the Flagler and York Salt Company, a salt mining and production business in Saginaw, Michigan. He found that salt mining required a fair bit of technical knowledge and struggled in the industry during the war. The company collapsed when the American Civil War undercut demand for salt, and Flagler returned to Bellevue having lost his initial $50,000 investment and an additional $50,000 he had borrowed from his father-in-law and Daniel. Flagler felt he had learned a valuable lesson: invest in a business only after thorough investigation.[4]		After the failure of his salt business in Saginaw, Flagler returned to Bellevue in 1866 and reentered the grain business as a commission merchant with The Harkness Grain Company. During this time he worked to pay back Steve Harkness. Through this business, Flagler became acquainted with John D. Rockefeller, who worked as a commission agent with Hewitt and Tuttle for the Harkness Grain Company. By the mid-1860s, Cleveland had become the center of the oil refining industry in America and Rockefeller left the grain business to start his own oil refinery. Rockefeller worked in association with chemist and inventor Samuel Andrews.		Needing capital for his new venture, Rockefeller approached Flagler in 1867. Flagler obtained $100,000 (equivalent of $1.7 million in 2016) from family member Stephen V. Harkness on the condition that Flagler be made a partner. The Rockefeller, Andrews & Flagler partnership was formed with Flagler in control of Harkness' interest.[5] The partnership eventually grew into the Standard Oil Corporation. It was Flagler's idea to use the rebate system to strengthen the firm's position against competitors and the transporting enterprises alike. Flagler was in a special position to make those deals due to his connections as a grain merchant. Though the refunds issued amounted to no more than fifteen cents on the dollar, they put Standard Oil in position to undercut other oil refineries.[6] By 1872, it led the American oil refining industry, producing 10,000 barrels per day (1,600 m3/d). The Flagler family moved to New York in 1877 since New York was becoming the center of commerce in the US. In 1885, Standard Oil moved its corporate headquarters to New York City to the iconic 26 Broadway location.		By the end of the American Civil War, Cleveland was one of the five main refining centers in the U.S. (besides Pittsburgh, Pennsylvania, New York City, and the region in northwestern Pennsylvania where most of the oil originated).		By 1869, there was three times more kerosene refining capacity than needed to supply the market, and the capacity remained in excess for many years.[7] In June 1870, Flagler and Rockefeller formed Standard Oil of Ohio, which rapidly became the most profitable refiner in Ohio. Standard Oil grew to become one of the largest shippers of oil and kerosene in the country. The railroads were fighting fiercely for traffic and, in an attempt to create a cartel to control freight rates, formed the South Improvement Company in collusion with Standard and other oil men outside the main oil centers.[8] The cartel received preferential treatment as a high-volume shipper, which included not just steep rebates of up to 50% for their product but also rebates for the shipment of competing products.[8] Part of this scheme was the announcement of sharply increased freight charges. This touched off a firestorm of protest from independent oil well owners, including boycotts and vandalism, which eventually led to the discovery of Standard Oil's part in the deal. A major New York refiner, Charles Pratt and Company, headed by Charles Pratt and Henry H. Rogers, led the opposition to this plan, and railroads soon backed off. Pennsylvania revoked the cartel’s charter, and non-preferential rates were restored for the time being.[9]		Undeterred, though vilified for the first time by the press, Flagler and Rockefeller continued with their self-reinforcing cycle of buying competing refiners, improving the efficiency of his operations, pressing for discounts on oil shipments, undercutting his competition, making secret deals, raising investment pools, and buying rivals out. In less than four months in 1872, in what was later known as "The Cleveland Conquest" or "The Cleveland Massacre", Standard Oil had absorbed 22 of its 26 Cleveland competitors.[10] Eventually, even his former antagonists, Pratt and Rogers, saw the futility of continuing to compete against Standard Oil: in 1874, they made a secret agreement with their old nemesis to be acquired. Pratt and Rogers became Flagler and Rockefeller's partners. Rogers, in particular, became one of Flagler and Rockefeller's key men in the formation of the Standard Oil Trust. Pratt's son, Charles Millard Pratt, became Secretary of Standard Oil. For many of his competitors, Flagler and Rockefeller had merely to show them the books so they could see what they were up against and make them a decent offer. If they refused his offer, Flagler and Rockefeller told them they would run them into bankruptcy and then cheaply buy up their assets at auction. Flagler and Rockefeller saw themselves as the industry’s saviors, "an angel of mercy" absorbing the weak and making the industry as a whole stronger, more efficient, and more competitive.[11] Standard was growing horizontally and vertically. It added its own pipelines, tank cars, and home delivery network. It kept oil prices low to stave off competitors, made its products affordable to the average household, and, to increase market penetration, sometimes sold below cost if necessary. It developed over 300 oil-based products from tar to paint to Vaseline petroleum jelly to chewing gum. By the end of the 1870s, Standard was refining over 90% of the oil in the U.S.[12]		In 1877, Standard clashed with Thomas A. Scott the president of the Pennsylvania Railroad, its chief hauler. Flagler and Rockefeller had envisioned the use of pipelines as an alternative transport system for oil and began a campaign to build and acquire them.[13] The railroad, seeing Standard’s incursion into the transportation and pipeline fields, struck back and formed a subsidiary to buy and build oil refineries and pipelines.[14] Standard countered and held back its shipments and, with the help of other railroads, started a price war that dramatically reduced freight payments and caused labor unrest as well. Flagler and Rockefeller eventually prevailed and the railroad sold all its oil interests to Standard. But in the aftermath of that battle, in 1879 the Commonwealth of Pennsylvania indicted Flagler and Rockefeller on charges of monopolizing the oil trade, starting an avalanche of similar court proceedings in other states and making a national issue of Standard Oil’s business practices.[15]		Standard Oil gradually gained almost complete control of oil refining and marketing in the United States through horizontal integration. In the kerosene industry, Standard Oil replaced the old distribution system with its own vertical system. It supplied kerosene by tank cars that brought the fuel to local markets, and tank wagons then delivered to retail customers, thus bypassing the existing network of wholesale jobbers.[16] Despite improving the quality and availability of kerosene products while greatly reducing their cost to the public (the price of kerosene dropped by nearly 80% over the life of the company), Standard Oil's business practices created intense controversy. Standard's most potent weapons against competitors were underselling, differential pricing, and secret transportation rebates.[17] The firm was attacked by journalists and politicians throughout its existence, in part for these monopolistic methods, giving momentum to the antitrust movement. By 1880, according to the New York World, Standard Oil was "the most cruel, impudent, pitiless, and grasping monopoly that ever fastened upon a country."[18] To the critics Flagler and Rockefeller replied, "In a business so large as ours..... some things are likely to be done which we cannot approve. We correct them as soon as they come to our knowledge."[18]		At that time, many legislatures had made it difficult to incorporate in one state and operate in another. As a result, Flagler and Rockefeller and their associates owned dozens of separate corporations, each of which operated in just one state; the management of the whole enterprise was rather unwieldy. In 1882, Flagler and Rockefeller's lawyers created an innovative form of corporation to centralize their holdings, giving birth to the Standard Oil Trust.[19] The "trust" was a corporation of corporations, and the entity's size and wealth drew much attention. Nine trustees, including Rockefeller, ran the 41 companies in the trust.[19] The public and the press were immediately suspicious of this new legal entity, and other businesses seized upon the idea and emulated it, further inflaming public sentiment. Standard Oil had gained an aura of invincibility, always prevailing against competitors, critics, and political enemies. It had become the richest, biggest, most feared business in the world, seemingly immune to the boom and bust of the business cycle, consistently racking up profits year after year.[20]		Its vast American empire included 20,000 domestic wells, 4,000 miles of pipeline, 5,000 tank cars, and over 100,000 employees.[20] Its share of world oil refining topped out above 90% but slowly dropped to about 80% for the rest of the century.[21] In spite of the formation of the trust and its perceived immunity from all competition, by the 1880s Standard Oil had passed its peak of power over the world oil market. Flagler and Rockefeller finally gave up their dream of controlling all the world’s oil refining. Rockefeller admitted later, "We realized that public sentiment would be against us if we actually refined all the oil."[21] Over time foreign competition and new finds abroad eroded his dominance. In the early 1880s, Flagler and Rockefeller created one of their most important innovations. Rather than try to influence the price of crude oil directly, Standard Oil had been exercising indirect control by altering oil storage charges to suit market conditions. Flagler and Rockefeller then decided to order the issuance of certificates against oil stored in its pipelines. These certificates became traded by speculators, thus creating the first oil-futures market which effectively set spot market prices from then on. The National Petroleum Exchange opened in Manhattan in late 1882 to facilitate the oil futures trading.[22]		Even though 85% of world crude production was still coming from Pennsylvania wells in the 1880s, overseas drilling in Russia and Asia began to reach the world market.[23] Robert Nobel had established his own refining enterprise in the abundant and cheaper Russian oil fields, including the region’s first pipeline and the world’s first oil tanker. The Paris Rothschilds jumped into the fray providing financing.[24] Additional fields were discovered in Burma and Java. Even more critical, the invention of the light bulb gradually began to erode the dominance of kerosene for illumination. But Standard Oil adapted, developing its own European presence, expanding into natural gas production in the U.S. then into gasoline for automobiles, which until then had been considered a waste product.[25]		Standard Oil moved its headquarters to New York City, at 26 Broadway, and Flagler and Rockefeller became central figures in the city's business community. In 1887, Congress created the Interstate Commerce Commission which was tasked with enforcing equal rates for all railroad freight, but by then Standard depended more on pipeline transport.[26] More threatening to Standard’s power was the Sherman Antitrust Act of 1890, originally used to control unions, but later central to the breakup of the Standard Oil trust.[27] Ohio was especially vigorous in applying its state anti-trust laws, and finally forced a separation of Standard Oil of Ohio from the rest of the company in 1892, the first step in the dissolution of the trust.[27]		Upon his ascent to the presidency, Theodore Roosevelt initiated dozens of suits under the Sherman Antitrust Act and coaxed reforms out of Congress. In 1901, U.S. Steel, now controlled by J. Pierpont Morgan, having bought Andrew Carnegie's steel assets, offered to buy Standard’s iron interests as well. A deal brokered by Henry Clay Frick exchanged Standard’s iron interests for U.S. Steel stock and gave Rockefeller and his son membership on the company’s board of directors.		One of the most effective attacks on Flagler and Rockefeller and their firm was the 1905 publication of The History of the Standard Oil Company, by Ida Tarbell, a leading muckraker. She documented the company’s espionage, price wars, heavy-handed marketing tactics, and courtroom evasions.[28] Although her work prompted a huge backlash against the company, Tarbell claims to have been surprised at its magnitude. "I never had an animus against their size and wealth, never objected to their corporate form. I was willing that they should combine and grow as big and wealthy as they could, but only by legitimate means. But they had never played fair, and that ruined their greatness for me." Tarbell's father had been driven out of the oil business during the South Improvement Company affair. Flagler and Rockefeller began a publicity campaign to put the company and themselves in a better light. Though Flagler and Rockefeller had long maintained a policy of active silence with the press, they decided to make themselves more accessible and responded with conciliatory comments such as "capital and labor are both wild forces which require intelligent legislation to hold them in restriction."[29] Flagler and Rockefeller continued to consolidate their oil interests as best they could until New Jersey, in 1909, changed its incorporation laws to effectively allow a re-creation of the trust in the form of a single holding company. Rockefeller retained his nominal title as president until 1911 and he kept his stock. At last in 1911, the Supreme Court of the United States found Standard Oil Company of New Jersey in violation of the Sherman Antitrust Act. By then the trust still had a 70% market share of the refined oil market but only 14% of the U.S. crude oil supply.[30] The court ruled that the trust originated in illegal monopoly practices and ordered it to be broken up into 34 new companies. These included, among many others, Continental Oil, which became Conoco, now part of ConocoPhillips; Standard of Indiana, which became Amoco, now part of BP; Standard of California, which became Chevron; Standard of New Jersey, which became Esso (and later, Exxon), now part of ExxonMobil; Standard of New York, which became Mobil, now part of ExxonMobil; and Standard of Ohio, which became Sohio, now part of BP. Pennzoil and Chevron have remained separate companies.[31]		When Flagler envisioned successes in the oil industry, he and Rockefeller started building their fortune in refining oil in Cleveland, Ohio. Cleveland became very well known for oil refining, as, "More and more crude oil was shipped from the oil regions to Cleveland for the refining process because of transportation facilities and the aggressiveness of the refiners there. It was due largely to the efforts of Henry M. Flagler and John D. Rockefeller."[32] Flagler and Rockefeller worked hard for their company to achieve such prominence. Henry explained: "We worked night and day, making good oil as cheaply as possible and selling it for all we could get."[33] Not only did Flagler and Rockefeller's Standard Oil company become well known in Ohio, they expanded to other states, as well as gained additional capital in purchasing smaller oil refining companies across the nation.[33] According to Allan Nevins, in John D. Rockefeller (p 292), "Standard Oil was born as a big enterprise, it had cut its teeth as a partnership and was now ready to plunge forward into a period of greater expansion and development. It soon was doing one tenth of all the petroleum business in the United States. Besides its two refineries and a barrel plant in Cleveland, it possessed a fleet of tank cars and warehouses in the oil regions as well as warehouses and tanks in New York."[34]		By 1892, Standard Oil had a monopoly over all oil refineries in the United States. In an overall calculation of America's oil refineries' assets and capital, Standard Oil surpassed all.[35] Standard Oil's combined assets equalled approximately $42,882,650.00 (U.S) from: Indiana, Kentucky, New Jersey, New York and Ohio. As well as the highest capitalization, totaling $26,000,000 (U.S).[35] The history of American oil refining begins with Henry Morrison Flagler, and his business associate and friend, John D. Rockefeller, as they built the biggest, most prosperous and monopolizing oil empire of their time: Standard Oil.		Standard Oil had the same principal owners that Rockefeller, Andrews and Flagler had, give or take a few business associates: one of whom was Rockefeller's brother, William.[36] Standard Oil monopolized quickly and took America by storm.[37] Although Standard Oil was a partnership, Flagler was credited as the brain behind the booming oil refining business. According to Edwin Lefevre, in "Flagler and Florida" from Everybody's Magazine, XXII (February, 1910) p. 183, "When John D. Rockefeller was asked if the Standard Oil company was the result of his thinking, he answered, "No, sir. I wish I had the brains to think of it. It was Henry M. Flagler."[38] Flagler served as an active part of Standard Oil until 1882. John Dustin Archbold, known for being more aggressive, was hired by the Rockefellers. Flagler stepped back to take a secondary role at Standard Oil, but served as a vice president through 1908 and was part of ownership until 1911.[39]		On the advice of his physician, Flagler traveled to Jacksonville for the winter with his first wife, Mary (née Harkness), who was quite ill. Two years after she died in 1881, he married again. Ida Alice (née Shourds) Flagler had been a caregiver for Mary. After their wedding, the couple traveled to Saint Augustine. Flagler found the city charming, but the hotel facilities and transportation systems inadequate. Franklin W. Smith had just finished building Villa Zorayda and Flagler offered to buy it for his honeymoon. Smith would not sell, but he planted the seed of St. Augustine's and Florida's future in Flagler's mind.[40]		Although Flagler remained on the board of directors of Standard Oil, he gave up his day-to-day involvement in the corporation to pursue his interests in Florida. He returned to St. Augustine in 1885 and made Smith an offer. If Smith could raise $50,000, Flagler would invest $150,000 and they would build a hotel together. Perhaps fortunately for Smith, he couldn't come up with the funds,[41] so Flagler began construction of the 540-room Ponce de León Hotel by himself, but spent several times his original estimate. Smith helped train the masons on the mixing and pouring techniques he used on Zorayda.[42]		Realizing the need for a sound transportation system to support his hotel ventures, Flagler purchased short line railroads in what would later become known as the Florida East Coast Railway. He modernized the existing railroads for them to accommodate heavier loads and more traffic.		His next project was the Ponce de León Hotel, now part of Flagler College. He invested with the guidance of Dr. Andrew Anderson, a native of St. Augustine. After many years of work, it opened on January 10, 1888, and was an instant success.		This project sparked Flagler's interest in creating a new "American Riviera." Two years later, he expanded his Florida holdings. He built a railroad bridge across the St. Johns River to gain access to the southern half of the state and purchased the Hotel Ormond, just north of Daytona. He also built the Alcazar hotel as an overflow hotel for the Ponce de León Hotel. The Alcazar stands today as the Lightner Museum next to the Casa Monica Hotel in St. Augustine that Flager bought from Franklin W. Smith. His personal dedication to the state of Florida was demonstrated when he began construction on his private residence, Kirkside, in St. Augustine.		Flagler completed the 1,100-room Royal Poinciana Hotel on the shores of Lake Worth in Palm Beach and extended his railroad to its service town, West Palm Beach, by 1894, founding Palm Beach and West Palm Beach.[2] The Royal Poinciana Hotel was at the time the largest wooden structure in the world. Two years later, Flagler built the Palm Beach Inn (renamed Breakers Hotel Complex in 1901), overlooking the Atlantic Ocean in Palm Beach.		Flagler originally intended West Palm Beach to be the terminus of his railroad system, but in 1894 and 1895, severe freezes hit the area, causing Flagler to reconsider. Sixty miles south, the area today known as Miami was reportedly unharmed by the freeze. To further convince Flagler to continue the railroad to Miami, he was offered land in exchange for laying rail tracks from private landowners, the Florida East Coast Canal and Transportation Company, and the Boston and Florida Atlantic Coast Land Company. The land owners were Julia Tuttle, whom he had met in Cleveland, Ohio, and William Brickell, who ran a trading post on the Miami River.		Such incentive led to the development of Miami, which was an unincorporated area at the time. Flagler encouraged fruit farming and settlement along his railway line and made many gifts to build hospitals, churches and schools in Florida.		By 1896, Flagler's railroad, the Florida East Coast Railway, reached Biscayne Bay. Flagler dredged a channel, built streets, instituted the first water and power systems, and financed the city's first newspaper, The Metropolis. When the city was incorporated in 1896, its citizens wanted to honor the man responsible for its growth by naming it "Flagler". He declined the honor, persuading them to use an old Indian name, "Mayaimi". Instead, an artificial island was constructed in Biscayne Bay called Flagler Monument Island. In 1897, Flagler opened the exclusive Royal Palm Hotel there. He became known as the Father of Miami, Florida.		Flagler's second wife, the former Ida Alice Shourds, was declared insane by Flagler's friend Dr. Anderson in 1896 and was institutionalized on and off starting that year. At the same time, he began to have a relationship affair with Mary Lily Kenan. In 1899 Flagler had created a strong enough acquaintance with Mary Lily that papers began to openly question whether the two were having an affair. That year he reportedly gifted her more than $1 million in jewelry.[43] In 1901, Flagler bribed the Florida Legislature and Governor to pass a law that made incurable insanity grounds for divorce, opening the way for Flagler to remarry. Flagler was the only person to be divorced under the law before it was repealed in 1905.[44] A spouse's mental incapacity was later restored by the legislature as a grounds for dissolution of marriage, and remains the law of Florida today.[45]		On August 24, 1901, 10 days after his divorce, Flagler married Mary Lily at her family's plantation, Liberty Hall, and the couple soon moved into their new Palm Beach estate, Whitehall, a 55-room beaux arts home designed by the New York-based firm of Carrère and Hastings, which also had designed the New York Public Library and the Pan American Exposition.[46] Built in 1902 as a wedding present to Mary Lily, Whitehall (now the Flagler Museum) was a 60,000-square-foot (5,600 m²) winter retreat that established the Palm Beach "season" of about 8–12 weeks, for the wealthy of America's Gilded Age.		By 1905, Flagler decided that his Florida East Coast Railway should be extended from Biscayne Bay to Key West, a point 128 miles (206 km) past the end of the Florida peninsula. At the time, Key West was Florida's most populous city, with a population of 20,000, and it was also the United States' deep water port closest to the canal that the U.S. government proposed to build in Panama. Flagler wanted to take advantage of additional trade with Cuba and Latin America as well as the increased trade with the west that the Panama Canal would bring.		In 1912, the Florida Overseas Railroad was completed to Key West. Over thirty years, Flagler had invested about $50 million in railroad, home and hotel construction and had made donations to suffering farmers after the freeze in 1894. When asked by the president of Rollins College in Winter Park about his philanthropic efforts, Flagler reportedly replied, "I believe this state is the easiest place for many men to gain a living. I do not believe any one else would develop it if I do not ... but I do hope to live long enough to prove I am a good business man by getting a dividend on my investment."[47]		In May 1913, Flagler fell down a flight of marble stairs at Whitehall. He never recovered and died in Palm Beach of his injuries on May 20 at 83 years of age.[48][49] At 3pm on the day of the funeral, May 23, 1913, every engine on the Florida East Coast Railway stopped wherever it was for ten minutes as a tribute to Flagler. It was reported that people along the railway line waited all night for the passing of the funeral train as it traveled from Palm Beach to St. Augustine.[50]		Flagler was entombed in the Flagler family mausoleum at Memorial Presbyterian Church in St. Augustine alongside his first wife, Mary Harkness; daughter, Jenny Louise; and granddaughter, Marjorie. Only his son Harry survived of the three children by his first marriage in 1853 to Mary Harkness. A large portion of his estate was designated for a "niece" who was said actually to be a child born out of wedlock.		When looking back at Flagler's life, after Flagler's death, George W. Perkins, of J.P. Morgan & Co., reflected, "But that any man could have the genius to see of what this wilderness of waterless sand and underbrush was capable and then have the nerve to build a railroad here, is more marvelous than similar development anywhere else in the world." [51]		Miami's main east-west street is named Flagler Street and is the main shopping street in Downtown Miami. There is also a monument to him on Flagler Monument Island in Biscayne Bay in Miami; Flagler College and Flagler Hospital are named after him in St. Augustine. Flagler County, Florida, Flagler Beach, Florida and Flagler, Colorado are also named for him. Whitehall, Palm Beach, is open to the public as the Henry Morrison Flagler Museum; his private railcar No. 91 is preserved inside a Beaux Arts pavilion built to look like a 19th-century railway palace.[52]		On February 24, 2006, a statue of Flagler was unveiled in Key West near the spot where the Over-Sea Railroad once terminated. Also, on July 28, 2006, a statue of Flagler was unveiled on the southeast steps of Miami's Dade County Courthouse, located on Miami's Flagler Street.		The Overseas Railroad, also known as the Key West Extension of the Florida East Coast Railway, was heavily damaged and partially destroyed in the Labor Day Hurricane of 1935. The railroad was financially unable to rebuild the destroyed sections, so the roadbed and remaining bridges were sold to the State of Florida, which built the Overseas Highway to Key West, using much of the remaining railway infrastructure.		Flagler's third wife, Mary Lily Kenan Flagler, was born in North Carolina; the top-ranked Kenan-Flagler Business School at the University of North Carolina at Chapel Hill is named for Flagler and his wife, who was an early benefactor of UNC along with her family and descendants.[53] After Flagler's death, she married an old friend, Robert Worth Bingham, who used an inheritance from her to buy the Louisville Courier-Journal newspaper. The Bingham-Flagler marriage (and questions about her death or possible murder) figured prominently in several books that appeared in the 1980s, when the Bingham family sold the newspaper in the midst of great acrimony. Control of the Flagler fortune largely passed into the hands of Mary Lily Kenan's family of sisters and brother, who survived into the 1960s.		
A tidal island is a piece of land that is connected to the mainland by a natural or man-made causeway that is exposed at low tide and submerged at high tide. Because of the mystique surrounding tidal islands many of them have been sites of religious worship, such as Mont Saint-Michel with its Benedictine Abbey. Tidal islands are also commonly the sites of fortresses because of their natural fortifications.						Grótta in Seltjarnarnes in Capital Region		43 (unbridged) tidal islands can be walked to from the UK mainland.[1]		
The shoreline is where the land meets the sea and it is continually changing. Over the long term, the water is eroding the land. Beaches represent a special case, in that they exist where sand accumulated from the same processes that strip away rocky and sedimentary material. That is, they can grow as well as erode. River deltas are another exception, in that silt that erodes up river can accrete at the river's outlet and extend ocean shorelines. Catastrophic events such as tsunamis, hurricanes and storm surges accelerate beach erosion, potentially carrying away the entire sand load. Human activities can be as catastrophic as hurricanes, albeit usually over a longer time interval.[citation needed]						Tsunamis, potentially enormous waves often caused by earthquakes, have great erosional and sediment-reworking potential. They may strip beaches of sand that may have taken years to accumulate and may destroy trees and other coastal vegetation. Tsunamis are also capable of flooding hundreds of meters inland past the typical high-water level and fast-moving water, associated with the inundating tsunami, can crush homes and other coastal structures.		A storm surge is an onshore gush of water associated with a low pressure weather system—storms. Storm surges can cause beach accretion and erosion.[1] Historically notable storm surges occurred during the North Sea Flood of 1953, Hurricane Katrina, and the 1970 Bhola cyclone.		The gradual evolution of beaches often comes from the interaction of longshore drift, a wave-driven process by which sediments move along a beach shore, and other sources of erosion or accretion, such as nearby rivers.		Deltas are nourished by alluvial systems and accumulate sand and silt, growing where the sediment flux from land is large enough to avoid complete removal by coastal currents, tides, or waves.		Most modern deltas formed during the last five thousand years, after the present sea-level high stand was attained. However, not all sediment remains permanently in place: in the short term (decades to centuries), exceptional river floods, storms or other energetic events may remove significant portions of delta sediment or change its lobe distribution and, on longer geological time scales, sea-level fluctuations lead to destruction of deltaic features.		In the Mediterranean sea, deltas have been continuously growing for the last several thousand years. Six to seven thousand years ago, the sea level stabilized, and continuous river systems, ephemeral torrents, and other factors began this steady accretion. Since intense human use of coastal areas is a relatively recent phenomenon (except in the Nile delta), beach contours were primarily shaped by natural forces until the last centuries.		In Barcelona, for example, the accretion of the coast was a natural process until the late Middle Ages, when harbor-building increased the rate of accretion.		The port of Ephesus, one of the great cities of the Ionian Greeks in Asia Minor, was filled with sediment due to accretion from a nearby river; it is now 5 kilometers (3.1 mi) from the sea. Likewise, Ostia, the once-important port near ancient Rome, is now several kilometers inland, the coastline having moved slowly seaward.		Bruges became a port during the early Middle Ages and was accessible by sea until around 1050. At that time, however, the natural link between Bruges and the sea silted up. In 1134, a storm flood opened a deep channel, the Zwin, linking the city to the sea until the fifteenth century via a canal from the Zwin to Bruges. Bruges had to use a number of outports, such as Damme and Sluis, for this purpose. In 1907, a new seaport was inaugurated in Zeebrugge.		At the present time important segments of low coasts are in recession, losing sand and reducing beach dimensions. This loss can occur very rapidly. There are various reasons for beach recession, some more natural than others (degree of anthropization). Examples of this are occurring at Sète, in California, in Poland, in Aveiro (Portugal), and in the Netherlands and elsewhere along the North Sea. In Europe, coastal erosion is widespread (at least 70%) and distributed very irregularly.		Some of the coastal defence bunkers of the Atlantic Wall, built by the German soldiers during the Second World War at the top of the dunes are now underwater 2/3 of the times. It shows 200 meters of recession of the beach in 65 years.		The coast recession near Sète is related with coastal drift sand supply interruption due to growth of the Rhone delta, which (like most deltas) is becoming independent of the rest of the coast. The present lido shoreline is 210 meters away from the Roman lido.		California's beaches and other shoreline features change according to the availability of beach sand, the wave and current energy impinging on the coast, and other physical processes that affect the movement of sand. A constant supply of sand is necessary for beaches to form and be maintained along this shoreline. Many human activities, including dam construction and river channelization, have reduced the supply of sand that reaches the ocean. This, in turn, has prevented beaches from being replenished and has thus created greater vulnerability for shorelines that have always been subject to varying levels of erosion. There are few practical solutions to improving sand supply from inland sources, so management of shoreline erosion will likely continue to focus at the land/sea interface along the California coastline.		Construction of breakwaters, jetties, or groyne fields to protect harbor entrances, maintain beaches, or protect coastal structures have both helped and harmed the movement of sand along the shoreline. Protective armoring formations trap sand and allow beaches to expand up-coast from the device, but can interrupt the flow of sand to beaches located down-coast.		During the last glaciation, the Baltic Polish area was covered in ice and associated morainal sediments. Deglaciation left a substantial amount of unconsolidated sediment. Currently, these unconsolidated sediments are strongly eroded and reworked by the sea.		The North Portuguese coast and its beaches were fed by large Iberian rivers. The massive building of dams in the Douro River basin has cut the sediment supply to the Aveiro coast, resulting in its recession. Hard protective works have been done all along.		The Dutch coast consists of sandy, multi-barred beaches and can be characterised as a wave-dominated coast. Approximately 290 km of the coast consists of dunes and 60 km is protected by structures such as dikes and dams. With the melting of the ice at the end of the last ice age the coastline shifted eastward until about 5000 years ago the present position of the Dutch coastline was reached.		As the sea level rise stagnated, the sand supply decreased and the formation of the beach ridges stopped, after which when the sea broke through the lines of dunes during storms, men started to defend the land by building primitive dikes and walls. The dunes, together with the beach and the shoreline, offer a natural, sandy defence to the sea. About 30% of the Netherlands lies below sea level.		Over the last 30 years, approximately 1 million m³ sand per year has been lost from the Dutch coast to deep water. In most northern coastal sections, erosion occurs in deep water and also in the nearshore zone. In most southern sections, sedimentation occurs in the nearshore zone and erosion in deep water.		Structural erosion is due to sea level rise relative to the land and, in some spots, it is caused by harbour dams. The Dutch coast looked at as a single unit shows erosive behaviour. Approximately 12 million m³ of sand is transferred annually from the North Sea to the Wadden Sea as a result of relative rising sea level and coastal erosion.		Several geological events and the climate can change (progressively or suddenly) the relative height of the Earth's surface to the sea-level. These events or processes continuously change coastlines.		Volcanic activity can create new islands. The 800 meters (2,600 ft) in diameter Surtsey Island, Iceland, for example, was created between November 1963 and June 1967. The island has since partially eroded, but it is expected to last another 100 years.		Some earthquakes can create sudden variations of relative ground level and change the coastline dramatically. Structurally controlled coasts include the San Andreas fault zone in California and the seismic Mediterranean belt (from Gibraltar to Greece).		The Bay of Pozzuoli, in Pozzuoli, Italy experienced hundreds of tremors between August 1982 and December 1984. The tremors, which reached a peak on October 4, 1983, damaged 8,000 buildings in the city center and raised the sea bottom by almost 2 meters (6.6 ft). This rendered the Bay of Pozzuoli too shallow for large craft and required the reconstruction of the harbour with new quays. The photo at the upper right shows the harbor before the uplift while the one on the bottom right shows the new quay.		Subsidence is the motion of the Earth's surface downward relative to the sea level due to internal geodynamic causes. The opposite of subsidence is uplift, which increases elevation.		Venice is probably the best-known example of a subsiding location. It experiences periodic flooding when extreme high tides or surges arrive. This phenomenon is caused by the compaction of young sediments in the Po River delta area, magnified by subsurface water and gas exploitation. Man-made works to solve this progressive sinking have been unsuccessful.		Mälaren, the third-largest lake in Sweden, is an example of deglacial uplift. It was once a bay on which seagoing vessels were once able to sail far into the country's interior, but it ultimately became a lake. Its uplift was caused by deglaciation: the removal of the weight of ice-age glaciers caused rapid uplift of the depressed land. For 2,000 years as the ice was unloaded, uplift proceeded at about 7.5 centimeters (3.0 in)/year. Once deglaciation was complete, uplift slowed to about 2.5 centimeters (0.98 in) annually, and it decreased exponentially after that. Today, annual uplift rates are 1 centimeter (0.39 in) or less, and studies suggest that rebound will continue for about another 10,000 years. The total uplift from the end of deglaciation may be up to 400 meters (1,300 ft).		
In earth science, erosion is the action of surface processes (such as water flow or wind) that remove soil, rock, or dissolved material from one location on the Earth's crust, then transport it away to another location.[1] The particulate breakdown of rock or soil into clastic sediment is referred to as physical or mechanical erosion; this contrasts with chemical erosion, where soil or rock material is removed from an area by its dissolving into a solvent (typically water), followed by the flow away of that solution. Eroded sediment or solutes may be transported just a few millimetres, or for thousands of kilometres.		Natural rates of erosion are controlled by the action of geomorphic drivers, such as rainfall;[2] bedrock wear in rivers; coastal erosion by the sea and waves; glacial plucking, abrasion, and scour; areal flooding; wind abrasion; groundwater processes; and mass movement processes in steep landscapes like landslides and debris flows. The rates at which such processes act control how fast a surface is eroded. Typically, physical erosion proceeds fastest on steeply sloping surfaces, and rates may also be sensitive to some climatically-controlled properties including amounts of water supplied (e.g., by rain), storminess, wind speed, wave fetch, or atmospheric temperature (especially for some ice-related processes). Feedbacks are also possible between rates of erosion and the amount of eroded material that is already carried by, for example, a river or glacier.[3][4] Processes of erosion that produce sediment or solutes from a place contrast with those of deposition, which control the arrival and emplacement of material at a new location.[1]		While erosion is a natural process, human activities have increased by 10-40 times the rate at which erosion is occurring globally.[5] At well-known agriculture sites such as the Appalachian Mountains, intensive farming practices have caused erosion up to 100x the speed of the natural rate of erosion in the region.[6] Excessive (or accelerated) erosion causes both "on-site" and "off-site" problems. On-site impacts include decreases in agricultural productivity and (on natural landscapes) ecological collapse, both because of loss of the nutrient-rich upper soil layers. In some cases, the eventual end result is desertification. Off-site effects include sedimentation of waterways and eutrophication of water bodies, as well as sediment-related damage to roads and houses. Water and wind erosion are the two primary causes of land degradation; combined, they are responsible for about 84% of the global extent of degraded land, making excessive erosion one of the most significant environmental problems worldwide.[7]:2[8]:1		Intensive agriculture, deforestation, roads, anthropogenic climate change and urban sprawl are amongst the most significant human activities in regard to their effect on stimulating erosion.[9] However, there are many prevention and remediation practices that can curtail or limit erosion of vulnerable soils.						Rainfall, and the surface runoff which may result from rainfall, produces four main types of soil erosion: splash erosion, sheet erosion, rill erosion, and gully erosion. Splash erosion is generally seen as the first and least severe stage in the soil erosion process, which is followed by sheet erosion, then rill erosion and finally gully erosion (the most severe of the four).[8]:60–61[10]		In splash erosion, the impact of a falling raindrop creates a small crater in the soil,[11] ejecting soil particles.[12] The distance these soil particles travel can be as much as 0.6 m (two feet) vertically and 1.5 m (five feet) horizontally on level ground.		If the soil is saturated, or if the rainfall rate is greater than the rate at which water can infiltrate into the soil, surface runoff occurs. If the runoff has sufficient flow energy, it will transport loosened soil particles (sediment) down the slope.[13] Sheet erosion is the transport of loosened soil particles by overland flow.[13]		Rill erosion refers to the development of small, ephemeral concentrated flow paths which function as both sediment source and sediment delivery systems for erosion on hillslopes. Generally, where water erosion rates on disturbed upland areas are greatest, rills are active. Flow depths in rills are typically of the order of a few centimetres (about an inch) or less and along-channel slopes may be quite steep. This means that rills exhibit hydraulic physics very different from water flowing through the deeper, wider channels of streams and rivers.[14]		Gully erosion occurs when runoff water accumulates and rapidly flows in narrow channels during or immediately after heavy rains or melting snow, removing soil to a considerable depth.[15][16][17]		Valley or stream erosion occurs with continued water flow along a linear feature. The erosion is both downward, deepening the valley, and headward, extending the valley into the hillside, creating head cuts and steep banks. In the earliest stage of stream erosion, the erosive activity is dominantly vertical, the valleys have a typical V cross-section and the stream gradient is relatively steep. When some base level is reached, the erosive activity switches to lateral erosion, which widens the valley floor and creates a narrow floodplain. The stream gradient becomes nearly flat, and lateral deposition of sediments becomes important as the stream meanders across the valley floor. In all stages of stream erosion, by far the most erosion occurs during times of flood, when more and faster-moving water is available to carry a larger sediment load. In such processes, it is not the water alone that erodes: suspended abrasive particles, pebbles and boulders can also act erosively as they traverse a surface, in a process known as traction.[18]		Bank erosion is the wearing away of the banks of a stream or river. This is distinguished from changes on the bed of the watercourse, which is referred to as scour. Erosion and changes in the form of river banks may be measured by inserting metal rods into the bank and marking the position of the bank surface along the rods at different times.[19]		Thermal erosion is the result of melting and weakening permafrost due to moving water.[20] It can occur both along rivers and at the coast. Rapid river channel migration observed in the Lena River of Siberia is due to thermal erosion, as these portions of the banks are composed of permafrost-cemented non-cohesive materials.[21] Much of this erosion occurs as the weakened banks fail in large slumps. Thermal erosion also affects the Arctic coast, where wave action and near-shore temperatures combine to undercut permafrost bluffs along the shoreline and cause them to fail. Annual erosion rates along a 100-kilometre (62-mile) segment of the Beaufort Sea shoreline averaged 5.6 metres (18 feet) per year from 1955 to 2002.[22]		Shoreline erosion, which occurs on both exposed and sheltered coasts, primarily occurs through the action of currents and waves but sea level (tidal) change can also play a role.		Hydraulic action takes place when air in a joint is suddenly compressed by a wave closing the entrance of the joint. This then cracks it. Wave pounding is when the sheer energy of the wave hitting the cliff or rock breaks pieces off. Abrasion or corrasion is caused by waves launching seaload at the cliff. It is the most effective and rapid form of shoreline erosion (not to be confused with corrosion). Corrosion is the dissolving of rock by carbonic acid in sea water.[citation needed] Limestone cliffs are particularly vulnerable to this kind of erosion. Attrition is where particles/seaload carried by the waves are worn down as they hit each other and the cliffs. This then makes the material easier to wash away. The material ends up as shingle and sand. Another significant source of erosion, particularly on carbonate coastlines, is the boring, scraping and grinding of organisms, a process termed bioerosion.[23]		Sediment is transported along the coast in the direction of the prevailing current (longshore drift). When the upcurrent amount of sediment is less than the amount being carried away, erosion occurs. When the upcurrent amount of sediment is greater, sand or gravel banks will tend to form as a result of deposition. These banks may slowly migrate along the coast in the direction of the longshore drift, alternately protecting and exposing parts of the coastline. Where there is a bend in the coastline, quite often a buildup of eroded material occurs forming a long narrow bank (a spit). Armoured beaches and submerged offshore sandbanks may also protect parts of a coastline from erosion. Over the years, as the shoals gradually shift, the erosion may be redirected to attack different parts of the shore.[citation needed]		Chemical erosion is the loss of matter in a landscape in the form of solutes. Chemical erosion is usually calculated from the solutes found in streams. Anders Rapp pioneered the study of chemical erosion in his work about Kärkevagge published in 1960.[24]		Glaciers erode predominantly by three different processes: abrasion/scouring, plucking, and ice thrusting. In an abrasion process, debris in the basal ice scrapes along the bed, polishing and gouging the underlying rocks, similar to sandpaper on wood. Scientists have shown that, in addition to the role of temperature played in valley-deepening, other glaciological processes, such as erosion also control cross-valley variations. In a homogeneous bedrock erosion pattern, curved channel cross section beneath the ice is created. Though the glacier continues to incise vertically, the shape of the channel beneath the ice eventually remain constant, reaching a U-shaped parabolic steady-state shape as we now see in glaciated valleys. Scientists also provide numerical estimate of the time required for the ultimate formation of a steady-shaped U-shaped valley - approximately 100,000 years. In a weak bedrock (containing material more erodible than the surrounding rocks) erosion pattern, on the contrary, the amount of overdeepening is limited because ice velocities and erosion rates are reduced.[25]		Glaciers can also cause pieces of bedrock to crack off in the process of plucking. In ice thrusting, the glacier freezes to its bed, then as it surges forward, it moves large sheets of frozen sediment at the base along with the glacier. This method produced some of the many thousands of lake basins that dot the edge of the Canadian Shield. Differences in the height of mountain ranges are not only being the result tectonic forces, such as rock uplift, but also local climate variations. Scientists use global analysis of topography to show that glacial erosion controls the maximum height of mountains, as the relief between mountain peaks and the snow line are generally confined to altitudes less than 1500 m.[26] The erosion caused by glaciers worldwide erodes mountains so effectively that the term glacial buzzsaw has become widely used, which describes the limiting effect of glaciers on the height of mountain ranges.[27] As mountains grow higher, they generally allow for more glacial activity (especially in the accumulation zone above the glacial equilibrium line altitude),[28] which causes increased rates of erosion of the mountain, decreasing mass faster than isostatic rebound can add to the mountain.[29] This provides a good example of a negative feedback loop. Ongoing research is showing that while glaciers tend to decrease mountain size, in some areas, glaciers can actually reduce the rate of erosion, acting as a glacial armour.[27] Ice can not only erode mountains, but also protect them from erosion. Depending on glacier regime, even steep alpine lands can be preserved through time with the help of ice. Scientists have proved this theory by sampling eight summits of northwestern Svalbard using Be10 and Al26, showing that northwestern Svalbard transformed from a glacier-erosion state under relatively mild glacial maxima temperature, to a glacier-armour state occupied by cold-based, protective ice during much colder glacial maxima temperatures as the Quaternary ice age progressed.[30]		These processes, combined with erosion and transport by the water network beneath the glacier, leave moraines, drumlins, ground moraine (till), kames, kame deltas, moulins, and glacial erratics in their wake, typically at the terminus or during glacier retreat.[citation needed]		The best-developed glacial valley morphology appears to be restricted to landscapes with low rock uplift rates (less than or equal to 2 mm per year) and high relief, leading to long-turnover times. Where rock uplift rates exceed 2 mm per year, glacial valley morphology has generally been significantly modified in postglacial time. Interplay of glacial erosion and tectonic forcing governs the morphologic impact of glaciations on active orogens, by both influencing their height, and by altering the patterns of erosion during subsequent glacial periods via a link between rock uplift and valley cross-sectional shape.[31]		At extremely high flows, kolks, or vortices are formed by large volumes of rapidly rushing water. Kolks cause extreme local erosion, plucking bedrock and creating pothole-type geographical features called Rock-cut basins. Examples can be seen in the flood regions result from glacial Lake Missoula, which created the channeled scablands in the Columbia Basin region of eastern Washington.[32]		Wind erosion is a major geomorphological force, especially in arid and semi-arid regions. It is also a major source of land degradation, evaporation, desertification, harmful airborne dust, and crop damage—especially after being increased far above natural rates by human activities such as deforestation, urbanization, and agriculture.[33][34]		Wind erosion is of two primary varieties: deflation, where the wind picks up and carries away loose particles; and abrasion, where surfaces are worn down as they are struck by airborne particles carried by wind. Deflation is divided into three categories: (1) surface creep, where larger, heavier particles slide or roll along the ground; (2) saltation, where particles are lifted a short height into the air, and bounce and saltate across the surface of the soil; and (3) suspension, where very small and light particles are lifted into the air by the wind, and are often carried for long distances. Saltation is responsible for the majority (50-70%) of wind erosion, followed by suspension (30-40%), and then surface creep (5-25%).[35]:57[36]		Wind erosion is much more severe in arid areas and during times of drought. For example, in the Great Plains, it is estimated that soil loss due to wind erosion can be as much as 6100 times greater in drought years than in wet years.[37]		Mass movement is the downward and outward movement of rock and sediments on a sloped surface, mainly due to the force of gravity.[38][39]		Mass movement is an important part of the erosional process, and is often the first stage in the breakdown and transport of weathered materials in mountainous areas.[40]:93 It moves material from higher elevations to lower elevations where other eroding agents such as streams and glaciers can then pick up the material and move it to even lower elevations. Mass-movement processes are always occurring continuously on all slopes; some mass-movement processes act very slowly; others occur very suddenly, often with disastrous results. Any perceptible down-slope movement of rock or sediment is often referred to in general terms as a landslide. However, landslides can be classified in a much more detailed way that reflects the mechanisms responsible for the movement and the velocity at which the movement occurs. One of the visible topographical manifestations of a very slow form of such activity is a scree slope.[citation needed]		Slumping happens on steep hillsides, occurring along distinct fracture zones, often within materials like clay that, once released, may move quite rapidly downhill. They will often show a spoon-shaped isostatic depression, in which the material has begun to slide downhill. In some cases, the slump is caused by water beneath the slope weakening it. In many cases it is simply the result of poor engineering along highways where it is a regular occurrence.[citation needed]		Surface creep is the slow movement of soil and rock debris by gravity which is usually not perceptible except through extended observation. However, the term can also describe the rolling of dislodged soil particles 0.5 to 1.0 mm (0.02 to 0.04 in) in diameter by wind along the soil surface.[41]		The amount and intensity of precipitation is the main climatic factor governing soil erosion by water. The relationship is particularly strong if heavy rainfall occurs at times when, or in locations where, the soil's surface is not well protected by vegetation. This might be during periods when agricultural activities leave the soil bare, or in semi-arid regions where vegetation is naturally sparse. Wind erosion requires strong winds, particularly during times of drought when vegetation is sparse and soil is dry (and so is more erodible). Other climatic factors such as average temperature and temperature range may also affect erosion, via their effects on vegetation and soil properties. In general, given similar vegetation and ecosystems, areas with more precipitation (especially high-intensity rainfall), more wind, or more storms are expected to have more erosion.		In some areas of the world (e.g. the mid-western USA), rainfall intensity is the primary determinant of erosivity (for a definition of erosivity check,[42]) with higher intensity rainfall generally resulting in more soil erosion by water. The size and velocity of rain drops is also an important factor. Larger and higher-velocity rain drops have greater kinetic energy, and thus their impact will displace soil particles by larger distances than smaller, slower-moving rain drops.[43]:29–31		In other regions of the world (e.g. western Europe), runoff and erosion result from relatively low intensities of stratiform rainfall falling onto previously saturated soil. In such situations, rainfall amount rather than intensity is the main factor determining the severity of soil erosion by water.[15]		In Taiwan, where typhoon frequency increased significantly in the 21st century, a strong link has been drawn between the increase in storm frequency with an increase in sediment load in rivers and reservoirs, highlighting the impacts climate change can have on erosion.[44]		Vegetation acts as an interface between the atmosphere and the soil. It increases the permeability of the soil to rainwater, thus decreasing runoff. It shelters the soil from winds, which results in decreased wind erosion, as well as advantageous changes in microclimate. The roots of the plants bind the soil together, and interweave with other roots, forming a more solid mass that is less susceptible to both water[45] and wind erosion. The removal of vegetation increases the rate of surface erosion.[46]		The topography of the land determines the velocity at which surface runoff will flow, which in turn determines the erosivity of the runoff. Longer, steeper slopes (especially those without adequate vegetative cover) are more susceptible to very high rates of erosion during heavy rains than shorter, less steep slopes. Steeper terrain is also more prone to mudslides, landslides, and other forms of gravitational erosion processes.[43]:28–30[47][48]		Tectonic processes control rates and distributions of erosion at the Earth's surface. If tectonic action causes part of the Earth's surface (e.g., a mountain range) to be raised or lowered relative to surrounding areas, this must necessarily change the gradient of the land surface. Because erosion rates are almost always sensitive to local slope (see above), this will change the rates of erosion in the uplifted area. Active tectonics also brings fresh, unweathered rock towards the surface, where it is exposed to the action of erosion.		However, erosion can also affect tectonic processes. The removal by erosion of large amounts of rock from a particular region, and its deposition elsewhere, can result in a lightening of the load on the lower crust and mantle. Because tectonic processes are driven by gradients in the stress field developed in the crust, this unloading can in turn cause tectonic or isostatic uplift in the region.[40]:99[49] In some cases, it has been hypothesised that these twin feedbacks can act to localise and enhance zones of very rapid exhumation of deep crustal rocks beneath places on the Earth's surface with extremely high erosion rates, for example, beneath the extremely steep terrain of Nanga Parbat in the western Himalayas. Such a place has been called a "tectonic aneurysm".[50]		Human land development, in forms including agricultural and urban development, is considered a significant factor in erosion[51] and sediment transport. In Taiwan, increases in sediment load in the northern, central, and southern regions of the island can be tracked with the timeline of development for each region throughout the 20th century.[44]		Mountain ranges are known to take many millions of years to erode to the degree they effectively cease to exist. Scholars Pitman and Golovchenko estimate that it takes probably more than 450 million years to erode a mountain mass similar to the Himalaya into an almost-flat peneplain if there are no major sea-level changes.[52] Erosion of mountains massifs can create a pattern of equally high summits called summit accordance.[53] It has been argued that extension during post-orogenic collapse is a more effective mechanism of lowering the height of orogenic mountains than erosion.[54]		Examples of heavily eroded mountain ranges include the Timanides of Northern Russia. Erosion of this orogen has produced sediments that are now found in the East European Platform, including the Cambrian Sablya Formation near Lake Ladoga. Studies of these sediments indicate that it is likely that the erosion of the orogen began in the Cambrian and then intensified in the Ordovician.[55]		If the rate of erosion is higher than the rate of soil formation the soils are being destroyed by erosion.[56] Where soil is not destroyed by erosion, erosion can in some cases prevent the formation of soil features that form slowly. Inceptisols are common soils that form in areas of fast erosion.[57]		While erosion of soils is a natural process, human activities have increased by 10-40 times the rate at which erosion is occurring globally. Excessive (or accelerated) erosion causes both "on-site" and "off-site" problems. On-site impacts include decreases in agricultural productivity and (on natural landscapes) ecological collapse, both because of loss of the nutrient-rich upper soil layers. In some cases, the eventual end result is desertification. Off-site effects include sedimentation of waterways and eutrophication of water bodies, as well as sediment-related damage to roads and houses. Water and wind erosion are the two primary causes of land degradation; combined, they are responsible for about 84% of the global extent of degraded land, making excessive erosion one of the most significant environmental problems.[8][58]		
The Blue Flag is a certification by the Foundation for Environmental Education (FEE)[1] that a beach, marina or sustainable boating tourism operator meets its stringent standards.		The Blue Flag is a trademark owned by FEE which is a not-for-profit, non-governmental organisation[2] consisting of 65 organisations in 60 member countries in Europe, Africa, Oceania, Asia, North America and South America.		FEE's Blue Flag criteria include standards for water quality, safety, environmental education and information, the provision of services and general environmental management criteria. The Blue Flag is sought for beaches, marinas and sustainable boating tourism operators as an indication of their high environmental and quality standards.		Certificates, which FEE refers to as awards, are issued on an annual basis to beaches and marinas of FEE member countries. The awards are announced yearly on 5 June for Europe, Canada, Morocco, Tunisia and other countries in a similar geographic location, and on 1 November for the Caribbean, New Zealand, South Africa and other countries in the southern hemisphere.[3]		In the European Union, the water quality standards are incorporated in the EC Water Framework Directive.		Spain has held the 1st position for nearly three decades since the awards began in 1987.[4]						As a result of the 2015 awards, a total of 4,154 Blue Flags are waving around the world.[5]		The table below lists the Blue Flags (both for beaches and marinas) awarded and in force in 2015.		The table can be sorted to show the total number of Blue Flags per country and also the number of Blue Flags per population, per area or per the length of the coastline of each country.		Note: Wales, Scotland, England and Northern Ireland have always been treated as individual countries e.g. in 2015 Northern Ireland had 10 Blue Flag beaches and marinas, England had 61 Wales had 41 and Scotland 1.[Blue Flag Website 1]		The Blue Flag was created in France in 1985 as a pilot scheme where French coastal municipalities were awarded the Blue Flag on the basis of criteria covering sewage treatment and bathing water quality.		1987 was the "European Year of the Environment" and the European Commission was responsible for developing the European Community activities of that year. The Foundation for Environmental Education in Europe (FEEE) presented the concept of the Blue Flag to the Commission, and it was agreed to launch the Blue Flag Programme as one of several "European Year of the Environment" activities in the Community.		The French concept of the Blue Flag was developed on European level to include other areas of environmental management, such as waste management and coastal planning and protection. Besides beaches marinas also became eligible for the Blue Flag.		In 1987, 244 beaches and 208 marinas from 10 countries were awarded the Blue Flag.		There have been increases in the numbers of Blue Flags awarded each year. The criteria have during these years been changed to more strict criteria. As an example, in 1992 the Programme started using the restrictive guideline values in the EEC Bathing Water Directive as imperative criteria, and this was also the year where all Blue Flag criteria became the same in all participating countries.		In 2001, FEEE rules were changed to allow non-European national organisations, sharing the objectives of FEEE, to become members, and changed its name by dropping Europe from its name, becoming the Foundation for Environmental Education (FEE).		Several organisations and authorities outside the European Union have joined FEE. FEE has been cooperating with UNEP and UN WTO on extending the Programme to areas outside Europe. South Africa, Canada, Morocco, Tunisia, New Zealand and four countries in the Caribbean region are members of FEE. Aruba and Brazil are currently in the pilot phase of the Programme and Jordan, Macedonia, Turks & Caicos Islands, Ukraine and United Arab Emirates have started the implementation of the Blue Flag Programme.		FEE standards allow for regional variations in beach criteria to reflect specific environmental conditions of a region. As of 2006 an international set of criteria is being used with some variations.		In 2016, Blue Flag extended its programme boat-based tourism activities like nature watching (whale watching, bird watching, cage diving etc.), recreational fishing, diving and crewed charter tours. Certified tour operators have to comply with criteria regarding the sustainable operation of their boats and their business as a whole.		In 2015 over 4,154 beaches and marinas globally were awarded the Blue Flag.[Blue Flag Website 2]		47 countries are currently participating in the Blue Flag Programme: Bahamas, Belgium, Brazil, Bulgaria, Canada, Croatia, Cyprus, Denmark, Dominican Republic, England, Estonia, France, Germany, Greece, Iceland, Ireland, Israel, Italy, Jordan, Latvia, Lithuania, Malta, Mexico, Montenegro, Morocco, Netherlands, New Zealand, Northern Ireland, Norway, Poland, Portugal, Puerto Rico, Romania, Serbia, Sint Marteen, Scotland, Slovenia, South Africa, Spain, Sweden, Tunisia, Trinidad and Tobago, Turkey, United Arab Emirates, Ukraine, US Virgin Islands and Wales.		Microbiological test as evidence for bacterial free		The criteria presented above apply to all tour operators that want to be awarded the Blue Flag. In addition, tour operators that offer whale watching, bird watching, seal watching, cage diving, recreational fishing and diving have to comply with additional criteria for the respective activity. These criteria are tailored to the different tourist experiences and take into account the specific environmental issues related to them. They include for example approach distances to different animal species, the correct use of equipment and the humane handling of animals that are caught during recreational fishing tours.		
Chelonii - Oppel 1811 Chlonopteria - Rafinesque 1814 Cheloniae - Schmid 1819 Edigitata - Haworth 1825 Oiacopodae - Wagler 1828 Pterodactyli - Mayer 1849		Sea turtles (superfamily Chelonioidea), sometimes called marine turtles,[3] are reptiles of the order Testudines. The seven extant species of sea turtles are: the green, loggerhead, Kemp's ridley, olive ridley, hawksbill, flatback, and leatherback.[4]		The majority of a sea turtle's body is protected by its shell. The turtle's shell is divided into two sections: carapace (the dorsal portion) and plastron (the ventral portion). The shell is made up of smaller plates called scutes. The leatherback is the only sea turtle that does not have a hard shell. Instead, it bears a mosaic of bony plates beneath its leathery skin.		In general, sea turtles have a more fusiform body plan than their terrestrial or freshwater counterparts. The reduced volume of a fusiform body means sea turtles can not retract their head, legs, and arms into their shells for protection like other turtles can.[5] However this more stream-line body plan reduces drag in the water and allows the turtle to swim more easily.		The leatherback is the largest species of sea turtle. Measuring 2–3 meters (6–9 ft) in length, and 1-1.5 m (3–5 ft) in width, weighing up to 700 kilograms (1500 lb). Other species are smaller, being mostly 60–120 cm (2–4 ft) and proportionally narrower.[6]		Sea turtles, along with other turtles and tortoises, are part of the order Testudines. All species except the leatherback are in the family Cheloniidae. The leatherback is the only extant member of the family Dermochelyidae.		The origin of sea turtles goes back to the Late Jurassic (150 million years ago) with genera such as Plesiochelys, from Europe. In Africa, the first marine turtle is Angolachelys, from the Turonian of Angola.[7] However, neither of these are related to extant sea turtles; the oldest representative of the lineage leading to these was Desmatochelys padillai , from the Early Cretaceous.		A lineage of unrelated marine testudines, the pleurodire bothremydids, also survived well into the Cenozoic.		Sea turtles constitute a single radiation that became distinct from all other turtles at least 110 million years ago.[citation needed]		Below is a cladogram showing the phylogenetic relationships of living and extinct sea turtles in the Chelonioidea based on Peer and Lee (2005)[8]		†Toxochelys		†Ctenochelys		†Euclastes		†Puppigerus		Cheloniidae		†Protostegidae		Dermochelyidae		Sea turtles can be found in oceans except for the polar regions. The flatback sea turtle is found solely on the northern coast of Australia. The Kemp's ridley sea turtle is found solely in the Gulf of Mexico and along the East Coast of the United States.[9]		Sea turtles are generally found in the waters over continental shelves. During the first three to five years of life, sea turtles spend most of their time in the pelagic zone floating in seaweed mats. Green sea turtles in particular are often found in Sargassum mats, in which they find shelter and food.[10] Once the sea turtle has reached adulthood it moves closer to the shore.[11] Females will come ashore to lay their eggs on sandy beaches during the nesting season.[12]		The habitat of a sea turtle has a significant influence on its morphology. Sea turtles are able to grow so large because of the immense size of their habitat: the ocean. The reason that sea turtles are much bigger than land tortoises and freshwater turtles is directly correlated with the vastness of the ocean, and the fact that they travel such far distances, especially the leatherback sea turtles. [13] Having more room to live enables more room for growth.		It takes decades for sea turtles to reach sexual maturity. Mature turtles may migrate thousands of miles to reach breeding sites. After mating at sea, adult female sea turtles return to land to lay their eggs. Different species of sea turtles exhibit various levels of philopatry. In the extreme case, females return to the beach where they hatched. This can take place every two to four years in maturity.		The mature nesting female hauls herself onto the beach, nearly always at night, and finds suitable sand in which to create a nest. Using her hind flippers, she digs a circular hole 40 to 50 centimetres (16 to 20 in) deep. After the hole is dug, the female then starts filling the nest with her clutch of soft-shelled eggs. Depending on the species, a typical clutch may contain 50-350 eggs. After laying, she re-fills the nest with sand, re-sculpting and smoothing the surface, and then camouflaging the nest with vegetation until it is relatively undetectable visually.[10] The whole process takes thirty to sixty minutes. She then returns to the ocean, leaving the eggs untended.[14]		Females may lay 1–8 clutches in a single season. Female sea turtles alternate between mating in the water and laying their eggs on land. Most sea turtle species nest individually. But ridley sea turtles come ashore en masse, known as an arribada (arrival). With the Kemp's ridley sea turtles this occurs during the day.		Sea turtles have temperature-dependent sex determination, meaning the developing turtle's sex depends on the temperature it is exposed to.[15][16][17][18][19] Warmer temperatures produce female hatchlings, while cooler temperatures produce male hatchlings.[15][16][17][18][19][20] The eggs will incubate for 50–60 days. The eggs in one nest hatch together over a short period of time. The baby turtles break free of the egg shell, dig through the sand, and crawl into the sea. Most species of sea turtles hatch at night. However, the Kemp's ridley commonly hatches during the day. Turtle nests that hatch during the day are more vulnerable to predators, and may encounter more human activity on beach.		Larger hatchlings have a higher probability of survival than smaller individuals, which can be explained by the fact that larger offspring are faster and thus less exposed to predation. Predators can only functionally intake so much; larger individuals are not targeted as often. A study conducted on this topic shows that body size is positively correlated with speed, so larger turtles are exposed to predators for a shorter amount of time.[21] The fact that there is size dependent predation on chelonians has led to the evolutionary development of large body sizes.		In 1987, Carr discovered that the young of green and loggerhead seaturtles spent a great deal of their pelagic lives in floating sargassum mats. Within these mats, they found ample shelter and food. In the absence of sargassum, sea turtle young feed in the vicinity of upwelling "fronts".[10] In 2007, Reich determined that green sea turtle hatchlings spend the first three to five years of their lives in pelagic waters. In the open ocean, pre-juveniles of this particular species were found to feed on zooplankton and smaller nekton before they are recruited into inshore seagrass meadows as obligate herbivores.[11][22]		Sea turtles maintain an internal environment that is hypotonic to the ocean. To maintain hypotonicity they must excrete excess salt ions.[23] Like other marine reptiles, sea turtles rely on a specialized gland to rid the body of excess salt ions, because reptilian kidneys cannot produce urine with a higher ion concentration than sea water.[24] All species of sea turtles have a lachrymal gland in the orbital cavity, capable of producing tears with a higher salt concentration than sea water.[25]		Leatherbacks face an increased osmotic challenge compared to other species of sea turtle, since their primary prey are jellyfish and other gelatinous plankton, whose fluids have the same concentration of salts as sea water. The much larger lachrymal gland found in leatherbacks may have evolved to cope with the higher intake of salts from their prey. A constant output of concentrated salty tears may be required to balance the input of salts from regular feeding, even considering leatherback tears can have a salt ion concentration almost twice that of other species of marine turtle.[26]		Hatchlings depend on drinking sea water immediately upon entering the ocean to replenish water lost during the hatching process. Salt gland functioning begins quickly after hatching, so that the young turtles can establish ion and water balance soon after entering the ocean. Survival and physiological performance hinge on immediate and efficient hydration following emergence from the nest.[24]		Most sea turtles (those in family Cheloniidae) are poikilotherms.[27] However the leatherback (family Dermochelyidae) are endotherms because they can maintain a body temperature 8 °C (14 °F) warmer than the ambient water.[27]		Green sea turtles in the relatively cooler Pacific are known to haul themselves out of the water on remote islands to bask in the sun.[28] This behavior has only been observed in a few locations including the Galapagos, Hawaii, Europa Island, and parts of Australia.[28]		Sea turtles are air breathing reptiles that have lungs, so they regularly surface to breathe. Sea turtles spend a majority of their time underwater, so they must be able to hold their breath for long periods.[29] Dive duration largely depends on activity. A foraging turtle may typically spend 5–40 min under water[29] while a sleeping sea turtle can remain under water for 4–7 hours.[30][31] Remarkably, sea turtle respiration remains aerobic for the vast majority of voluntary dive time.[29][31] When a sea turtle is forcibly submerged (e.g. entangled in a trawl net) its diving endurance is substantially reduced, so it is more susceptible to drowning.[29]		When surfacing to breathe, a sea turtle can quickly refill its lungs with a single explosive exhalation and rapid inhalation. Their large lungs permit rapid exchange of oxygen and avoid trapping gases during deep dives.		Gruber and Sparks (2015)[32] have observed the first fluorescence in a marine tetrapod (four-limbed vertebrates).[33] Sea turtles are the first biofluorescent reptile found in the wild.		According to Gruber and Sparks (2015) fluorescence is observed in an increasing number of marine creatures (cnidarians, ctenophores, annelids, arthropods, and chordates) and is now also considered to be widespread in cartilaginous and ray-finned fishes.[32]		The two marine biologists accidentally made the observation in the Solomon Islands on a hawksbill sea turtle, one of the rarest and most endangered turtle species in the ocean, during a night dive aimed to film the biofluorescence emitted by small sharks and coral reefs. The role of biofluorescence in marine organisms is often attributed to a strategy for attracting prey or perhaps a way to communicate. It could also serve as a way of defense or camouflage for the sea turtle hiding during night amongst other fluorescent organisms like corals. Fluorescent corals and sea creatures are best observed during night dives with a blue LED light and with a camera equipped with an orange optical filter to capture only the fluorescence light.[34][35]		The loggerhead, Kemp's ridley, olive ridley, and hawksbill sea turtles are omnivorous for their entire life. Omnivorous turtles may eat a wide variety of plant and animal life including decapods, seagrasses, seaweed, sponges, mollusks, cnidarians, echinoderms, worms and fish.[36][37][38][39] However some species specialize on certain prey.		The diet of green turtles changes with age.[40] Juveniles are omnivorous, but as they mature they become exclusively herbivorous.[37][40] This diet shift has an effect on the green turtle's morphology.[41][42] Green sea turtles have a serrated jaw that is used to eat sea grass and algae.[43]		Leatherback turtles feed almost exclusively on jellyfish and help control jellyfish populations.[44][45]		Hawksbills principally eat sponges, which constitute 70–95% of their diets in the Caribbean.[46]		Marine sea turtles are caught worldwide, although it is illegal to hunt most species in many countries.[47][48] A great deal of intentional marine sea turtle harvests worldwide are for food. Many parts of the world have long considered sea turtles to be fine dining. Ancient Chinese texts dating to the fifth century B.C.E. describe sea turtles as exotic delicacies.[49] Many coastal communities around the world depend on sea turtles as a source of protein, often harvesting several sea turtles at once and keeping them alive on their backs until needed. Coastal peoples gather sea turtle eggs for consumption.[50]		To a much lesser extent, specific species of marine sea turtles are targeted not for their flesh, but for their shells. Tortoiseshell, a traditional decorative ornamental material used in Japan and China, comes from the carapace scutes of the hawksbill sea turtle.[51][52] Ancient Greeks and ancient Romans processed sea turtle scutes (primarily from the hawksbill) for various articles and ornaments used by their elites, such as combs and brushes.[53] The skin of the flippers is prized for use as shoes and assorted leather goods.		The Moche people of ancient Peru worshipped the sea and its animals. They often depicted sea turtles in their art.[54]		Leatherback sea turtles enjoy immunity from the sting of the deadly box jellyfish and regularly eat them, helping keep tropical beaches safe for humans.		Beach towns, such as Tortuguero, Costa Rica, have transitioned from a tourism industry that made profits from selling sea turtle meat and shells to an ecotourism-based economy. Tortuguero is considered to be the founding location of sea turtle conservation. In the 1960s the cultural demand for sea turtle meat, shells, and eggs was quickly killing the once abundant sea turtle populations that nested on the beach. The Caribbean Conservation Corporation began working with villagers to promote ecotourism as a permanent substitute to sea turtle hunting. Sea turtle nesting grounds became sustainable. Tourists love to come and visit the nesting grounds, although it causes a lot of stress to the turtles because all of the eggs can get damaged or harmed.[55] Since the creation of a sea turtle, ecotourism-based economy, Tortugero annually houses thousands of tourists who visit the protected 22-mile (35 km) beach that hosts sea turtle walks and nesting grounds.[56][57]		Sea turtles play key roles in two habitat types: oceans and beaches/dunes.		In the oceans, sea turtles, especially green sea turtles, are one of very few creatures (manatees are another) that eat sea grass. Sea grass needs to be constantly cut short to help it grow across the sea floor. Sea turtle grazing helps maintain the health of the sea grass beds. Sea grass beds provide breeding and developmental grounds for numerous marine animals. Without them, many marine species humans harvest would be lost, as would the lower levels of the food chain. The reactions could result in many more marine species eventually becoming endangered or extinct.[58][citation needed]		Sea turtles use beaches and the lower dunes to nest and lay their eggs. Beaches and dunes are a fragile habitat that depend on vegetation to protect against erosion. Eggs, hatched or unhatched, and hatchlings that fail to make it into the ocean are nutrient sources for dune vegetation.[citation needed] Along a 20-mile (32 km) stretch of beach on the east coast of Florida sea turtles lay over 150,000 lb (68,000 kg) of eggs in the sand.[citation needed] Dune vegetation is able to grow and become stronger with the nutrients from sea turtle nests. Stronger vegetation and root systems help to hold the sand in the dunes and help protect the beach from erosion.[58]		The IUCN Red List classifies three species of sea turtle as either "Endangered" or "Critically Endangered".[59] An additional three species are classified as "Vulnerable".[59] The flatback is considered as "Data Deficient", meaning that its conservation status is unclear due to lack of data.[59] All species of sea turtle are listed in CITESAppendix I, restricting international trade of sea turtles and sea turtle products.[4][60]		Additionally, all populations of sea turtles that occur in United States waters are listed as threatened or endangered by the US Endangered Species Act (ESA).[61] The US listing status of the loggerhead is under review as of 2012.[61]		Threatened: all other populations[63]		Threatened: NW Atlantic, S Atlantic, SE Indo-Pacific, SW Indian populations[65]		Threatened: all other populations[69]		*The ESA manages sea turtles by population not by species.		In the Caribbean, researchers are having some success in assisting a comeback.[75] In September 2007, Corpus Christi, Texas, wildlife officials found 128 Kemp's ridley sea turtle nests on Texas beaches, a record number, including 81 on North Padre Island (Padre Island National Seashore) and four on Mustang Island. Wildlife officials released 10,594 Kemp's ridleys hatchlings along the Texas coast this year.		The Philippines has had several initiatives dealing with the issue of sea turtle conservation. In 2007, the province of Batangas declared the catching and eating of sea turtles (locally referred to as Pawikans) illegal. However, the law seems to have had little effect as sea turtle eggs are still in demand in Batangan markets. In September 2007, several Chinese poachers were apprehended off the Turtle Islands in the country's southernmost province of Tawi-Tawi. The poachers had collected more than a hundred sea turtles, along with 10,000 sea turtle eggs.[76]		Evaluating the progress of conservation programs is difficult, because many sea turtle populations have not been assessed adequately.[77] Most information on sea turtle populations comes from counting nests on beaches, but this doesn’t provide an accurate picture of the whole sea turtle population.[78] A 2010 United States National Research Council report concluded that more detailed information on sea turtles’ life cycles, such as birth rates and mortality, is needed.[79]		Nest relocation may not be a useful conservation technique for sea turtles. In one study on the freshwater Arrau turtle (Podocnemis expansa) researchers examined the effects of nest relocation.[80] They discovered that clutches of this freshwater turtle that were transplanted to a new location had higher mortality rates and more morphological abnormalities compared to non transplanted clutches.[80] The results clearly demonstrate that humans should not manipulate or relocate clutches of that turtle, and impart strong evidence of the detrimental effects that human activity can cause.[citation needed]		Most sea turtle mortality happens early in life. Sea turtles usually lay around one hundred eggs at a time, but on average only one of the eggs from the nest will survive to adulthood.[81] Raccoons, foxes, and seabirds may raid nests or hatchlings may be eaten within minutes of hatching as they make their initial run for the ocean. [82] Once in the water, they are susceptible to seabirds, large fish and even other turtles.		Adult sea turtles have few predators. Large aquatic carnivores such as sharks and crocodiles are their biggest threats; however, reports of terrestrial predators attacking nesting females are not uncommon. Jaguars have been reported to smash into the turtle's shell with its paw, and scoop out the flesh.[83]		Fibropapillomatosis disease causes tumors in sea turtles.		While many of the things that endanger sea turtles are natural predators[82], increasingly many threats to the sea turtle species have arrived with the ever-growing presence of humans.[84]		One of the most significant and contemporary threats to sea turtles comes from bycatch due to imprecise fishing methods. Long-lining has been identified as a major cause of accidental sea turtle death.[85][86] There is also black-market demand for tortoiseshell for both decoration and supposed health benefits.[87]		Sea turtles must surface to breathe. Caught in a fisherman's net, they are unable to surface and thus drown. In early 2007, almost a thousand sea turtles were killed inadvertently in the Bay of Bengal over the course of a few months after netting.[88]		However, some relatively inexpensive changes to fishing techniques, such as slightly larger hooks and traps from which sea turtles can escape, can dramatically cut the mortality rate.[89][90] Turtle Excluder Devices (TEDs) have reduced sea turtle bycatch in shrimp nets by 97 percent.		Beach development is another area which threatens sea turtles. Since many sea turtles return to the same beach each time to nest, development can disrupt the cycle.[citation needed] There has been a movement to protect these areas, in some cases by special police. In some areas, such as the east coast of Florida, conservationists dig up sea turtle eggs and relocate them to fenced nurseries to protect them from beach traffic.[citation needed]		Since hatchlings find their way to the ocean by crawling towards the brightest horizon, they can become disoriented on developed stretches of coastline.[citation needed] Lighting restrictions can prevent lights from shining on the beach and confusing hatchlings. Sea turtle-safe lighting uses red or amber LED light, invisible to sea turtles, in place of white light.[citation needed]		Another major threat to sea turtles is black-market trade in eggs and meat. This is a problem throughout the world, but especially a concern in China, the Philippines, India, Indonesia and the coastal nations of Latin America. Estimates reach as high as 35,000 sea turtles killed a year in Mexico and the same number in Nicaragua. Conservationists in Mexico and the United States have launched "Don't Eat Sea Turtle" campaigns in order to reduce this trade in sea turtle products. These campaigns have involved figures such as Dorismar, Los Tigres del Norte and Maná. Sea turtles are often consumed during the Catholic season of Lent, even though they are reptiles, not fish. Consequently, conservation organizations have written letters to the Pope asking that he declare sea turtles meat.[91]		Another danger comes from marine debris, especially plastics which may be mistaken for jellyfish, and abandoned fishing nets in which they can become entangled.		Climate change may also cause a threat to sea turtles. Since sand temperature at nesting beaches defines the sex of a sea turtle while developing in the egg, there is concern that rising temperatures may produce too many females.[citation needed] However, more research is needed to understand how climate change might affect sea turtle gender distribution and what other possible threats it may pose.[92]		Sea turtles are very vulnerable to oil pollution, both because of the oil's tendency to linger on the water's surface, and because oil can affect them at every stage of their life cycle.[93] Oil can poison the sea turtles upon entering their digestive system.		Injured sea turtles are rescued and rehabilitated (and, if possible, released back to the ocean) by professional organizations, such as the Gumbo Limbo Nature Center in Boca Raton, Florida, the Karen Beasley Sea Turtle Rescue and Rehabilitation Center in Surf City, North Carolina, and Sea Turtles 911 in Hainan, China.		One rescued sea turtle, named Nickel for the coin that was found lodged in her throat, lives at the Shedd Aquarium in Chicago.		Sea Turtles are believed to have a commensal relationship with some barnacles, in which the barnacles benefit from growing on turtles without harming them. Barnacles are small, hard shelled crustaceans found attached to multiple different substrates below or just above the ocean. The adult barnacle is a sessile organism, however in its larval stage it is planktonic and can move about the water column. The larval stage chooses where to settle and ultimately the habitat for its full adult life, which is typically between 5 and 10 years. A favorite settlement for barnacle larvae is the shell or skin around the neck of sea turtles. The larvae glue themselves to the chosen spot, a thin layer of flesh is wrapped around them and a shell is secreted. Many species of barnacles can settle on any substrate, however some species of barnacles have an obligatory commensal relationship with specific animals, which makes finding a suitable location harder.[94] Around 29 species of "turtle barnacles" have been recorded. However it is not solely on sea turtles that barnacles can be found; other organisms also serve as barnacle’s settlements. These organisms include mollusks, whales, decapod crustaceans, manatees and several other groups related to these species.[95]		Sea turtle shells are an ideal habitat for adult barnacles for three reasons. Turtles tend to live long lives, around 50 years, so barnacles do not have to worry about host death. Secondly, barnacles are suspension feeders. Sea turtles spend most of their lives swimming and following ocean currents and as water runs along the back of the turtle’s shell it passes over the barnacles, providing an almost constant water flow and influx of food particles. Lastly, the long distances and inter-ocean travel these sea turtles swim throughout their lifetime offers the perfect mechanism for dispersal of barnacle larvae. Allowing the barnacle species to distribute themselves throughout global waters is a high fitness advantage of this commensalism.[96]		This relationship however is not truly commensal. While the barnacles are not directly parasitic to their hosts, they have negative effects to the turtles on which they choose to reside. The barnacles add extra weight and drag to the sea turtle, increasing the energy it needs for swimming and affecting its ability to capture prey, with the effect increasing with the quantity of barnacles affixed to its back.[97]		
Rock or stone is a natural substance, a solid aggregate of one or more minerals or mineraloids. For example, granite, a common rock, is a combination of the minerals quartz, feldspar and biotite. The Earth's outer solid layer, the lithosphere, is made of rock.		Rock has been used by mankind throughout history. The minerals and metals found in rocks have been essential to human civilization.[1]		Three major groups of rocks are defined: igneous, sedimentary, and metamorphic. The scientific study of rocks is called petrology, which is an essential component of geology.						At a granular level, rocks are composed of grains of minerals, which, in turn, are homogeneous solids formed from a chemical compound that is arranged in an orderly manner. The aggregate minerals forming the rock are held together by chemical bonds. The types and abundance of minerals in a rock are determined by the manner in which the rock was formed. Many rocks contain silica (SiO2); a compound of silicon and oxygen that forms 74.3% of the Earth's crust. This material forms crystals with other compounds in the rock. The proportion of silica in rocks and minerals is a major factor in determining their name and properties.[2]		Rocks are geologically classified according to characteristics such as mineral and chemical composition, permeability, the texture of the constituent particles, and particle size. These physical properties are the end result of the processes that formed the rocks.[3] Over the course of time, rocks can transform from one type into another, as described by the geological model called the rock cycle. These events produce three general classes of rock: igneous, sedimentary, and metamorphic.		The three classes of rocks are subdivided into many groups. However, there are no hard and fast boundaries between allied rocks. By increase or decrease in the proportions of their constituent minerals they pass by every gradation into one another, the distinctive structures also of one kind of rock may often be traced gradually merging into those of another. Hence the definitions adopted in establishing rock nomenclature merely correspond to more or less arbitrary selected points in a continuously graduated series.[4]		Igneous rock (derived from the Latin word igneus meaning of fire, from ignis meaning fire) forms through the cooling and solidification of magma or lava. This magma can be derived from partial melts of pre-existing rocks in either a planet's mantle or crust. Typically, the melting of rocks is caused by one or more of three processes: an increase in temperature, a decrease in pressure, or a change in composition.		Igneous rocks are divided into two main categories: plutonic rock and volcanic. Plutonic or intrusive rocks result when magma cools and crystallizes slowly within the Earth's crust. A common example of this type is granite. Volcanic or extrusive rocks result from magma reaching the surface either as lava or fragmental ejecta, forming minerals such as pumice or basalt.[3] The chemical abundance and the rate of cooling of magma typically forms a sequence known as Bowen's reaction series. Most major igneous rocks are found along this scale.[2]		About 64.7% of the Earth's crust by volume consists of igneous rocks; making it the most plentiful category. Of these, 66% are basalts and gabbros, 16% are granite, and 17% granodiorites and diorites. Only 0.6% are syenites and 0.3% peridotites and dunites. The oceanic crust is 99% basalt, which is an igneous rock of mafic composition. Granites and similar rocks, known as meta-granitoids, form much of the continental crust.[5] Over 700 types of igneous rocks have been described, most of them having formed beneath the surface of Earth's crust. These have diverse properties, depending on their composition and the temperature and pressure conditions in which they were formed.		Sedimentary rocks are formed at the earth's surface by the accumulation and cementation of fragments of earlier rocks, minerals, and organisms[6] or as chemical precipitates and organic growths in water (sedimentation). This process causes clastic sediments (pieces of rock) or organic particles (detritus) to settle and accumulate, or for minerals to chemically precipitate (evaporite) from a solution. The particulate matter then undergoes compaction and cementation at moderate temperatures and pressures (diagenesis).		Before being deposited, sediments are formed by weathering of earlier rocks by erosion in a source area and then transported to the place of deposition by water, wind, ice, mass movement or glaciers (agents of denudation). Mud rocks comprise 65% (mudstone, shale and siltstone); sandstones 20 to 25% and carbonate rocks 10 to 15% (limestone and dolostone).[3] About 7.9% of the crust by volume is composed of sedimentary rocks, with 82% of those being shales, while the remainder consists of limestone (6%), sandstone and arkoses (12%).[5] Sedimentary rocks often contain fossils. Sedimentary rocks form under the influence of gravity and typically are deposited in horizontal or near horizontal layers or strata and may be referred to as stratified rocks. A small fraction of sedimentary rocks deposited on steep slopes will show cross bedding where one layer stops abruptly along an interface where another layer eroded the first as it was laid atop the first.		Metamorphic rocks are formed by subjecting any rock type—sedimentary rock, igneous rock or another older metamorphic rock—to different temperature and pressure conditions than those in which the original rock was formed. This process is called metamorphism; meaning to "change in form". The result is a profound change in physical properties and chemistry of the stone. The original rock, known as the protolith, transforms into other mineral types or other forms of the same minerals, by recrystallization.[3] The temperatures and pressures required for this process are always higher than those found at the Earth's surface: temperatures greater than 150 to 200 °C and pressures of 1500 bars.[7] Metamorphic rocks compose 27.4% of the crust by volume.[5]		The three major classes of metamorphic rock are based upon the formation mechanism. An intrusion of magma that heats the surrounding rock causes contact metamorphism—a temperature-dominated transformation. Pressure metamorphism occurs when sediments are buried deep under the ground; pressure is dominant, and temperature plays a smaller role. This is termed burial metamorphism, and it can result in rocks such as jade. Where both heat and pressure play a role, the mechanism is termed regional metamorphism. This is typically found in mountain-building regions.[2]		Depending on the structure, metamorphic rocks are divided into two general categories. Those that possess a texture are referred to as foliated; the remainders are termed non-foliated. The name of the rock is then determined based on the types of minerals present. Schists are foliated rocks that are primarily composed of lamellar minerals such as micas. A gneiss has visible bands of differing lightness, with a common example being the granite gneiss. Other varieties of foliated rock include slates, phyllites, and mylonite. Familiar examples of non-foliated metamorphic rocks include marble, soapstone, and serpentine. This branch contains quartzite—a metamorphosed form of sandstone—and hornfels.[2]		The use of rocks has had a huge impact on the cultural and technological development of the human race. Rocks have been used by humans and other hominids for at least 2.5 million years.[8] Lithic technology marks some of the oldest and continuously used technologies. The mining of rocks for their metal ore content has been one of the most important factors of human advancement, which has progressed at different rates in different places in part because of the kind of metals available from the rocks of a region.		Mining is the extraction of valuable minerals or other geological materials from the earth, from an ore body, vein or (coal) seam. This term also includes the removal of soil. Materials recovered by mining include base metals, precious metals, iron, uranium, coal, diamonds, limestone, oil shale, rock salt and potash. Mining is required to obtain any material that cannot be grown through agricultural processes, or created artificially in a laboratory or factory. Mining in a wider sense comprises extraction of any resource (e.g. petroleum, natural gas, salt or even water) from the earth.[9]		Mining of rock and metals has been done since prehistoric times. Modern mining processes involve prospecting for ore bodies, analysis of the profit potential of a proposed mine, extraction of the desired materials and finally reclamation of the land to prepare it for other uses once mining ceases.[10]		The nature of mining processes creates a potential negative impact on the environment both during the mining operations and for years after the mine has closed. This impact has led to most of the world's nations adopting regulations to manage negative effects of mining operations.[11]		
Seagrasses are flowering plants (angiosperms) belonging to four families (Posidoniaceae, Zosteraceae, Hydrocharitaceae and Cymodoceaceae), all in the order Alismatales (in the class of monocotyledons), which grow in marine, fully saline environments. There are 12 genera with some 60 species known.						These unusual marine flowering plants are called seagrasses because in many species the leaves are long and narrow, grow by rhizome extension, and often grow in large "meadows", which look like grassland: in other words, many of the species of seagrasses superficially resemble terrestrial grasses of the family Poaceae.		Like all autotrophic plants, seagrasses photosynthesize so are limited to growing in the submerged photic zone, and most occur in shallow and sheltered coastal waters anchored in sand or mud bottoms. Most species undergo submarine pollination and complete their entire life cycle underwater.		Seagrasses form extensive beds or meadows, which can be either monospecific (made up of a single species) or in mixed beds where more than one species coexist. In temperate areas, usually one or a few species dominate (like the eelgrass Zostera marina in the North Atlantic), whereas tropical beds usually are more diverse, with up to thirteen species recorded in the Philippines.		Seagrass beds are highly diverse and productive ecosystems, and can harbor hundreds of associated species from all phyla, for example juvenile and adult fish, epiphytic and free-living macroalgae and microalgae, mollusks, bristle worms, and nematodes. Few species were originally considered to feed directly on seagrass leaves (partly because of their low nutritional content), but scientific reviews and improved working methods have shown that seagrass herbivory is a highly important link in the food chain, with hundreds of species feeding on seagrasses worldwide, including green turtles, dugongs, manatees, fish, geese, swans, sea urchins and crabs.		Some fish species that visit/feed on seagrasses raise their young in adjacent mangroves or coral reefs. Also, seagrasses trap sediment and slow down water movement, causing suspended sediment to fall out. The trapping of sediment benefits coral by reducing sediment loads in the water.[1]		Seagrasses are sometimes labeled ecosystem engineers, because they partly create their own habitat: their leaves, by slowing down water currents, increase sedimentation, and their roots and rhizomes stabilize the seabed.		Their importance for associated species is mainly due to provision of shelter (through their three-dimensional structure in the water column) and to their extraordinarily high rate of primary production. As a result, seagrasses provide coastal zones with a number of ecosystem goods and ecosystem services, for instance habitat for commercially and recreationally valued fishery species,[3] fishing grounds, wave protection, oxygen production and protection against coastal erosion. Seagrass meadows account for more than 10% of the ocean’s total carbon storage.[4] Per hectare, it holds twice as much carbon dioxide as rain forests. Yearly, seagrasses sequester about 27.4 million tons of CO2 (Reference Needed). Global warming models suggest, some seagrasses will go extinct – Posidonia oceanica is expected to go extinct, or nearly so, by 2050. This would result in CO2 release.[5][6]		Historically, seagrasses were collected as fertilizer for sandy soil. This was an important use in the Ria de Aveiro, Portugal, where the plants collected were known as moliço.		In the early 20th century, in France and, to a lesser extent, the Channel Islands, dried seagrasses were used as a mattress (paillasse) filling - such mattresses were in high demand by French forces during World War I. It was also used for bandages and other purposes.		Currently, seagrass is used in furniture, and woven like rattan.		Natural disturbances, such as grazing, storms, ice-scouring, and desiccation, are an inherent part of seagrass ecosystem dynamics. Seagrasses display an extraordinarily high degree of phenotypic plasticity, adapting rapidly to changing environmental conditions.		Seagrasses are in global decline, with some 30,000 km2 (12,000 sq mi) lost during recent decades. The main cause is human disturbance, most notably eutrophication, mechanical destruction of habitat, and overfishing. Excessive input of nutrients (nitrogen, phosphorus) is directly toxic to seagrasses, but most importantly, it stimulates the growth of epiphytic and free-floating macro- and micro-algae. This weakens the sunlight, reducing the photosynthesis that nourishes the seagrass and the primary production results.		Decaying seagrass leaves and algae fuels increasing algal blooms, resulting in a positive feedback. This can cause a complete regime shift from seagrass to algal dominance. Accumulating evidence also suggests that overfishing of top predators (large predatory fish) could indirectly increase algal growth by reducing grazing control performed by mesograzers, such as crustaceans and gastropods, through a trophic cascade.		Macro algal blooms cause the decline and eradication of seagrasses throughout areas where nutrient loading or other sources of stimulated algal growth exist. Known as nuisance species, macroalgae grow in filamentous and sheet-like forms and form thick unattached mats over the seagrasse, occurring as epiphytes on seagrass leaves. Eutrophication leads to the forming of a bloom, causing the attenuation of light in the water column, which eventually leads to anoxic conditions for the seagrass and organisms living in/around the plant(s). In addition to the direct blockage of light to the plant, benthic macroalgae have low carbon/nitrogen content, causing their decomposition to stimulate bacterial activity, leading to sediment resuspension, an increase in water turbidity, and the further attenuation of light.[7][8]		When humans drive motor boats over shallow seagrass areas, sometimes the propeller blade can tear out or cut the seagrass.		The most-used methods to protect and restore seagrass meadows include nutrient and pollution reductions, protection using marine protected areas, and restoration using seagrass transplantation. There is also increasing recognition of the need to increase the resilience of seagrass to the impacts of future environmental change.[9]		In February 2017, Cornell University marine biologist and ecologist Dr. Joleah Lamb found that seagrass meadows may be able to remove various disease pathogens from seawater. Dr. Lamb and her research team studied small islands without wastewater treatment facilities in central Indonesia, and found that levels of potentially pathogenic marine bacteria – like Enterococcus – that affect humans, fishes, and invertebrates were reduced by 50 percent when seagrass meadows were present compared to paired sites without seagrass.[10]		
Large-scale coastal behaviour is an attempt to model the morphodynamics of coastal change at time and space scales appropriate to management and prediction. Temporally this is at the decade to century scale, spatially at the scale of tens of kilometers. It was developed by de Vriend.		Modelling large-scale coastal behaviour involves some level of parameterisation rather than simply upscaling from process or downscaling from the geological scale. It attempts to recognise patterns occurring at these scales. Cowell and Thom (2005) recognise the need to admit uncertainty in large-scale coastal behaviour given incomplete process knowledge.		
The Emerald Coast is an unofficial name for the coastal area in the US state of Florida on the Gulf of Mexico that stretches about 100 mi (161 km) through five counties, Escambia, Santa Rosa, Okaloosa, Walton, and Bay, from Pensacola to Panama City. Some South Alabama communities on the coast of Baldwin County, such as Gulf Shores, Orange Beach and Fort Morgan, embrace the term as well.						Beginning in 1946, for marketing purposes the coast from Fort Walton Beach to Panama City was called the "Playground of the Gulfcoast", as witnessed by the name of the Fort Walton Beach newspaper, the Playground News, later the Playground Daily News, and now the Northwest Florida Daily News. In 1952, this particular stretch of coast was dubbed the "Miracle Strip" by Claude Jenkins, a local journalist, a term which is still reflected in the name of the Miracle Strip Amusement Park and other local businesses.[1][2] The term "Miracle Strip" was officially adopted by thirty-five officials and members of three district Florida Motor Courts Association chapters on March 14, 1956, at a meeting held at the Staff Restaurant in Fort Walton Beach, for the 100-mile stretch of scenic Highway 98's "fabulous string of motels, hotels and nightspots" from Pensacola to Panama City. Members included representatives of local chambers of commerce.[3]		According to the Daily News, the term Emerald Coast was coined in 1983 by a junior high school student, Andrew Dier, who won $50 in the contest for a new area slogan.[4] Since then, the term has been expanded by popular usage to cover all of the northwest coast of Florida from Pensacola Beach to Panama City Beach.		Popular vacation destinations include Pensacola, Pensacola Beach, Gulf Breeze, Navarre, Navarre Beach, Fort Walton Beach, Niceville, WaterColor, Panama City Beach, Destin, and Seaside, a planned community whose iconic pastel-paint and tin-roof construction was made famous in the Jim Carrey movie The Truman Show, filmed in the area from 1996-1997. Other communities on the Emerald Coast include Perdido Key, Navarre, Sandestin, Mexico Beach, Grayton Beach, Inlet Beach, and Santa Rosa Beach.		The area is known as a family drive destination, although in the first decade of the 21st century, its popularity expanded greatly, leading to new construction booms and seemingly overnight changes.[5] Many development communities similar to Seaside sprang up in the southern part of Walton County and at the western end of Panama City Beach, raising property values.		Deep-sea fishing is a huge draw for the area, with Destin holding the nickname "World's Luckiest Fishing Village" [6] (and several saltwater world records) and Panama City Beach hosting the annual high-dollar Bay Point Billfish Invitational. The area has many seafood restaurants as well.		This part of Florida is home to several military bases, with installations including Naval Air Station Pensacola (home of the Navy's Blue Angels demonstration team and the initial training site for all naval aviators), Hurlburt Field, Eglin Air Force Base (one of the largest military bases in America), Tyndall Air Force Base (home to the Air Force's F-22 Raptor fighter jets), Coastal Systems Station-Naval Surface Warfare Center (home to the Navy Experimental Diving Unit and Naval Diving & Salvage Training Center), and Corry Station Naval Technical Training Center.		In addition to military bases and related civilian contractors, tourism, fishing, and hospitality industries are also major employers in the area.		The well-established military presence in the region has led to many film appearances, the earliest being the practice takeoff runs by Doolittle Raiders for Thirty Seconds Over Tokyo, shot at Peel Field, an auxiliary field at Eglin Field, in 1944. Some scenes in the 1949 film Twelve O'Clock High, another film about World War II, were also shot at Eglin.		The 1972 eco-horror film Frogs was filmed in Walton County, Florida, in and around the Wesley House, an old southern mansion located in Eden Gardens State Park in the town of Point Washington, situated on Tucker Bayou off Choctawhatchee Bay.		Exterior shots and several interior scenes for 1998's The Truman Show were filmed in Seaside.[7] Several scenes for Jaws 2 (1978) were filmed in the region as well. Interiors for the youth's pinball hang-out were filmed in Fort Walton Beach at the now-razed original location of Hog's Breath Saloon on Okaloosa Island, and Bruce the Shark's control sled was placed on the bottom of the Gulf off Navarre Beach and the mainland community of Navarre.		Redneck Riviera is the title of a song by Tom T. Hall about this region (from his 1996 album Songs from Sopchoppy). Lyrics include:		Parts of John Grisham's book The Whistler (2016) takes place in and around the Emerald Coast.		Coordinates: 30°23′37″N 86°29′45″W﻿ / ﻿30.3935337°N 86.4957833°W﻿ / 30.3935337; -86.4957833		
An esplanade or promenade is a long, open, level area, usually next to a river or large body of water, where people may walk. The original meaning of esplanade was a large, open, level area outside fortress or city walls to provide clear fields of fire for the fortress' guns. In modern usage the space allows people to walk for recreational purposes; esplanades are often on sea fronts, and allow walking whatever the state of the tide, without having to walk on the beach. Esplanades became popular in Victorian times when it was fashionable to visit seaside resorts. A promenade, often abbreviated to '(the) prom', was an area where people – couples and families especially – would go to walk for a while in order to 'be seen' and be considered part of 'society'.		In North America, esplanade has another meaning, being also a median (strip of raised land) dividing a roadway or boulevard. Sometimes they are just strips of grass, or some may have gardens and trees. Some roadway esplanades may be used as parks with a walking/jogging trail and benches.[1]		Esplanade and promenade are sometimes used interchangeably. The derivation of "promenade" indicates a place specifically intended for walking, though many modern promenades and esplanades also allow bicycles and other nonmotorized transport.[2] Some esplanades also include large boulevards or avenues where cars are permitted.		A similar term with the same meaning in the eastern coastal region of Spain is rambla, but more widely referred to as paseo marítimo ("esplanade"), paseo ("promenade") or explanada ("esplanade") in the Hispanic world.						Usedom, Western Pomerania, Germany - longest beach promenade in Europe[3] (Ahlbeck here)		Marine Drive, Mumbai, India		St Clair Beach and esplanade, Dunedin, New Zealand		The Corniche, Beirut, Lebanon		Promenade at Rizal Boulevard in Dumaguete City, Philippines		Sliema promenade, Malta		The Galle Face Green esplanade, Colombo, Sri Lanka		Gurney Drive, Penang		Błonia, Kraków, Poland		Blackpool's regenerated Promenade, England		Esplanade Row East, Kolkata, India		Boston Esplanade, Boston, United States		Esplanade in the Olympic Park of Sochi, Russia		Battery Park City, New York City, United States				
Region of Freshwater Influence (ROFI), a term coined by Prof. John Simpson[1] of the University of Wales, Bangor, and co-authors, in 1993 in Oceanologica Acta[2] for the Rhine river plume. The term refers to regions where rivers debouch into estuaries and coastal shelf seas where the currents patterns are governed by density differences between salt sea water and fresh river water. In other words, a ROFI is the region between the shelf sea regime and the estuary where the local input of freshwater buoyancy from the coastal source is comparable with, or exceeds, the seasonal input of buoyancy as heat which occurs all over the shelf.[3] Americans usually use the term river plume where Europeans use ROFI.				
Brighton /ˈbraɪtən/ ( listen) is a seaside resort on the south coast of England.[1] It is part of the ceremonial county of East Sussex, within the historic county of Sussex.		Archaeological evidence of settlement in the area dates back to the Bronze Age, Roman and Anglo-Saxon periods. The ancient settlement of "Brighthelmstone" was documented in the Domesday Book (1086). The town's importance grew in the Middle Ages as the Old Town developed, but it languished in the early modern period, affected by foreign attacks, storms, a suffering economy and a declining population. Brighton began to attract more visitors following improved road transport to London and becoming a boarding point for boats travelling to France. The town also developed in popularity as a health resort for sea bathing as a purported cure for illnesses.		In the Georgian era, Brighton developed as a fashionable seaside resort, encouraged by the patronage of the Prince Regent, later King George IV, who spent much time in the town and constructed the Royal Pavilion in the Regency era. Brighton continued to grow as a major centre of tourism following the arrival of the railways in 1841, becoming a popular destination for day-trippers from London. Many of the major attractions were built in the Victorian era, including the Grand Hotel, the West Pier, and the Brighton Palace Pier. The town continued to grow into the 20th century, expanding to incorporate more areas into the town's boundaries before joining the town of Hove to form the unitary authority of Brighton and Hove in 1997, which was granted city status in 2000.[2]		Brighton's location has made it a popular destination for tourists, renowned for its diverse communities, quirky shopping areas, large cultural, music and arts scene[3] and its large LGBT population, leading to its reverence as the "unofficial gay capital of the UK".[4] Brighton attracted 7.5 million day visitors in 2015/16 and 4.9 million overnight visitors,[5] and is the most popular seaside destination in the UK for overseas tourists.[6] Brighton has also been called the UK's "hippest city",[7] and "the happiest place to live in the UK".[8]						Brighton's earliest name was Bristelmestune, recorded in the Domesday Book. Although more than 40 variations have been documented, Brighthelmstone (or Brighthelmston) was the standard rendering between the 14th and 18th centuries.[9][10]		Brighton was originally an informal shortened form, first seen in 1660; it gradually supplanted the longer name, and was in general use from the late 18th century. Brighthelmstone was the town's official name until 1810, though.[10] The name is of Anglo-Saxon origin. Most scholars believe that it derives from Beorthelm + tūn—the homestead of Beorthelm, a common Old English name associated with villages elsewhere in England.[10] The tūn element is common in Sussex, especially on the coast, although it occurs infrequently in combination with a personal name.[11] An alternative etymology taken from the Old English words for "stony valley" is sometimes given but has less acceptance.[10] Brighthelm gives its name to, among other things, a church[12] and a pub in Brighton[13] and some halls of residence at the University of Sussex.[14] Writing in 1950, historian Antony Dale noted that unnamed antiquaries had suggested an Old English word "brist" or "briz", meaning "divided", could have contributed the first part of the historic name Brighthelmstone. The town was originally split in half by the Wellesbourne, a winterbourne which was culverted and buried in the 18th century.[15]		Brighton has several nicknames. Poet Horace Smith called it "The Queen of Watering Places", which is still widely used,[16] and "Old Ocean's Bauble".[17] Novelist William Makepeace Thackeray referred to "Doctor Brighton", calling the town "one of the best of Physicians". "London-by-Sea" is well-known, reflecting Brighton's popularity with Londoners as a day-trip resort, a commuter dormitory and a desirable destination for those wanting to move out of the metropolis. "The Queen of Slaughtering Places", a pun on Smith's description, became popular when the Brighton trunk murders came to the public's attention in the 1930s.[17] The mid 19th-century nickname "School Town" referred to the remarkable number of boarding, charity and church schools in the town at the time.[18]		The first settlement in the Brighton area was Whitehawk Camp, a Neolithic encampment on Whitehawk Hill which has been dated to between 3500 BC and 2700 BC.[19] It is one of six causewayed enclosures in Sussex. Archaeologists have only partially explored it, but have found numerous burial mounds, tools and bones, suggesting it was a place of some importance.[20] There was also a Bronze Age settlement at Coldean. Brythonic Celts arrived in Britain in the 7th century BC,[19] and an important Brythonic settlement existed at Hollingbury Camp on Hollingbury Hill. This Celtic Iron Age encampment dates from the 3rd or 2nd century BC and is circumscribed by substantial earthwork outer walls with a diameter of c. 1,000 feet (300 m). Cissbury Ring, roughly 10 miles (16 km) from Hollingbury, is suggested to have been the tribal "capital".[21]		Later, there was a Roman villa at Preston Village, a Roman road from London ran nearby, and much physical evidence of Roman occupation has been discovered locally.[19] From the 1st century AD, the Romans built a number of villas in Brighton and Romano-British Brythonic Celts formed farming settlements in the area.[22] After the Romans left in the early 4th century AD, the Brighton area returned to the control of the native Celts. Anglo-Saxons then invaded in the late 5th century AD, and the region became part of the Kingdom of Sussex, founded in 477 AD by king Ælle.[23]		Anthony Seldon identified five phases of development in pre-20th century Brighton.[24] The village of Bristelmestune was founded by these Anglo-Saxon invaders, probably in the early Saxon period. They were attracted by the easy access for boats, sheltered areas of raised land for building, and better conditions compared to the damp, cold and misty Weald to the north.[25] By the time of the Domesday survey in 1086 it was a fishing and agricultural settlement, a rent of 4,000 herring was established, and its population was about 400.[9][19] Its importance grew from the Norman era onwards. By the 14th century there was a parish church, a market and rudimentary law enforcement (the first town constable was elected in 1285).[26] Sacked and burnt by French invaders in the early 16th century—the earliest depiction of Brighton, a painting of c. 1520, shows Admiral Pregent de Bidoux's attack of June 1514—the town recovered strongly based on a thriving mackerel-fishing industry.[27] The grid of streets in the Old Town (the present Lanes area) were well developed and the town grew quickly: the population rose from c. 1,500 in 1600 to c. 4,000 in the 1640s.[19] By that time Brighton was Sussex's most populous and important town.[27]		Over the next few decades, though, events severely affected its local and national standing, such that by 1730 "it was a forlorn town decidedly down on its luck". More foreign attacks, storms (especially the devastating Great Storm of 1703), a declining fishing industry, and the emergence of nearby Shoreham as a significant port caused its economy to suffer.[27] By 1708 other parishes in Sussex were charged rates to alleviate poverty in Brighton, and Daniel Defoe wrote that the expected £8,000 cost of providing sea defences was "more than the whole town was worth". The population declined to 2,000 in the early 18th century.[19]		From the 1730s, Brighton entered its second phase of development—one which brought a rapid improvement in its fortunes. The contemporary fad for drinking and bathing in seawater as a purported cure for illnesses was enthusiastically encouraged by Dr Richard Russell from nearby Lewes. He sent many patients to "take the cure" in the sea at Brighton, published a popular treatise[note 1] on the subject, and moved to the town soon afterwards (the Royal Albion, one of Brighton's early hotels, occupies the site of his house).[29] Others were already visiting the town for recreational purposes before Russell became famous, and his actions coincided with other developments which made Brighton more attractive to visitors. From the 1760s it was a boarding point for boats travelling to France; road transport to London was improved[30] when the main road via Crawley was turnpiked in 1770;[31] and spas and indoor baths were opened by other entrepreneurial physicians such as Sake Dean Mahomed and Anthony Relhan (who also wrote the town's first guidebook).[30]		From 1780, development of the Georgian terraces had started, and the fishing village developed as the fashionable resort of Brighton. Growth of the town was further encouraged by the patronage of the Prince Regent (later King George IV) after his first visit in 1783.[32] He spent much of his leisure time in the town and constructed the Royal Pavilion during the early part of his Regency. In this period the modern form of the name Brighton came into common use.[33]		A permanent military presence was established in the city with the completion of Preston Barracks in 1793.[34]		The arrival of the London and Brighton Railway in 1841 brought Brighton within the reach of day-trippers from London. The population grew from around 7,000 in 1801 to more than 120,000 by 1901.[35] Many of the major attractions were built during the Victorian era, such as the Grand Hotel (1864), the West Pier (1866), and the Palace Pier (1899). Prior to either of these structures, the famous Chain Pier was built, to the designs of Captain Samuel Brown. It lasted from 1823 to 1896, and is featured in paintings by both Turner and Constable.[36]		Because of boundary changes, the land area of Brighton expanded from 1,640 acres (7 km2) in 1854 to 14,347 acres (58 km2) in 1952.[37] New housing estates were established in the acquired areas, including Moulsecoomb, Bevendean, Coldean and Whitehawk. The major expansion of 1928 also incorporated the villages of Patcham, Ovingdean and Rottingdean, and much council housing was built in parts of Woodingdean after the Second World War. In 1997, Brighton and Hove were joined to form the unitary authority of Brighton and Hove, which was granted city status by Queen Elizabeth II as part of the millennium celebrations in 2000.		In 2016, Government figures analysed by the charity Shelter revealed that Brighton and Hove had the worst rate for homelessness outside London and is worse than some boroughs in the capital.[38] One in 69 people in Brighton and Hove were calculated to be homeless. In a charity report issued in November 2016, three areas in Brighton & Hove, East Brighton, Queen’s Park, and Moulsecoomb & Bevendean ranked in the top ten per cent nationally for deprivation.[39] Although deprivation in Brighton is distributed across the whole of the city it is more concentrated in some areas than others. The highest concentration of deprivation is in the Whitehawk, Moulsecoomb, and Hollingbury areas of the city but is also found around the St. James’s Street and Eastern Road areas.[40] A 2015 government statistic showed that the area around Brighton’s Palace Pier roundabout and to the east towards St James’s Street in Kemptown is the seventh worst ‘living environment’ in England.[41] On 19 January 2017, Brighton council announced they were looking at certain initiatives to try and alleviate some of the increasing homelessness seen on Brighton's streets and were hoping to open the first in-house temporary housing for homeless people in the city.[42]		Brighton lies between the South Downs and the English Channel to the north and south, respectively. The Sussex coast forms a wide, shallow bay between the headlands of Selsey Bill and Beachy Head; Brighton developed near the centre of this bay around a seasonal river, the Wellesbourne (or Whalesbone), which flowed from the South Downs above Patcham.[9][43] This emptied into the English Channel at the beach near the East Cliff, forming "the natural drainage point for Brighton".[44]		Behind the estuary was a stagnant pond called the Pool or Poole, so named since the medieval era.[note 2] This was built over with houses and shops from 1793, when the Wellesbourne was culverted to prevent flooding,[44][45] and only the name of the road (Pool Valley, originally Pool Lane)[46] marks its site. One original house survives from the time of the pool's enclosure.[9] Behind Pool Valley is Old Steine (historically The Steyne), originally a flat and marshy area where fishermen dried their nets. The Wellesbourne occasionally reappears during times of prolonged heavy rain; author Mark Antony Lower referred to an early 19th-century drawing of the Royal Pavilion showing "quite a pool of water across the Steyne".[47]		Despite 16th-century writer Andrew Boorde's claim that "Bryght-Hempston [is] among the noble ports and havens of the realm",[48] Brighton never developed as a significant port: rather, it was considered as part of Shoreham. Nevertheless, the descriptions "Port of Brighthelmston" or "Port of Brighton" were sometimes used between the 14th and 19th centuries, as for example in 1766 when its notional limits were defined for customs purposes.[49]		The East Cliff runs for several miles from Pool Valley towards Rottingdean and Saltdean, reaching 24 metres (80 ft) above sea level. The soil beneath it, a mixture of alluvium and clay with some flint and chalk rubble, has experienced erosion for many years.[50] The cliff itself, like the rest of Brighton's soil, is chalk.[9] Below this are thin layers of Upper and Lower Greensand separated by a thicker band of Gault clay.[51] The land slopes upwards gradually from south to north towards the top of the Downs.		Main transport links developed along the floor of the Wellesbourne valley, from which the land climbs steeply—particularly on the east side. The earliest settlement was by the beach at the bottom of the valley,[43] which was partly protected from erosion by an underwater shale-bar. Changes in sea level affected the foreshore several times: 40 acres (16 ha) disappeared in the first half of the 14th century,[52] and the Great Storm of 1703 caused widespread destruction. The first sea defences were erected in 1723,[52] and a century later a long sea-wall was built.[50]		Brighton has a temperate climate: its Köppen climate classification is Cfb. It is characterised by mild, calm weather with high levels of sunshine, sea breezes and a "healthy, bracing air" attributed to the low level of tree cover.[53] Average rainfall levels increase as the land rises: the 1958–1990 mean was 740 millimetres (29 in) on the seafront and about 1,000 millimetres (39 in) at the top of the South Downs above Brighton.[53] Storms caused serious damage in 1703, 1806, 1824, 1836, 1848, 1850, 1896, 1910 and 1987. Snow is rare, but particularly severe falls were recorded in 1881 and 1967.[53]		At the time of the Domesday survey in 1086, Brighton was in the Rape of Lewes and the Hundred of Welesmere. The new Hundred of Whalesbone, which covered the parishes of Brighton, West Blatchington, Preston and Hove, was formed in 1296. Parishes moved in and out several times, and by 1801 only Brighton and West Blatchington were included in the Hundred.[57]		Brighton's ecclesiastical and civil parish boundaries were coterminous until 1873. Since then, the latter have changed several times as the urban area has expanded.[58] In its original form, Brighton covered about 1,640 acres (660 ha) between the English Channel, Hove, Preston, Ovingdean and Rottingdean. The civil parish was first extended from 31 October 1873, when 905 acres (366 ha) was annexed from Preston. Its ecclesiastical parish was not affected.		On 1 October 1923, 94 acres (38 ha) were added to Brighton from Patcham parish: Brighton Corporation was developing the Moulsecoomb council estate there at the time. On 1 April 1928, Brighton became a county borough and grew by nearly five times by adding Ovingdean and Rottingdean parishes in their entirety and parts of Falmer, Patcham and West Blatchington.[58] From 1 April 1952, more of Falmer and part of the adjacent Stanmer parish were added; 20 years later, land and marine territory associated with the new Brighton Marina development also became part of Brighton. Except for a small addition of rural land in 1993 (from Pyecombe parish), Brighton Borough's boundaries remained the same until it was joined to Hove Borough in 1997 to form the unitary authority of Brighton and Hove.[56]		The old boundary between Brighton and Hove is most clearly seen on the seafront, where the King Edward Peace Statue (1912) straddles the border, and in a twitten called Boundary Passage which runs northwards from Western Road to Montpelier Road.[59] There is a Grade II-listed parish boundary marker stone in this passageway.[60] Between Western Road and the seafront, the boundary runs up Little Western Street (pavement on eastern side, in Brighton), but it is not visible.[59] Northwards from Western Road, it runs to the west of Norfolk Road, Norfolk Terrace, Windlesham Road and Windlesham Gardens in the Montpelier area, then along the south side of Davigdor Road to Seven Dials. From there it runs along the west side of Dyke Road as far as Withdean Road in Withdean, at which point it crosses Dyke Road so that the section north of that is part of Hove parish. The boundary continues to follow Dyke Road towards Devil's Dyke on the South Downs.[61]		Brighton is covered by two constituencies in the Parliament of the United Kingdom: Brighton Kemptown and Brighton Pavilion. Both are marginal constituencies which were held by Labour from 1997 to 2010.[62] At the 2017 general election, Brighton Kemptown elected the Labour MP Lloyd Russell-Moyle, while Brighton Pavilion re-elected Caroline Lucas, the first Green Party MP elected to Westminster. In European elections, Brighton is part of the European Parliament constituency of South-East England.		As of 2017, there are 21 wards in the city of Brighton and Hove, of which 12 are in Brighton. Regency, St Peter's & North Laine, Preston Park, Withdean, Patcham, Hollingdean & Stanmer and Hanover & Elm Grove are part of the Brighton Pavilion constituency; Moulsecoomb & Bevendean, Queen's Park, East Brighton, Woodingdean and Rottingdean Coastal are covered by the Brighton Kemptown constituency.[63]		The newly created Borough of Brighton consisted of six wards in 1854: St Nicholas, St Peter, Pier, Park, Pavilion and West. When the territory was extended to include part of Preston parish in 1873, the new area became a seventh ward named Preston. The seven were split into 14 in 1894: Hanover, Kemp Town (renamed King's Cliff in 1908), Lewes Road, Montpelier, Pavilion, Pier, Preston, Preston Park, Queen's Park, Regency, St John, St Nicholas, St Peter, and West. Preston ward was extended in 1923 to incorporate the area taken into the borough from Patcham parish in 1923 for the construction of the Moulsecoomb estate, and in 1928 the ward was divided into four: Hollingbury, Moulsecoomb, Preston and Preston Park. Elm Grove and Patcham wards were created at the same time, bringing the total to 19. There were further changes in 1952, 1955 and 1983, at which time there were 16 wards.[64] This situation continued until 1 April 1997, when Hove and its wards became part of the new unitary authority of Brighton and Hove.[65]		Brighton Town Hall occupies a large site in The Lanes. Medieval Brighthelmston had a town hall, although it was called the Townhouse and functioned more like a market hall. A later building (1727) known as the Town Hall was principally used as a workhouse. Work on the first purpose-built town hall began in 1830; Thomas Read Kemp laid the first stone, and Thomas Cooper designed it on behalf of the Brighton Town Commissioners (of which he was a member). Brighton Corporation spent £40,000 to extend it in 1897–99 to the Classical design of Brighton Borough Surveyor Francis May. Despite this, the building was too small for municipal requirements by the mid-20th century, and extra council buildings were built in various locations throughout Brighton Borough Council's existence: the most recent, Bartholomew House and Priory House next to the town hall, were finished in 1987.[66][67] The town hall ceased to be responsible solely for Brighton's affairs when Brighton and Hove were united in 1997, but it is still used by Brighton & Hove City Council—particularly for weddings and civil ceremonies.[68]		The presence of a British subsidiary of the United States arms company EDO Corporation on the Home Farm Industrial Estate in Moulsecoomb has been the cause of protests since 2004. The premises were significantly damaged in January 2009 when protesters broke in.[69]		In 1985, the Borough Council described three "myths" about Brighton's economy. Common beliefs were that most of the working population commuted to London every day; that tourism provided most of Brighton's jobs and income; or that the borough's residents were "composed entirely of wealthy theatricals and retired businesspeople" rather than workers.[70] Brighton has been an important centre for commerce and employment since the 18th century. It is home to several major companies, some of which employ thousands of people locally; as a retail centre it is of regional importance; creative, digital and new media businesses are increasingly significant; and, although Brighton was never a major industrial centre, its railway works contributed to Britain's rail industry in the 19th and 20th centuries, particularly in the manufacture of steam locomotives.		Since the amalgamation of Brighton and Hove, economic and retail data has been produced at a citywide level only. Examples of statistics include: Brighton and Hove's tourism industry contributes £380m to the economy and employs 20,000 people directly or indirectly; the city has 9,600 registered companies; and a 2001 report identified it as one of five "supercities for the future".[71] In December 2013, Brighton was the third-highest ranked place on the UK Vitality Index Report, which measures the economic strength of towns and cities in the United Kingdom. It was "among the top performing towns and cities on almost all" of the 20 measures used by the index.[72]		Brighton's largest private sector employer is American Express, whose European headquarters are at John Street.[73] As of 2012, about 3,000 people work there.[74] Planning permission to demolish the old Amex offices and build a replacement was granted in 2009, and work started in March 2010. Other major employers include Lloyds Bank, Asda (which has hypermarkets at Hollingbury and Brighton Marina), Brighton & Hove Bus and Coach Company and call-centre operator Inkfish.[71] In 2012, it was reported that about 1,500 of Gatwick Airport's 21,000 workers lived in the city of Brighton and Hove.[75]		Brighton is a popular destination for conferences, exhibitions and trade fairs, and has had a purpose-built conference centre—the Brighton Centre—since 1977. Direct income from the Brighton Centre's 160 events per year is £8 million,[note 4] and a further £50 million is generated indirectly by visitors spending money during their stay. Events range from political party conferences to concerts.[76]		The Hollingbury Industrial Estate is one of the largest such facilities in Brighton; in its early days about 6,000 people were employed, principally in industrial jobs, but in the late 20th and early 21st centuries its focus has switched to commercial and retail development,[77] limiting Brighton's potential for industrial growth. Brighton Corporation laid out the estate on 18 acres (7.3 ha) of land around Crowhurst Road in 1950. By 1956, large-scale employment was provided at a bakery, a typewriter factory and a machine tools manufacturer among others. Most of the large factories closed during the recessions of the 1980s and 1990s, employment fell to 1,000, and structural changes started in the mid-1980s with a move towards small-scale industrial units (the Enterprise Estate was finished in October 1985) and then retail warehouses. Asda's superstore opened in November 1987, MFI followed two years later, and other retail units were built in the 1990s.[78] Two large headquarters buildings were vacated in quick succession when British Bookshops left in March 2011[79] and The Argus newspaper moved out of its headquarters in 2012—although the Brighton & Hove Bus and Coach Company signed a contract to move its 1,250 employees into the latter building.[80]		Brighton has a high density of businesses involved in the media sector, particularly digital or "new media", and since the 1990s has been referred to as "Silicon Beach".[81] By 2007, over 250 new media business had been founded in Brighton. Brandwatch is a social media monitoring company based in offices near Brighton station. Computer game design company Black Rock Studio was founded in 1998 and was taken over by Disney Interactive Studios,[71][81] who closed it down in 2011.[82] The Gamer Network, whose portfolio of websites relating to computer gaming (including Eurogamer) and creative industries was founded in 1999, is based in Brighton.[83]		By the early 21st century, the market for office accommodation in the city was characterised by fluctuating demand and a lack of supply of high-quality buildings. As an example, the Trafalgar Place development (c. 1990), "now considered a prime office location", stood partly empty for a decade.[84] Exion 27 (built in 2001), a high-tech, energy-efficient office development at Hollingbury, remained empty for several years and is still not in commercial use: it houses some administrative departments of the University of Brighton. It was Brighton's first ultramodern commercial property and was intended for mixed commercial and industrial use, but its completion coincided with a slump in demand for high-tech premises.[85][86]		The Lanes form a retail, leisure and residential area near the seafront, characterised by narrow alleyways following the street pattern of the original fishing village. The Lanes contain predominantly clothing stores, jewellers, antique shops, restaurants and pubs. The North Laine area is a retail, leisure and residential area immediately north of the Lanes. Its name derives from the Anglo-Saxon "Laine" meaning "fields", although the misnomer "North Lanes" is often used to describe the area. The North Laine contains a mix of businesses dominated by cafés, independent and avant-garde shops, bars and theatres.		Churchill Square is a shopping centre with a floor space of 470,000 sq ft (44,000 m2) and over 80 shops, several restaurants and 1,600 car-parking spaces.[87] It was built in the 1960s as an open-air, multi-level pedestrianised shopping centre, but was rebuilt and enlarged in 1998 and is no longer open-air. Further retail areas include Western Road and London Road, the latter of which is currently undergoing extensive regeneration in the form of new housing and commercial properties.[88]		The Royal Pavilion is a former royal palace built as a home for the Prince Regent during the early 19th century, under the direction of the architect John Nash, and is notable for its Indo-Saracenic architecture and Oriental interior. Other Indo-Saracenic buildings in Brighton include the Sassoon Mausoleum, now, with the bodies reburied elsewhere, in use as a chic supper club.		Brighton Marine Palace and Pier (long known as the Palace Pier) opened in 1899. It features a funfair, restaurants and arcade halls.[89]		The West Pier was built in 1866 and is one of only two Grade I listed piers in the United Kingdom. It has been closed since 1975. For some time it was under consideration for restoration, but two fires in 2003, and other setbacks, led to these plans being abandoned.[90] The Brighton i360 observation tower opened on 4 August 2016.[91] At 162 metres (531.49 feet) high, and with an observation pod rising to 138 metres (452.75 feet), the i360 is Britain's highest observation tower outside London – taller even than the London Eye.		Brighton clocktower, built in 1888 for Queen Victoria's jubilee, stands at the intersection of Brighton's busiest thoroughfares.		Volk's Electric Railway runs along the inland edge of the beach from Brighton Pier to Black Rock and Brighton Marina. It was created in 1883 and is the world's oldest operating electric railway.[92]		The Grand Hotel was built in 1864. The Brighton hotel bombing occurred there. Its nighttime blue lighting is particularly prominent along the foreshore.[93]		The 11th century (1086)[94] St Nicholas Church is the oldest building in Brighton, commonly known as "The Mother Church".[95] Other notable churches include the very tall brick-built St Bartholomew's (1874) designed by the architect Edmund Scott,[96] St Peter's (1828), and St. Martin's, noted for its decorated interior. Brighton's Quakers run the Friends' Meeting House in the Lanes. There is an active Unitarian community based in a Grade 2 listed building in New Road, and a Spiritualist church in Norfolk Square.[97] There are also a number of New Age outlets and groups.		Brighton-Hove has five synagogues: New Church Road Synagogue, Hove; Holland Road Synagogue, Hove; Brighton & Hove Progressive Synagogue, Hove; Brighton & Hove Reform Synagogue, Hove; Middle Street Synagogue; Brighton. The Middle Street Synagogue is a Grade II-listed building built in 1874–75. It is being gradually restored by English Heritage. There are also several mosques[98] and Buddhist centres.[99]		Brighton has become known as one of the least religious places in the UK, based upon analysis of the 2011 census which revealed that 42 per cent of the population profess no religion, far higher than the national average of 25%.[100] As part of the Jedi census phenomenon, 2.6 per cent claimed their religion was Jedi Knight, the largest percentage in the country.[101]		Brighton has a 5.4-mile (8.7 km) expanse of shingle beach,[52] part of the unbroken 8-mile (13 km) section within the city limits.[note 5] Neighbouring Hove is known for its hundreds of painted timber beach huts, but brick-walled chalets are also available on Brighton seafront, especially towards Rottingdean and Saltdean.[102] Especially east of the Palace Pier, a flat sandy foreshore is exposed at low tide.[52] The Palace Pier section of the beach has been awarded blue flag status.[103] Part of the beach adjoining Madeira Drive, to the east of the city centre, has been redeveloped into a sports complex and opened to the public in March 2007, with courts for pursuits such as beach volleyball and ultimate Frisbee among others.		The city council owns all the beaches, which are divided into named sections by groynes—the first of which were completed in 1724. Eastwards from the Hove boundary, the names are Boundary, Norfolk, Bedford, Metropole, Grand (referring to the four hotels with those names), Centre, King's, Old Ship, Volk's, Albion, Palace Pier, Aquarium, Athina (where the MS Athina B ran aground), Paston, Banjo, Duke's, Cliff, Crescent and Black Rock. Cliff Beach is a nudist beach.[104] Beyond Black Rock, the cliffs (part of the Brighton to Newhaven Cliffs Site of Special Scientific Interest) rise to more than 100 feet (30 m) and there are three small beaches at Ovingdean Gap, Rottingdean Gap and Saltdean Gap. All are connected by the Undercliff Walk,[52] which has been affected by several cliff falls since 2000.[105]		Since the demolition in 1978 of the Black Rock open-air lido at the eastern end of Brighton's seafront, the area has been developed and now features one of Europe's largest marinas. However, the site of the pool itself remains empty except for a skate park and graffiti wall. Since 2003 a series of developments have been proposed but have come to nothing, including housing, a five-star hotel with a winter garden, and an 11,000-seat sports arena.[106]		The seafront is also home to many restaurants, sports facilities, amusement arcades, nightclubs and bars.[107]		Brighton featured in a number of popular movies including Quadrophenia (1979), The End of the Affair (1999), Wimbledon (2004), MirrorMask (2005), Angus, Thongs and Perfect Snogging (2008), The Young Victoria (2009), Brighton Rock (2010 and 1947) and The Boat that Rocked (2009).[108]		The Duke of York's Picturehouse,[109] dating from 1910, was opened by Mrs Violet Melnotte-Wyatt. It is the country's oldest purpose-built cinema and was Brightons first Electric Bioscope, which still operates as an arthouse cinema. The Duke of York's Picturehouse expanded in 2012, adding two additional screens in a different location. The company is now occupying the upstairs of Komedia, situated on Gardner Street, central Brighton.[110] There are two multiplex cinemas, the Odeon on North Street and Cineworld in the Marina.		Each May the city hosts the Brighton Festival and Brighton Fringe, the second largest arts festival in the UK (after Edinburgh). This includes processions such as the Children's Parade, outdoor spectaculars often involving pyrotechnics, and theatre, music and visual arts in venues throughout the city, some brought into this use exclusively for the festival. The earliest feature of the festival, the Artists' Open Houses, are homes of artists and craftspeople opened to the public as galleries, and usually selling the work of the occupants. Since 2002, these have been organised independently of the official Festival and Fringe.		Brighton Fringe runs alongside Brighton Festival, and has grown to be one of the largest fringe festivals in the world.[111] Together with the street performers from Brighton Festival's "Streets of Brighton" events, and the Royal Mile-esque outdoor performances that make up "Fringe City", outdoor spectacles and events more than double during May.[112]		Other festivals include The Great Escape, featuring three nights of live music in venues across the city; the Soundwaves Festival in June, which shows classical music composed in the 21st Century, and involves both amateur and professional performers; Paddle Round the Pier; Brighton Live which each September stages a week of free gigs in pubs to show local bands; Burning the Clocks, a winter solstice celebration; and Brighton Pride (see lesbian, gay, bisexual and transgender community, below). For a number of years, Andrew Logan's Alternative Miss World extravaganza was held in the city.		The Kemptown area has its own small annual street festival, the Kemptown Carnival, and the Hanover area similarly has a "Hanover Day". Local resident Fatboy Slim puts on a "Big Beach Boutique" show most years. An inaugural White Nights (Nuit Blanche) all-night arts festival took place in October 2008 and continued for 4 years until it was postponed in 2012 due to a lack of European funding.[113] 2009 saw the first Brighton Zine Fest[114] celebrating zine and DIY culture within the city.		Brighton is the terminus of a number of London-to-Brighton rides, and runs, such as the veteran car run and bike ride. Transport rallies are also hosted on the seafront. Groups of mods and Rockers still bring their scooters and motorbikes to the town, but their gatherings are now much more sedate than the violent 1960s confrontations depicted in Quadrophenia.		Food and drink related festivals include the traditional Blessing of the Fisheries, where barbecued mackerel are eaten on the beach and the more recent Fiery Foods Chilli Festival.[115] There is also a twice-yearly general food festival.[116] The main Sussex beer festival is held in nearby Hove, and there is a smaller beer festival in the Hanover area. Foodies Festival[117] also counts Brighton as one of its seven national venues, with the event taking place between 25–27 May at Hove Lawns and including top chefs such as Loyd Grossman.		Brighton is the home of the UK's first Walk of Fame which celebrates the many rich and famous people associated with the city.[118]		Brighton records LGBT history in the city since the 19th century.[119] Many LGBT pubs, clubs, bars, restaurants, cafés and shops are located around Brighton and in particular around St James's Street in Kemptown.[120] Several LGBT charities, publishers, social and support groups are also based in the city. Brighton Pride is usually celebrated at the start of August.[121] Brighton also hosts an annual trans pride event, which is the first of its kind in the UK.[122] In a 2014 estimate, 11–15% of the city's population aged 16 or over is thought to be lesbian, gay or bisexual.[123] The city also had the highest percentage of same-sex households in the UK in 2004[124] and the largest number of civil partnership registrations outside London in 2013.[125]		Brighton museums include Brighton Museum & Art Gallery, Preston Manor, Booth Museum of Natural History, Brighton Toy and Model Museum, and Brighton Fishing Museum, the long established social epicentre of the seafront, which includes artefacts from the West Pier. The Royal Pavilion is also open to the public, serving as a museum to the British Regency.		Brighton has many night-life hotspots[126] and is associated with popular musicians including Fatboy Slim, Kirk Brandon, Tim Booth, Nick Cave, David Van Day from Dollar, and Robert Smith. Live music venues include the Concorde2,[127] Brighton Centre and the Brighton Dome, where ABBA received a substantial boost to their career when they won the Eurovision Song Contest 1974. Many events and performance companies operate in the city. Brighton’s has produced several successful bands & music artists including Royal Blood, The Kooks, Fatboy Slim, Freemasons, The Levellers and The Maccabees, British Sea Power, The Eighties Matchbox B-Line Disaster, Rizzle Kicks. Brighton is also home to several independent record labels.		Brighton has about 400 restaurants.[128]		Theatres include the Brighton Dome and associated Pavilion Theatre, the expanded Komedia (primarily a comedy and music venue but also a theatre), the Old Market which was renovated and re-opened in 2010 and the Theatre Royal[129] which celebrated its 200th anniversary in 2007. There are also smaller theatres such as the Marlborough Theatre, the New Venture, and the Brighton Little Theatre. The city has the new purpose built Brighton Open Air Theatre, or B•O•A•T, which is due to open for the Brighton Festival in May 2015. It is unique in that its programme will be chosen by lottery to ensure that it remains accessible and open to all comers.[citation needed]		Brighton & Hove City Council is responsible for 80 schools, of which 54 are in Brighton.[130]		The University of Sussex established in 1961 is a campus university between Stanmer Park and Falmer, four miles (6 km) from the city centre. Served by frequent trains (to Falmer railway station) and 24-hour buses, it has a student population of 12,500 of which 70% are undergraduates.[131] The university is currently ranked 18th in the UK[132] and 110th in the world by the World University Rankings.[133]		The University of Brighton, the former Brighton Polytechnic, has a student population of 20,017 of which 80% are undergraduates.[134] The university is on several sites with additional buildings in Falmer, Moulsecoomb, Eastbourne and Hastings.[135]		In 2003, the universities of Sussex and Brighton formed a medical school, known as Brighton and Sussex Medical School. The school was one of four new medical schools to be created as part of a government programme to increase the number of qualified NHS doctors. The school is based in Falmer and works closely with the Brighton and Sussex University Hospitals NHS Trust.		A range of non-university courses for students over 16, mainly in vocational education subjects, is provided at the further education college, City College Brighton and Hove. More academic subjects can be studied by 16–18-year-olds at Brighton Hove & Sussex Sixth Form College (BHASVIC) in the Seven Dials area. Varndean College in North Brighton occupies a commanding position. The 1920s building is celebrated for its façade and internal quads. The college offers academic A levels, The International Baccalaureate and vocational courses.		There are state schools and some faith schools. Notable state schools include[136] Longhill High School, Varndean School, Patcham High School, Dorothy Stringer High School, Blatchington Mill School and Sixth Form College and Brighton Aldridge Community Academy.		There are a number of independent schools, including Brighton College, Roedean School, Steiner School, BHHS and a Montessori School. As with the state schools, some independents are faith-based; Torah Academy, the last Jewish primary school, became a Pre-K/Nursery School at the end of the 2007. The Brighton Institute of Modern Music, a fully accredited music college, opened in 2001 and has since expanded to five locations throughout the UK.		In spring and summer, thousands of students from all over Europe gather to attend language courses at the many language schools.		Brighton & Hove Albion Football Club is the city's professional football team. After playing at the Goldstone Ground for 95 years, the club spent two years ground-sharing at Gillingham before returning to the town as tenants of the Withdean Athletics Stadium. However, in 2011 the club permanently moved to Falmer Stadium in Falmer at the start of the 2011–12 season, with the first match being played there in July 2011. The club's notable achievements including winning promotion to the Football League First Division for the first time in 1979, staying there for four seasons, during the last of which they reached the FA Cup Final and took Manchester United to a replay before losing 4-0. The 2017-18 Football season will see Brighton's debut in the Premier League, after a win against Wigan Athletic guaranteed automatic promotion to the top flight.[137] Notable former managers of the club include Brian Clough, Peter Taylor (born 1928), Peter Taylor (born 1953), Jimmy Melia, Liam Brady, Jimmy Case, Steve Gritt, Brian Horton, Steve Coppell and Mark McGhee. Notable former players include Gareth Barry, Dave Beasant, Justin Fashanu, Dennis Mortimer, Gordon Smith, Frank Stapleton, Howard Wilkinson and Bobby Zamora.		Whitehawk Football Club is a semi-professional football club based in the Whitehawk suburb of Brighton. Currently, they play in the Conference South having won promotion three times in the space four years between 2009–13. Whitehawk play their games at The Enclosed Ground, beautifully set into the South Downs, close to Brighton Marina. Notable former/current players include Sergio Torres, Jake Robinson, Matthew Lawrence and Darren Freeman.		Brighton and Hove is home to the Sussex County Cricket Club at Eaton Road in Hove.		Brighton Football Club (RFU) is one of the oldest Rugby Clubs in England.[138]		Brighton & Hove Hockey Club is a large hockey club, with a homeground based in Hove. The men's 1XI gained promotion to the England Hockey League system, Conference East, in 2013.[139]		Throughout the year many events take place on Madeira Drive (a piece of roadway on Brighton's seafront), which was constructed to host what is commonly held to be the world's oldest motor race, the Brighton Speed Trials, which has been running since 1905. The event is organised by the Brighton and Hove Motor Club and normally takes place on the second Saturday in September each year.		There is also an from time to time a beach soccer competition in a temporary stadium on imported sand on the beach. The inaugural contest in June 2002 featured football stars such as Eric Cantona and Matt Le Tissier.		Brighton has a horse-racing course, Brighton Racecourse, with the unusual feature that when the full length of the course is to be used, some of the grass turf of the track has to be laid over the tar at the top of Wilson Avenue, a public road, which therefore has to be closed for the races.		There is a greyhound racing circuit – the Brighton & Hove Greyhound Stadium – in Hove, run by Coral, at which Motorcycle speedway racing was staged in 1928.		The Brighton and Hove Pétanque Club runs an annual triples, doubles and singles competition, informal KOs, winter and summer league, plus Open competitions with other clubs. The club is affiliated to Sussex Pétanque, the local region of the English Pétanque Association, so they can also play at a Regional and National level. The Peace Statue terrain is the official pétanque terrain situated on the seafront near the West Pier.[140]		Brighton has two competitive swimming clubs. Brighton SC[141] formed in 1860 claims to be the oldest swimming club in England. Brighton Dolphin SC[142] was formed in 1891 as Brighton Ladies Swimming.		Brighton was chosen as one of the one of the 13 Rugby World Cup 2015 host cities,[143] with two games being played at the 30,750 capacity American Express Community Stadium (Although it was named the "Brighton Community Stadium" throughout the tournament for sponsorship reasons.) One of the two games played was one of the biggest shocks in the history of Rugby Union,[144] with Japan defeating South Africa 34 points to 32, with a try in the dying minutes of the game. The other game was between Samoa and the United States.		Brighton has several railway stations, many bus routes, coach services and taxis. A Rapid Transport System has been under consideration for some years.[145] Trolleybuses, trams, ferries and hydrofoil services have operated in the past.		Brighton is connected to the national road network by the A23 (London Road) northwards, and by two east–west routes: the A259 along the coast and the A27 trunk route inland. The A23 joins the M23 motorway at Pease Pottage near Gatwick Airport.[146] The A27 originally ran through the urban area along Old Shoreham Road and Lewes Road, but it now follows the route of the Brighton Bypass (opened in 1990) and the old alignment has become the A270.		A bypass was first proposed in 1932, six routes were submitted for approval in 1973, and the Department of the Environment published its recommended route in 1980. Public enquiries took place in 1983 and 1987, construction started in 1989 and the first section—between London Road at Patcham and the road to Devil's Dyke—opened in summer 1991.[147] By 1985 there were about 5,000 parking spaces in central Brighton. The largest car parks are at London Road, King Street, and the Churchill Square/Regency Road/Russell Road complex.[148] In 1969, a 520-space multi-storey car park was built beneath the central gardens of Regency Square.[148][149]		Frequent trains operate from Brighton railway station. Many Brighton residents commute to work in London[150] and destinations include London Victoria, London Bridge and St Pancras International. Most trains serve Gatwick Airport, and those operated by Thameslink continue to St Albans, Luton, Luton Airport Parkway and Bedford. The fastest service from London Victoria takes 51 minutes.[151] The West Coastway Line serves stations to Hove, Worthing, Portsmouth and Southampton; and the East Coastway Line runs via Lewes to Newhaven, Eastbourne, Hastings and Ashford, Kent, crossing the landmark London Road viaduct en route and providing "a dramatic high-level view" of Brighton.[151] A wider range of long-distance destinations was served until 2007–08 when rationalisation caused the ending of InterCity services via Kensington (Olympia) and Reading to Birmingham, Manchester and Edinburgh.[151] Twice-daily long-distance services to Bristol and Great Malvern are operated by Great Western Railway via the West Coastway Line.		Until deregulation in 1986, bus services in Brighton were provided by Southdown Motor Services and Brighton Borough Transport under a joint arrangement called "Brighton Area Transport Services". Southdown were part of the nationalised NBC group and were based at Freshfield Road in the Kemptown area; Brighton Borough Transport were owned by the council and used the former tram depot at Lewes Road as their headquarters. Joint tickets were available and revenue was shared.[152] The Brighton & Hove Bus Company, owned by the Go-Ahead Group since 1993, now runs most bus services in Brighton. Its fleet has about 280 buses.[153] Compass Travel, The Big Lemon, Metrobus, Stagecoach South and The Sussex Bus also operate some services to central Brighton. The city had 1,184 bus stops in 2012, 456 of which had a shelter.[154] Real-time travel information displays are provided at many stops.[153]		The only park and ride facility in Brighton is based at the Withdean Stadium. It does not offer a dedicated shuttle bus service: intending passengers must join the Brighton & Hove Bus Company's route 27 service to Saltdean—which travels via Brighton railway station, the Clock Tower and Old Steine—and pay standard fares.[155] The 20-year City Plan released in January 2013 ruled out an official park-and-ride facility, stating it would be an "inefficient use of public money, particularly in an era of declining car use". Councillors and residents in Woodingdean and Rottingdean have claimed that streets and car parks in those areas have become unofficial park-and-ride sites: drivers park for free and take buses into the city centre.[156]		Shoreham Airport is 9 miles (14 km) west of Brighton near the town of Shoreham-by-Sea.[146][157] The airport has since rebranded Brighton (Shoreham) Airport.[158]		Gatwick Airport is 22 miles (35 km) north on the A23; and regular coach and rail services operate from Brighton to the Airport.[146]		
Joaquín Sorolla y Bastida (Spanish: [xoaˈkin soˈɾoʎa]) (27 February 1863 – 10 August 1923) was a Spanish painter. Sorolla excelled in the painting of portraits, landscapes, and monumental works of social and historical themes. His most typical works are characterized by a dexterous representation of the people and landscape under the bright sunlight of his native land and sunlit water.[1]						Joaquín Sorolla was born on February 27, 1863 in Valencia, Spain. Sorolla was the eldest child born to a tradesman, also named Joaquin Sorolla, and his wife, Concepción Bastida. His sister, Concha, was born a year later. In August 1865, both children were orphaned when their parents died, possibly from cholera. They were thereafter cared for by their maternal aunt and uncle.[2]		He received his initial art education at the age of 9 in his native town, and then under a succession of teachers including Cayetano Capuz, Salustiano Asenjo. At the age of eighteen he traveled to Madrid, vigorously studying master paintings in the Museo del Prado. After completing his military service, at twenty-two Sorolla obtained a grant which enabled a four-year term to study painting in Rome, Italy, where he was welcomed by and found stability in the example of Francisco Pradilla, the director of the Spanish Academy in Rome. A long sojourn to Paris in 1885 provided his first exposure to modern painting; of special influence were exhibitions of Jules Bastien-Lepage and Adolf von Menzel. Back in Rome he studied with José Benlliure, Emilio Sala, and José Villegas Cordero.[3]		In 1888, Sorolla returned to Valencia to marry Clotilde García del Castillo, whom he had first met in 1879, while working in her father's studio. By 1895, they would have three children together: Maria, born in 1890, Joaquín, born in 1892, and Elena, born in 1895. In 1890, they moved to Madrid, and for the next decade Sorolla's efforts as an artist were focussed mainly on the production of large canvases of orientalist, mythological, historical, and social subjects, for display in salons and international exhibitions in Madrid, Paris, Venice, Munich, Berlin, and Chicago.[4]		His first striking success was achieved with Another Marguerite (1892), which was awarded a gold medal at the National Exhibition in Madrid, then first prize at the Chicago International Exhibition, where it was acquired and subsequently donated to the Washington University Museum in St. Louis, Missouri. He soon rose to general fame and became the acknowledged head of the modern Spanish school of painting. His picture The Return from Fishing (1894) was much admired at the Paris Salon and was acquired by the state for the Musée du Luxembourg. It indicated the direction of his mature output.[5]		Sorolla painted two masterpieces in 1897 linking art and science: Portrait of Dr. Simarro at the microscope and A Research. These paintings were presented at the National Exhibition of Fine Arts held in Madrid in that year and Sorolla won the Prize of Honor. Here, he presents his friend Simarro as a man of science who transmits his wisdom investigating and, in addition, it is the triumph of naturalism, as it recreates the indoor environment of the laboratory, catching the luminous atmosphere produced by the artificial reddish-yellow light of a gas burner that contrasts with the weak mauvish afternoon light that shines through the window. These paintings may be among the most outstanding world paintings of this genre.[6]		An even greater turning point in Sorolla's career was marked by the painting and exhibition of Sad Inheritance (1899, seen at left), an extremely large canvas, highly finished for public consideration. The subject was a depiction of crippled children bathing at the sea in Valencia, under the supervision of a monk. The polio epidemic that struck some years earlier the land of Valencia is present, possibly for the first time in the history of painting, through the image of the two affected children.[7] The painting earned Sorolla his greatest official recognition, the Grand Prix and a medal of honor at the Universal Exhibition in Paris in 1900, and the medal of honor at the National Exhibition in Madrid in 1901.		A series of preparatory oil sketches for Sad Inheritance were painted with the greatest luminosity and bravura, and foretold an increasing interest in shimmering light and of a medium deftly handled.[8] Sorolla thought well enough of these sketches that he presented two of them as gifts to American artists; one to John Singer Sargent, the other to William Merritt Chase.[9] After this painting Sorolla never returned to a theme of such overt social consciousness.[10]		The exhibit at the Paris Universal Exposition of 1900 won him a medal of honour and his nomination as Knight of the Legion of Honour; within the next few years Sorolla was honoured as a member of the Fine Art Academies of Paris, Lisbon, and Valencia, and as a Favourite Son of Valencia.		A special exhibition of his works—figure subjects, landscapes and portraits—at the Galeries Georges Petit in Paris in 1906 eclipsed all his earlier successes and led to his appointment as Officer of the Legion of Honour. The show included nearly 500 works, early paintings as well as recent sun-drenched beach scenes, landscapes, and portraits, a productivity which amazed critics and was a financial triumph.[11] Though subsequent large-scale exhibitions in Germany and London were greeted with more restraint, while in England in 1908 Sorolla met Archer Milton Huntington, who made him a member of The Hispanic Society of America in New York City, and invited him to exhibit there in 1909. The exhibition comprised 356 paintings, 195 of which sold. Sorolla spent five months in America and painted more than twenty portraits.[12]		Sorolla's work is often exhibited together with that of his contemporaries and friends, John Singer Sargent and Anders Zorn.[13]		Although formal portraiture was not Sorolla's genre of preference, because it tended to restrict his creative appetites and could reflect his lack of interest in his subjects,[14] the acceptance of portrait commissions proved profitable, and the portrayal of his family was irresistible. Sometimes the influence of Velázquez was uppermost, as in My Family (1901), a reference to Las Meninas which grouped his wife and children in the foreground, the painter reflected, at work, in a distant mirror.[15] At other times the desire to compete with his friend John Singer Sargent was evident, as in Portrait of Mrs. Ira Nelson Morris and her children (1911).[16] A series of portraits produced in the United States in 1909, commissioned through the Hispanic Society of America, was capped by the Portrait of Mr.Taft, President of the United States,[17] painted at the White House, and suggestive of convivial sessions between painter and president.[18]		The appearance of sunlight could be counted on to rouse his interest, and it was outdoors where he found his ideal portrait settings.[19] Thus, not only did his daughter pose standing in a sun-dappled landscape for María at La Granja (1907), but so did Spanish royalty, for the Portrait of King Alfonso XIII in a Hussar's Uniform (1907).[20] For Portrait of Mr. Louis Comfort Tiffany (1911),[21] the American artist posed seated at his easel in his Long Island garden, surrounded by extravagant flowers. The conceit reaches its high point in My Wife and Daughters in the Garden (1910, seen at right), in which the idea of traditional portraiture gives way to the sheer fluid delight of a painting constructed with thick passages of color, Sorolla's love of family and sunlight merged.		Early in 1911, Sorolla visited the United States for a second time, and exhibited 152 new paintings at the Saint Louis Art Museum[22] [23] and 161 at the Art Institute of Chicago a few weeks later.[24] Later that year Sorolla met Archie Huntington in Paris and signed a contract to paint a series of oils on life in Spain. These 14 magnificent murals, installed to this day in the Hispanic Society of America building in Manhattan, range from 12 to 14 feet in height, and total 227 feet in length.[25] [26] The major commission of his career, it would dominate the later years of Sorolla's life.		Huntington had envisioned the work depicting a history of Spain, but the painter preferred the less specific 'Vision of Spain', eventually opting for a representation of the regions of the Iberian Peninsula, and calling it The Provinces of Spain.[27] Despite the immensity of the canvases, Sorolla painted all but one en plein air, and travelled to the specific locales to paint them: Navarre, Aragon, Catalonia, Valencia, Elche, Seville, Andalusia, Extremadura, Galicia, Guipuzcoa, Castile, Leon, and Ayamonte, at each site painting models posed in local costume. Each mural celebrated the landscape and culture of its region, panoramas composed of throngs of laborers and locals. By 1917 he was, by his own admission, exhausted.[28] He completed the final panel by July 1919.[29]		Sorolla suffered a stroke in 1920, while painting a portrait in his garden in Madrid. Paralyzed for over three years, he died on 10 August 1923. He is buried in the Cementeri de Valencia, Spain.[30]		The Sorolla Room, housing the Provinces of Spain at the Hispanic Society of America, opened to the public in 1926.[31] The room closed for remodeling in 2008, and the murals toured museums in Spain for the first time. The Sorolla Room reopened in 2010, with the murals on permanent display.[32]		Sorolla's influence on some other Spanish painters, such as Alberto Pla y Rubio[33] and Julio Romero de Torres,[34] was so noted that they are described as "sorollista."[35]		After his death, Sorolla's widow, Clotilde García del Castillo, left many of his paintings to the Spanish public. The paintings eventually formed the collection that is now known as the Museo Sorolla, which was the artist's house in Madrid. The museum opened in 1932.		Sorolla's work is represented in museums throughout Spain, Europe, America, and in many private collections in Europe and America. In 1933, J. Paul Getty purchased ten Impressionist beach scenes made by Sorolla, several of which are now housed in the J. Paul Getty Museum.[36]		In 1960, Sorolla, el pintor de la luz, a short documentary written and directed by Manuel Domínguez was presented at the Cannes Film Festival.[37]		In 2007 many of his works were exhibited at the Petit Palais in Paris, alongside those of John Singer Sargent, a contemporary who painted in a similarly impressionist-influenced manner. In 2009, there was a special exhibition of his works at the Prado in Madrid, and in 2010, the exhibition visited the Oscar Niemeyer Museum in Curitiba, Brazil.		From 5 December 2011 to 10 March 2012, several of Sorolla's works were exhibited in Queen Sofía Spanish Institute, in New York. This exhibition included pieces used during Sorolla's eight-year research for The Vision of Spain.		An exhibition titled Sorolla & America explored Sorolla’s unique relationship with the United States in the early twentieth century. The exhibition opened at the Meadows Museum at SMU in Dallas (13 December 2013 - 19 April 2014). From there it traveled to the San Diego Museum of Art (30 May - 26 August 2014) and then to Fundación MAPFRE in Madrid (23 September 2014 - 11 January 2015).[38]		The Spanish National Dance Company honored the painter's The Vision of Spain by producing a ballet Sorolla based on the paintings[39]		The Horse’s Bath, Sorolla Museum, Madrid		Portrait of Dr Simarro at the microscope, 1897, (Luis Simarro Legacy Trust, Fundación General, Complutense University)		Children on the Seashore, 1903. In the upper right corner, Sorolla has included an oblique reference to another favorite theme, oxen pulling fishing boats in to shore. Philadelphia Museum of Art		Beach at Valencia, 1908.		My Wife and Daughters in the Garden, 1910.		Castilla or La fiesta del pan, 1913. First completed of The Provinces of Spain, 14 murals at the Hispanic Society in Manhattan.		Walk on the Beach or Paseo a orillas del mar, 1909. Sorolla Museum, Madrid		Robert Bacon, 1909		 This article incorporates text from a publication now in the public domain: Chisholm, Hugh, ed. (1911). "Joaquín Sorolla". Encyclopædia Britannica (11th ed.). Cambridge University Press. 		
Patronage is the support, encouragement, privilege, or financial aid that an organization or individual bestows to another. In the history of art, arts patronage refers to the support that kings, popes, and the wealthy have provided to artists such as musicians, painters, and sculptors. It can also refer to the right of bestowing offices or church benefices, the business given to a store by a regular customer, and the guardianship of saints. The word "patron" derives from the Latin: 'patronus' ("patron"), one who gives benefits to his clients (see Patronage in ancient Rome).		In some countries the term is used to describe political patronage, which is the use of state resources to reward individuals for their electoral support. Some patronage systems are legal, as in the Canadian tradition of the Prime Minister to appoint senators and the heads of a number of commissions and agencies; in many cases, these appointments go to people who have supported the political party of the Prime Minister. As well, the term may refer to a type of corruption or favoritism in which a party in power rewards groups, families, ethnicities for their electoral support using illegal gifts or fraudulently awarded appointments or government contracts.[1]						From the ancient world onward, patronage of the arts was important in art history. It is known in greatest detail in reference to medieval and Renaissance Europe, though patronage can also be traced in feudal Japan, the traditional Southeast Asian kingdoms, and elsewhere—art patronage tended to arise wherever a royal or imperial system and an aristocracy dominated a society and controlled a significant share of resources. Samuel Johnson defined a patron as "one who looks with unconcern on a man struggling for life in the water, and, when he has reached ground, encumbers him with help".[2]		Rulers, nobles and very wealthy people used patronage of the arts to endorse their political ambitions, social positions, and prestige. That is, patrons operated as sponsors. Most languages other than English still use the term mecenate, derived from the name of Gaius Maecenas, generous friend and adviser to the Roman Emperor Augustus. Some patrons, such as the Medici of Florence, used artistic patronage to "cleanse" wealth that was perceived as ill-gotten through usury. Art patronage was especially important in the creation of religious art. The Roman Catholic Church and later Protestant groups sponsored art and architecture, as seen in churches, cathedrals, painting, sculpture and handicrafts.		While sponsorship of artists and the commissioning of artwork is the best-known aspect of the patronage system, other disciplines also benefited from patronage, including those who studied natural philosophy (pre-modern science), musicians, writers, philosophers, alchemists, astrologers, and other scholars. Artists as diverse and important as Chrétien de Troyes, Leonardo da Vinci and Michelangelo, William Shakespeare, and Ben Jonson all sought and enjoyed the support of noble or ecclesiastical patrons.[3][4] Figures as late as Wolfgang Amadeus Mozart and Ludwig van Beethoven also participated in the system to some degree; it was only with the rise of bourgeois and capitalist social forms in the middle 19th century that European culture moved away from its patronage system to the more publicly supported system of museums, theaters, mass audiences and mass consumption that is familiar in the contemporary world.		This kind of system continues across many fields of the arts. Though the nature of the sponsors has changed—from churches to charitable foundations, and from aristocrats to plutocrats—the term patronage has a more neutral connotation than in politics. It may simply refer to direct support (often financial) of an artist, for example by grants. In the later part of the 20th century, the academic sub-discipline of patronage studies began to evolve, in recognition of the important and often neglected role that the phenomenon of patronage had played in the cultural life of previous centuries.		Charitable and other non-profit making organisations often seek an influential figurehead to act as patron. The relationship often does not involve money. As well as conferring credibility, these people can use their contacts and charisma to assist the organisation to raise funds or to affect government policy. The British Royal Family are especially prolific in this respect, devoting a large proportion of their time to a wide range of causes.[5]		Sometimes consumers support smaller or local businesses or corporations out of loyalty even if less expensive options exist. Their regular custom is referred to as 'patronage'. Patronage may entitle members of a consumers' cooperative to a share of the surplus or profit generated by the co-op, called a patronage refund. This refund is a form of dividend.		In the Church of England, patronage is the commonly used term for the right to present a candidate to a benefice.		The liturgical feast of the Patronage of Our Lady was first permitted by Decree of the Sacred Congregation of Rites on 6 May 1679, for all the ecclesiastical provinces of Spain, in memory of the victories obtained over the Saracens, heretics and other enemies from the sixth century to the reign of Philip IV of Spain. Pope Benedict XII ordered it to be kept in the Papal States on the third Sunday of November. To other places it is granted, on request, for some Sunday in November, to be designated by the ordinary. In many places the feast of the Patronage is held with an additional Marian title of Queen of All Saints, of Mercy, Mother of Graces. The Office is taken entirely from the Common of the Blessed Virgin, and the Mass is the "Salve sancta parens".[6]		The Church Patronage (Scotland) Act 1711, (in force until 1874) resulted in multiple secessions from the Church of Scotland, including the secession of 1733, which led to the formation of the Associate Presbytery, the secession of 1761, which led to the formation of the Relief Church, and the Disruption of 1843, which led to the formation of the Free Church of Scotland.		While most news companies, particularly in North America are funded through advertising revenue,[7] secondary funding sources include audience members and philanthropists who donate to for-profit and non-profit organizations.		Political leaders have at their disposal a great deal of patronage, in the sense that they make decisions on the appointment of officials inside and outside government (for example on quangos in the UK). Patronage is therefore a recognized power of the executive branch. In most countries the executive has the right to make many appointments, some of which may be lucrative (see also sinecures). In some democracies, high-level appointments are reviewed or approved by the legislature (as in the advice and consent of the United States Senate); in other countries, such as those using the Westminster system, this is not the case. Other types of political patronage may violate the laws or ethics codes, such as when political leaders engage in nepotism (hiring family members) and cronyism such as fraudulently awarding non-competitive government contracts to friends or relatives or pressuring the public service to hire an unqualified family member or friend.		Political patronage, also known as "Padrino System" also a slang call as balimbing (starfruit), in the Philippines, has been the source of many controversies and corruption. It has been an open secret that one cannot join the political arena of the Philippines without mastery of the Padrino System. From the lowest Barangay official, to the President of the Republic, it is expected that one gains political debts and dispenses political favor to advance one's career or gain influence, if not wealth.		After Soviet leader Vladimir Lenin's retirement from politics in March 1923 following a stroke, a power struggle began between Soviet Premier Alexei Rykov, Pravda editor Nikolai Bukharin, Profintern leader Mikhail Tomsky, Red Army founder Leon Trotsky, former Premier Lev Kamenev, Comintern leader Grigory Zinoviev, and General Secretary Joseph Stalin. Stalin used patronage to appoint many Stalinist delegates (such as Vyacheslav Molotov, Lazar Kaganovich, Grigory Ordzhonikidze, and Mikhail Kalinin) to the Party Politburo and Sovnarkom in order to sway the votes in his favour, making Stalin the effective leader of the country by 1929.		During 2012, the African National Congress (ANC) mayor of Beaufort West in the Western Cape Province wrote a letter which openly and illegally solicited funds from the Construction Education and Training Authority for the ANC's 2016 election campaign. This episode, amongst many others including instances revolving around president Jacob Zuma, revealed how the African National Congress as ruling political party utilized patronage to reward supporters and strengthen the leading faction of the party's control over governmental institutions.[8]		In the United States during the Gilded Age, patronage became a controversial issue. Tammany boss William M. Tweed was an American politician who ran what is considered now to have been one of the most corrupt political machines in the country's history. Tweed and his cronies ruled for a brief time with absolute power over the city and state of New York. At the height of his influence, Tweed was the third-largest landowner in New York City, a director of the Erie Railway, the Tenth National Bank, and the New-York Printing Company, as well as proprietor of the Metropolitan Hotel.[9] At times he was a member of the United States House of Representatives, the New York City Board of Advisors, and the New York State Senate. In 1873, Tweed was convicted for diverting between $40 million and $200 million of public monies.[10]		Six months after James Garfield became president in 1881, Charles J. Guiteau, a disappointed office-seeker, assassinated him. To prevent further political violence and to assuage public outrage, Congress passed the Pendleton Act in 1883, which set up the Civil Service Commission. Henceforth, applicants for most federal government jobs would have to pass an examination. Federal politicians' influence over bureaucratic appointments waned, and patronage declined as a national political issue.		Beginning in 1969, a Supreme Court case in Chicago, Michael L. Shakman v. Democratic Organization of Cook County, occurred involving political patronage and its constitutionality. Shakman claimed that much of the patronage going on in Chicago politics was unlawful on the grounds of the first and fourteenth amendments. Through a series of legal battle and negotiations, the two parties agreed upon The Shakman Decrees. Under these decrees it was declared that the employment status of most public employees could not be affected positively or negatively based on political allegiance, with exceptions for politically inclined positions. The case is still in negotiation today, as there are points yet to be decided.[11][12][13]		Political patronage is not always considered corrupt. In the United States, the U.S. Constitution provides the president with the power to appoint individuals to government positions. He or she also may appoint personal advisers without congressional approval. Not surprisingly, these individuals tend to be supporters of the president. Similarly, at the state and local levels, governors and mayors retain appointments powers. Some scholars have argued that patronage may be used for laudable purposes, such as the "recognition" of minority communities through the appointment of their members to a high-profile positions. Bearfield has argued that patronage be used for four general purposes: create or strengthen a political organization; achieve democratic or egalitarian goals; bridge political divisions and create coalitions; and to alter the existing patronage system.[14]		Boliburguesía is a term that was coined by journalist Juan Carlos Zapata in order to "define the oligarchy that has developed under the protection of the Chavez government".[15] During Hugo Chávez's tenure, he seized thousands of properties and businesses while also reducing the footprint of foreign companies.[16] Venezuela's economy was then largely state-run and was operated by military officers that had their business and government affairs connected.[16] Senior fellow at the Brookings Institution, Harold Trinkunas, stated that involving the military in business was "a danger", with Trinkunas explaining that the Venezuelan military "has the greatest ability to coerce people, into business like they have".[16] According to Bloomberg Business, "[b]y showering contracts on former military officials and pro-government business executives, Chavez put a new face on the system of patronage".[16]		There are historical examples where the noble classes financed scientific pursuits.		Many Barmakids were patrons of the sciences, which greatly helped the propagation of Indian science and scholarship from the neighbouring Academy of Gundishapur into the Arabic world. They patronized scholars such as Gebir and Jabril ibn Bukhtishu. They are also credited with the establishment of the first paper mill in Baghdad. The power of the Barmakids in those times is reflected in The Book of One Thousand and One Nights; the vizier Ja'far appears in several stories, as well as a tale that gave rise to the expression "Barmecide feast".		We know of Yahya b Khalid al Barmaki (805) as a patron of physicians and, specifically, of the translation of Hindu medical works into both Arabic and Persian. In all likelihood however, his activity took place in the orbit of the caliphal court in Iraq , where at the behest of Harun al Rashid (786 -809), such books were translated into Arabic. Thus Khurasan and Transoxania were effectively bypassed in this transfer of learning from India to Islam, even though, undeniably the Barmakis cultural outlook owed something to their land of origin, northern Afghanistan, and Yahya al Barmaki's interest in medicine may have derived from no longer identifiable family tradition.[17]		In the same manner as commercial patronage, those who attend a sporting event may be referred to as patrons, though the usage in much of the world is now considered archaic—with some notable exceptions. Those who attend the Masters Tournament, one of the four major championship of professional golf, are still traditionally referred to as "patrons," largely at the insistence of the Augusta National Golf Club. This insistence is occasionally made fun of by sportswriters and other media.[18] In polo, a "patron" is a person who puts together a team by hiring one or more professionals. The rest of the team may be amateurs, often including the patron himself (or, increasingly, herself).		Also, people who attend hurling or Gaelic football games organised by the Gaelic Athletic Association are referred to as patrons.[19][20]		
As ocean surface waves come closer to shore they break, forming the foamy, bubbly surface called surf. The region of breaking waves defines the surf zone. After breaking in the surf zone, the waves (now reduced in height) continue to move in, and they run up onto the sloping front of the beach, forming an uprush of water called swash. The water then runs back again as backswash. The nearshore zone where wave water comes onto the beach is the surf zone. The water in the surf zone, or breaker zone, is shallow, usually between 5 and 10 m (16 and 33 ft) deep; this causes the waves to be unstable.						The animals that often are found living in the surf zone are crabs, clams, and snails. Surf clams and mole crabs are two species that stand out as inhabitants of the surf zone. Both of these animals are very fast burrowers. The surf clam, also known as the variable coquina, is a filter feeder that uses its gills to filter microalgae, tiny zooplankton, and small particulates out of seawater. The mole crab is a suspension feeder that eats by capturing zooplankton with its antennae. All of these creatures burrow down into the sand to escape from being pulled into the ocean from the tides and waves. They also burrow themselves in the sand to protect themselves from predators. The surf zone is full of nutrients, oxygen, and sunlight which leaves the zone very productive with animal life.		The surf zone can contain dangerous rip currents: strong local currents which flow offshore and pose a threat to swimmers. Rip-current outlooks use the following set of qualifications:		
Submergent coastlines are stretches along the coast that have been inundated by the sea by a relative rise in sea levels from either isostacy or eustacy.		Submergent coastline are the opposite of emergent coastlines, which have experienced a relative fall in sea levels.		Features of a submergent coastline are drowned river valleys or rias and drowned glaciated valleys or fjords.		Estuaries are often the drowned mouths of rivers.		The Western Coastal Plains of the Indian subcontinent are examples of submergent coastline. An ancient city of Dvārakā, mentioned in the great epic Mahabharata, islands now under water. The coastline also forms the estuaries of the Narmada and the Tapti Rivers.				
Scarborough (/ˈskɑːrbrə/ or /ˈskɑːrbərə/)[2][3] is a town on the North Sea coast of North Yorkshire, England. Historically part of the North Riding of Yorkshire, the town lies between 10–230 feet (3–70 m) above sea level, rising steeply northward and westward from the harbour on to limestone cliffs. The older part of the town lies around the harbour and is protected by a rocky headland.		With a population of just over 61,000, Scarborough is the largest holiday resort on the Yorkshire coast. The town has fishing and service industries, including a growing digital and creative economy, as well as being a tourist destination. People who live in the town are known as Scarborians.[4]						The most striking feature of the town's geography is a high rocky promontory pointing eastward into the North Sea. The promontory supports the 11th-century ruins of Scarborough Castle and divides the seafront into two bays, north and south.		The South Bay was the site of the original medieval settlement and harbour, which form the old town. This remains the main tourist area, with a sandy beach, cafés, amusements, arcades, theatres and entertainment facilities. The modern commercial town centre has migrated 440 yards (400 m) north-west of the harbour area and 100 feet (30 m) above it and contains the transport hubs, main services, shopping and nightlife. The harbour has undergone major regeneration including the new Albert Strange Pontoons,[5] a more pedestrian-friendly promenade, street lighting and seating.		The North Bay has traditionally been the more peaceful end of the resort and is home to Peasholm Park which, in June 2007, was restored to its Japanese-themed glory, complete with reconstructed pagoda.[6] For many years a mock maritime battle (based on the Battle of the River Plate) has been regularly re-enacted on the boating lake with large model boats and fireworks throughout the summer holiday season. The North Bay Railway is a miniature railway running from the park through Northstead Manor Gardens to the Sea Life Centre at Scalby Mills. The North Bay Railway has what is believed to be the oldest operational diesel-hydraulic locomotive in the world. Neptune was built in 1931 by Hudswell Clarke of Leeds and is appropriately numbered 1931.		Northstead Manor Gardens include the North Bay Railway and three other attractions: a water chute, a boating lake with boats for hire during the summer season and an open-air theatre. The Lord Mayor of London opened the theatre in 1932 and audiences flocked to see Merrie England, the first production to be staged at the outdoor venue. Productions were put on during the summer seasons until musicals ceased in 1968 after West Side Story, apart from a YMCA production in 1982. In 1997 the dressing rooms and stage set building on the island were demolished and the seating removed. The last concert to be held at the open-air theatre before it closed in 1986 was James Last and his orchestra. Scarborough's open-air theatre was reopened on Friday 23 July 2010 by Queen Elizabeth II with an operatic concert starring José Carreras and Dame Kiri Te Kanawa, accompanied by the Opera North Orchestra, concluding with a firework display.		North Bay and South Bay are linked by Marine Drive, an extensive Victorian promenade, built around the base of the headland. Overlooking both bays is Scarborough Castle, which was bombarded by the German warships SMS Derfflinger and SMS Von der Tann in the First World War. Both bays have popular sandy beaches and numerous rock-pools at low tide.		The South Cliff Promenade above the Spa and South Cliff Gardens has excellent views of the South Bay and old town. Its splendid Regency and Victorian terraces are still intact, with a mix of quality hotels and flats. The ITV television drama The Royal and its recent spin-off series, The Royal Today were both filmed in the area. The South Bay has the largest illuminated 'star disk' anywhere in the UK. It is 85 feet (26 m) across and fitted with subterranean lights representing the 42 brightest stars and major constellations that can be seen from Scarborough in the northern skies.[7]		To the south-west of the town, beside the York to Scarborough railway line, is an ornamental lake known as Scarborough Mere. In the 20th century the Mere was a popular park, with rowing boats, canoes and a miniature pirate ship – the Hispaniola – on which passengers were taken to 'Treasure Island' to dig for doubloons.[8] Since the late 1990s the Mere has been redesigned as a natural space for picnics, fishing and walkers. In 2012 a new snack bar was built alongside the Mere. The lake is now part of the Oliver's Mount Country Park and the Hispaniola now sails out of Scarborough harbour during the summer season.		The town was reportedly founded around 966 AD as Skarðaborg by Thorgils Skarthi, a Viking raider, though there is no archaeological evidence to support these claims, made during the 1960s, as part of a pageant of Scarborough events. The origin of this belief is a fragment of an Icelandic Saga. In the 4th century there had briefly been a Roman signal station on Scarborough headland and there is evidence of much earlier Stone Age and Bronze Age settlements. However any new settlement was soon burned to the ground by a rival band of Vikings under Tosti (Tostig Godwinson), Lord of Falsgrave, and Harald III of Norway. The destruction and massacre meant that very little remained to be recorded in the Domesday survey of 1085. The original inland village of Falsgrave was also Saxon rather than Viking.		Scarborough recovered under King Henry II, who built an Angevin stone castle on the headland and granted the town charters in 1155 and 1163, permitting a market on the sands and establishing rule by burgesses. Edward II granted Scarborough Castle to his favourite, Piers Gaveston. The castle was subsequently besieged by forces led by the barons Percy, Warenne, Clifford and Pembroke. Gaveston was captured and taken to Oxford and thence to Warwick Castle for execution.		In 1318, the town was burnt by the Scots, under Sir James Douglas following the Capture of Berwick upon Tweed.		In the Middle Ages Scarborough Fair, permitted in a royal charter of 1253, held a six-week trading festival attracting merchants from all over Europe. It ran from Assumption Day, 15 August, until Michaelmas Day, 29 September. The fair continued to be held for 500 years, from the 13th to the 18th century, and is commemorated in the song Scarborough Fair:		Scarborough and its castle changed hands seven times between Royalists and Parliamentarians during the English Civil War of the 1640s, enduring two lengthy and violent sieges. Following the civil war, much of the town lay in ruins.		In 1626, Elizabeth Farrow discovered a stream of acidic water running from one of the cliffs to the south of the town.[9] This gave birth to Scarborough Spa, and Dr Wittie's book about the spa waters published in 1660 attracted a flood of visitors to the town. Scarborough Spa became Britain's first seaside resort, though the first rolling bathing machines were not noted on the sands until 1735. It was a popular getaway destination for the wealthy of London, such as the bookseller Andrew Millar and his family. Their son Andrew junior died there in 1750.[10]		The coming of the Scarborough–York railway in 1845 increased the tide of visitors. Scarborough railway station claims a record for the world's longest platform seat.[11] From the 1880s until the First World War, Scarborough was one of the regular destinations for The Bass Excursions, when fifteen trains would take between 8,000 and 9,000 employees of Bass's Burton brewery on an annual trip to the seaside.		A young Malton architect, John Gibson, designed the Crown Spa Hotel, Scarborough's first purpose-built hotel.[12] In 1841 a railway link between York and Scarborough was being talked of and he decided that the area above the popular Spa building could be developed. He designed and laid the foundations before passing the construction of this hotel to the newly formed South Cliff Building Company. On Tuesday, 10 June 1845 Scarborough's first hotel was opened—a marketing coup at the time, as the Grand Hotel, soon to be Europe's largest, was not yet finished.[13]		When the Grand Hotel was completed in 1867 it was one of the largest hotels in the world and one of the first giant purpose-built hotels in Europe. Four towers represent the seasons, 12 floors represent the months, 52 chimneys represent the weeks and originally 365 bedrooms represented the days of the year. A blue plaque outside marks where the novelist Anne Brontë died in 1849. She was buried in the graveyard of St Mary's Church by the castle.[14]		The town has a fine Anglican church, St Martin-on-the-Hill, built in 1862–63 as the parish church of South Cliff. It contains works by Dante Gabriel Rossetti, William Morris, Edward Burne-Jones and Ford Madox Brown.[15]		During the First World War, the town was bombarded by German warships of the High Seas Fleet, an act which shocked the British (see Raid on Scarborough, Hartlepool and Whitby).		In 1929 the steam drifter Ascendent caught a 560-pound (250 kg) tunny (Atlantic bluefin tuna) and a Scarborough showman awarded the crew 50 shillings so he could exhibit it as a tourist attraction.[16] Big-game tunny fishing off Scarborough effectively started in 1930 when Lorenzo "Lawrie" Mitchell–Henry, landed a tunny caught on rod and line weighing 560 pounds (250 kg).[17] A gentlemen's club, the British Tunny Club, was founded in 1933 and set up its headquarters in the town at the place which is now a restaurant with the same name.[17][18] Scarborough became a resort for high society.[16] A women's world tuna challenge cup was held for many years.[16]		Colonel (and, later, Sir) Edward Peel landed a world-record tunny of 798 pounds (362 kg), capturing the record by 40 pounds (18.1 kg) from one caught off Nova Scotia by American champion Zane Grey.[19][20][21] The British record which still stands is for a fish weighing 851 pounds (386 kg) caught off Scarborough in 1933 by Laurie Mitchell-Henry.[16]		On 5 June 1993 Scarborough made headlines around the world when a landslip caused part of the Holbeck Hall Hotel, along with its gardens, to fall into the sea. Although the slip was shored up with rocks and the land has long since grassed over, evidence of the cliff's collapse remains clearly visible from The Esplanade, near Shuttleworth Gardens.[22]		The climate is temperate with mild summers and cool, windy, winters. The hottest months of the year are July and August, with temperatures reaching an average high of 17 °C and falling to 11 °C at night. The average daytime temperatures in January are 4 °C, falling to 1 °C at night. The station's elevation of 110 metres (360 ft) is far above sea level compared to the immediate coastline, where the climate is likely slightly milder year round.		Scarborough's fishing industry is still active, though much reduced in size. The working harbour is home to a fish market including a shop and wooden stalls where fresh, locally-caught seafood can be purchased by the public.		The tourism trade continues to be a major part of the local economy with Scarborough being the second most-visited destination in England by British holidaymakers.[25] While weekend and mid-week-break trade are tending to replace the traditional week-long family holiday, the beaches and attractions are always very busy throughout summer – a marked contrast to the quieter winter months when Scarborough is often seen as a peaceful bolt-hole from cities such as Leeds and Bradford. Confidence in the hospitality industry is high, evidenced by major refits in recent years, often targeted at a higher-spending clientele. Significant amongst these is the Grand, Scarborough's biggest hotel, which overlooks the South Bay, and also the Palm Court Hotel.		Scarborough's town centre has many major shopping chains alongside boutique independent shops. As well as a main pedestrianised shopping street (home to various chain stores and eateries) and the Brunswick shopping centre, boutique stores can be found on Bar Street and St Thomas Street. The town also has an indoor market with a large range of antique shops and independent traders in its vaults, and a smaller market on the South Bay. W Boyes & Co, a discount department store chain which has 44 stores across the north is based at Eastfield, on the outskirts of Scarborough. Its flagship store is located in Queen Street.		Manufacturers based in Scarborough include the Plaxton Company (a division of Alexander Dennis) which has been building coaches and buses since 1907,[26] and Cast Iron Radiators Ltd.[27]		Creative industries have been cited as playing a vital role in the regeneration of Scarborough – a report in 2005 estimated that they comprised 19% of the town's economy. They were also a major focus of Scarborough's winning entry in the 2008 Enterprising Britain competition, with representatives from Woodend Creative Workspace and Scarborough-based Electric Angel Design representing the town in the Yorkshire and Humber regional heats. In the finals in London on 16 October 2008, Scarborough won the title of Britain's Most Enterprising Town,[28] and subsequently went on to win the European Enterprise Awards as Great Britain's representative, on 13 May 2009 in Prague.[29]		In 2010 the town was the winner of the 'Great Town Award', as nominated by the Academy of Urbanism, beating Chester and Cambridge respectively.[30]		Scarborough's recent investment in digital connectivity is significant. The town has the UK's first free Wi-Fi seafront and harbour area and one of Europe's fastest internet connections (100MB).[31]		In recent years, arts, business and education have collaborated annually to produce Digital Scarborough – a celebration of the town's digital activities including a wide range of events from business networking to film showings and gigs with DJs and VJs.[citation needed]		Scarborough General Hospital is the local district general NHS hospital. It is run by the York Teaching Hospital NHS Foundation Trust and is the largest employer in the area employing over 2,400 staff.		The population of the town (comprising Castle, Central, Eastfield, Falsgrave Park, Newby, North Bay, Northstead, Ramshill, Stepney, Weaponness and Woodlands wards) is just over 60,000. Scarborough is at the heart of an urban area of just under 100,000 residents, and the rest of the Borough of Scarborough has well over that figure; during the peak season, tourism can double the population. 7.5% of the population are aged over 60, compared with an average of 20.9% nationally. Only 21.9% of the population are aged between 20 and 39, compared to 28.1% nationally.		Scarborough has four major roads serving the town; these also link it to other major towns and cities.		Scarborough railway station is close to the town centre and runs services from York, Leeds, Manchester and Liverpool on the North TransPennine Express route and from Hull on the Yorkshire Coast Line. It has the longest station seat in the world at 152 yards (139 m) in length. The town used to be connected to Whitby via the Scarborough and Whitby Railway along the Yorkshire coast, however this was closed down in 1965 due to the Beeching cuts. There is also a railway station in the suburb of Crossgates.		Scarborough has 25 main bus routes, operated by Scarborough and District, Arriva North East, Shoreline Suncruisers, and Yorkshire Coastliner. These link the town centre with its suburbs and local towns and cities such as Leeds, York, Hull, Middlesbrough and the North York Moors. The town is also served by two Park and Ride services, with its locations located on the A64 and A165. Buses run from each terminus to the town centre and South Bay at least every 12 minutes seven days a week, with stopping points around the town centre. Buses from the Filey Road terminus on the A165 also stop at the University. Open top tourist buses also run along the sea front and Marine Drive, linking the South and North bays.		Although the town has no ferry services, there are transport links to Hull which runs frequent services to northern Europe.		Scarborough has a wide cultural scene, spread across the town and seafront. It draws people not only from around the country, but from across the world.		Dramatist Alan Ayckbourn has lived in Scarborough for many years. He has produced seventy-five plays in Scarborough and was the artistic director of the famous Stephen Joseph Theatre, where almost all his plays receive their first performance. Chris Monks took over as artistic director in 2009.[32] The town also hosts the annual National Student Drama Festival at the Stephen Joseph Theatre, the Spa Centre and other venues. The Open Air Theatre, seating 6,500, has been recently restored and was officially opened by The Queen on 20 May 2010.[33] The YMCA Theatre is an amateur theatre seating 290. It is very well equipped and hosts some 35 productions a year, including musicals and dance shows.[34]		As of 2014[update], Scarborough has two cinemas, the Hollywood Plaza and the Stephen Joseph Theatre.		A third, the Futurist Theatre, closed in January 2014 when the operator's lease expired.[35]		Scarborough has a long-established museum and visual-arts facilities. Wood End, the former home of The Sitwells, was converted into the Woodend museum,[note 1] a creative centre including workspace for artists and the digital cluster, plus an exhibition space.[36] The Rotunda Museum underwent a multimillion-pound redevelopment to become a national centre for geology.[37] 2006 also saw the formation of a creative industries network called 'Creative Coast' comprising artists, designers, writers and other creatives with the shared vision of a culturally vibrant economy on the North Yorkshire coast.[38]		Scarborough has a considerable graffiti culture, with as many as 20 'writers' currently active. There are two areas where graffiti art is legal in Scarborough, Sainsbury's basketball courts / all-weather pitch and Falsgrave Park wall. Both have seen many collaborations and murals.		The Grade II listed Scarborough Spa complex is home to the Scarborough Spa Orchestra, the last remaining seaside orchestra in the UK. The orchestra gives ten concerts every week during the summer months, playing music from an extensive repertoire of classical and light music with no programme repeats.[citation needed] It became famous during the 1950s and 1960s when concerts from the Palm Court in Scarborough were frequently featured on BBC radio, conducted by Max Jaffa. Former conductors include the composer of the waltz 'Nights of Gladness', Charles Ancliffe.[citation needed]		The globally successful pop / soul singer Robert Palmer spent his teenage years in Scarborough, attending Scarborough Boys' High School.[39]		In November 1987 the town was chosen as the venue for the first-ever Eurovision fan club convention. Members of the then fan club, Europa-UK, gathered in the Palm Court Hotel for the first such event to be held in the UK.[citation needed]		During the late 1980s and the first half of the 1990s, Scarborough band Little Angels were one of the most well-known hard rock bands in the UK. Their third and final studio album, Jam, peaked at #1 on the UK charts in early 1993.[40]		The town is home to the annual Scarborough Jazz Festival which takes place each September at The Spa Complex, and features internationally renowned musicians. Between 2001 and 2008 an eclectic rock and pop festival known as 'Beached' took place on the sands of South Bay. In summer 2005, Scarborough played host to the Sonic Arts Network Expo.[citation needed]		'Acoustic Gathering', a free one-day music festival, has been held annually in Peasholm Park since September 2005. This features over 20 bands and singer/songwriters from all parts of the UK including a number of local groups and musicians, all performing from the bandstand in the centre of the lake.[41] Singer-songwriter Ashley Hicklin grew up in Scarborough and recorded a music video for the song "All The Time in the World" at Scarborough's Spa Complex and in the amusement arcades.[citation needed] The indie band One Night Only also recorded a video in Scarborough for their song "Just for Tonight". It features Scarborough's South Bay and the amusement arcades.[citation needed] The town was the main influence behind Alternative Rock band Everyone An Army's second EP "A Coastal Dance on the Grave of Romance" who were born and raised there.[citation needed]		Seafest is an annual festival which takes place at West Pier and around the harbour area in July/[42] It celebrates the region's fishing history and hosts a large gathering of folk singers, shantymen and musicians, drawing artists from all over the U.K. and from other nations including Senegal, Sicily, Canada, Éire, Luxembourg, Germany, the Netherlands, Brittany and the USA. In addition there are children's entertainments and a 'Sea Fish Cookery' marquee where visiting chefs demonstrate seafood preparation.		Heroes Welcome is a movement which originated in and is administered from Scarborough to encourage communities to demonstrate support to members of the armed forces.[43] In 2008 a hand-drawn poster stating "Heroes Welcome Here" was displayed in a Scarborough seafront restaurant.[44] From this gesture has evolved a national network of towns, cities and counties.[45] Businesses are invited to display a sticker extending a special welcome to service personnel. Member communities are located as far north as the Oykle Valley in the Scottish Highlands to as far south as the Falkland Islands. The Rock of Gibraltar joined in February 2013.[46]		The films Little Voice,[47] Possession, and A Chorus of Disapproval[48] were filmed on location in Scarborough and surrounds. Also filmed in the district were scenes from Miranda, Dancing Queen, Beltenbros, The Brides in the Bath and The Damned United. Television series filmed in the area include Heartbeat, its spin-off series The Royal, CBBC's All At Sea , BBC1's Rosie, and scenes from the second series of Five Days. The 2015 series of The Syndicate starring Anthony Andrews, Melanie Hill and Lenny Henry also filmed scenes in Scarborough.		Scarborough is twinned with:		The town has a small higher education institution, the University of Hull: Scarborough Campus, due to close in summer 2017. In 2015, Coventry University Scarborough Campus opened with a small first cohort and moved from temporary accommodation to a purpose-built site in September 2016. Ultimately, the university will cater for 3000 students studying an innovative, intensive pattern of study. Further Education is provided by Yorkshire Coast College and Scarborough Sixth Form College. The six main state secondary schools in Scarborough are Graham School, George Pindar School, Scalby School, and St Augustine's Catholic School. Raincliffe School formally closed on 31 August 2012, merging with Graham School. In September, 2016, Scarborough University Technical College (UTC) opened for 14-18 year olds. The campus is part of a £47 million pound development including Coventry University Scarborough Campus and a sports village in the Weaponness Valley.[49]		Scarborough is also home to two private schools, Scarborough College (for ages 13 to 18 years) and Bramcote Junior School (ages 4 to 13 years). Bramcote faced closure in 2009[50] despite releasing equity by mortgaging the four acre site.[51] Scarborough College abolished A-levels and has been an International Baccalaureate (IB) World School since June 2006.		Scarborough International School of English,[52] established in 1968 is accredited by the British Council and members of English UK and English UK North. The school offers English Language courses to students from around the world.		There is also a private international language school called Anglolang,[53] established in 1985, which teaches the English language to overseas students, companies, educational institutions, organised groups and individuals.		Education in Scarborough is notable for its commitment to the digital economy with 2006 seeing the formation of the University of Hull's School of Arts and New Media, at the Scarborough Campus. Scarborough is one of the UK mainland's first wireless campuses.[54]		The Scarborough Amateur Rowing Club was founded in May 1869, and is the oldest surviving rowing club on the north-east coast.[56] For more than 100 years, sea rowing has taken place on the Yorkshire coast between the Tees and the Humber. Beginning with friendly rivalry between the fishermen and the jet miners from Blyth (the German Ocean Race), the sport has progressed to what it is today. More recent successes for the club include Bob Hewitt, who now competes as a lightweight rower for the national team. In 2006 the club finally won the acclaimed Wilson Cup, until then held by rival clubs in neighbouring town Whitby for over eighty years. Rowing takes place throughout the summer months.		The Blue Riband event for Scarborough Yacht Club, is the annual 210 nautical mile race, from the town, to IJmuiden in the Netherlands.[57] The Yacht Club is based in the old keepers' accommodation adjoining the lighthouse in the harbour. The lighthouse itself dates from 1806, but it had to be rebuilt following damage sustained in the bombardment of 1914. It is still an active light and is owned and operated by the borough council.[58]		Scarborough is home to the Oliver's Mount racing circuit. This track is composed of twisty public roads and has played host to domestic motorcycling and rallying events for many years. Noted motorcycle racers who have raced at Oliver's Mount include Barry Sheene, Ron Haslam and Guy Martin. The town was the home of the 2nd RAC Rally in 1952.		Scarborough Cricket Club, won the ECB National Club Cricket Championship at Lord's on five occasions between 1972 and 1982, a record number of victories. The club also hosts the annual Scarborough Cricket Festival, and Yorkshire County Cricket Club uses North Marine Road, for a selection of home fixtures throughout the season. The club competes in the Yorkshire ECB County Premier League, in which as the Yorkshire League, the club enjoyed great success.		The former Scarborough Football Club enjoyed a career in the Football League during the 1990s before being relegated to the Conference North in 2006 and to the Northern Premier League the following year. One of its greatest achievements was winning the FA Trophy at Wembley Stadium on three occasions and being runners-up on one. They also held the distinction of being the first club to win automatic promotion to the Football League, when in 1987 they were promoted as champions of the GM Vauxhall Conference. In 2007 a new club, Scarborough Athletic, was formed and is currently playing its home matches in neighbouring Bridlington.		In 2007, the town hosted the World Thundercat Championships (for inflatable powerboats), and similar events in 2008 and 2015. Scarborough Rugby Union Football Club moved to a new £4-million ground development, on the outskirts of town in January 2009 (Silver Royd), the club is very ambitious and reached the semi-finals of the National Intermediate Cup, in 2015. The venue is also home to Scarborough Athletic Club and many sports facilities. The nationally achieving Scarborough Gymnastics Academy, has a highly developed specialist facility in the west of the town. Scarborough Sports Centre was a past venue for international tennis tournaments, attracting such stars as Fred Perry, Rod Laver and Pancho Gonzales. Scarborough Indoor Bowls Centre is utilized for a variety of events, throughout the year.		The town has two principal golf courses, North Cliff and South Cliff, plus some smaller ventures. Ganton Golf Club, which has hosted tournaments such as the Ryder Cup and Walker Cup, is situated approximately 8 miles to the west of Scarborough.		George Pindar School, which is based at Eastfield, is a Sports Community College, and is home to Scarborough Pirates ARLFC, Scarborough Seahawks Basketball and formerly Scarborough Hockey Club, who are now at Scarborough College. The centre also boasts a state-of-the-art Tennis facility. Scarborough Table Tennis Centre is located at Graham School.		A national martial arts organisation, The Empire Martial Arts Association, is based in Scarborough.		The Tourist Information Centre in the South Bay is the finishing point of The White Rose Way, a long distance walk from Leeds.[59]		Scarborough Sea Anglers is an internet forum dedicated to recreational sea fishing, a popular local pastime.		Scarborough was the finishing point, for Stage 1 of the inaugural 2015 Tour de Yorkshire, hosted on 1 May, and subsequently in 2016 and 2017.		A sports village based in Weaponness Valley, will provide the new home stadium of Scarborough Athletic, from 2017.		Scarborough in snow		The South Bay		Spa Bridge (footbridge)		The Grand Hotel		An old seafront police box		The "Belle" at Scarborough Lighthouse 2007		First World War recruitment poster depicting the effects of the German bombardment of Scarborough in 1914		The Spa and the Grand Hotel		Scarborough Marina and Harbour with the Castle in view		Anticlockwise Ravenscar		Scarborough		Clockwise Osgodby		
An artificial reef is a human-made underwater structure, typically built to promote marine life in areas with a generally featureless bottom, to control erosion, block ship passage, or improve surfing.		Many reefs are built using objects that were built for other purposes, for example by sinking oil rigs (through the Rigs-to-Reefs program), scuttling ships, or by deploying rubble or construction debris. Other artificial reefs are purpose built (e.g. the reef balls) from PVC or concrete. Shipwrecks may become artificial reefs when preserved on the sea floor. Regardless of construction method, artificial reefs generally provide hard surfaces where algae and invertebrates such as barnacles, corals, and oysters attach; the accumulation of attached marine life in turn provides intricate structure and food for assemblages of fish.		The construction of artificial reefs is thousands of years old. Ancient Persians blocked the mouth of the Tigris River to thwart Indian pirates by building an artificial reef,[1] and during the First Punic War the Romans built a reef across the mouth of the Carthaginian harbor in Sicily to trap the enemy ships within[2] and assist in driving the Carthaginians from the island.		Artificial reefs to increase fish yields or for algaculture have been used at least since 17th-century Japan, when rubble and rocks were used to grow kelp,[3] while the earliest recorded construction of artificial reef in the United States is from the 1830s when logs from huts were used off the coast of South Carolina to improve fishing.[4]		Since at least the 1830s, US fishermen used interlaced logs to build artificial reefs. More recently, castaway junk, such as old refrigerators, shopping carts, ditched cars, out-of-service vending machines replaced the logs in ad hoc reefs. Officially sanctioned projects have incorporated decommissioned subway cars, vintage battle tanks, armored personnel carriers and oil drilling rigs.[5]		Artificial reefs tend to develop in more or less predictable stages. First, where an ocean current encounters a vertical structure, it can create a plankton-rich upwelling that provides a reliable feeding spot for small fish such as sardines and minnows, which draw in pelagic predators like bluefin tuna and sharks. Next come creatures seeking protection from the ocean's lethal openness—hole and crevice dwellers such as grouper, snapper, squirrelfish, eels, and triggerfish. Opportunistic predators such as jack and barracuda also appear, waiting for their prey to venture out. Over months and years the reef structure becomes encrusted with algae, tunicates, hard and soft corals, and sponges.[5]		Mineral accretion involves applying a low voltage current to a metallic structure to cause limestone to crystallize on the surface, to which coral planulae can attach and grow. The electric current also speeds post-attachment growth.[6]		EMA works like charging a battery with a positive pole, the cathode, and a negative pole, the anode. Applying electric current attracts various dissolved minerals to either the cathode or the anode. Chemical reactions take place at both poles. On the anode, bubbles of oxygen and chlorine gas form. These bubbles float to the surface and dissolve into the air. On the cathode, bubbles of hydrogen gas and a limestone precipitate appear.		The voltage is low enough that it can be generated by floating solar panels or from wave motion.		A coalition of scientists named the Global Coral Reef Alliance (GCRA) is developing a technique called the Biorock Process using mineral accretion for reef restoration, mariculture, and shoreline protection.[6]		Artificial surfing reefs have been created in several locations around the world. Supporters cite subsidiary benefits such as coastal protection, habitat enhancement and coastal research. The world's first attempt was made in El Segundo, near Los Angeles, in California. The next attempt was at Mosman Beach, Perth, Western Australia. This reef was constructed of large granite rocks placed in a pyramidal shape to form an appropriate breaking wave form that would suit surfers. An artificial reef constructed of over 400 massive, geotextile bags (each one larger than a bus) filled with sand was constructed in 2000 at Narrowneck on the Gold Coast of Queensland, Australia. This artificial reef had two objectives: stabilizing beach nourishment and improving surfing conditions.		Europe's first artificial reef was approved in 2008. Construction began August 30, 2008, in Boscombe, Bournemouth, UK (5 months after 3 local councillors spent 18 days in New Zealand on a fact-finding mission on the matter[7]), and opened in November 2009. The £3 million (2.5% of the Council's annual budget that year) reef was expected to create waves up to 30% larger and double the number of surfing days annually. Construction on this reef began in June 2008, and was completed in August 2009.[8] Boscombe Reef was built from large sand-filled geotextile containers, totaling 13,000 cubic metres (460,000 cu ft). It failed entirely and attempts were made to repurpose it as a multi purpose reef which also failed. Bournemouth Council attempted to recover monies from the New Zealand-based reef construction company which shortly went into administration before any compensation was paid.		In the United States demanding coastal permitting requirements present major obstacles to building surfing reefs. The only reef built in the U.S. for surfing is southern California's "Pratte's Reef", which was constructed in 2000 and removed in 2008 as planned.[9]		Artificial surfing reefs typically resemble a "submerged breakwater", and proponents suggest benefits beyond surfing conditions. Many coastlines are subject to powerful waves that crash directly onshore. An artificial reef 150–300 yards (140–270 m) offshore might create surfing opportunities and, by dissipating wave energy, make swimming safer and reduce coastal erosion.		According to The Ocean Conservancy, a Washington, D.C.-based environmental group, the Osbourne reef may be an indication that the benefits of artificial reefs need to be re-examined. Jack Sobel, a senior scientist at the group, has said "There's little evidence that artificial reefs have a net benefit," citing concerns such as toxicity from paint, plastics parts, etc., damage to ecosystems and concentrating fish into one place (worsening overfishing).[10]		Since reefs have been damaged by human caused environmental and ecological changes such as overfishing, people have started creating artificial reefs. Artificial reefs can show quick increases in local fish population rehabilitation, coral reef, and algae growth. Though the quick positive response that artificial reefs tend to show is often interpreted wrongly and the overall impact on the ecosystem is overlooked. Increased fish populations have not been thoroughly examined and it is so far proven that artificial reefs attract far more fish to be caught by fishermen than the amount of biomass that is actually produced by the artificial reef. James Bohnsack, a biologist with the National Marine Fisheries Service (NMFS) concluded artificial reefs don't actually increase fish populations, they simply concentrate fish and make them easier for fishermen to locate and catch. Artificial reefs generally serve merely as FAD’s (Fish Aggregating Devices) bringing in fish from natural reefs, to be caught on the man made landmark. It is proven that artificial reefs attract fish, though it is still uncertain whether or not they make up for the losses, and further research must be done.[11]		The fish attracted and brought in to the artificial reef zones vary from reef to reef, and many times artificial reefs do in fact attract more fish than natural surrounding reefs. The fish that the reef will attract depends largely on the age, size and structure of the artificial reef. Different reefs attract different types of fish and large reef structures like the artificial reefs created by sinking large ships attract larger fish. In addition to attracting certain fish based on the structure of the artificial reef, the structure of the natural existing reef effects the impact of the artificial reef as well.		It was found that the use of shipwrecks to create artificial reefs in rocky zones created a new trophic structure and changed the local reefs ecosystem. The large steel shipwrecks served as the home for certain species of marine life and all the species nearby migrated to the shipwreck. This created an unbalance in the natural ecosystem and altered many different marine lives habitats because of the altered state of the old natural reef. There may be many other artificial reefs worldwide that are negatively impacting the natural reef in the same way.[12]		There are thousands of popular wreck diving sites throughout the world built around shipwrecks sunk as artificial reefs.[13] Some of these artificial wrecks are sunk deliberately to attract divers. Such wrecks as USS Spiegel Grove and USS Oriskany in Florida, USS Indra and USS Aeolus in North Carolina, and Bianca C in Grenada draw thousands of divers annually.[14]		Many ships and other unnaturally composed structures such as old tires are often used for constructing artificial reefs. The materials used in most artificial reefs are also likely to cause pollution by the releasing of excessive amounts of chemicals and nutrients that are not naturally found in reef environments. Retired naval vessels can release Polychlorinated Byphenyls (PCBs), asbestos, iron, lead paint and anti-fouling paint which leaches into the ocean and becomes part of the food-chain.[15] Dumping tires into the ocean is a practice used to create many artificial reefs and a great example of the possibility that there are unseen dangers in creating artificial reefs . With millions of tires produced every year creating artificial reefs with them seemed like a great idea and was practiced around the world. Using trash to try and better the environment seemed like a great idea, but unfortunately, some of the reefs did much more harm than good. In Florida alone, 571 permitted artificial reefs exist and the number of illegal reefs is thought to be much greater. Using old products, such as tires, is taking possible risks and many marine biologists are skeptical about the amount of positive impacts that these reefs will have. Artificial reefs continue to be constructed around the world despite inconclusive studies and the high risks associated with them.[11]		Tires are widely used and need to be disposed of, thus they would make a great artificial reef construction material provided they don’t release pollutants.[11] Tires are made from many chemicals and compounds, all varying. Tires are made differently by each manufacturer and can contain chemicals such as black carbon, sulphur, zinc oxide, and peroxides. Tire rubber formulas still undergo change and there is a huge variety in their material composition. The US National Artificial Reef Plan states that tires are a good reef construction material because there have been no toxic effects released from the decomposition of tires; though there is little information published to back up the claims and the future decomposing of the many different types of rubber tires could create unseen pollution.[16]		The use of tires has fallen out of favor with marine biologists. Tropical storms wash tires onto beaches, destroy nearby coral reefs and inhibit new coral growth.[17] As a result, states such as Florida and the country of France have begun large scale removal of tire reefs.[18][19] One example is the Osborne Reef off the coast of Fort Lauderdale, Florida. Storms broke the nylon straps holding the tire bundles together and boaters were allowed to dump used tires at the site. Since 2007 approximately 130,000 of an estimated 700,000 tires have been removed.[20] At other artificial reef sites hurricanes pushed tires up on beaches from Florida to North Carolina, damaging reefs, causing pollution and requiring costly cleanup.[21] As a result, the Ocean Conservancy now includes tire removal during the International Coastal Cleanup in September of each year.[22]		Some artificial reefs are used to prevent coastal erosion. Artificial reefs that are used to prevent coastal erosion can be designed to act in several ways. Some are designed to force waves to break off shore and deposit their energy in a different area than directly on the coastline and ripping apart beaches and establishments. Other reefs are designed to hold in sediment on beaches. These reefs trap the sediment and prevent the sediment from being dispersed. The reefs are specifically designed for each unique zone to preserve the existing coast from erosion. (Morang et, al 2014) [23]		Florida is the site of many artificial reefs, many created from deliberately sunken ships, including Coast Guard cutters Duane and Bibb and the U.S. Navy landing ship Spiegel Grove.[5]		In the early 1970s, more than 2,000,000 used vehicle tires were dumped off the coast of Fort Lauderdale, Florida to form an artificial reef. However, the tires were not properly secured to the reef structures, and ocean currents broke them loose, sending them crashing into the developing reef and its natural neighbors. As of 2009, fewer than 100,000 of the tires had been removed after more than 10 years of efforts.[24]		Neptune Reef was originally conceived as an art project that would gradually decay. Burial at sea became a way of financing the project. As of 2011, about 200 "placements" had occurred. Cremated remains are mixed with concrete and either encased in columns or molded into sea-star, brain-coral, 15 feet (4.6 m) castings of lions or other shapes before entering the water.[5]		In 1921 the US battleship Massachusetts was scuttled in shallow water off the coast of Pensacola, Florida and then used as a target for experimental artillery. The ship was never scrapped and in 1956 it was declared the property of the state of Florida by the Florida Supreme Court. Since 1993 the wreck has been a Florida Underwater Archaeological Preserve and is included in the National Register of Historic Places. She serves as an artificial reef and diving spot.		The world's largest artificial reef was created by the purposeful sinking of the 44,000 ton aircraft carrier USS Oriskany off the coast of Pensacola, Florida, in 2006.[25]		The second-largest artificial reef is USNS Hoyt S. Vandenberg, a former World War II era troop transport that served as a spacecraft tracking ship after the war. The Vandenberg was scuttled seven miles off Key West on May 27, 2009, in 140 feet (43 m) of clear water.[26] Supporters expect the ship to draw recreational divers away from natural reefs, allowing those reefs to recover from damage from overuse.[27]		The site of ex-Spiegel Grove is located on Dixie Shoal, 6 miles (9.7 km) off the Florida Keys in the Florida Keys National Marine Sanctuary. Her exact location is 25°04′00.23″N 80°18′00.7″W﻿ / ﻿25.0667306°N 80.300194°W﻿ / 25.0667306; -80.300194.		USS Yancey was sunk as an artificial reef off Morehead City, North Carolina, 1990. She is lying on her starboard side at a depth of 160 ft (49 m)		USCGC Spar was scuttled in October 2004 in 108 feet (33 m) of water, 30 miles (48 km) off Morehead City, North Carolina, where she now serves as an artificial reef.[28]		USS Indra was sunk as an artificial reef, 4 August 1992 in 60 feet (18 m) of water. 34°33′55″N 76°58′30″W﻿ / ﻿34.56528°N 76.97500°W﻿ / 34.56528; -76.97500Coordinates: 34°33′55″N 76°58′30″W﻿ / ﻿34.56528°N 76.97500°W﻿ / 34.56528; -76.97500[29]		USS Aeolus was sunk to form an artificial reef in August 1988. The ex-Aeolus, located about 22 miles from Beaufort Inlet in 110 feet (30 m) of water, is regularly visited by divers.		In late 2000, the MTA New York City Transit decided to phase out an outdated fleet of subway cars to make room for new R142 and R142A trains. The obsolete subway cars, (nicknamed "Redbirds"), had run on the IRT lines in the New York City Subway system for 40 years. Each car was stripped, decontaminated, loaded on a barge, and sunk in the Atlantic Ocean off the coast of Delaware. Some cars had number plates removed because of rust, which were then auctioned off on eBay. A total of 1200 subway cars were sunk for this project.		In September 2007, the MTA approved a further contract worth $6 million[citation needed], to send 1600 of its retired subway cars to be used as artificial reefs. Most of these trains had run on the BMT/IND lines. The trains included the R32, R38, R40, and R42. The MTA has replaced them with the R160A and R160B trains. The old models were sheathed in stainless steel, except for the plastic front ends, which were removed before sinking. The retired fleet included old work trains and cars damaged beyond repair.		Since November 2009, artist Jason deCaires Taylor has created more than 400 life size sculptures off the coast of Cancun, Mexico. The coral reefs in this region suffered heavy degradation due to repetitive hurricane abuse. This project funded by The National Marine Park and the Cancun Nautical Association was designed to emulate coral reefs using a neutral ph clay. Taylor has constructed unique settings depicting daily activities ranging from a man watching TV to a 1970s replica of a Volkswagen Beetle. This artificial reef has relieved pressure from the nearby Manchones Reef. The design and materials implemented in this project have proved the ecological viability of artificial reefs.[30]		Since the late 1990s, the Australian government has been providing decommissioned warships for use as artificial reefs for recreational scuba diving. So far, the following six ships have been sunk:		The Gibraltar Reef was first proposed by Dr. Eric Shaw in 1973. Initial experiments with tires proved unsuccessful as the tires were simply swept away by currents or buried underneath sand. In 1974, boats from local marinas and the Gibraltar Port Authority were donated. The first two were barges that were sunk in Camp Bay. In 2006, a 65-ton wooden boat, True Joy (also referred to as Noah's Ark) was sunk here as well, followed by MV New Flame, a mid-sized bulk carrier, in 2007.		In 2013, a dropping of more than 70 concrete blocks, each one square meter with metal bars, took place. This led to heated debate between the United Kingdom and Spain, with Gibraltar accusing Spain of over forty incursions into their waters per month[36] and Spain accusing Gibraltar of including metal bars in the reef to stop Spanish fishermen trawling the seabed for fish. The dropping led to a diplomatic conflict between the Kingdom of Spain and the United Kingdom due to Gibraltar being a British Overseas Territory.		It is an artificial reef off the coast of Pondicherry, India constructed of fully recycled materials such as concrete, rocks, trees, palms, and iron bars. It is located at the depth of 18 metres (59 ft). It is also there in Kovalam, Kerala. It is built there to promote surfing.		Pearl of Dubai is an art inspired Lost City variant artificial reef off the coast of Dubai. The site encompasses five acres in total and is located at the World Islands. Located at a depth of 10 to 20 metres (33 to 66 ft), the site is designed as an ancient lost city, complete with temples and statues using regional design cues from 800 BC.[37]		The Underwater Chocolate Hills is an artificial reef project being undertaken by Spindrift Reefs Dive Center[38] off the coast of Panglao Island in the Philippines. They are using broken coral harvested by local divers, who are in turn attaching it to wire structures underwater. The structures are unique in that they are built in the same shape as the Chocolate Hills which can be found in the Bohol Region. This is being done to build a new dive site and new marine habitat for the area.		
The bathing machine was a device, popular in the 18th and 19th centuries, to allow people to change out of their usual clothes, change into swimwear, and wade in the ocean at beaches. Bathing machines were roofed and walled wooden carts rolled into the sea. Some had solid wooden walls while others had canvas walls over a wooden frame.		The bathing machine was part of etiquette for sea-bathing more rigorously enforced upon women than men but to be observed by both sexes among those who wished to be proper.[1]		Especially in Britain, men and women were usually segregated, so nobody of the opposite sex might catch sight of them in their bathing suits, which (although extremely modest by modern standards) were not considered proper clothing in which to be seen.						The bathing machines in use in Margate, Kent, were described in 1805 as		four-wheeled carriages, covered with canvas, and having at one end of them an umbrella of the same materials which is let down to the surface of the water, so that the bather descending from the machine by a few steps is concealed from the public view, whereby the most refined female is enabled to enjoy the advantages of the sea with the strictest delicacy.		People entered the small room of the machine while it was on the beach, wearing their street clothing. In the machine they changed into their bathing suit, although men were allowed to bathe nude until the 1860s,[3] placing their street clothes into a raised compartment where they would remain dry.[4]		Probably all bathing machines had small windows,[3] but one writer in the Manchester Guardian of May 26, 1906 considered them "ill-lighted" and wondered why bathing machines were not improved with a skylight.[5] The machine would then be wheeled or slid into the water. The most common machines had large wide wheels and were propelled in and out of the surf by a horse or a pair of horses with a driver. Less common were machines pushed in and out of the water by human power. Some resorts had wooden rails into the water for the wheels to roll on; a few had bathing machines pulled in and out by cables propelled by a steam engine.		Once in the water, the occupants disembarked from the sea side down steps into the water. Many machines had doors front and back; those with only one door would be backed into the sea or need to be turned around. It was considered essential that the machine blocked any view of the bather from the shore. Some machines were equipped with a canvas tent lowered from the seaside door, sometimes capable of being lowered to the water, giving the bather greater privacy. Some resorts employed a dipper, a strong person of the same sex who would assist the bather in and out of the sea. Some dippers were said to push bathers into the water, then yank them out, considered part of the experience.[6]		Bathing machines would often be equipped with a small flag which could be raised by the bather as a signal to the driver that they were ready to return to shore.		According to some sources, the bathing machine was developed in 1750 in Margate, Kent, though this may relate primarily to the "modesty hood" (bathing costumes were not yet common and most people bathed naked). "Mr. Benjamin Beale, a Quaker, was the inventor of the Bath Machine. Their structure is simple, but quite convenient; and by means of the umbrella, the pleasures of bathing may be enjoyed in so private a manner, as to be consistent with the strictest delicacy."[7] In Scarborough Public Library there is an engraving by John Setterington dated 1736 which shows people bathing and popularly believed to be first evidence for bathing machines, however Devon claims this was a year earlier in 1735.[8]		Bathing machines were most common in the United Kingdom and parts of the British Empire with a British population, but were also used in France, Germany, the United States, Mexico, and other nations. Legal segregation of bathing areas in Britain ended in 1901, and the bathing machine declined rapidly. By the start of the 1920s, bathing machines were almost extinct, even on beaches catering to an older clientele.[9]		The bathing machines remained in active use on English beaches until the 1890s, when they began to be parked on the beach. They were then used as stationary changing rooms for a number of years. Most of them had disappeared in the United Kingdom by 1914.[10] However, they have survived to this day as bathing boxes in many parts around the world.		
Quartz is a mineral composed of silicon and oxygen atoms in a continuous framework of SiO4 silicon–oxygen tetrahedra, with each oxygen being shared between two tetrahedra, giving an overall chemical formula of SiO2. Quartz is the second most abundant mineral in Earth's continental crust, behind feldspar.[7]		Quartz crystals are chiral, and exist in two forms, the normal α-quartz and the high-temperature β-quartz. The transformation from α-quartz to beta-quartz takes place abruptly at 573 °C (846 K). Since the transformation is accompanied by a significant change in volume, it can easily induce fracturing of ceramics or rocks passing through this temperature limit.		There are many different varieties of quartz, several of which are semi-precious gemstones. Since antiquity, varieties of quartz have been the most commonly used minerals in the making of jewelry and hardstone carvings, especially in Eurasia.						The word "quartz" is derived from the German word "Quarz" and its Middle High German ancestor "twarc", which probably originated in Slavic, cf. Czech tvrdý ("hard"), Polish twardy ("hard"), Serbian and Croatian tvrd ("hard").[8]		The Ancient Greeks referred to quartz as κρύσταλλος (krustallos) derived from the Ancient Greek κρύος (kruos) meaning "icy cold", because some philosophers (including Theophrastus) apparently believed the mineral to be a form of supercooled ice.[9] Today, the term rock crystal is sometimes used as an alternative name for the purest form of quartz.		Quartz belongs to the trigonal crystal system. The ideal crystal shape is a six-sided prism terminating with six-sided pyramids at each end. In nature quartz crystals are often twinned (with twin right-handed and left-handed quartz crystals), distorted, or so intergrown with adjacent crystals of quartz or other minerals as to only show part of this shape, or to lack obvious crystal faces altogether and appear massive. Well-formed crystals typically form in a 'bed' that has unconstrained growth into a void; usually the crystals are attached at the other end to a matrix and only one termination pyramid is present. However, doubly terminated crystals do occur where they develop freely without attachment, for instance within gypsum. A quartz geode is such a situation where the void is approximately spherical in shape, lined with a bed of crystals pointing inward.		α-quartz crystallizes in the trigonal crystal system, space group P3121 or P3221 depending on the chirality. β-quartz belongs to the hexagonal system, space group P6222 and P6422, respectively.[10] These space groups are truly chiral (they each belong to the 11 enantiomorphous pairs). Both α-quartz and β-quartz are examples of chiral crystal structures composed of achiral building blocks (SiO4 tetrahedra in the present case). The transformation between α- and β-quartz only involves a comparatively minor rotation of the tetrahedra with respect to one another, without change in the way they are linked.		Crystal structure of α-quartz (red balls are oxygen, grey are silicon)		β-quartz		Although many of the varietal names historically arose from the color of the mineral, current scientific naming schemes refer primarily to the microstructure of the mineral. Color is a secondary identifier for the cryptocrystalline minerals, although it is a primary identifier for the macrocrystalline varieties.		Pure quartz, traditionally called rock crystal or clear quartz, is colorless and transparent or translucent, and has often been used for hardstone carvings, such as the Lothair Crystal. Common colored varieties include citrine, rose quartz, amethyst, smoky quartz, milky quartz, and others.		The most important distinction between types of quartz is that of macrocrystalline (individual crystals visible to the unaided eye) and the microcrystalline or cryptocrystalline varieties (aggregates of crystals visible only under high magnification). The cryptocrystalline varieties are either translucent or mostly opaque, while the transparent varieties tend to be macrocrystalline. Chalcedony is a cryptocrystalline form of silica consisting of fine intergrowths of both quartz, and its monoclinic polymorph moganite.[11] Other opaque gemstone varieties of quartz, or mixed rocks including quartz, often including contrasting bands or patterns of color, are agate, carnelian or sard, onyx, heliotrope, and jasper.		Amethyst is a form of quartz that ranges from a bright to dark or dull purple color. The world's largest deposits of amethysts can be found in Brazil, Mexico, Uruguay, Russia, France, Namibia and Morocco. Sometimes amethyst and citrine are found growing in the same crystal. It is then referred to as ametrine. An amethyst is formed when there is iron in the area where it was formed.		Blue quartz contains inclusions of fibrous magnesio-riebeckite or crocidolite.[12]		Inclusions of the mineral dumortierite within quartz pieces often result in silky-appearing splotches with a blue hue, shades giving off purple and/or grey colors additionally being found. "Dumortierite quartz" (sometimes called "blue quartz") will sometimes feature contrasting light and dark color zones across the material.[13][14] Interest in the certain quality forms of blue quartz as a collectible gemstone particularly arises in India and in the United States.[13]		Citrine is a variety of quartz whose color ranges from a pale yellow to brown due to ferric impurities. Natural citrines are rare; most commercial citrines are heat-treated amethysts or smoky quartzes. However, a heat-treated amethyst will have small lines in the crystal, as opposed to a natural citrine's cloudy or smokey appearance. It is nearly impossible to differentiate between cut citrine and yellow topaz visually, but they differ in hardness. Brazil is the leading producer of citrine, with much of its production coming from the state of Rio Grande do Sul. The name is derived from the Latin word citrina which means "yellow" and is also the origin of the word "citron". Sometimes citrine and amethyst can be found together in the same crystal, which is then referred to as ametrine.[15] Citrine has been referred to as the "merchant's stone" or "money stone", due to a superstition that it would bring prosperity.[16]		Milk quartz or milky quartz is the most common variety of crystalline quartz. The white color is caused by minute fluid inclusions of gas, liquid, or both, trapped during crystal formation,[17] making it of little value for optical and quality gemstone applications.[18]		Rose quartz is a type of quartz which exhibits a pale pink to rose red hue. The color is usually considered as due to trace amounts of titanium, iron, or manganese, in the massive material. Some rose quartz contains microscopic rutile needles which produces an asterism in transmitted light. Recent X-ray diffraction studies suggest that the color is due to thin microscopic fibers of possibly dumortierite within the massive quartz.[19]		Additionally, there is a rare type of pink quartz (also frequently called crystalline rose quartz) with color that is thought to be caused by trace amounts of phosphate or aluminium. The color in crystals is apparently photosensitive and subject to fading. The first crystals were found in a pegmatite found near Rumford, Maine, USA and in Minas Gerais, Brazil.[20]		Smoky quartz is a gray, translucent version of quartz. It ranges in clarity from almost complete transparency to a brownish-gray crystal that is almost opaque. Some can also be black.		Prasiolite, also known as vermarine, is a variety of quartz that is green in color. Since 1950, almost all natural prasiolite has come from a small Brazilian mine, but it is also seen in Lower Silesia in Poland. Naturally occurring prasiolite is also found in the Thunder Bay area of Canada. It is a rare mineral in nature; most green quartz is heat-treated amethyst.[21]		Herkimer Diamond		Rock crystal		Ametrine		Amethyst		Blue quartz		Chalcedony		Citrine		Rose quartz		Prasiolite		Rutilated quartz		Sceptred quartz		Smoky quartz		Not all varieties of quartz are naturally occurring. Some clear quartz crystals can be treated using heat or gamma-irradiation to induce color where it would not otherwise have occurred naturally. Susceptibility to such treatments depends on the location from which the quartz was mined.[22]		Prasiolite, an olive colored material, is produced by heat treatment; natural prasiolite has also been observed in Lower Silesia in Poland. Although citrine occurs naturally, the majority is the result of heat-treated amethyst. Carnelian is widely heat-treated to deepen its color.		Because natural quartz is often twinned, synthetic quartz is produced for use in industry. Large, flawless, single crystals are synthesized in an autoclave via the hydrothermal process; emeralds are also synthesized in this fashion.		Like other crystals, quartz may be coated with metal vapors to give it an attractive sheen.		Quartz is a defining constituent of granite and other felsic igneous rocks. It is very common in sedimentary rocks such as sandstone and shale. It is a common constituent of schist, gneiss, quartzite and other metamorphic rocks. Quartz has the lowest potential for weathering in the Goldich dissolution series and consequently it is very common as a residual mineral in stream sediments and residual soils.		While the majority of quartz crystallizes from molten magma, much quartz also chemically precipitates from hot hydrothermal veins as gangue, sometimes with ore minerals like gold, silver and copper. Large crystals of quartz are found in magmatic pegmatites. Well-formed crystals may reach several meters in length and weigh hundreds of kilograms.		Naturally occurring quartz crystals of extremely high purity, necessary for the crucibles and other equipment used for growing silicon wafers in the semiconductor industry, are expensive and rare. A major mining location for high purity quartz is the Spruce Pine Gem Mine in Spruce Pine, North Carolina, United States.[23]		The largest documented single crystal of quartz was found near Itapore, Goiaz, Brazil; it measured approximately 6.1×1.5×1.5 m and weighed more than 44 tonnes.[24]		Tridymite and cristobalite are high-temperature polymorphs of SiO2 that occur in high-silica volcanic rocks. Coesite is a denser polymorph of SiO2 found in some meteorite impact sites and in metamorphic rocks formed at pressures greater than those typical of the Earth's crust. Stishovite is a yet denser and higher-pressure polymorph of SiO2 found in some meteorite impact sites. Lechatelierite is an amorphous silica glass SiO2 which is formed by lightning strikes in quartz sand.		The word "quartz" comes from the German  Quarz (help·info),[25] which is of Slavic origin (Czech miners called it křemen). Other sources attribute the word's origin to the Saxon word Querkluftertz, meaning cross-vein ore.[26]		Quartz is the most common material identified as the mystical substance maban in Australian Aboriginal mythology. It is found regularly in passage tomb cemeteries in Europe in a burial context, such as Newgrange or Carrowmore in Ireland. The Irish word for quartz is grianchloch, which means 'sunstone'. Quartz was also used in Prehistoric Ireland, as well as many other countries, for stone tools; both vein quartz and rock crystal were knapped as part of the lithic technology of the prehistoric peoples.[27]		While jade has been since earliest times the most prized semi-precious stone for carving in East Asia and Pre-Columbian America, in Europe and the Middle East the different varieties of quartz were the most commonly used for the various types of jewelry and hardstone carving, including engraved gems and cameo gems, rock crystal vases, and extravagant vessels. The tradition continued to produce objects that were very highly valued until the mid-19th century, when it largely fell from fashion except in jewelry. Cameo technique exploits the bands of color in onyx and other varieties.		Roman naturalist Pliny the Elder believed quartz to be water ice, permanently frozen after great lengths of time.[29] (The word "crystal" comes from the Greek word κρύσταλλος, "ice".) He supported this idea by saying that quartz is found near glaciers in the Alps, but not on volcanic mountains, and that large quartz crystals were fashioned into spheres to cool the hands. This idea persisted until at least the 17th century. He also knew of the ability of quartz to split light into a spectrum.		In the 17th century, Nicolas Steno's study of quartz paved the way for modern crystallography. He discovered that regardless of a quartz crystal's size or shape, its long prism faces always joined at a perfect 60° angle.[30]		Quartz's piezoelectric properties were discovered by Jacques and Pierre Curie in 1880.[31][32] The quartz oscillator or resonator was first developed by Walter Guyton Cady in 1921.[33][34] George Washington Pierce designed and patented quartz crystal oscillators in 1923.[35][36][37] Warren Marrison created the first quartz oscillator clock based on the work of Cady and Pierce in 1927.[38]		Efforts to synthesize quartz began in the mid nineteenth century as scientists attempted to create minerals under laboratory conditions that mimicked the conditions in which the minerals formed in nature: German geologist Karl Emil von Schafhäutl (1803–1890)[39] was the first person to synthesize quartz when in 1845 he created microscopic quartz crystals in a pressure cooker.[40] However, the quality and size of the crystals that were produced by these early efforts were poor.[41]		By the 1930s, the electronics industry had become dependent on quartz crystals. The only source of suitable crystals was Brazil; however, World War II disrupted the supplies from Brazil, so nations attempted to synthesize quartz on a commercial scale. German mineralogist Richard Nacken (1884–1971) achieved some success during the 1930s and 1940s.[42] After the war, many laboratories attempted to grow large quartz crystals. In the United States, the U.S. Army Signal Corps contracted with Bell Laboratories and with the Brush Development Company of Cleveland, Ohio to synthesize crystals following Nacken's lead.[43][44] (Prior to World War II, Brush Development produced piezoelectric crystals for record players.) By 1948, Brush Development had grown crystals that were 1.5 inches (3.8 cm) in diameter, the largest to date.[45][46] By the 1950s, hydrothermal synthesis techniques were producing synthetic quartz crystals on an industrial scale, and today virtually all the quartz crystal used in the modern electronics industry is synthetic.		Some types of quartz crystals have piezoelectric properties; they develop an electric potential upon the application of mechanical stress.[47] An early use of this property of quartz crystals was in phonograph pickups. One of the most common piezoelectric uses of quartz today is as a crystal oscillator. The quartz clock is a familiar device using the mineral. The resonant frequency of a quartz crystal oscillator is changed by mechanically loading it, and this principle is used for very accurate measurements of very small mass changes in the quartz crystal microbalance and in thin-film thickness monitors.		
An atoll ( /ˈætɒl/, /ˈætɔːl/, /ˈætoʊl/, /əˈtɒl/, /əˈtɔːl/ or /əˈtoʊl/),[1][2] sometimes called a coral atoll, is a ring-shaped coral reef including a coral rim that encircles a lagoon partially or completely. There may be coral islands/cays on the rim.[3](p60)[4] The coral of the atoll often sits atop the rim of an extinct seamount or volcano which has eroded or subsided partially beneath the water. The lagoon forms over the volcanic crater or caldera while the higher rim remains above water or at shallow depths that permit the coral to grow and form the reefs. For the atoll to persist, continued erosion or subsidence must be at a rate slow enough to permit reef growth upwards and outwards to replace the lost height.[5]						The word atoll comes from the Dhivehi (an Indo-Aryan language spoken on the Maldive Islands) word atholhu (Dhivehi: އަތޮޅު, [ˈət̪ɔɭu]), meaning an administrative subdivision.OED Its first recorded use in English was in 1625 as atollon – Charles Darwin recognized its indigenous origin and coined, in his The Structure and Distribution of Coral Reefs, the definition of atolls as "circular groups of coral islets" that is synonymous with "lagoon-island".[6](p2)		More modern definitions of atoll describe them as "annular reefs enclosing a lagoon in which there are no promontories other than reefs and islets composed of reef detritus"[7] or "in an exclusively morphological sense, [as] a ring-shaped ribbon reef enclosing a lagoon".[8]		The distribution of atolls around the globe is instructive: most of the world's atolls are in the Pacific Ocean (with concentrations in the Tuamotu Islands, Caroline Islands, Marshall Islands, Coral Sea Islands, and the island groups of Kiribati, Tuvalu and Tokelau) and Indian Ocean (the Atolls of the Maldives, the Lakshadweep Islands, the Chagos Archipelago and the Outer Islands of the Seychelles). The Atlantic Ocean has no large groups of atolls, other than eight atolls east of Nicaragua that belong to the Colombian department of San Andres and Providencia in the Caribbean.		Reef-building corals will thrive only in warm tropical and subtropical waters of oceans and seas, and therefore atolls are only found in the tropics and subtropics. The northernmost atoll of the world is Kure Atoll at 28°24′ N, along with other atolls of the Northwestern Hawaiian Islands. The southernmost atolls of the world are Elizabeth Reef at 29°58′ S, and nearby Middleton Reef at 29°29′ S, in the Tasman Sea, both of which are part of the Coral Sea Islands Territory. The next southerly atoll is Ducie Island in the Pitcairn Islands Group, at 24°40′ S. Bermuda is sometimes claimed as the "northernmost atoll" at a latitude of 32°24′ N. At this latitude coral reefs would not develop without the warming waters of the Gulf Stream. However, Bermuda is termed a pseudo-atoll because its general form, while resembling that of an atoll, has a very different mode of formation. While there is no atoll directly on the equator, the closest atoll to the Equator is Aranuka of Kiribati, with its southern tip just 12 km north of the equator.		In most cases, the land area of an atoll is very small in comparison to the total area. Atoll islands are low lying, with their elevations less than 5 meters (9). Measured by total area, Lifou (1146 km²) is the largest raised coral atoll of the world, followed by Rennell Island (660 km²).[12] More sources however list as the largest atoll in the world in terms of land area Kiritimati, which is also a raised coral atoll (321.37 km² land area; according to other sources even 575 km²), 160 km² main lagoon, 168 km² other lagoons (according to other sources 319 km² total lagoon size). The remains of an ancient atoll as a hill in a limestone area is called a reef knoll. The second largest atoll by dry land area is Aldabra with 155 km². The largest atoll in terms of island numbers is Huvadhu Atoll in the south of the Maldives with 255 islands.		In 1842, Charles Darwin explained the creation of coral atolls in the southern Pacific Ocean based upon observations made during a five-year voyage aboard the HMS Beagle from 1831 to 1836. Accepted as basically correct, his explanation involved considering that several tropical island types—from high volcanic island, through barrier reef island, to atoll—represented a sequence of gradual subsidence of what started as an oceanic volcano. He reasoned that a fringing coral reef surrounding a volcanic island in the tropical sea will grow upwards as the island subsides (sinks), becoming an "almost atoll", or barrier reef island, as typified by an island such as Aitutaki in the Cook Islands, Bora Bora and others in the Society Islands. The fringing reef becomes a barrier reef for the reason that the outer part of the reef maintains itself near sea level through biotic growth, while the inner part of the reef falls behind, becoming a lagoon because conditions are less favorable for the coral and calcareous algae responsible for most reef growth. In time, subsidence carries the old volcano below the ocean surface and the barrier reef remains. At this point, the island has become an atoll.		Atolls are the product of the growth of tropical marine organisms, and so these islands are only found in warm tropical waters. Volcanic islands located beyond the warm water temperature requirements of hermatypic (reef-building) organisms become seamounts as they subside and are eroded away at the surface. An island that is located where the ocean water temperatures are just sufficiently warm for upward reef growth to keep pace with the rate of subsidence is said to be at the Darwin Point. Islands in colder, more polar regions evolve towards seamounts or guyots; warmer, more equatorial islands evolve towards atolls, for example Kure Atoll.		Darwin's theory starts with a volcanic island which becomes extinct		As the island and ocean floor subside, coral growth builds a fringing reef, often including a shallow lagoon between the land and the main reef		As the subsidence continues the fringing reef becomes a larger barrier reef farther from the shore with a bigger and deeper lagoon inside		Ultimately the island sinks below the sea, and the barrier reef becomes an atoll enclosing an open lagoon		Reginald Aldworth Daly offered a somewhat different explanation for atoll formation: islands worn away by erosion, by ocean waves and streams, during the last glacial stand of the sea of some 900 feet (270 m) below present sea level developed as coral islands (atolls), or barrier reefs on a platform surrounding a volcanic island not completely worn away, as sea level gradually rose from melting of the glaciers. Discovery of the great depth of the volcanic remnant beneath many atolls such as at Midway Atoll favors the Darwin explanation, although there can be little doubt that fluctuating sea level has had considerable influence on atolls and other reefs.		Coral atolls are also an important place where dolomitization of calcite occurs. At certain depths water is undersaturated in calcium carbonate but saturated in dolomite. Convection created by tides and sea currents enhance this change. Hydrothermal currents created by volcanoes under the atoll may also play an important role.		In 1896, 1897 and 1898, the Royal Society of London carried out drilling on Funafuti atoll in Tuvalu for the purpose of investigating the formation of coral reefs to determine whether traces of shallow water organisms could be found at depth in the coral of Pacific atolls. This investigation followed the work on the structure and distribution of coral reefs conducted by Charles Darwin in the Pacific.		The first expedition in 1896 was led by Professor William Johnson Sollas of the University of Oxford. The geologists included Walter George Woolnough and Edgeworth David of the University of Sydney. Professor Edgeworth David led the expedition in 1897.[13] The third expedition in 1898 was led by Alfred Edmund Finckh.[14][15][16]		On January 6, 2009, U.S. President George W. Bush announced that the creation of the Pacific Remote Islands Marine National Monument, covering several islands and atolls under U.S. jurisdiction.[17][18](Number 1, page 14)		
A cobble (sometimes a cobblestone) is a clast of rock defined on the Udden–Wentworth scale as having a particle size of 64–256 millimeters (2.5–10.1 in), larger than a pebble and smaller than a boulder. Other scales define a cobble's size in slightly different terms. A rock made predominantly of cobbles is termed a conglomerate. Cobblestone is a building material based on cobbles.						Cobbles, also called cobblestones, derive their name from the word cob, meaning a rounded lump. The term is further related to the German Kopf, meaning head.[1] Chester Wentworth referred to cobbles as cobble bowlders [sic] in his 1922 paper that would become the basis for the Udden–Wentworth scale.[2]		Within the widely used Krumbein phi scale of grain sizes, cobbles are defined as clasts of rock ranging from −6 to −8 φ. This classification corresponds with the Udden–Wentworth size scale which defines cobbles as clasts with diameters from 64–256 millimeters (2.5–10.1 in). On this scale, cobbles are larger than pebbles which measure 4–64 millimeters (0.16–2.52 in) in diameter and smaller than boulders, whose diameters range from 256–4,096 millimeters (10.1–161.3 in). On the Udden–Wentworth scale, an unlithified fraction of cobbles is classified as gravel while a lithified sample primarily composed of cobbles is a conglomerate.[2] The Committee on Sedimentation of the US National Research Council has recommended that in situ cobbles be identified by their process of origination, if possible (e.g. cobbles by disintegration, by exfoliation, etc.).[3]		In the late 1800s and early to mid-1900s, prior to the Udden–Wentworth scale's widespread adoption, size classifications tended to group all particles larger than 2 millimeters (0.079 in) together as gravel or stones. Other scales have defined the size of a cobble slightly differently than the Udden–Wentworth; the British Standards Institution denotes a cobble as any clast ranging in diameter from 60–200 millimeters (2.4–7.9 in) while the United States Department of Agriculture's definition suggests a range of 75–250 millimeters (3.0–9.8 in) and the ISO standard 14688 names cobbles as ranging from 63–200 millimeters (2.5–7.9 in) in diameter.[4]		Various attempts have been made to refine the Udden–Wentworth scale, including its definition of cobbles.[4] In 1968, D. J. Doeglas proposed subdividing the cobble designation into two fractions, small cobbles (for particles with diameters from 64–125 millimeters [2.5–4.9 in]) and large cobbles (for particles with diameters from 125–250 millimeters [4.9–9.8 in]).[5] A 1999 paper by Terence C. Blair and John G. McPherson argued that the Udden–Wentworth and Krumbein scales betrayed a historical emphasis on the study of sand grains while ignoring larger gravel grains. They proposed defining fine cobbles as those with diameters from 64–128 millimeters (2.5–5.0 in) (−6 to −7 φ) and coarse cobbles as those with diameters from 128–256 millimeters (5.0–10.1 in) (−7 to −8 φ).[2] In 2012, Simon J. Blott and Kenneth Pye suggested that the cobble designation be eliminated altogether, replaced by very small boulder and small boulder designations equivalent in size to Blair and McPherson's fine and coarse cobbles, respectively.[4]		When occurring in streams, cobbles are likely to be found in mountain valley streambeds that are moderately steep.[6] Cobbles are also transported by glaciers and deposited as with other grades of sediment as till. If the till is water-laid, finer particles like sand and pebbles may be entirely washed away, leaving a deposit of only boulders and cobbles. Glacially transported cobbles tend to share several identifying features including a tabular shape and downward diagonal striations on lateral facets.[7]		Cobble conglomerates may be alluvial in origin or the product of "stone avalanches", a type of debris flow resulting from unconsolidated cobbles and gravel.[8] In such stone avalanches, well-rounded cobbles may travel the farthest on account of their low rolling friction.[9] When the product of alluvial processes, the cobble conglomerate's matrix consists of gravel and coarse sand. In contrast, the matrices of flow-deposited conglomerates are primarily mud.[8]		
Pocket beach is usually a small beach, between two headlands. In an idealized setting, there is very little or no exchange of sediment between the pocket beach and the adjacent shorelines.		Pocket beaches can be natural or artificial. Many natural pocket beaches exist throughout the world. Artificial pocket beaches are usually constructed in areas where natural beaches are fairly narrow or absent. Examples of artificial pocket beaches include over 100 such systems on Chesapeake Bay in the United States, each consisting of several individual pocket beaches; the Fisher Key, Florida project constructed on a dredge spoil island originally consisting of cobble dredge material;, and the Fred Howard Park Beach that was constructed offshore of a muddy mangrove shoreline. Additionally, there have been many pocket beaches constructed in the Caribbean where resorts have been developed along rocky shorelines with minimal natural beaches.				
François Blanc (12 December 1806 – 27 July 1877), nicknamed "The Magician of Homburg" and "The Magician of Monte Carlo", was a French entrepreneur and operator of casinos, including the Monte Carlo Casino in Monaco.		His daughter, Marie-Félix, married Roland Bonaparte and had issue.		François was born on December 12, 1806 with his twin brother Louis. They grew up in a small town and were impressed every time circus came with a show - it seemed so interesting and simple so they followed the circus to learn all the tricks of the trade, boys were dreaming to become rich and successful and learnt so much and worked on different jobs. Finally, they started to work in gambling business in Marseilles and earning some money brothers decided to develop their business and started to speculate on government pensions and got into real estate development. In that way they attracted attention to their business and were arrested, but not for a long time because law was not adopted yet for such cases. They were released and moved to Paris, but after King Louis Philippe passed new laws they had to move again - to Luxembourgh. They run profitable business there but It was just the first little step to their success in Hesse-Homburg near Frankfurt, where brothers signed a contract with a monarch because of debts of the city and in order to develop tourism industry.		One innovation was the introduction of the single 0 style roulette wheel in 1843. This allowed Bad Homburg to compete against the casinos of Paris which offered the traditional wheel with both single and double zero house pockets. A legend says that François Blanc supposedly bargained with the devil to obtain the secrets of roulette. The legend is based on the fact that the sum of all the numbers on the roulette wheel (from 0 to 36) is 666, which is the "Number of the Beast".[1]		The venture was a great success, Homburg became popular in a moment with a lot of entertainment, gambling houses, hotels - all the richest and famous came there for new emotions and fun. In a while François Blanc was given the name "The Magician of Homburg".		Homburg could attract people only in summer months, during cold winter all the tourists preferred to rest in warmer places. Also In the 1860s, the government of Frankfurt decided to abolish gambling as they felt that their region no longer needed its help in attracting tourists. It gave an idea to François to move to South and open all-year business.		It happened that the Prince of Monaco had recently legalized gambling, so "The Magician of Homburg" became that first person to establish a casino operation in Monaco. To establish Monaco as a gambling mecca for the elite of Europe, he invested his money in roads, railways to make people come to Monaco as a new place of rest and fortune. His new King gave François a freedom, so he turned from "The Magician of Homburg" to "The Magician of Monte Carlo" and he left his mark in a history of Monaco.				
Waikīkī (/waɪkiːˈkiː/; Hawaiian: [vɐjˈtiːˈtiː, wɐjˈtiːˈtiː]) (also known as Waikiki Beach) is a beachfront neighborhood of Honolulu, on the south shore of the island of Oʻahu, in Hawaii, United States. Waikiki is most famous for Waikīkī Beach, but it is just one of six beaches in the district, the others being Queen's Beach, Kuhio Beach, Gray's Beach, Fort DeRussy Beach and Kahanamoku Beach.		Waikīkī is home to public places including Kapiʻolani Park, Fort DeRussy, Kahanamoku Lagoon, Kūhiō Beach Park, and Ala Wai Harbor.						The name Waikīkī means spouting fresh water in the Hawaiian language, for springs and streams that fed wetlands that once separated Waikīkī from the interior.[1]		The area was a retreat for Hawaiian royalty in the 1800s who enjoyed surfing there on early forms of longboards.[2]		A few small hotels opened in the 1880s. In 1893, Greek-American George Lycurgus leased the guest house of Allen Herbert and renamed it the "Sans Souci" (French for "without worries") creating one of the first beach resorts. Later that year Robert Louis Stevenson stayed at the resort; subsequently it became a popular destination for tourists from the mainland.[3] The area at coordinates 21°15′49″N 157°49′17″W﻿ / ﻿21.26361°N 157.82139°W﻿ / 21.26361; -157.82139 is still called "Sans Souci Beach".[4]		Today, the area is filled with large resort hotels, such as the Hilton Hawaiian Village, Halekulani, the Hyatt Regency Waikīkī, Marriott Waikiki, Sheraton Waikīkī, and historic hotels dating back to the early 20th century (such as the Moana Surfrider Hotel and the Royal Hawaiian Hotel). The beach hosts many events a year, including surf competitions, outdoor performances, hula dancing and outrigger canoe races.		The neighborhood extends from the Ala Wai Canal (a channel dug to drain former wetlands) on the west and north, to Diamond Head (Lēʻahi) on the east. Waikīkī Beach is noted for its views of the Diamond Head tuff cone, its usually warm and cloud-free climate and its surf break.[5][6][7]		The Waikīkī skyline is now dotted with an abundance of both high-rises and resort hotels. The beach is actually fairly short, with half of it marked off for surfers. For some distance into the ocean the water is quite shallow, although there are numerous rocks on the bottom. As with most ocean beaches the waves can have some force, particularly on windy days. The surf at Waikīkī is known for its long rolling break, making it ideal for long boarding, tandem surfing and beginners.[8][9]		Waikīkī's main thoroughfare is Kalakaua Avenue, named after King Kalakaua, which houses most of the high-end hotels (Royal Hawaiian, Sheraton, Hyatt, Moana Surfrider Hotel), most of the luxury designer brand stores (Apple Store, Chanel, Louis Vuitton, Prada, Burberry, Dior, Tiffany & Co., Fendi, Cartier, Gucci, and Coach) and popular surf clothing brand stores (Quiksilver, Billabong, Volcom). Waikīkī's other main thoroughfare, Kuhio Avenue, named after Prince Kuhio, is better known for its restaurants, cafes and grocers, along with its clubs, nightlife and prostitution.[10][11]		Over time, Waikīkī beach has had problems with erosion, leading to the construction of groynes and beach replenishment projects. For example, in the 1920s and 1930s sand was imported from Manhattan Beach, California, via ship and barge to Waikīkī.[12] Importing stopped in the 1970s. Officials are looking for ways to sustain the existing sand by eliminating loss due to tidal flow.[13] Subject to permits, a partial restoration was completed in the spring of 2012. The proposed project imported sand from nearby shoals and widened the 1,700-foot (520 m) long beach by about 37 feet (11 m) between the Royal Hawaiian Hotel concrete groyne and the Kūhiō Beach crib wall. The project restored the beach to its 1985 shoreline.[14]		Waikiki Beach has had contamination problems with sewage spills.[15][16][17][18]		China Airlines operates its Honolulu Branch Office in Waikīkī.[19] NTT DoCoMo also has limited operations here for the convenience of Japanese tourists. Hawaiian Airlines is based in Honolulu.[20]		District 6 of the Honolulu Police Department (HPD) encompasses Waikiki.[21] The Waikīkī HPD Substation is located at 2425 Kalakaua Avenue next to Kuhio Beach Park.[22]		The United States Postal Service operates the Waikīkī Post Office at 330 Saratoga Road.[23]		Hawaii Department of Education operates public schools. Thomas Jefferson Elementary School is located in Waikīkī proper, while Waikīkī Elementary School is located nearby, at the makai (southern) edge of the Kapahulu neighborhood.[24]		The Hawaii State Public Library System operates the Waikīkī Public Library at 400 Kapahulu Avenue.[25]		Waikiki is twinned with:		Surfboards in Waikiki		Waikīkī Beach facing Diamond Head, 1958		Waikiki Beach view		Aerial view of Waikiki Beach and Honolulu, Hawaii.		Statue of Prince Kuhio in Waikiki.		A zebra shark swimming at Waikiki Aquarium.		Coordinates: 21°16′31″N 157°49′52″W﻿ / ﻿21.2752°N 157.8312°W﻿ / 21.2752; -157.8312		
This is a list of beaches of the world, sorted by country. A beach is a landform along the shoreline of an ocean, sea, lake, or river. It usually consists of loose particles, which are often composed of rock, such as sand, gravel, shingle, pebbles, or cobblestones. Beaches typically occur in areas along the coast where wave or current action deposits and reworks sediments. The particles comprising a beach are occasionally biological in origin, such as mollusc shells or coralline algae.		Source: Beaches in Algeria[2]		Template:Pigeon beach Template:Galleon beach		Source: Argentina's Travel Guide — Beaches[3]		La Tonnara Beach, Corsica		Argelès-sur-Mer, Pyrénées-Orientales		A panoramic image of Bora Bora, French Polynesia		[6][7]												Bahía de cata, El playon, La punta, Cuyagua, Los Caracas, Playa pantaleta, Playa lido, Playa muerta, Chuao, Cepe, Playa grande, Playa Parguito, El yaque, Los roques, Isla de coche, La ciénaga, uricao, la boca, el diario, El Playon, Adicora, Playa Medina, Playa la punta, Las Isletas de Piritu, Playa punta la cruz.		
Particle size, also called grain size, refers to the diameter of individual grains of sediment, or the lithified particles in clastic rocks. The term may also be applied to other granular materials. This is different from the crystallite size, which refers to the size of a single crystal inside a particle or grain. A single grain can be composed of several crystals. Granular material can range from very small colloidal particles, through clay, silt, sand, gravel, and cobbles, to boulders.						Size ranges define limits of classes that are given names in the Wentworth scale (or Udden–Wentworth scale) used in the United States. The Krumbein phi (φ) scale, a modification of the Wentworth scale created by W. C. Krumbein[1] in 1937, is a logarithmic scale computed by the equation		where		This equation can be rearranged to find diameter using φ:		In some schemes, gravel is anything larger than sand (comprising granule, pebble, cobble, and boulder in the table above).		ISO 14688-1:2002, establishes the basic principles for the identification and classification of soils on the basis of those material and mass characteristics most commonly used for soils for engineering purposes. ISO 14688-1 is applicable to natural soils in situ, similar man-made materials in situ and soils redeposited by people.[2]		An accumulation of sediment can also be characterized by the grain size distribution. A sediment deposit can undergo sorting when a particle size range is removed by an agency such as a river or the wind. The sorting can be quantified using the Inclusive Graphic Standard Deviation:[3]		where		The result of this can be described using the following terms:		
A beach ridge is a wave-swept or wave-deposited ridge running parallel to a shoreline. It is commonly composed of sand as well as sediment worked from underlying beach material. The movement of sediment by wave action is called littoral transport. Movement of material parallel to the shoreline is called longshore transport. Movement perpendicular to the shore is called on-offshore transport. A beach ridge may be capped by, or associated with, sand dunes. The height of a beach ridge is affected by wave size and energy.		A fall in water level (or an uplift of land) can isolate a beach ridge from the body of water that created it. Isolated beach ridges may be found along dry lakes in the western United States and inland of the Great Lakes of North America, where they formed at the end of the last ice age when lake levels were much higher due to glacial melting and obstructed outflow caused by glacial ice. Some isolated beach ridges are found in parts of Scandinavia, where glacial melting relieved pressure on land masses and resulted in subsequent crustal lifting or post-glacial rebound. A rise in water level can submerge beach ridges created at an earlier stage, causing them to erode and become less distinct. Beach ridges can become routes for roads and trails.		
Accretion is the process of coastal sediment returning to the visible portion of a beach or foreshore following a submersion event. A sustainable beach or foreshore often goes through a cycle of submersion during rough weather then accretion during calmer periods. If a coastline is not in a healthy sustainable state, then erosion can be more serious and accretion does not fully restore the original volume of the visible beach or foreshore leading to permanent beach loss.				
Bulkhead line is an officially set line along a shoreline, usually beyond the dry land, to demark a territory allowable to be treated as dry land, to separate the jurisdictions of dry land and water authorities, for construction and riparian activities, to establish limits to the allowable obstructions to navigation and other waterfront uses.[1]		In particular, it may limit the construction of piers in the absence of an official pier line (pierhead line).[2]		Various jurisdictions may define it in different ways. A formal definition may read as follows: A geographic line along a reach of navigable water that has been adopted by a municipal ordinance and approved by the Department of Natural Resources, and which allows limited filling between this bulkhead line and the original ordinary high water mark, except where such filling is prohibited by the floodway provisions. (Several municipalities in Wisconsin use wording closely approximating this sample.)		
A river delta is a landform that forms from deposition of sediment carried by a river as the flow leaves its mouth and enters slower-moving or standing water.[1][2] This occurs where a river enters an ocean, sea, estuary, lake, reservoir, or (more rarely) another river that cannot transport away the supplied sediment. The size and shape of a delta is controlled by the balance between watershed processes that supply sediment and receiving basin processes that redistribute, sequester, and export that sediment.[3][4] The size, geometry, and location of the receiving basin also plays an important role in delta evolution. River deltas are important in human civilization, as they are major agricultural production centers and population centers. They can provide coastline defense and can impact drinking water supply.[5] They are also ecologically important, with different species assemblages depending on their landscape position.						River deltas form when a river carrying sediment reaches either (1) a body of water, such as a lake, ocean, or reservoir, (2) another river that cannot remove the sediment quickly enough to stop delta formation, or (3) an inland region where the water spreads out and deposits sediments. The tidal currents also cannot be too strong, as sediment would wash out into the water body faster than the river deposits it. Of course, the river must carry enough sediment to layer into deltas over time. The river's velocity decreases rapidly, causing it to deposit the majority, if not all, of its load. This alluvium builds up to form the river delta.[6] When the flow enters the standing water, it is no longer confined to its channel and expands in width. This flow expansion results in a decrease in the flow velocity, which diminishes the ability of the flow to transport sediment. As a result, sediment drops out of the flow and deposits. Over time, this single channel builds a deltaic lobe (such as the bird's-foot of the Mississippi or Ural river deltas), pushing its mouth into the standing water. As the deltaic lobe advances, the gradient of the river channel becomes lower because the river channel is longer but has the same change in elevation (see slope).		As the slope of the river channel decreases, it becomes unstable for two reasons. First, gravity makes the water flow in the most direct course down slope. If the river breaches its natural levees (i.e., during a flood), it spills out onto a new course with a shorter route to the ocean, thereby obtaining a more stable steeper slope.[7] Second, as its slope gets lower, the amount of shear stress on the bed decreases, which results in deposition of sediment within the channel and a rise in the channel bed relative to the floodplain. This makes it easier for the river to breach its levees and cut a new channel that enters the body of standing water at a steeper slope. Often when the channel does this, some of its flow remains in the abandoned channel. When these channel-switching events occur, a mature delta develops a distributary network.		Another way these distributary networks form is from deposition of mouth bars (mid-channel sand and/or gravel bars at the mouth of a river). When this mid-channel bar is deposited at the mouth of a river, the flow is routed around it. This results in additional deposition on the upstream end of the mouth-bar, which splits the river into two distributary channels. A good example of the result of this process is the Wax Lake Delta.		In both of these cases, depositional processes force redistribution of deposition from areas of high deposition to areas of low deposition. This results in the smoothing of the planform (or map-view) shape of the delta as the channels move across its surface and deposit sediment. Because the sediment is laid down in this fashion, the shape of these deltas approximates a fan. The more often the flow changes course, the shape develops as closer to an ideal fan, because more rapid changes in channel position results in more uniform deposition of sediment on the delta front. The Mississippi and Ural River deltas, with their bird's-feet, are examples of rivers that do not avulse often enough to form a symmetrical fan shape. Alluvial fan deltas, as seen by their name, avulse frequently and more closely approximate an ideal fan shape.		Deltas are typically classified according to the main control on deposition, which is a combination of river, wave, and tidal processes,[8] depending on the strength of each.[9] The other two factors that play a major role are landscape position and the grain size distribution of the source sediment entering the delta from the river.[10]		In wave dominated deltas, wave-driven sediment transport controls the shape of the delta, and much of the sediment emanating from the river mouth is deflected along the coast line.[8] The relationship between waves and river deltas is quite variable and largely influenced by the deepwater wave regimes of the receiving basin. With a high wave energy near shore and a steeper slope offshore, waves will make river deltas smoother. Waves can also be responsible for carrying sediments away from the river delta, causing the delta to retreat.[5] For deltas that form further upriver in an estuary, there are complex yet quantifiable linkages between winds, tides, river discharge, and delta water levels.[11][12]		Erosion is also an important control in tide dominated deltas, such as the Ganges Delta, which may be mainly submarine, with prominent sand bars and ridges. This tends to produce a "dendritic" structure.[13] Tidal deltas behave differently from river- and wave-dominated deltas, which tend to have a few main distributaries. Once a wave- or river- distributary silts up, it is abandoned, and a new channel forms elsewhere. In a tidal delta, new distributaries are formed during times when there's a lot of water around – such as floods or storm surges. These distributaries slowly silt up at a pretty constant rate until they fizzle out.[13]		A Gilbert delta (named after Grove Karl Gilbert) is a specific type of delta formed from coarse sediments, as opposed to gently-sloping muddy deltas such as that of the Mississippi. For example, a mountain river depositing sediment into a freshwater lake would form this kind of delta.[14] [15] While some authors describe both lacustrine and marine locations of Gilbert deltas,[14] others note that their formation is more characteristic of the freshwater lakes, where it is easier for the river water to mix with the lakewater faster (as opposed to the case of a river falling into the sea or a salt lake, where less dense fresh water brought by the river stays on top longer).[16]		G.K. Gilbert himself first described this type of delta on Lake Bonneville in 1885.[16] Elsewhere, similar structures occur, for example, at the mouths of several creeks that flow into Okanagan Lake in British Columbia and forming prominent peninsulas at Naramata (49°35′30″N 119°35′30″W﻿ / ﻿49.59167°N 119.59167°W﻿ / 49.59167; -119.59167), Summerland (49°34′23″N 119°37′45″W﻿ / ﻿49.57306°N 119.62917°W﻿ / 49.57306; -119.62917), or Peachland (49°47′00″N 119°42′45″W﻿ / ﻿49.78333°N 119.71250°W﻿ / 49.78333; -119.71250).		A tidal freshwater delta[17] is a sedimentary deposit formed at the boundary between an upland stream and an estuary, in the region known as the "subestuary".[18] Drowned coastal river valleys that were inundated by rising sea levels during the late Pleistocene and subsequent Holocene tend to have dendritic estuaries with many feeder tributaries. Each tributary mimics this salinity gradient from their brackish junction with the mainstem estuary up to the fresh stream feeding the head of tidal propagation. As a result, the tributaries are considered to be “subestuaries”.The origin and evolution of a tidal freshwater delta involves processes that are typical of all deltas[4] as well as processes that are unique to the tidal freshwater setting.[19][20] The combination of processes that create a tidal freshwater delta result in a distinct morphology and unique environmental characteristics. Many tidal freshwater deltas that exist today are directly caused by the onset of or changes in historical land use, especially deforestation, intensive agriculture, and urbanization.[21] These ideas are well illustrated by the many tidal freshwater deltas prograding into Chesapeake Bay along the east coastline of the United States. Research has demonstrated that the accumulating sediments in this estuary derive from post-European settlement deforestation, agriculture, and urban development.[22][23][24]		Other rivers, particularly those on coasts with significant tidal range, do not form a delta but enter into the sea in the form of an estuary. Notable examples include the Saint Lawrence River and the Tagus estuary.		In rare cases the river delta is located inside a large valley and is called an inverted river delta. Sometimes a river divides into multiple branches in an inland area, only to rejoin and continue to the sea. Such an area is called an inland delta, and often occurs on former lake beds. The Inner Niger Delta and Peace–Athabasca Delta are notable examples. The Amazon has also an inland delta before the island of Marajó.		In some cases, a river flowing into a flat arid area splits into channels that evaporate as it progresses into the desert. Okavango Delta in Botswana is one well-known example.		The generic term mega delta can be used to describe very large Asian river deltas, such as the Changjiang (Yangtze), Pearl, Red, Mekong, Irrawaddy, Ganges-Brahmaputra, and Indus.		The formation of a delta is complicated, multiple, and cross-cutting over time, but in a simple delta three main types of bedding may be distinguished: the bottomset beds, foreset/frontset beds, and topset beds. This three part structure may be seen in small scale by crossbedding.[14][25]		The Ganges/Brahmaputra combination delta, which spans most of Bangladesh and empties into the Bay of Bengal, is the world's largest delta.		The St. Clair River delta, between the Canadian province of Ontario and the U.S. state of Michigan, is the largest delta emptying into a body of fresh water.		Other rivers with notable deltas include the:		Human activities, such as the creation of dams for hydroelectric power or to create reservoirs can radically alter delta ecosystems. Dams block sedimentation, which can cause the delta to erode away. The use of water upstream can greatly increase salinity levels as less fresh water flows to meet the salty ocean water. While nearly all deltas have been impacted to some degree by humans, the Nile Delta and Colorado River Delta are some of the most extreme examples of the ecological devastation caused to deltas by damming and diversion of water. Construction, irrigation, and land alteration have impacted delta formation. As humans have altered surface roughness, runoff, and groundwater storage, studies have shown river delta retreat. However, historical data documents show that during the Roman Empire and Little Ice Age (times where there was considerable anthropogenic pressure), there were significant sediment accumulation in deltas. The industrial revolution has only amplified the impact of humans on delta growth and retreat.[28]		Ancient deltas are a benefit to the economy due to their well sorted sand and gravel. Sand and gravel is often quarried from these old deltas and used in concrete for highways, buildings, sidewalks, and even landscaping. More than 1 billion tons of sand and gravel are produced in the United States alone.[29] Not all sand and gravel quarries are former deltas, but for ones that are, a lot of the sorting is already done by the power of water.		As lowlands often adjacent to urban areas, deltas often comprise extensive industrial and commercial areas as well as agricultural land. These uses are often in conflict. The Fraser Delta in British Columbia, Canada, includes the Vancouver Airport and the Roberts Bank Superport and the Annacis Island industrial zone, and a mix of commercial, residential and agricultural land. Space is so limited in the Lower Mainland region, and in British Columbia in general, which is very mountainous, that the Agricultural Land Reserve was created to preserve agricultural land for food production.		Researchers have found a number of examples of deltas that formed in Martian lakes. Finding deltas is a major sign that Mars once had large amounts of water. Deltas have been found over a wide geographical range. Below are pictures of a few.[30]		Delta in Ismenius Lacus quadrangle, as seen by THEMIS.		Delta in Lunae Palus quadrangle, as seen by THEMIS.		Delta in Margaritifer Sinus quadrangle as seen by THEMIS.		Probable delta in Eberswalde crater, as seen by Mars Global Surveyor. Image in Margaritifer Sinus quadrangle.		
In fluid dynamics, wind waves, or wind-generated waves, are surface waves that occur on the free surface of bodies of water (like oceans, seas, lakes, rivers, canals, puddles or ponds). They result from the wind blowing over an area of fluid surface. Waves in the oceans can travel thousands of miles before reaching land. Wind waves on Earth range in size from small ripples, to waves over 100 ft (30 m) high.[1]		When directly generated and affected by local winds, a wind wave system is called a wind sea. After the wind ceases to blow, wind waves are called swells. More generally, a swell consists of wind-generated waves that are not significantly affected by the local wind at that time. They have been generated elsewhere or some time ago.[2] Wind waves in the ocean are called ocean surface waves.		Wind waves have a certain amount of randomness: subsequent waves differ in height, duration, and shape with limited predictability. They can be described as a stochastic process, in combination with the physics governing their generation, growth, propagation and decay—as well as governing the interdependence between flow quantities such as: the water surface movements, flow velocities and water pressure. The key statistics of wind waves (both seas and swells) in evolving sea states can be predicted with wind wave models.		Although waves are usually considered in the water seas of Earth, the hydrocarbon seas of Titan may also have wind-driven waves.[3]						The great majority of large breakers seen at a beach result from distant winds. Five factors influence the formation of the flow structures in wind waves:[4]		All of these factors work together to determine the size of wind waves and the structure of the flow within them.		The main dimensions associated with waves are:		A fully developed sea has the maximum wave size theoretically possible for a wind of a specific strength, duration, and fetch. Further exposure to that specific wind could only cause a dissipation of energy due to the breaking of wave tops and formation of "whitecaps". Waves in a given area typically have a range of heights. For weather reporting and for scientific analysis of wind wave statistics, their characteristic height over a period of time is usually expressed as significant wave height. This figure represents an average height of the highest one-third of the waves in a given time period (usually chosen somewhere in the range from 20 minutes to twelve hours), or in a specific wave or storm system. The significant wave height is also the value a "trained observer" (e.g. from a ship's crew) would estimate from visual observation of a sea state. Given the variability of wave height, the largest individual waves are likely to be somewhat less than twice the reported significant wave height for a particular day or storm.[5]		Wave formation on an initially flat water surface by wind is started by a random distribution of normal pressure of turbulent wind flow over the water. This pressure fluctuation produces normal and tangential stresses in the surface water, which generates waves. It is assumed that:[6]		The second mechanism involves wind shear forces on the water surface. John W. Miles suggested a surface wave generation mechanism which is initiated by turbulent wind shear flows based on the inviscid Orr-Sommerfeld equation in 1957. He found the energy transfer from wind to water surface is proportional to the curvature of the velocity profile of the wind at the point where the mean wind speed is equal to the wave speed. Since the wind speed profile is logarithmic to the water surface, the curvature has a negative sign at this point. This relation shows the wind flow transferring its kinetic energy to the water surface at their interface.		Assumptions:		Generally these wave formation mechanisms occur together on the water surface and eventually produce fully developed waves.		For example,[8] if we assume a flat sea surface (Beaufort state 0), and a sudden wind flow blows steadily across the sea surface, the physical wave generation process follows the sequence:		Three different types of wind waves develop over time:		Ripples appear on smooth water when the wind blows, but will die quickly if the wind stops. The restoring force that allows them to propagate is surface tension. Sea waves are larger-scale, often irregular motions that form under sustained winds. These waves tend to last much longer, even after the wind has died, and the restoring force that allows them to propagate is gravity. As waves propagate away from their area of origin, they naturally separate into groups of common direction and wavelength. The sets of waves formed in this way are known as swells.		Individual "rogue waves" (also called "freak waves", "monster waves", "killer waves", and "king waves") much higher than the other waves in the sea state can occur. In the case of the Draupner wave, its 25 m (82 ft) height was 2.2 times the significant wave height. Such waves are distinct from tides, caused by the Moon and Sun's gravitational pull, tsunamis that are caused by underwater earthquakes or landslides, and waves generated by underwater explosions or the fall of meteorites—all having far longer wavelengths than wind waves.		Yet, the largest ever recorded wind waves are common — not rogue — waves in extreme sea states. For example: 29.1 m (95 ft) high waves have been recorded on the RRS Discovery in a sea with 18.5 m (61 ft) significant wave height, so the highest wave is only 1.6 times the significant wave height.[12] The biggest recorded by a buoy (as of 2011) was 32.3 m (106 ft) high during the 2007 typhoon Krosa near Taiwan.[13]		Ocean waves can be classified based on: the disturbing force(s) that create(s) them; the extent to which the disturbing force(s) continue(s) to influence them after formation; the extent to which the restoring force(s) weaken(s) (or flatten) them; and their wavelength or period. Seismic Sea waves have a period of ~20 minutes, and speeds of 760 km/h (470 mph). Wind waves (deep-water waves) have a period of about 20 seconds.		The speed of all ocean waves is controlled by gravity, wavelength, and water depth. Most characteristics of ocean waves depend on the relationship between their wavelength and water depth. Wavelength determines the size of the orbits of water molecules within a wave, but water depth determines the shape of the orbits. The paths of water molecules in a wind wave are circular only when the wave is traveling in deep water. A wave cannot "feel" the bottom when it moves through water deeper than half its wavelength because too little wave energy is contained in the small circles below that depth. Waves moving through water deeper than half their wavelength are known as deep-water waves. On the other hand, the orbits of water molecules in waves moving through shallow water are flattened by the proximity of the sea surface bottom. Waves in water shallower than 1/20 their original wavelength are known as shallow-water waves. Transitional waves travel through water deeper than 1/20 their original wavelength but shallower than half their original wavelength.		In general, the longer the wavelength, the faster the wave energy will move through the water. For deep-water waves, this relationship is represented with the following formula:		where C is speed (celerity), L is wavelength, and T is time, or period (in seconds).		The speed of a deep-water wave may also be approximated by:		where g is the acceleration due to gravity, 9.8 meters (32 feet) per second squared. Because g and π (3.14) are constants, the equation can be reduced to:		when C is measured in meters per second and L in meters. Note that in both formulas the wave speed is proportional to the square root of the wavelength.		The speed of shallow-water waves is described by a different equation that may be written as:		where C is speed (in meters per second), g is the acceleration due to gravity, and d is the depth of the water (in meters). The period of a wave remains unchanged regardless of the depth of water through which it is moving. As deep-water waves enter the shallows and feel the bottom, however, their speed is reduced and their crests "bunch up," so their wavelength shortens.		As waves travel from deep to shallow water, their shape alters (wave height increases, speed decreases, and length decreases as wave orbits become asymmetrical). This process is called shoaling.		Wave refraction is the process by which wave crests realign themselves as a result of decreasing water depths. Varying depths along a wave crest cause the crest to travel at different phase speeds, with those parts of the wave in deeper water moving faster than those in shallow water. This process continues until the crests become (nearly) parallel to the depth contours. Rays—lines normal to wave crests between which a fixed amount of energy flux is contained—converge on local shallows and shoals. Therefore, the wave energy between rays is concentrated as they converge, with a resulting increase in wave height.		Because these effects are related to a spatial variation in the phase speed, and because the phase speed also changes with the ambient current – due to the Doppler shift – the same effects of refraction and altering wave height also occur due to current variations. In the case of meeting an adverse current the wave steepens, i.e. its wave height increases while the wave length decreases, similar to the shoaling when the water depth decreases.[15]		Some waves undergo a phenomenon called "breaking".[16] A breaking wave is one whose base can no longer support its top, causing it to collapse. A wave breaks when it runs into shallow water, or when two wave systems oppose and combine forces. When the slope, or steepness ratio, of a wave is too great, breaking is inevitable.		Individual waves in deep water break when the wave steepness—the ratio of the wave height H to the wavelength λ—exceeds about 0.17, so for H > 0.17 λ. In shallow water, with the water depth small compared to the wavelength, the individual waves break when their wave height H is larger than 0.8 times the water depth h, that is H > 0.8 h.[17] Waves can also break if the wind grows strong enough to blow the crest off the base of the wave.		Three main types of breaking waves are identified by surfers or surf lifesavers. Their varying characteristics make them more or less suitable for surfing, and present different dangers.		Wind waves are mechanical waves that propagate. along the interface between water and air; the restoring force is provided by gravity, and so they are often referred to as surface gravity waves. As the wind blows, pressure and friction perturb the equilibrium of the water surface and transfer energy from the air to the water, forming waves. The initial formation of waves by the wind is described in the theory of Phillips from 1957, and the subsequent growth of the small waves has been modeled by Miles, also in 1957.[18][19]		In linear plane waves of one wavelength in deep water, parcels near the surface move not plainly up and down but in circular orbits: forward above and backward below (compared the wave propagation direction). As a result, the surface of the water forms not an exact sine wave, but more a trochoid with the sharper curves upwards—as modeled in trochoidal wave theory. Wind waves are thus a combination of transversal and longitudinal waves.		When waves propagate in shallow water, (where the depth is less than half the wavelength) the particle trajectories are compressed into ellipses.[21][22]		In reality, for finite values of the wave amplitude (height), the particle paths do not form closed orbits; rather, after the passage of each crest, particles are displaced slightly from their previous positions, a phenomenon known as Stokes drift.[23][24]		As the depth below the free surface increases, the radius of the circular motion decreases. At a depth equal to half the wavelength λ, the orbital movement has decayed to less than 5% of its value at the surface. The phase speed (also called the celerity) of a surface gravity wave is – for pure periodic wave motion of small-amplitude waves – well approximated by		where		In deep water, where d ≥ 1 2 λ {\displaystyle d\geq {\frac {1}{2}}\lambda } , so 2 π d λ ≥ π {\displaystyle {\frac {2\pi d}{\lambda }}\geq \pi } and the hyperbolic tangent approaches 1 {\displaystyle 1} , the speed c {\displaystyle c} approximates		In SI units, with c deep {\displaystyle c_{\text{deep}}} in m/s, c deep ≈ 1.25 λ {\displaystyle c_{\text{deep}}\approx 1.25{\sqrt {\lambda }}} , when λ {\displaystyle \lambda } is measured in metres. This expression tells us that waves of different wavelengths travel at different speeds. The fastest waves in a storm are the ones with the longest wavelength. As a result, after a storm, the first waves to arrive on the coast are the long-wavelength swells.		For intermediate and shallow water, the Boussinesq equations are applicable, combining frequency dispersion and nonlinear effects. And in very shallow water, the shallow water equations can be used.		If the wavelength is very long compared to the water depth, the phase speed (by taking the limit of c when the wavelength approaches infinity) can be approximated by		On the other hand, for very short wavelengths, surface tension plays an important role and the phase speed of these gravity-capillary waves can (in deep water) be approximated by		where		When several wave trains are present, as is always the case in nature, the waves form groups. In deep water the groups travel at a group velocity which is half of the phase speed.[26] Following a single wave in a group one can see the wave appearing at the back of the group, growing and finally disappearing at the front of the group.		As the water depth d {\displaystyle d} decreases towards the coast, this will have an effect: wave height changes due to wave shoaling and refraction. As the wave height increases, the wave may become unstable when the crest of the wave moves faster than the trough. This causes surf, a breaking of the waves.		The movement of wind waves can be captured by wave energy devices. The energy density (per unit area) of regular sinusoidal waves depends on the water density ρ {\displaystyle \rho } , gravity acceleration g {\displaystyle g} and the wave height H {\displaystyle H} (which, for regular waves, is equal to twice the amplitude, a {\displaystyle a} ):		The velocity of propagation of this energy is the group velocity.		Surfers are very interested in the wave forecasts. There are many websites that provide predictions of the surf quality for the upcoming days and weeks. Wind wave models are driven by more general weather models that predict the winds and pressures over the oceans, seas and lakes.		Wind wave models are also an important part of examining the impact of shore protection and beach nourishment proposals. For many beach areas there is only patchy information about the wave climate, therefore estimating the effect of wind waves is important for managing littoral environments.		Ocean water waves generate land seismic waves that propagate hundreds of kilometers into the land.[27] These seismic signals usually have the period of 6 ± 2 seconds. Such recordings were first reported and understood in about 1900.		There are two types of seismic "ocean waves". The primary waves are generated in shallow waters by direct water wave-land interaction and have the same period as the water waves (10 to 16 seconds). The more powerful secondary waves are generated by the superposition of ocean waves of equal period traveling in opposite directions, thus generating standing gravity waves – with an associated pressure oscillation at half the period, which is not diminishing with depth. The theory for microseism generation by standing waves was provided by Michael Longuet-Higgins in 1950, after in 1941 Pierre Bernard suggested this relation with standing waves on the basis of observations.[28][29]		Internal waves can form at the boundary between water layers of different densities. These sub-surface waves are called internal waves. As is the case with ocean waves at the air-ocean interface, internal waves possess troughs, crests, wavelength, and period. Internal waves move very slowly because the density difference between the joined media is very small. Internal waves occur in the ocean at the base of the pycnocline, especially at the bottom edge of a steep thermocline. The wave height of internal waves may be greater than 30 meters (98 feet), causing the pycnocline to undulate slowly through a considerable depth. Their wavelength often exceeds 0.8 kilometres (0.50 mi) and their periods are typically 5 to 8 minutes. Internal waves are generated by wind energy, tidal energy, and ocean currents. Surface manifestations of internal waves have been photographed from space.		Internal waves may mix nutrients into surface water and trigger plankton blooms. They can also affect submarines and oil platforms.		
In physical oceanography, undertow is the average under-current which is moving offshore when waves are approaching a shore. Undertow is a necessary and universal feature: it is a return flow compensating for the onshore-directed average transport of water by the waves in the zone above the wave troughs. The undertow's flow velocities are generally strongest in the surf zone, where the water is shallow and the waves are high due to shoaling.[1]		In popular usage, the word "undertow" is often misapplied to rip currents.[2] An undertow occurs everywhere underneath shore-approaching waves, whereas rip currents are localized narrow offshore currents occurring at certain locations along the coast. Unlike undertow, rip currents are strong at the surface.						An "undertow" is a steady, offshore-directed compensation flow, which occurs below waves near the shore. Physically, nearshore, the wave-induced mass flux between wave crest and trough is onshore directed. This mass transport is localized in the upper part of the water column, i.e. above the wave troughs. To compensate for the amount of water being transported towards the shore, a second-order (i.e. proportional to the wave height squared), offshore-directed mean current takes place in the lower section of the water column. This flow – the undertow – affects the nearshore waves everywhere, unlike rip currents localized at certain positions along the shore.[3]		The term undertow is used in scientific coastal oceanography papers.[4][5][6] The distribution of flow velocities in the undertow over the water column is important as it strongly influences the on- or offshore transport of sediment. Outside the surf zone there is a near-bed onshore-directed sediment transport induced by Stokes drift and skewed-asymmetric wave transport. In the surf zone, strong undertow generates a near-bed offshore sediment transport. These antagonistic flows may lead to sand bar formation where the flows converge near the wave breaking point, or in the wave breaking zone.[4][5][6][7]		An exact relation for the mass flux of a nonlinear periodic wave on an inviscid fluid layer was established by Levi-Civita in 1924.[8] In a frame of reference according to Stokes' first definition of wave celerity, the mass flux M w {\displaystyle M_{w}} of the wave is related to the wave's kinetic energy density E k {\displaystyle E_{k}} (integrated over depth and thereafter averaged over wavelength) and phase speed c {\displaystyle c} through:		Similarly, Longuet Higgins showed in 1975 that – for the common situation of zero mass flux towards the shore (i.e. Stokes' second definition of wave celerity) – normal-incident periodic waves produce a depth- and time-averaged undertow velocity:[9]		with h {\displaystyle h} the mean water depth and ρ {\displaystyle \rho } the fluid density. The positive flow direction of u ¯ {\displaystyle {\bar {u}}} is in the wave propagation direction.		For small-amplitude waves, there is equipartition of kinetic ( E k {\displaystyle E_{k}} ) and potential energy ( E p {\displaystyle E_{p}} ):		with E w {\displaystyle E_{w}} the total energy density of the wave, integrated over depth and averaged over horizontal space. Since in general the potential energy E p {\displaystyle E_{p}} is much easier to measure than the kinetic energy, the wave energy is approximately E w ≈ 1 8 ρ g H 2 {\displaystyle {E_{w}\approx {\tfrac {1}{8}}\rho gH^{2}}} (with H {\displaystyle H} the wave height). So		For irregular waves the required wave height is the root-mean-square wave height H rms ≈ 8 σ , {\displaystyle H_{\text{rms}}\approx {\sqrt {8}}\;\sigma ,} with σ {\displaystyle \sigma } the standard deviation of the free-surface elevation.[10] The potential energy is E p = 1 2 ρ g σ 2 {\displaystyle E_{p}={\tfrac {1}{2}}\rho g\sigma ^{2}} and E w ≈ ρ g σ 2 . {\displaystyle E_{w}\approx \rho g\sigma ^{2}.}		The distribution of the undertow velocity over the water depth is a topic of ongoing research.[4][5][6]		In popular usage, the word "undertow" is sometimes used correctly, in the same sense it is in oceanography. However the term "undertow" is also often used incorrectly, in the mistaken belief that near beaches there is a water flow or current that can pull a person down vertically and hold them underwater until they drown. This misconception stems from a basic lack of knowledge about water currents, and from confusing undertow (which is usually not dangerous) with the more substantial dangers of rip currents. Rip currents also cannot pull a person down, but they can carry a person out beyond the zone of the breaking waves.		In contrast to undertow, rip currents are responsible for the great majority of drownings close to beaches. When a swimmer enters a rip current, it starts to carry the person offshore. If the swimmer understands how to deal with this situation, he or she can easily exit the rip current by swimming at right angles to the flow, in other words swimming parallel to the shore, or by simply treading water or floating. However, if the swimmer does not know these simple solutions, or does not possess the necessary water skills, they may panic and drown, or they may exhaust themselves by trying unsuccessfully to swim directly against the flow.		On the United States Lifesaving Association website it is explained that some uses of the word "undertow" are incorrect:		A rip current is a horizontal current. Rip currents do not pull people under the water–-they pull people away from shore. Drowning deaths occur when people pulled offshore are unable to keep themselves afloat and swim to shore. This may be due to any combination of fear, panic, exhaustion, or lack of swimming skills.		In some regions rip currents are referred to by other, incorrect terms such as 'rip tides' and 'undertow'. We encourage exclusive use of the correct term – rip currents. Use of other terms may confuse people and negatively impact public education efforts.[2]		
A pebble is a clast of rock with a particle size of 2 to 64 millimetres based on the Krumbein phi scale of sedimentology. Pebbles are generally considered larger than granules (2 to 4 millimetres diameter) and smaller than cobbles (64 to 256 millimetres diameter). A rock made predominantly of pebbles is termed a conglomerate. Pebble tools are among the earliest known man-made artifacts, dating from the Palaeolithic period of human history.		A beach composed chiefly of surface pebbles is commonly termed a shingle beach. This type of beach has armoring characteristics with respect to wave erosion, as well as ecological niches that provide habitat for animals and plants.		Inshore banks of shingle (large quantities of pebbles) exist in some locations, such as the entrance to the River Ore, where the moving banks of shingle give notable navigational challenges.[1]		Pebbles come in various colors and textures and can have streaks, known as veins, of quartz or other minerals. Pebbles are mostly smooth but, dependent on how frequently they come in contact with the sea, they can have marks of contact with other rocks or other pebbles. Pebbles left above the high water mark may have growths of organisms such as lichen on them, signifying the lack of contact with seawater.						Pebbles are found in two locations – on the beaches of various oceans and seas, and inland where ancient seas used to cover the land. When then the seas retreated, the rocks became landlocked. They can also be found in lakes and ponds. Pebbles can also form in rivers, and travel into estuaries where the smoothing continues in the sea.		Beach pebbles and river pebbles (also known as river rock) are distinct in their geological formation and appearance.		Beach pebbles form gradually over time as the ocean water washes over loose rock particles. The result is a smooth, rounded appearance. The typical size range is from 2 mm to 50 mm. The colors range from translucent white to black, and include shades of yellow, brown, red and green. Some of the more plentiful pebble beaches are found along the coast of the Pacific Ocean, beginning in the United States and extending down to the tip of South America in Argentina. Other pebble beaches are found in northern Europe (particularly on the beaches of the Norwegian Sea), along the coast of the U.K. and Ireland, on the shores of Australia, and around the islands of Indonesia and Japan.		Inland pebbles (river pebbles of river rock) are usually found along the shores of large rivers and lakes. These pebbles form as the flowing water washes over rock particles on the bottom and along the shores of the river. The smoothness and color of river pebbles depends on several factors, such as the composition of the soil of the river banks, the chemical characteristics of the water, and the speed of the current. Because river current is gentler than the ocean waves, river pebbles are usually not as smooth as beach pebbles. The most common colors of river rock are black, grey, green, brown and white.		Beach pebbles and river pebbles are used for a variety of purposes, both outdoors and indoors. They can be sorted by color and size, and they can also be polished to improve the texture and color. Outdoors, beach pebbles are often used for landscaping, construction and as decorative elements. Beach pebbles are often used to cover walkways and driveways, around pools, in and around plant containers, on patios and decks. Beach and river pebbles are also used to create water-smart gardens in areas where water is scarce. Small pebbles are also used to create living spaces and gardens on the rooftops of buildings. Indoors, pebbles can be used as bookends and paperweights. Large pebbles are also used to create "pet rocks" for children.		On Mars, slabs of pebbly conglomerate rock have been found and have been interpreted by scientists as having formed in an ancient streambed. The gravels, which were discovered by NASA's Mars rover Curiosity, range from the size of sand particles to the size of golf balls. Analysis has shown that the pebbles were deposited by a stream that flowed at walking pace and was ankle- to hip-deep.[2]		Sea wave polishing pebbles into rounded corners		Beach pebbles made of halite; western Dead Sea coast, Israel.		Pebbles on a beach at Broulee, Australia		
A natural arch, natural bridge or, less commonly, a rock arch is a natural rock formation where an arch has formed with an opening underneath. Natural arches commonly form where inland cliffs, coastal cliffs, fins or stacks are subject to erosion from the sea, rivers or weathering (subaerial processes).		Most natural arches are formed from narrow fins and sea stacks composed of sandstone or limestone with steep, often vertical, cliff faces. The formations become narrower due to erosion over geologic time scales. The softer rock stratum erodes away creating rock shelters, or alcoves, on opposite sides of the formation beneath the relatively harder stratum, or caprock, above it. The alcoves erode further into the formation eventually meeting underneath the harder caprock layer, thus creating an arch. The erosional processes exploit weaknesses in the softer rock layers making cracks larger and removing material more quickly than the caprock; however, the caprock itself continues to erode after an arch has formed, which will ultimately lead to collapse.		The choice between bridge and arch is somewhat arbitrary. The Natural Arch and Bridge Society identifies a bridge as a subtype of arch that is primarily water-formed.[1] By contrast, the Dictionary of Geological Terms defines a natural bridge as a "natural arch that spans a valley of erosion."[2]		The largest natural arch, by a significant margin, is the Xianren Bridge in China, with a span of 122 ± 5 meters (400 ± 15 ft).[3]						On coasts two different types of arches can form depending on the geology. On discordant coastlines rock types run at 90° to the coast. Wave refraction concentrates the wave energy on the headland, and an arch forms when caves break through the headland. Two examples of this type of arch are London Arch—previously known as London Bridge—in Victoria, Australia, and Neil Island in Andaman, India. When these arches eventually collapse, they form stacks and stumps. On concordant coastlines rock types run parallel to the coastline, with weak rock such as shale protected by stronger rock such as limestone. The wave action along concordant coastlines breaks through the strong rock and then erodes the weak rock very quickly. Good examples of this type of arch are the Durdle Door and Stair Hole near Lulworth Cove on Dorset's Jurassic Coast in south England. When Stair Hole eventually collapses it will form a cove.		Weather-eroded arches begin their formation as deep cracks which penetrate into a sandstone layer. Erosion occurring within the cracks wears away exposed rock layers and enlarges the surface cracks isolating narrow sandstone walls which are called fins. Alternating frosts and thawing cause crumbling and flaking of the porous sandstone and eventually cut through some of the fins. The resulting holes become enlarged to arch proportions by rockfalls and weathering. The arches eventually collapse leaving only buttresses that in time will erode.[4]		Many weather-eroded arches are found in Arches National Park, Canyonlands National Park, and Grand Staircase-Escalante National Monument, all located in southern Utah, United States.		Some natural bridges may look like arches, but they form in the path of streams that wear away and penetrate the rock. Pothole arches form by chemical weathering as water collects in natural depressions and eventually cuts through to the layer below.		Natural Bridges National Monument in Utah protects the area surrounding three large natural bridges all of which were formed by streams running through canyons. The largest of which is named Sipapu Bridge with a span of 225 feet (69 m). The Rainbow Bridge National Monument's namesake was also formed by flowing water which created the largest known natural bridge in the Western Hemisphere with a span of 234 feet (71 m), based on a laser measurement made in 2007. Xianren Bridge, also known as Fairy Bridge, in Guangxi, China is currently the world's largest known natural bridge with a span recorded at 400 feet (120 m) by the Natural Arch and Bridge Society in October 2010, with a precision of ±15 feet (4.6 m).[5][6]		Natural bridges can form from natural limestone caves, where paired sinkholes collapse and a ridge of stone is left standing in between, with the cave passageway connecting from sinkhole to sinkhole.		Like all rock formations, natural bridges are subject to continued erosion, and will eventually collapse and disappear. One example of this was the double-arched Victorian coastal rock formation, London Bridge, which lost an arch after storms increased erosion.[7]		Moon Hill in Yangshuo, Guizhou Province, China, is an example of an arch formed by the remnant of a karst limestone cave.		In a few places in the world, natural arches are utilized by humans as transportation bridges with highways or railroads running across them.		In Virginia, US Route 11 traverses Natural Bridge. Two additional natural arch roadways are found in Kentucky. The first arch, a cave erosion arch made of limestone, is located in Carter Caves State Resort Park and it has a paved road on top. The second arch, a weather-eroded sandstone arch with a dirt road on top, is located on the edge of Natural Bridge State Park in Kentucky. The latter arch is called White's Branch Arch (also known as the Narrows) and the road going over it is usually referred to as the Narrows Road.		In Europe, the Romanian village of Ponoarele has a road 60 m long and 13 m wide, passing over a stone arch 4 m thick, 20 m high, with a 9 m span. The arch is called God's Bridge (Podul lui Dumnezeu).		In South America, the railroad from Lima, Peru crosses the Rio Yauli on a natural bridge near kilometer 214.2 as it approaches the city of La Oroya, Peru.		
Clay is a fine-grained natural rock or soil material that combines one or more clay minerals with traces of metal oxides and organic matter. Geologic clay deposits are mostly composed of phyllosilicate minerals containing variable amounts of water trapped in the mineral structure. Clays are plastic due to that water content and become hard, brittle and non–plastic upon drying or firing.[1][2][3] Depending on the soil's content in which it is found, clay can appear in various colours from white to dull grey or brown to deep orange-red.		Although many naturally occurring deposits include both silts and clay, clays are distinguished from other fine-grained soils by differences in size and mineralogy. Silts, which are fine-grained soils that do not include clay minerals, tend to have larger particle sizes than clays. There is, however, some overlap in particle size and other physical properties. The distinction between silt and clay varies by discipline. Geologists and soil scientists usually consider the separation to occur at a particle size of 2 µm (clays being finer than silts), sedimentologists often use 4–5 μm, and colloid chemists use 1 μm.[1] Geotechnical engineers distinguish between silts and clays based on the plasticity properties of the soil, as measured by the soils' Atterberg limits. ISO 14688 grades clay particles as being smaller than 2 μm and silt particles as being larger.						Clay minerals typically form over long periods of time as a result of the gradual chemical weathering of rocks, usually silicate-bearing, by low concentrations of carbonic acid and other diluted solvents. These solvents, usually acidic, migrate through the weathering rock after leaching through upper weathered layers. In addition to the weathering process, some clay minerals are formed through hydrothermal activity. There are two types of clay deposits: primary and secondary. Primary clays form as residual deposits in soil and remain at the site of formation. Secondary clays are clays that have been transported from their original location by water erosion and deposited in a new sedimentary deposit.[4] Clay deposits are typically associated with very low energy depositional environments such as large lakes and marine basins.		Depending on the academic source, there are three or four main groups of clays: kaolinite, montmorillonite-smectite, illite, and chlorite. Chlorites are not always considered to be a clay, sometimes being classified as a separate group within the phyllosilicates. There are approximately 30 different types of "pure" clays in these categories, but most "natural" clay deposits are mixtures of these different types, along with other weathered minerals.		Varve (or varved clay) is clay with visible annual layers, which are formed by seasonal deposition of those layers and are marked by differences in erosion and organic content. This type of deposit is common in former glacial lakes. When fine sediments are delivered into the calm waters of these glacial lake basins away from the shoreline, they settle to the lake bed. The resulting seasonal layering is preserved in an even distribution of clay sediment banding.[4]		Quick clay is a unique type of marine clay indigenous to the glaciated terrains of Norway, Canada, Northern Ireland, and Sweden. It is a highly sensitive clay, prone to liquefaction, which has been involved in several deadly landslides.		Clays exhibit plasticity when mixed with water in certain proportions. However, when dry, clay becomes firm and when fired in a kiln, permanent physical and chemical changes occur. These changes convert the clay into a ceramic material. Because of these properties, clay is used for making pottery, both utilitarian and decorative, and construction products, such as bricks, wall and floor tiles. Different types of clay, when used with different minerals and firing conditions, are used to produce earthenware, stoneware, and porcelain. Prehistoric humans discovered the useful properties of clay. Some of the earliest pottery shards recovered are from central Honshu, Japan. They are associated with the Jomon culture and deposits they were recovered from have been dated to around 14,000 BC.[5]		Clay tablets were the first known writing medium.[6] Scribes wrote by inscribing them with cuneiform script using a blunt reed called a stylus. Purpose-made clay balls were also used as sling ammunition.		Clays sintered in fire were the first form of ceramic. Bricks, cooking pots, art objects, dishware, and even musical instruments such as the ocarina can all be shaped from clay before being fired. Clay is also used in many industrial processes, such as paper making, cement production, and chemical filtering. Clay is also often used in the manufacture of pipes for smoking tobacco. Until the late 20th century, bentonite clay was widely used as a mold binder in the manufacture of sand castings.		Clay, being relatively impermeable to water, is also used where natural seals are needed, such as in the cores of dams, or as a barrier in landfills against toxic seepage (lining the landfill, preferably in combination with geotextiles).[7] (See Puddling.)		Studies in the early 21st century have investigated clay's absorption capacities in various applications, such as the removal of heavy metals from waste water and air purification.[8][9]		Traditional uses of clay as medicine go back to prehistoric times. An example is Armenian bole, which is used to soothe an upset stomach, similar to the way parrots (and later, humans) in South America originally used clay.[10] Kaolin clay and attapulgite have been used as anti-diarrheal medicines.		Clay is one of the oldest building materials on Earth, among other ancient, naturally-occurring geologic materials such as stone and organic materials like wood.[11] Between one-half and two-thirds of the world's population, in both traditional societies as well as developed countries, still live or work in buildings made with clay, often baked into brick, as an essential part of its load-bearing structure. Also a primary ingredient in many natural building techniques, clay is used to create adobe, cob, cordwood, and rammed earth structures and building elements such as wattle and daub, clay plaster, clay render case, clay floors and clay paints and ceramic building material. Clay was used as a mortar in brick chimneys and stone walls where protected from water.		
Gambling is the wagering of money or something of value (referred to as "the stakes") on an event with an uncertain outcome with the primary intent of winning money or material goods. Gambling thus requires three elements be present: consideration, chance and prize.[1] The outcome of the wager is often immediate, such as a single roll of dice, a spin of a roulette wheel, or a horse crossing the finish line, but longer time frames are also common, allowing wagers on the outcome of a future sports contest or even an entire sports season.		The term gaming[2] in this context typically refers to instances in which the activity has been specifically permitted by law. The two words are not mutually exclusive; i.e., a "gaming" company offers (legal) "gambling" activities to the public[3] and may be regulated by one of many gaming control boards, for example, the Nevada Gaming Control Board. However, this distinction is not universally observed in the English-speaking world. For instance, in the United Kingdom, the regulator of gambling activities is called the Gambling Commission (not the Gaming Commission).[4] The word gaming is used more frequently since the rise of computer and video games to describe activities that do not necessarily involve wagering, especially online gaming, with the new usage still not having displaced the old usage as the primary definition in common dictionaries.		Gambling is also a major international commercial activity, with the legal gambling market totaling an estimated $335 billion in 2009.[5] In other forms, gambling can be conducted with materials which have a value, but are not real money. For example, players of marbles games might wager marbles, and likewise games of Pogs or Magic: The Gathering can be played with the collectible game pieces (respectively, small discs and trading cards) as stakes, resulting in a meta-game regarding the value of a player's collection of pieces.						Many popular games played in modern casinos originate from Europe and China.[6] Games such as craps, baccarat, roulette, and blackjack originate from different areas of Europe. A version of keno, an ancient Chinese lottery game, is played in casinos around the world. In addition, pai gow poker, a hybrid between pai gow and poker is also played.[7]		Many jurisdictions, local as well as national, either ban gambling or heavily control it by licensing the vendors. Such regulation generally leads to gambling tourism and illegal gambling in the areas where it is not allowed. The involvement of governments, through regulation and taxation, has led to a close connection between many governments and gaming organizations, where legal gambling provides significant government revenue, such as in Monaco or Macau, China.		There is generally legislation requiring that the odds in gaming devices are statistically random, to prevent manufacturers from making some high-payoff results impossible. Since these high-payoffs have very low probability, a house bias can quite easily be missed unless the odds are checked carefully.[8]		Most jurisdictions that allow gambling require participants to be above a certain age. In some jurisdictions, the gambling age differs depending on the type of gambling. For example, in many American states one must be over 21 to enter a casino, but may buy a lottery ticket after turning 18.		Because contracts of insurance have many features in common with wagers, insurance contracts are often distinguished under law as agreements in which either party has an interest in the "bet-upon" outcome beyond the specific financial terms. e.g.: a "bet" with an insurer on whether one's house will burn down is not gambling, but rather insurance — as the homeowner has an obvious interest in the continued existence of his/her home independent of the purely financial aspects of the "bet" (i.e., the insurance policy). Nonetheless, both insurance and gambling contracts are typically considered aleatory contracts under most legal systems, though they are subject to different types of regulation.		Under common law, particularly English Law (English unjust enrichment), a gambling contract may not give a casino bona fide purchaser status, permitting the recovery of stolen funds in some situations. In Lipkin Gorman v Karpnale Ltd, where a solicitor used stolen funds to gamble at a casino, the House of Lords overruled the High Court's previous verdict, adjudicating that the casino return the stolen funds less those subject to any change of position defence. U.S. Law precedents are somewhat similar.[9] For case law on recovery of gambling losses where the loser had stolen the funds see "Rights of owner of stolen money as against one who won it in gambling transaction from thief".[10]		An interesting wrinkle to these fact pattern is to ask what happens when the person trying to make recovery is the gambler's spouse, and the money or property lost was either the spouse's, or was community property. This was a minor plot point in a Perry Mason novel, The Case of the Singing Skirt, and it cites an actual case Novo v. Hotel Del Rio.[11]		Religious perspectives on gambling have been mixed. Ancient Hindu poems like the Gambler's Lament and the Mahabharata testify to the popularity of gambling among ancient Indians. However, the text Arthashastra (c. 4th century BCE) recommends taxation and control of gambling.[12] Ancient Jewish authorities frowned on gambling, even disqualifying professional gamblers from testifying in court.[13]		The Catholic Church holds the position that there is no moral impediment to gambling, so long as it is fair, all bettors have a reasonable chance of winning, that there is no fraud involved, and the parties involved do not have actual knowledge of the outcome of the bet (unless they have disclosed this knowledge).[14] Gambling has often been seen as having social consequences, as satirized by Balzac. For these social and religious reasons, most legal jurisdictions limit gambling, as advocated by Pascal.[15] as long as the following conditions are met; the gambler can afford losing the bet, stops when the limit is reached, and the motivation is entertainment and not personal gain leading to the "love of money"[16] or making a living.[17] In general, Catholic bishops have opposed casino gambling on the grounds it too often tempts people into problem gambling or addiction, has particularly negative effects on poor people; they sometimes also cite secondary effects such as increases in loan sharking, prostitution, corruption, and general public immorality.[18][19][20] In at least one case, the same bishop opposing a casino has sold land to be used for its construction.[21] Some parish pastors have also opposed casinos for the additional reason that they would take customers away from church bingo and annual festivals where games such as blackjack, roulette, craps, and poker are used for fundraising.[22]		Although different interpretations of Shari‘ah (Islamic Law) exist in the Muslim world, there is a consensus among the ‘Ulema’ (Arabic: عُـلـمـاء‎‎, Scholars (of Islam)) that gambling is haraam (Arabic: حَـرام‎‎, sinful or forbidden). In assertions made during its prohibition, Muslim jurists describe gambling as being both un-Qur’anic, and as being generally harmful to the Muslim Ummah (Arabic: أُمَّـة‎‎, Community). The Islamic terminology for gambling is Maisir, however this also has a second definition meaning easy money.[23] In parts of the world that implement full Shari‘ah, such as Aceh, punishments for Muslim gamblers can range up to 12 lashes or a one-year prison term and a fine for those who provide a venue for such practises.[24] Some Islamic nations prohibit gambling; most other countries regulate it.[25]		While almost any game can be played for money, and any game typically played for money can also be played just for fun, some games are generally offered in a casino setting.		Gambling games that take place outside of casinos include Bingo (as played in the US and UK), dead pool, lotteries, pull-tab games and scratchcards, and Mahjong.		Other non-casino gambling games include:		*Although coin tossing isn't usually played in a casino, it has been known to be an official gambling game in some Australian casinos[26]		Fixed-odds betting and Parimutuel betting frequently occur at many types of sporting events, and political elections. In addition many bookmakers offer fixed odds on a number of non-sports related outcomes, for example the direction and extent of movement of various financial indices, the winner of television competitions such as Big Brother, and election results.[27] Interactive prediction markets also offer trading on these outcomes, with "shares" of results trading on an open market.		One of the most widespread forms of gambling involves betting on horse or greyhound racing. Wagering may take place through parimutuel pools, or bookmakers may take bets personally. Parimutuel wagers pay off at prices determined by support in the wagering pools, while bookmakers pay off either at the odds offered at the time of accepting the bet; or at the median odds offered by track bookmakers at the time the race started.		Betting on team sports has become an important service industry in many countries. For example, millions of people play the football pools every week in the United Kingdom. In addition to organized sports betting, both legal and illegal, there are many side-betting games played by casual groups of spectators, such as NCAA Basketball Tournament Bracket Pools, Super Bowl Squares, Fantasy Sports Leagues with monetary entry fees and winnings, and in-person spectator games like Moundball.		Arbitrage betting is a theoretically risk-free betting system in which every outcome of an event is bet upon so that a known profit will be made by the bettor upon completion of the event, regardless of the outcome. Arbitrage betting is a combination of the ancient art of arbitrage trading and gambling, which has been made possible by the large numbers of bookmakers in the marketplace, creating occasional opportunities for arbitrage.		One can also bet with another person that a statement is true or false, or that a specified event will happen (a "back bet") or will not happen (a "lay bet") within a specified time. This occurs in particular when two people have opposing but strongly held views on truth or events. Not only do the parties hope to gain from the bet, they place the bet also to demonstrate their certainty about the issue. Some means of determining the issue at stake must exist. Sometimes the amount bet remains nominal, demonstrating the outcome as one of principle rather than of financial importance.		Betting exchanges allow consumers to both back and lay at odds of their choice. Similar in some ways to a stock exchange, a bettor may want to back a horse (hoping it will win) or lay a horse (hoping it will lose, effectively acting as bookmaker).		Many betting systems have been created in an attempt to "beat the house" but no system can make a mathematically unprofitable bet in terms of expected value profitable over time. Widely used systems include:		Many risk-return choices are sometimes referred to colloquially as "gambling."[28] Whether this terminology is acceptable is a matter of debate:		Investments are also usually not considered gambling, although some investments can involve significant risk. Examples of investments include stocks, bonds and real estate. Starting a business can also be considered a form of investment. Investments are generally not considered gambling when they meet the following criteria:		Some speculative investment activities are particularly risky, but are sometimes perceived to be different from gambling:		Studies show that though many people participate in gambling as a form of recreation or even as a means to gain an income, gambling, like any behavior that involves variation in brain chemistry, can become a harmful, behavioral addiction. Behavioral addiction can occur with all the negative consequences in a person's life minus the physical issues faced by people who compulsively engage in drug and alcohol abuse.[29] Reinforcement schedules may also make gamblers persist in gambling even after repeated losses.[medical citation needed]		The Russian writer and problem gambler Fyodor Dostoevsky portrays in his novella The Gambler the psychological implications of gambling and how gambling can affect gamblers. He also associates gambling and the idea of "getting rich quick", suggesting that Russians may have a particular affinity for gambling. Dostoevsky shows the effect of betting money for the chance of gaining more in 19th-century Europe. The association between Russians and gambling has fed legends of the origins of Russian roulette. There are many symptoms and reasons for gambling. Gamblers gamble more money to try and win back money that they have lost and some gamble to relieve feelings of helplessness and anxiety.[30]		Gamblers exhibit a number of cognitive and motivational biases that distort the perceived odds of events and that influence their preferences for gambles. For example, gambler exhibit a costly aversion to betting against their favorite team or political candidate.[31]		
Silt is granular material of a size between sand and clay, whose mineral origin is quartz[1] and feldspar. Silt may occur as a soil (often mixed with sand or clay) or as sediment mixed in suspension with water (also known as a suspended load) and soil in a body of water such as a river. It may also exist as soil deposited at the bottom of a water body, like mudflows from landslides. Silt has a moderate specific area with a typically non-sticky, plastic feel. Silt usually has a floury feel when dry, and a slippery feel when wet. Silt can be visually observed with a hand lens.						Silt is created by a variety of physical processes capable of splitting the generally sand-sized quartz crystals of primary rocks by exploiting deficiencies in their lattice.[2] These involve chemical weathering of rock[3] and regolith, and a number of physical weathering processes such as frost shattering[4] and haloclasty.[5] The main process is abrasion through transport, including fluvial comminution, aeolian attrition and glacial grinding.[6] It is in semi-arid environments[7] that substantial quantities of silt are produced. Silt is sometimes known as "rock flour" or "stone dust", especially when produced by glacial action. Mineralogically, silt is composed mainly of quartz and feldspar. Sedimentary rock composed mainly of silt is known as siltstone. Liquefaction created by a strong earthquake is silt suspended in water that is hydrodynamically forced up from below ground level.		In the Udden–Wentworth scale (due to Krumbein), silt particles range between 0.0039 and 0.0625 mm, larger than clay but smaller than sand particles. ISO 14688 grades silts between 0.002 mm and 0.063 mm. In actuality, silt is chemically distinct from clay, and unlike clay, grains of silt are approximately the same size in all dimensions; furthermore, their size ranges overlap. Clays are formed from thin plate-shaped particles held together by electrostatic forces, so present a cohesion. According to the U.S. Department of Agriculture Soil Texture Classification system, the sand-silt distinction is made at the 0.05 mm particle size.[8] The USDA system has been adopted by the Food and Agriculture Organization (FAO). In the Unified Soil Classification System (USCS) and the AASHTO Soil Classification system, the sand-silt distinction is made at the 0.075 mm particle size (i.e., material passing the #200 sieve). Silts and clays are distinguished mechanically by their plasticity.		Silt is easily transported in water or other liquid and is fine enough to be carried long distances by air in the form of dust. Thick deposits of silty material resulting from deposition by aeolian processes are often called loess. Silt and clay contribute to turbidity in water. Silt is transported by streams or by water currents in the ocean. When silt appears as a pollutant in water the phenomenon is known as siltation.		Silt, deposited by annual floods along the Nile River, created the rich, fertile soil that sustained the Ancient Egyptian civilization. Silt deposited by the Mississippi River throughout the 20th century has decreased due to a system of levees, contributing to the disappearance of protective wetlands and barrier islands in the delta region surrounding New Orleans.[9]		In south east Bangladesh, in the Noakhali district, cross dams were built in the 1960s whereby silt gradually started forming new land called "chars". The district of Noakhali has gained more than 28 square miles (73 km2) of land in the past 50 years.		With Dutch funding, the Bangladeshi government began to help develop older chars in the late 1970s, and the effort has since become a multi-agency operation building roads, culverts, embankments, cyclone shelters, toilets and ponds, as well as distributing land to settlers. By fall 2010, the program will have allotted some 27,000 acres (100 km2) to 21,000 families.[10]		A main source of silt in urban rivers is disturbance of soil by construction activity.[citation needed] A main source in rural rivers is erosion from plowing of farm fields, clearcutting or slash and burn treatment of forests.[citation needed]		The fertile black silt of the Nile river's banks is a symbol of rebirth, associated with the Egyptian god Anubis.[11]		
A wave-cut platform, coastal benches, or wave-cut benches is the narrow flat area often found at the base of a sea cliff or along the shoreline of a lake, bay, or sea that was created by[citation needed] the erosion of waves. Wave-cut platforms are often most obvious at low tide when they become visible as huge areas of flat rock. Sometimes the landward side of the platform is covered by sand, forming the beach, and then the platform can only be identified at low tides or when storms move the sand.						Wave-cut platforms form when destructive waves hit against the cliff face, causing undercutting between the high and low water marks, mainly as a result of corrosion and hydraulic power, creating a wave-cut notch. This notch then enlarges into a cave. The waves undermine this portion until the roof of the cave cannot hold due to the pressure and freeze-thaw weathering acting on it, and collapses, resulting in the cliff retreating landward. The base of the cave forms the wave-cut platform as attrition causes the collapsed material to be broken down into smaller pieces, while some cliff material may be washed into the sea. This may be deposited at the end of the platform, forming an off-shore terrace.		Because of the continual wave action, a wave-cut platform represents an extremely hostile environment and only the toughest of organisms can utilize such a niche.		Ancient wave-cut platforms provide evidence of past sea and lake levels. Raised and abandoned platforms, sometimes found behind modern beaches, are evidence of higher sea levels in the geological past,[1] and have been used to identify areas of isostatic adjustment. By using scientific dating methods, or examination of marine fossils found on the platform, it is possible to work out when the platform was formed, thus giving geographers and geologists information about sea levels at known times in the past. This has been used in the United Kingdom and other previously glaciated areas to calculate the rate at which land is rising now that it is no longer covered in ice.		Where the coastline itself is changing due to seismic action, there may be a series of platforms showing earlier sea levels and indicating the amount of uplift caused by various earthquakes.		According to Trenhaile,[2] Sunamura,[3] and Massalink and Hughes,[4] the term 'wave-cut platform' should no longer be used as it assumes that shore platforms are the result of wave action, which is not always true. Shore platforms, like comparable river and lake platforms, are erosional features that develop when removal of saprock and other debris by waves and currents leaves behind a bedrock surface below the water table.[5]		Raised beach and shore platform, Bleik, Norway		Shore platforms from Lake Bonneville (Pleistocene), Utah, USA.		Shore platform at St Bees Head, UK.		Jurassic wave-cut platform at Tedbury Camp, southern England.		
A rocky shore is an intertidal area of seacoasts where solid rock predominates. Rocky shores are biologically rich environments, and are a useful "natural laboratory" for studying intertidal ecology and other biological processes. Due to their high accessibility, they have been well studied for a long time and their species are well known.[1][2]						There are a large number of factors that favour the survival of life on rocky shores. Temperate coastal waters are mixed by waves and convection, maintaining adequate availability of nutrients. Also, the sea brings plankton and broken organic matter in with each tide. The high availability of light (due to low depths) and nutrient levels means that primary productivity of seaweeds and algae can be very high. Human actions can also benefit rocky shores due to nutrient runoff.		Despite these favourable factors, there are also a number of challenges to marine organisms associated with the rocky shore ecosystem. Generally, the distribution of benthic species is limited by salinity, wave exposure, temperature, desiccation and general stress. The constant threat of desiccation during exposure at low tide can result in dehydration. Hence, many species have developed adaptations to prevent this drying out, such as the production of mucous layers and shells. Many species use shells and holdfasts to provide stability against strong wave actions. There are also a variety of other challenges such as temperature fluctuations due to tidal flow (resulting in exposure), changes in salinity and various ranges of illumination. Other threats include predation from birds and other marine organisms, as well as the effects of pollution.		The Ballantine Scale is a biologically defined scale for measuring the degree of exposure level of wave action on a rocky shore. Devised in 1961 by W. J. Ballantine, then at the zoology department of Queen Mary College, London, U.K., the scale is based on the observation that where shoreline species are concerned "Different species growing on rocky shores require different degrees of protection from certain aspects of the physical environment, of which wave action is often the most important." The species present in the littoral zone therefore indicate the degree of the shore's exposure.[3] The scale runs from (1) an "extremely exposed" shore, to (8) an "extremely sheltered" shore.		Tidal movements of water creates zonation patterns along rocky shores from high to low-tide.[4] The area above the high-tide mark is the supralittoral zone which is virtually a terrestrial environment. The area around the high-tide mark is known as the intertidal fringe. Between the high and low-tide marks is the intertidal or littoral zone. Below the low-tide mark is the sublittoral or subtidal zone. The presence and abundance of different animals and algae vary in different zones along the rocky shore due to differing adaptations to the varying levels of exposure to sun and desiccation along the rocky shore.		Rocky shores are exposed to many forms of pollution, in particular pollution related to oil spills. Prominent spills are the Torrey Canyon spill,[5] The Amoco Cadiz spill outside the Brittany coast in France[6] and the Exxon Valdez spill in Prince William Sound, Alaska, USA. Garbage such as plastics and metals being left behind by people is also a problem among many rocky coastlines that attract tourists.		
North Pier is the most northerly of the three coastal piers in Blackpool, England. Built in the 1860s, it is also the oldest and longest of the three. Although originally intended only as a promenade, competition forced the pier to widen its attractions to include theatres and bars. Unlike Blackpool's other piers, which attracted the working classes with open air dancing and amusements, North Pier catered for the "better-class" market, with orchestra concerts and respectable comedians. Until 2011, it was the only Blackpool pier that consistently charged admission.		The pier is designated by English Heritage as a Grade II listed building, due to its status as the oldest surviving pier created by Eugenius Birch. As of 2015 it is still in regular use, despite having suffered damage from fires, storms and collisions with boats. Its attractions include bars, a theatre, a carousel and an arcade. One of the oldest remaining Sooty glove puppets is on display commemorating Harry Corbett buying the original puppet there.						North Pier was built at the seaward end of Talbot Road, where the town's first railway station, Blackpool North, was built.[1] Its name reflects its location as the most northerly of Blackpool's three piers. It is about 450 yards (410 m) north of Blackpool Tower, which is roughly the midpoint of Blackpool's promenade. The sea front is particularly straight and flat on this stretch of coastline, and the 550 yards (500 m) pier[1] extends at right angles into the Irish Sea, more or less level with the promenade.		The construction of Blackpool Pier (eventually North Pier) started in May 1862, in Layton-cum-Warbreck, part of the parish of Bispham.[2] In October 1862 severe storms suggested that the planned height of the pier was insufficient, and it was increased by 3 feet (0.91 m).[2] North Pier was the second of fourteen piers designed by Eugenius Birch, and since Margate Pier was destroyed by a storm in 1978, it is the oldest of the remaining examples of his work still in use.[3] It was the first of Birch's piers to be built by Glasgow engineering firm Richard Laidlaw and Son.[2]		The pier, which cost £11,740 to build,[4] originally consisted of a promenade 468 yards (428 m) long and 9 yards (8.2 m) wide, extending to 18 yards (16 m) wide at the pier-head. The bulk of the pier was constructed from cast iron, with a wooden deck laid on top. The cast iron piles on which the structure rests were inserted using Birch's screw pile process; the screw-tipped piles were twisted into the sand until they hit bedrock. This made construction much quicker and easier, and guaranteed that the pier had a solid foundation.[5] The cast iron columns, 12 inches (300 mm) in diameter, were filled with concrete for stability at intervals of 20 yards (18 m), and supported by struts that were on average were slightly more than 1 inch (25 mm) thick.[2] The pier's promenade deck is lined with wooden benches with ornamental cast iron backs. At intervals along the pier are hexagonal kiosks built around 1900 in wood and glass with minaret roofs topped with decorative finials.[6] On opening two of the kiosks were occupied by a bookstall and confectionery stall and the kiosks near the ends of the pier were seated shelters.[4] The pier-head is a combination of 420 tons of cast iron and 340 tons of wrought iron[4] columns; standing 50 feet (15 m) above the low water line, it sees a regular 35 feet (11 m) change in sea level due to the tide.[2]		The pier was officially opened in a grand ceremony on 21 May 1863, even though the final 50 yards (46 m) had not yet been completed. All the shops in the area were closed and decorated with flags and streamers[4] for the ceremony, which included a procession and a cannon salute, and was attended by more than 20,000 visitors.[7] Although the town only had a population of approximately 4,000, more than 200,000 holiday makers regularly stayed there during the summer months;[2] this included 275,000 admissions in 1863, 400,000 in 1864 and 465,000 the following year.[4] The pier was officially opened by Major Preston, and he and 150 officials then travelled to the Clifton Hotel for a celebratory meal.[4]		The pier was intended primarily for leisure rather than seafaring; for the price of 2d (worth approximately £4.90 in 2012)[note 1] the pier provided the opportunity for visitors to walk close to the sea without distractions.[8] This fee was insufficient to deter "trippers'", which led to Major Preston campaigning for a new pier to cater for the 'trippers'.[4] In 1866, the government agreed that a second pier could be built, despite objections from the Blackpool Pier Company that it was close to their pier and therefore unnecessary.[9]		As permitted by the original parliamentary order, a landing jetty was built at the end of North Pier in incremental stages between 1864 and 1867. The full length of the jetty was 158 yards (144 m), and the extensions increased the pier's total length to its current 550 yards (500 m).[1] The Blackpool Pier Company used the jetty to operate pleasure steamers that made trips to the surrounding areas.[1][10] In 1871 swimming and diving lessons were added to the pier.[4]		In 1874, the pier-head was extended to allow Richard Knill Freeman to incorporate a pavilion, which opened in 1877.[10] The interior decoration led it to be known as the "Indian Pavilion", and it was Blackpool's primary venue for indoor entertainment until the Winter Gardens opened in 1879.[11]		To differentiate itself from the new pier, North Pier focused on catering for the "better classes", charging for entry and including attractions such as an orchestra[12] and band concerts,[4] in contrast to the Central Pier (or the "People's pier"), which regularly had music playing and open-air dancing.[13] The pier owners highlighted the difference, charging at least a shilling (worth approximately £19.90 in 2012)[note 2] for concerts and ensuring that advertisements for comedians focused on their lack of vulgarity. Sundays were given over to a church parade.[14]		On 8 October 1892, a storm-damaged vessel, Sirene, hit the southern side of the pier, causing four shops and part of the deck to collapse onto the beach below. Several columns were also dislodged, and the ship's bowsprit hit the pier entrance. All eleven crew members were rescued when they were hauled onto the pier. Damage to the pier was estimated to be £5,000 and was promptly repaired.[4]		Nelson's former flagship, HMS Foudroyant, was moored alongside North Pier for an exhibition, but slipped anchor and was wrecked on the shore in a violent storm on 16 June 1897, damaging part of the jetty. The wreck of the ship broke up during December storms.[15]		The pier was closed for the winter during 1895–96 as it unsafe; as a result, the pier was widened as electric lighting was added.[4]		An Arcade Pavilion was added in 1903 at the entrance to the pier and contained a wide range of amusements to suit all tastes. Further alterations were made to the pier in 1932-33 when the open air stand was replaced with a stage and sun lounge.[4]		In 1936, a pleasure steamer returning from Llandudno crashed into the pier. The collision left a 10 feet (3.0 m) gap, and stranded a number of people at the far end.[16]		The 1874 Indian Pavilion was severely damaged by fire in 1921. It was refurbished, but was then destroyed by a second fire in 1938. In 1939 it was replaced by a theatre, built in an Art Deco style.[1][17] At around the same time, the bandstand was removed and replaced with a sun lounge.		In the 1960s, the Merrie England bar and an amusement arcade were constructed at the end of the pier nearest to the shore. The 1939 theatre, which is still in use, narrowly escaped damage in 1985 when the early stages of a fire were noticed by performer Vince Hill. In the 1980s, a Victorian-styled entrance was built. In 1991 the pier gained the Carousel bar as an additional attraction, and a small tramway to ease access to the pier-head.[18] By this point, the pier had ceased to have any nautical use, but the jetty section was adapted for use as a helicopter pad in the late 1980s.[1] The Christmas Eve storm of 1997 destroyed the landing jetty, including the helipad.[19]		The North Pier is one of the few remaining examples of Birch's classic pier architecture and is a Grade II Listed building, the only Blackpool pier to hold that status.[6][20] It was recognised as "Pier of the Year" in 2004 by the National Piers Society.[21]		North Pier's attractions include a Gypsy palm reader and an ice cream parlour, the North Pier Theatre, a Victorian tea room, and the Carousel and Merrie England bars. The arcade, built in the 1960s, has approximately eleven million coins pass through its machines each year.[22]		One of the earliest Sooty bear puppets used by Harry Corbett is on display on the pier. Corbett bought the original Sooty puppet on North Pier for his son, Matthew. When Corbett took the puppet on BBC's Talent Night programme, he marked the nose and ears with soot so that they would show up on the black and white television, giving the puppet its name.[23]		The Carousel bar on the pier-head has a Victorian wrought iron canopy, and its outdoor sun-lounge is classified as the largest beer garden in Blackpool. Next to the bar is a two tier carousel, the "Venetian Carousel", which is protected from sand and spray by a glass wall.[24]		After the fire in 1938, the pavilion was replaced with a 1,564 seat theatre which has since hosted a number of acts including; Frankie Vaughan, Frank Randle, Tessie O'Shea, Dave Morris, Bernard Delfont, Morecambe and Wise, Paul Daniels, Freddie Starr, Russ Abbot, Bruce Forsyth, Des O'Connor, Joe Longthorne, Lily Savage, Brian Conley and Hale and Pace.[4]		In 2002 a heritage room with photographs was opened up, the foyer entrance was refurbished and a disabled lift added. By 2005, there was no longer a live organist playing in the sun lounge although other live entertainment continues.[4] In 2013, the live organist was brought back into the sun lounge.		The pier was built and owned by the Blackpool Pier Company, created with three thousand £5-shares in 1861 (worth approximately £2,990 in 2012).[note 3] The same firm operated the pier in 1953,[25] and the company was incorporated in 1965.[26] The Resorts Division of First Leisure, including the pier, was sold to Leisure Parks for £74 million in 1998.[4] In 2009, the pier was sold to the Six Piers group, which owns Blackpool's other two piers, and hoped to use it as a more tranquil alternative to them.[27] The new owners opened the Victorian-themed tea room, and built an eight-seat shuttle running the length of the pier.[28]		In April 2011, the pier was sold to a Blackpool family firm, Sedgwick's, the owners of amusement arcades and the big wheel on Blackpool's Central Pier. Peter Sedgwick explained that he proposed to his wife on North Pier forty years ago, and promised to buy it for her one day.[29] He said that he wants to restore the Victorian heritage of the pier and re-instate the pier's tram. An admission charge of fifty pence to access the board-walk section of the pier was abolished by the Sedgwicks.[30]		A petition to wind up the Northern Victorian Pier Limited (the company used by the Sedgwick family to manage Blackpool North Pier) was presented on 17 September 2012 by Carlsberg UK Limited, a creditor of the company, and this was to be heard at Blackpool County Court on 15 November 2012.[31]		At the 11th hour, an agreement to pay the outstanding balance owed to Carlsberg was made and Peter Sedgwick's company escaped liquidation.[32]		
Seashore wildlife habitats exist from the Tropics to the Arctic and Antarctic. Seashores and beaches provide varied habitats in different parts of the world, and even within the same beach. Phytoplankton is at the bottom of some food chains, while zooplankton and other organisms eat phytoplankton. Kelp is also autotrophic and at the bottom of many food chains. Coastal areas are stressed through rapid changes, for example due to tides.						The coasts round Britain and the sea nearby is of international significance. Animal life varies from large whales, dolphins and porpoises, grey seals and common seals, through to microscopic animals. There are more than 200 species of fish, ranging from small fish like blennies through to basking sharks that are the second largest shark in the world.		Habitats include areas of landslips, beaches with sand, shingle and rock, cliffs, coastal lagoons, isolated sea stacks and islands, muddy estuaries, salt marshes, submaritime zones (i.e. land influenced by sea spray) and the sea itself. British coasts are affected by strong winds and in some areas large waves. British tidal ranges are large compared to some other parts of the world. Sheltered shores support different life from exposed shores. [1] [2]		Non-flowering plants range from microscopic plants through to seaweed or kelp up to 5 meters in height. Many animals feed on kelp and kelp provides sheltered habitats for yet others. Sea grass is the only type of flowering plant that grows in British seas, but it nonetheless forms vast beds.		Invertebrates in coastal Britain are very diverse and include brittle stars, hermit crabs, mussels, prawns, sponges, sea anemones and sea squirts. Efforts are made to conserve rare plants and animals in Nature reserves.		Cliffs, islands and sea stacks are a habitat for breeding sea birds such as guillemots, kittiwakes and razor bills, as well as rock doves which can live inland as well. Peregrine falcons hunt the doves. Estuaries provide a habitat for waders and ducks, especially in winter.		The coasts round Britain and the sea nearby is of international significance. Animal life varies from large whales, dolphins and porpoises, grey seals and common seals, through to microscopic animals. There are more than 200 species of fish, ranging from small fish like blennies through to basking sharks that are the second largest shark in the world.		Habitats include areas of landslips, beaches with sand, shingle and rock, cliffs, coastal lagoons, isolated sea stacks and islands, muddy estuaries, salt marshes, submaritime zones (i.e. land influenced by sea spray) and the sea itself. British coasts are affected by strong winds and in some areas large waves. British tidal ranges are large compared to some other parts of the world. Sheltered shores support different life from exposed shores. [3] [4]		Non-flowering plants range from microscopic plants through to seaweed or kelp up to 5 meters in height. Many animals feed on kelp and kelp provides sheltered habitats for yet others. Sea grass is the only type of flowering plant that grows in British seas, but it nonetheless forms vast beds.		Invertebrates in coastal Britains are very diverse and include brittle stars, hermit crabs, mussels, prawns, sponges, sea anemones and sea squirts. Efforts are made to conserve rare plants and animals in Nature reserves.		Cliffs, islands and sea stacks are a habitat for breeding sea birds such as guillemots, kittiwakes and razor bills, as well as rock doves which can live inland as well. Peregrine falcons hunt the doves. Estuaries provide a habitat for waders and ducks, especially in winter.		
Hippoidea is a superfamily of decapod crustaceans known as sand crabs, mole crabs, or sand fleas.[1][2][3]						Hippoids are adapted to burrowing into sandy beaches, a habit they share with raninid crabs, and the parallel evolution of the two groups is striking.[4] The whole body is almost ovoid, the first pereiopods have no claws, and the telson is long, none of which are seen in related groups.[5] Unlike most other decapods, sand crabs cannot walk; instead, they use their legs to dig into the sand.[6] Members of the family Hippidae beat their uropods to swim.[6]		Apart from the polar regions, hippoids can be found on beaches throughout the world. Larvae of one species have also been found in Antarctic waters, despite the lack of suitable sandy beaches in the Antarctic.[7]		Alongside hermit crabs and allies (Paguroidea), squat lobsters and allies (Galatheoidea) and the hairy stone crab (Lomis hirta, Lomisoidea), Hippoidea is one of the four groups that make up the infraorder Anomura.[8] Of the four, Hippoidea is thought to be the most basal, with the other three groups being more closely related to each other than to Hippoidea.[9]		The fossil record of sand crabs is sparse,[10] but extends back to the Cretaceous period.[4] Sand crabs are placed in three families (exclusively fossil taxa are marked †):[11][12]		
Marine regression is a geological process occurring when areas of submerged seafloor are exposed above the sea level. The opposite event, marine transgression, occurs when flooding from the sea covers previously exposed land.[1]		Evidence of marine regressions and transgressions occurs throughout the fossil record, and these fluctuations are thought to have caused or contributed to several mass extinctions, among them the Permian-Triassic extinction event (250 million years ago) and Cretaceous–Paleogene extinction event (66 Ma). At the time of the Permian-Triassic extinction, the largest extinction event in the Earth's history, global sea level fell 250 m (820 ft).[2]		A major regression could itself cause marine organisms in shallow seas to go extinct, but mass extinctions tend to involve both terrestrial and aquatic species, and it is harder to see how a marine regression could cause widespread extinctions of land animals. Regressions are, therefore, seen as correlates or symptoms of major extinctions, rather than primary causes. The Permian regression might have been related to the formation of Pangaea: the accumulation of all the major landmasses into one body could have facilitated a regression, by providing "a slight enlargement of the ocean basins as the great continents coalesced."[3] However, that cause could not have applied in all, or even many, other cases.		During the ice ages of the Pleistocene, a clear correlation existed between marine regressions and episodes of glaciation; as the balance shifts between the global cryosphere and hydrosphere, more of the planet's water in ice sheets means less in the oceans. At the height of the last ice age, at around 18,000 years before the present, the global sea level was 120 to 130 m (390-425 ft) lower than today. A cold spell around 6 million years ago was linked to an advance in glaciation, a marine regression, and the start of the Messinian salinity crisis in the Mediterranean basin. Some major regressions of the past, however, seem unrelated to glaciation episodes — the regression that accompanied the mass extinction at the end of the Cretaceous Period being one example.		A clear and certain understanding of major marine regressions has not yet been achieved; according to one hypothesis, regressions may be linked to a "slowdown in sea-floor spreading, leading to a generalized drop in sea level (as the mid-ocean ridges would take up less space)...."[4] In that view, major marine regressions are one aspect of a normal variation in rates of plate tectonic activity, which lead to major episodes of global volcanism like the Siberian Traps and the Deccan Traps, which in turn cause large extinction events.		
Wrack is part of the common names of several species of seaweed in the family Fucaceae. It may also refer more generally to any seaweeds or seagrasses that wash up on beaches and may accumulate in the wrack zone.[1]		It consists largely of species of Fucus — brown seaweeds with flat branched ribbon-like fronds, characterized in F. serratus by a saw-toothed margin and in F. vesiculosus, another common species, by bearing air-bladders. Another component of sea wrack may be seagrasses such as Zostera marina a marine flowering plant with bright green long narrow grass-like leaves.[2] Posidonia australis, which occurs sub-tidally on the southern coasts of Australia, sheds its older ribbon-like leaf blades in winter, resulting in thick accumulations along more sheltered shorelines.		Historically wrack was used for making manure, and for making "kelp",[2] a form of potash.[3]		
An anchialine pool or pond (pronounced "AN-key-ah-lin", from Greek ankhialos, "near the sea") is a landlocked body of water with a subterranean connection to the ocean. Anchialine pools are a feature of coastal aquifers which are density stratified, with the water near the surface being fresh or brackish, and saline water intruding from the coast below at some depth. Depending on the site, it is sometimes possible to access the deeper saline water directly in the anchialine pool or sometimes it may be accessible by cave diving.[1]		Water levels in anchialine pools often fluctuate with tidal changes due to the coastal location and the connection with the ocean.[2] The range in water levels fluctuations will be decreased (damped) and delayed compared to the range and time observed for the adjacent tide. The primary controls on the damping and lag are the distance from the coast, and the hydraulic conductivity of the geological materials.		Anchialine pools are extremely common worldwide especially along neo-tropical coastlines where the geology and aquifer system are relatively young, and there is minimal soil development. Such conditions occur notably where the bedrock is limestone or recently formed volcanic lava. Many anchialine pools are found on the coastlines of the island of Hawaii, and on the Yucatán Peninsula, where they are locally called cenotes, as well as Christmas Island.[3] The Sailor's Hat crater created by an explosives test in 1965 is an anchialine pool.[4]		Ecological studies of anchialine pools frequently identify regionally rare and sometimes endemic species. In Hawaii, the pools are home to the ʻōpaeʻula (Hawaiian shrimp, Halocaridina rubra). In karst anchialine pools and the caves these may be connected to, the fauna are diverse and include crustaceans, including remipedia and copepods, and among the vertebrates are several species of blind cave fish.[5]				
In geology, saltation (from Latin saltus, "leap") is a specific type of particle transport by fluids such as wind or water. It occurs when loose material is removed from a bed and carried by the fluid, before being transported back to the surface. Examples include pebble transport by rivers, sand drift over desert surfaces, soil blowing over fields, and snow drift over smooth surfaces such as those in the Arctic or Canadian Prairies.						At low fluid velocities, loose material rolls downstream, staying in contact with the surface. This is called creep or reptation. Here the forces exerted by the fluid on the particle are only enough to roll the particle around the point of contact with the surface.		Once the wind speed reaches a certain critical value, termed the impact or fluid threshold,[1] the drag and lift forces exerted by the fluid are sufficient to lift some particles from the surface. These particles are accelerated by the fluid, and pulled downward by gravity, causing them to travel in roughly ballistic trajectories.[2] If a particle has obtained sufficient speed from the acceleration by the fluid, it can eject, or splash, other particles in saltation,[3] which propagates the process.[4] Depending on the surface, the particle could also disintegrate on impact, or eject much finer sediment from the surface. In air, this process of saltation bombardment creates most of the dust in dust storms.[5] In rivers, this process repeats continually, gradually eroding away the river bed, but also transporting-in fresh material from upstream.		Suspension generally affects small particles ('small' means ~70 micrometres or less for particles in air[5]). For these particles, vertical drag forces due to turbulent fluctuations in the fluid are similar in magnitude to the weight of the particle. These smaller particles are carried by the fluid in suspension, and advected downstream. The smaller the particle, the less important the downward pull of gravity, and the longer the particle is likely to stay in suspension.				A recent study finds that saltating sand particles induces a static electric field by friction. Saltating sand acquires a negative charge relative to the ground which in turn loosens more sand particles which then begin saltating. This process has been found to double the number of particles predicted by previous theory.[6] This is significant in meteorology because it is primarily the saltation of sand particles which dislodges smaller dust particles into the atmosphere. Dust particles and other aerosols such as soot affect the amount of sunlight received by the atmosphere and earth, and are nuclei for condensation of the water vapour.		Saltation layers can also form in avalanches.		
Long Beach is a city in Pacific County, Washington, United States. The population was 1,392 at the 2010 census.						Long Beach began when Henry Harrison Tinker bought a land claim from Charles E. Reed in 1880. He platted the town and called it "Tinkerville."[7] Long Beach was officially incorporated on January 18, 1922. From 1889 to 1930, a narrow gauge railroad called the Ilwaco Railway and Navigation Company ran up the whole peninsula.		The Long Beach depot was built between First and Second Streets on the east side of the track, which ran north along "B" Street.[8] A major destination in Long Beach was Tinker's Hotel, later renamed the Long Beach Hotel, and built very close to the station. This was the second hotel built at the site by Henry Harrison Tinker, the founder of Long Beach. Tinker's first hotel burned down in 1894. He built another one just a few feet to the east and south of the rail depot.[9] The image in the gallery shows a crowd waiting for the train sometime between 1901 and 1907. Just across the tracks (which doubled in this area)[10] from Tinker's Hotel in Long Beach was the Portland Hotel. The Portland Hotel, owned by the Hanniman family featured an enormous round (and unique) turret-like structure. The Portland Hotel burned down on December 6, 1914, and was not replaced.[9] The Driftwood Hotel was another common Long Beach destination.		The boardwalk area near the station was known as "Rubberneck Row."[11] Businesses existing in August 1911 that can be identified along Rubberneck Row from photographs (see images in this article) include, on the west side of the tracks, an establishment advertising "Baths" (possibly the Crystal Baths, an indoor swimming pool), Milton York Candies, a "Postal Shop," and a soda fountain just across from the station advertising "Milk Shake." A somewhat earlier photograph shows a sign for a livery stable immediately to the west across the tracks from Tinker's Hotel, followed (proceeding southwards) by a barber shop, "Vincent's Souvenirs," and "The Candy Man". A banner stretching above the tracks advertises a restaurant. The photo published by Feagans shows it was produced by H.A. Vincent, Ilwaco and Long Beach, who was probably the owner of Vincent's Souvenirs.[12] Then, in the late 80's, the Marsh's free Museum was made to show people wonders of the northwest.		Long Beach is located at 46°21′3″N 124°3′13″W﻿ / ﻿46.35083°N 124.05361°W﻿ / 46.35083; -124.05361 (46.350959, -124.053643)[13] on the Long Beach Peninsula. According to the United States Census Bureau, the city has a total area of 1.35 square miles (3.50 km2), all of it land.[2]		With a marine west coast-cool summer Mediterranean climate, Long Beach is known for its year round mild climate. Both hot and cold weather is rare. The record high temperature is 99 degrees Fahrenheit on August 10, 1981 and the record low is 0 degrees Fahrenheit on December 8, 1972. Long Beach records nearly 80 inches of rainfall annually. Snow is not as common as rain, but can happen every once in a while.		If a magnitude 9.0 earthquake were to hit the Cascadia subduction zone, emergency planners estimate the first tsunami waves could hit Long Beach 20 to 25 minutes later. At a December 2016 open house, the city government presented initial plans of a proposed 32-foot berm which could potentially accommodate eight-hundred and fifty persons. The structure would have a "modified prow" much like a ship looking out to sea.[15] The shape is also designed to withstand the backwash from a tsunami. The total estimated cost would be $3.4 million of which the Federal Emergency Management Agency (FEMA) would pay 75%, the Emergency Management Division of Washington State 12.5%, and the City of Long Beach 12.5%.[16]		As of the census[3] of 2010, there were 1,392 people, 726 households, and 342 families residing in the city. The population density was 1,031.1 inhabitants per square mile (398.1/km2). There were 1,564 housing units at an average density of 1,158.5 per square mile (447.3/km2). The racial makeup of the city was 91.5% White, 0.1% African American, 0.8% Native American, 1.3% Asian, 0.2% Pacific Islander, 3.7% from other races, and 2.5% from two or more races. Hispanic or Latino of any race were 7.7% of the population.		There were 726 households of which 15.4% had children under the age of 18 living with them, 33.9% were married couples living together, 9.1% had a female householder with no husband present, 4.1% had a male householder with no wife present, and 52.9% were non-families. 44.8% of all households were made up of individuals and 18.8% had someone living alone who was 65 years of age or older. The average household size was 1.85 and the average family size was 2.54.		The median age in the city was 50.1 years. 14.5% of residents were under the age of 18; 8.5% were between the ages of 18 and 24; 20.1% were from 25 to 44; 32.1% were from 45 to 64; and 24.6% were 65 years of age or older. The gender makeup of the city was 47.8% male and 52.2% female.		As of the census[5] of 2000, there were 1,283 people, 660 households, and 314 families residing in the city. The population density was 1,018.7 people per square mile (393.2/km²). There were 1,155 housing units at an average density of 917.1 per square mile (353.9/km²). The racial makeup of the city was 89.87% White, 0.08% African American, 1.09% Native American, 1.40% Asian, 1.56% from other races, and 6.00% from two or more races. Hispanic or Latino of any race were 4.83% of the population. 19.6% were of German, 11.5% Irish, 10.3% English, 6.3% American and 5.7% Norwegian ancestry according to Census 2000.		There were 660 households out of which 17.0% had children under the age of 18 living with them, 34.2% were married couples living together, 11.8% had a female householder with no husband present, and 52.3% were non-families. 43.8% of all households were made up of individuals and 20.5% had someone living alone who was 65 years of age or older. The average household size was 1.92 and the average family size was 2.63.		In the city, the population was spread out with 17.6% under the age of 18, 5.8% from 18 to 24, 23.1% from 25 to 44, 28.9% from 45 to 64, and 24.5% who were 65 years of age or older. The median age was 47 years. For every 100 females there were 81.2 males. For every 100 females age 18 and over, there were 77.9 males.		The median income for a household in the city was $23,611, and the median income for a family was $33,029. Males had a median income of $30,938 versus $20,625 for females. The per capita income for the city was $21,266. About 13.4% of families and 18.7% of the population were below the poverty line, including 19.5% of those under age 18 and 11.4% of those age 65 or over.		Crystal Baths, Long Beach, WA, about 1905, looking south towards Cape Disappointment (high land in background)		Long Beach, WA, July 1909 "Rubberneck Row," looking north towards depot (building with 2 windows in distance just to right of telegraph pole)		Waiting for train, Long Beach, WA, August 1911, looking south, probably from depot window or roof		Tinker's Hotel, Long Beach, WA, looking east		Long Beach (formerly Tinker's Hotel), April 1953		Breakers Hotel, Long Beach, WA, looking east from beach		Breakers Hotel looking west		Jake the Alligator Man at Marsh's Free Museum in Long Beach		The Whale Skeleton on the Long Beach Trail		Marsh's Free Museum		Long Beach police station		World's largest chopsticks		
Terns are seabirds in the family Laridae that have a worldwide distribution and are normally found near the sea, rivers, or wetlands. Terns are treated as a subgroup of the family Laridae which includes gulls and skimmers and consist of eleven genera. They are slender, lightly built birds with long, forked tails, narrow wings, long bills, and relatively short legs. Most species are pale grey above and white below, with a contrasting black cap to the head, but the marsh terns, the Inca tern, and some noddies have dark plumage for at least part of the year. The sexes are identical in appearance, but young birds are readily distinguishable from adults. Terns have a non-breeding plumage, which usually involves a white forehead and much-reduced black cap.		The terns are birds of open habitats that typically breed in noisy colonies and lay their eggs on bare ground with little or no nest material. Marsh terns construct floating nests from the vegetation in their wetland habitats, and a few species build simple nests in trees, on cliffs or in crevices. The white tern, uniquely, lays its single egg on a bare tree branch. Depending on the species, one to three eggs make up the clutch. Most species feed on fish caught by diving from flight, but the marsh terns are insect-eaters, and some large terns will supplement their diet with small land vertebrates. Many terns are long-distance migrants, and the Arctic tern may see more daylight in a year than any other animal.		Terns are long-lived birds and are relatively free from natural predators and parasites; most species are declining in numbers due directly or indirectly to human activities, including habitat loss, pollution, disturbance, and predation by introduced mammals. The Chinese crested tern is in a critical situation and three other species are classed as endangered. International agreements provide a measure of protection, but adults and eggs of some species are still used for food in the tropics. The eggs of two species are eaten in the West Indies because they are believed to have aphrodisiac properties.						The Charadriiformes order of birds contains 18 coastal seabird and wader families. Within the order, the terns form a lineage with the gulls, and, less closely, with the skimmers, skuas, and auks.[1][2] Early authors such as Conrad Gessner, Francis Willughby, and William Turner did not clearly separate terns from gulls,[3] but Linnaeus recognised the distinction in his 1758 Systema Naturae, placing the gulls in the genus Larus and the terns in Sterna. He gave Sterna the description rostrum subulatum, "awl-shaped bill", referring to the long, pointed bills typical of this group of birds, a feature that distinguishes them from the thicker-billed gulls.[4][5][6] Behaviour and morphology suggest that the terns are more closely related to the gulls than to the skimmers or skuas, and although Charles Lucien Bonaparte created the family Sternidae for the terns in 1838, for many years they were considered to be a subfamily, Sterninae, of the gull family, Laridae. Relationships between various tern species, and between the terns and the other Charadriiformes, were formerly difficult to resolve because of a poor fossil record and the misidentification of some finds.[7][8]		Following genetic research in the early twenty-first century, the terns were historically treated as a separate family: Sternidae.[9][10] Most terns were formerly treated as belonging to one large genus, Sterna, with just a few dark species placed in other genera; in 1959, only the noddies and the Inca tern were excluded from Sterna.[11][12] A recent analysis of DNA sequences supported the splitting of Sterna into several smaller genera.[12][13] One study of part of the cytochrome b gene sequence found a close relationship between terns and a group of waders in the suborder Thinocori.[14] These results are in disagreement with other molecular and morphological studies, and have been interpreted as showing either a large degree of molecular convergent evolution between the terns and these waders, or the retention of an ancient genotype.[9]		The word "stearn" was used for these birds in Old English as early as the eighth century, and appears in the poem The Seafarer, written in the ninth century or earlier. Variants such as "tearn" occurred by the eleventh century, although the older form lingered on in Norfolk dialect for several centuries.[3] As now, the term was used for the inland black tern as well as the marine species.[15][16] Some authorities consider "tearn" and similar forms to be variants of "stearn",[3] while others derive the English words from Scandinavian equivalents such as Danish and Norwegian terne or Swedish tärna, and ultimately from Old Norse þerna.[17][18] Linnaeus adopted "stearn" or "sterna" (which the naturalist William Turner had used in 1544 as a Latinisation of an English word, presumably "stern", for the black tern)[19][20] or a North Germanic equivalent for his genus name Sterna.[21]		The cladogram shows the relationships between the tern genera, and the currently recognised species, based on mitochondrial DNA studies, are listed below:[13]		Anous		Gygis		Onychoprion		Sternula		Phaetusa		Phaetusa		Gelochelidon		Hydroprogne		Chlidonias		Thalasseus		Sterna		In addition to extant species, the fossil record includes a Miocene palaeospecies, Sterna milne-edwardsii.[26]		The genera Anous, Procelsterna and Gygis are collectively known as noddies, the Chlidonias species are the marsh terns,[7] and all other species comprise the sea terns.[27][28]		Terns range in size from the least tern, at 23 cm (9.1 in) in length and weighing 30–45 g (1.1–1.6 oz),[29][30] to the Caspian tern at 48–56 cm (19–22 in), 500–700 g (18–25 oz).[31][32] They are longer-billed, lighter-bodied, and more streamlined than gulls, and their long tails and long narrow wings give them an elegance in flight. Male and female plumages are identical, although the male can be 2–5% larger than the female and often has a relatively larger bill. Sea terns have deeply forked tails, and at least a shallow "V" is shown by all other species.[7] The noddies (genera Anous, Procelsterna and Gygis) have unusual notched-wedge shaped tails, the longest tail feathers being the middle-outer, rather than the central or outermost.[22][33] Although their legs are short, terns can run well. They rarely swim, despite having webbed feet, usually landing on water only to bathe.[7]		The majority of sea terns have light grey or white body plumage as adults, with a black cap to the head. The legs and bill are various combinations of red, orange, yellow, or black depending on species. The pale plumage is conspicuous from a distance at sea, and may attract other birds to a good feeding area for these fish-eating species. When seen against the sky, the white underparts also help to hide the hunting bird from its intended prey. The Inca tern has mainly dark plumage, and three species that mainly eat insects, the black tern, white-winged tern, and black-bellied tern, have black underparts in the breeding season. The Anous noddies have dark plumage with a pale head cap. The reason for their dark plumage is unknown, but it has been suggested that in tropical areas, where food resources are scarce, the less conspicuous colouration makes it harder for other noddies to detect a feeding bird.[34] Plumage type, especially the head pattern, is linked to the phylogeny of the terns, and the pale-capped, dark-bodied noddies are believed to have diverged earlier than the other genera from an ancestral white-headed gull, followed by the partially black-headed Onychoprion and Sternula groupings.[13]		Juvenile terns typically have brown- or yellow-tinged upperparts, and the feathers have dark edges that give the plumage a scaly appearance. They have dark bands on the wings and short tails. In most species, the subsequent moult does not start until after migration, the plumage then becoming more like the adult, but with some retained juvenile feathers and a white forehead with only a partial dark cap. By the second summer, the appearance is very like the adult, and full mature plumage is usually attained by the third year. After breeding, terns moult into a winter plumage, typically showing a white forehead. Heavily worn or aberrant plumages such as melanism and albinism are much rarer in terns than in gulls.[35]		Terns have a wide repertoire of vocalisations. For example, the common tern has a distinctive alarm, kee-yah, also used as a warning to intruders, and a shorter kyar, given as an individual takes flight in response to a more serious threat; this quietens the usually noisy colony while its residents assess the danger. Other calls include a down-slurred keeur given when an adult is approaching the nest with a fish, and a kip uttered during social contact.[36] Parents and chicks can locate one another by call,[37] and siblings also recognise each other's vocalisations from about the twelfth day after hatching, which helps to keep the brood together.[38][39]		Vocal differences reinforce species separation between closely related birds such as the least and little terns,[40] and can help humans distinguish similar species, such as common and Arctic terns, since flight calls are unique to each species.[41][42]		Terns have a worldwide distribution, breeding on all continents including Antarctica. The northernmost and southernmost breeders are the Arctic tern and Antarctic tern respectively.[7][43] Many terns breeding in temperate zones are long-distance migrants, and the Arctic tern probably sees more annual daylight than any other animal as it migrates from its northern breeding grounds to Antarctic waters, a return journey of more than 30,000 km (19,000 mi). A common tern that hatched in Sweden and was found dead five months later on Stewart Island, New Zealand, must have flown at least 25,000 km (16,000 mi).[44] Actual flight distances are, of course, much greater than the shortest possible route. Arctic terns from Greenland were shown by radio geolocation to average 70,000 km (43,000 mi) on their annual migrations.[45]		Most terns breed on open sandy or rocky areas on coasts and islands. The yellow-billed, large-billed, and black-fronted terns breed only on rivers, and common, least and little terns also sometimes use inland locations. The marsh terns, Trudeau's tern and some Forster's terns nest in inland marshes. The black noddy and the white tern nest above ground level on cliffs or in trees. Migratory terns move to the coast after breeding, and most species winter near land, although some marine species, like the Aleutian tern, may wander far from land. The sooty tern is entirely oceanic when not breeding, and healthy young birds are not seen on land for up to five years after fledging until they return to breed. They lack waterproof plumage, so they cannot rest on the sea. Where they spend the years prior to breeding is unknown.[7]		Terns are normally monogamous, although trios or female-female pairings have been observed in at least three species.[7][46] Most terns breed annually and at the same time of year, but some tropical species may nest at intervals shorter than 12 months or asynchronously. Most terns become sexually mature when aged three, although some small species may breed in their second year. Some large sea terns, including the sooty and bridled terns, are four or older when they first breed. Terns normally breed in colonies, and are site-faithful if their habitat is sufficiently stable. A few species nest in small or dispersed groups, but most breed in colonies of up to a few hundred pairs, often alongside other seabirds such as gulls or skimmers.[7] Large tern species tend to form larger colonies,[42] which in the case of the sooty tern can contain up to two million pairs. Large species nest very close together and sit tightly, making it difficult for aerial predators to land among them. Smaller species are less closely packed and mob intruders. Peruvian and Damara terns have small dispersed colonies and rely on the cryptic plumage of the eggs and young for protection.[7]		The male selects a territory, which he defends against conspecifics, and re-establishes a pair bond with his mate or attracts a new female if necessary. Courtship involves ritualised flight and ground displays, and the male often presents a fish to his partner. Most species have little or no nest, laying the eggs onto bare ground, but Trudeau's tern, Forster's tern and the marsh terns construct floating nests from the vegetation in their wetland habitats. Black and lesser noddies build nests of twigs, feathers and excreta on tree branches, and brown, blue, and grey noddies make rough platforms of grass and seaweed on cliff ledges, in cavities or on other rocky surfaces.[7][47] The Inca tern nests in crevices, caves and disused burrows, such as that of a Humboldt penguin.[48] The white tern is unique in that it lays its single egg on a bare tree branch.[49]		Tropical species usually lay just one egg, but two or three is typical in cooler regions if there is an adequate food supply. The time taken to complete the clutch varies, but for temperate species incubation takes 21–28 days.[7] The eggs of most gulls and terns are brown with dark splotches, so they are difficult for predators to spot on the beach.[42] The precocial chicks fledge in about four weeks after hatching. Tropical species take longer because of the poorer food supply. Both parents incubate the eggs and feed the chicks, although the female does more incubating and less fishing than her partner.[7] Young birds migrate with the adults.[42] Terns are generally long-lived birds, with individuals typically returning for 7–10 breeding seasons. Maximum known ages include 34 for an Arctic tern and 32 for a sooty. Although several other species are known to live in captivity for up to 20 years, their greatest recorded ages are underestimates because the birds can outlive their rings.[7] Interbreeding between tern species is rare, and involves closely related species when it occurs. Hybrids recorded include common tern with roseate, Sandwich with lesser-crested, and black with white-winged.[50]		Most terns hunt fish by diving, often hovering first, and the particular approach technique used can help to distinguish similar species at a distance.[51] Sea terns often hunt in association with porpoises or predatory fish, such as bluefish, tuna or bonitos, since these large marine animals drive the prey to the surface. Sooty terns feed at night as the fish rise to the surface, and are believed to sleep on the wing since they become waterlogged easily. Terns of several species will feed on invertebrates, following the plough or hunting on foot on mudflats.[7] The marsh terns normally catch insects in the air or pick them off the surface of fresh water. Other species will sometimes use these techniques if the opportunity arises.[52] An individual tern's foraging efficiency increases with its age.[42]		The gull-billed tern is an opportunist predator, taking a wide variety of prey from marine, freshwater and terrestrial habitats. Depending on what is available it will eat small crabs, fish, crayfish, grasshoppers and other large insects, lizards and amphibians. Warm-blooded prey includes mice and the eggs and chicks of other beach-breeding birds; least terns, little terns and members of its own species may be victims.[53][54][55] The greater crested tern will also occasionally catch unusual vertebrate species such as agamid lizards and green sea turtle hatchlings, and follows trawlers for discards.[56]		The eyes of terns cannot accommodate under water, so they rely on accurate sighting from the air before they plunge-dive.[57] Like other seabirds that feed at the surface or dive for food, terns have red oil droplets in the cones of their retinas;[58] birds that have to look through an air/water interface have more deeply coloured carotenoid pigments in the oil drops than other species.[59] The pigment also improves visual contrast and sharpens distance vision, especially in hazy conditions,[58] and helps terns to locate shoals of fish, although it is uncertain whether they are sighting the phytoplankton on which the fish feed, or other feeding birds.[60] The red colouring reduces ultraviolet sensitivity, which in any case is an adaptation more suited to terrestrial feeders like the gulls,[61] and this protects the eye from UV damage.[57]		The inaccessibility of many tern colonies gave them a measure of protection from mammalian predators, especially on islands, but introduced species brought by humans can seriously affect breeding birds. These can be predators such as foxes, raccoons, cats and rats, or animals that destroy the habitat, including rabbits, goats and pigs.[7] Problems arise not only on formerly mammal-free islands, as in New Zealand, but also where an alien carnivore, such as the American mink in Scotland, presents an unfamiliar threat.[62]		Adult terns may be hunted by owls and raptors, and their chicks and eggs may be taken by herons, crows or gulls.[7][53] Less obvious nest predators include ruddy turnstones in the Arctic, and gull-billed terns in little tern colonies.[53][63] Adults may be robbed of their catch by avian kleptoparasites such as frigatebirds, skuas, other terns or large gulls.[7][64]		External parasites include chewing lice of the genus Saemundssonia,[65] feather lice and fleas such as Ceratophyllus borealis.[66] Lice are often host specific, and the closely related common and Arctic terns carry quite different species.[67] Internal parasites include the crustacean Reighardia sternae, and tapeworms such as Ligula intestinalis and members of the genera Diphyllobothrium and Schistocephalus.[68] Terns are normally free of blood parasites, unlike gulls that often carry Haemoproteus species. An exception is the brown noddy, which sometimes harbours protozoa of that genus.[69] In 1961 the common tern was the first wild bird species identified as being infected with avian influenza, the H5N3 variant being found in an outbreak involving South African birds.[70] Several species of terns have been implicated as carriers of West Nile virus.[71]		Terns and their eggs have long been eaten by humans and island colonies were raided by sailors on long voyages since the eggs or large chicks were an easily obtained source of protein. Eggs are still illegally harvested in southern Europe, and adults of wintering birds are taken as food in West Africa and South America. The roseate tern is significantly affected by this hunting, with adult survival 10% lower than would otherwise be expected. In the West Indies, the eggs of roseate and sooty terns are believed to be aphrodisiacs, and are disproportionately targeted by egg collectors. Tern skins and feathers have long been used for making items of clothing such as capes and hats, and this became a large-scale activity in the second half of the nineteenth century when it became fashionable to use feathers in hatmaking. This trend started in Europe but soon spread to the Americas and Australia. White was the preferred colour, and sometimes wings or entire birds were used.[7][72]		Terns have sometimes benefited from human activities, following the plough or fishing boats for easy food supplies, although some birds get trapped in nets or swallow plastic. Fishermen looked for feeding tern flocks, since the birds could lead them to fish shoals. Overfishing of small fish such as sand eels can lead to steep declines in the colonies relying on these prey items. More generally, the loss or disruption to tern colonies caused by human activities has caused declines in many species.[7] Pollution has been a problem in some areas, and in the 1960s and 1970s DDT caused egg loss through thinning of the shells. In the 1980s, organochlorides caused severe declines in the Great Lakes area of the US.[42] Because of their sensitivity to pollutants, terns are sometimes used as indicators of contamination levels.[7]		Habitat enhancements used to increase the breeding success of terns include floating nest platforms for black, common and Caspian terns,[73][74][75] and artificial islands created for a number of different species.[76][77] More specialised interventions include providing nest boxes for roseate terns, which normally nest in the shelter of tallish vegetation,[78] and using artificial eelgrass mats to encourage common terns to nest in areas not vulnerable to flooding.[79]		A number of terns face serious threats, and the Chinese crested tern is classed as "critically endangered" by BirdLife International. It has a population of fewer than 50 birds and a breeding range of just 9 km2 (3.5 mi2). It is declining due to egg collection, human disturbance and the loss of coastal wetlands in China.[80] Three other species are categorised as "endangered", with declining populations of less than 10,000 birds. The South Asian black-bellied tern is threatened by habitat loss, egg collecting for food, pollution and predation.[81] In New Zealand, the black-fronted tern is facing a rapid fall in numbers due to predation by introduced mammals and Australian magpies. Disturbance by cattle and sheep and by human activities is also a factor.[24] The Peruvian tern was initially damaged by the collapse of anchoveta stocks in 1972, but breeding colonies have subsequently been lost due to building, disturbance and pollution in their coastal wetlands.[82]		The Australasian fairy tern is described as "vulnerable". Disturbance by humans, dogs and vehicles, predation by introduced species and inappropriate water level management in South Australia are the main reasons for its decline.[83] Five species are "near threatened", indicating less severe concerns or only potential vulnerability. The elegant tern is so categorised because 95% of the population breeds on one island, Isla Rasa in the Gulf of California, and the Kerguelen tern has a population of less than 5,000 adults breeding on small and often stormy Pacific islands.[84][85] Three species, the Inca, Damara, and river terns, are expected to decline in the future due to habitat loss and disturbance.[48][86][87] Some tern subspecies are endangered, including the California least tern and the Easter Island race of the grey noddy.[7]		Most tern species are declining in numbers due to the loss or disturbance of breeding habitat, pollution and increased predation. Gull populations have increased over the last century because of reduced persecution and the availability of food from human activities, and terns have been forced out of many traditional nesting areas by the larger birds. A few species are defying the trend and showing local increases, including the Arctic tern in Scandinavia, Forster's tern around the Great Lakes, the Sandwich tern in eastern North America and its yellow-billed subspecies, the Cayenne tern, in the Caribbean.[7]		Terns are protected by international legislation such as the Agreement on the Conservation of African-Eurasian Migratory Waterbirds (AEWA) and the US-Canada Migratory Bird Treaty Act of 1918.[88][89] Parties to the AWEA agreement are required to engage in a wide range of conservation strategies described in a detailed action plan. The plan is intended to address key issues such as species and habitat conservation, management of human activities, research, education, and implementation.[90] The North American legislation is similar, although there is a greater emphasis on protection.[91]		
A mouth bar is a bar in a river that is typically created in the middle of a channel in a river delta.[1] It is created by a positive feedback between mid-channel deposition and flow divergence. As the flow diverges near the ocean, sediment settles out in the channel and creates an incipient mouth bar. As flow is routed around the incipient bar, additional sediment is deposited on the incipient bar. This continued process results in the formation of a full-fledged mouth bar, which causes the channel to bifurcate. This continued process leads to the characteristic fractal tree pattern found in some prograding river-dominated deltas.				
A raised shoreline is an ancient shoreline exposed above current water level.[1] These landforms are formed by a relative change in sea level due to global sea level rise, isostatic rebound, and/or tectonic uplift. These surfaces are usually exposed above modern sea level when a heavily glaciated area experiences a glacial retreat, causing water levels to rise. This area will then experience post-glacial rebound, effectively raising the shoreline surface. Examples of raised shorelines can be found along the coasts of formerly glaciated areas in Ireland[2] and Scotland, as well as in North America. Raised shorelines are exposed at various locations around the Puget Sound of Washington State.[3]		
A granule is a clast of rock with a particle size of 2 to 4 millimetres based on the Krumbein phi scale of sedimentology. Granules are generally considered to be larger than sand (0.0625 to 2 millimetres diameter) and smaller than pebbles (4 to 64 millimetres diameter). A rock made predominantly of granules is termed a granule conglomerate.[1]				
A seaside resort is a resort town or resort hotel, located on the coast. Sometimes it is also an officially accredited title, that is only awarded to a town when the requirements are met (like the title Seebad in Germany).		Where a beach is the primary focus for tourists, it may be called a beach resort.						The coast has always been a recreational environment,[citation needed] although until the mid-nineteenth century, such recreation was a luxury only for the wealthy. Even in Roman times, the town of Baiae, by the Tyrrhenian Sea in Italy, was a resort for those who were sufficiently prosperous.[citation needed] Mersea Island, in Essex, England was a seaside holiday destination for wealthy Romans living in Colchester.[1]		The development of the beach as a popular leisure resort from the mid-19th century was the first manifestation of what is now the global tourist industry. The first seaside resorts were opened in the 18th century for the aristocracy, who began to frequent the seaside as well as the then fashionable spa towns, for recreation and health.[2] One of the earliest such seaside resorts was Scarborough in Yorkshire during the 1720s; it had been a popular spa town since a stream of acidic water was discovered running from one of the cliffs to the south of the town in the 17th century.[2] The first rolling bathing machines were introduced by 1735.		In 1793, Heiligendamm in Mecklenburg, Germany was founded as the first seaside resort of the European continent, which successfully attracted Europe's aristocracy to the Baltic Sea.[3]		The opening of the resort in Brighton and its reception of royal patronage from King George IV extended the seaside as a resort for health and pleasure to the much larger London market, and the beach became a centre for upper-class pleasure and frivolity. This trend was praised and artistically elevated by the new romantic ideal of the picturesque landscape; Jane Austen's unfinished novel Sanditon is an example of that. Later, Queen Victoria's long-standing patronage of the Isle of Wight and Ramsgate in Kent ensured that a seaside residence was considered as a highly fashionable possession for those wealthy enough to afford more than one home.		The extension of this form of leisure to the middle and working class began with the development of the railways in the 1840s, which offered cheap and affordable fares to fast growing resort towns. In particular, the completion of a branch line to the small seaside town Blackpool from Poulton led to a sustained economic and demographic boom. A sudden influx of visitors arriving by rail provided the motivation for entrepreneurs to build accommodation and create new attractions, leading to more visitors and a rapid cycle of growth throughout the 1850s and 1860s.[4]		The growth was intensified by the practice among the Lancashire cotton mill owners of closing the factories for a week every year to service and repair machinery. These became known as wakes weeks. Each town's mills would close for a different week, allowing Blackpool to manage a steady and reliable stream of visitors over a prolonged period in the summer. A prominent feature of the resort was the promenade and the pleasure piers, where an eclectic variety of performances vied for the people's attention. In 1863, the North Pier in Blackpool was completed, rapidly becoming a centre of attraction for elite visitors. Central Pier was completed in 1868, with a theatre and a large open-air dance floor.[5]		Many popular beach resorts were equipped with bathing machines because even the all-covering beachwear of the period was considered immodest.		By the end of the century the English coastline had over 100 large resort towns, some with populations exceeding 50,000.[6]		The development of the seaside resort abroad was stimulated by the well developed English love of the beach. The French Riviera alongside the Mediterranean had already become a popular destination for the British upper class by the end of the 18th century. In 1864, the first railway to Nice was completed, making the Riviera accessible to visitors from all over Europe. By 1874, residents of foreign enclaves in Nice, most of whom were British, numbered 25,000. The coastline became renowned for attracting the royalty of Europe, including Queen Victoria and King Edward VII.[7]		In the United States, early seaside resorts in the late 1800's catered to the wealthy class and city businessmen. Cape May, New Jersey became one of the first coastal resorts in the United States, when regular steamboat traffic on the Delaware River began after the War of 1812. Early visitors to Cape May included Henry Clay in 1847, and Abraham Lincoln in 1849. By 1880, Henry Flagler extended several rail lines southward down the Atlantic coastline of the United States, enticing the northern upper class families south to subtropical Florida. The Florida East Coast Railway brought northern tourists to St. Augustine in greater numbers, and by 1887 Flagler began construction of two large ornate hotels in St. Augustine, the 540-room Ponce de Leon Hotel and the Hotel Alcazar, and bought the Casa Monica Hotel the next year.		Continental European attitudes towards gambling and nudity tended to be more lax than in Britain, and British and French entrepreneurs were quick to exploit the possibilities. In 1863, the Prince of Monaco, Charles III and François Blanc, a French businessman, arranged for steamships and carriages to take visitors from Nice to Monaco, where large luxury hotels, gardens and casinos were built. The place was renamed Monte Carlo. Commercial seabathing also spread to other areas of the United States and parts of the British Empire such as Australia, where surfing became popular in the early 20th century. By the 1970s cheap and affordable air travel was the catalyst for the growth of a truly global tourism market.		Recreational fishing and leisure boat pursuits have recently become very lucrative, and traditional fishing villages are often well positioned to take advantage of this. For example, Destin, on the coast of Florida, has evolved from an artisanal fishing village into a seaside resort dedicated to tourism with a large fishing fleet of recreational charter boats.[8] The tourist appeal of fishing villages has become so big that the Korean government is purpose-building 48 fishing villages for their tourist drawing power.[9]		Popular seaside resorts on the Flemish coast of West-Vlaanderen exist at the famous Knokke, Ostend and also De Panne and coastal towns along the North Sea served by the coastal tramway Kustram run by De Lijn.		There are many seaside resorts on the jagged coastline of Croatia, including several on its islands, which have been popular for many years. Examples include:		With three long coastlines, France has many seaside resorts on its various coasts; for specific towns in each region, see the following articles:		Germany is famous for its traditional seaside resorts on the Baltic Sea and the North Sea coasts, mainly established in the 19th century. In German they are called Seebad ("Sea Spa") or Seeheilbad, sometimes with Ostsee- or Nordsee- as prefixes for the respective coastline.		The most prestigious resorts can be found along the Baltic coastline, including the islands of Rugia and Usedom. They often feature a unique architectural style called resort architecture. The coast of Mecklenburg and Western Pomerania alone has an overall length of 2000 km[10] and is nicknamed German Riviera.[11] Heiligendamm in Mecklenburg, established in 1793, is the oldest seaside resort in Germany and continental Europe.[12]		Most important coastal areas with seaside resorts in Germany:		Selection of German seaside resorts along the Baltic Sea coastline:		At the North Sea coastline:		The 'Irish Riviera' on the South Coast of Ireland features the seaside resorts of Youghal, Ardmore, Dungarvan, Cóbh and Ballycotton, all set close to the south coast of Ireland. Youghal has been a favoured holiday destination for over 100 years, situated on the banks of the River Blackwater as it reaches the sea. Youghal is well known for its beaches, having been, until 2008, the only town in the Republic of Ireland with two beaches awarded E.U. Blue Flag status. Dungarvan is a seaside market town beneath the mountains in the centre of the Irish south coast. Kinsale is often described as a food lover's and yachting town, with a diverse range of restaurants, as well as a large and active creative community with numerous art galleries and record and book shops.		Seaside resorts in the East of Ireland developed after the introduction of rail travel. The Dublin and Kingstown Railway introduced day-trippers from Dublin to Kingstown (now Dún Laoghaire) in South Dublin, and the coastal town became Ireland's first seaside resort. Other South Dublin towns and villages such as Sandycove, Dalkey and Killiney grew as seaside resorts when the rail network was expanded. Since the opening of Bray Daly Station in 1852, the County Wicklow coastal town of Bray has become the largest seaside resort on the East Coast of Ireland. The town of Greystones, five miles south of Bray, also grew as a seaside resort when the railway line was extended in 1855. Other seaside resorts include Courtown and Rosslare Strand in County Wexford.		Ulster has a number of seaside resorts, such as Portrush, situated on the north coast, with its two beaches and a world-famous golf course, Royal Portrush Golf Club.[13] Other Ulster seaside resorts are Newcastle, located on the east coast at the foot of the Mourne Mountains; Ballycastle; Portstewart; Rathmullan; Bundoran and Bangor. Bangor Marina is one of the largest in Ireland and the marina has on occasion been awarded the Blue Flag for attention to environmental issues.		The main seaside towns in the west of Ireland are in Clare; the largest are Lahinch and Kilkee. Lahinch is a popular surfing location.		Like British resorts, many seaside towns in Ireland have turned to other entertainment industries. Larger resorts such as Bray or Portrush host air shows, while most resorts host summer festivals.		Israel is a major tourist area. Tourism in Israel is one of the major sources of income, with beautiful beaches, such as those found on the Mediterranean Sea and the Red Sea. Most tourists come from the United States and European countries. Other resorts include:		Italy is known for its seaside resorts, visited both by Italian and North European tourists. Many of these resorts have a history of tourism which dates back to the 19th century.		A selection of Italian seaside resorts includes:		Many seaside resorts are located in Honshu, Shikoku, and Kyushu.[citation needed]		Many seaside resorts are located in Gyeongsang, Jeolla, Chungcheong, Gangwon, Gyeonggi, Incheon, Ulsan and Busan.		The following are the main resort towns in Malta:[14]		Mexican resorts are popular with many North American residents, with Mexico being the second most visited country in the Americas. Notable resorts on the mainland and Baja Gold Coast and Peninsula include:		There are many seaside resorts on the Dutch coast, chiefly in the provinces of North Holland, South Holland and Zeeland, as well as on the West Frisian Islands.		A selection includes:		Poland's coast on the Baltic Sea includes many traditional seaside resorts, most of which were German until 1945, including Sopot, Łeba, Świnoujście, Władysławowo, Mielno, Ustka and Kołobrzeg. The resorts have become more popular since the 1990s, following the return of democracy to Poland.[15]		Many European and world tourists visit Portuguese resorts, particularly those on the Algarve. Notable resorts include:		The Romanian Black Sea resorts stretch from the Danube Delta in the north down to the Romanian-Bulgarian boarder in the south, along 275 kilometers of coastline.		Notable seaside resorts in South America include Buzios, Camboriú, Florianópolis, Recife and Salvador de Bahia in Brazil; Mar del Plata in Argentina; Punta del Este and Piriapolis in Uruguay; Viña del Mar in Chile; Cartagena in Colombia; and Salinas in Ecuador.		Spanish resorts are popular with many European and world residents. Notable resorts on the mainland and islands include:		Some examples of Ukrainian seaside resort towns are:		The United Kingdom saw the popularisation of seaside resorts, and nowhere was this more seen than in Blackpool. Blackpool catered for workers from across industrial Northern England, who packed its beaches and promenade. Other northern towns (for example Bridlington, Cleethorpes, Morecambe, Scarborough, Skegness, and Southport) shared in the success of this new concept, especially from trade during wakes weeks. The concept spread rapidly to other British coastal towns including several on the coast of North Wales, notably Rhyl, and Llandudno, the largest resort in Wales and known as "The Queen of the Welsh Resorts", from as early as 1864.[18] As the nineteenth century progressed, British working class day-trippers travelled on organized trips such as railway excursions, or by steamer, for which long piers were erected so that the ships bringing the trade could berth.		Another area notable for its seaside resorts was (and is) the Firth of Clyde, outside Glasgow. Glaswegians would take a ferry "doon the watter" from the city, down the River Clyde to the islands and peninsulas of the Firth of Clyde, such as Cowal, Bute, Arran, and Kintyre. Resorts include Rothesay, Lamlash, Whiting Bay, Dunoon, Tighnabruaich, Carrick Castle, Helensburgh, Largs, Millport and Campbeltown. In contrast to the fates of many resorts, many from the Firth of Clyde have continued to enjoy prosperity thanks to their becoming middle-class commuter towns.		Some resorts, especially those more southerly such as Bournemouth and Brighton, were built as new towns or extended by local landowners to appeal to wealthier holidaymakers. Others came about due to their proximity to large urban areas of population, such as Southend-on-sea, which became increasingly popular with residents of London once rail links were established to it allowing day trips from the City. The south coast has many seaside towns, the most being in Sussex.		From the last quarter of the twentieth century, the popularity of the British seaside resort has declined for the same reason that it first flourished: advancements in transport. The greater accessibility of foreign holiday destinations, through package holidays and, more recently, European low-cost airlines, affords people the freedom to holiday abroad. Despite the loyalty of returning holidaymakers, resorts such as Blackpool have struggled to compete against the favorable weather of Southern Europe and the sunbelt in the United States. Now, many symbols of the traditional British resort (holiday camps, end-of-the-pier shows and saucy postcards) are regarded by some as drab and outdated; the skies are imagined to be overcast and the beach windswept. This is not always true; for example Broadstairs in Kent has retained much of its old world charm with Punch and Judy and donkey rides and still remains popular being only one hour from the M25.		Many seaside towns have turned to other entertainment industries, and some of them have a good deal of nightlife. The cinemas and theatres often remain to become host to a number of pubs, bars, restaurants and nightclubs. Most of their entertainment facilities cater to local people and the beaches still remain popular during the summer months. Although international tourism turned people away from British seaside towns, it also brought in foreign travel and as a result, many seaside towns offer foreign language schools, the students of which often return to vacation and sometimes to settle.		A lot of people can also afford more time off and 'second holidays' and short breaks, resulting in increased tourism in British seaside towns. Many young people and students are able to take short holidays and discover the town's nightlife. Many seaside towns boast large shopping centres which also attract people from a wide area. Day trippers still come to the coastal towns but on a more local scale than during the 19th century.		Many coastal towns are also popular retirement hotspots where older people take short breaks in the autumn months.		In contrast, the fortunes of Brighton, which has neither holiday camps nor (now) end-of-the-pier shows, have grown considerably and, because of this, the resort is repeatedly held up as the model of a modern resort. However, unlike the Golden Miles of other British resorts, the sea is not Brighton's primary attraction; rather it is an attractive backdrop to an attitude of broad-minded cosmopolitan hedonism. The resulting sense of uniqueness, coupled with the city's proximity to London, has led to Brighton's restoration as a fashionable resort and the dwelling-place of the affluent.		Other English coastal towns have successfully sought to project a sense of their unique character. In particular, Southwold on the Suffolk coast is an active yet peaceful retirement haven with an emphasis on calmness, quiet countryside and jazz. Weymouth, Dorset offers itself as 'the gateway to the Jurassic Coast', Britain's only natural World Heritage Site. Newquay in Cornwall offers itself as the 'surfing capital of Britain', hosting international surfing events on its shores.		Torbay in South Devon is known is also known as the English Riviera. Consisting of the towns of Torquay, Paignton with its pier and Brixham, the bay has 20 beaches and coves along its 22-mile (35 km) coastline, ranging from small secluded coves to the larger promenade style seafronts of Torquay's Torre Abbey Sands and Paignton Sands.		However, British seaside resorts have faced increasingly stiff competition from traditionally sunnier resorts overseas since the 1970s. In 1975, some 9,000 British families holidayed abroad, but by the mid-1980s that figure had risen to some 20,000. A decade later, the figure was around 30,000. This was largely due to the falling price of air travel which the Conservative government of Margaret Thatcher (elected in 1979) had allowed.[19] This decline is discussed in the Morrissey song 'Everyday Is Like Sunday' where daily life in the resort is likened to the emptiness of streets once associated with the shop closures on Sunday.		With 3,800 miles (6100 Km) of coastline, the USA mainland has hundreds of seaside resorts on three coasts, Atlantic Ocean, Gulf of Mexico, and Pacific ocean. Unlike in many smaller countries, the seaside resorts in the USA are located in various climate zones, with great differences in topography and environment. Many American seaside resorts are popular destination across the world, known for their climates, culture, and entertainment opportunities.		American seaside resorts first developed near the big industrial cities of the Northeast like New York City, Philadelphia, and Boston. Cape May, New Jersey, and Provincetown, MA, were two of the first seaside resorts in the 1800's that catered to city works in New York and Boston. Cape May is often called Americas "first seaside resort". The early emergence of Cape May as a summer resort was due to easy transport by water from Philadelphia to the Atlantic Ocean. Early Cape May vacationers were carried to the town on sloops from Philadelphia, and water transport was also easy from New York, Baltimore, Washington, D.C. and points south. The resort business in Cape May began to thrive when regular steamboat traffic on the Delaware River began after the War of 1812. Early visitors to Cape May included Henry Clay in 1847, and Abraham Lincoln in 1849. Today, the Cape May Historic District is one of the largest and well preserved examples of Victorian architecture in the United States.		On the southern Atlantic coast, Henry Flagler had the idea to make St. Augustine, Florida a winter resort. He built several rail lines south, and combined them with existing lines to create the Florida East Coast Railway in 1885. He built a railroad bridge over the St. Johns River in 1888, opening up the Atlantic coast of Florida to development. In 1887 Flagler began construction of two large ornate hotels in St. Augustine, the 540-room Ponce de Leon Hotel and the Hotel Alcazar, and bought the Casa Monica Hotel the next year.		In Miami, Florida, the community of Cocoanut (now Coconut) Grove began development as a resort town in the 1880s with the building of the Bayview House (aka Peacock Inn) which closed in 1902. Visitors to the greater Miami area then flocked to Camp Biscayne (in Coconut Grove), the Royal Palm Hotel in Downtown Miami, and other resort hotels in Miami, as well as in smaller numbers to the Florida Keys. In 1894, the lavish Royal Poinciana Hotel opened in Palm Beach, Florida, with rave reviews from wealthy New York tourists who picked oranges in January to their delight. On the Gulf of Mexico, the City of Galveston was emerging as a booming city, and in 1882, architect Nicholas J. Clayton designed the Beach Hotel. By 1888, Galveston, TX was a wealthy city and booming seaside playground for wealthy New Orleans businessmen.		On the Pacific coast in California, in April 1886, Babcock and Story created the Coronado Beach Company, which sought to develop Coronado as a seaside resort. In the mid-1880s, the San Diego region was in the midst of one of its first real estate booms. The Hotel del Coronado was built in March 1887, with Babcock's visions for the hotel built around a courtyard of tropical trees, shrubs and flowers, with a dining wing to give full value to the view of the ocean, bay and city. By 1915, more hotels were built along the Los Angeles coastline to serve the wealthy tourists and Hollywood film makers. In May of 1926, brothers E.A. "Jack" Harter and T.D. "Til" Harter built the Hotel Casa del Mar in Santa Monica, at a cost of $2 million, creating one of the most successful beach clubs in Southern California, popular with socialites and Hollywood celebrities.		In the 1920's, Carl Fisher was the main promoter of Miami Beach, and helped to develop the city as a seaside resort. To accommodate the wealthy tourists, several grand hotels were built, among them the Flamingo Hotel. In 1926, the massive The Breakers hotel in Palm Beach had been rebuilt, and there was a large northern tourist industry in coastal southern Florida. By the 1950s with increasing auto travel, more seaside resorts grew along the Atlantic and Pacific coasts, while small, declining industrial ports were being rebuilt. In 1954, the Fontainebleau Miami Beach, and was considered, (at that time) the most lavish seaside hotel in the world.		In the modern era, hundreds of seaside resorts now string the Gulf, Atlantic, and Pacific coasts of the United States. Many Americans move with the seasons when they visit seaside resorts, vacationing in northern seaside areas in the warm season (April through October), and then moving to southern areas in the cold season (November through March). Many seaside resorts in Florida and California however, see travelers all year.		Some examples of well-known and sought-after American coastal resort towns are:		
A landform is a natural feature of the solid surface of the Earth or other planetary body. Landforms together make up a given terrain, and their arrangement in the landscape is known as topography. Typical landforms include hills, mountains, plateaus, canyons, valleys, as well as shoreline features such as bays, peninsulas, and seas, including submerged features such as mid-ocean ridges, volcanoes, and the great ocean basins.						Landforms are categorized by characteristic physical attributes such as elevation, slope, orientation, stratification, rock exposure, and soil type. Gross physical features or landforms include intuitive elements such as berms, mounds, hills, ridges, cliffs, valleys, rivers, peninsulas, volcanoes, and numerous other structural and size-scaled (i.e. ponds vs. lakes, hills vs. mountains) elements including various kinds of inland and oceanic waterbodies and sub-surface features.		Oceans and continents exemplify the highest-order landforms. Landform elements are parts of a high-order landforms that can be further identified and systematically given a cohesive definition such as hill-tops, shoulders, saddles, foreslopes and backslopes.		Some generic landform elements including: pits, peaks, channels, ridges, passes, pools and plains.		Terrain (or relief) is the third or vertical dimension of land surface. Topography is the study of terrain, although the word is often used as a synonym for relief itself. When relief is described underwater, the term bathymetry is used. In cartography, many different techniques are used to describe relief, including contour lines and TIN (Triangulated irregular network).		Elementary landforms (segments, facets, relief units) are the smallest homogeneous divisions of the land surface, at the given scale/resolution. These are areas with relatively homogeneous morphometric properties, bounded by lines of discontinuity. A plateau or a hill can be observed at various scales ranging from few hundred meters to hundreds of kilometers. Hence, the spatial distribution of landforms is often scale-dependent as is the case for soils and geological strata.		A number of factors, ranging from plate tectonics to erosion and deposition, can generate and affect landforms. Biological factors can also influence landforms— for example, note the role of vegetation in the development of dune systems and salt marshes, and the work of corals and algae in the formation of coral reefs.		Landforms do not include man-made features, such as canals, ports and many harbors; and geographic features, such as deserts, forests, and grasslands. Many of the terms are not restricted to refer to features of the planet Earth, and can be used to describe surface features of other planets and similar objects in the Universe. Examples are mountains, hills, polar caps, and valleys, which are found on all of the terrestrial planets.		The scientific study of landforms is known as geomorphology.		Landforms may be extracted from a digital elevation model using some automated techniques where the data has been gathered by modern satellites and stereoscopic aerial surveillance cameras.[1] Until recently, compiling the data found in such data sets required time consuming and expensive techniques involving many man-hours. The most detailed DEMs available are measured directly using LIDAR techniques.		
In physical geography, a dune is a hill of loose sand built by wind or the flow of water.[1] Dunes occur in different shapes and sizes, formed by interaction with the flow of air or water. Most kinds of dunes are longer on the windward side where the sand is pushed up the dune and have a shorter "slip face" in the lee of the wind. The valley or trough between dunes is called a slack. A "dune field" is an area covered by extensive sand dunes. Dunes occur, for example, in some deserts and along some coasts.		Some coastal areas have one or more sets of dunes running parallel to the shoreline directly inland from the beach. In most cases, the dunes are important in protecting the land against potential ravages by storm waves from the sea. Although the most widely distributed dunes are those associated with coastal regions, the largest complexes of dunes are found inland in dry regions and associated with ancient lake or sea beds.		Dunes can form under the action of water flow (fluvial processes), and on sand or gravel beds of rivers, estuaries and the sea-bed.		The modern word "dune" came into English from French c. 1790,[2] which in turn came from Middle Dutch dūne.[1]						Crescent-shaped mounds are generally wider than they are long. The slipfaces are on the concave sides of the dunes. These dunes form under winds that blow consistently from one direction, and they also are known as barchans, or transverse dunes. Some types of crescentic dunes move more quickly over desert surfaces than any other type of dune. A group of dunes moved more than 100 metres per year between 1954 and 1959 in China's Ningxia Province, and similar speeds have been recorded in the Western Desert of Egypt. The largest crescentic dunes on Earth, with mean crest-to-crest widths of more than three kilometres, are in China's Taklamakan Desert.[3]		Fixed crescentic dunes that form on the leeward margins of playas and river valleys in arid and semiarid regions in response to the direction(s) of prevailing winds, are known as lunettes, source-bordering dunes, bourrelets and clay dunes. They may be composed of clay, silt, sand, or gypsum, eroded from the basin floor or shore, transported up the concave side of the dune, and deposited on the convex side. Examples in Australia are up to 6.5 km long, 1 km wide, and up to 50 metres high. They also occur in southern and West Africa, and in parts of the western United States, especially Texas.[4]		Straight or slightly sinuous sand ridges typically much longer than they are wide are known as linear dunes. They may be more than 160 kilometres (100 miles) long. Some linear dunes merge to form Y-shaped compound dunes. Many form in bidirectional wind regimes. The long axes of these dunes extend in the resultant direction of sand movement.[5]		Linear loess hills known as pahas are superficially similar. These hills appear to have been formed during the last ice age under permafrost conditions dominated by sparse tundra vegetation.		Radially symmetrical, star dunes are pyramidal sand mounds with slipfaces on three or more arms that radiate from the high center of the mound. They tend to accumulate in areas with multidirectional wind regimes. Star dunes grow upward rather than laterally. They dominate the Grand Erg Oriental of the Sahara. In other deserts, they occur around the margins of the sand seas, particularly near topographic barriers. In the southeast Badain Jaran Desert of China, the star dunes are up to 500 metres tall and may be the tallest dunes on Earth.		Oval or circular mounds that generally lack a slipface. Dome dunes are rare and occur at the far upwind margins of sand seas.		U-shaped mounds of sand with convex noses trailed by elongated arms are parabolic dunes. These dunes are formed from blowout dunes where the erosion of vegetated sand leads to a U-shaped depression. The elongated arms are held in place by vegetation; the largest arm known on Earth reaches 12 km. Sometimes these dunes are called U-shaped, blowout, or hairpin dunes, and they are well known in coastal deserts. Unlike crescent shaped dunes, their crests point upwind. The bulk of the sand in the dune migrates forward.		In plan view, these are U-shaped or V-shaped mounds of well-sorted, very fine to medium sand with elongated arms that extend upwind behind the central part of the dune. There are slipfaces that often occur on the outer side of the nose and on the outer slopes of the arms.		These dunes often occur in semiarid areas where the precipitation is retained in the lower parts of the dune and underlying soils. The stability of the dunes was once attributed to the vegetative cover but recent research has pointed to water as the main source of parabolic dune stability. The vegetation that covers them—grasses, shrubs, and trees—help anchor the trailing arms. In inland deserts, parabolic dunes commonly originate and extend downwind from blowouts in sand sheets only partly anchored by vegetation. They can also originate from beach sands and extend inland into vegetated areas in coastal zones and on shores of large lakes.		Most parabolic dunes do not reach heights higher than a few tens of metres except at their nose, where vegetation stops or slows the advance of accumulating sand.		Simple parabolic dunes have only one set of arms that trail upwind, behind the leading nose. Compound parabolic dunes are coalesced features with several sets of trailing arms. Complex parabolic dunes include subsidiary superposed or coalesced forms, usually of barchanoid or linear shapes.		Parabolic dunes, like crescent dunes, occur in areas where very strong winds are mostly unidirectional. Although these dunes are found in areas now characterized by variable wind speeds, the effective winds associated with the growth and migration of both the parabolic and crescent dunes probably are the most consistent in wind direction.		The grain size for these well-sorted, very fine to medium sands is about 0.06 to 0.5 mm. Parabolic dunes have loose sand and steep slopes only on their outer flanks. The inner slopes are mostly well packed and anchored by vegetation, as are the corridors between individual dunes. Because all dune arms are oriented in the same direction, and, the inter-dune corridors are generally swept clear of loose sand, the corridors can usually be traversed in between the trailing arms of the dune. However to cross straight over the dune by going over the trailing arms, can be very difficult. Also, traversing the nose is very difficult as well because the nose is usually made up of loose sand without much if any vegetation.		A type of extensive parabolic dune that lacks discernible slipfaces and has mostly coarse grained sand is known as a zibar.[6] The term zibar comes from the Arabic word to describe "rolling transverse ridges ... with a hard surface".[7] The dunes are small, have low relief, and can be found in many places across the planet from Wyoming (United States) to Saudi Arabia to Australia. Spacing between zibars ranges from 50 to 400 metres and they don't become more than 10 metres high.[8] The dunes form at about ninety degrees to the prevailing wind which blows away the small, fine-grained sand leaving behind the coarser grained sand to form the crest.[9]		Longitudinal dunes (also called Seif dunes, after the Arabic word for "sword"), elongate parallel to the prevailing wind, possibly caused by a larger dune having its smaller sides blown away. Seif dunes are sharp-crested and are common in the Sahara. They range up to 300 m (980 ft) in height and 300 km (190 mi) in length. In the southern third of the Arabian Peninsula, a vast erg called the Rub' al Khali or the Empty Quarter, contains seif dunes that stretch for almost 200 km and reach heights of over 300 m.		Seif dunes are thought to develop from barchans if a change of the usual wind direction occurs. The new wind direction will lead to the development of a new wing and the over development of one of the original wings. If the prevailing wind then becomes dominant for a lengthy period of time the dune will revert to its barchan form, with one exaggerated wing. Should the strong wind then return the exaggerated wing will further extend so that eventually it will be supplied with sand when the prevailing wind returns. The wing will continue to grow under both wind conditions, thus producing a seif dune. On a seif dune the slipface develops on the side facing away from the strong wind, while the slipface of a barchan faces the direction of movement. In the sheltered troughs between highly developed seif dunes barchans may be formed because the wind is unidirectional.		A transverse dune is perpendicular to the prevailing wind, probably caused by a steady build-up of sand on an already existing minuscule mound.		Occurring wherever winds periodically reverse direction, reversing dunes are varieties of any of the above shapes. These dunes typically have major and minor slipfaces oriented in opposite directions.		All these dune shapes may occur in three forms: simple, compound, and complex. Simple dunes are basic forms with a minimum number of slipfaces that define the geometric type. Compound dunes are large dunes on which smaller dunes of similar type and slipface orientation are superimposed, and complex dunes are combinations of two or more dune types. A crescentic dune with a star dune superimposed on its crest is the most common complex dune. Simple dunes represent a wind regime that has not changed in intensity or direction since the formation of the dune, while compound and complex dunes suggest that the intensity and direction of the wind has changed.		The sand mass of dunes can move either windward or leeward, depending on if the wind is making contact with the dune from below or above its apogee. If wind hits from above, the sand particles move leeward. If sand hits from below, sand particles move windward. The leeward flux of sand is greater than the windward flux. Further, when the wind carrying sand particles when it hits the dune, the dune’s sand particles will saltate more than if the wind had hit the dune without carrying sand particles.[10]		Dunes form where the beach is wide enough to allow for the accumulation of wind-blown sand, and where prevailing onshore winds tend to blow sand inland. Obstacles—for example, vegetation, pebbles and so on—tend to slow down the wind and lead to the deposition of sand grains.[11] These small "incipient dunes or "shadow dunes" tend to grow in the vertical direction if the obstacle slowing the wind can also grow vertically (i.e., vegetation). Models of coastal dunes suggest that their final equilibrium height is related to the distance between the water line and where vegetation can grow.[12] Additionally the height of coastal dunes is impacted by storm events, which can erode dunes. Recent work has suggested that coastal dunes tend to evolve toward a high or low morphology depending on the growth rate of dunes relative to storm frequency. In certain conditions, both low and high dunes are possible — dunes are a system that shows bistable dynamics.[13][14]		Dunes provide privacy and shelter from the wind.		As a dune forms, plant succession occurs. The conditions on an embryo dune are harsh, with salt spray from the sea carried on strong winds. The dune is well drained and often dry, and composed of calcium carbonate from seashells. Rotting seaweed, brought in by storm waves adds nutrients to allow pioneer species to colonize the dune. These pioneer species are marram grass, sea wort grass and other sea grasses in the United Kingdom. These plants are well adapted to the harsh conditions of the foredune typically having deep roots which reach the water table, root nodules that produce nitrogen compounds, and protected stoma, reducing transpiration. Also, the deep roots bind the sand together, and the dune grows into a foredune as more sand is blown over the grasses. The grasses add nitrogen to the soil, meaning other, less hardy plants can then colonize the dunes. Typically these are heather, heaths and gorses. These too are adapted to the low soil water content and have small, prickly leaves which reduce transpiration. Heather adds humus to the soil and is usually replaced by coniferous trees, which can tolerate low soil pH, caused by the accumulation and decomposition of organic matter with nitrate leaching.[15] Coniferous forests and heathland are common climax communities for sand dune systems.		Young dunes are called yellow dunes and dunes which have high humus content are called grey dunes. Leaching occurs on the dunes, washing humus into the slacks, and the slacks may be much more developed than the exposed tops of the dunes. It is usually in the slacks that more rare species are developed and there is a tendency for the dune slacks soil to be waterlogged and where only marsh plants can survive. These plants would include: creeping willow, cotton grass, yellow iris, reeds, and rushes. As for the species, there is a tendency for natterjack toads to breed here.		Dune ecosystems are extremely difficult places for plants to survive. This is due to a number of pressures related to their proximity to the ocean and confinement to growth on sandy substrates.  These include:		There are many adaptations plants have evolved to cope with these pressures:		A nabkha, or coppice dune, is a small dune anchored by vegetation. They usually indicate desertification or soil erosion, and serve as nesting and burrow sites for animals.		Sub-aqueous (underwater) dunes form on a bed of sand or gravel under the actions of water flow. They are ubiquitous in natural channels such as rivers and estuaries, and also form in engineered canals and pipelines. Dunes move downstream as the upstream slope is eroded and the sediment deposited on the downstream or lee slope in typical bedform construction.[16]		These dunes most often form as a continuous 'train' of dunes, showing remarkable similarity in wavelength and height.		Dunes on the bed of a channel significantly increase flow resistance, their presence and growth playing a major part in river flooding.		A lithified (consolidated) sand dune is a type of sandstone that is formed when a marine or aeolian sand dune becomes compacted and hardened. Once in this form, water passing through the rock can carry and deposit minerals, which can alter the color of the rock. Cross-bedded layers of stacks of lithified dunes can produce the cross-hatching patterns, such as those seen in the Zion National Park in the western United States.		A slang term, used in the southwest US, for consolidated and hardened sand dunes is "slickrock", a name that was introduced by pioneers of the Old West because their steel-rimmed wagon wheels could not gain traction on the rock.		Sand dunes can have a negative impact on humans when they encroach on human habitats. Sand dunes move via a few different means, all of them helped along by wind. One way that dunes can move is by saltation, where sand particles skip along the ground like a bouncing ball. When these skipping particles land, they may knock into other particles and cause them to move as well, in a process known as creep. With slightly stronger winds, particles collide in mid-air, causing sheet flows. In a major dust storm, dunes may move tens of metres through such sheet flows. Also as in the case of snow, sand avalanches, falling down the slipface of the dunes—that face away from the winds—also move the dunes forward.		Sand threatens buildings and crops in Africa, the Middle East, and China. Drenching sand dunes with oil stops their migration, but this approach is quite destructive to the dunes' animal habitats and uses a valuable resource. Sand fences might also slow their movement to a crawl, but geologists are still analyzing results for the optimum fence designs.[citation needed] Preventing sand dunes from overwhelming towns, villages, and agricultural areas has become a priority for the United Nations Environment Programme. Planting dunes with vegetation also helps to stabilise them.		Dune habitats provide niches for highly specialized plants and animals, including numerous rare species and some endangered species. Due to widespread human population expansion, dunes face destruction through land development and recreational usages, as well as alteration to prevent the encroachment of sand onto inhabited areas. Some countries, notably the United States, Australia, Canada, New Zealand, the United Kingdom, Netherlands, and Sri Lanka have developed significant programs of dune protection through the use of sand dune stabilization. In the U.K., a Biodiversity Action Plan has been developed to assess dunes loss and to prevent future dunes destruction.		Dunes can likely be found in any environment where there is a substantial atmosphere, winds, and dust to be blown. Dunes are common on Mars and in the equatorial regions of Titan.		Titan's dunes include large expanses with modal lengths of about 20–30 km. The regions are not topographically confined, resembling sand seas. These dunes are interpreted to be longitudinal dunes whose crests are oriented parallel to the dominant wind direction, which generally indicates west-to-east wind flow. The sand is likely composed of hydrocarbon particles, possibly with some water ice mixed in.[25]		
A tidal marsh is a type of marsh that is found along rivers, coasts and estuaries of which the flooding characteristics are determined by the tidal movement of the adjacent estuary, sea or ocean.[1] Tidal wetlands experience many overlapping persistent cycles, including day-night temperature fluctuations, diurnal tides, semi-diurnal tides, spring-neap tides, seasonal vegetation growth and decay, decadal El Niño-Southern Oscillation climate variations, and centennial to millennial trends in sea level and climate. They are also impacted by transient disturbances such as hurricanes, floods, storms, and upland fires.		According to the salinity of the flooding water, tidal marshes are differentiated into freshwater, brackish and saline varieties. They may also be classified into coastal marshes and estuarine marshes on the basis of their landscape position. From landscape position one can infer a lot about the origin, controlling processes, age, disturbance regime, and future of a tidal marsh. Tidal freshwater marshes are further divided into deltaic and fringing types[2]. Extensive research has been conducted on deltaic tidal freshwater marshes in Chesapeake Bay[3], which saw many form as a result of historic deforestation and intensive agriculture[4].		Internally, individual marshes of each salinity level are commonly zoned into lower marshes (also called intertidal marshes) and upper or high marshes, based on their elevation with respect to the sea level.[1][5] In tidal freshwater marshes there can also be a middle marsh zone[6].		In addition they may also be classified into back-barrier marshes, estuarine brackish marshes and tidal freshwater marshes, according to the degree of the influence of the sea level.[5]		Tidal Marshes can contain island off their shore called barrier islands. These cigar shaped islands form parallel and close to the shoreline of a tidal marsh.[7] The islands fully exposed during low tide look like a hill, and during a high tide being fully surrounded by water look like an island. Formation of barrier islands have been explained in many ways by history’s scientific minds, some mechanisms of barrier island formation are offshore bar theory, spit accretion theory, and formation can even be due to climate change.[8][9] Contrary to what one might think the presence of saline resistant plants does not affect the erosion rates of tidal marsh islands, rather the contributing factor to erosion rates is the soil type of the island.[10]		
The continental shelf is an underwater landmass which extends from a continent, resulting in an area of relatively shallow water known as a shelf sea. Much of the shelves were exposed during glacial periods and interglacial periods.		The shelf surrounding an island is known as an insular shelf.		The continental margin, between the continental shelf and the abyssal plain, comprises a steep continental slope followed by the flatter continental rise. Sediment from the continent above cascades down the slope and accumulates as a pile of sediment at the base of the slope, called the continental rise. Extending as far as 500 km (310 mi) from the slope, it consists of thick sediments deposited by turbidity currents from the shelf and slope.[1] The continental rise's gradient is intermediate between the slope and the shelf, on the order of 0.5–1°.[2]		Under the United Nations Convention on the Law of the Sea, the name continental shelf was given a legal definition as the stretch of the seabed adjacent to the shores of a particular country to which it belongs.						The width of the continental shelf varies considerably – it is not uncommon for an area to have virtually no shelf at all, particularly where the forward edge of an advancing oceanic plate dives beneath continental crust in an offshore subduction zone such as off the coast of Chile or the west coast of Sumatra. The largest shelf – the Siberian Shelf in the Arctic Ocean – stretches to 1,500 kilometers (930 mi) in width. The South China Sea lies over another extensive area of continental shelf, the Sunda Shelf, which joins Borneo, Sumatra, and Java to the Asian mainland. Other familiar bodies of water that overlie continental shelves are the North Sea and the Persian Gulf. The average width of continental shelves is about 80 km (50 mi). The depth of the shelf also varies, but is generally limited to water shallower than 150 m (490 ft).[3] The slope of the shelf is usually quite low, on the order of 0.5°; vertical relief is also minimal, at less than 20 m (66 ft).[4]		Though the continental shelf is treated as a physiographic province of the ocean, it is not part of the deep ocean basin proper, but the flooded margins of the continent.[5] Passive continental margins such as most of the Atlantic coasts have wide and shallow shelves, made of thick sedimentary wedges derived from long erosion of a neighboring continent. Active continental margins have narrow, relatively steep shelves, due to frequent earthquakes that move sediment to the deep sea.[6]		The shelf usually ends at a point of increasing slope[7] (called the shelf break). The sea floor below the break is the continental slope. Below the slope is the continental rise, which finally merges into the deep ocean floor, the abyssal plain. The continental shelf and the slope are part of the continental margin.		The shelf area is commonly subdivided into the inner continental shelf, mid continental shelf, and outer continental shelf, each with their specific geomorphology and marine biology.		The character of the shelf changes dramatically at the shelf break, where the continental slope begins. With a few exceptions, the shelf break is located at a remarkably uniform depth of roughly 140 m (460 ft); this is likely a hallmark of past ice ages, when sea level was lower than it is now.[8]		The continental slope is much steeper than the shelf; the average angle is 3°, but it can be as low as 1° or as high as 10°.[9] The slope is often cut with submarine canyons. The physical mechanisms involved in forming these canyons were not well understood until the 1960s.[10]		The continental shelves are covered by terrigenous sediments; that is, those derived from erosion of the continents. However, little of the sediment is from current rivers; some 60–70% of the sediment on the world's shelves is relict sediment, deposited during the last ice age, when sea level was 100–120 m lower than it is now.[11]		Sediments usually become increasingly fine with distance from the coast; sand is limited to shallow, wave-agitated waters, while silt and clays are deposited in quieter, deep water far offshore.[12] These accumulate 15–40 cm every millennium, much faster than deep-sea pelagic sediments.[13]		Continental shelves teem with life, because of the sunlight available in shallow waters, in contrast to the biotic desert of the oceans' abyssal plain. The pelagic (water column) environment of the continental shelf constitutes the neritic zone, and the benthic (sea floor) province of the shelf is the sublittoral zone.[14]		Though the shelves are usually fertile, if anoxic conditions prevail during sedimentation, the deposits may over geologic time become sources for fossil fuels.		The relatively accessible continental shelf is the best understood part of the ocean floor. Most commercial exploitation from the sea, such as metallic-ore, non-metallic ore, and hydrocarbon extraction, takes place on the continental shelf. Sovereign rights over their continental shelves up to a depth of 200 metres or to a distance where the depth of waters admitted of resource exploitation were claimed by the marine nations that signed the Convention on the Continental Shelf drawn up by the UN's International Law Commission in 1958. This was partly superseded by the 1982 United Nations Convention on the Law of the Sea.[15] which created the 200 nautical mile exclusive economic zone and extended continental shelf rights for states with physical continental shelves that extend beyond that distance.		The legal definition of a continental shelf differs significantly from the geological definition. UNCLOS states that the shelf extends to the limit of the continental margin, but no less than 200 nautical miles from the baseline. Thus inhabited volcanic islands such as the Canaries, which have no actual continental shelf, nonetheless have a legal continental shelf, whereas uninhabitable islands have no shelf.		
Manhattan Beach is a city in southwestern Los Angeles County, California, United States, on the Pacific coast south of El Segundo, and north of Hermosa Beach. Manhattan Beach is one of the three Beach Cities that make up the South Bay. Mira Costa High School in Manhattan Beach is ranked in the top 1% of high schools nationally.[10]						In 1863, a Scottish immigrant, Sir Robert Burnett, purchased Rancho Sausal Redondo and Rancho Aguaje de la Centinela from Avila's heirs for $33,000. Ten years later in 1873, Burnett leased the ranch to a Canadian, Daniel Freeman (not the American Daniel Freeman, who was the first to file a claim under the Homestead Act of 1862). Burnett returned to Scotland. Freeman moved his wife and three children onto the ranch and started growing various crops. On May 4, 1885, Freeman bought the ranch from Burnett for $140,000.		George H. Peck owned a lot of the land that became part of the north section of Manhattan Beach. A coin flip decided the town's name. Around 1902, the beach suburb was named "Manhattan" after developer Stewart Merrill's home, the New York City borough of Manhattan. "Beach" was appended to the city's name in 1927 at the behest of the postmaster.[11]		The land in Manhattan Beach was formerly sand dunes. During the 1920s and 1930s, builders leveled uneven sandy sites and some excess sand was sold and shipped to Waikiki, Hawaii, to convert their reef and rock beach into a sandy beach. The sand was also used to build the Los Angeles Coliseum and portions of the Pacific Coast Highway.		Manhattan Beach benefits from ocean breezes that provide clean air and summer temperatures that are 10 to 20 °F (5.6 to 11.1 °C) cooler than the inland regions of Southern California. The Manhattan Beach Unified School District has test scores ranked #3 in the state of California according to California Department of Education statistics. Forbes magazine ranked Manhattan Beach Unified as the sixth best School District in the U.S. According to a July 5, 2014, article in the Beach Reporter newspaper, the city of Manhattan Beach has more educated residents (according to percentage of residents with bachelor's degree or higher) than any other Los Angeles suburb.[12]		Many high-profile individuals in the sports and entertainment industry live in Manhattan Beach due to its oceanfront desirability, top performing school district, and commuting distance to Los Angeles.[13] GQ Magazine named Manhattan Beach one of the nation's six best beaches in their July 2014 issue.		The city has a total area of 3.9 square miles (10 km2). Manhattan Beach features 2.1 miles (3.4 km) of ocean frontage.		Manhattan Beach is a hotspot for beach volleyball and surfing.		A majority of the land in Manhattan Beach was once exposed sand dunes which now lie beneath the city's buildings and streets. The underlying dunes afford residents ocean views throughout western portions of the city. The tallest hill is 244 feet high and located in the city's southwest region. The only remaining exposed sand dune is at Sand Dune Park, where sand resembling the original landscape can also be found. In the late 1920s, Manhattan Beach excess sand was purchased by Hawaiʻian developers, who negotiated a deal with the Kuhn Brothers Construction Company to ship the sand across the Pacific Ocean from Manhattan Beach via Los Angeles Harbor to Waikiki Beach over a 10-year period.		The beach is approximately 400 feet wide and 2.1 miles long. In the early part of the last century, the beach was narrow (approximately 150 feet) and sloping. From 1938 to 1989, it more than doubled in width when large quantities of sand were placed on beaches to the north during construction of the Hyperion Treatment Plant, Marina Del Rey, and Scattergood Power Plant. The sand was carried southward by the ocean's natural littoral flow and widened Manhattan Beach.[14]		Every August, the city hosts the Manhattan Beach Open Volleyball Tournament and the International Surf Festival.		Residents have divided the city into several distinct neighborhoods, including the "Sand Section", "Hill Section", "Tree Section", "Gas Lamp Section", "The Village", "Manhattan Heights", "The Knolls"(East Manhattan Beach), "Liberty Village", "Poet's Section" (Shelley, Tennyson, Longfellow, Keats), and "El Porto" (North Manhattan Beach).		The "Hill Section" is known for its high priced homes where many of the residences are remodeled or newly constructed. The steep hills allow panoramic ocean and city views.		The nearby "Sand Section" is notable for its quiet walk-street neighborhoods adjacent to the ocean. Oceanfront homes stretch along the bike path and walking lane of "The Strand". "The Strand" section of Manhattan Beach includes some of the most expensive real estate per square foot in the United States.[15]		Since 2010, new property developments in Manhattan Beach cannot exceed two lot parcels. Size and appearance restrictions were enacted by the Manhattan Beach City Council to preserve the appearance of the beachfront community after three lots were joined to create a 16,000 square foot oceanside home in 2008.[16]		"Downtown" Manhattan Beach is considered the heart of the city. The area runs along Manhattan Beach Boulevard and the streets perpendicular to the Manhattan Beach Pier and Valley Drive. There are many Zagat rated casual-fine dining restaurants, specialty boutiques and retailers that create a pedestrian friendly, mixed-use downtown center. The Metlox site, where the pottery factory once stood for decades, was closed in the early 1990s and redeveloped into a mixed-use center. The new Metlox site includes a luxury boutique hotel, spa, restaurants, shops and underground parking.		North Manhattan Beach business district is located near the intersection of Rosecrans and Highland and has many excellent restaurants and shops. The district is defined as covering "32nd Street to 45th Street and consist[s] of over 80 businesses".[17]		The "Rosecrans corridor" is located on the south side of Rosecrans Avenue, east of Sepulveda, and west of Aviation.		The Manhattan Beach Country Club, the Marriott Hotel and Golf Course, Fry's electronics, retail stores, restaurants, supermarkets, multi-story office buildings, and shopping centers border the Rosecrans corridor between Sepulveda and Aviation Boulevards. The Rosecrans corridor is adjacent to The Point[18] and Plaza El Segundo[19] off Sepulveda Blvd, which features additional retailers including Whole Foods Market.		The "Sepulveda Corridor" occupies the commercial zone, and is the city's main north-south highway. The area includes the Manhattan Village Mall, which is located east of Sepulveda Boulevard between Marine and Rosecrans Avenues. The mall, built in the early 1980s, was remodeled in the late 1990s and early 2000s. The mall is anchored by Macy's on both ends and tenants include Pottery Barn, Pottery Barn Kids, Williams-Sonoma, and the Apple Store. Many restaurants such as Islands, Chili's, Olive Garden, and the Tin Roof are co-located with the mall. The Manhattan Village Mall is planning a new multimillion-dollar redevelopment which will add both outdoor and enclosed retail and restaurant space. There are several medium-size hotels, large automobile dealerships, automotive repair shops, restaurants, multi-story office buildings, medical buildings, pharmacies, banks, small shopping centers and a Target store along this corridor.		The "Aviation Corridor" is located along Aviation Boulevard (the city's eastern boundary), south of Rosecrans Avenue, and north of Marine Avenue. Aviation High School was located at the intersection of Manhattan Beach Blvd and Aviation until it closed in the early 1980s.[20] The zone includes several major entertainment and aerospace complexes, including Manhattan Beach Studios[21] and the Northrop Grumman Space Park Complex.[22] Manhattan Beach Media Campus is home to the production of many popular releases in movies and entertainment, including the Marvel pictures "Thor" and "Iron Man 2" and both sequels to James Cameron's "Avatar" movie.[23] The studio complex is equipped with one of the largest photovoltaic solar panel rooftop installations in the area which generates approximately 1 megawatt of power.		Manhattan Beach is known for its clean, wide, sandy beaches and attracts over 3.8 million visitors annually.[24] Along the Strand at the eastern edge of the beach, a concrete bike path is reserved for bicycles. The bikeway extends north to Santa Monica and south to Palos Verdes. A separate 2.1 mile walkway, reserved for pedestrians, runs alongside the bike path. Restrooms and shower facilities are provided adjacent to the Strand paths. Beach volleyball, swimming, body boarding and surfing are popular activities among residents and visitors. Popular surf spots include the Pier and El Porto. Lifeguard stations are located along the entire length of the beach and the beach is cleaned and groomed daily by crews from LA County Beaches and Harbors Department.		CNN Money named Manhattan Beach #1 as the "2011 Best Places For the Rich and Single",[25] while The Travel Channel named Manhattan Beach the 9th sexiest beach on earth for its 2008 "21 Sexiest Beaches" show.[26] Manhattan Beach has also been nicknamed the "Pearl of the South Bay" for its beauty and desirability.		There are several public parks in the city. The largest and most popular is Polliwog Park located on Manhattan Beach Boulevard, two blocks west of Aviation Boulevard. Polliwog Park has a small lake, open-air concert amphitheater, playground equipment, picnic tables, restrooms, and a fenced dog exercise area. It is also the site of the Manhattan Beach Historical Society Red Cottage, which is home to the city's collection of historical artifacts. Marine Avenue Park, west of Aviation Boulevard on Marine, has several lighted ball fields, basketball courts, and an indoor racket ball facility. Live Oak Park in the downtown area has ball fields, playground equipment, tennis courts and picnic tables.		An area known as the "Green Belt" or "Veteran's Parkway" is a pedestrian-friendly walkway that runs adjacent to Valley Drive and Ardmore Avenue near downtown Manhattan Beach. Nearly 20 acres total and comprising 3 miles in length, the wood-chip walkway is a popular trail for runners and dog-walkers.		For over 50 years, the city of Manhattan Beach hosts an annual Hometown Fair[27] at Live Oak Park in downtown Manhattan Beach. Popular among community residents, the fair features food and drink, live music, games and booths to raise funds for local causes.		The 2010 United States Census[29] reported that Manhattan Beach had a population of 35,135. The population density was 8,914.7 people per square mile (3,442.0/km²). The racial makeup of Manhattan Beach was 29,686 (84.5%) White (79.3% Non-Hispanic White),[30] 290 (0.8%) Black or African American (U.S. Census), 59 (0.2%) Native American, 3,023 (8.6%) Asian, 49 (0.1%) Pacific Islander, 409 (1.2%) from other races, and 1,619 (4.6%) from two or more races. Hispanic or Latino of any race were 2,440 persons (6.9%).		The Census reported that 35,107 people (99.9% of the population) lived in households, 28 (0.1%) lived in non-institutionalized group quarters, and 0 (0%) were institutionalized.		There were 14,038 households, out of which 4,735 (33.7%) had children under the age of 18 living in them, 7,583 (54.0%) were opposite-sex married couples living together, 892 (6.4%) had a female householder with no husband present, 438 (3.1%) had a male householder with no wife present. There were 695 (5.0%) unmarried opposite-sex partnerships, and 85 (0.6%) same-sex married couples or partnerships. 3,627 households (25.8%) were made up of individuals and 1,078 (7.7%) had someone living alone who was 65 years of age or older. The average household size was 2.50. There were 8,913 families (63.5% of all households); the average family size was 3.10.		The population was spread out with 8,725 people (24.8%) under the age of 18, 1,740 people (5.0%) aged 18 to 24, 9,532 people (27.1%) aged 25 to 44, 10,681 people (30.4%) aged 45 to 64, and 4,457 people (12.7%) who were 65 years of age or older. The median age was 40.9 years. For every 100 females there were 100.4 males. For every 100 females age 18 and over, there were 99.2 males. There were 14,929 housing units at an average density of 3,787.9 per square mile (1,462.5/km²), of which 9,420 (67.1%) were owner-occupied, and 4,618 (32.9%) were occupied by renters. The homeowner vacancy rate was 0.8%; the rental vacancy rate was 5.3%. 25,587 people (72.8% of the population) lived in owner-occupied housing units and 9,520 people (27.1%) lived in rental housing units.		According to the 2010 United States Census, Manhattan Beach had a median household income of $139,259, with 3.4% of the population living below the federal poverty line.[30]		Residential prices in Manhattan Beach are among the highest in the state of California. In 2013, the Dataquick study reported that more homes exceeding $1 million were sold in Manhattan Beach than any other city in California. Pacific Palisades, Beverly Hills, La Jolla, Malibu, Bel-Air, Orinda, Atherton, Montecito, and other high end cities in California ranked behind Manhattan Beach. The Higley 100 Census survey found that The Hill Section of Manhattan Beach is the second highest mean household income neighborhood in Los Angeles County, with Beverly Park ranking first and Beverly Hills (the 90210 section) ranking third, respectively.[31] The current median residential home price is $2.2 million according to a Nov. 23, 2014, Los Angeles Times article, and land values in Manhattan Beach rank among the highest per square foot in the nation.[32] Land values on the Manhattan Beach "Strand" are routinely around $10 million for a 3,000 square foot piece of land.		According to the City's 2010 Comprehensive Annual Financial Report,[33] the top employers in the city are:		The city of Manhattan Beach is governed by a five-member City Council. City Council members are elected every four years. The office of the Mayor of Manhattan Beach rotates every ten months among the members of the City Council, so that each City Council member serves one term as Mayor. A City Manager is appointed by the City Council. An elected City Treasurer serves a four-year term.		The Beach Cities Health District,[34] provides health and wellness services to the residents of Hermosa Beach, Manhattan Beach, and Redondo Beach. The voters of the three beach cities elect the 5-member Board of Directors to 4-year terms. One of 78 California Health Districts,[35] it was created in 1955 as South Bay Hospital and took on its current name in 1993. Beach Cities Health District opened AdventurePlex,[36] a Manhattan Beach fitness center for kids and their families, in 2002. Filled with mazes, tunnels, outdoor rock climbing walls, complex ropes courses, and an indoor gym, AdventurePlex challenges children physically and intellectually in health-focused recreational activities.		Manhattan Beach is in the Fourth Supervisorial District of Los Angeles County. Don Knabe is the District Supervisor. The county collects taxes on properties in Manhattan Beach and maintains property assessment rolls. Los Angeles County maintains the beach and provides daily cleaning and grooming. The county also maintains the bike path at the eastern edge of the beach. The Manhattan Beach County Library is located downtown on Highland Avenue two blocks north of Manhattan Beach Boulevard. The library is part of the County of Los Angeles Public Library system, and includes internet accessible computers, WiFi, and access to the six million items in the county library collection. The new $19 million, 20,000 square foot, two story facility featuring a glass exterior was completed in 2015.		In the California State Legislature, Manhattan Beach is in the 26th Senate District, represented by Democrat Ben Allen, and in the 66th Assembly District, represented by Democrat Al Muratsuchi.[37]		In the United States House of Representatives, Manhattan Beach is in California's 33rd congressional district, represented by Democrat Ted Lieu.[38]		Manhattan Beach is currently ranked as one of the best suburbs in Los Angeles Country for its high-earning and well educated residents.[39] According to US Census data, Manhattan Beach holds the ranking as the second most educated city in Los Angeles County and the fifth most educated city in the state of California.[40] Manhattan Beach's top performing school district is currently ranked as the third best in the state of California,[41] and Forbes Magazine ranked the city's school district, MBUSD, as the sixth best school district in the United States.[42]		Public education in Manhattan Beach is provided by the Manhattan Beach Unified School District, which oversees five elementary schools (Grandview, Meadows, Pacific, Pennekamp, Robinson), one middle school (Manhattan Beach Middle School), and one high school (Mira Costa).		The Manhattan Beach Unified School district is ranked as the third best performing school district in the state of California. The district received a score of 926 on the 2010 California Academic Performance Index.[43] Each individual school also ranks at the top of its respective category.[44]		Private schools located in Manhattan Beach include American Martyrs Catholic School, Manhattan Academy, Montessori School of Manhattan Beach and Journey of Faith Christian School.		Manhattan Beach is served by Easy Reader-Manhattan Beach, Beach Magazine, the Daily Breeze, the Los Angeles Times, and the Beach Reporter.		Filming locations		Other		See: List of people from Manhattan Beach, California		Coordinates: 33°53′20″N 118°24′19″W﻿ / ﻿33.88889°N 118.40528°W﻿ / 33.88889; -118.40528		
A reef is a bar of rock, sand, coral or similar material, lying beneath the surface of water. Reefs may be up to 261 feet (80 m) below the surface.[citation needed]		Many reefs result from abiotic processes—deposition of sand, wave erosion planing down rock outcrops, and other natural processes—but the best-known reefs are the coral reefs of tropical waters developed through biotic processes dominated by corals and calcareous algae. Artificial reefs such as shipwrecks are sometimes created to enhance physical complexity on generally featureless sand bottoms in order to attract a diverse assemblage of organisms, especially fish.						There is a variety of biotic reef types, including oyster reefs, but the most massive and widely distributed are tropical coral reefs. Although corals are major contributors to the framework and bulk material comprising a coral reef, the organisms most responsible for reef growth against the constant assault from ocean waves are calcareous algae, especially, although not entirely, species of coralline algae.		These biotic reef types take on additional names depending upon how the reef lies in relation to the land, if any. Reef types include fringing reef, barrier reefs, as well as atolls. A fringing reef is a reef that is attached to an island. A barrier reef forms a calcareous barrier around an island resulting in a lagoon between the shore and the reef. An atoll is a ring reef with no land present. The reef front (ocean side) is a high energy locale whereas the internal lagoon will be at a lower energy with fine grained sediments.		One useful definition distinguishes reefs from mounds as follows. Both are considered to be varieties of organosedimentary buildups: sedimentary features, built by the interaction of organisms and their environment, that have synoptic relief and whose biotic composition differs from that found on and beneath the surrounding sea floor. Reefs are held up by a macroscopic skeletal framework. Coral reefs are an excellent example of this kind. Corals and calcareous algae grow on top of one another and form a three-dimensional framework that is modified in various ways by other organisms and inorganic processes. By contrast, mounds lack a macroscopic skeletal framework. Mounds are built by microorganisms or by organisms that don't grow a skeletal framework. A microbial mound might be built exclusively or primarily by cyanobacteria. Excellent examples of biostromes formed by cyanobacteria occur in the Great Salt Lake of Utah (USA), and in Shark Bay, Western Australia.		Cyanobacteria do not have skeletons and individuals are microscopic. Cyanobacteria encourage the precipitation or accumulation of calcium carbonate and can produce distinct sediment bodies in composition that have relief on the seafloor. Cyanobacterial mounds were most abundant before the evolution of shelly macroscopic organisms, but they still exist today (stromatolites are microbial mounds with a laminated internal structure). Bryozoans and crinoids, common contributors to marine sediments during the Mississippian (for example), produced a very different kind of mound. Bryozoans are small and the skeletons of crinoids disintegrate. However, bryozoan and crinoid meadows can persist over time and produce compositionally distinct bodies of sediment with depositional relief.		The Proterozoic Belt Supergroup contains evidence of possible microbial mat and dome structures similar to stromatolite reef complexes.[1]		Ancient reefs buried within stratigraphic sections are of considerable interest to geologists because they provide paleo-environmental information about the location in Earth's history. In addition, reef structures within a sequence of sedimentary rocks provide a discontinuity which may serve as a trap or conduit for fossil fuels or mineralizing fluids to form petroleum or ore deposits.		Corals, including some major extinct groups Rugosa and Tabulata, have been important reef builders through much of the Phanerozoic since the Ordovician Period. However, other organism groups, such as calcifying algae, especially members of the red algae Rhodophyta, and molluscs (especially the rudist bivalves during the Cretaceous Period) have created massive structures at various times. During the Cambrian Period, the conical or tubular skeletons of Archaeocyatha, an extinct group of uncertain affinities (possibly sponges), built reefs. Other groups, such as the Bryozoa have been important interstitial organisms, living between the framework builders. The corals which build reefs today, the Scleractinia, arose after the Permian–Triassic extinction event that wiped out the earlier rugose corals (as well as many other groups), and became increasingly important reef builders throughout the Mesozoic Era. They may have arisen from a rugose coral ancestor. Rugose corals built their skeletons of calcite and have a different symmetry from that of the scleractinian corals, whose skeletons are aragonite. However, there are some unusual examples of well-preserved aragonitic rugose corals in the late Permian. In addition, calcite has been reported in the initial post-larval calcification in a few scleractinian corals. Nevertheless, scleractinian corals (which arose in the middle Triassic) may have arisen from a non-calcifying ancestor independent of the rugosan corals (which disappeared in the late Permian).		
The Côte d'Azur (French pronunciation: ​[kot daˈzyʁ]; Occitan: Còsta d'Azur pronounced [ˈkɔstɔ daˈzyɾ]; literal translation "Coast of Azure"), often known in English as the French Riviera, is the Mediterranean coastline of the southeast corner of France, also including the state of Monaco. There is no official boundary, but it is usually considered to extend from the Italian border (Italian Riviera) in the east to Saint-Tropez, Hyères, Toulon, or Cassis in the west.[1][2]		This coastline was one of the first modern resort areas. It began as a winter health resort for the British upper class at the end of the 18th century. With the arrival of the railway in the mid-19th century, it became the playground and vacation spot of British, Russian, and other aristocrats, such as Queen Victoria and King Edward VII, when he was Prince of Wales. In the summer, it also played home to many members of the Rothschild family. In the first half of the 20th century, it was frequented by artists and writers, including Pablo Picasso, Henri Matisse, Edith Wharton, Somerset Maugham, and Aldous Huxley, as well as wealthy Americans and Europeans. After World War II, it became a popular tourist destination and convention site. Many celebrities, such as Elton John and Brigitte Bardot, have homes in the region. Officially, the Côte d'Azur is home to 163 nationalities with 83,962 foreign residents,[3] although estimates of the number of non-French nationals living in the area are often much higher.[4]		Its largest city is Nice, which has a population of 347,060 (2006).[5] The city is the center of a communauté urbaine – Nice-Côte d'Azur – bringing together 24 communes and more than 500,000 inhabitants and 933,080 in the urban area.		Nice is home to Nice Côte d'Azur Airport, France's third-busiest airport (after Paris-Charles de Gaulle Airport and Paris-Orly), which is on an area of partially reclaimed coastal land at the western end of the Promenade des Anglais. A second airport at Mandelieu was once the region's commercial airport,[6] but is now mainly used by private and business aircraft.[7] The A8 autoroute runs through the region, as does the old main road generally known as the Route nationale 7 (officially now the DN7 in the Var and the D6007 in the Alpes-Maritimes).[8] Trains serve the coastal region and inland to Grasse, with the TGV Sud Est service reaching Nice-Ville station in five and a half hours from Paris.		The French Riviera has a total population of more than two million. It contains the seaside resorts of Cap-d'Ail, Beaulieu-sur-Mer, Saint-Jean-Cap-Ferrat, Villefranche-sur-Mer, Antibes, Juan-les-Pins, Cannes, Saint-Raphaël, Fréjus, Sainte Maxime and Saint-Tropez,[9] It is also home to a high-tech/science park or technopole at Sophia-Antipolis (north of Antibes), and a research and technology center at the University of Nice Sophia-Antipolis. The region has 35,000 students, of whom 25 percent are working toward a doctorate.[10]		The French Riviera is a major yachting and cruising area with several marinas along its coast. According to the Côte d'Azur Economic Development Agency, each year the Riviera hosts 50 percent of the world's superyacht fleet, with 90 percent of all superyachts visiting the region's coast at least once in their lifetime.[11]		As a tourist center, French Riviera benefits from 310 to 330 days of sunshine per year, 115 kilometres (71 miles) of coastline and beaches, 18 golf courses, 14 ski resorts and 3,000 restaurants.[12]						The name Côte d'Azur was given to the coast by the writer Stéphen Liégeard in his book, La Côte d’azur, published in December 1887.[13] Liégeard was born in Dijon, in the French department of Côte-d'Or, and adapted that name by substituting the azure blue color of the Mediterranean for the gold of Côte-d'Or.[14]		The term French Riviera is typical of English use. It was built by analogy with the term Italian Riviera, which extends east of the French Riviera (from Ventimiglia to La Spezia).[15] As early as the 19th century, the British referred to the region as the Riviera or the French Riviera, usually referring to the eastern part of the coast, between Monaco and the Italian border.[16] Originally, riviera is an Italian noun which means "coastline".[17]		In Occitan (Niçard and Provençal) and French, the only usual names are Còsta d'Azur in Occitan and Côte d'Azur in French.[18] A name like "French Riviera" (Ribiera Francesa in Occitan, Riviera Française in French) is unusual and sounds odd; it could only work as a word-to-word translation of the British point of view. For instance, in French, "Riviera Française" is found in the online Larousse encyclopedia[19] to refer to the holidays of a group of English workers (moreover, in Occitan, the word ribiera "coastline" mostly works as a common name, whereas in French, the old-fashioned term Rivière de Gênes was used to refer to the Italian Riviera whose center is Genoa).[20]		The Côte d'Azur and the French Riviera have no official boundaries. Some sources put the western boundary at Saint-Tropez in the Var département. Others include Saint Tropez, Hyères or Toulon in the Var (departement), or as far as Cassis in the Bouches-du-Rhône département.[1][2] In her 1955 novel, The Talented Mr. Ripley, Patricia Highsmith describes the Riviera as including all of the coast between Toulon and the Italian border.		The Côte d'Azur has been inhabited since prehistoric times. Primitive tools dating to between 1,000,000 and 1,050,000 years ago were discovered in the Grotte du Vallonnet, near Roquebrune-Cap-Martin, with stones and bones of animals, including bovines, rhinoceros, and bison. At Terra Amata (380,000 to 230,000 years ago), near the Nice Port, a fireplace was discovered that is one of the oldest found in Europe.[21]		Stone dolmens, monuments from the Bronze Age, can be found near Draguignan, while the Valley of Marvels (Vallée des Merveilles) near Mount Bégo, at 2,000 m (6,600 ft) elevation, is presumed to have been an outdoor religious sanctuary, having over 40,000 drawings of people and animals, dated to about 2000 BC.[22]		Beginning in the 7th century BC, Greek sailors from Asia Minor began to visit and then build trading posts (emporia) along the Côte d'Azur. Emporia were started at Olbia (Saint-Pierre-de-l'Almanarre, near Hyères); Antipolis (Antibes) and Nicaea (Nice). These settlements, which traded with the inhabitants of the interior, became rivals of the Etruscans and Phoenicians, who also visited the Côte d'Azur.		In 8 BC the Emperor Augustus built an imposing trophy monument at La Turbie (the Trophy of the Alps or Trophy of Augustus) to mark the pacification of the region.		Roman towns, monuments and amphitheatres were built along the Côte d'Azur and many still survive, such as the amphitheatre and baths at Cimiez, above Nice, and the amphitheatre, Roman walls and other remains at Fréjus.		Roman Provence reached the height of its power and prosperity during the 2nd and 3rd centuries AD. In the mid-3rd century, Germanic peoples began to invade the region, and Roman power weakened.		In the same period, Christianity started to become a powerful force in the region. The first cathedrals were built in the 4th century, and bishoprics were established: in Fréjus at the end of the 4th century, Cimiez and Vence in 439, and Antibes in 442. The oldest Christian structure still in existence on the Côte d'Azur is the baptistery of Fréjus Cathedral, built at the end of the 5th century, which also saw the founding of the first monastery in the region, Lerins Monastery on an island off the coast at Cannes.		The fall of the Western Roman Empire in the first half of the 5th century was followed by invasions of Provence by the Visigoths, the Burgundians and the Ostrogoths. There was then a long period of wars and dynastic quarrels, which in turn led to further invasions by the Saracens and the Normans in the 9th century.		Some peace was restored to the coast by the establishment in 879 of a new kingdom of Provence, ruled first by the Bosonids dynasty (879–1112), then by the Catalans (1112–1246), and finally by the Angevins (1246–1382, elder branch, 1382–1483 (younger branch).		In the 13th century, another powerful political force appeared, the House of Grimaldi. Descended from a Genoese nobleman expelled from Genoa by his rivals in 1271, members of the different branches of the Grimaldis took power in Monaco, Antibes and Nice, and built castles at Grimaud, Cagnes-sur-Mer and Antibes. Albert II, the current Prince of Monaco is a descendant of the Grimaldis.		In 1388, the city of Nice and its surrounding territory, from the mouth of the Var to the Italian border, were separated from Provence and came under the protection of the House of Savoy. The territory was called the Comté de Nice after 1526, and thereafter its language, history and culture were separate from those of Provence until 1860, when it was re-attached to France under Napoleon III.		Provence retained its formal independence until 1480, when the last Comte de Provence, René I of Naples, died and left the Comté to his nephew, Charles du Maine, who in turn left it to Louis XI of France. In 1486, Provence formally became part of France.		Until the end of the 18th century, the area later known as the Côte d'Azur was a remote and impoverished region, known mostly for fishing, olive groves and the production of flowers for perfume (manufactured in Grasse).		A new phase began when the coast became a fashionable health resort for the British upper class in the late 18th century. The first British traveller to describe its benefits was the novelist Tobias Smollett, who visited Nice in 1763 when it was still an Italian city within the Kingdom of Sardinia. Smollett brought Nice and its warm winter climate to the attention of the British aristocracy with Travels through France and Italy, written in 1765. At about the same time, a Scottish doctor, John Brown, became famous for prescribing what he called climato-therapy, a change in climate, to cure a variety of diseases including tuberculosis, known then as consumption. The French historian Paul Gonnet wrote that, as a result, Nice was filled with "a colony of pale and listless English women and listless sons of nobility near death".		In 1834, a British nobleman and politician named Henry Peter Brougham, First Baron Brougham and Vaux, who had played an important part in the abolition of the slave trade, travelled with an unwell sister to the south of France, intending to go to Italy. A cholera epidemic in Italy forced him to stop at Cannes, where he enjoyed the climate and scenery so much that he bought land and built a villa. He began to spend his winters there and, owing to his fame, others followed: Cannes soon had a small British enclave.		Robert Louis Stevenson was a later British visitor who came for his health. In 1882 he rented a villa called La Solitude at Hyères, where he wrote much of A Child's Garden of Verses.		In 1864, six years after Nice became part of France following the Second Italian War of Independence the first railway was completed, making Nice and the Riviera accessible to visitors from all over Europe. One hundred thousand visitors arrived in 1865. By 1874, residents of foreign enclaves in Nice, most of whom were British, numbered 25,000.		In the mid-19th century British and French entrepreneurs began to see the potential of promoting tourism along the Côte d'Azur. At the time, gambling was illegal in France and Italy. In 1856, the Prince of Monaco, Charles III, began constructing a casino in Monaco, which was called a health spa to avoid criticism by the church. The casino was a failure, but in 1863 the Prince signed an agreement with François Blanc, a French businessman already operating a successful casino at Baden-Baden (southwestern Germany), to build a resort and new casino. Blanc arranged for steamships and carriages to take visitors from Nice to Monaco, and built hotels, gardens and a casino in a place called Spélugues. At the suggestion of his mother, Princess Caroline, Charles III renamed the place Monte Carlo after himself. When the railway reached Monte Carlo in 1870, many thousands of visitors began to arrive and the population of the principality of Monaco doubled.		The French Riviera soon became a popular destination for European royalty. Just days after the railway reached Nice in 1864, Tsar Alexander II of Russia visited on a private train, followed soon afterwards by Napoleon III and then Leopold II, the King of the Belgians.		Queen Victoria was a frequent visitor. In 1882 she stayed in Menton, and in 1891 spent several years at the Grand Hotel at Grasse. In 1892 she stayed at the Hotel Cost-belle in Hyères. In successive years from 1895 to 1899 she stayed in Cimiez in the hills above Nice. First, in 1895 and 1896, she patronised the Grand Hôtel, while in later years she and her staff took over the entire west wing of the Excelsior Hôtel Régina, which had been designed with her needs specifically in mind (part of which later became the home and studio of the renowned artist Henri Matisse). She travelled with an entourage of between sixty and a hundred, including chef, ladies in waiting, dentist, Indian servants, her own bed and her own food.[23]		The Prince of Wales was a regular visitor to Cannes, starting in 1872. He frequented the Club Nautique, a private club on the Croisette, the fashionable seafront boulevard of Cannes. He visited there each spring for a two-month period, observing yacht races from shore while the royal yacht floated, Britannia, was sailed by professional crewmen. After he became King in 1901, he never again visited the French Riviera.		By the end of the 19th century the Côte d'Azur began to attract artistic painters, who appreciated the climate, the bright colors and clear light. Among them were Auguste Renoir, who settled in Cagnes-sur-Mer and in Mougins, Henri Matisse and Pablo Picasso.		The First World War brought down many of the royal houses of Europe and altered the nature and the calendar of the French Riviera. Following the war, greater numbers of Americans began arriving, with business moguls and celebrities eventually outnumbering aristocrats. The 'High Society' scene moved from a winter season to a summer season.		Americans began coming to the south of France in the 19th century. Henry James set part of his novel, The Ambassadors, on the Riviera. James Gordon Bennett Jr, the son and heir of the founder of the New York Herald, had a villa in Beaulieu. Industrialist John Pierpont Morgan gambled at Monte Carlo and bought 18th-century paintings by Fragonard in Grasse – shipping them to the Metropolitan Museum in New York.		A feature of the French Riviera in the inter-war years was the Train Bleu, an all first-class sleeper train which brought wealthy passengers down from Calais. It made its first trip in 1922, and carried Winston Churchill, Somerset Maugham, and the future King Edward VIII over the years.		While Europe was still recovering from the war and the American dollar was strong, American writers and artists started arriving on the Côte d'Azur. Edith Wharton wrote The Age of Innocence (1920) at a villa near Hyères, winning the Pulitzer Prize for the novel (the first woman to do so). Dancer Isadora Duncan frequented Cannes and Nice, but died in 1927 when her scarf caught in a wheel of the Amilcar motor car in which she was a passenger and strangled her. The writer F. Scott Fitzgerald first visited with his wife Zelda in 1924, stopping at Hyères, Cannes and Monte Carlo – eventually staying at Saint-Raphaël, where he wrote much of The Great Gatsby and began Tender is the Night.		While Americans were largely responsible for making summer the high season, a French fashion designer, Coco Chanel, made sunbathing fashionable. She acquired a striking tan during the summer of 1923, and tans then became the fashion in Paris.		During the abdication crisis of the British Monarchy in 1936, Wallis Simpson, the intended bride of King Edward VIII, was staying at the Villa Lou Vieie in Cannes, talking with the King by telephone each day. After his abdication, the Duke of Windsor (as he became) and his new wife stayed at the Villa La Croe near Antibes.		The English playwright and novelist Somerset Maugham also became a resident in 1926, buying the Villa Mauresque toward the tip of Cap Ferrat, near Nice.[24]		When Germany invaded France in June 1940, the remaining British colony was evacuated to Gibraltar and eventually to Britain. American Jewish groups helped some of the Jewish artists living in the south of France, such as Marc Chagall, to escape to the United States. In August 1942, 600 Jews from Nice were rounded up by French police and sent to Drancy, and eventually to death camps. In all about 5,000 French Jews from Nice perished during the war.		On 15 August 1944, American parachute troops landed near Fréjus, and a fleet landed 60,000 troops of the American Seventh Army and French First Army between Cavalaire and Agay, east of Saint-Raphaël. German resistance crumbled in days.		Saint-Tropez was badly damaged by German mines at the time of the liberation. The novelist Colette organized an effort to assure the town was rebuilt in its original style.		When the war ended, artists Marc Chagall and Pablo Picasso returned to live and work.		The Cannes Film Festival was launched in September 1946, marking the return of French cinema to world screens. The Festival Palace was built in 1949 on the site of the old Cercle Nautique, where the Prince of Wales had met his mistresses in the late 19th century. The release of the French film Et Dieu… créa la femme (And God Created Woman) in November 1956 was a major event for the Riviera, making an international star of Brigitte Bardot, and making an international tourist destination of Saint-Tropez, particularly for the new class of wealthy international travellers called the jet set.		The marriage of American film actress Grace Kelly to Prince Rainier of Monaco on 18 April 1956, attracted world attention once again. It was viewed on television by 30 million people.		During the 1960s, the Mayor of Nice, Jacques Médecin, decided to reduce the dependence of the Riviera on ordinary tourism, and to make it a destination for international congresses and conventions. He built the Palais des Congrès at the Acropolis in Nice, and founded a Chagall Museum and a Matisse Museum at Cimiez. High-rise apartment buildings and real estate developments began to spread.		At the end of August, 1997, Princess Diana and Dodi Fayed spent their last days together on his father's yacht off Pampelonne Beach near Saint-Tropez, shortly before they were killed in a traffic accident in the Alma Tunnel in Paris.		Places on the Côte d'Azur (following the broadest definition), following the coast from south-west to north-east, include:		Some data related to tourism on the Riviera in 2006:		The Côte d'Azur has a Mediterranean climate, with sunny, hot, dry summers and mild winters. Winter temperatures are moderated by the Mediterranean; days of frost are rare. The average daily low temperature in Nice in January is 5.4 °C (41.7 °F); the January average daily low temperature in Toulon is 6.2 °C (43.2 °F). The average high temperature in August in Nice is 28.6 °C (83.5 °F); in Toulon the average daily high temperature is 29.7 °C (85.5 °F)		The Côte d'Azur receives more rainfall than Paris annually (803.3 mm (31.63 in) annually in Nice and 684.8 mm (26.96 in) in Toulon compared with 649.8 mm (25.58 in) in Paris), but the rainy days are much less frequent; 111 rainy days a year in Paris compared with 61 days in Toulon and 63 in Nice. Toulon has 2,793 hours of sunshine a year, Nice has 2,668 hours.[25]		Micro-climates exist in these coastal regions, and there can be great differences in the weather between various locations. Strong winds such as the Mistral, a cold dry wind from the northwest or from the east, are another characteristic, particularly in the winter.		Nice and the Alpes-Maritimes département are sheltered by the Alps. The winds are usually gentle, from the sea to the land, though sometimes the mistral blows strongly from the northwest, or, turned by the mountains, from the east. In 1956 a mistral from the northwest reached 180 kilometres per hour (110 mph) at Nice Airport.[25] Sometimes, in summer, the sirocco brings high temperatures and reddish desert sand from the Sahara. (See Winds of Provence.)		Rain can be torrential, particularly in the autumn, when storms and rain are caused by the difference between the colder air inland and the warm Mediterranean water temperature (20–24 °C [68–75 °F]). The rainiest months are September (75.6 millimetres [2.98 in] average rainfall); October (143.9 millimetres [5.67 in]); November (94.3 millimetres [3.71 in]) and December (87.8 millimetres [3.46 in]).[25]		Snow on the coast is rare, falling on average once every ten years. 1956 was exceptional, when 20 cm (7.9 in) blanketed the coast.[25] In January 1985 the coast between Cannes and Menton received 30 to 40 cm (12 to 16 in). In the mountains, snow is present from November to May.		The département of Var (which includes Saint-Tropez and Hyères) has a climate slightly warmer, drier and sunnier than Nice and Alpes-Maritimes, but is less sheltered from the wind.		The mistral wind, which brings cold and dry air down from the upper Alpine regions via the Rhône valley and extends with diminishing intensity along the Côte d'Azur, blows frequently during the winter. Strong winds blow for about 75 days a year in Fréjus.[25]		Several major events take place:		The climate and vivid colors of the Mediterranean attracted many famous artists during the 19th and 20th centuries. They included:		Coordinates: 43°21′54″N 6°50′59″E﻿ / ﻿43.36500°N 6.84972°E﻿ / 43.36500; 6.84972		
Slumping is a technique in which items are made in a kiln by means of shaping glass over molds at high temperatures. The slumping of a pyrometric cone is often used to measure temperature in a kiln.						Slumping glass is a highly technical operation that is subject to many variations, both controlled and uncontrolled. When an item is being slumped in a kiln, the mold over which it is being formed (which can be made of either ceramic, sand or metal) must be coated with a release agent that will stop the molten glass from sticking to the mold. Such release agents, a typical one being boron nitride, give off toxic fumes when they are first heated and must be used in a ventilated area.		The glass is cut to the shape of the mold (but slightly larger to allow for shrinkage) and placed on top of it, before the kiln is heated.		The stages of the firing can be varied but typically start to climb at quite a rapid rate until the heat places the glass in an "orange state" i.e., flexible. At that point, gravity will allow the glass to slump into the mold and the temperature is held at a constant for a period that is known as the "soak". Following this stage, the kiln is allowed to cool slowly so that the slumped glass can anneal and be removed from the kiln. If two differing colours of glass are used in a single piece of work, the same CoE (Coefficient of thermal Expansion) glass must be used, or the finished piece will suffer from fractures as the glass will shrink at differing rates and allow tension to build up to the point of destruction. To compensate for this, many glass manufacturers subscribe to make glass to the same CoE. Examples include Spectrum glass system 96 or uroborus 96 series, and the use of this glass will allow the cooling to remain uniform and ensure that no tension builds up as the work cools.		During the Roman period open vessels, such as bowls and plates, could be produced by forming a glass sheet over a core or former. This technique resulted in vessels with rough surfaces, which could then be ground or polished to a smooth finish.[1] An additional technique, used in the production of Roman pillar-moulded bowls, utilised a slotted tool to impress ribs on the glass sheet prior to slumping. This created a bowl with a ribbed exterior, and these were then polished around the rim and sometimes given horizontal cut lines inside for further decoration.[1]		
A lagoon is a shallow body of water separated from a larger body of water by barrier islands or reefs. Lagoons are commonly divided into coastal lagoons and atoll lagoons. They have also been identified as occurring on mixed-sand and gravel coastlines. There is an overlap between bodies of water classified as coastal lagoons and bodies of water classified as estuaries. Lagoons are common coastal features around many parts of the world.		Lagoons can also be man-made and used for wastewater treatment, as is the case for e.g. aerated lagoons and anaerobic lagoons.						Lagoons are shallow, often elongated bodies of water separated from a larger body of water by a shallow or exposed shoal, coral reef, or similar feature. Some authorities include fresh water bodies in the definition of "lagoon", while others explicitly restrict "lagoon" to bodies of water with some degree of salinity. The distinction between "lagoon" and "estuary" also varies between authorities. Richard A. Davis Jr. restricts "lagoon" to bodies of water with little or no fresh water inflow, and little or no tidal flow, and calls any bay that receives a regular flow of fresh water an "estuary". Davis does state that the terms "lagoon" and "estuary" are "often loosely applied, even in scientific literature."[1] Timothy M. Kusky characterizes lagoons as normally being elongated parallel to the coast, while estuaries are usually drowned river valleys, elongated perpendicular to the coast.[1][2][3][4][5] When used within the context of a distinctive portion of coral reef ecosystems, the term "lagoon" is synonymous with the term "back reef" or "backreef", which is more commonly used by coral reef scientists to refer to the same area.[6] Coastal lagoons are classified as inland bodies of water.[7][8]		Many lagoons do not include "lagoon" in their common names. Albemarle and Pamlico sounds in North Carolina,[9] Great South Bay between Long Island and the barrier beaches of Fire Island in New York,[10] Isle of Wight Bay, which separates Ocean City, Maryland from the rest of Worcester County, Maryland,[11] Banana River in Florida,[12] Lake Illawarra in New South Wales,[13] Montrose Basin in Scotland,[14] and Broad Water in Wales have all been classified as lagoons, despite their names. In England, The Fleet at Chesil Beach has also been described as a lagoon.		In Latin America, the term laguna in Spanish, which lagoon translates to, may be used for a small fresh water lake in a similar way a creek is considered a small river. However, sometimes it is popularly used to describe a full-sized lake, such as Laguna Catemaco in Mexico, which is actually the third largest lake by area in the country. The brackish water lagoon may be thus explicitly identified as a "coastal lagoon" (laguna costera). In Portuguese the same usage is found: lagoa may be a body of shallow sea water, or a small freshwater lake not linked to the sea.		Lagoon is derived from the Italian laguna, which refers to the waters around Venice, the Lagoon of Venice. Laguna is attested in English by at least 1612, and had been Anglicized to "lagune" by 1673. In 1697 William Dampier referred to a "Lagune or Lake of Salt water" on the coast of Mexico. Captain James Cook described an island "of Oval form with a Lagoon in the middle" in 1769.[15]		Atoll lagoons form as coral reefs grow upwards while the islands that the reefs surround subside, until eventually only the reefs remain above sea level. Unlike the lagoons that form shoreward of fringing reefs, atoll lagoons often contain some deep (>20m) portions.		Coastal lagoons form along gently sloping coasts where barrier islands or reefs can develop off-shore, and the sea-level is rising relative to the land along the shore (either because of an intrinsic rise in sea-level, or subsidence of the land along the coast). Coastal lagoons do not form along steep or rocky coasts, or if the range of tides is more than 4 metres (13 ft). Due to the gentle slope of the coast, coastal lagoons are shallow. They are sensitive to changes in sea level due to global warming. A relative drop in sea level may leave a lagoon largely dry, while a rise in sea level may let the sea breach or destroy barrier islands, and leave reefs too deep under water to protect the lagoon. Coastal lagoons are young and dynamic, and may be short-lived in geological terms. Coastal lagoons are common, occurring along nearly 15 percent of the world's shorelines. In the United States, lagoons are found along more than 75 percent of the eastern and Gulf coasts.[3][4]		Coastal lagoons are usually connected to the open ocean by inlets between barrier islands. The number and size of the inlets, precipitation, evaporation, and inflow of fresh water all affect the nature of the lagoon. Lagoons with little or no interchange with the open ocean, little or no inflow of fresh water, and high evaporation rates, such as Lake St. Lucia, in South Africa, may become highly saline. Lagoons with no connection to the open ocean and significant inflow of fresh water, such as the Lake Worth Lagoon in Florida in the middle of the 19th century, may be entirely fresh. On the other hand, lagoons with many wide inlets, such as the Wadden Sea, have strong tidal currents and mixing. Coastal lagoons tend to accumulate sediments from inflowing rivers, from runoff from the shores of the lagoon, and from sediment carried into the lagoon through inlets by the tide. Large quantities of sediment may be occasionally be deposited in a lagoon when storm waves overwash barrier islands. Mangroves and marsh plants can facilitate the accumulation of sediment in a lagoon. Benthic organisms may stabilize or destabilize sediments.[3][4]		River-mouth lagoons on mixed sand and gravel (MSG) beaches form at the river-coast interface where a typically braided, although sometimes meandering, river interacts with a coastal environment that is significantly affected by longshore drift.[17] The lagoons which form on the MSG coastlines are common on the east coast of the South Island of New Zealand and have long been referred to as hapua by the Māori. This classification differentiates hapua from similar lagoons located on the New Zealand coast termed waituna. Hapua are often located on paraglacial coastal areas[18] where there is a low level of coastal development and minimal population density. Hapua form as the river carves out an elongated coast-parallel area, blocked from the sea by a MSG barrier which constantly alters its shape and volume due to longshore drift.[17][19] Longshore drift continually extends the barrier behind which the hapua forms by transporting sediment along the coast. Hapua are defined as a narrow shore-parallel extensions of the coastal riverbed.[19] They discharge the majority of stored water to the ocean via an ephemeral and highly mobile drainage channel or outlet.[20] The remainder percolates through the MSG barrier due to its high levels of permeability. Hapua systems are driven by a wide range of dynamic processes that are generally classified as fluvial or marine; changes in the balance between these processes as well as the antecedent barrier conditions can cause shifts in the morphology of the hapua, in particular the barrier. New Zealand examples include the Rakaia, Ashburton and Hurunui river-mouths.		Hapua have been identified as establishing in the Canterbury Bight coastal region on the east coast of the South Island. They are often found in areas of coarse-grained sediment where contributing rivers have moderately steep bed gradients.[17] MSG beaches in the Canterbury Bight region contain a wide range of sediment sizes from sand to boulders[21] and are exposed to the high energy waves that make up an east coast swell environment.[22] MSG beaches are reflective rather than dissipative energy zones due to their morphological characteristics. They have a steep foreshore which is known as the ‘engine room’ of the beach profile. In this zone, swash and backwash are dominating processes alongside longshore transport.[23] MSG beaches do not have a surf zone; instead a single line of breakers is visible in all sea conditions.[17] Hapua are associated with MSG beaches as the variation in sediment size allows for the barrier to be permeable.		The east coast of the South Island has been identified as being in a period of chronic erosion of approximately 0.5 metres per year.[24] This erosion trend is a result of a number of factors. According to the classification scheme of Zenkovich,[18] the rivers on the east coast can be described as ‘small’; this classification is not related to their flow rate but to the insufficient amount of sediment that they transport to the coast to nourish it. The sediment provided is not adequate to nourish the coast against its typical high energy waves and strong longshore drift. These two processes constantly remove sediment depositing it either offshore or further up drift.[25] As the coastline becomes eroded the hapua have been 'rolling back' by eroding the backshore to move landwards.[19]		Hapua or river-mouth lagoons form in micro-tidal environments. A micro-tidal environment is where the tidal range (distance between low tide and high tide) is less than two metres.[17] Tidal currents in a micro-tidal zone are less than those found on meso-tidal (two – four metres) and macro-tidal (greater than four metres) coastlines.[26] Hapua form in this type of tidal environment as the tidal currents are unable to compete with the powerful freshwater flows of the rivers therefore there is no negligible tidal penetration to the lagoon.[17] A fourth element of the environment in which hapua form is the strong longshore drift component.[17] Longshore or littoral drift is the transportation of sediments along the coast at an angle to the shoreline. In the Canterbury Bight coastal area; the dominant swell direction is northwards from the Southern Ocean.[17] Therefore, the principal movement of sediment via longshore drift is north towards Banks Peninsula. Hapua are located in areas dominated by longshore drift; because it aids the formation of the barrier behind which the hapua is sited.		A hapua also requires sediment to form the lagoon barrier. Sediment which nourishes the east coast of New Zealand can be sourced from three different areas. Material from the highly erodible Southern Alps is removed via weathering; then carried across the Canterbury Plains by various braided rivers to the east coast beaches.[19][25] The second source of sediment is the high cliffs which are located in the hinterland of lagoons.[25] These can be eroded during the occurrence of high river flow or sea storm events. Beaches further south provide nourishment to the northern coast via longshore transport.		Hapua have a number of characteristics which includes shifts between a variety of morphodynamic states due to changes in the balance between marine and fluvial processes as well as the antecedent barrier conditions.[19] The MSG barrier constantly changes size and shape as a result of the longshore drift. Water stored in the hapua drains to the coast predominately though an outlet; although it can also seep through the barrier depending on the permeability of the material.[19][27]		Changes in the level of the lagoon water do not occur as a result of saltwater or tidal intrusion. Water in a hapua is predominately freshwater originating from the associated river. Hapua are non-estuarine, there is no tidal inflow however the tide does have an effect on the level of water in the lagoon. As the tide reaches its peak, the lagoon water has a much smaller amount of barrier to permeate through so the lagoon level rises.[28] This is related to a physics theory known as hydraulic head. The lagoon level has a similar sinusoidal wave shape as the tide but reaches its peak slightly later.[27] In general, any saltwater intrusion into the hapua will only occur during a storm via wave overtopping or sea spray.[19][25]		Hapua can act as both a source and sink of sediment.[24][25] The majority of sediment in the hapua is fluvial sourced.[17] During medium to low river flows, coarser sediment generally collects in the hapua; while some of the finer sediment can be transported through the outlet to the coast.[25] During flood events the hapua is 'flushed out' with larger amounts of sediment transferred through the outlet. This sediment can be deposited offshore or downdrift of the hapua replenishing the undernourished beach.[25] If a large amount of material is released to the coast at one time it can be identified as a 'slug'. These can often be visible from aerial photographs.		Antecedent barrier conditions combined with changes in the balance between marine and fluvial processes results in shifts between a variety of morphological states in a hapua or river-mouth lagoon on a MSG beach. Marine processes includes the direction of wave approach, wave height and the coincidence of storm waves with high tides.[29] Marine processes tend to dominate the majority of morphodynamic conditions until there is a large enough flood event in the associated river to breach the barrier.[17] The level and frequency of base or flood flows are attributed to fluvial processes. Antecedent barrier conditions are the permeability, volume and height of the barrier as well as the width and presence of previous outlet channels.[29] During low to medium river flows, the outlet from the lagoon to the sea becomes offset in the direction of longshore drift.[25] Outlet efficiency tends to decrease the further away from the main river-mouth the outlet is.[19] A decrease in efficiency can cause the outlet to become choked with sediment and the hapua to close temporarily. The potential for closure varies between different hapua depending on whether marine or fluvial processes are the bigger driver in the event. A high flow event; such as a fresh or flood can breach the barrier directly opposite the main river channel.[19][25] This causes an immediate decrease in the water level of the hapua; as well as transporting previously deposited sediments into the ocean. Flood events are important for eroding lagoon back shores; this is a behaviour which allows hapua to retreat landward and thus remain coastal landforms even with coastal transgression and sea level rise.[19] During high flow events there is also the possibility for secondary breaches of the barrier or lagoon truncation to occur.		Storm events also have the ability to close hapua outlets as waves overtop the barrier depositing sediment and choking the scoured channel.[24] The resultant swift increase in lagoon water level causes a new outlet to be breached rapidly due to the large hydraulic head that forms between the lagoon and sea water levels. Storm breaching is believed to be an important but unpredictable control on the duration of closures at low to moderate river flow levels in smaller hapua.[24]		Hapua are extremely important for a number of reasons. They provide a link between the river and sea for migrating fish as well as a corridor for migratory birds.[17][30] To lose this link via closure of the hapua outlet could result in losing entire generations of specific species as they may need to migrate to the ocean or the river as a vital part of their lifecycle. River-mouth lagoons such as hapua were also used a source for mahinga kai (food gathering) by the Māori people.[17][30] However, this is no longer the case due to catchment degradation which has resulted in lagoon deterioration. River-mouth lagoons on MSG beaches are not well explained in international literature.		The hapua located at the mouth of the Rakaia River stretches approximately three kilometres north from where the river-mouth reaches the coast. The average width of the hapua between 1952 and 2004 was approximately 50 metres; whilst the surface area has stabilised at approximately 600,000 square metres since 1966.[31] The coastal hinterland is composed of erodible cliffs and a low-lying area commonly known as the Rakaia Huts. This area has changed notably since European Settlement; with the drainage of ecologically significant wetlands and development of the small bach community.		The Rakaia River begins in the Southern Alps, providing approximately 4.2 Mt per year of sediment to the east coast. It is a braided river with a catchment area of 3105 kilometres squared and a mean flow of 221 cubic metres per second.[32] The mouth of the Rakaia River reaches the coast south of Banks Peninsula. As the river reaches the coast it diverges into two channels; with the main channel flowing to the south of the island.[24] As the hapua is located in the Canterbury Bight it is in a state of constant morphological change due to the prevailing southerly sea swells and resultant northwards longshore drift.		
in the African Union  (light blue)		[Note 1]		South Africa, officially the Republic of South Africa (RSA), is the southernmost country in Africa. It is bounded on the south by 2,798 kilometres (1,739 mi) of coastline of Southern Africa stretching along the South Atlantic and Indian Oceans;[9][10][11] on the north by the neighbouring countries of Namibia, Botswana, and Zimbabwe; and on the east and northeast by Mozambique and Swaziland; and surrounds the kingdom of Lesotho.[12] South Africa is the 25th-largest country in the world by land area, and with close to 56,000,000 people, is the world's 24th-most populous nation. It is the southernmost country on the mainland of the Old World or the Eastern Hemisphere. About 80% of South Africans are of Sub-Saharan African ancestry,[5] divided among a variety of ethnic groups speaking different Bantu languages, nine of which have official status.[11] The remaining population consists of Africa's largest communities of European (white), Asian (Indian), and multiracial (coloured) ancestry.		South Africa is a multiethnic society encompassing a wide variety of cultures, languages, and religions. Its pluralistic makeup is reflected in the constitution's recognition of eleven official languages, which is among the highest number of any country in the world.[11] Two of these languages are of European origin: Afrikaans developed from Dutch and serves as the first language of most white and coloured South Africans; English reflects the legacy of British colonialism, and is commonly used in public and commercial life, though it is fourth-ranked as a spoken first language.[11] The country is one of the few in Africa never to have had a coup d'état, and regular elections have been held for almost a century. However, the vast majority of Black South Africans were not enfranchised until 1994. During the twentieth century, the Black majority sought to recover its rights from the dominant White minority, with this struggle playing a large role in the country's recent history and politics. The National Party imposed the apartheid system in 1948, institutionalising previous racial segregation. After a long and sometimes violent struggle by the African National Congress and other anti-apartheid activists both inside and outside the country, discriminatory laws began to be repealed or abolished from 1990 onwards.		Since 1994, all ethnic and linguistic groups have held political representation in the country's democracy, which comprises a parliamentary republic and nine provinces. South Africa is often referred to as the "Rainbow Nation" to describe the country's multicultural diversity, especially in the wake of apartheid.[13] The World Bank classifies South Africa as an upper-middle-income economy, and a newly industrialised country.[14][15] Its economy is the second-largest in Africa, and the 34th-largest in the world.[6] In terms of purchasing power parity, South Africa has the seventh-highest per capita income in Africa. However, poverty and inequality remain widespread, with about a quarter of the population unemployed and living on less than US$1.25 a day.[16][17] Nevertheless, South Africa has been identified as a middle power in international affairs, and maintains significant regional influence.[18][19]						The name "South Africa" is derived from the country's geographic location at the southern tip of Africa. Upon formation the country was named the Union of South Africa in English, reflecting its origin from the unification of four formerly separate British colonies. Since 1961 the long form name in English has been the "Republic of South Africa". In Dutch the country was named Republiek van Zuid-Afrika, replaced in 1983 by the Afrikaans Republiek van Suid-Afrika. Since 1994 the Republic has had an official name in each of its 11 official languages.		Mzansi, derived from the Xhosa noun umzantsi meaning "south", is a colloquial name for South Africa,[20][21] while some Pan-Africanist political parties prefer the term "Azania".[22]		South Africa contains some of the oldest archaeological and human fossil sites in the world.[23][24][25] Extensive fossil remains have been recovered from a series of caves in Gauteng Province. The area is a UNESCO World Heritage site and has been termed the Cradle of Humankind. The sites include Sterkfontein, which is one of the richest hominin fossil sites in the world. Other sites include Swartkrans, Gondolin Cave Kromdraai, Coopers Cave and Malapa. The first hominin fossil discovered in Africa, the Taung Child was found near Taung in 1924. Further hominin remains have been recovered from the sites of Makapansgat in Limpopo, Cornelia and Florisbad in the Free State, Border Cave in KwaZulu-Natal, Klasies River Mouth in eastern Cape and Pinnacle Point, Elandsfontein and Die Kelders Cave in Western Cape. These sites suggest that various hominid species existed in South Africa from about three million years ago starting with Australopithecus africanus.[26] These were succeeded by various species, including Australopithecus sediba, Homo ergaster, Homo erectus, Homo rhodesiensis, Homo helmei, Homo naledi and modern humans, Homo sapiens. Modern humans have inhabited Southern Africa for at least 170,000 years.		Within the Vaal River valley, pebble tools have been located.[27]		Settlements of Bantu-speaking peoples, who were iron-using agriculturists and herdsmen, were already present south of the Limpopo River (now the northern border with Botswana and Zimbabwe) by the 4th or 5th century CE. (See Bantu expansion.) They displaced, conquered and absorbed the original Khoisan speakers, the Khoikhoi and San peoples. The Bantu slowly moved south. The earliest ironworks in modern-day KwaZulu-Natal Province are believed to date from around 1050. The southernmost group was the Xhosa people, whose language incorporates certain linguistic traits from the earlier Khoisan people. The Xhosa reached the Great Fish River, in today's Eastern Cape Province. As they migrated, these larger Iron Age populations displaced or assimilated earlier peoples. In Mpumalanga, several stone circles have been found along with the stone arrangement that has been named Adam's Calendar.		At the time of European contact, the dominant ethnic group were Bantu-speaking peoples who had migrated from other parts of Africa about one thousand years before. The two major historic groups were the Xhosa and Zulu peoples.		In 1487, the Portuguese explorer Bartolomeu Dias led the first European voyage to land in southern Africa.[28] On 4 December, he landed at Walfisch Bay (now known as Walvis Bay in present-day Namibia). This was south of the furthest point reached in 1485 by his predecessor, the Portuguese navigator Diogo Cão (Cape Cross, north of the bay). Dias continued down the western coast of southern Africa. After 8 January 1488, prevented by storms from proceeding along the coast, he sailed out of sight of land and passed the southernmost point of Africa without seeing it. He reached as far up the eastern coast of Africa as, what he called, Rio do Infante, probably the present-day Groot River, in May 1488, but on his return he saw the Cape, which he first named Cabo das Tormentas (Cape of Storms). His King, John II, renamed the point Cabo da Boa Esperança, or Cape of Good Hope, as it led to the riches of the East Indies.[29] Dias' feat of navigation was later immortalised in Luís de Camões' Portuguese epic poem, The Lusiads (1572).		By the early 17th century, Portugal's maritime power was starting to decline, and English and Dutch merchants competed to oust Lisbon from its lucrative monopoly on the spice trade.[30] Representatives of the British East India Company did call sporadically at the Cape in search of provisions as early as 1601, but later came to favour Ascension Island and St. Helena as alternative ports of refuge.[31] Dutch interest was aroused after 1647, when two employees of the Dutch East India Company (VOC) were shipwrecked there for several months. The sailors were able to survive by obtaining fresh water and meat from the natives.[31] They also sowed vegetables in the fertile soil.[32] Upon their return to Holland they reported favourably on the Cape's potential as a "warehouse and garden" for provisions to stock passing ships for long voyages.[31]		In 1652, a century and a half after the discovery of the Cape sea route, Jan van Riebeeck established a victualing station at the Cape of Good Hope, at what would become Cape Town, on behalf of the Dutch East India Company.[33][34] In time, the Cape become home to a large population of "vrijlieden", also known as "vrijburgers" (free citizens), former Company employees who stayed in Dutch territories overseas after serving their contracts.[34] Dutch traders also imported thousands of slaves to the fledgling colony from Indonesia, Madagascar, and parts of eastern Africa.[35] Some of the earliest mixed race communities in the country were later formed through unions between vrijburgers, their slaves, and various indigenous peoples.[36] This led to the development of a new ethnic group, the Cape Coloureds, most of whom adopted the Dutch language and Christian faith.[36]		The eastward expansion of Dutch colonists ushered in a series of wars with the southwesterly migrating Xhosa tribe, as both sides competed for the pastureland necessary to graze their cattle near the Great Fish River.[37] Vrijburgers who became independent farmers on the frontier were known as Boers, with some adopting semi-nomadic lifestyles being denoted as trekboers.[37] The Boers formed loose militias, which they termed commandos, and forged alliances with Khoisan groups to repel Xhosa raids.[37] Both sides launched bloody but inconclusive offensives, and sporadic violence, often accompanied by livestock theft, remained common for several decades.[37]		Great Britain occupied Cape Town between 1795 and 1803 to prevent it from falling under the control of the French First Republic, which had invaded the Low Countries.[37] Despite briefly returning to Dutch rule under the Batavian Republic in 1803, the Cape was occupied again by the British in 1806.[38] Following the end of the Napoleonic Wars, it was formally ceded to Great Britain and became an integral part of the British Empire.[39] British immigration to South Africa began around 1818, subsequently culminating in the arrival of the 1820 Settlers.[39] The new colonists were induced to settle for a variety of reasons, namely to increase the size of the European workforce and to bolster frontier regions against Xhosa incursions.[39]		In the first two decades of the 19th century, the Zulu people grew in power and expanded their territory under their leader, Shaka.[40] Shaka's warfare led indirectly to the Mfecane ("crushing") that devastated and depopulated the inland plateau in the early 1820s.[41][42] An offshoot of the Zulu, the Matabele people created a larger empire that included large parts of the highveld under their king Mzilikazi.		During the early 1800s, many Dutch settlers departed from the Cape Colony, where they had been subjected to British control. They migrated to the future Natal, Orange Free State, and Transvaal regions. The Boers founded the Boer Republics: the South African Republic (now Gauteng, Limpopo, Mpumalanga and North West provinces) and the Orange Free State (Free State).		The discovery of diamonds in 1867 and gold in 1884 in the interior started the Mineral Revolution and increased economic growth and immigration. This intensified British efforts to gain control over the indigenous peoples. The struggle to control these important economic resources was a factor in relations between Europeans and the indigenous population and also between the Boers and the British.[43]		The Anglo-Zulu War was fought in 1879 between the British Empire and the Zulu Kingdom. Following Lord Carnarvon's successful introduction of federation in Canada, it was thought that similar political effort, coupled with military campaigns, might succeed with the African kingdoms, tribal areas and Boer republics in South Africa. In 1874, Sir Henry Bartle Frere was sent to South Africa as High Commissioner for the British Empire to bring such plans into being. Among the obstacles were the presence of the independent states of the South African Republic and the Kingdom of Zululand and its army. The Zulu nation spectacularly defeated the British at the Battle of Isandlwana. Eventually though the war was lost resulting in the end of the Zulu nation's independence.		The Boer Republics successfully resisted British encroachments during the First Boer War (1880–1881) using guerrilla warfare tactics, which were well suited to local conditions. The British returned with greater numbers, more experience, and new strategy in the Second Boer War (1899–1902) but suffered heavy casualties through attrition; nonetheless, they were ultimately successful.		Within the country, anti-British policies among white South Africans focused on independence. During the Dutch and British colonial years, racial segregation was mostly informal, though some legislation was enacted to control the settlement and movement of native people, including the Native Location Act of 1879 and the system of pass laws.[44][45][46][47][48]		Eight years after the end of the Second Boer War and after four years of negotiation, an act of the British Parliament (South Africa Act 1909) granted nominal independence, while creating the Union of South Africa on 31 May 1910. The Union was a dominion that included the former territories of the Cape and Natal colonies, as well as the republics of Orange Free State and Transvaal.[49]		The Natives' Land Act of 1913 severely restricted the ownership of land by blacks; at that stage natives controlled only 7% of the country. The amount of land reserved for indigenous peoples was later marginally increased.[50]		In 1931 the union was fully sovereign from the United Kingdom with the passage of the Statute of Westminster, which abolished the last powers of the British Government on the country. In 1934, the South African Party and National Party merged to form the United Party, seeking reconciliation between Afrikaners and English-speaking "Whites". In 1939 the party split over the entry of the Union into World War II as an ally of the United Kingdom, a move which the National Party followers strongly opposed.		In 1948, the National Party was elected to power. It strengthened the racial segregation begun under Dutch and British colonial rule. The Nationalist Government classified all peoples into three races and developed rights and limitations for each. The white minority (less than 20%[51]) controlled the vastly larger black majority. The legally institutionalised segregation became known as apartheid. While whites enjoyed the highest standard of living in all of Africa, comparable to First World Western nations, the black majority remained disadvantaged by almost every standard, including income, education, housing, and life expectancy. The Freedom Charter, adopted in 1955 by the Congress Alliance, demanded a non-racial society and an end to discrimination.		On 31 May 1961, the country became a republic following a referendum in which white voters narrowly voted in favour thereof (the British-dominated Natal province rallied against the issue).[52] Queen Elizabeth II was stripped of the title Queen of South Africa, and the last Governor-General, namely Charles Robberts Swart, became State President. As a concession to the Westminster system, the presidency remained parliamentary appointed and virtually powerless until P. W. Botha's Constitution Act of 1983, which (intact in these regards) eliminated the office of Prime Minister and instated a near-unique "strong presidency" responsible to parliament. Pressured by other Commonwealth of Nations countries, South Africa withdrew from the organisation in 1961, and rejoined it only in 1994.		Despite opposition both within and outside the country, the government legislated for a continuation of apartheid. The security forces cracked down on internal dissent, and violence became widespread, with anti-apartheid organisations such as the African National Congress, the Azanian People's Organisation, and the Pan-Africanist Congress carrying out guerrilla warfare[53] and urban sabotage.[54] The three rival resistance movements also engaged in occasional inter-factional clashes as they jockeyed for domestic influence.[55] Apartheid became increasingly controversial, and several countries began to boycott business with the South African government because of its racial policies. These measures were later extended to international sanctions and the divestment of holdings by foreign investors.[56][57]		In the late 1970s, South Africa initiated a programme of nuclear weapons development. In the following decade, it produced six deliverable nuclear weapons.[58][59]		The Mahlabatini Declaration of Faith, signed by Mangosuthu Buthelezi and Harry Schwarz in 1974, enshrined the principles of peaceful transition of power and equality for all, the first of such agreements by black and white political leaders in South Africa. Ultimately, F. W. de Klerk opened bilateral discussions with Nelson Mandela in 1993 for a transition of policies and government.		In 1990 the National Party government took the first step towards dismantling discrimination when it lifted the ban on the African National Congress and other political organisations. It released Nelson Mandela from prison after twenty-seven years' serving a sentence for sabotage. A negotiation process followed. With approval from a predominantly white referendum, the government repealed apartheid legislation. South Africa also destroyed its nuclear arsenal and acceded to the Nuclear Non-Proliferation Treaty. South Africa held its first universal elections in 1994, which the ANC won by an overwhelming majority. It has been in power ever since. The country rejoined the Commonwealth of Nations and became a member of the Southern African Development Community (SADC).		In post-apartheid South Africa, unemployment has been extremely high as the country has struggled with many changes. While many blacks have risen to middle or upper classes, the overall unemployment rate of blacks worsened between 1994 and 2003.[60] Poverty among whites, previously rare, increased.[61] In addition, the current government has struggled to achieve the monetary and fiscal discipline to ensure both redistribution of wealth and economic growth. Since the ANC-led government took power, the United Nations Human Development Index of South Africa has fallen, while it was steadily rising until the mid-1990s.[62] Some may be attributed to the HIV/AIDS pandemic, and the failure of the government to take steps to address it in the early years.[63]		In May 2008, riots left over sixty people dead.[64] The Centre on Housing Rights and Evictions estimates over 100,000 people were driven from their homes.[65] The targets were mainly migrants and refugees seeking asylum, but a third of the victims were South African citizens.[64] In a 2006 survey, the South African Migration Project concluded that South Africans are more opposed to immigration than anywhere else in the world.[66] The United Nations High Commissioner for Refugees in 2008 reported over 200,000 refugees applied for asylum in South Africa, almost four times as many as the year before.[67] These people were mainly from Zimbabwe, though many also come from Burundi, Democratic Republic of the Congo, Rwanda, Eritrea, Ethiopia and Somalia.[67] Competition over jobs, business opportunities, public services and housing has led to tension between refugees and host communities.[67] While xenophobia is still a problem, recent violence has not been as widespread as initially feared.[67]		South Africa is located at the southernmost region of Africa, with a long coastline that stretches more than 2,500 km (1,553 mi) and along two oceans (the South Atlantic and the Indian). At 1,219,912 km2 (471,011 sq mi),[68] South Africa is the 25th-largest country in the world and is comparable in size to Colombia. Mafadi in the Drakensberg at 3,450 m (11,320 ft) is the highest peak in South Africa. Excluding the Prince Edward Islands, the country lies between latitudes 22° and 35°S, and longitudes 16° and 33°E.		The interior of South Africa consists of a vast, in most places almost flat, plateau with an altitude of between 1,000 m (3,300 ft) and 2,100 m (6,900 ft), highest in the east and sloping gently downwards towards the west and north, and slightly less noticeably so to the south and south-west.[69] This plateau is surrounded by the Great Escarpment[70] whose eastern, and highest, stretch is known as the Drakensberg.[71]		The south and south-western parts of the plateau (at approximately 1100–1800 m above sea level), and the adjoining plain below (at approximately 700–800 m above sea level – see map on the right) is known as the Great Karoo, which consists of sparsely populated scrubland. To the north the Great Karoo fades into the even drier and more arid Bushmanland, which eventually becomes the Kalahari desert in the very north-west of the country. The mid-eastern, and highest part of the plateau is known as the Highveld. This relatively well-watered area is home to a great proportion of the country’s commercial farmlands, and contains its largest conurbation (Gauteng Province). To the north of Highveld, from about the 25° 30' S line of latitude, the plateau slopes downwards into the Bushveld, which ultimately gives way to the Limpopo lowlands or Lowveld.[70]		The coastal belt, below the Great Escarpment, moving clockwise from the northeast, consists of the Limpopo Lowveld, which merges into the Mpumalanga Lowveld, below the Mpumalanga Drakensberg (the eastern portion of the Great Escarpment).[72] This is hotter, drier and less intensely cultivated than the Highveld above the escarpment.[70] The Kruger National Park, located in the provinces of Limpopo and Mpumalanga in northeastern South Africa, occupies a large portion of the Lowveld covering 19,633 square kilometres (7,580 sq mi.) [73] South of the Lowveld the annual rainfall increases as one enters KwaZulu-Natal Province, which, especially near the coast, is subtropically hot and humid. The KwaZulu-Natal – Lesotho international border is formed by the highest portion of the Great Escarpment, or Drakensberg, which reaches an altitude of over 3,000 m (9,800 ft).[74] The climate at the foot of this part of the Drakensberg is temperate.		The coastal belt below the south and south-western stretches of the Great Escarpment contains several ranges of Cape Fold Mountains which run parallel to the coast, separating the Great Escarpment from the ocean.[75][76] (These parallel ranges of fold mountains are shown on the map, above left. Note the course of the Great Escarpment to the north of these mountain ranges.) The land (at approximately 400–500 m above sea level) between two of these ranges of fold mountains in the south (i.e. between the Outeniqua and Langeberg ranges to the south and the Swartberg range to the north) is known as the Little Karoo,[70] which consists of semi-desert scrubland similar to that of the Great Karoo, except that its northern strip along the foothills of the Swartberg Mountains, has a somewhat higher rainfall and is therefore more cultivated than the Great Karoo. The Little Karoo is historically, and still, famous for its ostrich farming around the town of Oudtshoorn. The lowland area (700–800 m above sea level) to the north of the Swartberg mountain range up to the Great Escarpment is the lowland part of the Great Karoo (see map at top right), which is climatically and botanically almost indistinguishable from the Karoo above the Great Escarpment. The narrow coastal strip between the most seaward Cape Fold Mountain range (i.e., the Langeberg–Outeniqua mountains) and the ocean has a moderately high year-round rainfall, especially in the George-Knysna-Plettenberg Bay region, which is known as the Garden Route. It is famous for the most extensive areas of indigenous forests in South Africa (a generally forest-poor country).		In the south-west corner of the country the Cape Peninsula forms the southernmost tip of the coastal strip which borders the Atlantic Ocean, and ultimately terminates at the country’s border with Namibia at the Orange River. The Cape Peninsula has a Mediterranean climate, making it and its immediate surrounds the only portion of Africa south of the Sahara which receives most of its rainfall in winter.[77][78] The greater Cape Town metropolitan area is situated on the Cape Peninsula and is home to 3.7 million people according to the 2011 population census. It is the country's legislative capital.		The coastal belt to the north of the Cape Peninsula is bounded on the west by the Atlantic Ocean and the first row of north-south running Cape Fold Mountains to the east. The Cape Fold Mountains peter out at about the 32° S line of latitude,[76] after which the coastal plain is bounded by the Great Escarpment itself. The most southerly portion of this coastal belt is known as the Swartland and Malmesbury Plain, which is an important wheat growing region, relying on winter rains. The region further north is known as Namaqualand,[79] which becomes more and more arid as one approaches the Orange River. The little rain that falls, tends to fall in winter,[78] which results in one of the world’s most spectacular displays of flowers carpeting huge stretches of veld in spring (August–September).		South Africa also has one possession, the small sub-Antarctic archipelago of the Prince Edward Islands, consisting of Marion Island (290 km2 or 110 sq mi) and Prince Edward Island (45 km2 or 17 sq mi) (not to be confused with the Canadian province of the same name).		South Africa has a generally temperate climate, due in part to being surrounded by the Atlantic and Indian Oceans on three sides, by its location in the climatically milder Southern Hemisphere and due to the average elevation rising steadily towards the north (towards the equator) and further inland. Due to this varied topography and oceanic influence, a great variety of climatic zones exist. The climatic zones range from the extreme desert of the southern Namib in the farthest northwest to the lush subtropical climate in the east along the Mozambique border and the Indian Ocean. Winters in South Africa occur between June and August.		The extreme southwest has a climate remarkably similar to that of the Mediterranean with wet winters and hot, dry summers, hosting the famous fynbos biome of shrubland and thicket. This area also produces much of the wine in South Africa. This region is also particularly known for its wind, which blows intermittently almost all year. The severity of this wind made passing around the Cape of Good Hope particularly treacherous for sailors, causing many shipwrecks. Further east on the south coast, rainfall is distributed more evenly throughout the year, producing a green landscape. This area is popularly known as the Garden Route.		The Free State is particularly flat because it lies centrally on the high plateau. North of the Vaal River, the Highveld becomes better watered and does not experience subtropical extremes of heat. Johannesburg, in the centre of the Highveld, is at 1,740 m (5,709 ft) and receives an annual rainfall of 760 mm (29.9 in). Winters in this region are cold, although snow is rare.		The high Drakensberg mountains, which form the south-eastern escarpment of the Highveld, offer limited skiing opportunities in winter. The coldest place on mainland South Africa is Sutherland in the western Roggeveld Mountains, where midwinter temperatures can reach as low as −15 °C (5 °F). The Prince Edward Islands have colder average annual temperatures, but Sutherland has colder extremes. The deep interior of mainland South Africa has the hottest temperatures: a temperature of 51.7 °C (125.06 °F) was recorded in 1948 in the Northern Cape Kalahari near Upington,[80] but this temperature is unofficial and was not recorded with standard equipment, the official highest temperature is 48.8 °C (119.84 °F) at Vioolsdrif in January 1993.[81]		South Africa signed the Rio Convention on Biological Diversity on 4 June 1994, and became a party to the convention on 2 November 1995.[82] It has subsequently produced a National Biodiversity Strategy and Action Plan, which was received by the convention on 7 June 2006.[83] The country is ranked sixth out of the world's seventeen megadiverse countries.[84]		Numerous mammals are found in the bushveld including Transvaal lions, African leopards, South African cheetahs, southern white rhinos, blue wildebeest, kudus, impalas, hyenas, hippopotamuses and South African giraffes. A significant extent of the bushveld exists in the north-east including Kruger National Park and the Sabi Sand Game Reserve, as well as in the far north in the Waterberg Biosphere. South Africa houses many endemic species, among them the critically endangered riverine rabbit (Bunolagus monticullaris) in the Karoo.		Up to 1945, more than 4900 species of fungi (including lichen-forming species) had been recorded.[85] In 2006, the total number of fungi which occur in South Africa was conservatively estimated at about 200,000 species, but that did not take into account fungi associated with insects.[86] If correct, then the number of South African fungi dwarfs that of its plants. In at least some major South African ecosystems, an exceptionally high percentage of fungi are highly specific in terms of the plants with which they occur.[87] The country's biodiversity strategy and action plan does not mention fungi (including lichen-forming fungi).[83]		With more than 22,000 different higher plants, or about 9% of all the known species of plants on Earth,[88] South Africa is particularly rich in plant diversity. The most prevalent biome in South Africa is the grassland, particularly on the Highveld, where the plant cover is dominated by different grasses, low shrubs, and acacia trees, mainly camel-thorn and whitethorn. Vegetation becomes even more sparse towards the northwest due to low rainfall. There are several species of water-storing succulents like aloes and euphorbias in the very hot and dry Namaqualand area. The grass and thorn savannah turns slowly into a bush savannah towards the north-east of the country, with denser growth. There are significant numbers of baobab trees in this area, near the northern end of Kruger National Park.[89]		The fynbos biome, which makes up the majority of the area and plant life in the Cape floristic region, one of the six floral kingdoms, is located in a small region of the Western Cape and contains more than 9,000 of those species, making it among the richest regions on earth in terms of plant diversity.[citation needed] Most of the plants are evergreen hard-leaf plants with fine, needle-like leaves, such as the sclerophyllous plants. Another uniquely South African flowering plant group is the genus Protea. There are around 130 different species of Protea in South Africa.		While South Africa has a great wealth of flowering plants, only 1% of South Africa is forest, almost exclusively in the humid coastal plain of KwaZulu-Natal, where there are also areas of Southern Africa mangroves in river mouths. There are even smaller reserves of forests that are out of the reach of fire, known as montane forests. Plantations of imported tree species are predominant, particularly the non-native eucalyptus and pine.		South Africa has lost a large area of natural habitat in the last four decades, primarily due to overpopulation, sprawling development patterns and deforestation during the 19th century. South Africa is one of the worst affected countries in the world when it comes to invasion by alien species with many (e.g. black wattle, Port Jackson willow, Hakea, Lantana and Jacaranda) posing a significant threat to the native biodiversity and the already scarce water resources. The original temperate forest found by the first European settlers was exploited ruthlessly until only small patches remained. Currently, South African hardwood trees like real yellowwood (Podocarpus latifolius), stinkwood (Ocotea bullata), and South African black ironwood (Olea laurifolia) are under government protection. Statistics from the South African Environmental Affairs department show a record 1215 rhinos have been killed in 2014.[90]		Climate change is expected to bring considerable warming and drying to much of this already semi-arid region, with greater frequency and intensity of extreme weather events such as heatwaves, flooding and drought. According to computer generated climate modelling produced by the South African National Biodiversity Institute[91] parts of southern Africa will see an increase in temperature by about one degree Celsius along the coast to more than four degrees Celsius in the already hot hinterland such as the Northern Cape in late spring and summertime by 2050. The Cape Floral Kingdom, been identified as one of the global biodiversity hotspots, it will be hit very hard by climate change. Drought, increased intensity and frequency of fire and climbing temperatures are expected to push many rare species towards extinction.		South Africa is a parliamentary republic, although unlike most such republics the President is both head of state and head of government, and depends for his tenure on the confidence of Parliament. The executive, legislature and judiciary are all subject to the supremacy of the Constitution, and the superior courts have the power to strike down executive actions and acts of Parliament if they are unconstitutional.		The National Assembly, the lower house of Parliament, consists of 400 members and is elected every five years by a system of party-list proportional representation. The National Council of Provinces, the upper house, consists of ninety members, with each of the nine provincial legislatures electing ten members.		After each parliamentary election, the National Assembly elects one of its members as President; hence the President serves a term of office the same as that of the Assembly, normally five years. No President may serve more than two terms in office.[92] The President appoints a Deputy President and Ministers, who form the Cabinet which consists of Departments and Ministries. The President and the Cabinet may be removed by the National Assembly by a motion of no confidence.		In the most recent election, held on 7 May 2014, the African National Congress (ANC) won 62.2% of the vote and 249 seats, while the main opposition, the Democratic Alliance (DA) won 22.2% of the vote and 89 seats. The Economic Freedom Fighters, founded by Julius Malema, the former President of the ANC's Youth Wing who was later expelled from the ANC, won 6.4% of the vote and 25 seats. The ANC has been the governing political party in South Africa since the end of apartheid.		South Africa has no legally defined capital city. The fourth chapter of the Constitution of South Africa, states that "The seat of Parliament is Cape Town, but an Act of Parliament enacted in accordance with section 76(1) and (5) may determine that the seat of Parliament is elsewhere."[93] The country's three branches of government are split over different cities. Cape Town, as the seat of Parliament, is the legislative capital; Pretoria, as the seat of the President and Cabinet, is the administrative capital; and Bloemfontein, as the seat of the Supreme Court of Appeal, is the judicial capital, while the Constitutional Court of South Africa sits in Johannesburg. Most foreign embassies are located in Pretoria.		Since 2004, South Africa has had many thousands of popular protests, some violent, making it, according to one academic, the "most protest-rich country in the world".[94] There have been a number of incidents of political repression as well as threats of future repression in violation of this constitution leading some analysts and civil society organisations to conclude that there is or could be a new climate of political repression,[95][96] or a decline in political tolerance.[97]		In 2008, South Africa placed 5th out of 48 sub-Saharan African countries on the Ibrahim Index of African Governance. South Africa scored well in the categories of Rule of Law, Transparency & Corruption and Participation & Human Rights, but was let down by its relatively poor performance in Safety & Security.[98] In November 2006, South Africa became the first African country to legalise same-sex marriage.[99]		The Constitution of South Africa is the supreme rule of law in the country. The primary sources of South African law are Roman-Dutch mercantile law and personal law with English Common law, as imports of Dutch settlements and British colonialism.[100] The first European based law in South Africa was brought by the Dutch East India Company and is called Roman-Dutch law. It was imported before the codification of European law into the Napoleonic Code and is comparable in many ways to Scots law. This was followed in the 19th century by English law, both common and statutory. Starting in 1910 with unification, South Africa had its own parliament which passed laws specific for South Africa, building on those previously passed for the individual member colonies.		The judicial system consists of the magistrates' courts, which hear lesser criminal cases and smaller civil cases; the High Courts, which are courts of general jurisdiction for specific areas; the Supreme Court of Appeal, which is the highest court in all but constitutional matters; and the Constitutional Court, which hears only constitutional matters.		Nearly 50 murders are committed each day in South Africa.[101] In the year ended March 2014 there were 17,068 murders and the murder rate was 32.2 per 100,000 - about five times higher than the global average of 6 per 100,000.[102] Middle-class South Africans seek security in gated communities.[103] The private security industry in South Africa is the largest in the world,[104] with nearly 9,000 registered companies and 400,000 registered active private security guards, more than the South African police and army combined.[105] Many emigrants from South Africa also state that crime was a big motivator for them to leave.[106] Crime against the farming community has continued to be a major problem.[107]		It is estimated that 500,000 women are raped in South Africa every year[108] with the average woman more likely to be raped than complete secondary school.[109] A 2009 survey found one in four South African men admitted to raping someone[110] and another survey found one in three women out of 4000 surveyed women said they had been raped in the past year.[111] Rapes are also perpetrated by children (some as young as ten).[112] Child and baby rape incidences are some of the highest in the world, largely as a result of the virgin cleansing myth, and a number of high-profile cases (sometimes as young as eight months[112]) have outraged the nation.[113]		As the Union of South Africa, the country was a founding member of the United Nations. The then Prime Minister Jan Smuts wrote the preamble to the United Nations Charter.[114][115] South Africa is one of the founding members of the African Union (AU), and has the second largest economy of all the members. It is also a founding member of the AU's New Partnership for Africa's Development (NEPAD).		South Africa has played a key role as a mediator in African conflicts over the last decade, such as in Burundi, the Democratic Republic of Congo, the Comoros, and Zimbabwe. After apartheid ended, South Africa was readmitted to the Commonwealth of Nations. The country is a member of the Group of 77 and chaired the organisation in 2006. South Africa is also a member of the Southern African Development Community, South Atlantic Peace and Cooperation Zone, Southern African Customs Union, Antarctic Treaty System, World Trade Organization, International Monetary Fund, G20, G8+5, and the Port Management Association of Eastern and Southern Africa.		South African President Jacob Zuma and Chinese President Hu Jintao upgraded bilateral ties between the two countries on 24 August 2010, when they signed the Beijing Agreement, which elevated South Africa's earlier "strategic partnership" with China to the higher level of "comprehensive strategic partnership" in both economic and political affairs, including the strengthening of exchanges between their respective ruling parties and legislatures.[116][117] In April 2011, South Africa formally joined the Brazil-Russia-India-China (BRICS) grouping of countries, identified by President Zuma as the country's largest trading partners, and also the largest trading partners with Africa as a whole. Zuma asserted that BRICS member countries would also work with each other through the UN, the Group of Twenty (G20) and the India, Brazil South Africa (IBSA) forum.[118]		The South African National Defence Force (SANDF) was created in 1994,[119][120] as an all volunteer force composed of the former South African Defence Force, the forces of the African nationalist groups (Umkhonto we Sizwe and Azanian People's Liberation Army), and the former Bantustan defence forces.[119] The SANDF is subdivided into four branches, the South African Army, the South African Air Force, the South African Navy, and the South African Military Health Service.[121] In recent years, the SANDF has become a major peacekeeping force in Africa,[122] and has been involved in operations in Lesotho, the Democratic Republic of the Congo,[122] and Burundi,[122] amongst others. It has also served in multi-national UN peacekeeping forces such as the United Nations Force Intervention Brigade for example.		South Africa is the only African country to have successfully developed nuclear weapons. It became the first country (followed by Ukraine) with nuclear capability to voluntarily renounce and dismantle its programme and in the process signed the Nuclear Non-Proliferation Treaty in 1991.[123] South Africa undertook a nuclear weapons programme in the 1970s[123] According to former state president FW de Klerk, the decision to build a "nuclear deterrent" was taken "as early as 1974 against a backdrop of a Soviet expansionist threat."[124] South Africa is alleged to have conducted a nuclear test over the Atlantic in 1979,[125] although this is officially denied. Former president FW de Klerk maintained that South Africa had "never conducted a clandestine nuclear test."[124] Six nuclear devices were completed between 1980 and 1990, but all were dismantled before South Africa signed the Nuclear Non-Proliferation Treaty in 1991.[124]		Each of the nine provinces is governed by a unicameral legislature, which is elected every five years by party-list proportional representation. The legislature elects a Premier as head of government, and the Premier appoints an Executive Council as a provincial cabinet. The powers of provincial governments are limited to topics listed in the Constitution; these topics include such fields as health, education, public housing and transport.		The provinces are in turn divided into 52 districts: 8 metropolitan and 44 district municipalities. The district municipalities are further subdivided into 226 local municipalities. The metropolitan municipalities, which govern the largest urban agglomerations, perform the functions of both district and local municipalities.		South Africa has a mixed economy, the second-largest in Africa after Nigeria. It also has a relatively high GDP per capita compared to other countries in Sub-Saharan Africa ($11,750 at PPP as of 2012). Despite this, South Africa is still burdened by a relatively high rate of poverty and unemployment, and is also ranked in the Top 10 countries in the world for income inequality,[127][128][129] measured by the Gini coefficient.		Unlike most of the world's poor countries, South Africa does not have a thriving informal economy. Only 15% of South African jobs are in the informal sector, compared with around half in Brazil and India and nearly three-quarters in Indonesia. The OECD attributes this difference to South Africa's widespread welfare system.[130] World Bank research shows that South Africa has one of the widest gaps between per capita GNP versus its Human Development Index ranking, with only Botswana showing a larger gap.[131]		After 1994, government policy brought down inflation, stabilised public finances, and some foreign capital was attracted, however growth was still subpar.[132] From 2004 onwards, economic growth picked up significantly; both employment and capital formation increased.[132] During the presidency of Jacob Zuma, the government has begun to increase the role of state-owned enterprises. Some of the biggest state-owned companies are Eskom, the electric power monopoly, South African Airways (SAA), and Transnet, the railway and ports monopoly. Some of these state-owned companies have not been profitable, such as SAA, which has required bailouts totaling R30,000,000,000 ($2,300,000,000) over twenty years.[133]		South Africa is a popular tourist destination, and a substantial amount of revenue comes from tourism.[134] Illegal immigrants are involved in informal trading.[135] Many emigrants to South Africa continue to live in poor conditions, and the immigration policy has become increasingly restrictive since 1994.[136]		Principal international trading partners of South Africa—outside Africa—include: Germany, the United States, China, Japan, the United Kingdom and Spain.[137]		The South African agricultural industry contributes around 10% of formal employment, relatively low compared to other parts of Africa, as well as providing work for casual labourers and contributing around 2.6% of GDP for the nation.[138] Due to the aridity of the land, only 13.5% of the land can be used for crop production, and only 3% is considered high potential land.[139]		In August 2013, South Africa was ranked as the top African Country of the Future by FDi magazine based on the country's economic potential, labour environment, cost-effectiveness, infrastructure, business friendliness, and Foreign direct investment Strategy.[140]		The FSI ranks South Africa as the 36th safest tax haven in the world, ahead of the Philippines but behind the Bahamas.		During 1995–2003, the number of formal jobs decreased and informal jobs increased; overall unemployment worsened.[60]		The government's Black Economic Empowerment policies have drawn criticism from Neva Makgetla, lead economist for research and information at the Development Bank of Southern Africa, for focusing "almost exclusively on promoting individual ownership by black people (which) does little to address broader economic disparities, though the rich may become more diverse."[141] Official affirmative action policies have seen a rise in black economic wealth and an emerging black middle-class.[142] Other problems include state ownership and interference, which impose high barriers to entry in many areas.[143] Restrictive labour regulations have contributed to the unemployment malaise.[60]		Along with many other African countries, South Africa has been experiencing a "brain drain" within the past twenty years. This is believed to be potentially damaging for the regional economy,[144][not in citation given][clarification needed] and is almost certainly detrimental for the well-being of those reliant on the healthcare infrastructure.[145] The skills drain in South Africa tends to demonstrate racial contours given the skills distribution legacy of South Africa and has thus resulted in large white South African communities moving abroad.[146] However, the statistics which purport to show a brain drain are disputed and also do not account for repatriation and expiry of foreign work contracts. According to several surveys[147][148] there has been a reverse in brain drain following the global financial crisis of 2008-2009 and the expiry of foreign work contracts. In the first quarter of 2011, confidence levels for graduate professionals were recorded at a level of 84% in a PPS survey.[149]		Several important scientific and technological developments have originated in South Africa. The first human-to-human heart transplant was performed by cardiac surgeon Dr. Christiaan Barnard at Groote Schuur Hospital in December 1967, Max Theiler developed a vaccine against yellow fever, Allan McLeod Cormack pioneered x-ray computed tomography, and Aaron Klug developed crystallographic electron microscopy techniques. With the exception of that of Barnard, all of these advancements were recognised with Nobel Prizes. Sydney Brenner won most recently, in 2002, for his pioneering work in molecular biology.		Mark Shuttleworth founded an early Internet security company Thawte, that was subsequently bought out by world-leader VeriSign. Despite government efforts to encourage entrepreneurship in biotechnology, IT and other high technology fields, no other notable groundbreaking companies have been founded in South Africa. It is the expressed objective of the government to transition the economy to be more reliant on high technology, based on the realisation that South Africa cannot compete with Far Eastern economies in manufacturing, nor can the republic rely on its mineral wealth in perpetuity.		South Africa has cultivated a burgeoning astronomy community. It hosts the Southern African Large Telescope, the largest optical telescope in the Southern Hemisphere. South Africa is currently building the Karoo Array Telescope as a pathfinder for the €1,500,000,000 Square Kilometre Array project.[150] On 25 May 2012, it was announced that hosting of the Square Kilometer Array Telescope will be split over both the South African and the Australia/New Zealand sites.[151]		After the end of Apartheid, South Africa's newly elected ANC government struggled with the-then growing service and backlogs with respect to access to Water supply and Sanitation developed. The government thus made a strong commitment to high service standards and to high levels of investment subsidies to achieve those standards. Since then, the country has made some progress with regard to improving access to water supply: It reached universal access to an improved water source in urban areas, and in rural areas the share of those with access increased from 66% to 79% from 1990 to 2010.[152]		South Africa also has a strong water industry with a track record in innovation. However, much less progress has been achieved on sanitation: Access increased only from 71% to 79% during the same period.[152] Significant problems remain concerning the financial sustainability of service providers, leading to a lack of attention to maintenance. The uncertainty about the government's ability to sustain funding levels in the sector is also a concern. Two distinctive features of the South African water sector are the policy of free basic water and the existence of water boards, which are bulk water supply agencies that operate pipelines and sell water from reservoirs to municipalities.		In May 2014, it was announced that Durban's Water and Sanitation Department won the Stockholm Industry Water Award "for its transformative and inclusive approach", calling it "one of the most progressive utilities in the world". The city has connected 1,300,000 additional people to piped water and provided 700,000 with access to toilets in fourteen years. It also was South Africa's first municipality to put free basic water for the poor into practice. Furthermore, it has promoted Rainwater harvesting and mini hydropower.[153]		South Africa is a nation of about 55,000,000 (2016 estimate) people of diverse origins, cultures, languages, and religions. The last census was held in 2011. South Africa is home to an estimated 5,000,000 illegal immigrants, including some 3,000,000 Zimbabweans.[154][155][156] A series of anti-immigrant riots occurred in South Africa beginning on 11 May 2008.[157][158]		Statistics South Africa asks people to describe themselves in the census in terms of five racial population groups.[159] The 2011 census figures for these groups were Black African at 79.2%, White at 8.9%, Coloured at 8.9%, Asian at 2.5%, and Other/Unspecified at 0.5%.[5]:21 The first census in South Africa in 1911 showed that whites made up 22% of the population; it declined to 16% in 1980.[160]		South Africa hosts a sizeable refugee and asylum seeker population. According to the World Refugee Survey 2008, published by the US Committee for Refugees and Immigrants, this population numbered approximately 144,700 people in 2007.[161] Groups of refugees and asylum seekers numbering over 10,000 included people from Zimbabwe (48,400), The Democratic Republic of the Congo (24,800), and Somalia (12,900).[161] These populations mainly lived in Johannesburg, Pretoria, Durban, Cape Town, and Port Elizabeth.[161] Many refugees have now also started to work and live in rural areas in provinces such as Mpumalanga, KwaZulu-Natal and the Eastern Cape.		South Africa has eleven official languages:[162] Afrikaans, English, Ndebele, Northern Sotho, Sotho, Swazi, Tswana, Tsonga, Venda, Xhosa, and Zulu. In this regard it is third only to Bolivia and India in number. While all the languages are formally equal, some languages are spoken more than others. According to the 2011 census, the three most spoken first languages are Zulu (22.7%), Xhosa (16.0%), and Afrikaans (13.5%).[163] Despite the fact that English is recognised as the language of commerce and science, it ranked fourth, and was listed as the first language of only 9.6% of South Africans in 2011 but remains the de facto lingua franca of the nation.[163]		The country also recognises several unofficial languages, including Fanagalo, Khoe, Lobedu, Nama, Northern Ndebele, Phuthi, and South African Sign Language.[164] These unofficial languages may be used in certain official uses in limited areas where it has been determined that these languages are prevalent.		Many of the unofficial languages of the San and Khoikhoi people contain regional dialects stretching northwards into Namibia and Botswana, and elsewhere. These people, who are a physically distinct population from other Africans, have their own cultural identity based on their hunter-gatherer societies. They have been marginalised to a great extent, and the remainder of their languages are in danger of becoming extinct.		Many White South Africans also speak European languages, including Portuguese (also spoken by Black Angolans and Mozambicans), German, and Greek, while some Asians in South Africa speak Asian languages, such as Gujarati, Hindi, Tamil, Telugu, and Urdu. French is spoken in South Africa by immigrants from French-speaking parts of Africa.		According to the 2001 census, Christians accounted for 79.8% of the population, with a majority of them being members of various Protestant denominations (broadly defined to include syncretic African initiated churches) and a minority of Roman Catholics and other Christians. Christian category includes Zion Christian (11.1%), Pentecostal (Charismatic) (8.2%), Roman Catholic (7.1%), Methodist (6.8%), Dutch Reformed (Nederduits Gereformeerde Kerk; 6.7%), Anglican (3.8%). Members of remaining Christian churches accounted for another 36% of the population. Muslims accounted for 1.5% of the population, Hindus 1.2%, traditional African religion 0.3% and Judaism 0.2%. 15.1% had no religious affiliation, 0.6% were other and 1.4% were unspecified.[137][175][176]		African initiated churches formed the largest of the Christian groups. It was believed that many of the persons who claimed no affiliation with any organised religion adhered to traditional African religion. There are an estimated 200,000 indigenous traditional healers in South Africa, and up to 60% of South Africans consult these healers,[177] generally called sangomas or inyangas. These healers use a combination of ancestral spiritual beliefs and a belief in the spiritual and medicinal properties of local fauna and flora, commonly known as muti, to facilitate healing in clients. Many peoples have syncretic religious practices combining Christian and indigenous influences.[178]		South African Muslims comprise mainly those who are described as "Coloured" and those who are described as Indians. They have been joined by Black or White South African converts as well as others from other parts of Africa.[179] South African Muslims claim that their faith is the fastest-growing religion of conversion in the country, with the number of black Muslims growing sixfold, from 12,000 in 1991 to 74,700 in 2004.[179][180]		South Africa is also home to a substantial Jewish population, descended from European Jews who arrived as a minority among other European settlers. This population peaked in the 1970s at 120,000, though only around 67,000 remain today, the rest having emigrated. Even so, these numbers make the Jewish community in South Africa the twelfth largest in the world.[181]		Ethnic Indian Hindus form another significant portion of the population.[175]		The South African black majority still has a substantial number of rural inhabitants who lead largely impoverished lives. It is among these people that cultural traditions survive most strongly; as Blacks have become increasingly urbanised and Westernised, aspects of traditional culture have declined. Members of the middle-class, who are predominantly White but whose ranks include growing numbers of Black, Coloured and Indian people,[182] have lifestyles similar in many respects to that of people found in Western Europe, North America and Australasia.		The South African Scout Association was one of the first youth organisations to open its doors to youth and adults of all races in South Africa. This happened on 2 July 1977 at a conference known as Quo Vadis.[183]		South African art includes the oldest art objects in the world, which were discovered in a South African cave, and dated from 75,000 years ago.[184] The scattered tribes of Khoisan peoples moving into South Africa from around 10,000 BC had their own fluent art styles seen today in a multitude of cave paintings. They were superseded by Bantu/Nguni peoples with their own vocabularies of art forms. New forms of art evolved in the mines and townships: a dynamic art using everything from plastic strips to bicycle spokes. The Dutch-influenced folk art of the Afrikaner Trekboers and the urban white artists earnestly following changing European traditions from the 1850s onwards also contributed to this eclectic mix, which continues to evolve today.		South African literature emerged from a unique social and political history. One of the first well-known novels written by a Black author in an African language was Solomon Thekiso Plaatje's Mhudi, written in 1930. During the 1950s, Drum magazine became a hotbed of political satire, fiction, and essays, giving a voice to urban Black culture.		Notable White South African authors include Alan Paton, who published the acclaimed novel Cry, the Beloved Country in 1948. Nadine Gordimer became the first South African to be awarded the Nobel Prize for Literature in 1991. Her most famous novel, July's People, was released in 1981. J.M. Coetzee won the Nobel Prize for Literature, in 2003. When awarding the prize, the Swedish Academy stated that Coetzee "in innumerable guises portrays the surprising involvement of the outsider".[185]		The plays of Athol Fugard have been regularly premiered in fringe theatres in South Africa, London (The Royal Court Theatre) and New York. Olive Schreiner's The Story of an African Farm (1883) was a revelation in Victorian literature: it is heralded by many as introducing feminism into the novel form.		Breyten Breytenbach was jailed for his involvement with the guerrilla movement against apartheid. Andre Brink was the first Afrikaner writer to be banned by the government after he released the novel A Dry White Season.		The South African media sector is large, and South Africa is one of Africa's major media centres. While South Africa's many broadcasters and publications reflect the diversity of the population as a whole, the most commonly used language is English. However, all ten other official languages are represented to some extent or another.		There is great diversity in South African music. Black musicians have developed a unique style called Kwaito. Kwaito is said to have taken over radio, television, and magazines.[186] Of note is Brenda Fassie, who launched to fame with her song "Weekend Special", which was sung in English. More famous traditional musicians include Ladysmith Black Mambazo, while the Soweto String Quartet performs classic music with an African flavour. South Africa has produced world-famous jazz musicians, notably Hugh Masekela, Jonas Gwangwa, Abdullah Ibrahim, Miriam Makeba, Jonathan Butler, Chris McGregor, and Sathima Bea Benjamin. Afrikaans music covers multiple genres, such as the contemporary Steve Hofmeyr, the punk rock band Fokofpolisiekar and the singer-songwriter Jeremy Loops.		Although few South African film productions are known outside South Africa itself, many foreign films have been produced about South Africa. Arguably, the most high-profile film portraying South Africa in recent years was District 9. Other notable exceptions are the film Tsotsi, which won the Academy Award for Foreign Language Film at the 78th Academy Awards in 2006 as well as U-Carmen e-Khayelitsha, which won the Golden Bear at the 2005 Berlin International Film Festival. In 2015, Oliver Hermanus' film, The Endless River, became the first South African film selected for the Venice Film Festival.		South African culture is diverse; foods from many cultures are enjoyed by all and especially marketed to tourists who wish to sample the large variety of South African cuisine. In addition to food, music and dance feature prominently.[citation needed]		South African cuisine is heavily meat-based and has spawned the distinctively South African social gathering known as a braai, or barbecue. South Africa has also developed into a major wine producer, with some of the best vineyards lying in valleys around Stellenbosch, Franschhoek, Paarl and Barrydale.[187]		South Africa's most popular sports are soccer, rugby and cricket.[188] Other sports with significant support are swimming, athletics, golf, boxing, tennis, ringball, and netball. Although soccer commands the greatest following among the youth, other sports like basketball, surfing and skateboarding are increasingly popular.		Soccer players who have played for major foreign clubs include Steven Pienaar, Lucas Radebe and Philemon Masinga, Benni McCarthy, Aaron Mokoena, and Delron Buckley. South Africa, hosted the 2010 FIFA World Cup, and FIFA president Sepp Blatter awarded South Africa a grade 9 out of 10 for successfully hosting the event. The 2010 FIFA World Cup also marked the first time the competition had been hosted on the African continent.[189]		Famous boxing personalities include Baby Jake Jacob Matlala, Vuyani Bungu, Welcome Ncita, Dingaan Thobela, Gerrie Coetzee and Brian Mitchell. Durban Surfer Jordy Smith won the 2010 Billabong J-Bay competition making him the #1 ranked surfer in the world. South Africa produced Formula One motor racing's 1979 world champion Jody Scheckter. Famous current cricket players include AB de Villiers, Hashim Amla, Dale Steyn, Vernon Philander, Faf du Plessis etc. Most of them also participate in the Indian Premier League.		South Africa has also produced numerous world class rugby players, including Francois Pienaar, Joost van der Westhuizen, Danie Craven, Frik du Preez, Naas Botha and Bryan Habana. South Africa hosted and won the 1995 Rugby World Cup and won the 2007 Rugby World Cup in France. It followed the 1995 Rugby World Cup by hosting the 1996 African Cup of Nations, with the national team going on to win the tournament. It also hosted the 2003 Cricket World Cup, the 2007 World Twenty20 Championship. South Africa has also won the inaugural edition of the 1998 ICC KnockOut Trophy by defeating West Indies in the final.South Africa team also went onto win the inaugural edition of the Blind Cricket World Cup in 1998.		In 2004, the swimming team of Roland Schoeman, Lyndon Ferns, Darian Townsend and Ryk Neethling won the gold medal at the Olympic Games in Athens, simultaneously breaking the world record in the 4x100 freestyle relay. Penny Heyns won Olympic Gold in the 1996 Atlanta Olympic Games. In 2012, Oscar Pistorius became the first double amputee sprinter to compete at the Olympic Games in London. In golf, Gary Player is generally regarded as one of the greatest golfers of all time, having won the Career Grand Slam, one of five golfers to have done so. Other South African golfers to have won major tournaments include Bobby Locke, Ernie Els, Retief Goosen, Tim Clark, Trevor Immelman, Louis Oosthuizen and Charl Schwartzel.		The adult literacy rate in 2007 was 88.7%.[190] South Africa has a 3-tier system of education starting with primary school, followed by high school and tertiary education in the form of (academic) universities and universities of technology. Learners have twelve years of formal schooling, from Grades 1-12. Grade R is a pre-primary foundation year. [191] Primary schools span the first seven years of schooling.[192] High School education spans a further five years. The Senior Certificate examination takes place at the end of Grade 12 and is necessary for tertiary studies at a South African university.[191]		Public universities in South Africa are divided into three types: traditional universities, which offer theoretically-oriented university degrees; universities of technology ("Technikons"), which offer vocational oriented diplomas and degrees; and comprehensive universities, which offer both types of qualifications. There are 23 public universities in South Africa: 11 traditional universities, 6 universities of technology and 6 comprehensive universities.		Under apartheid, schools for Blacks were subject to discrimination through inadequate funding and a separate syllabus called Bantu Education which was only designed to give them sufficient skills to work as labourers.[193] In 2004, South Africa started reforming its higher education system, merging and incorporating smaller universities into larger institutions, and renaming all higher education institutions "university" to redress these imbalances. By 2015, 1,400,000 students in higher education have benefited from a financial aid scheme which was promulgated in 1999.[194]		Public expenditure on education was at 5.4% of the 2002–05 GDP.[195]		According to the South African Institute of Race Relations, the life expectancy in 2009 was 71 years for a White South African and 48 years for a Black South African.[196] The healthcare spending in the country is about 9% of GDP.[197]		Only 16% of the population is covered by medical schemes.[198] About 20% use private healthcare.[199] The rest pay "out of pocket" or through hospital cash plans.[199] The three dominant hospital groups, Mediclinic, Life Healthcare and Netcare, together control 75% of the market.[199] About 84% of the population depend on the public healthcare system,[197] which is beset with chronic human resource shortages and limited resources.[200]		South Africa is home to the third-largest hospital in the world, the Chris Hani Baragwanath Hospital.[201]		According to the 2015 UNAIDS Report, South Africa has an estimated 7,000,000 people living with HIV– more than any other country in the world.[202] A 2008 study revealed that HIV/AIDS infection in South Africa is distinctly divided along racial lines: 13.6% of Blacks are HIV-positive, whereas only 0.3% of Whites have the disease.[203] Most deaths are experienced by economically active individuals, resulting in many AIDS orphans who in many cases depend on the state for care and financial support.[204] It is estimated that there are 1,200,000 orphaned children in South Africa.[204]		The link between HIV, a virus spread primarily by sexual contact, and AIDS was long denied by prior president Thabo Mbeki and then health minister Manto Tshabalala-Msimang, who insisted that the many deaths in the country are due to malnutrition, and hence poverty, and not HIV.[205] In 2007, in response to international pressure, the government made efforts to fight AIDS.[206] After the 2009 general election, President Jacob Zuma appointed Dr Aaron Motsoaledi as the new minister and committed his government to increasing funding for and widening the scope of AIDS treatment.[207]		1. All twenty-eight member states of the European Union are also members of the WTO in their own right:		2. Special administrative regions of the People's Republic of China, participates as "Hong Kong, China" and "Macao China". 3. Officially the Republic of China, participates as "Separate Customs Territory of Taiwan, Penghu, Kinmen and Matsu", and "Chinese Taipei" in short.		Click on a coloured area to see an article about English in that country or region		Coordinates: 30°S 25°E﻿ / ﻿30°S 25°E﻿ / -30; 25		
The Galápagos Islands (official name: Archipiélago de Colón, other Spanish name: Islas Galápagos, Spanish pronunciation: [ˈislas ɣaˈlapaɣos]), part of the Republic of Ecuador, are an archipelago of volcanic islands distributed on either side of the Equator in the Pacific Ocean surrounding the centre of the Western Hemisphere, 906 km (563 mi) west of continental Ecuador. The islands are known for their vast number of endemic species and were studied by Charles Darwin during the second voyage of HMS Beagle, as his observations and collections contributed to the inception of Darwin's theory of evolution by natural selection.		The Galápagos Islands and their surrounding waters form the Galápagos Province of Ecuador, the Galápagos National Park, and the Galápagos Marine Reserve. The principal language on the islands is Spanish. The islands have a population of slightly over 25,000.[1]		The first recorded visit to the islands happened by chance in 1535, when Fray Tomás de Berlanga, the Bishop of Panamá, was surprised with this undiscovered land during a voyage to Peru to arbitrate in a dispute between Francisco Pizarro and Diego de Almagro. De Berlanga eventually returned to the Spanish Empire and described the conditions of the islands and the animals that inhabited them. The group of islands was shown and named in Abraham Ortelius's atlas published in 1570. The first crude map of the islands was made in 1684 by the buccaneer Ambrose Cowley, who named the individual islands after some of his fellow pirates or after British royalty and noblemen. These names were used in the authoritative navigation charts of the islands prepared during the Beagle survey under captain Robert Fitzroy, and in Darwin's popular book The Voyage of the Beagle. The new Republic of Ecuador took the islands from Spanish ownership in 1832, and subsequently gave them official Spanish names.[2] The older names remained in use in English language publications, including Herman Melville's The Encantadas of 1854.						Volcanism has been continuous on the Galapagos Islands for at least 20 Myr, and perhaps even longer. The mantle plume beneath the east-ward moving Nazca Plate (51 km/myr) has given rise to a 3 km thick platform under the island chain and seamounts. Besides the Galapagos Archipelago, other key tectonic features in the region include the Northern Galapagos Volcanic Province between the archipelago and the Galapagos Spreading Center (GSC) 200 km to the north at the boundary of the Nazca Plate and the Cocos Plate. This spreading center truncates into the East Pacific Rise on the west and is bounded by the Cocos Ridge and Carnegie Ridge in the east. Furthermore, the Galapagos Hotspot is at the northern boundary of the Pacific Large Low Shear Velocity Province while the Easter Hotspot is on the southern boundary.[3][4][5]		The Galapagos Archipelago is characterized by numerous contemporaneous volcanoes, some with plume magma sources, others from the asthenosphere, possibly due to the young and thin oceanic crust. The GSC caused structural weaknesses in this thin lithosphere leading to eruptions forming the Galapagos Platform. Fernandina and Isabela in particular are aligned along these weaknesses. Lacking a well-defined rift zone, the islands have a high rate of inflation prior to eruption. Sierra Negra on Isabela Island experienced a 240 cm uplift between 1992 and 1998, most recent eruption in 2005, while Fernandina on Fernandina Island indicated an uplift of 90 cm, most recent eruption in 2009. Alcedo on Isabela Island had an uplift of greater than 90 cm, most recent eruption in 1993. Additional characteristics of the Galapagos Archipelago are closer volcano spacing, smaller volcano sizes, and larger calderas. For instance, Isabela Island includes 6 major volcanoes, Ecuador, Wolf, Darwin, Alcedo, Sierra Negraa and Cerro Azul, with most recent eruptions ranging from 1813 to 2008. The neighboring islands of Santiago and Fernandina last erupted in 1906 and 2009, respectively. Overall, the 9 active volcanoes in the archipelago have erupted 24 times between 1961 and 2011. The shape of these volcanoes is that of an "overturned soup bowl" as opposed to the "overturned saucer plate" of the Hawaiian Islands. The Galapagos shape is due to the pattern of radial and circumferential fissure, radial on the flanks, but circumferential near the caldera summits. It is the circumferential fissures which give rise to stacks of short lava flows.[6]		The volcanoes at the west end of the archipelago are in general, taller, younger, have well developed calderas, and are mostly composed of tholeiitic basalt, while those on the east are shorter, older, lack calderas, and have a more diverse composition. The ages of the islands, from west to east are 0.05 Ma for Fernandina, 0.65 Ma for Isabela, 1.10 Ma for Santiago, 1.7 Ma for Santa Cruz, 2.90 Ma for Santa Fe, and 3.2 Ma for San Cristobal. The calderas on Sierra Negra and Alcedo have active fault systems. The Sierra Negra fault is associated with a sill 2 km below the caldera. The caldera on Fernandina experienced the largest basaltic volcano collapse in history, with the 1968 phreatomagmatic eruption. Fernandina has also been the most active volcano since 1790, with recent eruptions in 1991, 1995, 2005, and 2009, and the entire surface has been covered in numerous flows since 4.3 Ka. The western volcanoes have numerous tuff cones.[6] [7][8][5]		The islands are located in the eastern Pacific Ocean, 973 km (605 mi) off the west coast of South America. The closest land mass is that of mainland Ecuador, the country to which they belong, 926 km/500 nmi to the east.		The islands are found at the coordinates 1°40'N–1°36'S, 89°16'–92°01'W. Straddling the equator, islands in the chain are located in both the northern and southern hemispheres, with Volcán Wolf and Volcán Ecuador on Isla Isabela being directly on the equator. Española Island, the southernmost islet of the archipelago, and Darwin Island, the northernmost one, are spread out over a distance of 220 km (137 mi). The International Hydrographic Organization (IHO) considers them wholly within the South Pacific Ocean, however.[9] The Galápagos Archipelago consists of 7,880 km2 (3,040 sq mi) of land spread over 45,000 km2 (17,000 sq mi) of ocean. The largest of the islands, Isabela, measures 2,250 sq mi/5,827 km2[10] and makes up close to three-quarters of the total land area of the Galápagos. Volcán Wolf on Isabela is the highest point, with an elevation of 1,707 m (5,600 ft) above sea level.		The group consists of 18 main islands, 3 smaller islands, and 107 rocks and islets. The islands are located at the Galapagos Triple Junction. The archipelago is located on the Nazca Plate (a tectonic plate), which is moving east/southeast, diving under the South American Plate at a rate of about 2.5 inches (6.4 cm) per year.[11] It is also atop the Galápagos hotspot, a place where the Earth's crust is being melted from below by a mantle plume, creating volcanoes. The first islands formed here at least 8 million and possibly up to 90 million years ago.[12]		While the older islands have disappeared below the sea as they moved away from the mantle plume, the youngest islands, Isabela and Fernandina, are still being formed, with the most recent volcanic eruption in April 2009 where lava from the volcanic island Fernandina started flowing both towards the island's shoreline and into the center caldera.		The 18[13] main islands (each having a land area at least 1 km2) of the archipelago (with their English names) shown alphabetically:		Although the islands are located on the Equator, the Humboldt Current brings cold water to them, causing frequent drizzles during most of the year. The weather is periodically influenced by the El Niño events, which occur about every 3–7 years and are characterized by warm sea surface temperatures, a rise in sea level, greater wave action, and a depletion of nutrients in the water.[15]		During the season known as the garúa (June to November), the temperature by the sea is 22 °C (72 °F), a steady and cold wind blows from south and southeast, frequent drizzles (garúas) last most of the day, and dense fog conceals the islands. During the warm season (December to May), the average sea and air temperature rises to 25 °C (77 °F), there is no wind at all, there are sporadic, though strong, rains and the sun shines.		Weather changes as altitude increases in the large islands. Temperature decreases gradually with altitude, while precipitation increases due to the condensation of moisture in clouds on the slopes. There is a large range in precipitation from one place to another, not only with altitude, but also depending on the location of the islands, and also with the seasons.		The following table corresponding to the wet 1969 shows the variation of precipitation in different places of Santa Cruz Island:		The precipitation also depends on the geographical location. During March 1969, the precipitation over Charles Darwin Station, on the southern coast of Santa Cruz was 249.0 mm (9.80 in), while on Baltra Island, the precipitation during the same month was only 137.6 mm (5.42 in). This is because Baltra is located behind Santa Cruz with respect to the prevailing southerly winds, so most of the moisture gets precipitated in the Santa Cruz highlands.		There are significant changes in precipitation from one year to another, too. At Charles Darwin Station, the precipitation during March 1969 was 249.0 mm (9.80 in), but during March 1970, it was only 1.2 mm (0.05 in).		On the larger islands, the pattern of generally wet highlands and drier lowlands impacts the flora. The vegetation in the highlands tends to be green and lush, with tropical woodland in places. The lowland areas tend to have arid and semi-arid vegetation, with many thorny shrubs and cacti, and almost bare volcanic rock elsewhere.		According to a 1952 study by Thor Heyerdahl and Arne Skjølsvold, remains of potsherds and other artifacts from several sites on the islands suggest visitation by South American peoples in pre-Columbian era.[16] The group located an Inca flute and shards from more than 130 pieces of ceramics, which were later identified as pre-Incan. However, no remains of graves, ceremonial vessels and constructions have ever been found, suggesting no permanent settlement occurred before the Spanish arrived in the 16th century.[17] It is not clear who the first visitors to the islands were, but they were probably sailors blown off course or people on hapless fishing boats blown out to sea. Most of them were likely unimpressed by the lack of fresh water on the islands. Whether the Incas ever made it here is disputed; in 1572, Spanish chronicler Pedro Sarmiento de Gamboa claimed that Topa Inca Yupanqui, the second Sapa Inca of the Inca Empire had visited the archipelago, but there is little evidence for this, and many experts consider it a far-fetched legend, especially since the Incas were not seafaring people.[18]		European discovery of the Galápagos Islands occurred when Spaniard Fray Tomás de Berlanga, the fourth Bishop of Panama, sailed to Peru to settle a dispute between Francisco Pizarro and his lieutenants. De Berlanga's vessel drifted off course when the winds diminished, and his party reached the islands on 10 March 1535.		The Galápagos Islands first appeared on the maps of Gerardus Mercator and Abraham Ortelius, in about 1570.[19] The islands were named "Insulae de los Galopegos" (Islands of the Tortoises) in reference to the giant tortoises found there.[20]		The first English captain to visit the Galápagos Islands was Richard Hawkins, in 1593. Until the early 19th century, the archipelago was often used as a hideout by mostly English pirates who pilfered Spanish galleons carrying gold and silver from South America to Spain.		In 1793, James Colnett described the flora and fauna of Galápagos, and suggested the islands could be used as base for the whalers operating in the Pacific Ocean. He drew the first accurate navigation charts of the islands. Whalers and maritime fur traders killed and captured thousands of the Galápagos tortoises to extract their fat. The tortoises could be kept on board ship as a means of providing of fresh protein, as these animals could survive for several months on board without any food or water. The hunting of the tortoises was responsible for greatly diminishing, and in some cases eliminating, certain species. Along with whalers came the fur-seal hunters, who brought the population of this animal close to extinction.		The first known permanent human resident on Galápagos was Patrick Watkins, an Irish sailor who was marooned on the Island Floreana from 1807 to 1809. According to later accounts,[21][22] Watkins managed to survive by hunting, growing vegetables and trading with visiting whalers, before finally stealing an open boat and navigating to Guayaquil.		In 1818 the Nantucket whaleship Globe, under Captain George Washington Gardner, discovered a "mother lode" of sperm whales some thousand miles west of the South American coast approximately at the equator. He returned to Nantucket in 1820 with more than 2000 barrels of sperm whale oil and the news of his discovery. This led to an influx of whaleships to exploit the new whaling ground and the Galápagos Islands became a frequent stop for the whalers both before and after visiting what came to be known as the Offshore Grounds. This led to the establishment in the Galápagos Islands of a kind of unofficial "post office" where whaleships stopped to pick up and drop off letters as well as for provisioning and repairing.[23]		In October 1820, the whaleship Essex, out of Nantucket, stopped at the Galápagos for these purposes on its way to the Offshore Grounds. On what was then known as Charles Island, while most of the crew were hunting tortoises one crewmember, English boatsteerer Thomas Chappel, for reasons still unclear, lit a fire which quickly burned out of control. Some of the tortoise hunters had a narrow escape and had to run a gauntlet of fire to get back to the ship. Soon almost the entire island was in flames. Crewmembers reported that after a day of sailing away they could still see the flames against the horizon. One crewmember who returned to the Galápagos several years afterward described the entire island as still a blackened wasteland.[24]		Ecuador annexed the Galápagos Islands on 12 February 1832, naming them the Archipelago of Ecuador. This new name added to several names that had been, and are still, used to refer to the archipelago. The first governor of Galápagos, General José de Villamil, brought a group of convicts to populate the island of Floreana, and in October 1832, some artisans and farmers joined them.		The voyage of the Beagle brought the survey ship HMS Beagle, under captain Robert FitzRoy, to the Galápagos on 15 September 1835 to survey approaches to harbours. The captain and others on board, including his companion, the young naturalist Charles Darwin, made observations on the geology and biology on Chatham, Charles, Albemarle and James islands before they left on 20 October to continue on their round-the-world expedition. Primarily a geologist at the time, Darwin was impressed by the quantity of volcanic craters they saw, later referring to the archipelago as "that land of craters." His study of several volcanic formations over the 5 weeks he stayed in the islands, led to several important geological discoveries, including the first, correct explanation for how volcanic tuff is formed.[25] Darwin noticed the mockingbirds differed between islands, though he thought the birds now known as Darwin's finches were unrelated to each other, and did not bother labelling them by island.[26] Nicholas Lawson, acting Governor of Galápagos for the Republic of the Equator, met them on Charles Island, and as they walked to the prison colony, Lawson told Darwin the tortoises differed from island to island.[27] Towards the end of the voyage, Darwin speculated that the distribution of the mockingbirds and the tortoises might "undermine the stability of Species".[28] When specimens of birds were analysed on his return to England, it was found that many apparently different kinds of birds were species of finches, which were unique to islands. These facts were crucial in Darwin's development of his theory of natural selection explaining evolution, which was presented in The Origin of Species.[26]		José Valdizán and Manuel Julián Cobos tried a new colonization, beginning the exploitation of a type of lichen found in the islands (Roccella portentosa) used as a coloring agent. After the assassination of Valdizán by some of his workers, Cobos brought from the continent a group of more than a hundred workers to San Cristóbal Island, and tried his luck at planting sugar cane. He ruled his plantation with an iron hand, which led to his assassination in 1904. In 1897, Antonio Gil began another plantation on Isabela Island.		Over the course of a whole year, from September 1904, an expedition of the Academy of Sciences of California, led by Rollo Beck, stayed in the Galápagos collecting scientific material on geology, entomology, ornithology, botany, zoology and herpetology. Another expedition from that Academy was done in 1932 (Templeton Crocker Expedition) to collect insects, fish, shells, fossils, birds and plants.		For a long time during the early 1900s and at least through 1929, a cash strapped Ecuador had reached out for potential buyers of the islands to alleviate financial troubles at home. The US had repeatedly expressed its interest in buying the islands for military use as they were positioned strategically guarding the Panama Canal.[29] Besides the United State, Japan, Germany and Chile also expressed interest in establishing bases in the islands at the turn of the century.[30][31] Chile had previously acquired the Straits of Magellan[32] and Easter Island for strategic reasons and leutenant Gregorio Santa Cruz argued in 1903 that possesing an island in equatorial waters, like the Galápagos, would be of great benefit since the geopolitical situation of Chile was expected to drastically change when the Panama Canal opened. Another benefit would be to widen the security radius of Chile.[33]		In 1920s and 1930s, a small wave of European settlers arrived in the islands. There occurred a series of unsolved disappearances on the island of Floreana in the 1930s among the largely European expatriate residents at the time. The Galápagos Affair: Satan Came to Eden is a 2013 feature-length documentary film about the same. Ecuadorian laws provided all colonists with the possibility of receiving twenty hectares each of free land, the right to maintain their citizenship, freedom from taxation for the first ten years in Galápagos, and the right to hunt and fish freely on all uninhabited islands where they might settle.[34] The first European colonists to arrive were Norwegians who settled briefly on Floreana, before moving on to San Cristobal and Santa Cruz. A few years later, other colonists from Europe, America and Ecuador started arriving on the islands, seeking a simpler life.[35] Descendants of the Norwegian Kastdalen family and the German Angermeyer still live on the islands.		During World War II, Ecuador authorized the United States to establish a naval base in Baltra Island, and radar stations in other strategic locations. Baltra was established as a United States Army Air Force base. Baltra was given the name of "Beta Base" along with "Alpha Base" in Nicaragua and "Gamma Base" in Salinas (continental Ecuador). The Crews stationed at Baltra and the aforementioned locations established a geographic triangle of protection in charge of patrolling the Pacific for enemy submarines, and also provided protection for the Panama Canal. After the war, the facilities were given to the government of Ecuador. Today, the island continues as an official Ecuadorian military base. The foundations and other remains of the US base can still be seen as one crosses the island. In 1946, a penal colony was established in Isabela Island, but it was suspended in 1959.		The Galápagos became a national park in 1959,[36] and tourism started in the 1960s, imposing several restrictions upon the human population already living on the island. However, opportunities in the tourism, fishing, and farming industries attracted a mass of poor fishermen and farmers from mainland Ecuador. In the 1990s and 2000s, violent confrontations between parts of the local population and the Galápagos National Park Service occurred, including capturing and killing giant tortoises and holding staff of the Galápagos National Park Service hostage to obtain higher annual sea cucumber quotas.[37]		The islands are administered by a provincial government. It was made a province by presidential decree by President Guillermo Rodríguez Lara on 18 February 1973. The province is divided into cantons, each covering certain islands. The capital is Puerto Baquerizo Moreno.		The largest ethnic group is composed of Ecuadorian Mestizos, the mixed descendants of Spanish colonists and indigenous Native Americans, who arrived mainly in the last century from the continental part of Ecuador. There is also a large number of whites, mostly of Spanish descent. Some descendants of the early European and American colonists on the islands also still remain on the islands.		In 1959, approximately 1,000 to 2,000 people called the islands their home. In 1972 a census in the archipelago recorded a population of 3,488. By the 1980s, this number had risen to more than 15,000 people, and in 2010 there were 25,124 people in the Galápagos.		Five of the islands are inhabited: Baltra, Floreana, Isabela, San Cristobal and Santa Cruz.		Options for flying into the Galápagos are limited to two islands: San Cristobal (San Cristóbal Airport) and Baltra (Seymour Airport). Private aircraft must use Baltra as it is the airport equipped with overnight plane accommodations. Seymour Airport on Baltra was recently renovated (2012–2013) to accommodate larger planes.		Until 1969 the only way to visit was on a private or chartered vessel. There was no regular air service until Forrest Nelson's Hotel Galápagos began the first organized tours in April 1969. Soon other travel companies brought in tour ships and yachts, and local fishermen began converting their wooden boats for rudimentary cruising with guests. These vessels were the main source of overnight accommodations in the Galápagos. Today there are about 85 yachts and ships equipped for overnight guests. In 2006 the Baltra military governed island, was opened up to limited overnight camping. Baltra also requires permits by the military government for overnight stays on the beach. Other inhabited islands also allow camping on the beaches designated as "recreational" use to the locals. All of these camping permits are limited to number of people and nights, with most nights not to exceed three.		Land based hotels are opening on the inhabited islands of San Cristobal, Santa Cruz, Floreana and Isabela. By 2012, more than half the visitors to Galápagos made their tours using day boats and these small hotels. Restaurants, easy access and economy make this an attractive travel option. The cruise tours are still the best way to see all the complex environment and wildlife of the islands.		There are only 116 visitor sites in the Galápagos: 54 land sites and 62 scuba-diving or snorkeling sites. Small groups are allowed to visit in 2- to 4-hour shifts only, to limit impact on the area. All groups are accompanied by licensed guides.		Though the first protective legislation for the Galápagos was enacted in 1930 and supplemented in 1936, it was not until the late 1950s that positive action was taken to control what was happening to the native flora and fauna. In 1955, the International Union for the Conservation of Nature organized a fact-finding mission to the Galápagos. Two years later, in 1957, UNESCO, in cooperation with the government of Ecuador, sent another expedition to study the conservation situation and choose a site for a research station.		In 1959, the centenary year of Charles Darwin's publication of The Origin of Species, the Ecuadorian government declared 97.5% of the archipelago's land area a national park, excepting areas already colonised. The Charles Darwin Foundation (CDF) was founded the same year. The core responsibility of CDF, an international nongovernmental organization (NGO) constituted in Belgium, is to conduct research and provide the research findings to the government for effective management of Galápagos. CDF's research efforts began with the establishment of the Charles Darwin Research Station on Santa Cruz Island in 1964. During the early years, conservation programs, such as eradication of introduced species and protection of native species, were carried out by research station personnel. Now much of that work is accomplished by the Galápagos National Park Service using the research findings and methodologies developed by CDF.		In 1986, the 70,000 square kilometers (27,000 sq mi) of ocean surrounding the islands was declared a marine reserve, second in size only to Australia's Great Barrier Reef. In 1990, the archipelago became a whale sanctuary. UNESCO recognised the islands in 1978 as a World Heritage Site[38] and in 1985, as a biosphere reserve. This was later extended in December 2001 to include the marine reserve. In July 2010, the World Heritage Committee agreed to remove the Galápagos Islands from its list of precious sites endangered by environmental threats or overuse.[39]		Noteworthy species include:		Introduced plants and animals, such as feral goats, cats, and cattle, brought accidentally or willingly to the islands by humans, represent the main threat to Galápagos. Quick to reproduce and with no natural predators, these alien species decimated the habitats of native species. The native animals, lacking natural predators on the islands, are defenseless to introduced predators.		There are over 700 introduced plant species today. There are only 500 native and endemic species. This difference is creating a major problem for the islands and the natural species that inhabit them. These plants have invaded large areas and eliminated endemic species in the humid zones of San Cristobal, Floreana, Isabela and Santa Cruz. Some of the most harmful introduced plants are the guayaba or guava (Psidium guajava), avocado (Persea americana), cascarilla (Cinchona pubescens), balsa (Ochroma pyramidale), hill raspberry (Rubus niveus), various citrus (orange, grapefruit, lemon), floripondio, higuerilla (Ricinus communis) trees and the elephant grass, Pennisetum purpureum.		Many species were introduced to the Galápagos by pirates. Thor Heyerdahl quoted documents that mention the Viceroy of Peru, knowing that British pirates ate the goats that they themselves had released in the islands, ordered dogs to be freed there to eliminate the goats.[16] Also, when colonization of Floreana by José de Villamil failed, he ordered the goats, donkeys, cattle and other animals from the farms in Floreana be transferred to other islands for the purpose of later colonization.		Non-native goats, pigs, dogs, rats, cats, mice, sheep, horses, donkeys, cows, poultry, ants, cockroaches, and some parasites inhabit the islands today. Dogs and cats attack the tame birds and destroy the nests of birds, land tortoises, and marine turtles. They sometimes kill small Galápagos tortoises and iguanas.[40] Pigs are even more harmful, covering larger areas and destroying the nests of tortoises, turtles and iguanas, as well as eating the animals' native food. Pigs also knock down vegetation in their search for roots and insects. This problem abounds in Cerro Azul volcano and Isabela, and in Santiago, pigs may be the cause of the disappearance of the land iguanas that were so abundant when Darwin visited. The black rat (Rattus rattus) attacks small Galápagos tortoises when they leave the nest, so in Pinzón they stopped the reproduction for a period of more than 50 years; only adults were found on that island.[41] Also, where the black rat is found, the endemic rat has disappeared. Cattle and donkeys eat all the available vegetation and compete with native species for the scarce water. In 1959, fishermen introduced one male and two female goats to Pinta island; by 1973, the National Park service estimated the population of goats to be over 30,000 individuals. Goats were also introduced to Marchena in 1967 and to Rabida in 1971. A goat eradication program, however, cleared the goats from Pinta and Santiago and most of the goat population from Isabela.[42] In fact, by 2006 all feral pigs, donkeys and non-sterile goats had been eliminated from Santiago and Isabela, the largest islands with the worst problems due to non-native mammals.[43][44]		The fast-growing poultry industry on the inhabited islands has been cause for concern from local conservationists, who fear domestic birds could introduce disease into the endemic wild bird populations.		The Galápagos marine sanctuary is under threat from a host of illegal fishing activities, in addition to other problems of development.[45] The most pressing threat to the Marine Reserve comes from local, mainland and foreign fishing targeting marine life illegally within the Reserve, such as sharks (hammerheads and other species) for their fins,[45] and the harvest of sea cucumbers out of season. Development threatens both land and sea species. The growth of both the tourism industry and local populations fuelled by high birth rates and illegal immigration threaten the wildlife of the Archipelago. The grounding of the oil tanker Jessica in 2001 and the subsequent oil spill brought this threat to world attention.		In 2007, UNESCO put the Galápagos Islands on their List of World Heritage in Danger because of threats posed by invasive species, unbridled tourism and overfishing.[46] On 29 July 2010, the World Heritage Committee decided to remove the Galápagos Islands from the list because the Committee found significant progress had been made by Ecuador in addressing these problems.[47]		On 28 January 2008, Galápagos National Park official Victor Carrion announced 53 sea lions (13 pups, 25 youngsters, 9 males and 6 females) were killed at the Galápagos Islands nature reserve on Pinta, with their heads caved in. In 2001, poachers killed 35 male sea lions.[48]		The Galápagos Islands were short-listed as a candidate to be one of the New7Wonders of Nature by the New7Wonders of Nature Foundation. As of February 2009, the archipelago was ranked first in Group B, the category for islands.[49]		The islands' biodiversity is under threat from several sources. The human population is growing at an unsustainable rate of 8% per year (1995). Introduced species have caused damage, and in 1996 a US$5 million, five-year eradication plan commenced in an attempt to rid the islands of introduced species such as goats, rats, deer, and donkeys. Except for the rats, the project was essentially completed in 2006.[43][44] Rats have only been eliminated from the smaller Galapagos Islands of Rábida and Pinzón.[50]		El Niño has adversely affected the marine ecosystem. In January 2001, an oil slick from a stranded tanker threatened the islands, but winds and shifting ocean currents helped disperse the oil before much damage was done. The 1997–98 El Niño adversely affected wildlife in the waters surrounding the islands, as the waters were 5 °C (9 °F) warmer than normal. Corals and barnacles suffered, hammerhead sharks were driven away, and most of the island's seabirds failed to breed in 1997–98. The mortality rate of marine iguanas rose as the green algae they feed on was replaced by inedible red algae. During the 1982–83 El Niño, 70% of the marine iguanas starved to death because of this.[51]		
A beach is a geological formation consisting of loose rock particles along the shoreline of a body of water.		Beach, Beaches or beaching may also refer to:						
The geomorphological term feeder bluff is not a standard, widely accepted geologic term; its use has been limited to the Puget Sound region. The concept was apparently first discussed at Western Washington University. The term feeder bluff has been applied to certain coastal cliffs or headlands that provide sediment to down-current beaches as the result of wave action on the bluff.		A bluff will be more susceptible to erosion if the sediment is unconsolidated, and more resistant in crystalline rocks, like granite. Rocks that are heavily fractured are also very likely to suffer from erosion because the water can flow between the cracks to speed up the process. A bluff will retreat towards land as the erosion processes continue.		The term has not been extensively researched; specific criteria have not been developed to distinguish "feeder bluffs" from other types of bluffs; and quantities and rates of sediment supply to beaches and the littoral drift are unspecified and unknown. The overall contribution of "feeder bluffs" to beach processes, unlike the well-researched effects of sediment from rivers, is still undetermined.		
Coordinates: 25°S 133°E﻿ / ﻿25°S 133°E﻿ / -25; 133		Australia (/əˈstreɪliə/ ( listen), /ɒ-/, /-ljə/),[11][12] officially the Commonwealth of Australia,[13] is a country comprising the mainland of the Australian continent, the island of Tasmania and numerous smaller islands. It is the largest country in Oceania and the world's sixth-largest country by total area. The neighbouring countries are Papua New Guinea, Indonesia and East Timor to the north; the Solomon Islands and Vanuatu to the north-east; and New Zealand to the south-east. Australia's capital is Canberra, and its largest urban area is Sydney.		For about 50,000 years[14] before the first British settlement in the late 18th century,[15][16] Australia was inhabited by indigenous Australians,[17] who spoke languages classifiable into roughly 250 groups.[18][19] After the European discovery of the continent by Dutch explorers in 1606, Australia's eastern half was claimed by Great Britain in 1770 and initially settled through penal transportation to the colony of New South Wales from 26 January 1788. The population grew steadily in subsequent decades, and by the 1850s most of the continent had been explored and an additional five self-governing crown colonies established. On 1 January 1901, the six colonies federated, forming the Commonwealth of Australia. Australia has since maintained a stable liberal democratic political system that functions as a federal parliamentary constitutional monarchy comprising six states and several territories.		Australia has the world's 13th-largest economy and ninth-highest per capita income (IMF).[20] With the second-highest human development index globally, the country ranks highly in quality of life, health, education, economic freedom, and civil liberties and political rights.[21] Australia is a member of the United Nations, G20, Commonwealth of Nations, ANZUS, Organisation for Economic Co-operation and Development (OECD), World Trade Organization, Asia-Pacific Economic Cooperation, and the Pacific Islands Forum. The population of 25 million[6] is highly urbanised and heavily concentrated on the eastern seaboard.[22] As of 2015, Australia had the 9th largest number of people born overseas, higher than Spain (10th) and Italy (11th).[23]						The name Australia (pronounced [əˈstɹæɪljə, -liə] in Australian English[24]) is derived from the Latin Terra Australis ("southern land"), a name used for a hypothetical continent in the Southern Hemisphere since ancient times.[25] When Europeans first began visiting and mapping Australia in the 17th century, the name Terra Australis was naturally applied to the new territories.[N 4]		Until the early 19th century, Australia was best known as "New Holland", a name first applied by the Dutch explorer Abel Tasman in 1644 (as Nieuw-Holland) and subsequently anglicised. Terra Australis still saw occasional usage, such as in scientific texts.[N 5] The name Australia was popularised by the explorer Matthew Flinders, who said it was "more agreeable to the ear, and an assimilation to the names of the other great portions of the earth".[31] The first time that Australia appears to have been officially used was in April 1817, in which Governor Lachlan Macquarie acknowledged the receipt of Flinders' charts of Australia from Lord Bathurst.[32] In December 1817, Macquarie recommended to the Colonial Office that it be formally adopted.[33] In 1824, the Admiralty agreed that the continent should be known officially by that name.[34] The first official published use of the new name came with the 1830 publication of "The Australia Directory" by the Hydrographic Office.[35]		Colloquial names for Australia include "Oz" and "the Land Down Under" (usually shortened to just "Down Under"). Other epithets include "the Great Southern Land", "the Lucky Country", "the Sunburnt Country", and "the Wide Brown Land". The latter two both derive from Dorothea Mackellar's 1908 poem "My Country".[36]		Human habitation of the Australian continent is estimated to have begun between 42,000 and 48,000 years ago,[37][38] possibly with the migration of people by land bridges and short sea-crossings from what is now Southeast Asia. These first inhabitants may have been ancestors of modern Indigenous Australians.[39] At the time of European settlement in the late 18th century, most Indigenous Australians were hunter-gatherers, with a complex oral culture and spiritual values based on reverence for the land and a belief in the Dreamtime. The Torres Strait Islanders, ethnically Melanesian, were originally horticulturists and hunter-gatherers.[40] The northern coasts and waters of Australia were visited sporadically by fishermen from Maritime Southeast Asia.[41]		The first recorded European sighting of the Australian mainland, and the first recorded European landfall on the Australian continent (in 1606), are attributed to the Dutch. The first ship and crew to chart the Australian coast and meet with Aboriginal people was the Duyfken captained by Dutch navigator, Willem Janszoon.[42] He sighted the coast of Cape York Peninsula in early 1606, and made landfall on 26 February at the Pennefather River near the modern town of Weipa on Cape York.[43] The Dutch charted the whole of the western and northern coastlines and named the island continent "New Holland" during the 17th century, but made no attempt at settlement.[43] William Dampier, an English explorer and privateer, landed on the north-west coast of New Holland in 1688 and again in 1699 on a return trip.[44] In 1770, James Cook sailed along and mapped the east coast, which he named New South Wales and claimed for Great Britain.[45]		With the loss of its American colonies in 1783, the British Government sent a fleet of ships, the "First Fleet", under the command of Captain Arthur Phillip, to establish a new penal colony in New South Wales. A camp was set up and the flag raised at Sydney Cove, Port Jackson, on 26 January 1788,[16] a date which became Australia's national day, Australia Day, although the British Crown Colony of New South Wales was not formally promulgated until 7 February 1788. The first settlement led to the foundation of Sydney, and the exploration and settlement of other regions.		A British settlement was established in Van Diemen's Land, now known as Tasmania, in 1803, and it became a separate colony in 1825.[46] The United Kingdom formally claimed the western part of Western Australia (the Swan River Colony) in 1828.[47] Separate colonies were carved from parts of New South Wales: South Australia in 1836, Victoria in 1851, and Queensland in 1859.[48] The Northern Territory was founded in 1911 when it was excised from South Australia.[49] South Australia was founded as a "free province"—it was never a penal colony.[50] Victoria and Western Australia were also founded "free", but later accepted transported convicts.[51][52] A campaign by the settlers of New South Wales led to the end of convict transportation to that colony; the last convict ship arrived in 1848.[53]		The indigenous population, estimated to have been between 750,000 and 1,000,000 in 1788,[54] declined for 150 years following settlement, mainly due to infectious disease.[55] Thousands more died as a result of frontier conflict with settlers.[56] A government policy of "assimilation" beginning with the Aboriginal Protection Act 1869 resulted in the removal of many Aboriginal children from their families and communities—often referred to as the Stolen Generations—a practice which may also have contributed to the decline in the indigenous population.[57] As a result of the 1967 referendum, the Federal government's power to enact special laws with respect to a particular race was extended to enable the making of laws with respect to Aborigines.[58] Traditional ownership of land ("native title") was not recognised in law until 1992, when the High Court of Australia held in Mabo v Queensland (No 2) that the legal doctrine that Australia had been terra nullius ("land belonging to no one") did not apply to Australia at the time of British settlement.[59]		A gold rush began in Australia in the early 1850s[60] and the Eureka Rebellion against mining licence fees in 1854 was an early expression of civil disobedience.[61] Between 1855 and 1890, the six colonies individually gained responsible government, managing most of their own affairs while remaining part of the British Empire.[62] The Colonial Office in London retained control of some matters, notably foreign affairs,[63] defence,[64] and international shipping.		On 1 January 1901, federation of the colonies was achieved after a decade of planning, consultation and voting.[65] This established the Commonwealth of Australia as a dominion of the British Empire.[66][67] The Federal Capital Territory (later renamed the Australian Capital Territory) was formed in 1911 as the location for the future federal capital of Canberra. Melbourne was the temporary seat of government from 1901 to 1927 while Canberra was being constructed.[68] The Northern Territory was transferred from the control of the South Australian government to the federal parliament in 1911.[69] In 1914, Australia joined Britain in fighting World War I, with support from both the outgoing Commonwealth Liberal Party and the incoming Australian Labor Party.[70][71] Australians took part in many of the major battles fought on the Western Front.[72] Of about 416,000 who served, about 60,000 were killed and another 152,000 were wounded.[73] Many Australians regard the defeat of the Australian and New Zealand Army Corps (ANZACs) at Gallipoli as the birth of the nation—its first major military action.[74][75] The Kokoda Track campaign is regarded by many as an analogous nation-defining event during World War II.[76]		Britain's Statute of Westminster 1931 formally ended most of the constitutional links between Australia and the UK. Australia adopted it in 1942,[77] but it was backdated to 1939 to confirm the validity of legislation passed by the Australian Parliament during World War II.[78][79] The shock of the United Kingdom's defeat in Asia in 1942 and the threat of Japanese invasion caused Australia to turn to the United States as a new ally and protector.[80] Since 1951, Australia has been a formal military ally of the US, under the ANZUS treaty.[81] After World War II Australia encouraged immigration from mainland Europe. Since the 1970s and following the abolition of the White Australia policy, immigration from Asia and elsewhere was also promoted.[82] As a result, Australia's demography, culture, and self-image were transformed.[83] The final constitutional ties between Australia and the UK were severed with the passing of the Australia Act 1986, ending any British role in the government of the Australian States, and closing the option of judicial appeals to the Privy Council in London.[84] In a 1999 referendum, 55% of voters and a majority in every state rejected a proposal to become a republic with a president appointed by a two-thirds vote in both Houses of the Australian Parliament. Since the election of the Whitlam Government in 1972,[85] there has been an increasing focus in foreign policy on ties with other Pacific Rim nations, while maintaining close ties with Australia's traditional allies and trading partners.[86]		Australia's landmass of 7,617,930 square kilometres (2,941,300 sq mi)[87] is on the Indo-Australian Plate. Surrounded by the Indian and Pacific oceans,[N 6] it is separated from Asia by the Arafura and Timor seas, with the Coral Sea lying off the Queensland coast, and the Tasman Sea lying between Australia and New Zealand. The world's smallest continent[89] and sixth largest country by total area,[90] Australia—owing to its size and isolation—is often dubbed the "island continent",[91] and is sometimes considered the world's largest island.[92] Australia has 34,218 kilometres (21,262 mi) of coastline (excluding all offshore islands),[93] and claims an extensive Exclusive Economic Zone of 8,148,250 square kilometres (3,146,060 sq mi). This exclusive economic zone does not include the Australian Antarctic Territory.[94] Apart from Macquarie Island, Australia lies between latitudes 9° and 44°S, and longitudes 112° and 154°E.		The Great Barrier Reef, the world's largest coral reef,[95] lies a short distance off the north-east coast and extends for over 2,000 kilometres (1,240 mi). Mount Augustus, claimed to be the world's largest monolith,[96] is located in Western Australia. At 2,228 metres (7,310 ft), Mount Kosciuszko on the Great Dividing Range is the highest mountain on the Australian mainland. Even taller are Mawson Peak (at 2,745 metres or 9,006 feet), on the remote Australian territory of Heard Island, and, in the Australian Antarctic Territory, Mount McClintock and Mount Menzies, at 3,492 metres (11,457 ft) and 3,355 metres (11,007 ft) respectively.[97]		Australia's size gives it a wide variety of landscapes, with tropical rainforests in the north-east, mountain ranges in the south-east, south-west and east, and dry desert in the centre.[98] It is the flattest continent,[99] with the oldest and least fertile soils;[100][101] desert or semi-arid land commonly known as the outback makes up by far the largest portion of land.[102] The driest inhabited continent, its annual rainfall averaged over continental area is less than 500 mm.[103] The population density, 2.8 inhabitants per square kilometre, is among the lowest in the world,[104] although a large proportion of the population lives along the temperate south-eastern coastline.[105]		Eastern Australia is marked by the Great Dividing Range, which runs parallel to the coast of Queensland, New South Wales and much of Victoria. The name is not strictly accurate, because parts of the range consist of low hills, and the highlands are typically no more than 1,600 metres (5,249 ft) in height.[106] The coastal uplands and a belt of Brigalow grasslands lie between the coast and the mountains, while inland of the dividing range are large areas of grassland.[106][107] These include the western plains of New South Wales, and the Einasleigh Uplands, Barkly Tableland, and Mulga Lands of inland Queensland. The northernmost point of the east coast is the tropical-rainforested Cape York Peninsula.[108][109][110][111]		The landscapes of the Top End and the Gulf Country—with their tropical climate—include forest, woodland, wetland, grassland, rainforest and desert.[112][113][114] At the north-west corner of the continent are the sandstone cliffs and gorges of The Kimberley, and below that the Pilbara. To the south of these and inland, lie more areas of grassland: the Ord Victoria Plain and the Western Australian Mulga shrublands.[115][116][117] At the heart of the country are the uplands of central Australia. Prominent features of the centre and south include Uluru (also known as Ayers Rock), the famous sandstone monolith, and the inland Simpson, Tirari and Sturt Stony, Gibson, Great Sandy, Tanami, and Great Victoria deserts, with the famous Nullarbor Plain on the southern coast.[118][119][120][121]		The climate of Australia is significantly influenced by ocean currents, including the Indian Ocean Dipole and the El Niño–Southern Oscillation, which is correlated with periodic drought, and the seasonal tropical low-pressure system that produces cyclones in northern Australia.[122][123] These factors cause rainfall to vary markedly from year to year. Much of the northern part of the country has a tropical, predominantly summer-rainfall (monsoon)[103] The south-west corner of the country has a Mediterranean climate.[124] The south-east ranges from oceanic (Tasmania and coastal Victoria) to humid subtropical (upper half of New South Wales). The interior is arid to semi-arid.[103]		According to the Bureau of Meteorology's 2011 Australian Climate Statement, Australia had lower than average temperatures in 2011 as a consequence of a La Niña weather pattern; however, "the country's 10-year average continues to demonstrate the rising trend in temperatures, with 2002–2011 likely to rank in the top two warmest 10-year periods on record for Australia, at 0.52 °C (0.94 °F) above the long-term average".[125] Furthermore, 2014 was Australia's third warmest year since national temperature observations commenced in 1910.[126][127] Water restrictions are frequently in place in many regions and cities of Australia in response to chronic shortages due to urban population increases and localised drought.[128][129] Throughout much of the continent, major flooding regularly follows extended periods of drought, flushing out inland river systems, overflowing dams and inundating large inland flood plains, as occurred throughout Eastern Australia in 2010, 2011 and 2012 after the 2000s Australian drought.		Australia's carbon dioxide emissions per capita are among the highest in the world, lower than those of only a few other industrialised nations.[130] A carbon tax was introduced in 2012 and helped to reduce Australia's emissions but was scrapped in 2014 under the Liberal Government.[131] Since the carbon tax was repealed, emissions have again continued to rise.[132]		Although most of Australia is semi-arid or desert, it includes a diverse range of habitats from alpine heaths to tropical rainforests, and is recognised as a megadiverse country. Fungi typify that diversity; an estimated 250,000 species—of which only 5% have been described—occur in Australia.[133] Because of the continent's great age, extremely variable weather patterns, and long-term geographic isolation, much of Australia's biota is unique. About 85% of flowering plants, 84% of mammals, more than 45% of birds, and 89% of in-shore, temperate-zone fish are endemic.[134] Australia has the greatest number of reptiles of any country, with 755 species.[135] Besides Antarctica, Australia is the only continent that developed without feline species. Feral cats may have been introduced in the 17th century by Dutch shipwrecks, and later in the 18th century by European settlers. They are now considered a major factor in the decline and extinction of many vulnerable and endangered native species.[136]		Australian forests are mostly made up of evergreen species, particularly eucalyptus trees in the less arid regions; wattles replace them as the dominant species in drier regions and deserts.[137] Among well-known Australian animals are the monotremes (the platypus and echidna); a host of marsupials, including the kangaroo, koala, and wombat, and birds such as the emu and the kookaburra.[137] Australia is home to many dangerous animals including some of the most venomous snakes in the world.[138] The dingo was introduced by Austronesian people who traded with Indigenous Australians around 3000 BCE.[139] Many animal and plant species became extinct soon after first human settlement,[140] including the Australian megafauna; others have disappeared since European settlement, among them the thylacine.[141][142]		Many of Australia's ecoregions, and the species within those regions, are threatened by human activities and introduced animal, chromistan, fungal and plant species.[143] All these factors have led to Australia having the highest mammal extinction rate of any country in the world.[144] The federal Environment Protection and Biodiversity Conservation Act 1999 is the legal framework for the protection of threatened species.[145] Numerous protected areas have been created under the National Strategy for the Conservation of Australia's Biological Diversity to protect and preserve unique ecosystems;[146][147] 65 wetlands are listed under the Ramsar Convention,[148] and 16 natural World Heritage Sites have been established.[149] Australia was ranked 3rd out of 178 countries in the world on the 2014 Environmental Performance Index.[150]		Australia is a federal parliamentary constitutional monarchy[151] with Elizabeth II at its apex as the Queen of Australia, a role that is distinct from her position as monarch of the other Commonwealth realms. The Queen is represented in Australia by the Governor-General at the federal level and by the Governors at the state level, who by convention act on the advice of her ministers.[152][153] Thus, in practice the Governor-General has no actual decision-making or de facto governmental role, and merely acts as a legal figurehead for the actions of the Prime Minister and the Federal Executive Council. The Governor-General does have extraordinary reserve powers which may be exercised outside the Prime Minister's request in rare and limited circumstances, the most notable exercise of which was the dismissal of the Whitlam Government in the constitutional crisis of 1975.[154]		The federal government is separated into three branches:		In the Senate (the upper house), there are 76 senators: twelve each from the states and two each from the mainland territories (the Australian Capital Territory and the Northern Territory).[156] The House of Representatives (the lower house) has 150 members elected from single-member electoral divisions, commonly known as "electorates" or "seats", allocated to states on the basis of population,[157] with each original state guaranteed a minimum of five seats.[158] Elections for both chambers are normally held every three years simultaneously; senators have overlapping six-year terms except for those from the territories, whose terms are not fixed but are tied to the electoral cycle for the lower house; thus only 40 of the 76 places in the Senate are put to each election unless the cycle is interrupted by a double dissolution.[156]		Australia's electoral system uses preferential voting for all lower house elections with the exception of Tasmania and the ACT which, along with the Senate and most state upper houses, combine it with proportional representation in a system known as the single transferable vote. Voting is compulsory for all enrolled citizens 18 years and over in every jurisdiction,[159] as is enrolment (with the exception of South Australia).[160] The party with majority support in the House of Representatives forms the government and its leader becomes Prime Minister. In cases where no party has majority support, the Governor-General has the constitutional power to appoint the Prime Minister and, if necessary, dismiss one that has lost the confidence of Parliament.[161]		There are two major political groups that usually form government, federally and in the states: the Australian Labor Party and the Coalition which is a formal grouping of the Liberal Party and its minor partner, the National Party.[162][163] Within Australian political culture, the Coalition is considered centre-right and the Labor Party is considered centre-left.[164] Independent members and several minor parties have achieved representation in Australian parliaments, mostly in upper houses.		In September 2015, Malcolm Turnbull successfully challenged Abbott for leadership of the Coalition, and was sworn in as the 29th Prime Minister of Australia.[165] The most recent federal election was held on 2 July 2016 and resulted in the Coalition forming a majority government.[166]		Australia has six states—New South Wales (NSW), Queensland (QLD), South Australia (SA), Tasmania (TAS), Victoria (VIC) and Western Australia (WA)—and two major mainland territories—the Australian Capital Territory (ACT) and the Northern Territory (NT). In most respects these two territories function as states, except that the Commonwealth Parliament has the power to modify or repeal any legislation passed by the territory parliaments.[167]		Under the constitution, the States essentially have plenary legislative power to legislate on any subject, whereas the Commonwealth (federal) Parliament may only legislate within the subject areas enumerated under section 51. For example, State parliaments have the power to legislate with respect to education, criminal law and state police, health, transport, and local government, but the Commonwealth Parliament does not have any specific power to legislate in these areas.[168] However, Commonwealth laws prevail over State laws to the extent of the inconsistency.[169] In addition, the Commonwealth has the power to levy income tax which, coupled with the power to make grants to States, has given it the financial means to incentivize States to pursue specific legislative agendas within areas over which the Commonwealth does not have legislative power.		Each state and major mainland territory has its own parliament—unicameral in the Northern Territory, the ACT and Queensland, and bicameral in the other states. The states are sovereign entities, although subject to certain powers of the Commonwealth as defined by the Constitution. The lower houses are known as the Legislative Assembly (the House of Assembly in South Australia and Tasmania); the upper houses are known as the Legislative Council. The head of the government in each state is the Premier and in each territory the Chief Minister. The Queen is represented in each state by a Governor; and in the Northern Territory, the Administrator.[170] In the Commonwealth, the Queen's representative is the Governor-General.[171]		The Commonwealth Parliament also directly administers the following external territories: Ashmore and Cartier Islands; Australian Antarctic Territory; Christmas Island; Cocos (Keeling) Islands; Coral Sea Islands; Heard Island and McDonald Islands; and Jervis Bay Territory, a naval base and sea port for the national capital in land that was formerly part of New South Wales.[155] The external territory of Norfolk Island previously exercised considerable autonomy under the Norfolk Island Act 1979 through its own legislative assembly and an Administrator to represent the Queen.[172] In 2015, the Commonwealth Parliament abolished self-government, integrating Norfolk Island into the Australian tax and welfare systems and replacing its legislative assembly with a council.[173] Macquarie Island is administered by Tasmania, and Lord Howe Island by New South Wales.		Over recent decades, Australia's foreign relations have been driven by a close association with the United States through the ANZUS pact, and by a desire to develop relationships with Asia and the Pacific, particularly through ASEAN and the Pacific Islands Forum. In 2005 Australia secured an inaugural seat at the East Asia Summit following its accession to the Treaty of Amity and Cooperation in Southeast Asia, and in 2011 attended the Sixth East Asia Summit in Indonesia. Australia is a member of the Commonwealth of Nations, in which the Commonwealth Heads of Government meetings provide the main forum for co-operation.[174]		Australia has pursued the cause of international trade liberalisation.[175] It led the formation of the Cairns Group and Asia-Pacific Economic Cooperation.[176][177] Australia is a member of the Organisation for Economic Co-operation and Development and the World Trade Organization,[178][179] and has pursued several major bilateral free trade agreements, most recently the Australia–United States Free Trade Agreement[180] and Closer Economic Relations with New Zealand,[181] with another free trade agreement being negotiated with China—the Australia–China Free Trade Agreement—and Japan,[182] South Korea in 2011,[183][184] Australia–Chile Free Trade Agreement, and as of November 2015 has put the Trans-Pacific Partnership before parliament for ratification.[185]		Along with New Zealand, the United Kingdom, Malaysia and Singapore, Australia is party to the Five Power Defence Arrangements, a regional defence agreement. A founding member country of the United Nations, Australia is strongly committed to multilateralism[186] and maintains an international aid program under which some 60 countries receive assistance. The 2005–06 budget provides A$2.5 billion for development assistance.[187] Australia ranks fifteenth overall in the Center for Global Development's 2012 Commitment to Development Index.[188]		Australia's armed forces—the Australian Defence Force (ADF)—comprise the Royal Australian Navy (RAN), the Australian Army and the Royal Australian Air Force (RAAF), in total numbering 81,214 personnel (including 57,982 regulars and 23,232 reservists) as of November 2015. The titular role of Commander-in-Chief is vested in the Governor-General, who appoints a Chief of the Defence Force from one of the armed services on the advice of the government.[189] Day-to-day force operations are under the command of the Chief, while broader administration and the formulation of defence policy is undertaken by the Minister and Department of Defence.		In the 2015–16 budget, defence spending was A$31.9 billion or 1.92% of GDP,[190] representing the 13th largest defence budget.[191] Australia has been involved in UN and regional peacekeeping, disaster relief and armed conflict, including the 2003 invasion of Iraq; it currently has deployed about 2,241 personnel in varying capacities to 12 international operations in areas including Iraq and Afghanistan.[192]		Australia is a wealthy country; it generates its income from various sources including mining-related exports, telecommunications, banking and manufacturing.[194][195][196] It has a market economy, a relatively high GDP per capita, and a relatively low rate of poverty. In terms of average wealth, Australia ranked second in the world after Switzerland in 2013, although the nation's poverty rate increased from 10.2% to 11.8%, from 2000/01 to 2013.[197][198] It was identified by the Credit Suisse Research Institute as the nation with the highest median wealth in the world and the second-highest average wealth per adult in 2013.[197]		The Australian dollar is the currency for the nation, including Christmas Island, Cocos (Keeling) Islands, and Norfolk Island, as well as the independent Pacific Island states of Kiribati, Nauru, and Tuvalu. With the 2006 merger of the Australian Stock Exchange and the Sydney Futures Exchange, the Australian Securities Exchange became the ninth largest in the world.[199]		Ranked fifth in the Index of Economic Freedom (2017),[200] Australia is the world's twelfth largest economy and has the sixth highest per capita GDP (nominal) at US$56,291.[201] The country was ranked second in the United Nations 2016 Human Development Index.[202] All of Australia's major cities fare well in global comparative livability surveys;[203] Melbourne reached top spot for the fourth year in a row on The Economist's 2014 list of the world's most liveable cities, followed by Adelaide, Sydney, and Perth in the fifth, seventh, and ninth places respectively.[204] Total government debt in Australia is about $190 billion[205] – 20% of GDP in 2010.[206] Australia has among the highest house prices and some of the highest household debt levels in the world.[207]		An emphasis on exporting commodities rather than manufactured goods has underpinned a significant increase in Australia's terms of trade since the start of the 21st century, due to rising commodity prices. Australia has a balance of payments that is more than 7% of GDP negative, and has had persistently large current account deficits for more than 50 years.[209] Australia has grown at an average annual rate of 3.6% for over 15 years, in comparison to the OECD annual average of 2.5%.[209]		Australia was the only advanced economy not to experience a recession due to the global financial downturn in 2008–2009.[210] However, the economies of six of Australia's major trading partners have been in recession, which in turn has affected Australia, significantly hampering its economic growth in recent years.[211][212] From 2012 to early 2013, Australia's national economy grew, but some non-mining states and Australia's non-mining economy experienced a recession.[213][214][215]		The Hawke Government floated the Australian dollar in 1983 and partially deregulated the financial system.[216] The Howard Government followed with a partial deregulation of the labour market and the further privatisation of state-owned businesses, most notably in the telecommunications industry.[217] The indirect tax system was substantially changed in July 2000 with the introduction of a 10% Goods and Services Tax (GST).[218] In Australia's tax system, personal and company income tax are the main sources of government revenue.[219]		In May 2012, there were 11,537,900 people employed (either full- or part-time), with an unemployment rate of 5.1%.[220] Youth unemployment (15–24) stood at 11.2%.[220] Data released in mid-November 2013 showed that the number of welfare recipients had grown by 55%. In 2007 228,621 Newstart unemployment allowance recipients were registered, a total that increased to 646,414 in March 2013.[221] According to the Graduate Careers Survey, full-time employment for newly qualified professionals from various occupations has declined since 2011 but it increases for graduates three years after graduation.[222][223]		Since 2008, inflation has typically been 2–3% and the base interest rate 5–6%. The service sector of the economy, including tourism, education, and financial services, accounts for about 70% of GDP.[224] Rich in natural resources, Australia is a major exporter of agricultural products, particularly wheat and wool, minerals such as iron-ore and gold, and energy in the forms of liquified natural gas and coal. Although agriculture and natural resources account for only 3% and 5% of GDP respectively, they contribute substantially to export performance. Australia's largest export markets are Japan, China, the US, South Korea, and New Zealand.[225] Australia is the world's fourth largest exporter of wine, and the wine industry contributes $5.5 billion per year to the nation's economy.[226]		Until the Second World War, the vast majority of settlers and immigrants came from the British Isles, and a majority of Australians have some British or Irish ancestry. These Australians form an ethnic group known as Anglo-Celtic Australians. In the 2016 Australian census, the most commonly nominated ancestries were English (36.1%), Australian (33.5%),[227] Irish (11.0%), Scottish (9.3%), Chinese (5.6%), Italian (4.6%), German (4.5%), Indian (2.8%), Greek (1.8%), and Dutch (1.6%).[228]		Australia's population has quadrupled since the end of World War I,[229] much of this increase from immigration. Following World War II and through to 2000, almost 5.9 million of the total population settled in the country as new immigrants.[230] Most immigrants are skilled,[231] but the immigration quota includes categories for family members and refugees.[231] By 2050, Australia's population is currently projected to reach around 42 million.[232] Nevertheless, its population density, 2.8 inhabitants per square kilometre, remains among the lowest in the world.[104]		In 2016, more than a quarter (26%) of Australia's population were born overseas; the five largest immigrant groups were those born in England (3.9%), New Zealand (2.2%), Mainland China (2.2%), India (1.9%), and the Philippines (1%).[233] Following the abolition of the White Australia policy in 1973, numerous government initiatives have been established to encourage and promote racial harmony based on a policy of multiculturalism.[234] In 2015–16, there were 189,770 permanent immigrants admitted to Australia, mainly from Asia.[235]		The Indigenous population—Aborigines and Torres Strait Islanders—was counted at 649,171 (2.8% of the total population) in 2016.[236] The increase is partly due to many people with Indigenous heritage previously having been overlooked by the census due to undercount and cases where their Indigenous status had not been recorded on the form. Indigenous Australians experience higher than average rates of imprisonment and unemployment, lower levels of education, and life expectancies for males and females that are, respectively, 11 and 17 years lower than those of non-indigenous Australians.[225][237][238] Some remote Indigenous communities have been described as having "failed state"-like conditions.[239]		In common with many other developed countries, Australia is experiencing a demographic shift towards an older population, with more retirees and fewer people of working age. In 2004, the average age of the civilian population was 38.8 years.[240] A large number of Australians (759,849 for the period 2002–03;[241] 1 million or 5% of the total population in 2005[242]) live outside their home country.		Although Australia has no official language, English has always been entrenched as the de facto national language.[2] Australian English is a major variety of the language with a distinctive accent and lexicon,[245] and differs slightly from other varieties of English in grammar and spelling.[246] General Australian serves as the standard dialect.		According to the 2016 census, English is the only language spoken in the home for close to 72.7% of the population. The next most common languages spoken at home are Mandarin (2.5%), Arabic (1.4%), Cantonese (1.2%), Vietnamese (1.2%) and Italian (1.2%).[247] A considerable proportion of first- and second-generation migrants are bilingual.		Over 250 Indigenous Australian languages are thought to have existed at the time of first European contact, of which less than 20 are still in daily use by all age groups.[248][249] About 110 others are spoken exclusively by older people.[249] At the time of the 2006 census, 52,000 Indigenous Australians, representing 12% of the Indigenous population, reported that they spoke an Indigenous language at home.[250] Australia has a sign language known as Auslan, which is the main language of about 5,500 deaf people.[251]		Australia has no state religion; Section 116 of the Australian Constitution prohibits the federal government from making any law to establish any religion, impose any religious observance, or prohibit the free exercise of any religion.[252] In the 2016 census, 52.1% of Australians were counted as Christian, including 22.6% as Roman Catholic and 13.3% as Anglican; 30.1% of the population reported having "no religion"; 7.3% identify with non-Christian religions, the largest of these being Islam (2.6%), followed by Buddhism (2.5%), Hinduism (1.9%) and Judaism (0.4%). The remaining 9.6% of the population did not provide an adequate answer. Those who reported having no religion increased conspicuously from 19% in 2006 to 30% in 2016. The largest change was between 2011 (22%) and 2016 (30.1%), when a further 2.2 million people reported having no religion.[253]		Before European settlement, the animist beliefs of Australia's indigenous people had been practised for many thousands of years. Mainland Aboriginal Australians' spirituality is known as the Dreamtime and it places a heavy emphasis on belonging to the land. The collection of stories that it contains shaped Aboriginal law and customs. Aboriginal art, story and dance continue to draw on these spiritual traditions. The spirituality and customs of Torres Strait Islanders, who inhabit the islands between Australia and New Guinea, reflected their Melanesian origins and dependence on the sea. The 1996 Australian census counted more than 7000 respondents as followers of a traditional Aboriginal religion.[254]		Since the arrival of the First Fleet of British ships in 1788, Christianity has grown to be the major religion practised in Australia. Christian churches have played an integral role in the development of education, health and welfare services in Australia. For much of Australian history the Church of England (now known as the Anglican Church of Australia) was the largest religious denomination. However, multicultural immigration has contributed to a decline in its relative position, and the Roman Catholic Church has benefitted from recent immigration to become the largest group. Similarly, Islam, Buddhism, Hinduism and Judaism have all grown in Australia over the past half-century.[255]		Australia has one of the lowest levels of religious adherence in the world.[256] In 2001, only 8.8% of Australians attended church on a weekly basis.[257]		Australia has the third and seventh highest life expectancy of males and females respectively in the world.[258] Life expectancy in Australia in 2010 was 79.5 years for males and 84.0 years for females.[259] Australia has the highest rates of skin cancer in the world,[260] while cigarette smoking is the largest preventable cause of death and disease, responsible for 7.8% of the total mortality and disease. Ranked second in preventable causes is hypertension at 7.6%, with obesity third at 7.5%.[261][262] Australia ranks 35th in the world[263] and near the top of developed nations for its proportion of obese adults [264] and nearly two thirds (63%) of its adult population is either overweight or obese.[265]		Total expenditure on health (including private sector spending) is around 9.8% of GDP.[266] Australia introduced universal health care in 1975.[267] Known as Medicare, it is now nominally funded by an income tax surcharge known as the Medicare levy, currently set at 1.5%.[268] The states manage hospitals and attached outpatient services, while the Commonwealth funds the Pharmaceutical Benefits Scheme (subsidising the costs of medicines) and general practice.[267]		School attendance, or registration for home schooling,[270] is compulsory throughout Australia. Education is the responsibility of the individual states and territories[271] so the rules vary between states, but in general children are required to attend school from the age of about 5 until about 16.[272][273] In some states (e.g., Western Australia,[274] the Northern Territory[275] and New South Wales[276][277]), children aged 16–17 are required to either attend school or participate in vocational training, such as an apprenticeship.		Australia has an adult literacy rate that was estimated to be 99% in 2003.[278] However, a 2011–12 report for the Australian Bureau of Statistics reported that Tasmania has a literacy and numeracy rate of only 50%.[279] In the Programme for International Student Assessment, Australia regularly scores among the top five of thirty major developed countries (member countries of the Organisation for Economic Co-operation and Development). Catholic education accounts for the largest non-government sector.		Australia has 37 government-funded universities and two private universities, as well as a number of other specialist institutions that provide approved courses at the higher education level.[280] The OECD places Australia among the most expensive nations to attend university.[281] There is a state-based system of vocational training, known as TAFE, and many trades conduct apprenticeships for training new tradespeople.[282] About 58% of Australians aged from 25 to 64 have vocational or tertiary qualifications,[225] and the tertiary graduation rate of 49% is the highest among OECD countries. The ratio of international to local students in tertiary education in Australia is the highest in the OECD countries.[283] In addition, 38 percent of Australia's population has a university or college degree, which is among the highest percentages in the world.[284][285]		Since 1788, the primary influence behind Australian culture has been Anglo-Celtic Western culture, with some Indigenous influences.[287][288] The divergence and evolution that has occurred in the ensuing centuries has resulted in a distinctive Australian culture.[289][290] Since the mid-20th century, American popular culture has strongly influenced Australia, particularly through television and cinema.[291] Other cultural influences come from neighbouring Asian countries, and through large-scale immigration from non-English-speaking nations.[291][292]		Indigenous Australian rock art is the oldest and richest in the world, dating as far back as 60,000 years and spread across hundreds of thousands of sites.[293] Traditional designs, patterns and stories infuse contemporary Indigenous Australian art, "the last great art movement of the 20th century";[294] its exponents include Emily Kame Kngwarreye.[295] Early colonial artists, trained in Europe, showed a fascination with the unfamiliar land.[296] The impressionistic works of Arthur Streeton, Tom Roberts and others associated with the 19th-century Heidelberg School—the first "distinctively Australian" movement in Western art—gave expression to a burgeoning Australian nationalism in the lead-up to Federation.[296] While the school remained influential into the new century, modernists such as Margaret Preston, and, later, Sidney Nolan and Arthur Boyd, explored new artistic trends.[296] The landscape remained a central subject matter for Fred Williams, Brett Whiteley and other post-World War II artists whose works, eclectic in style yet uniquely Australian, moved between the figurative and the abstract.[296][297] The national and state galleries maintain collections of local and international art.[298] Australia has one of the world's highest attendances of art galleries and museums per head of population.[299]		Australian literature grew slowly in the decades following European settlement though Indigenous oral traditions, many of which have since been recorded in writing, are much older.[301] 19th-century writers such as Henry Lawson and Banjo Paterson captured the experience of the bush using a distinctive Australian vocabulary. Their works are still popular; Paterson's bush poem "Waltzing Matilda" (1895) is regarded as Australia's unofficial national anthem.[302] Miles Franklin is the namesake of Australia's most prestigious literary prize, awarded annually to the best novel about Australian life.[303] Its first recipient, Patrick White, went on to win the Nobel Prize in Literature in 1973.[304] Australian winners of the Booker Prize include Peter Carey, Thomas Keneally and Richard Flanagan.[305] Author David Malouf, playwright David Williamson and poet Les Murray are also renowned literary figures.[306][307]		Many of Australia's performing arts companies receive funding through the federal government's Australia Council.[308] There is a symphony orchestra in each state,[309] and a national opera company, Opera Australia,[310] well known for its famous soprano Joan Sutherland.[311] At the beginning of the 20th century, Nellie Melba was one of the world's leading opera singers.[312] Ballet and dance are represented by The Australian Ballet and various state companies. Each state has a publicly funded theatre company.[313]		The Story of the Kelly Gang (1906), the world's first feature length film, spurred a boom in Australian cinema during the silent film era.[314] After World War I, Hollywood monopolised the industry,[315] and by the 1960s Australian film production had effectively ceased.[316] With the benefit of government support, the Australian New Wave of the 1970s brought provocative and successful films, many exploring themes of national identity, such as Wake in Fright and Gallipoli,[317] while "Crocodile" Dundee and the Ozploitation movement's Mad Max series became international blockbusters.[318] In a film market flooded with foreign content, Australian films delivered a 7.7% share of the local box office in 2015.[319] The AACTAs are Australia's premier film and television awards, and notable Academy Award winners from Australia include Geoffrey Rush, Nicole Kidman, Cate Blanchett and Heath Ledger.[320]		Australia has two public broadcasters (the Australian Broadcasting Corporation and the multicultural Special Broadcasting Service), three commercial television networks, several pay-TV services,[321] and numerous public, non-profit television and radio stations. Each major city has at least one daily newspaper,[321] and there are two national daily newspapers, The Australian and The Australian Financial Review.[321] In 2010, Reporters Without Borders placed Australia 18th on a list of 178 countries ranked by press freedom, behind New Zealand (8th) but ahead of the United Kingdom (19th) and United States (20th).[322] This relatively low ranking is primarily because of the limited diversity of commercial media ownership in Australia;[323] most print media are under the control of News Corporation and Fairfax Media.[324]		Most Indigenous Australian tribal groups subsisted on a simple hunter-gatherer diet of native fauna and flora, otherwise called bush tucker.[325][326] The first settlers introduced British food to the continent, much of which is now considered typical Australian food, such as the Sunday roast.[327][328] Multicultural immigration transformed Australian cuisine; post-World War II European migrants, particularly from the Mediterranean, helped to build a thriving Australian coffee culture, and the influence of Asian cultures has led to Australian variants of their staple foods, such as the Chinese-inspired dim sim and Chiko Roll.[329] Vegemite, pavlova, lamingtons and meat pies are regarded as iconic Australian foods.[330] Australian wine is produced mainly in the southern, cooler parts of the country.		Australia is also known for its cafe and coffee culture in urban centres, which has influenced coffee culture abroad, including New York City.[331] Australia and New Zealand were responsible for the flat white coffee.		About 24% of Australians over the age of 15 regularly participate in organised sporting activities.[225]		Australia is unique in that it has professional leagues for four football codes. Australian rules football, the world's oldest major football code and Australia's most popular sport in terms of revenue and spectatorship, originated in Melbourne in the late 1850s, and predominates in all states except New South Wales and Queensland, where rugby league holds sway, followed by rugby union. Soccer, while ranked fourth in popularity and resources, has the highest overall participation rates.[333]		Australia is a powerhouse in water-based sports, such as swimming and surfing.[334] The surf lifesaving movement originated in Australia, and the volunteer lifesaver is one of the country's icons.[335] Nationally, other popular sports include horse racing, basketball, and motor racing. The annual Melbourne Cup horse race and the Sydney to Hobart yacht race attract intense interest.[336] In 2016, the Australian Sports Commission revealed that swimming, cycling and soccer are the three most popular participation sports.[337][338]		Australia is one of five nations to have participated in every Summer Olympics of the modern era,[339] and has hosted the Games twice: 1956 in Melbourne and 2000 in Sydney.[340] Australia has also participated in every Commonwealth Games,[341] hosting the event in 1938, 1962, 1982, 2006 and will host the 2018 Commonwealth Games.[342] Australia made its inaugural appearance at the Pacific Games in 2015. As well as being a regular FIFA World Cup participant, Australia has won the OFC Nations Cup four times and the AFC Asian Cup once – the only country to have won championships in two different FIFA confederations.[343] The country regularly competes among the world elite basketball teams as it is among the global top three teams in terms of qualifications to the Basketball Tournament at the Summer Olympics. Other major international events held in Australia include the Australian Open tennis grand slam tournament, international cricket matches, and the Australian Formula One Grand Prix. The highest-rating television programs include sports telecasts such as the Summer Olympics, FIFA World Cup, The Ashes, Rugby League State of Origin, and the grand finals of the National Rugby League and Australian Football League.[344] Skiing in Australia began in the 1860s and snow sports take place in the Australian Alps and parts of Tasmania.		Click on a coloured area to see an article about English in that country or region		
Hong Kong has a long coastline that is full of twists and turns with many bays and beaches. Many of them are well sheltered by mountains nearby, as Hong Kong is a mountainous place. As a result, large waves seldom appear at the bays, making them suitable for human swimming.		However, with the increasing development and urbanisation of Hong Kong, water quality has worsened resulting in the closure of several beaches previously suitable for swimming. These include Approach Beach, Ting Kau Beach, Anglers' Beach, Gemini Beaches, Hoi Mei Wan Beach, Casam Beach and Lido Beach in Tsuen Wan. In 2011, Lido Beach, Casam Beach, Approach Beach and Hoi Mei Wan Beach were reopened following an improvement in water quality.[1]		About half of the beaches suitable for swimming in Hong Kong are managed by the Leisure and Cultural Services Department (LCSD), and are officially referred to as gazetted beaches. A number of other beaches are privately owned or not gazetted, but are nonetheless publicly accessible.						A total of forty-one beaches in Hong Kong are managed by the LCSD. Twelve of them are located on Hong Kong Island, and the remaining 29 are located across the New Territories, including the Outlying Islands. Some are temporarily closed to swimmers.		1. Butterfly Beach (蝴蝶灣泳灘) 2. Castle Peak Beach (青山灣泳灘) 3. Kadoorie Beach (加多利灣泳灘) 4. Cafeteria Old Beach (舊咖啡灣泳灘) 5. Cafeteria New Beach (新咖啡灣泳灘) 6. Golden Beach (黃金泳灘)		7. Anglers' Beach (釣魚灣泳灘) 8. Gemini Beaches (雙仙灣泳灘) 9. Hoi Mei Wan Beach (海美灣泳灘) 10. Casam Beach (更生灣泳灘) 11. Lido Beach (麗都灣泳灘) 12. Ting Kau Beach (汀九灣泳灘) 13. Approach Beach (近水灣泳灘) 14. Ma Wan Tung Wan Beach (馬灣東灣泳灘)		15. Trio Beach (三星灣泳灘) 16. Kiu Tsui Beach (橋咀泳灘) 17. Hap Mun Bay Beach (廈門灣泳灘) 18. Silverstrand Beach (銀線灣泳灘) 19. Clear Water Bay First Beach (清水灣第一灣泳灘) 20. Clear Water Bay Second Beach (清水灣第二灣泳灘)		21. Deep Water Bay Beach (深水灣泳灘) 22. Repulse Bay (淺水灣泳灘) 23. Middle Bay Beach (中灣泳灘) 24. South Bay Beach (南灣泳灘) 25. Chung Hom Kok Beach (舂坎角泳灘) 26. St. Stephen's Beach (聖士提反灣泳灘) 27. Stanley Main Beach (赤柱正灘泳灘) 28. Hairpin Beach (夏萍灣泳灘) 29. Turtle Cove Beach (龜背灣泳灘) 30. Shek O Beach (石澳泳灘) 31. Rocky Bay Beach 32. Big Wave Bay Beach (大浪湾泳滩)		33. Hung Shing Yeh Beach (洪聖爺灣泳灘) 34. Lo So Sing Beach (蘆鬚城泳灘)		35. Kwun Yam Beach (觀音灣泳灘) 36. Cheung Chau Tung Wan Beach (長洲東灣泳灘)		37. Silvermine Bay Beach (銀鑛灣泳灘) 38. Pui O Beach (貝澳泳灘) 39. Upper Cheung Sha Beach (上長沙泳灘) 40. Lower Cheung Sha Beach (下長沙泳灘) 41. Tong Fuk Beach (塘福泳灘)		Kadoorie Beach (加多利灣泳灘) is located at 18¾ milestone, Castle Peak Road. The enquires of the beach are 2450 6336 and 2451 3461. There are BBQ area, changing rooms, shower facilities and toilet. Lifeguard service hours are 0900–1800 in April to May, September to October, and also on Mondays to Fridays in June to August. On Saturdays, Sundays and public holidays in June to August, lifeguard service hours are 0800–1900. Lifeguard services are suspended during winter(November to March).		Cafeteria Old Beach (舊咖啡灣泳灘) is located at 18¾ milestone, Castle Peak Road. The enquires of the beach are 2450 6306 and 2451 3461. There are refreshment kiosk, BBQ area, changing room,shower facilities, toilet and bathing shed. Lifeguard service hours are 0900–1800 in April to May, September to October, and also on Mondays to Fridays in June to August. On Saturdays, Sundays and public holidays in June to August, lifeguard service hours are 0800–1900. Lifeguard services are suspended during winter(November to March).		Cafeteria New Beach (新咖啡灣泳灘) is located at 18½ milestone, Castle Peak Road. The enquires of the beach are 2450 6440 and 2451 3461. There are refreshment kiosk and beach volleyball court. Lifeguard service hours are 0900–1800 in April to May, September to October, and also on Mondays to Fridays in June to August. On Saturdays, Sundays and public holidays in June to August, lifeguard service hours are 0800–1900. Lifeguard services are suspended during winter(November to March).		Golden Beach (黃金泳灘) is located at the 18½ milestone of Castle Peak Road, Tuen Mun. It is the largest beach in Tuen Mun with a total area of 78,500 m² and a length of 545 metres. It is the first artificial beach in Hong Kong. It is classified as a Grade 2 beach, meaning that the water quality is fair. Refreshment kiosks, a hotel and a shopping mall are to be found adjacent to the beach.		Golden Beach is unique amongst the beaches of Hong Kong in that it has a volleyball court. The Hong Kong Beach Volleyball Team occasionally practises on Golden Beach.		Golden Beach is served by KMB bus routes 52x (Tuen Mun Central Bus Terminus ↔ Mongkok), 53 (Yuen Long ↔ Tsuen Wan) and 61M (Tuen Mun Central Bus Terminus ↔ Kwai Fong); by Citybus bus routes 962/N962 (Lung Mun Oasis ↔ Causeway Bay), 962B (Chi Lok Fa Yuen ↔ Admiralty) and 962S (Chi Lok Fa Yuen ↔ Causeway Bay); by MTR Bus feeder bus routes K51 (Fu Tai ↔ Tai Lam) and K53 (Tuen Mun Station ↺ So Kwun Wat).		Ma Wan Tung Wan Beach (馬灣東灣泳灘) is located on Ma Wan island.		Deep Water Bay Beach (深水灣) is located on southern Hong Kong Island. See Deep Water Bay.		Repulse Bay Beach (淺水灣泳灘), traditionally Hong Kong's most popular because of its easy access by bus and extensive facilities, is located on southern Hong Kong Island. See Repulse Bay.		These two small beaches at South Bay and Middle Bay are located within walking distance of Repulse Bay Beach. However, since they are not directly accessible by public transport, they tend to be quieter and less crowded than Repulse Bay.		The beach situated east of Stanley and west of Tai Tam Reservoir is Turtle Cove Beach (龜背灣泳灘) which is a Grade 1 beach. Being less than 70 meters long, it can easily be considered[by whom?] as a "baby beach". Turtle Cove is very well equipped; with changing rooms, toilets and showers as well as a small playground, a soft drinks kiosk and seven barbecue pits.		Turtle Cove Beach is accessible by bus No.14 from exit A of the Sai Wan Ho MTR station or mini-bus 16X from Chai Wan; the beach is located near the Red Hill estate stop (past the Tai Tam Reservoir). From near the bus stop, stairs lead down the hill to the beach.		Big Wave Bay Beach (大浪灣泳灘) in Southern District is also the site of prehistoric rock carvings similar to those found on Cheung Chau Island.[2] Not to be confused with other places called Big Wave Bay or Tai Long Wan in Hong Kong.		Hung Shing Yeh Beach (洪聖爺灣泳灘) is the most popular beach on Lamma Island. The sand on the beach is very fine, like powder. The water of the Beach is clean and it is classified as a Grade 1 beach.		Near the beach, there is a barbecue area, refreshment kiosk, and shower and changing facilities.		There is no public transport on Lamma Island. To reach the beach one must travel to Yung Shue Wan from Central by ferry, and then walk for about 20 minutes. The route is signposted.		Lo So Shing Beach (盧鬚城泳灘) is located on Lamma Island about halfway between the main villages of Yung Shue Wan and Sok Kwu Wan. The water of the beach is clean and it is classified as a Grade 1 beach. Some years ago the government of Hong Kong built shower and refreshment facilities there, which remain almost unused because of the beach's remote location and the absence of public transport.		To reach the beach one must travel to Yung Shue Wan or Sok Kwu Wan from Central by ferry, and then walk for about 40 minutes.		There are two main beaches on Cheung Chau: Cheung Chau Tung Wan Beach (長洲東灣泳灘) and Kwun Yam Beach (觀音灣) aka. Afternoon Beach. Although they are not as big as the well-known beaches along the Hong Kong Island coast, they do have their own qualities. Kwun Yam Beach is a beautiful fine white beach situated on the east coast of Cheung Chau. The water quality is good and it is classified as a Grade 1 beach. It provides many water sports facilities, particularly for sailboarding. Many lovers like to take leisurely walks there and to enjoy the village scene which still keeps the old traditions. Also, it is the place where Hong Kong's first Olympic medallist, Lee Lai Shan, practised when she was young. A formal monument to her achievement is erected in the children's playground on Tung Wan Beach, while an unofficial monument is to be found beside the "windsurfer" café owned by her uncle, which is situated between the two beaches.		Hong Kong's largest island, Lantau, has several beaches which are clean, uncrowded and relatively convenient to reach. For all of them, the first step is to simply take the ferry from Central to Mui Wo. Then, if necessary, one can just hop on a bus.		Silvermine Bay Beach (銀鑛灣泳灘), which is a Grade 1 beach, is the easiest one to get to, since it is located about a 5-minute walk away from the Mui Wo ferry pier. Since there is a sandbar area, this beach is ideal for flinging frisbees or flying kites. Further along the beach is a swimming area with several lifeguards on duty. Many visitors rent a bike for the afternoon, and stop off at the many refreshment kiosks and little restaurants along the road fronting the beach. If people do not feel like hurrying back into the city, they can also choose to stay overnight at the Silvermine Beach Hotel, located right on the waterfront. Also, there are several other hotels and guesthouses in the area where people can stay.		Cheung Sha Beach is located in Cheung Sha, on the southern shore of Lantau Island. It is divided into two parts by a small headland: Upper Cheung Sha Beach (east) and Lower Cheung Sha Beach (west). It is 3 km long and is one of the longest beaches in Hong Kong.[3] The beaches are accessible from South Lantau Road.[4] Tong Fuk Beach is located nearby, to the west of Lower Cheung Sha Beach.		Many of these beaches are difficult to reach. Because they are not maintained by the government, some may be unclean at times. As no lifeguards are on duty, swimmers are recommended to exercise caution. Non-gazetted beaches are also not equipped with shark nets.		Gazetted beaches in Hong Kong are classified into four grades ( Grades 1 – 4 ) according to the level of E. coli in the water of the beaches. This is done by the Environmental Protection Department. Every week, water samples of each beach are collected for analysis to find out their bacterial level.		Grade 1 means that the water qualities of the beaches are good. The amount of E. coli is no more than 24 counts per 100 mL of beach water. Also no related case of skin and gastrointestinal illnesses has been reported by swimmers who have swum at these beaches.		Grade 2 means that the water qualities of the beaches are fair. The amount of E. coli is about 25 – 180 counts per 100 mL of beach water. Also the rate of skin and gastrointestinal illnesses is no more than 10 cases per 1000 swimmers.		Grade 3 means that the water qualities of the beaches are poor. The amount of E. coli is about 181 – 610 counts per 100 mL of beach water. Also the rate of skin and gastrointestinal illnesses is about 11 – 15 cases per 1000 swimmers.		Grade 4 means that the water quality is very poor. The amount of E. coli is greater than 610 counts per 100 mL of beach water. Also the rate of skin and gastrointestinal illnesses is greater than 15 cases per 1000 swimmers. As a result, swimmers are advised not to swim at Grade 4 beaches.		
The fetch, also called the fetch length, is the length of water over which a given wind has blown. Fetch is used in geography and meteorology and its effects are usually associated with sea state and when it reaches shore it is the main factor that creates storm surge which leads to coastal erosion and flooding. It also plays a large part in longshore drift as well.		Fetch length, along with the wind speed (wind strength), determines the size (sea state) of waves produced. The wind direction is considered constant. The longer the fetch and the faster the wind speed, the more wind energy is imparted to the water surface and the larger the resulting sea state will be.		
A cove is a small type of bay or coastal inlet. Coves usually have narrow, restricted entrances, are often circular or oval, and are often situated within a larger bay. Small, narrow, sheltered bays, inlets, creeks, or recesses in a coast are often considered coves. Colloquially, the term can be used to describe a sheltered bay.		Geomorphology describes coves as precipitously-walled and rounded cirque-like openings as in a valley extending into or down a mountainside, or in a hollow or nook of a cliff or steep mountainside.		Coves are formed by differential erosion, which occurs when softer rocks are worn away faster than the harder rocks surrounding them. These rocks further erode to form a circular bay with a narrow entrance, called a cove.		A notable example is Lulworth Cove on the Jurassic Coast in Dorset, England. To its west, a second cove, Stair Hole, is forming.				
An isthmus ( /ˈɪsθməs/ or /ˈɪsməs/;[1] plural: isthmuses; from Ancient Greek: ἰσθμός isthmos "neck"[2]) is a narrow piece of land connecting two larger areas across an expanse of water that otherwise separates them.[3] A tombolo is an isthmus that consists of a spit or bar, and a strait is the sea counterpart of an isthmus.		Canals are often built across isthmuses, where they may be a particularly advantageous short cut for marine transport. For example, the Panama Canal crosses the Isthmus of Panama, connecting the North Atlantic and Pacific Oceans; the Suez Canal connects the Mediterranean Sea and the Red Sea, cutting across the western side of the Isthmus of Suez, formed by the Sinai Peninsula; and the Crinan Canal crosses the isthmus between Loch Crinan and Loch Gilp, which connects the Kintyre peninsula with the rest of Scotland. Another example is the Welland Canal in the Niagara Peninsula (Technically an isthmus). It connects Lake Ontario to Lake Erie.		
The continental margin is one of the three major zones of the ocean floor, the other two being deep-ocean basins, and mid-ocean ridges. The continental margin is the shallow water area found in proximity to continent. [1]   The continental margin consists of three different features: the continental rise, the continental slope, and the continental shelf.[2] Continental margins constitute about 28% of the oceanic area.[1] 		The continental shelf is the portion of the continental margin that transitions from the shore out towards to ocean. They are believed to make up 7 percent of the sea floor.[3] The width of continental shelves worldwide varies from a 30 meters to 1500 kilometers.[4] It is generally flat, and ends at the shelf break, where there is a drastic increase in slope angle. The mean slope of continental shelves worldwide is 0° 07’ degrees, and typically steeper closer to the coastline than it is near the shelf break.[5] At the shelf break begins the continental slope, which can be one to five kilometers above the deep-ocean floor. The continental slope often exhibits features called submarine canyons.[4] Submarine canyons often cut into the continental shelves deeply, with near vertical slopes, and continue to cut the morphology to the abyssal plain.[5] The valleys are often V-shaped, and can sometime enlarge onto the continental shelf. At the base of the continental slope, there is a sudden decrease in slope, and the sea floor begins to level out towards the abyssal plain. This portion of the seafloor is called the continental rise, and marks the end of the continental margin.[2]						There are two types of continental margins: active and passive margins.[2]		Active margins are typically associated with lithospheric plate boundaries. These active margins can be convergent or transform margins, and are also places of high tectonic activity, including volcanoes and earthquakes. The West Coast of North America and South America is considered an active margin.[4] Active continental margins are typically narrow from coast to shelf break, with steep descents into trenches.[4] Convergent active margins occur where oceanic plates meet continental plates. The denser oceanic plate subducts below the less dense continental plate. Convergent active margins are the most common type of active margin. Transform active margins are more rare, and occur when an oceanic plate and a continental plate are moving parallel to each other in opposite directions. These transform margins are often characterized by many offshore faults, which causes high degree of relief offshore, marked by islands, shallow banks, and deep basins. This is known as the continental borderland.[2]		Passive margins are often located in the interior of lithospheric plates, away from the plate boundaries, and lack major tectonic activity. They often face mid-ocean ridges.[3] The East Coast of the United States is an example of a passive margin. These margins are much wider and less sloped than active margins.		As continental crust weathers and erodes, it degrades into mainly sands and clays. Many of these particles end up in streams and rivers that then dump into the ocean. Of all the sediment in the stream load, 80% is then trapped and dispersed on continental margins.[3] While modern river sediment is often still preserved closer to shore, continental shelves show high levels of glacial and relict sediments, deposited when sea level was lower.[3] Often found on passive margins are several kilometers of sediment, consisting of terrigenous and carbonate (biogenous) deposits.These sediment reservoirs are often useful in the study of paleoceanography and the original formation of ocean basins.[3] These deposits are often not well preserved on active margin shelves due to tectonic activity.[4]		Economically, the continental shelf is the most economically valuable part of the ocean. It often is the most productive portion of the continental margin, as well as the most studied portion, due to its relatively shallow, accessible depths.[4]		Due to the rise of offshore drilling, mining and the limitations of fisheries off the continental shelf, the United Nations Convention on “Law of the Sea” was established. The edge of the continental margin is one criterion for the boundary of the internationally recognized claims to underwater resources by countries in the definition of the "continental shelf" by the United Nations Convention on the Law of the Sea (although in the UN definition the "legal continental shelf" may extend beyond the geomorphological continental shelf and vice versa).[1] Such resources include fishing grounds, oil and gas accumulations, sand, gravel, and some heavy minerals in the shallower areas of the margin. Metallic minerals resources are thought to also be associated with certain active margins, and of great value. [3]		
An island or isle is any piece of sub-continental land that is surrounded by water.[2] Very small islands such as emergent land features on atolls can be called islets, skerries, cays or keys. An island in a river or a lake island may be called an eyot or ait, and a small island off the coast may be called a holm. A grouping of geographically or geologically related islands is called an archipelago, e.g. the Philippines.		An island may be described as such, despite the presence of an artificial land bridge; examples are Singapore and its causeway, and the various Dutch delta islands, such as IJsselmonde. Some places may even retain "island" in their names for historical reasons after being connected to a larger landmass by a land bridge or landfill, such as Coney Island and Coronado Island, though these are strictly tied islands. Conversely, when a piece of land is separated from the mainland by a man-made canal, for example the Peloponnese by the Corinth Canal or Marble Hill in northern Manhattan during the time between the building of the United States Ship Canal and the filling-in of the Harlem River which surrounded the area, it is generally not considered an island.		There are two main types of islands in the sea: continental and oceanic. There are also artificial islands.						The word island derives from Middle English iland, from Old English igland (from ig or ieg, similarly meaning 'island' when used independently, and -land carrying its contemporary meaning; cf. Dutch eiland ("island"), German Eiland ("small island")). However, the spelling of the word was modified in the 15th century because of a false etymology caused by an incorrect association with the etymologically unrelated Old French loanword isle, which itself comes from the Latin word insula.[3] Old English ieg is actually a cognate of Swedish ö and German Aue, and related to Latin aqua (water).[4]		Greenland is the world's largest island, with an area of over 2.1 million km², while Australia, the world's smallest continent, has an area of 7.6 million km², but there is no standard of size which distinguishes islands from continents,[5] or from islets.[6] There is a difference between islands and continents in terms of geology. Continents sit on continental lithosphere which is part of tectonic plates floating high on Earth's mantle. Oceanic crust is also part of tectonic plates, but it is denser than continental lithosphere, so it floats low on the mantle. Islands are either extensions of the oceanic crust (e.g. volcanic islands) or geologically they are part of some continent sitting on continental lithosphere (e.g. Greenland). This holds true for Australia, which sits on its own continental lithosphere and tectonic plate.		Continental islands are bodies of land that lie on the continental shelf of a continent.[7] Examples are Borneo, Java, Sumatra, Sakhalin, Taiwan and Hainan off Asia; New Guinea, Tasmania, and Kangaroo Island off Australia; Great Britain, Ireland, and Sicily off Europe; Greenland, Newfoundland, Long Island, and Sable Island off North America; and Barbados, Falklands and Trinidad off South America.		A special type of continental island is the microcontinental island, which is created when a continent is rifted. Examples are Madagascar and Socotra off Africa, the Kerguelen Islands, New Caledonia, New Zealand, and some of the Seychelles.		Another subtype is an island or bar formed by deposition of tiny rocks where water current loses some of its carrying capacity. This includes:		Islets are very small islands.		Oceanic islands are islands that do not sit on continental shelves. The vast majority are volcanic in origin, such as Saint Helena in the South Atlantic Ocean.[8] The few oceanic islands that are not volcanic are tectonic in origin and arise where plate movements have lifted up the ocean floor above the surface. Examples are Saint Peter and Paul Rocks in the Atlantic Ocean and Macquarie Island in the Pacific.		One type of volcanic oceanic island is found in a volcanic island arc. These islands arise from volcanoes where the subduction of one plate under another is occurring. Examples are the Aleutian Islands, the Mariana Islands, and most of Tonga in the Pacific Ocean. The only examples in the Atlantic Ocean are some of the Lesser Antilles and the South Sandwich Islands.		Another type of volcanic oceanic island occurs where an oceanic rift reaches the surface. There are two examples: Iceland, which is the world's second largest volcanic island, and Jan Mayen. Both are in the Atlantic.		A third type of volcanic oceanic island is formed over volcanic hotspots. A hotspot is more or less stationary relative to the moving tectonic plate above it, so a chain of islands results as the plate drifts. Over long periods of time, this type of island is eventually "drowned" by isostatic adjustment and eroded, becoming a seamount. Plate movement across a hot-spot produces a line of islands oriented in the direction of the plate movement. An example is the Hawaiian Islands, from Hawaii to Kure, which continue beneath the sea surface in a more northerly direction as the Emperor Seamounts. Another chain with similar orientation is the Tuamotu Archipelago; its older, northerly trend is the Line Islands. The southernmost chain is the Austral Islands, with its northerly trending part the atolls in the nation of Tuvalu. Tristan da Cunha is an example of a hotspot volcano in the Atlantic Ocean. Another hot spot in the Atlantic is the island of Surtsey, which was formed in 1963.		An atoll is an island formed from a coral reef that has grown on an eroded and submerged volcanic island. The reef rises to the surface of the water and forms a new island. Atolls are typically ring-shaped with a central lagoon. Examples are the Line Islands in the Pacific and the Maldives in the Indian Ocean.		Approximately 45,000 tropical islands with an area of at least 5 hectares (12 acres) exist.[9] Examples formed from coral reefs include Maldives, Tonga, Samoa, Nauru, and Polynesia.[9] Granite islands include Seychelles and Tioman and volcanic islands such as Saint Helena.		The socio-economic diversity of tropical islands ranges from the Stone Age societies in the interior of Madagascar, Borneo, and Papua New Guinea to the high-tech lifestyles of the city-islands of Singapore and Hong Kong.[10]		International tourism is a significant factor in the economy of many tropical islands including Seychelles, Sri Lanka, Mauritius, Réunion, Hawaii, and the Maldives.		Almost all of the Earth's islands are natural and have been formed by tectonic forces or volcanic eruptions. However, artificial (man-made) islands also exist, such as the island in Osaka Bay off the Japanese island of Honshu, on which Kansai International Airport is located. Artificial islands can be built using natural materials (e.g., earth, rock, or sand) or artificial ones (e.g., concrete slabs or recycled waste).[11][12] Sometimes natural islands are artificially enlarged, such as Vasilyevsky Island in the Russian city of St. Petersburg, which had its western shore extended westward by some 0.5 km in the construction of the Passenger Port of St. Petersburg.[13]		Notes		
Sea foam, ocean foam, beach foam, or spume is a type of foam created by the agitation of seawater, particularly when it contains higher concentrations of dissolved organic matter (including proteins, lignins, and lipids)[1] derived from sources such as the offshore breakdown of algal blooms. These compounds can act as surfactants or foaming agents. As the seawater is churned by breaking waves in the surf zone adjacent to the shore, the presence of these surfactants under these turbulent conditions traps air, forming persistent bubbles that stick to each other through surface tension. Due to its low density and persistence, foam can be blown by strong on-shore winds from the beachface inland.						Where polluted stormwater from rivers or drains discharges to the coast, sea foam formed on adjacent beaches can be polluted with viruses and other contaminants,[2][3] and may have an unpleasant odour.[4]		If crude oil discharged from tankers at sea, or motor oil, sewage and detergents from polluted stormwater are present, the resulting sea foam is even more persistent, and can have a chocolate mousse texture.[3]		If the foam forms from the breakdown of a harmful algal bloom (including those caused by some dinoflagellates and cyanobacteria), direct contact with the foam, or inhalation of aerosols derived from the foam as it dries, can cause skin irritations or respiratory discomfort.[1]		On rare occasions large amounts of sea foam up to several metres thick can accumulate at the coast and constitute a physical hazard to beach users, through concealing large rocks and voids, storm debris and, in northern New South Wales, there are even anecdotes of sea snakes.[2]		
Othonoi or Othoni (Greek: Οθωνοί, Italian: Fanò or Othoni) is a Greek island and the westernmost point of Greece. It is a former community of the Ionian Islands. Since the 2011 local government reform it is part of the municipality of Corfu, of which it is a municipal unit.[3] The municipal unit has an area of 10.078 km2.[4] It is located northwest of Corfu. Population 392 (2011). It is the biggest of the Diapontia Islands and it is divided into two regions (Ano Panta - Kato Panta). In the 19th century the island was the capital of the Diapontia Islands municipality, which also included nearby islands of Ereikoussa, Mathraki, islets and rocks of Diakopo, Diaplo, Karavi, Kastrino, Leipso, Ostrako, Plaka, Plateia and Tracheia. Othoni is about 47 n.miles from Santa Maria di Leuca cape, Italy.[5][6]						The first name according to ancient texts (Hesychius, 3rd cent. BC) was "Othronos" (Οθρονός), "Othronoi" (Οθρωνοί) and by Procopius seams to be "Othoni" (Οθωνή) (6th c.). According to Pliny (1st cent.) was "Thoronos" (Θόρονος). Other names were "Fidonisi" (Snake island) because of the many snakes that are said to have invaded the island, and "Fano" (Lamp) which is used in international charters and by the Italians because of the lighthouse that it is on the island. There are also views that came from the word "screen" (Greek:Οθόνη) as "Othones" seems that the local seamen call the sails of their sailing boats.[7]		At the beginning of the second millennium, the island was conquered alternatively by the Franks (the 11th century) and the Venetians (12th century), and often attacked by pirates of Barbary and Algeria. From the end of 1383 until 1386 the domination of Corfu brought by Charles III of Naples. In his letter he stated that on April 19, 1383 granted the usufruct of Othoni Ereikoussa, Mathraki, Diapolo and Vido, the knight Theodore Skaliti as fief.[8] In 1537, the Turkish fleet under the command of Greek origin pirate and admiral Hayreddin Barbarossa massacred the inhabitants of Othoni island after a long battle. In Stavros district at an altitude of 217 m. a white stone cross exists until today to commemorate that event.[9]		The last settlers of Othoni apparently came from Paxos and Ioannina, Parga and the region of Epirus. Dated after the Battle of Nafpaktos in 1571,when the Turkish fleet was destroyed and the islanders began to move more safely. After the last movement, the residents of Othoni island colonized the two other small islands, Ereikoussa and Mathraki.[10] In 1815, the English conquered Othonoi and as is said, sent to the island sick soldiers to recover because of the good climate that prevailed. The Treaty signed on March 29, 1864 between the three powers (England, France, Russia) and the Kingdom of Greece, the Ionian Islands -and Diapontia islands- passed definitively to Greek sovereignty on 21 May. On October 5, 1864, the Ionian Parliament realized the purpose of the convocation solemnly acting union with Greece one and indivisible state under the king, George I of Greece.[11] From 1869 until 1912 Othoni, Ereikousa and Mathraki formed the municipality of Dimos Diapontion with Othoni as capital.[12]		Othoni have achieved big naval and maritime history as men crowd the island and the surrounding islands were involved in shipping (1880-1990). It is significant that there is no family without a sailor. Also, many Othoniotes were senior crews in war ships. Main maritime occupations was sailor, boatswain, master or engineer of any class etc. A lot of Othoniotes were ship owners as they had a large number of yachts and commercial steamships traveling to many Mediterranean ports.[13] Unfortunately, within these decades of history that wrote Othoniotes at sea, there were some victims because of several wrecks due to sloppiness and carelessness of those responsible in the last century.[14][15]		On 29 December 1940, the Greek submarine Protefs sank in the sea area of Othonoi. The submarine had attacked an Italian convoy carrying ammunition to Vlorë. After sinking the steamer Sardegna, the submarine was rammed by the Italian torpedo boat Antares. The loss of the submarine was the first loss of the Greek Navy in World War II. A monument to honor the memory of the crew, was inaugurated in Othonoi on June 15, 2015. [16]		According to a legend, in the ancient times it was the island of nymph Calypso, who lived in a large cave. Odysseus fell in love and remained like a prisoner there for seven years. Homer called thιs island Ogygia. Due to his scriptures there was a strong scent of cypress on Ogygia island. Othonoi is a place with many of these trees. Odysseus left the island by a raft and he sank on Scheria the island of Corfu . This is an extra element that justifies the legend of Othonoi being Ogygia, because of the short distance that separates the two islands.[17] According to Hesychius, after the Trojan War, Elephenor, king of Avantes from Euboea fled to the island after the fall of Troy, to atone as he had killed his grandfather, Abas.[18]		Most Othoniotes (local dialect: Thoniotes) have migrated to Corfu, Athens and abroad (especially to the USA) because of the unemployment and few exploitable resources (1900-1960).The main work was the olive and oil production. Most men of that time were involved in nautical professions (sailor, bosun, carpenter, captain, skipper etc.) and worked on commercial and war ships which were operating in every part of earth. Main occupation of current residents is tourism, fishing and olive production. Previously there has been significant cultivation of vines, the beekeeping and livestock.[19]		Othoni is divided into two regions which are Ano Panta (Greek: Άνω πάντα) and Kato Panta (Greek: Κάτω πάντα). There are more than 20.[20]		Most beaches on the island are accessible by boat, including Ammos, Molos, Kamini, Kanoula, Kontoskes, Rogi, Fyki, Xilosermi, and Aspri Ammos. It is a well known island for underwater photography because of the peculiar geomorphology of the seabed and the many caves. Other points of interest are the Moshopontikas, Xylosermi, Fyki bay (where there is the sunken wreck of Sarah ship). Othoni was frequently visited by the French naturalist Jacques Cousteau and his exploratory vessel Calypso.[23]		The traditional trail was created and used by the first inhabitants, and was subsequently reopened by the municipality and private initiatives. Locals and visitors can use the trail to reach almost every neighborhood and part of the island on foot, as well as Mount Imerovigli (Merovigli), and the highest peak of the island, with a height of over 390 metres (1,280 ft), with views of the other Diapontia Islands, Ionian sea and Adriatic sea.[24]		The island is almost completely covered by trees which produce a small species of olive, the "Elea the cherry" (Olea microcarpa), commonly Lianolia or ladoelia, with a high content of high quality oil, which is common in all the Ionian Islands. It was densely planted during Venetian rule, so most are aged 300–400 years exceeding a height of 7 metres (23 ft). There are cypresses and fruit trees on almost all mountain slopes. The tall mulberry (or Skamnia) and fig (or Skeria) are found in nearly all districts and gardens that host many species of fruit and vegetables, and features large cabbage called by Othoniotes cramps, as in Cyprus. Most houses have, instead of tents or sheds, pergolas with vines or pergoulies. Oregano, sage and many other herbs.[25]		Othoni is the first migratory bird station in southeastern Europe from Libya, especially for turtle doves. There are also grouse and snipe (xilokotes) during the winter months, and Petritis falcons, the European bee-eater birds, martins, ravens and several species of eagles. There are several hares and rabbits. The most common species of reptile is the viper (Vipera ammodytes or astritis). Marine mammals have been observed off the island's coast, including the bottlenose dolphin, at least three species of sharks (including white shark), while sporadically near the cave of Calypso there have been monk seals. also found almost all varieties of marine fauna, such as the white sea bream, red mullet, the snapper, the grouper, the bumpkin (weighing up to 30 pounds), octopus, moray, the stingray, lobster. Remarkable is the presence of barnacles and sea urchins. Zooplankton is in small coves of the island and especially in seaweed is abundant at night, and when the sea is calm, the plankton illuminates the sea bed.[26]		The climate of Othoni is mild, and generally warm and temperate. The winters are rainier than the summers in Othoni. The Köppen-Geiger climate classification is Csa. The average temperature in Othoni is 16.7 °C. About 1026 mm of precipitation falls annually.		A dialect is spoken resembling that of Corfu and having a similar prosody. It is heavily influenced by Italian.		The island is accessible by boat with regular services from Corfu port and Agios Stefanos Avliotes. There is a port in Avlakia district (with fishing port), for several small private yachts and boats.The island has a heliport for emergencies. Asphalt roads are available on many parts of the island, about 12 kilometres (7.5 mi) of which are extended to settlements. There is complete electrification and a telephone network with Internet access.		Alexandros Mastoras, mayor of Corfu city (2003-2004)[27] [28]		Othoni's lighthouse		Koukouli rock		Sunset, Chorio		Ammos port		Virgin Mary orthodox church		Aspri ammos beach		Ztrila square, Chorio		One of the old stone bridges of Othoni		Ammos district		Old mill, Damaskatika district		Saint George, Chorio		Trail sign		
A cliffed coast, also called an abrasion coast, is a form of coast where the action of marine waves has formed steep cliffs that may or may not be precipitous. It contrasts with a flat or alluvial coast.						In coastal areas in which the land surface dips at a relatively steep angle below the water table, the continuous action of marine waves on the coastline, known as abrasion, may create a steep declivity known as a cliff, the slope angle of which depends on a variety of factors including the jointing, bedding and hardness of the materials making up the cliff as well as the erosional processes themselves.[1][2] The slope is constantly being eroded. The waves attacking the cliff-foot form a wave-cut notch by constant abrasion action producing an overhang. This overhang grows in size as the cliff is undercut, until it collapses under its own weight. The loose debris that has broken off is gradually carried away from the area in front of the cliff by the action of the sea. As the coastal cliffs collapse, the shoreline recedes inland. The speed at which this happens depends, in particular, on the strength of the surf, the height of the cliff, the frequency of storm surges and the hardness of the bedrock. Thus, the Mecklenburg coast in Germany recedes by about 25 centimetres per year, whereas the chalk cliffs of southern England retreat by just ½ a centimetre each year. A cliffed coast is made of a loose bedrock material, such as at the Red Cliff on the German island of Sylt, but can also occur in hard rock like the red sandstone cliffs on Heligoland. There are, however, differences between the former and the latter regarding some peculiarities of the coast line.		On a rocky cliffed coast made up of material which is relatively resistant to erosion such as sandstone, limestone or granite, a flat rocky wave-cut platform or abrasion platform is formed in front of the cliff. It represents the foot of the cliff preserved at and below the level of water table. If there is a tectonic uplift of the coast, these abrasion platforms can be raised to form coastal terraces, from which the amount of uplift can be calculated from their elevation relative to the sea level, taking into account any eustatic sea level changes. On a cliffed coast made up of material which is only fairly or even hardly resistant to erosion no wave-cut platform but a beach is formed in front of the sea cliff.		If waves carve notches at a narrow point on both sides of a promontory on the rocky cliffed coast, a natural arch may be formed.[3] When the arch collapses as the coastline recedes further a stack is left behind on the wave-cut platform. The best-known example in Germany is the Lange Anna on Heligoland.		Furthermore, on a rocky cliffed coast wave action is not the only driving force for coastline retreat. General weathering of the bedrock is almost equally important.[2]		"Living cliffs" are those on a coast that is still active, i.e. that is being eroded and is receding. A "dead cliff", by contrast, is only reached by very high marine waves and is therefore subjected to very little change. A clear indication of a lack of activity at a dead cliff is a covering of vegetation that appears on the cliff as wave action against it subsides.		Well-known coasts with living cliffs in Germany are the Red Cliff (Rote Kliff) in Kampen on the island of Sylt or the chalk cliffs on the Jasmund Peninsula. The Königsstuhl on the island of Rügen is a good example of a dead cliff. Others may be found in the regions of the present-day Wadden Sea coast of the North Sea a few kilometres inland. These show the former coastline from which the sea retreated as the level of water in the North Sea fell.		Steep sea cliffs can also be caused by catastrophic debris avalanches. These have been common on the submerged flanks of ocean island volcanos such as the Hawaiian Islands and the Cape Verde Islands.[4][5]		
Victoria (Alexandrina Victoria; 24 May 1819 – 22 January 1901) was Queen of the United Kingdom of Great Britain and Ireland from 20 June 1837 until her death. From 1 May 1876, she adopted the additional title of Empress of India.		Victoria was the daughter of Prince Edward, Duke of Kent and Strathearn, the fourth son of George III of the United Kingdom. Both the Duke of Kent and King George III died in 1820, and Victoria was raised under close supervision by her German-born mother, Princess Victoria of Saxe-Coburg-Saalfeld. She inherited the throne at the age of 18, after her father's three elder brothers had all died, leaving no surviving legitimate children. The United Kingdom was already an established constitutional monarchy, in which the sovereign held relatively little direct political power. Privately, Victoria attempted to influence government policy and ministerial appointments; publicly, she became a national icon who was identified with strict standards of personal morality.		Victoria married her first cousin, Prince Albert of Saxe-Coburg and Gotha, in 1840. Their nine children married into royal and noble families across the continent, tying them together and earning her the sobriquet "the grandmother of Europe". After Albert's death in 1861, Victoria plunged into deep mourning and avoided public appearances. As a result of her seclusion, republicanism temporarily gained strength, but in the latter half of her reign her popularity recovered. Her Golden and Diamond Jubilees were times of public celebration.		Her reign of 63 years and seven months is known as the Victorian era and was longer than that of any of her predecessors. It was a period of industrial, cultural, political, scientific, and military change within the United Kingdom, and was marked by a great expansion of the British Empire. She was the last British monarch of the House of Hanover. Her son and successor, Edward VII, inaugurated the House of Saxe-Coburg and Gotha, the line of his father.						Victoria's father was Prince Edward, Duke of Kent and Strathearn, the fourth son of the reigning King of the United Kingdom, George III. Until 1817, Edward's niece, Princess Charlotte of Wales, was the only legitimate grandchild of George III. Her death in 1817 precipitated a succession crisis that brought pressure on the Duke of Kent and his unmarried brothers to marry and have children. In 1818 he married Princess Victoria of Saxe-Coburg-Saalfeld, a widowed German princess with two children—Carl (1804–1856) and Feodora (1807–1872)—by her first marriage to the Prince of Leiningen. Her brother Leopold was Princess Charlotte's widower. The Duke and Duchess of Kent's only child, Victoria, was born at 4.15 a.m. on 24 May 1819 at Kensington Palace in London.[1]		Victoria was christened privately by the Archbishop of Canterbury, Charles Manners-Sutton, on 24 June 1819 in the Cupola Room at Kensington Palace.[2] She was baptised Alexandrina, after one of her godparents, Emperor Alexander I of Russia, and Victoria, after her mother. Additional names proposed by her parents—Georgina (or Georgiana), Charlotte, and Augusta—were dropped on the instructions of the Duke's eldest brother, George, the Prince Regent.[3]		At birth, Victoria was fifth in the line of succession after the four eldest sons of George III: George, the Prince Regent (later George IV); Frederick, the Duke of York; William, the Duke of Clarence (later William IV); and Victoria's father, Edward, the Duke of Kent.[4] The Prince Regent had no surviving children, and the Duke of York had no children; further, both were estranged from their wives, who were both past child-bearing age, so the two eldest brothers were unlikely to have any further children. The Duke of Clarence and the Duke of Kent married on the same day in 1818, but both of Clarence's daughters (born in 1819 and 1820) died as infants. Victoria's father died in January 1820, when Victoria was less than a year old. A week later her grandfather died and was succeeded by his eldest son, George IV. The Duke of York died in 1827. When George IV died in 1830, he was succeeded by his next surviving brother, William IV, and Victoria became heir presumptive. The Regency Act 1830 made special provision for the Duchess of Kent (Victoria's mother) to act as regent in case William died while Victoria was still a minor.[5] King William distrusted the Duchess's capacity to be regent, and in 1836 he declared in her presence that he wanted to live until Victoria's 18th birthday, so that a regency could be avoided.[6]		Victoria later described her childhood as "rather melancholy".[7] Her mother was extremely protective, and Victoria was raised largely isolated from other children under the so-called "Kensington System", an elaborate set of rules and protocols devised by the Duchess and her ambitious and domineering comptroller, Sir John Conroy, who was rumoured to be the Duchess's lover.[8] The system prevented the princess from meeting people whom her mother and Conroy deemed undesirable (including most of her father's family), and was designed to render her weak and dependent upon them.[9] The Duchess avoided the court because she was scandalised by the presence of King William's illegitimate children,[10] and perhaps prompted the emergence of Victorian morality by insisting that her daughter avoid any appearance of sexual impropriety.[11] Victoria shared a bedroom with her mother every night, studied with private tutors to a regular timetable, and spent her play-hours with her dolls and her King Charles Spaniel, Dash.[12] Her lessons included French, German, Italian, and Latin,[13] but she spoke only English at home.[14]		In 1830, the Duchess of Kent and Conroy took Victoria across the centre of England to visit the Malvern Hills, stopping at towns and great country houses along the way.[15] Similar journeys to other parts of England and Wales were taken in 1832, 1833, 1834 and 1835. To the King's annoyance, Victoria was enthusiastically welcomed in each of the stops.[16] William compared the journeys to royal progresses and was concerned that they portrayed Victoria as his rival rather than his heir presumptive.[17] Victoria disliked the trips; the constant round of public appearances made her tired and ill, and there was little time for her to rest.[18] She objected on the grounds of the King's disapproval, but her mother dismissed his complaints as motivated by jealousy, and forced Victoria to continue the tours.[19] At Ramsgate in October 1835, Victoria contracted a severe fever, which Conroy initially dismissed as a childish pretence.[20] While Victoria was ill, Conroy and the Duchess unsuccessfully badgered her to make Conroy her private secretary.[21] As a teenager, Victoria resisted persistent attempts by her mother and Conroy to appoint him to her staff.[22] Once queen, she banned him from her presence, but he remained in her mother's household.[23]		By 1836, the Duchess's brother, Leopold, who had been King of the Belgians since 1831, hoped to marry his niece to his nephew, Prince Albert of Saxe-Coburg and Gotha.[24] Leopold, Victoria's mother, and Albert's father (Ernest I, Duke of Saxe-Coburg and Gotha) were siblings. Leopold arranged for Victoria's mother to invite her Coburg relatives to visit her in May 1836, with the purpose of introducing Victoria to Albert.[25] William IV, however, disapproved of any match with the Coburgs, and instead favoured the suit of Prince Alexander of the Netherlands, second son of the Prince of Orange.[26] Victoria was aware of the various matrimonial plans and critically appraised a parade of eligible princes.[27] According to her diary, she enjoyed Albert's company from the beginning. After the visit she wrote, "[Albert] is extremely handsome; his hair is about the same colour as mine; his eyes are large and blue, and he has a beautiful nose and a very sweet mouth with fine teeth; but the charm of his countenance is his expression, which is most delightful."[28] Alexander, on the other hand, was "very plain".[29]		Victoria wrote to her uncle Leopold, whom Victoria considered her "best and kindest adviser",[30] to thank him "for the prospect of great happiness you have contributed to give me, in the person of dear Albert ... He possesses every quality that could be desired to render me perfectly happy. He is so sensible, so kind, and so good, and so amiable too. He has besides the most pleasing and delightful exterior and appearance you can possibly see."[31] However at 17, Victoria, though interested in Albert, was not yet ready to marry. The parties did not undertake a formal engagement, but assumed that the match would take place in due time.[32]		Victoria turned 18 on 24 May 1837, and a regency was avoided. Less than a month later, on 20 June 1837, William IV died at the age of 71, and Victoria became Queen of the United Kingdom.[33] In her diary she wrote, "I was awoke at 6 o'clock by Mamma, who told me the Archbishop of Canterbury and Lord Conyngham were here and wished to see me. I got out of bed and went into my sitting-room (only in my dressing gown) and alone, and saw them. Lord Conyngham then acquainted me that my poor Uncle, the King, was no more, and had expired at 12 minutes past 2 this morning, and consequently that I am Queen."[34] Official documents prepared on the first day of her reign described her as Alexandrina Victoria, but the first name was withdrawn at her own wish and not used again.[35]		Since 1714, Britain had shared a monarch with Hanover in Germany, but under Salic law women were excluded from the Hanoverian succession. While Victoria inherited all the British dominions, Hanover passed instead to her father's younger brother, her unpopular uncle the Duke of Cumberland and Teviotdale, who became King of Hanover. He was her heir presumptive until she married and had a child.[36]		At the time of her accession, the government was led by the Whig prime minister Lord Melbourne, who at once became a powerful influence on the politically inexperienced Queen, who relied on him for advice.[37] Charles Greville supposed that the widowed and childless Melbourne was "passionately fond of her as he might be of his daughter if he had one", and Victoria probably saw him as a father figure.[38] Her coronation took place on 28 June 1838 at Westminster Abbey. Over 400,000 visitors came to London for the celebrations.[39] She became the first sovereign to take up residence at Buckingham Palace[40] and inherited the revenues of the duchies of Lancaster and Cornwall as well as being granted a civil list allowance of £385,000 per year. Financially prudent, she paid off her father's debts.[41]		At the start of her reign Victoria was popular,[42] but her reputation suffered in an 1839 court intrigue when one of her mother's ladies-in-waiting, Lady Flora Hastings, developed an abdominal growth that was widely rumoured to be an out-of-wedlock pregnancy by Sir John Conroy.[43] Victoria believed the rumours.[44] She hated Conroy, and despised "that odious Lady Flora",[45] because she had conspired with Conroy and the Duchess of Kent in the Kensington System.[46] At first, Lady Flora refused to submit to a naked medical examination, until in mid-February she eventually agreed, and was found to be a virgin.[47] Conroy, the Hastings family and the opposition Tories organised a press campaign implicating the Queen in the spreading of false rumours about Lady Flora.[48] When Lady Flora died in July, the post-mortem revealed a large tumour on her liver that had distended her abdomen.[49] At public appearances, Victoria was hissed and jeered as "Mrs. Melbourne".[50]		In 1839, Melbourne resigned after Radicals and Tories (both of whom Victoria detested) voted against a bill to suspend the constitution of Jamaica. The bill removed political power from plantation owners who were resisting measures associated with the abolition of slavery.[51] The Queen commissioned a Tory, Sir Robert Peel, to form a new ministry. At the time, it was customary for the prime minister to appoint members of the Royal Household, who were usually his political allies and their spouses. Many of the Queen's ladies of the bedchamber were wives of Whigs, and Peel expected to replace them with wives of Tories. In what became known as the bedchamber crisis, Victoria, advised by Melbourne, objected to their removal. Peel refused to govern under the restrictions imposed by the Queen, and consequently resigned his commission, allowing Melbourne to return to office.[52]		Though Victoria was now queen, as an unmarried young woman she was required by social convention to live with her mother, despite their differences over the Kensington System and her mother's continued reliance on Conroy.[53] Her mother was consigned to a remote apartment in Buckingham Palace, and Victoria often refused to see her.[54] When Victoria complained to Melbourne that her mother's close proximity promised "torment for many years", Melbourne sympathised but said it could be avoided by marriage, which Victoria called a "schocking [sic] alternative".[55] She showed interest in Albert's education for the future role he would have to play as her husband, but she resisted attempts to rush her into wedlock.[56]		Victoria continued to praise Albert following his second visit in October 1839. Albert and Victoria felt mutual affection and the Queen proposed to him on 15 October 1839, just five days after he had arrived at Windsor.[57] They were married on 10 February 1840, in the Chapel Royal of St James's Palace, London. Victoria was besotted. She spent the evening after their wedding lying down with a headache, but wrote ecstatically in her diary:		I NEVER, NEVER spent such an evening!!! MY DEAREST DEAREST DEAR Albert ... his excessive love & affection gave me feelings of heavenly love & happiness I never could have hoped to have felt before! He clasped me in his arms, & we kissed each other again & again! His beauty, his sweetness & gentleness – really how can I ever be thankful enough to have such a Husband! ... to be called by names of tenderness, I have never yet heard used to me before – was bliss beyond belief! Oh! This was the happiest day of my life![58]		Albert became an important political adviser as well as the Queen's companion, replacing Lord Melbourne as the dominant, influential figure in the first half of her life.[59] Victoria's mother was evicted from the palace, to Ingestre House in Belgrave Square. After the death of Princess Augusta in 1840, Victoria's mother was given both Clarence and Frogmore Houses.[60] Through Albert's mediation, relations between mother and daughter slowly improved.[61]		During Victoria's first pregnancy in 1840, in the first few months of the marriage, 18-year-old Edward Oxford attempted to assassinate her while she was riding in a carriage with Prince Albert on her way to visit her mother. Oxford fired twice, but either both bullets missed or, as he later claimed, the guns had no shot.[62] He was tried for high treason, found not guilty on the grounds of insanity, and committed to an insane asylum indefinitely.[63] In the immediate aftermath of the attack, Victoria's popularity soared, mitigating residual discontent over the Hastings affair and the bedchamber crisis.[64] Her daughter, also named Victoria, was born on 21 November 1840. The Queen hated being pregnant,[65] viewed breast-feeding with disgust,[66] and thought newborn babies were ugly.[67] Nevertheless, over the following seventeen years, she and Albert had a further eight children: Albert Edward, Prince of Wales (b. 1841), Alice (b. 1843), Alfred (b. 1844), Helena (b. 1846), Louise (b. 1848), Arthur (b. 1850), Leopold (b. 1853) and Beatrice (b. 1857).		Victoria's household was largely run by her childhood governess, Baroness Louise Lehzen from Hanover. Lehzen had been a formative influence on Victoria,[68] and had supported her against the Kensington System.[69] Albert, however, thought Lehzen was incompetent, and that her mismanagement threatened his daughter's health. After a furious row between Victoria and Albert over the issue, Lehzen was pensioned off, and Victoria's close relationship with her ended.[70]		On 29 May 1842, Victoria was riding in a carriage along The Mall, London, when John Francis aimed a pistol at her but the gun did not fire; he escaped. The following day, Victoria drove the same route, though faster and with a greater escort, in a deliberate attempt to provoke Francis to take a second aim and catch him in the act. As expected, Francis shot at her, but he was seized by plain-clothes policemen, and convicted of high treason. On 3 July, two days after Francis's death sentence was commuted to transportation for life, John William Bean also tried to fire a pistol at the Queen, but it was loaded only with paper and tobacco and had too little charge.[71] Edward Oxford felt that the attempts were encouraged by his acquittal in 1840. Bean was sentenced to 18 months in jail.[72] In a similar attack in 1849, unemployed Irishman William Hamilton fired a powder-filled pistol at Victoria's carriage as it passed along Constitution Hill, London.[73] In 1850, the Queen did sustain injury when she was assaulted by a possibly insane ex-army officer, Robert Pate. As Victoria was riding in a carriage, Pate struck her with his cane, crushing her bonnet and bruising her forehead. Both Hamilton and Pate were sentenced to seven years' transportation.[74]		Melbourne's support in the House of Commons weakened through the early years of Victoria's reign, and in the 1841 general election the Whigs were defeated. Peel became prime minister, and the ladies of the bedchamber most associated with the Whigs were replaced.[75]		In 1845, Ireland was hit by a potato blight.[77] In the next four years, over a million Irish people died and another million emigrated in what became known as the Great Famine.[78] In Ireland, Victoria was labelled "The Famine Queen".[79][80] She personally donated £2,000 to the British Relief Association, more than any other individual famine relief donor,[81] and also supported the Maynooth Grant to a Roman Catholic seminary in Ireland, despite Protestant opposition.[82] The story that she donated only £5 in aid to the Irish, and on the same day gave the same amount to Battersea Dogs Home, was a myth generated towards the end of the 19th century.[83]		By 1846, Peel's ministry faced a crisis involving the repeal of the Corn Laws. Many Tories—by then known also as Conservatives—were opposed to the repeal, but Peel, some Tories (the "Peelites"), most Whigs and Victoria supported it. Peel resigned in 1846, after the repeal narrowly passed, and was replaced by Lord John Russell.[84]		Internationally, Victoria took a keen interest in the improvement of relations between France and Britain.[85] She made and hosted several visits between the British royal family and the House of Orleans, who were related by marriage through the Coburgs. In 1843 and 1845, she and Albert stayed with King Louis Philippe I at château d'Eu in Normandy; she was the first British or English monarch to visit a French one since the meeting of Henry VIII of England and Francis I of France on the Field of the Cloth of Gold in 1520.[86] When Louis Philippe made a reciprocal trip in 1844, he became the first French king to visit a British sovereign.[87] Louis Philippe was deposed in the revolutions of 1848, and fled to exile in England.[88] At the height of a revolutionary scare in the United Kingdom in April 1848, Victoria and her family left London for the greater safety of Osborne House,[89] a private estate on the Isle of Wight that they had purchased in 1845 and redeveloped.[90] Demonstrations by Chartists and Irish nationalists failed to attract widespread support, and the scare died down without any major disturbances.[91] Victoria's first visit to Ireland in 1849 was a public relations success, but it had no lasting impact or effect on the growth of Irish nationalism.[92]		Russell's ministry, though Whig, was not favoured by the Queen.[93] She found particularly offensive the Foreign Secretary, Lord Palmerston, who often acted without consulting the Cabinet, the Prime Minister, or the Queen.[94] Victoria complained to Russell that Palmerston sent official dispatches to foreign leaders without her knowledge, but Palmerston was retained in office and continued to act on his own initiative, despite her repeated remonstrances. It was only in 1851 that Palmerston was removed after he announced the British government's approval of President Louis-Napoleon Bonaparte's coup in France without consulting the Prime Minister.[95] The following year, President Bonaparte was declared Emperor Napoleon III, by which time Russell's administration had been replaced by a short-lived minority government led by Lord Derby.		In 1853, Victoria gave birth to her eighth child, Leopold, with the aid of the new anaesthetic, chloroform. Victoria was so impressed by the relief it gave from the pain of childbirth that she used it again in 1857 at the birth of her ninth and final child, Beatrice, despite opposition from members of the clergy, who considered it against biblical teaching, and members of the medical profession, who thought it dangerous.[96] Victoria may have suffered from postnatal depression after many of her pregnancies.[97] Letters from Albert to Victoria intermittently complain of her loss of self-control. For example, about a month after Leopold's birth Albert complained in a letter to Victoria about her "continuance of hysterics" over a "miserable trifle".[98]		In early 1855, the government of Lord Aberdeen, who had replaced Derby, fell amidst recriminations over the poor management of British troops in the Crimean War. Victoria approached both Derby and Russell to form a ministry, but neither had sufficient support, and Victoria was forced to appoint Palmerston as prime minister.[99]		Napoleon III, since the Crimean War Britain's closest ally,[97] visited London in April 1855, and from 17 to 28 August the same year Victoria and Albert returned the visit.[100] Napoleon III met the couple at Boulogne and accompanied them to Paris.[101] They visited the Exposition Universelle (a successor to Albert's 1851 brainchild the Great Exhibition) and Napoleon I's tomb at Les Invalides (to which his remains had only been returned in 1840), and were guests of honour at a 1,200-guest ball at the Palace of Versailles.[102]		On 14 January 1858, an Italian refugee from Britain called Felice Orsini attempted to assassinate Napoleon III with a bomb made in England.[103] The ensuing diplomatic crisis destabilised the government, and Palmerston resigned. Derby was reinstated as prime minister.[104] Victoria and Albert attended the opening of a new basin at the French military port of Cherbourg on 5 August 1858, in an attempt by Napoleon III to reassure Britain that his military preparations were directed elsewhere. On her return Victoria wrote to Derby reprimanding him for the poor state of the Royal Navy in comparison to the French one.[105] Derby's ministry did not last long, and in June 1859 Victoria recalled Palmerston to office.[106]		Eleven days after Orsini's assassination attempt in France, Victoria's eldest daughter married Prince Frederick William of Prussia in London. They had been betrothed since September 1855, when Princess Victoria was 14 years old; the marriage was delayed by the Queen and Prince Albert until the bride was 17.[107] The Queen and Albert hoped that their daughter and son-in-law would be a liberalising influence in the enlarging Prussian state.[108] Victoria felt "sick at heart" to see her daughter leave England for Germany; "It really makes me shudder", she wrote to Princess Victoria in one of her frequent letters, "when I look round to all your sweet, happy, unconscious sisters, and think I must give them up too – one by one."[109] Almost exactly a year later, Princess Victoria gave birth to the Queen's first grandchild, Wilhelm, who would become the last German Kaiser.		In March 1861, Victoria's mother died, with Victoria at her side. Through reading her mother's papers, Victoria discovered that her mother had loved her deeply;[110] she was heart-broken, and blamed Conroy and Lehzen for "wickedly" estranging her from her mother.[111] To relieve his wife during her intense and deep grief,[112] Albert took on most of her duties, despite being ill himself with chronic stomach trouble.[113] In August, Victoria and Albert visited their son, the Prince of Wales, who was attending army manoeuvres near Dublin, and spent a few days holidaying in Killarney. In November, Albert was made aware of gossip that his son had slept with an actress in Ireland.[114] Appalled, Albert travelled to Cambridge, where his son was studying, to confront him.[115] By the beginning of December, Albert was very unwell.[116] He was diagnosed with typhoid fever by William Jenner, and died on 14 December 1861. Victoria was devastated.[117] She blamed her husband's death on worry over the Prince of Wales's philandering. He had been "killed by that dreadful business", she said.[118] She entered a state of mourning and wore black for the remainder of her life. She avoided public appearances, and rarely set foot in London in the following years.[119] Her seclusion earned her the nickname "widow of Windsor".[120]		Victoria's self-imposed isolation from the public diminished the popularity of the monarchy, and encouraged the growth of the republican movement.[121] She did undertake her official government duties, yet chose to remain secluded in her royal residences—Windsor Castle, Osborne House, and the private estate in Scotland that she and Albert had acquired in 1847, Balmoral Castle. In March 1864, a protester stuck a notice on the railings of Buckingham Palace that announced "these commanding premises to be let or sold in consequence of the late occupant's declining business".[122] Her uncle Leopold wrote to her advising her to appear in public. She agreed to visit the gardens of the Royal Horticultural Society at Kensington and take a drive through London in an open carriage.[123]		Through the 1860s, Victoria relied increasingly on a manservant from Scotland, John Brown.[124] Slanderous rumours of a romantic connection and even a secret marriage appeared in print, and the Queen was referred to as "Mrs. Brown".[125] The story of their relationship was the subject of the 1997 movie Mrs. Brown. A painting by Sir Edwin Henry Landseer depicting the Queen with Brown was exhibited at the Royal Academy, and Victoria published a book, Leaves from the Journal of Our Life in the Highlands, which featured Brown prominently and in which the Queen praised him highly.[126]		Palmerston died in 1865, and after a brief ministry led by Russell, Derby returned to power. In 1866, Victoria attended the State Opening of Parliament for the first time since Albert's death.[127] The following year she supported the passing of the Reform Act 1867 which doubled the electorate by extending the franchise to many urban working men,[128] though she was not in favour of votes for women.[129] Derby resigned in 1868, to be replaced by Benjamin Disraeli, who charmed Victoria. "Everyone likes flattery," he said, "and when you come to royalty you should lay it on with a trowel."[130] With the phrase "we authors, Ma'am", he complimented her.[131] Disraeli's ministry only lasted a matter of months, and at the end of the year his Liberal rival, William Ewart Gladstone, was appointed prime minister. Victoria found Gladstone's demeanour far less appealing; he spoke to her, she is thought to have complained, as though she were "a public meeting rather than a woman".[132]		In 1870, republican sentiment in Britain, fed by the Queen's seclusion, was boosted after the establishment of the Third French Republic.[133] A republican rally in Trafalgar Square demanded Victoria's removal, and Radical MPs spoke against her.[134] In August and September 1871, she was seriously ill with an abscess in her arm, which Joseph Lister successfully lanced and treated with his new antiseptic carbolic acid spray.[135] In late November 1871, at the height of the republican movement, the Prince of Wales contracted typhoid fever, the disease that was believed to have killed his father, and Victoria was fearful her son would die.[136] As the tenth anniversary of her husband's death approached, her son's condition grew no better, and Victoria's distress continued.[137] To general rejoicing, he pulled through.[138] Mother and son attended a public parade through London and a grand service of thanksgiving in St Paul's Cathedral on 27 February 1872, and republican feeling subsided.[139]		On the last day of February 1872, two days after the thanksgiving service, 17-year-old Arthur O'Connor (great-nephew of Irish MP Feargus O'Connor) waved an unloaded pistol at Victoria's open carriage just after she had arrived at Buckingham Palace. Brown, who was attending the Queen, grabbed him and O'Connor was later sentenced to 12 months' imprisonment.[140] As a result of the incident, Victoria's popularity recovered further.[141]		After the Indian Rebellion of 1857, the British East India Company, which had ruled much of India, was dissolved, and Britain's possessions and protectorates on the Indian subcontinent were formally incorporated into the British Empire. The Queen had a relatively balanced view of the conflict, and condemned atrocities on both sides.[142] She wrote of "her feelings of horror and regret at the result of this bloody civil war",[143] and insisted, urged on by Albert, that an official proclamation announcing the transfer of power from the company to the state "should breathe feelings of generosity, benevolence and religious toleration".[144] At her behest, a reference threatening the "undermining of native religions and customs" was replaced by a passage guaranteeing religious freedom.[144]		In the 1874 general election, Disraeli was returned to power. He passed the Public Worship Regulation Act 1874, which removed Catholic rituals from the Anglican liturgy and which Victoria strongly supported.[146] She preferred short, simple services, and personally considered herself more aligned with the presbyterian Church of Scotland than the episcopal Church of England.[147] He also pushed the Royal Titles Act 1876 through Parliament, so that Victoria took the title "Empress of India" from 1 May 1876.[148] The new title was proclaimed at the Delhi Durbar of 1 January 1877.[149]		On 14 December 1878, the anniversary of Albert's death, Victoria's second daughter Alice, who had married Louis of Hesse, died of diphtheria in Darmstadt. Victoria noted the coincidence of the dates as "almost incredible and most mysterious".[150] In May 1879, she became a great-grandmother (on the birth of Princess Feodora of Saxe-Meiningen) and passed her "poor old 60th birthday". She felt "aged" by "the loss of my beloved child".[151]		Between April 1877 and February 1878, she threatened five times to abdicate while pressuring Disraeli to act against Russia during the Russo-Turkish War, but her threats had no impact on the events or their conclusion with the Congress of Berlin.[152] Disraeli's expansionist foreign policy, which Victoria endorsed, led to conflicts such as the Anglo-Zulu War and the Second Anglo-Afghan War. "If we are to maintain our position as a first-rate Power", she wrote, "we must ... be Prepared for attacks and wars, somewhere or other, CONTINUALLY."[153] Victoria saw the expansion of the British Empire as civilising and benign, protecting native peoples from more aggressive powers or cruel rulers: "It is not in our custom to annexe countries", she said, "unless we are obliged & forced to do so."[154] To Victoria's dismay, Disraeli lost the 1880 general election, and Gladstone returned as prime minister.[155] When Disraeli died the following year, she was blinded by "fast falling tears",[156] and erected a memorial tablet "placed by his grateful Sovereign and Friend, Victoria R.I."[157]		On 2 March 1882, Roderick Maclean, a disgruntled poet apparently offended by Victoria's refusal to accept one of his poems,[158] shot at the Queen as her carriage left Windsor railway station. Two schoolboys from Eton College struck him with their umbrellas, until he was hustled away by a policeman.[159] Victoria was outraged when he was found not guilty by reason of insanity,[160] but was so pleased by the many expressions of loyalty after the attack that she said it was "worth being shot at—to see how much one is loved".[161]		On 17 March 1883, she fell down some stairs at Windsor, which left her lame until July; she never fully recovered and was plagued with rheumatism thereafter.[162] Brown died 10 days after her accident, and to the consternation of her private secretary, Sir Henry Ponsonby, Victoria began work on a eulogistic biography of Brown.[163] Ponsonby and Randall Davidson, Dean of Windsor, who had both seen early drafts, advised Victoria against publication, on the grounds that it would stoke the rumours of a love affair.[164] The manuscript was destroyed.[165] In early 1884, Victoria did publish More Leaves from a Journal of a Life in the Highlands, a sequel to her earlier book, which she dedicated to her "devoted personal attendant and faithful friend John Brown".[166] On the day after the first anniversary of Brown's death, Victoria was informed by telegram that her youngest son, Leopold, had died in Cannes. He was "the dearest of my dear sons", she lamented.[167] The following month, Victoria's youngest child, Beatrice, met and fell in love with Prince Henry of Battenberg at the wedding of Victoria's granddaughter Princess Victoria of Hesse and by Rhine to Henry's brother Prince Louis of Battenberg. Beatrice and Henry planned to marry, but Victoria opposed the match at first, wishing to keep Beatrice at home to act as her companion. After a year, she was won around to the marriage by Henry and Beatrice's promise to remain living with and attending her.[168]		Victoria was pleased when Gladstone resigned in 1885 after his budget was defeated.[169] She thought his government was "the worst I have ever had", and blamed him for the death of General Gordon at Khartoum.[170] Gladstone was replaced by Lord Salisbury. Salisbury's government only lasted a few months, however, and Victoria was forced to recall Gladstone, whom she referred to as a "half crazy & really in many ways ridiculous old man".[171] Gladstone attempted to pass a bill granting Ireland home rule, but to Victoria's glee it was defeated.[172] In the ensuing election, Gladstone's party lost to Salisbury's and the government switched hands again.		In 1887, the British Empire celebrated Victoria's Golden Jubilee. Victoria marked the fiftieth anniversary of her accession on 20 June with a banquet to which 50 kings and princes were invited. The following day, she participated in a procession and attended a thanksgiving service in Westminster Abbey.[173] By this time, Victoria was once again extremely popular.[174] Two days later on 23 June,[175] she engaged two Indian Muslims as waiters, one of whom was Abdul Karim. He was soon promoted to "Munshi": teaching her Hindustani, and acting as a clerk.[176] Her family and retainers were appalled, and accused Abdul Karim of spying for the Muslim Patriotic League, and biasing the Queen against the Hindus.[177] Equerry Frederick Ponsonby (the son of Sir Henry) discovered that the Munshi had lied about his parentage, and reported to Lord Elgin, Viceroy of India, "the Munshi occupies very much the same position as John Brown used to do."[178] Victoria dismissed their complaints as racial prejudice.[179] Abdul Karim remained in her service until he returned to India with a pension on her death.[180]		Victoria's eldest daughter became Empress consort of Germany in 1888, but she was widowed within the year, and Victoria's grandchild Wilhelm became German Emperor as Wilhelm II. Under Wilhelm, Victoria and Albert's hopes of a liberal Germany were not fulfilled. He believed in autocracy. Victoria thought he had "little heart or Zartgefühl [tact] – and ... his conscience & intelligence have been completely wharped [sic]".[181]		Gladstone returned to power after the 1892 general election; he was 82 years old. Victoria objected when Gladstone proposed appointing the Radical MP Henry Labouchère to the Cabinet, so Gladstone agreed not to appoint him.[182] In 1894, Gladstone retired and, without consulting the outgoing prime minister, Victoria appointed Lord Rosebery as prime minister.[183] His government was weak, and the following year Lord Salisbury replaced him. Salisbury remained prime minister for the remainder of Victoria's reign.[184]		On 23 September 1896, Victoria surpassed her grandfather George III as the longest-reigning monarch in English, Scottish, and British history. The Queen requested that any special celebrations be delayed until 1897, to coincide with her Diamond Jubilee,[185] which was made a festival of the British Empire at the suggestion of Colonial Secretary Joseph Chamberlain.[186] The prime ministers of all the self-governing dominions were invited to London for the festivities.[187] One reason for including the prime ministers of the dominions and excluding foreign heads of state was to avoid having to invite Victoria's grandson, Wilhelm II of Germany who, it was feared, might cause trouble at the event.[188]		The Queen's Diamond Jubilee procession on 22 June 1897 followed a route six miles long through London and included troops from all over the empire. The procession paused for an open-air service of thanksgiving held outside St Paul's Cathedral, throughout which Victoria sat in her open carriage, to avoid her having to climb the steps to enter the building. The celebration was marked by vast crowds of spectators and great outpourings of affection for the 78-year-old Queen.[189]		Victoria visited mainland Europe regularly for holidays. In 1889, during a stay in Biarritz, she became the first reigning monarch from Britain to set foot in Spain when she crossed the border for a brief visit.[190] By April 1900, the Boer War was so unpopular in mainland Europe that her annual trip to France seemed inadvisable. Instead, the Queen went to Ireland for the first time since 1861, in part to acknowledge the contribution of Irish regiments to the South African war.[191] In July, her second son Alfred ("Affie") died; "Oh, God! My poor darling Affie gone too", she wrote in her journal. "It is a horrible year, nothing but sadness & horrors of one kind & another."[192]		Following a custom she maintained throughout her widowhood, Victoria spent the Christmas of 1900 at Osborne House on the Isle of Wight. Rheumatism in her legs had rendered her lame, and her eyesight was clouded by cataracts.[193] Through early January, she felt "weak and unwell",[194] and by mid-January she was "drowsy ... dazed, [and] confused".[195] She died on Tuesday, 22 January 1901, at half past six in the evening, at the age of 81.[196] Her son and successor King Edward VII, and her eldest grandson, Emperor Wilhelm II of Germany, were at her deathbed.[197] Her favourite pet Pomeranian, Turi, was laid upon her deathbed as a last request.[198]		In 1897, Victoria had written instructions for her funeral, which was to be military as befitting a soldier's daughter and the head of the army,[97] and white instead of black.[199] On 25 January, Edward VII, the Kaiser and Prince Arthur, Duke of Connaught, helped lift her body into the coffin.[200] She was dressed in a white dress and her wedding veil.[201] An array of mementos commemorating her extended family, friends and servants were laid in the coffin with her, at her request, by her doctor and dressers. One of Albert's dressing gowns was placed by her side, with a plaster cast of his hand, while a lock of John Brown's hair, along with a picture of him, was placed in her left hand concealed from the view of the family by a carefully positioned bunch of flowers.[97][202] Items of jewellery placed on Victoria included the wedding ring of John Brown's mother, given to her by Brown in 1883.[97] Her funeral was held on Saturday, 2 February, in St George's Chapel, Windsor Castle, and after two days of lying-in-state, she was interred beside Prince Albert in Frogmore Mausoleum at Windsor Great Park.[203]		With a reign of 63 years, seven months and two days, Victoria was the longest-reigning British monarch and the longest-reigning queen regnant in world history until her great-great-granddaughter Elizabeth II surpassed her on 9 September 2015.[204] She was the last monarch of Britain from the House of Hanover. Her son and successor Edward VII belonged to her husband's House of Saxe-Coburg and Gotha.		According to one of her biographers, Giles St Aubyn, Victoria wrote an average of 2,500 words a day during her adult life.[208] From July 1832 until just before her death, she kept a detailed journal, which eventually encompassed 122 volumes.[209] After Victoria's death, her youngest daughter, Princess Beatrice, was appointed her literary executor. Beatrice transcribed and edited the diaries covering Victoria's accession onwards, and burned the originals in the process.[210] Despite this destruction, much of the diaries still exist. In addition to Beatrice's edited copy, Lord Esher transcribed the volumes from 1832 to 1861 before Beatrice destroyed them.[211] Part of Victoria's extensive correspondence has been published in volumes edited by A. C. Benson, Hector Bolitho, George Earle Buckle, Lord Esher, Roger Fulford, and Richard Hough among others.[212]		Victoria was physically unprepossessing—she was stout, dowdy and only about five feet tall—but she succeeded in projecting a grand image.[213] She experienced unpopularity during the first years of her widowhood, but was well liked during the 1880s and 1890s, when she embodied the empire as a benevolent matriarchal figure.[214] Only after the release of her diary and letters did the extent of her political influence become known to the wider public.[97][215] Biographies of Victoria written before much of the primary material became available, such as Lytton Strachey's Queen Victoria of 1921, are now considered out of date.[216] The biographies written by Elizabeth Longford and Cecil Woodham-Smith, in 1964 and 1972 respectively, are still widely admired.[217] They, and others, conclude that as a person Victoria was emotional, obstinate, honest, and straight-talking.[218]		Through Victoria's reign, the gradual establishment of a modern constitutional monarchy in Britain continued. Reforms of the voting system increased the power of the House of Commons at the expense of the House of Lords and the monarch.[219] In 1867, Walter Bagehot wrote that the monarch only retained "the right to be consulted, the right to encourage, and the right to warn".[220] As Victoria's monarchy became more symbolic than political, it placed a strong emphasis on morality and family values, in contrast to the sexual, financial and personal scandals that had been associated with previous members of the House of Hanover and which had discredited the monarchy. The concept of the "family monarchy", with which the burgeoning middle classes could identify, was solidified.[221]		Victoria's links with Europe's royal families earned her the nickname "the grandmother of Europe".[222] Victoria and Albert had 42 grandchildren, of whom 34 survived to adulthood. Their descendants include Elizabeth II, Prince Philip, Duke of Edinburgh, Harald V of Norway, Carl XVI Gustaf of Sweden, Margrethe II of Denmark, and Felipe VI of Spain.		Victoria's youngest son, Leopold, was affected by the blood-clotting disease haemophilia B and two of her five daughters, Alice and Beatrice, were carriers. Royal haemophiliacs descended from Victoria included her great-grandsons, Alexei Nikolaevich, Tsarevich of Russia, Alfonso, Prince of Asturias, and Infante Gonzalo of Spain.[223] The presence of the disease in Victoria's descendants, but not in her ancestors, led to modern speculation that her true father was not the Duke of Kent but a haemophiliac.[224] There is no documentary evidence of a haemophiliac in connection with Victoria's mother, and as male carriers always suffer the disease, even if such a man had existed he would have been seriously ill.[225] It is more likely that the mutation arose spontaneously because Victoria's father was over 50 at the time of her conception and haemophilia arises more frequently in the children of older fathers.[226] Spontaneous mutations account for about a third of cases.[227]		Around the world, places and memorials are dedicated to her, especially in the Commonwealth nations. Places named after her include Africa's largest lake, Victoria Falls, the capitals of British Columbia (Victoria) and Saskatchewan (Regina), and two Australian states (Victoria and Queensland).		The Victoria Cross was introduced in 1856 to reward acts of valour during the Crimean War, and it remains the highest British, Canadian, Australian, and New Zealander award for bravery. Victoria Day is a Canadian statutory holiday and a local public holiday in parts of Scotland celebrated on the last Monday before or on 24 May (Queen Victoria's birthday).		At the end of her reign, the Queen's full style and title were: "Her Majesty Victoria, by the Grace of God, of the United Kingdom of Great Britain and Ireland Queen, Defender of the Faith, Empress of India."[228]		As Sovereign, Victoria used the royal coat of arms of the United Kingdom. Before her accession, she received no grant of arms. As she could not succeed to the throne of Hanover, her arms did not carry the Hanoverian symbols that were used by her immediate predecessors. Her arms have been borne by all of her successors on the throne.		Outside Scotland, the blazon for the shield—also used on the Royal Standard—is: Quarterly: I and IV, Gules, three lions passant guardant in pale Or (for England); II, Or, a lion rampant within a double tressure flory-counter-flory Gules (for Scotland); III, Azure, a harp Or stringed Argent (for Ireland). In Scotland, the first and fourth quarters are occupied by the Scottish lion, and the second by the English lions. The crests, mottoes, and supporters also differ in and outside Scotland.[229]				
Florida /ˈflɒrᵻdə/ ( listen) (Spanish for "land of flowers") is a state located in the southeastern region of the United States. It is bordered to the west by the Gulf of Mexico, to the north by Alabama and Georgia, to the east by the Atlantic Ocean, and to the south by the Straits of Florida and Cuba. Florida is the 22nd-most extensive, the 3rd-most populous,[9] and the 8th-most densely populated of the U.S. states. Jacksonville is the most populous municipality in the state and is the largest city by area in the contiguous United States. The Miami metropolitan area is Florida's most populous urban area. The city of Tallahassee is the state capital.		A peninsula between the Gulf of Mexico, the Atlantic Ocean, and the Straits of Florida, it has the longest coastline in the contiguous United States, approximately 1,350 miles (2,170 km), and is the only state that borders both the Gulf of Mexico and the Atlantic Ocean. Much of the state is at or near sea level and is characterized by sedimentary soil. The climate varies from subtropical in the north to tropical in the south.[10] The American alligator, American crocodile, Florida panther, and manatee can be found in the Everglades National Park.		Since the first European contact was made in 1513 by Spanish explorer Juan Ponce de León – who named it La Florida ([la floˈɾiða] "land of flowers") upon landing there in the Easter season, Pascua Florida[11] – Florida was a challenge for the European colonial powers before it gained statehood in the United States in 1845. It was a principal location of the Seminole Wars against the Native Americans, and racial segregation after the American Civil War.		Today, Florida is distinctive for its large Cuban expatriate community and high population growth, as well as for its increasing environmental issues. The state's economy relies mainly on tourism, agriculture, and transportation, which developed in the late 19th century. Florida is also renowned for amusement parks, orange crops, the Kennedy Space Center, and as a popular destination for retirees.		Florida culture is a reflection of influences and multiple inheritance; Native American, European American, Hispanic and Latino, and African American heritages can be found in the architecture and cuisine. Florida has attracted many writers such as Marjorie Kinnan Rawlings, Ernest Hemingway and Tennessee Williams, and continues to attract celebrities and athletes. It is internationally known for golf, tennis, auto racing and water sports.						By the 16th century, the earliest time for which there is a historical record, major Native American groups included the Apalachee (of the Florida Panhandle), the Timucua (of northern and central Florida), the Ais (of the central Atlantic coast), the Tocobaga (of the Tampa Bay area), the Calusa (of southwest Florida) and the Tequesta (of the southeastern coast).		Florida was the first part of the continental United States to be visited and settled by Europeans. The earliest known European explorers came with the Spanish conquistador Juan Ponce de León. Ponce de León spotted and landed on the peninsula on April 2, 1513. He named the region La Florida ("land of flowers").[12] The story that he was searching for the Fountain of Youth is a myth.[13]		"In May 1539, Conquistador Hernando de Soto skirted the coast of Florida, searching for a deep harbor to land. He described seeing a thick wall of red mangroves spread mile after mile, some reaching as high as 70 feet (21 m), with intertwined and elevated roots making landing difficult. Very soon, 'many smokes' appeared 'along the whole coast', billowing against the sky, when the Native ancestors of the Seminole spotted the newcomers and spread the alarm by signal fires".[14] The Spanish introduced Christianity, cattle, horses, sheep, the Castilian language, and more to Florida.[15][full citation needed] Spain established several settlements in Florida, with varying degrees of success. In 1559, Don Tristán de Luna y Arellano established a settlement at present-day Pensacola, making it the first attempted settlement in Florida, but it was mostly abandoned by 1561.		In 1565, the settlement of St. Augustine (San Agustín) was established under the leadership of admiral and governor Pedro Menéndez de Avilés, creating what would become the oldest European settlement in the continental U.S. and establishing the first generation of Floridanos and the government of Florida.[16] Spain maintained tenuous control over the region by converting the local tribes to Christianity.		The geographical area of Florida diminished with the establishment of English settlements to the north and French claims to the west. The English attacked St. Augustine, burning the city and its cathedral to the ground several times. Spain built the Castillo de San Marcos in 1672 and Fort Matanzas in 1742 to defend Florida's capital city from attacks, and to maintain its strategic position in the defense of the Captaincy General of Cuba and the Spanish West Indies.		Florida attracted numerous Africans and African-Americans from adjacent British colonies who sought freedom from slavery. In 1738, Governor Manuel de Montiano established Fort Gracia Real de Santa Teresa de Mose near St. Augustine, a fortified town for escaped slaves to whom Montiano granted citizenship and freedom in return for their service in the Florida militia, and which became the first free black settlement legally sanctioned in North America.[17][18]		In 1763, Spain traded Florida to the Kingdom of Great Britain for control of Havana, Cuba, which had been captured by the British during the Seven Years' War. It was part of a large expansion of British territory following their victory in the Seven Years' War. A large portion of the Floridano population left, taking along most of the remaining indigenous population to Cuba.[19] The British soon constructed the King's Road connecting St. Augustine to Georgia. The road crossed the St. Johns River at a narrow point, which the Seminole called Wacca Pilatka and the British named "Cow Ford", both names ostensibly reflecting the fact that cattle were brought across the river there.[20][21][22]		The British divided and consolidated the Florida provinces (Las Floridas) into East Florida and West Florida, a division the Spanish government kept after the brief British period.[23] The British government gave land grants to officers and soldiers who had fought in the French and Indian War in order to encourage settlement. In order to induce settlers to move to Florida, reports of its natural wealth were published in England. A large number of British settlers who were "energetic and of good character" moved to Florida, mostly coming from South Carolina, Georgia and England. There was also a group of settlers who came from the colony of Bermuda. This would be the first permanent English-speaking population in what is now Duval County, Baker County, St. Johns County and Nassau County. The British built good public roads and introduced the cultivation of sugar cane, indigo and fruits as well the export of lumber.[24][25]		As a result of these initiatives northeastern Florida prospered economically in a way it never did under Spanish administration. Furthermore, the British governors were directed to call general assemblies as soon as possible in order to make laws for the Floridas and in the meantime they were, with the advice of councils, to establish courts. This would be the first introduction of much of the English-derived legal system which Florida still has today including trial by jury, habeas corpus and county-based government.[24][25] Neither East Florida nor West Florida would send any representatives to Philadelphia to draft the Declaration of Independence. Florida would remain a Loyalist stronghold for the duration of the American Revolution.[26]		Spain regained both East and West Florida after Britain's defeat in the American Revolution and the subsequent Treaty of Versailles in 1783, and continued the provincial divisions until 1821.		Defense of Florida's northern border with the United States was minor during the second Spanish period. The region became a haven for escaped slaves and a base for Indian attacks against U.S. territories, and the U.S. pressed Spain for reform.		Americans of English descent and Americans of Scots-Irish descent began moving into northern Florida from the backwoods of Georgia and South Carolina. Though technically not allowed by the Spanish authorities and the Floridan government, they were never able to effectively police the border region and the backwoods settlers from the United States would continue to immigrate into Florida unchecked. These migrants, mixing with the already present British settlers who had remained in Florida since the British period, would be the progenitors of the population known as Florida Crackers.[27]		These American settlers established a permanent foothold in the area and ignored Spanish authorities. The British settlers who had remained also resented Spanish rule, leading to a rebellion in 1810 and the establishment for ninety days of the so-called Free and Independent Republic of West Florida on September 23. After meetings beginning in June, rebels overcame the garrison at Baton Rouge (now in Louisiana), and unfurled the flag of the new republic: a single white star on a blue field. This flag would later become known as the "Bonnie Blue Flag".		In 1810, parts of West Florida were annexed by proclamation of President James Madison, who claimed the region as part of the Louisiana Purchase. These parts were incorporated into the newly formed Territory of Orleans. The U.S. annexed the Mobile District of West Florida to the Mississippi Territory in 1812. Spain continued to dispute the area, though the United States gradually increased the area it occupied. In 1812, a group of settlers from Georgia, with de facto support from the U.S. federal government, attempted to overthrow the Floridan government in the province of East Florida. The settlers hoped to convince Floridans to join their cause and proclaim independence from Spain, but the settlers lost their tenuous support from the federal government and abandoned their cause by 1813.[28]		Seminole Indians based in East Florida began raiding Georgia settlements, and offering havens for runaway slaves. The United States Army led increasingly frequent incursions into Spanish territory, including the 1817–1818 campaign against the Seminole Indians by Andrew Jackson that became known as the First Seminole War. The United States now effectively controlled East Florida. Control was necessary according to Secretary of State John Quincy Adams because Florida had become "a derelict open to the occupancy of every enemy, civilized or savage, of the United States, and serving no other earthly purpose than as a post of annoyance to them."[29]		Florida had become a burden to Spain, which could not afford to send settlers or garrisons. Madrid therefore decided to cede the territory to the United States through the Adams-Onís Treaty, which took effect in 1821.[30] President James Monroe was authorized on March 3, 1821 to take possession of East Florida and West Florida for the United States and provide for initial governance.[31] Andrew Jackson, on behalf of the U.S. federal government, served as a military commissioner with the powers of governor of the newly acquired territory for a brief period.[32] On March 30, 1822, the U.S. Congress merged East Florida and part of West Florida into the Florida Territory.[33]		By the early 1800s, Indian removal was a significant issue throughout the southeastern U.S. and also in Florida. In 1830, the U.S. Congress passed the Indian Removal Act and as settlement increased, pressure grew on the United States government to remove the Indians from Florida. Seminoles harbored runaway blacks, known as the Black Seminoles, and clashes between whites and Indians grew with the influx of new settlers. In 1832, the Treaty of Payne's Landing promised to the Seminoles lands west of the Mississippi River if they agreed to leave Florida. Many Seminole left at this time.		Some Seminoles remained, and the U.S. Army arrived in Florida, leading to the Second Seminole War (1835–1842). Following the war, approximately 3,000 Seminole and 800 Black Seminole were removed to Indian Territory. A few hundred Seminole remained in Florida in the Everglades.		On March 3, 1845, Florida became the 27th state to join the United States of America.[34] The state was admitted as a slave state and ceased to be a sanctuary for runaway slaves. Initially its population grew slowly.		As European-American settlers continued to encroach on Seminole lands, and the United States intervened to move the remaining Seminoles to the West. The Third Seminole War (1855–58) resulted in the forced removal of most of the remaining Seminoles, although hundreds of Seminole Indians remained in the Everglades.[35]		American settlers began to establish cotton plantations in northern Florida, which required numerous laborers, which they supplied by buying slaves in the domestic market. By 1860 Florida had only 140,424 people, of whom 44% were enslaved. There were fewer than 1,000 free African Americans before the American Civil War.[36]		In January 1861, nearly all delegates in the Florida Legislature approved an ordinance of secession, declaring Florida to be "a sovereign and independent nation"—an apparent reassertion to the preamble in Florida's Constitution of 1838, in which Florida agreed with Congress to be a "Free and Independent State." Although not directly related to the issue of slavery, the ordinance declared Florida's secession from the Union, allowing it to become one of the founding members of the Confederate States, a looser union of states.		The confederal union received little help from Florida; the 15,000 men it offered were generally sent elsewhere. The largest engagements in the state were the Battle of Olustee, on February 20, 1864, and the Battle of Natural Bridge, on March 6, 1865. Both were Confederate victories.[37] The war ended in 1865.		Following the American Civil War, Florida's congressional representation was restored on June 25, 1868, albeit forcefully after Radical Reconstruction and the installation of unelected government officials under the final authority of federal military commanders. After the Reconstruction period ended in 1876, white Democrats regained power in the state legislature. In 1885 they created a new constitution, followed by statutes through 1889 that disfranchised most blacks and many poor whites.[citation needed]		Until the mid-20th century, Florida was the least populous Southern state. In 1900 its population was only 528,542, of whom nearly 44% were African American, the same proportion as before the Civil War.[38] The boll weevil devastated cotton crops.		Forty thousand blacks, roughly one-fifth of their 1900 population, left the state in the Great Migration. They left due to lynchings and racial violence, and for better opportunities.[39] Disfranchisement for most African Americans in the state persisted until the Civil Rights Movement of the 1960s gained federal legislation in 1965 to enforce protection of their constitutional suffrage.		Historically, Florida's economy was based upon agricultural products such as cattle farming, sugarcane, citrus, tomatoes, and strawberries.		Economic prosperity in the 1920s stimulated tourism to Florida and related development of hotels and resort communities. Combined with its sudden elevation in profile was the Florida land boom of the 1920s, which brought a brief period of intense land development. Devastating hurricanes in 1926 and 1928, followed by the Great Depression, brought that period to a halt. Florida's economy did not fully recover until the military buildup for World War II.		The climate, tempered by the growing availability of air conditioning, and low cost of living made the state a haven. Migration from the Rust Belt and the Northeast sharply increased Florida's population after the war. In recent decades, more migrants have come for the jobs in a developing economy.		With a population of more than 18 million according to the 2010 census, Florida is the most populous state in the Southeastern United States, and the fourth-most populous in the United States.		Key West Historic District		Laura Street in Downtown Jacksonville		The Florida House on Capitol Hill, or "embassy of Florida" in D.C.		Historic Ybor City in Tampa		The Downtown Miami Historic District has some of the oldest buildings in Miami		Much of the state of Florida is situated on a peninsula between the Gulf of Mexico, the Atlantic Ocean and the Straits of Florida. Spanning two time zones, it extends to the northwest into a panhandle, extending along the northern Gulf of Mexico. It is bordered on the north by the states of Georgia and Alabama, and on the west, at the end of the panhandle, by Alabama. It is the only state that borders both the Atlantic Ocean and the Gulf of Mexico.		Florida is west of The Bahamas and 90 miles (140 km) north of Cuba. Florida is one of the largest states east of the Mississippi River, and only Alaska and Michigan are larger in water area. The water boundary is 3 nautical miles (3.5 mi; 5.6 km) offshore in the Atlantic Ocean[40] and 9 nautical miles (10 mi; 17 km) offshore in the Gulf of Mexico.[40]		At 345 feet (105 m) above mean sea level, Britton Hill is the highest point in Florida and the lowest highpoint of any U.S. state.[41] Much of the state south of Orlando lies at a lower elevation than northern Florida, and is fairly level. Much of the state is at or near sea level.		However, some places such as Clearwater have promontories that rise 50 to 100 ft (15 to 30 m) above the water. Much of Central and North Florida, typically 25 mi (40 km) or more away from the coastline, have rolling hills with elevations ranging from 100 to 250 ft (30 to 76 m). The highest point in peninsular Florida (east and south of the Suwannee River), Sugarloaf Mountain, is a 312-foot (95 m) peak in Lake County.[42] On average, Florida is the flattest state in the United States.[43]		The climate of Florida is tempered somewhat by the fact that no part of the state is distant from the ocean. North of Lake Okeechobee, the prevalent climate is humid subtropical (Köppen: Cfa), while areas south of the lake (including the Florida Keys) have a true tropical climate (Köppen: Aw).[44] Mean high temperatures for late July are primarily in the low 90s Fahrenheit (32–34 °C). Mean low temperatures for early to mid January range from the low 40s Fahrenheit (4–7 °C) in northern Florida to above 60 °F (16 °C) from Miami on southward. With an average daily temperature of 70.7 °F (21.5 °C), it is the warmest state in the U.S.[45]		In the summer, high temperatures in the state seldom exceed 100 °F (38 °C). Several record cold maxima have been in the 30s °F (−1 to 4 °C) and record lows have been in the 10s (−12 to −7 °C). These temperatures normally extend at most a few days at a time in the northern and central parts of Florida. Southern Florida, however, rarely encounters freezing temperatures.[citation needed]		The hottest temperature ever recorded in Florida was 109 °F (43 °C), which was set on June 29, 1931 in Monticello. The coldest temperature was −2 °F (−19 °C), on February 13, 1899, just 25 miles (40 km) away, in Tallahassee.[46][47]		Due to its subtropical and tropical climate, Florida rarely receives snow. However, on rare occasions, a combination of cold moisture and freezing temperatures can result in snowfall in the farthest northern regions. Frost is more common than snow, occurring sometimes in the panhandle.[citation needed]		The USDA Plant hardiness zones for the state range from zone 8a (no colder than 10 °F or −12 °C) in the inland western panhandle to zone 11b (no colder than 45 °F or 7 °C) in the lower Florida Keys.[48]		Florida's nickname is the "Sunshine State", but severe weather is a common occurrence in the state. Central Florida is known as the lightning capital of the United States, as it experiences more lightning strikes than anywhere else in the United States.[55] Florida has one of the highest average precipitation levels of any state,[56] in large part because afternoon thunderstorms are common in much of the state from late spring until early autumn. A narrow eastern part of the state including Orlando and Jacksonville receives between 2,400 and 2,800 hours of sunshine annually. The rest of the state, including Miami, receives between 2,800 and 3,200 hours annually.[57]		Florida leads the United States in tornadoes per area (when including waterspouts)[58] but they do not typically reach the intensity of those in the Midwest and Great Plains. Hail often accompanies the most severe thunderstorms.[citation needed]		Hurricanes pose a severe threat each year during the June 1 to November 30 hurricane season, particularly from August to October. Florida is the most hurricane-prone state, with subtropical or tropical water on a lengthy coastline. Of the category 4 or higher storms that have struck the United States, 83% have either hit Florida or Texas.[59] From 1851 to 2006, Florida was struck by 114 hurricanes, 37 of them major—category 3 and above.[59] It is rare for a hurricane season to pass without any impact in the state by at least a tropical storm.[citation needed]		Florida was the site of what was then the costliest weather disaster in U.S. history, Hurricane Andrew, which caused more than $25 billion in damage when it struck in August 1992; it held that distinction until 2005, when Hurricane Katrina surpassed it. Hurricane Wilma—the second-most expensive hurricane in Florida history—landed just south of Marco Island in October 2005.[60][61]		Hurricane Andrew bearing down on Florida on August 23, 1992.		The Royal Poinciana grows in South Florida and blooms in the winter, an indication of South Florida's tropical climate		Summer afternoon showers from the Everglades traveling eastward over Downtown Miami		Fall foliage occurs annually in North Florida.		Snow is uncommon in Florida, but has occurred in every major Florida city at least once.		Winter in Miami. Miami's tropical climate makes it a top tourist destination in the winter.		Florida is host to many types of wildlife including:		The only known calving area for the northern right whale is off the coasts of Florida and Georgia.[66]		The native bear population has risen from a historic low of 300 in the 1970s, to 3,000 in 2011.[67]		Since their accidental importation from South America into North America in the 1930s, the red imported fire ant population has increased its territorial range to include most of the Southern United States, including Florida. They are more aggressive than most native ant species and have a painful sting.[68]		A number of non-native snakes and lizards have been released in the wild. In 2010 the state created a hunting season for Burmese and Indian pythons, African rock pythons, green anacondas, and Nile monitor lizards.[69] Green iguanas have also established a firm population in the southern part of the state.		There are about 500,000 feral pigs in Florida.[70]		Key deer in the lower Florida Keys		The Florida scrub jay is found only in Florida.		West Indian manatee		Florida panther, native of South Florida		Leatherback sea turtle		Whooping crane		There are about 3,000 different types of wildflowers in Florida. This is the third-most diverse state in the union, behind California and Texas, both larger states.[71]		On the east coast of the state, mangroves have normally dominated the coast from Cocoa Beach southward; salt marshes from St. Augustine northward. From St. Augustine south to Cocoa Beach, the coast fluctuates between the two, depending on the annual weather conditions.[65]		Everglades National Park in Southern Florida		Bahia Honda in the Florida Keys		Ocala National Forest in Central and Northern Florida.		Timucuan Ecological and Historic Preserve in Northeast Florida		Florida is a low per capita energy user.[72] It is estimated that approximately 4% of energy in the state is generated through renewable resources.[73] Florida's energy production is 6% of the nation's total energy output, while total production of pollutants is lower, with figures of 6% for nitrogen oxide, 5% for carbon dioxide, and 4% for sulfur dioxide.[73]		All potable water resources have been controlled by the state government through five regional water authorities since 1972.[74]		Red tide has been an issue on the southwest coast of Florida, as well as other areas. While there has been a great deal of conjecture over the cause of the toxic algae bloom, there is no evidence that it is being caused by pollution or that there has been an increase in the duration or frequency of red tides.[75]		The Florida panther is close to extinction. A record 23 were killed in 2009 predominately by automobile collisions, leaving about 100 individuals in the wild. The Center for Biological Diversity and others have therefore called for a special protected area for the panther to be established.[76] Manatees are also dying at a rate higher than their reproduction.		Much of Florida has an elevation of less than 12 feet (3.7 m), including many populated areas. Therefore, it is susceptible to rising sea levels associated with global warming.[77] The Atlantic beaches that are vital to the state's economy are being washed out to sea due to rising sea levels caused by climate change. The Miami beach area, close to the continental shelf, is running out of accessible offshore sand reserves.[78]		The Florida peninsula is a porous plateau of karst limestone sitting atop bedrock known as the Florida Platform. The largest deposits of potash in the United States are found in Florida.[79]		Extended systems of underwater caves, sinkholes and springs are found throughout the state and supply most of the water used by residents. The limestone is topped with sandy soils deposited as ancient beaches over millions of years as global sea levels rose and fell. During the last glacial period, lower sea levels and a drier climate revealed a much wider peninsula, largely savanna.[80] The Everglades, an enormously wide, slow-flowing river encompasses the southern tip of the peninsula. Sinkhole damage claims on property in the state exceeded a total of $2 billion from 2006 through 2010.[81]		Florida is tied for last place as having the fewest earthquakes of any U.S. state.[82][83] Earthquakes are rare because Florida is not located near any tectonic plate boundaries.		The United States Census Bureau estimates that the population of Florida was 20,271,272 on July 1, 2015, a 7.82% increase since the 2010 United States Census.[85] The population of Florida in the 2010 census was 18,801,310.[86] Florida was the seventh fastest-growing state in the U.S. in the 12-month period ending July 1, 2012.[87] In 2010, the center of population of Florida was located between Fort Meade and Frostproof. The center of population has moved less than 5 miles (8 km) to the east and approximately 1 mile (1.6 km) to the north between 1980 and 2010 and has been located in Polk County since the 1960 census.[88] The population exceeded 19.7 million by December 2014, surpassing the population of the state of New York for the first time.[89]		Florida contains the highest percentage of people over 65 (17%).[90] There were 186,102 military retirees living in the state in 2008.[91] About two-thirds of the population was born in another state, the second highest in the U.S.[92]		In 2010, illegal immigrants constituted an estimated 5.7% of the population. This was the sixth highest percentage of any state in the U.S.[93][94] There were an estimated 675,000 illegal immigrants in the state in 2010.[95]		A 2013 Gallup poll indicated that 47% of the residents agreed that Florida was the best state to live in. Results in other states ranged from a low of 18% to a high of 77%.[96]		The legal name in Florida for a city, town or village is "municipality". In Florida there is no legal difference between towns, villages and cities.[97]		In 2012, 75% of the population lived within 10 miles (16 km) of the coastline.[98]		The largest metropolitan area in the state as well as the entire southeastern United States is the Miami metropolitan area, with about 6.06 million people. The Tampa Bay Area, with over 3.02 million people, is the second largest; the Orlando metropolitan area, with over 2.44 million people, is the third; and the Jacksonville metropolitan area, with over 1.47 million people, is fourth.		Florida has 22 Metropolitan Statistical Areas (MSAs) defined by the United States Office of Management and Budget (OMB). 43 of Florida's 67 counties are in a MSA.		Hispanic and Latinos of any race made up 22.5% of the population in 2010.[103] As of 2011, 57% of Florida's population younger than age 1 were minorities (meaning that they had at least one parent who was not non-Hispanic white).[104]		In 2010, 6.9% of the population (1,269,765) considered themselves to be of only American ancestry (regardless of race or ethnicity).[105][106] Many of these were of English or Scotch-Irish descent; however, their families have lived in the state for so long, that they choose to identify as having "American" ancestry or do not know their ancestry.[107][108][109][110][111][112] In the 1980 United States census the largest ancestry group reported in Florida was English with 2,232,514 Floridians claiming that they were of English or mostly English American ancestry.[113] Some of their ancestry went back to the original thirteen colonies.		As of 2010, those of (non-Hispanic white) European ancestry accounted for 57.9% of Florida's population. Out of the 57.9%, the largest groups were 12.0% German (2,212,391), 10.7% Irish (1,979,058), 8.8% English (1,629,832), 6.6% Italian (1,215,242), 2.8% Polish (511,229), and 2.7% French (504,641).[105][106] White Americans of all European backgrounds are present in all areas of the state. In 1970, non-Hispanic whites were nearly 80% of Florida's population.[114] Those of English and Irish ancestry are present in large numbers in all the urban/suburban areas across the state. Some native white Floridians, especially those who have descended from long-time Florida families, may refer to themselves as "Florida crackers"; others see the term as a derogatory one. Like whites in most of the other Southern states, they descend mainly from English and Scots-Irish settlers, as well as some other British American settlers.[115]		As of 2010, those of Hispanic or Latino ancestry accounted for 22.5% (4,223,806) of Florida's population. Out of the 22.5%, the largest groups were 6.5% (1,213,438) Cuban, 4.5% (847,550) Puerto Rican, 3.3% (629,718) Mexican, and 1.6% (300,414) Colombian.[117] Florida's Hispanic population includes large communities of Cuban Americans in Miami and Tampa, Puerto Ricans in Orlando and Tampa, and Mexican/Central American migrant workers. The Hispanic community continues to grow more affluent and mobile. As of 2011, 57.0% of Florida's children under the age of 1 belonged to minority groups.[118] Florida has a large and diverse Hispanic population, with Cubans and Puerto Ricans being the largest groups in the state. Nearly 80% of Cuban Americans live in Florida, especially South Florida where there is a long-standing and affluent Cuban community.[119] Florida has the second largest Puerto Rican population after New York, as well as the fastest-growing in the nation.[120] Puerto Ricans are more widespread throughout the state, though the heaviest concentrations are in the Orlando area of Central Florida.[121]		As of 2010, those of African ancestry accounted for 16.0% of Florida's population, which includes African Americans. Out of the 16.0%, 4.0% (741,879) were West Indian or Afro-Caribbean American.[105][106][117] During the early 1900s, black people made up nearly half of the state's population.[122] In response to segregation, disfranchisement and agricultural depression, many African Americans migrated from Florida to northern cities in the Great Migration, in waves from 1910 to 1940, and again starting in the later 1940s. They moved for jobs, better education for their children and the chance to vote and participate in society. By 1960 the proportion of African Americans in the state had declined to 18%.[123] Conversely large numbers of northern whites moved to the state.[citation needed] Today, large concentrations of black residents can be found in northern and central Florida. Aside from blacks descended from African slaves brought to the US south, there are also large numbers of blacks of West Indian, recent African, and Afro-Latino immigrant origins, especially in the Miami/South Florida area. In 2010, Florida had the highest percentage of West Indians in the United States, with 2.0% (378,926) from Haitian ancestry, 1.3% (236,950) Jamaican,[124] and 0.13% Bahamian [125]All other (non-Hispanic) Caribbean nations were well below 0.1% of Florida residents.[124][126]		As of 2010, those of Asian ancestry accounted for 2.4% of Florida's population.[105][106]		In 1988 English was affirmed as the state's official language in the Florida Constitution. Spanish is also widely spoken, especially as immigration has continued from Latin America. Twenty percent of the population speak Spanish as their first language. Twenty-seven percent of Florida's population reports speaking a mother language other than English, and more than 200 first languages other than English are spoken at home in the state.[127][128]		The most common languages spoken in Florida as a first language in 2010 are:[127]		The 2014 Pew Religious Landscape Survey showed the religious makeup of the state was as follows:[129]		In 2010, the three largest denominational groups in Florida were the Roman Catholic Church, the Southern Baptist Convention, and the United Methodist Church.[130]		Florida is mostly Protestant, but Roman Catholicism is the single largest denomination in the state, due in significant part to the state's large Hispanic population. There is also a sizable Jewish community, located mainly in South Florida; this is the largest Jewish population in the South and the third-largest in the U.S. behind those of New York and California.[131]		The basic structure, duties, function, and operations of the government of the state of Florida are defined and established by the Florida Constitution, which establishes the basic law of the state and guarantees various rights and freedoms of the people. The state government consists of three separate branches: judicial, executive, and legislative. The legislature enacts bills, which, if signed by the governor, become law.		The Florida Legislature comprises the Florida Senate, which has 40 members, and the Florida House of Representatives, which has 120 members. The current Governor of Florida is Rick Scott. The Florida Supreme Court consists of a Chief Justice and six Justices.		Florida has 67 counties. Some reference materials may show only 66 because Duval County is consolidated with the City of Jacksonville. There are 379 cities in Florida (out of 411) that report regularly to the Florida Department of Revenue, but there are other incorporated municipalities that do not. The state government's primary source of revenue is sales tax. Florida does not impose a personal income tax. The primary revenue source for cities and counties is property tax; unpaid taxes are subject to tax sales which are held (at the county level) in May and (due to the extensive use of online bidding sites) are highly popular.		There were 800 federal corruption convictions from 1988 to 2007, more than any other state.[132]		From 1952 to 1964, most voters were registered Democrats, but the state voted for the Republican presidential candidate in every election except for 1964. The following year, Congress passed and President Lyndon B. Johnson signed the Voting Rights Act of 1965, providing for oversight of state practices and enforcement of constitutional voting rights for African Americans and other minorities in order to prevent the discrimination and disenfranchisement that had excluded most of them for decades from the political process.		From the 1930s through much of the 1960s, Florida was essentially a one-party state dominated by white conservative Democrats, who together with other Democrats of the Solid South, exercised considerable control in Congress. They gained federal money from national programs; like other southern states, Florida residents have received more federal monies than they pay in taxes: the state is a net beneficiary. Since the 1970s, the conservative white majority of voters in the state has largely shifted from the Democratic to the Republican Party. It has continued to support Republican presidential candidates through the 20th century, except in 1976 and 1996, when the Democratic nominee was from the South. They have had "the luxury of voting for presidential candidates who pledge to cut taxes and halt the expansion of government while knowing that their congressional delegations will continue to protect federal spending."[134]		In the 2008 and 2012 presidential elections, Barack Obama carried the state as a northern Democrat, attracting high voter turnout especially among the young, Independents, and minority voters, of whom Hispanics comprise an increasingly large proportion. 2008 marked the first time since 1932, when Franklin D. Roosevelt carried the state, that Florida was carried by a Northern Democrat for president.		The first post-Reconstruction era Republican elected to Congress from Florida was William C. Cramer in 1954 from Pinellas County on the Gulf Coast,[135] where demographic changes were underway. In this period, African Americans were still disenfranchised by the state's constitution and discriminatory practices; in the 19th century they had made up most of the Republican Party. Cramer built a different Republican Party in Florida, attracting local white conservatives and transplants from northern and midwestern states. In 1966 Claude R. Kirk, Jr. was elected as the first post-Reconstruction Republican governor, in an upset election.[136] In 1968 Edward J. Gurney, also a white conservative, was elected as the state's first post-reconstruction Republican US Senator.[137] In 1970 Democrats took the governorship and the open US Senate seat, and maintained dominance for years.		Since the mid-20th century, Florida has been considered a bellwether, voting for 13 successful presidential candidates since 1952. It voted for the loser only three times.[138]		In 1998, Democratic voters dominated areas of the state with a high percentage of racial minorities and transplanted white liberals from the northeastern United States, known colloquially as "snowbirds".[139] South Florida and the Miami metropolitan area are dominated by both racial minorities and white liberals. Because of this, the area has consistently voted as one of the most Democratic areas of the state. The Daytona Beach area is similar demographically and the city of Orlando has a large Hispanic population, which has often favored Democrats. Republicans, made up mostly of white conservatives, have dominated throughout much of the rest of Florida, particularly in the more rural and suburban areas. This is characteristic of its voter base throughout the Deep South.[139]		The fast-growing I-4 corridor area, which runs through Central Florida and connects the cities of Daytona Beach, Orlando, and Tampa/St. Petersburg, has had a fairly even breakdown of Republican and Democratic voters. The area is often seen as a merging point of the conservative northern portion of the state and the liberal southern portion, making it the biggest swing area in the state. Since the late 20th century, the voting results in this area, containing 40% of Florida voters, has often determined who will win the state of Florida in presidential elections.[140]		The Democratic Party has maintained an edge in voter registration, both statewide and in 40 of the 67 counties, including Miami-Dade, Broward, and Palm Beach counties, the state's three most populous.[141]		In 2000, George W. Bush won the U.S. Presidential election by a margin of 271–266 in the Electoral College.[142] Of the 271 electoral votes for Bush, 25 were cast by electors from Florida.[143] The Florida results were contested and a recount was ordered by the court, with the results settled in a court decision.		Reapportionment following the 2010 United States Census gave the state two more seats in the House of Representatives.[144] The legislature's redistricting, announced in 2012, was quickly challenged in court, on the grounds that it had unfairly benefited Republican interests. In 2015, the Florida Supreme Court ruled on appeal that the congressional districts had to be redrawn because of the legislature's violation of the Fair District Amendments to the state constitution passed in 2010; it accepted a new map in early December 2015.		The political make-up of congressional and legislative districts has enabled Republicans to control the governorship and most statewide elective offices, and 17 of the state's 27 seats in the 2012 House of Representatives.[145] Florida has been listed as a swing state in Presidential elections since 1950, voting for the losing candidate once in that period of time.[146]		In the closely contested 2000 election, the state played a pivotal role.[142][143][147][148][149][150] Out of more than 5.8 million votes for the two main contenders Bush and Al Gore, around 500 votes separated the two candidates for the all-decisive Florida electoral votes that landed Bush the election win. Florida's felony disenfranchisement law is more severe than most European nations or other American states. A 2002 study in the American Sociological Review concluded that "if the state's 827,000 disenfranchised felons had voted at the same rate as other Floridians, Democratic candidate Al Gore would have won Florida—and the presidency—by more than 80,000 votes."[151]		In 2008, delegates of both the Republican Florida primary election and Democratic Florida primary election were stripped of half of their votes when the conventions met in August due to violation of both parties' national rules.		In the 2010 elections, Republicans solidified their dominance statewide, by winning the governor's mansion, and maintaining firm majorities in both houses of the state legislature. They won four previously Democratic-held seats to create a 19–6 Republican-majority delegation representing Florida in the federal House of Representatives.		In 2010, more than 63% of state voters approved the initiated Amendments 5 and 6 to the state constitution, to ensure more fairness in districting. These have become known as the Fair District Amendments. As a result of the 2010 United States Census, Florida gained two House of Representative seats in 2012.[144] The legislature issued revised congressional districts in 2012, which were immediately challenged in court by supporters of the above amendments.		The court ruled in 2014, after lengthy testimony, that at least two districts had to be redrawn because of gerrymandering. After this was appealed, in July 2015 the Florida Supreme Court ruled that lawmakers had followed an illegal and unconstitutional process overly influenced by party operatives, and ruled that at least eight districts had to be redrawn. On December 2, 2015, a 5-2 majority of the Court accepted a new map of congressional districts, some of which was drawn by challengers. Their ruling affirmed the map previously approved by Leon County Judge Terry Lewis, who had overseen the original trial. It particularly makes changes in South Florida. There are likely to be additional challenges to the map and districts.[152]		According to The Sentencing Project, the effect of Florida's felony disenfranchisement law is such that in 2014, "[m]ore than one in ten Floridians – and nearly one in four African-American Floridians – are [were] shut out of the polls because of felony convictions," although they had completed sentences and parole/probation requirements.[153]		The state repealed mandatory auto inspection in 1981.[154]		In 1972, the state made personal injury protection auto insurance mandatory for drivers, becoming the second in the nation to enact a no-fault insurance law. The ease of receiving payments under this law is seen as precipitating a major increase in insurance fraud.[155] Auto insurance fraud was the highest in the nation in 2011, estimated at close to $1 billion.[156] Fraud is particularly centered in the Miami-Dade metropolitan and Tampa areas.[157][158][159]		Florida was ranked the fifth-most dangerous state in 2009. Ranking was based on the record of serious felonies committed in 2008.[160] The state was the sixth highest scammed state in 2010. It ranked first in mortgage fraud in 2009.[161]		In 2009, 44% of highway fatalities involved alcohol.[162] Florida is one of seven states that prohibit the open carry of handguns. This law was passed in 1987.[163]		According to the Federal Trade Commission, Florida has the highest per capita rate of both reported fraud and other types of complaints and reported including identity theft complaints.[164]		In the twentieth century, tourism, industry, construction, international banking, biomedical and life sciences, healthcare research, simulation training, aerospace and defense, and commercial space travel have contributed to the state's economic development.[citation needed]		The Gross Domestic Product (GDP) of Florida in 2016 was $926 billion.[167] Its GDP is the fourth largest economy in the United States.[168] In 2010, it became the fourth largest exporter of trade goods.[169] The major contributors to the state's gross output in 2007 were general services, financial services, trade, transportation and public utilities, manufacturing and construction respectively. In 2010–11, the state budget was $70.5 billion, having reached a high of $73.8 billion in 2006–07.[170] Chief Executive Magazine name Florida the third "Best State for Business" in 2011.[171]		The economy is driven almost entirely by its nineteen metropolitan areas. In 2004, they had a combined total of 95.7% of the state's domestic product.[172]		In 2011, Florida's per capita personal income was $39,563, ranking 27th in the nation.[173] In February 2011, the state's unemployment rate was 11.5%.[174] Florida is one of seven states that do not impose a personal income tax.		Florida's constitution establishes a state minimum wage that is adjusted for inflation annually. As of January 1, 2017, Florida's minimum wage was $5.08 for tipped positions, and $8.10 for non-tipped positions, which was higher than the federal rate of $7.25.[175]		Florida has 4 cities in the top 25 cities in the U.S. with the most credit card debt.[176] The state also had the second-highest credit card delinquency rate, with 1.45% of cardholders in the state more than 90 days delinquent on one or more credit cards.[177]		There were 2.4 million Floridians living in poverty in 2008. 18.4% of children 18 and younger were living in poverty.[178] Miami is the sixth poorest big city in the United States.[179] In 2010, over 2.5 million Floridians were on food stamps, up from 1.2 million in 2007. To qualify, Floridians must make less than 133% of the federal poverty level, which would be under $29,000 for a family of four.[180]		In the early 20th century, land speculators discovered Florida, and businessmen such as Henry Plant and Henry Flagler developed railroad systems, which led people to move in, drawn by the weather and local economies. From then on, tourism boomed, fueling a cycle of development that overwhelmed a great deal of farmland.		Because of the collective effect on the insurance industry of the hurricane claims of 2004, homeowners insurance has risen 40% to 60% and deductibles have risen.[60]		At the end of the third quarter in 2008, Florida had the highest mortgage delinquency rate in the U.S., with 7.8% of mortgages delinquent at least 60 days.[177] A 2009 list of national housing markets that were hard hit in the real estate crash included a disproportionate number in Florida.[181] The early 21st-century building boom left Florida with 300,000 vacant homes in 2009, according to state figures.[182] In 2009, the US Census Bureau estimated that Floridians spent an average 49.1% of personal income on housing-related costs, the third highest percentage in the U.S.[183]		In the third quarter of 2009, there were 278,189 delinquent loans, 80,327 foreclosures.[184] Sales of existing homes for February 2010 was 11,890, up 21% from the same month in 2009. Only two metropolitan areas showed a decrease in homes sold: Panama City and Brevard County. The average sales price for an existing house was $131,000, 7% decrease from the prior year.[185][dubious – discuss]		If you can't find something to do in Florida, you're just boring...		Tourism makes up one of the largest sectors of the state economy, with nearly 1.4 million persons employed in the tourism industry in 2016 (a record for the state, surpassing the 1.2 million employment from 2015).[187][188] In 2015, Florida broke the 100-million visitor mark for the first time in state history by hosting a record 105 million visitors[188][189] and broke that record in 2016 with 112.8 million tourists; Florida has set tourism records for six consecutive years.[187]		Many beach towns are popular tourist destinations, particularly during winter and spring break. Twenty-three million tourists visited Florida beaches in 2000, spending $22 billion.[190] The public has a right to beach access under the public trust doctrine, but some areas have access effectively blocked by private owners for a long distance.[191]		Amusement parks, especially in the Greater Orlando area, make up a significant portion of tourism. The Walt Disney World Resort is the most visited vacation resort in the world with over 50 million annual visitors, consisting of four theme parks, 27 themed resort hotels, 9 non–Disney hotels, two water parks, four golf courses and other recreational venues.[192] Other major theme parks in the area include Universal Orlando Resort, SeaWorld Orlando and Busch Gardens Tampa.		Agriculture is the second largest industry in the state. Citrus fruit, especially oranges, are a major part of the economy, and Florida produces the majority of citrus fruit grown in the United States. In 2006, 67% of all citrus, 74% of oranges, 58% of tangerines, and 54% of grapefruit were grown in Florida. About 95% of commercial orange production in the state is destined for processing (mostly as orange juice, the official state beverage).[193]		Citrus canker continues to be an issue of concern. From 1997 to 2013, the growing of citrus trees has declined 25%, from 600,000 acres (240,000 ha) to 450,000 acres (180,000 ha). Citrus greening disease is incurable. A study states that it has caused the loss of $4.5 billion between 2006 and 2012. As of 2014, it was the major agricultural concern.[194]		Other products include sugarcane, strawberries, tomatoes and celery.[195] The state is the largest producer of sweet corn and green beans for the U.S.[196]		The Everglades Agricultural Area is a major center for agriculture. The environmental impact of agriculture, especially water pollution, is a major issue in Florida today.		In 2009, fishing was a $6 billion industry, employing 60,000 jobs for sports and commercial purposes.[197]		Florida is the leading state for sales of power boats. There were $1.96 billion worth of boats sold in 2013.[199]		Phosphate mining, concentrated in the Bone Valley, is the state's third-largest industry. The state produces about 75% of the phosphate required by farmers in the United States and 25% of the world supply, with about 95% used for agriculture (90% for fertilizer and 5% for livestock feed supplements) and 5% used for other products.[200]		After the watershed events of Hurricane Andrew in 1992, the state of Florida began investing in economic development through the Office of Trade, Tourism, and Economic Development. Governor Jeb Bush realized that watershed events such as Andrew negatively impacted Florida's backbone industry of tourism severely. The office was directed to target Medical/Bio-Sciences among others. Three years later, The Scripps Research Institute (TSRI) announced it had chosen Florida for its newest expansion. In 2003, TSRI announced plans to establish a major science center in Palm Beach, a 364,000 square feet (33,800 m2) facility on 100 acres (40 ha), which TSRI planned to occupy in 2006.[201]		Since the development of the federal NASA Merritt Island launch sites on Cape Canaveral (most notably Kennedy Space Center) in 1962, Florida has developed a sizable aerospace industry.		Another major economic engine in Florida is the United States military. There are 24 military bases in the state, housing three Unified Combatant Commands; United States Central Command in Tampa, United States Southern Command in Doral, and United States Special Operations Command in Tampa. Some 109,390 U.S. military personnel stationed in Florida,[202] contributing, directly and indirectly, $52 billion a year to the state's economy.[203]		In 2009, there were 89,706 federal workers employed within the state.[204] Tens of thousands more employees work for contractors who have federal contracts, including those with the military.		In 2012, government of all levels was a top employer in all counties in the state, because this classification includes public school teachers and other school staff. School boards employ nearly 1 of every 30 workers in the state. The federal military was the top employer in three counties.[205]		There were 2.7 million Medicaid patients in Florida in 2009. The governor has proposed adding $2.6 billion to care for the expected 300,000 additional patients in 2011.[206] The cost of caring for 2.3 million clients in 2010 was $18.8 billion.[207] This is nearly 30% of Florida's budget.[208] Medicaid paid for 60% of all births in Florida in 2009.[61] The state has a program for those not covered by Medicaid.		In 2013, Florida refused to participate in providing coverage for the uninsured under the Affordable Care Act, popularly called Obamacare. The Florida legislature also refused to accept additional Federal funding for Medicaid, although this would have helped its constituents at no cost to the state. As a result, Florida is second only to Texas in the percentage of its citizens without health insurance.[209]		Florida has the largest collection of Art Deco and Streamline Moderne buildings in both the United States and the entire world, most of which are located in the Miami metropolitan area, especially Miami Beach's Art Deco District, constructed as the city was becoming a resort destination.[210] A unique architectural design found only in Florida is the post-World War II Miami Modern, which can be seen in areas such as Miami's MiMo Historic District.		Being of early importance as a regional center of banking and finance, the architecture of Jacksonville displays a wide variety of styles and design principles. Many of state's earliest skyscrapers were constructed in Jacksonville, dating as far back as 1902,[211] and last holding a state height record from 1974 to 1981.[212] The city is endowed with one of the largest collections of Prairie School buildings outside of the Midwest.[213] Jacksonville is also noteworthy for its collection of Mid-Century modern architecture.[214]		Some sections of the state feature architectural styles including Spanish revival, Florida vernacular, and Mediterranean Revival.[215][216] A notable collection of these styles can be found in St. Augustine, the oldest continuously occupied European-established settlement within the borders of the United States.[217]		Florida's public primary and secondary schools are administered by the Florida Department of Education. School districts are organized within county boundaries. Each school district has an elected Board of Education which sets policy, budget, goals, and approves expenditures. Management is the responsibility of a Superintendent of schools.		The Florida Department of Education is required by law to train educators in teaching English for Speakers of Other Languages (ESOL).[218]		The State University System of Florida was founded in 1905, and is governed by the Florida Board of Governors. During the 2010 academic year, 312,216 students attended one of these twelve universities. The Florida College System comprises 28 public community and state colleges. In 2011–12, enrollment consisted of more than 875,000 students.[219] As of 2017 the University of Central Florida, with over 64,000 students, is the largest university by enrollment in the United States.[220]		Florida's first private university, Stetson University, was founded in 1883. The Independent Colleges and Universities of Florida is an association of 28 private, educational institutions in the state.[221] This Association reported that their member institutions served over 121,000 students in the fall of 2006.[222]		In 2016, Florida charged the second lowest tuition in the nation for four years, $26,000 for in-state students, to $86,000 for out-of-state students. This compares with an average of 34,800 nationally for in-state students.[223]		Florida State University Tallahassee		University of Florida Gainesville		Florida Gulf Coast University Fort Myers		Flagler College Saint Augustine		University of Miami Coral Gables		University of Central Florida Orlando		Florida's highway system contains 1,473 mi (2,371 km) of interstate highway, and 9,934 mi (15,987 km) of non-interstate highway, such as state highways and U.S. Highways. Florida's interstates, state highways, and U.S. Highways are maintained by the Florida Department of Transportation.		In 2011, there were about 9,000 retail gas stations in the state. Floridians consume 21 million gallons of gasoline daily, ranking it third in national use.[224][225] Motorists have the 45th lowest rate of car insurance in the U.S. 24% are uninsured.[226]		Drivers between 15 and 19 years of age averaged 364 car crashes a year per ten thousand licensed Florida drivers in 2010. Drivers 70 and older averaged 95 per 10,000 during the same time frame. A spokesperson for the non-profit Insurance Institute said that "Older drivers are more of a threat to themselves."[227]		Before the construction of routes under the Federal Aid Highway Act of 1956, Florida began construction of a long cross-state toll road, Florida's Turnpike. The first section, from Fort Pierce south to the Golden Glades Interchange was completed in 1957. After a second section north through Orlando to Wildwood (near present-day The Villages), and a southward extension around Miami to Homestead, it was finished in 1974.		Florida's primary interstate routes include:		Florida has 131 public airports.[228] Florida's seven large hub and medium hub airports, as classified by the FAA, are the following:		Florida is served by Amtrak, operating numerous lines throughout, connecting the state's largest cities to points north in the United States and Canada. The busiest Amtrak train stations in Florida in 2011 were: Sanford (259,944), Orlando (179,142), Tampa Union Station (140,785), Miami (94,556), and Jacksonville (74,733).[229] Sanford, in Greater Orlando, is the southern terminus of the Auto Train, which originates at Lorton, Virginia, south of Washington, D.C. Until 2005, Orlando was also the eastern terminus of the Sunset Limited, which travels across the southern United States via New Orleans, Houston, and San Antonio to its western terminus of Los Angeles. Florida is served by two additional Amtrak trains (the Silver Star and the Silver Meteor), which operate between New York City and Miami. Miami Central Station, the city's rapid transit, commuter rail, intercity rail, and bus hub, is under construction.		The Florida Department of Transportation was preparing to build a high-speed rail between Tampa, Lakeland and Orlando.[230] This was to be the first phase of the Florida High Speed Rail system.[231] Soil work began in July 2010[232][233] and construction of the line was slated to begin in 2011, with the initial Tampa-Orlando phase completed by 2014.[234] The second phase, would have extended the line to Miami. Governor Scott, however, refused federal funds and the project has been canceled.		All Aboard Florida is a proposed higher-speed rail service that would run between Orlando and Miami at speeds up to 125 mph. Its Miami to Cocoa portion is scheduled to open in 2016, with the final segment to Orlando opening in 2017.		Florida has three NFL teams, two MLB teams, two NBA teams, two NHL teams, and one MLS team. Florida gained its first permanent major-league professional sports team in 1966 when the American Football League added the Miami Dolphins. The state of Florida has given professional sports franchises some subsidies in the form of tax breaks since 1991.[240]		About half of all Major League Baseball teams conduct spring training in the state, with teams informally organized into the "Grapefruit League". Throughout MLB history, other teams have held spring training in Florida.		NASCAR (headquartered in Daytona Beach) begins all three of its major auto racing series in Florida at Daytona International Speedway in February, featuring the Daytona 500, and ends all three Series in November at Homestead-Miami Speedway. Daytona also has the Coke Zero 400 NASCAR race weekend around Independence Day in July. The 24 Hours of Daytona is one of the world's most prestigious endurance auto races. The Grand Prix of St. Petersburg and Grand Prix of Miami have held IndyCar races as well.		The PGA of America is headquartered in Palm Beach Gardens, the PGA Tour is headquartered in Ponte Vedra Beach, and the LPGA is headquartered in Daytona Beach. The Players Championship, WGC-Cadillac Championship, Arnold Palmer Invitational, Honda Classic and Valspar Championship are PGA Tour rounds.		The Miami Masters is an ATP World Tour Masters 1000 and WTA Premier tennis event, whereas the Delray Beach International Tennis Championships is an ATP World Tour 250 event.		Minor league baseball, football, basketball, ice hockey, soccer and indoor football teams are based in Florida. Three of the Arena Football League's teams are in Florida.		Florida's universities have a number of collegiate sport programs, especially the Florida State Seminoles and Miami Hurricanes of the Atlantic Coast Conference and the Florida Gators of the Southeastern Conference.				Coordinates: 28°06′N 81°36′W﻿ / ﻿28.1°N 81.6°W﻿ / 28.1; -81.6		
Cuspate forelands, also known as cuspate barriers or nesses in Britain, are geographical features found on coastlines and lakeshores that are created primarily by longshore drift.[1] Formed by accretion and progradation of sand and shingle, they extend outwards from the shoreline in a triangular shape.[1] Some cuspate forelands may be stabilised by vegetation, while others may migrate down the shoreline. Because some cuspate forelands provide an important habitat for many flora and fauna, effective management is required to reduce the impacts from both human activities and physical factors such as climate change and sea level rise.						The debate involving how cuspate forelands form is ongoing.[2] However, the most widely accepted process of formation involves long shore drift.[1] Where longshore drift occurs in opposite directions, two spits merge into a triangular protrusion along a coastline or lakeshore.[1] Their formation is also dependent on dominant and prevailing winds working in opposite directions.[1] Formation can also occur when waves are diffracted around a barrier.[3]		Cuspate forelands can form both along coastlines and along lakeshores. Those formed along coastlines can be in the lee of an offshore island, along a coastline that has no islands in the vicinity, or at a stream mouth where disposition occurs.[4]		A cuspate foreland can form in a strait or along a coastline that has no islands or shoals in the area.[4] In this case, longshore drift as well as prevailing wind and waves bring sediment together from opposite directions.[2] If there is a large angle between the waves and the shoreline, the sediment converges, accumulates, and forms beach ridges.[2][5] Over time, a cuspate foreland forms as a result of continued accretion and progradation.[4] An example of this type of cuspate foreland is the one found at Dungeness along the southern coast of Britain.[6] This cuspate foreland has formed as a result of the merging of SW waves from the English Channel, and waves from the east from the Strait of Dover.[4] Another example is the cuspate foreland found between Awatere River and White Bluffs in Marlborough, New Zealand.[7] This foreland has ridges on the eastern and northern sides which face the prominent waves.[7]		In other circumstances, spits are formed when long shore drift moves beach material down the beach until the coastline makes an abrupt change in direction, leading to the beach material 'spilling over' the corner to create a protrusion. This normally occurs across a river mouth. In the case of a cuspate foreland, the prevailing wind and a powerful secondary wind in the opposite direction move shingle down the coastline from both directions to a place where the coastline changes, causing a foreland to develop.[8] The majority of cuspate forelands are formed over a coastline that juts out into the sea at enough of an angle to allow the drifting beach material to 'spill over' as a result of long shore drift in both directions.		A cuspate foreland can form in the lee of an island. In this case, oncoming waves are diffracted around the island, protecting the coastline from the oncoming wave fronts.[1] Sediments brought along the shoreline via longshore drift are then able to settle and accumulate in the lee of the island where there is less wave energy.[1] This type of foreland has formed on the west shore of the North Island of New Zealand, in the lee of Kapiti Island.[9] Waves refract around Kapiti Island, forming an area of low wave energy where sediment from the Waikanae River is able to settle.[9] There is uncertainty whether the cuspate foreland has formed as a result of sediments coming from the north via longshore drift, or whether it has formed as a result of a complex cycle of sediments moving out to the continental shelf and then back again.[9]		As well as forming along coastlines, cuspate forelands can also form along lake shores, although less is known about this type of cuspate foreland. This type of cuspate foreland includes Point Pelee along the shoreline of Lake Erie, and those found along the shoreline of Lake Victoria in Australia. There are two theories with regard to the formation of Point Pelee. Firstly, it is thought that Point Pelee has formed from depositional processes.[10] Alternatively, it is suggested that Point Pelee is a relic of a past feature that has eroded over time.[10] This gap in knowledge provides the opportunity for further research. It is likely that Point Pelee is migrating westwards since accretion is occurring on the western side, and erosion is occurring on the eastern side.[10] Lake Victoria in Australia also has a number of cuspate forelands. Point Scott is a cuspate foreland along this lakeshore that has formed from the gradual accumulation of sand and gravel.[11]		Cuspate forelands can be separated into three distinct areas: the central nose or apex, and two marginal wings.[9] The apex usually has ridges that run parallel to the converging shorelines.[6] Cuspate forelands can extend up to 5 km from the shoreline, and an underwater shoal may extend much further, up to 15 km from the exposed apex.[2] Located between the mainland and the foreland are often lagoons or marshy areas.[6] In some areas, such as along the North Carolina coastline, a series of cuspate forelands may form at least 100 km apart.[5] In areas that have a large amount of shingle, such as the cuspate foreland at Dungeness, it is also common for a fresh water table to be present.[12]		Once formed, cuspate forelands can remain where they are and continue to develop as sediment accumulates, or alternatively they may migrate down the coast as one side of the foreland erodes and the other side accretes.[4] Cuspate Forelands that move are typical of those that are formed on open coastlines.[1] The direction of migration is often indicated by a series of successive beach ridges on the advancing side of the foreland where there is less wave energy.[1][4] The movement of cuspate forelands is commonly explained by longshore drift acting as the main process. However, there have been observed cases where two cuspate forelands on the same shoreline have migrated in opposite directions, showing that longshore drift does not always provide a sufficient explanation for their migration.[1]		If there is an offshore sandbank present, the position of the cuspate foreland is usually related to its position.[1] If there is a change in the position of the sandbank, the position of the cuspate foreland typically follows.[1] Not only does the sandbank act like an island since it causes waves to refract around it, but it also provides a source of sediment.[1] As sand erodes from the sandbank, it is pushed towards the coastline, contributing to the formation of the cuspate foreland as the sandbank migrates along the coast.[1] This often occurs in the opposite direction to longshore drift.[1]		In the case of a cuspate foreland that has formed close to an island, it is possible for it to extend right up to the island, forming a tombolo.[1] Depending on the physical conditions such as storms, the feature can alternate between a cuspate foreland and a tombolo.[1] Gabo Island in South Australia is an example of where this occurs.[1]		After the formation of the cuspate foreland into its distinctive triangular shape, it will start to be colonised by pioneer species that are hardy and tough enough to survive in the environment. These pioneer species secure the cuspate foreland and allow a greater amount of sediment to further secure it. Colonization and succession of vegetation is dependent on a number of factors. Firstly, if the shingle is too coarse, the amount of fine sediment that can remain between the spaces is reduced, and the likelihood that seeds will germinate and grow upwards is low.[12] Seeds will also fail to germinate and grow if there is insufficient retention of fresh water.[12] Stable cuspate forelands that are composed of shingle often have vegetation above the high tide line.[12] As vegetation is established, mites and collembolans break down plant matter such as roots, resulting in the accumulation of organic matter.[12] Plants also cause the soil to develop and water retention to increase, therefore providing a habitat where more plants can grow.[12] Vegetation above the high tide line is common on cuspate forelands that are stable and composed of shingle.[12]		Cuspate forelands provide a habitat for various flora and fauna. If a foreland is relatively stable and experiences low wave impact, it may be possible for vegetation to grow.[12] In the United Kingdom, 11 taxa of invertebrates are found on shingle habitats.[12] Shingle beaches also provide a habitat for birds to breed, nest, and rest en route while migrating.[12]		There are different management issues with regard to cuspate forelands depending on their formation. If a cuspate foreland has formed from deposition, it may be vulnerable if human interference alters the transport of sediments from the shoreline.[10] However, if the cuspate foreland is a relic of a past feature that has eroded, human interference with longshore sediment movement will not have a significant impact on the cuspate foreland.[10] For a cuspate foreland to be maintained, the input of sediment must be greater than output of sediment.[10] Activities such as coastal development or engineering must be regulated for sediment to continue moving towards the foreland where it can be deposited.[11] Development along cuspate forelands is risky due to erosion and the vulnerability to storms and sea level rise.[11][12] As sea levels rise, cuspate forelands are likely to be at risk as they could move inland.[12]		At Point Pelee, approximately 1,900 hectares of former agricultural land on the cuspate foreland is now under water as a result of wind erosion and compaction of organic soils on the foreland.[10] This foreland is particularly vulnerable to erosion when high lake levels are combined with spring and autumn cyclonic activity.[10] Erosion can also occur as spring storms cause ice to scour the lake bottom at the edge of the foreland.[10] Because there is uncertainty about its formation, there is uncertainty with regard to management, although Parks Canada realises the importance of including Point Pelee National Park in management plans.[10][13]		When there is an aquifer present under a cuspate foreland, regulation of water removal is required. At Dungeness, water restrictions have been put in place to maintain the aquifer level.[12]		The management of coastlines needs to take into account the natural processes that occur on cuspate forelands since many provide a habitat for birds. Alternative ways of managing coastal erosion is needed, such as the use of ‘soft’ defences instead of high impact defences such as sea walls.[12] Some cuspate forelands naturally do not contain any vegetation due to a high level of disturbance from physical factors such as wave action.[12] However, with the frequency of storms arising from climate change, the effect on forelands and their associated vegetation needs to be effectively managed.		
A discordant coastline occurs where bands of different rock type run perpendicular to the coast.		The differing resistance to erosion leads to the formation of headlands and bays. A hard rock type such as granite is resistant to erosion and creates a promontory whilst a softer rock type such as the clays of Bagshot Beds is easily eroded creating a bay.		Part of the Dorset coastline running north from the Portland limestone of Durlston Head is a clear example of a discordant coastline. The Portland limestone is resistant to erosion; then to the north there is a bay at Swanage where the rock type is a softer greensand. North of Swanage, the chalk outcrop creates the headland which includes Old Harry Rocks.		The converse of a discordant coastline is a concordant coastline.				
Coordinates: 40°N 4°W﻿ / ﻿40°N 4°W﻿ / 40; -4		– in Europe  (green & dark grey) – in the European Union  (green)		Spain (Spanish: España [esˈpaɲa] ( listen)), officially the Kingdom of Spain (Spanish: Reino de España),[a][b] is a sovereign state located on the Iberian Peninsula in southwestern Europe, with two large archipelagoes, the Balearic Islands in the Mediterranean Sea and the Canary Islands off the North African Atlantic coast, two cities, Ceuta and Melilla, in the North African mainland and several small islands in the Alboran Sea near the Moroccan coast. The country's mainland is bordered to the south and east by the Mediterranean Sea except for a small land boundary with Gibraltar; to the north and northeast by France, Andorra, and the Bay of Biscay; and to the west and northwest by Portugal and the Atlantic Ocean. It is the only European country to have a border with an African country (Morocco)[h] and its African territory accounts for nearly 5% of its population, mostly in the Canary Islands but also in Ceuta and Melilla.		With an area of 505,990 km2 (195,360 sq mi), Spain is the largest country in Southern Europe, the second largest country in Western Europe and the European Union, and the fourth largest country in the European continent. By population, Spain is the sixth largest in Europe and the fifth in the European Union. Spain's capital and largest city is Madrid; other major urban areas include Barcelona, Valencia, Seville, Bilbao and Málaga.		Modern humans first arrived in the Iberian Peninsula around 35,000 years ago. Iberian cultures along with ancient Phoenician, Greek and Carthaginian settlements developed on the peninsula until it came under Roman rule around 200 BCE, after which the region was named Hispania, based on the earlier Phoenician name Span or Spania.[10] In the Middle Ages, the area was conquered by Germanic tribes and later by the Moors. Spain emerged as a unified country in the 15th century, following the marriage of the Catholic Monarchs and the completion of the eight centuries-long reconquest, or Reconquista from the Moors in 1492. In the early modern period, Spain became one of history's first global colonial empires, leaving a vast cultural and linguistic legacy that includes over 500 million Spanish speakers, making Spanish the world's second most spoken first language, after Mandarin Chinese.		Spain is a parliamentary democracy and constitutional monarchy. The current Spanish king is Felipe VI. It is a middle power and a major developed country[11] with the world's fourteenth largest economy by nominal GDP and sixteenth largest by purchasing power parity. It is a member of the United Nations (UN), the European Union (EU), the Eurozone, the Council of Europe (CoE), the Organization of Ibero-American States (OEI), the North Atlantic Treaty Organization (NATO), the Organisation for Economic Co-operation and Development (OECD), the World Trade Organization (WTO) and many other international organisations. Spain has a "permanent invitation" to the G20 summits that occur generally once a year.						The origins of the Roman name Hispania, from which the modern name España was derived, are uncertain due to inadequate evidence, although it is documented that the Phoenicians and Carthaginians referred to the region as Spania, therefore the most widely accepted etymology is a Semitic-Phoenician one.[10][12] Down the centuries there have been a number of accounts and hypotheses:		The Renaissance scholar Antonio de Nebrija proposed that the word Hispania evolved from the Iberian word Hispalis, meaning "city of the western world".		Jesús Luis Cunchillos argues that the root of the term span is the Phoenician word spy, meaning "to forge metals". Therefore, i-spn-ya would mean "the land where metals are forged".[13] It may be a derivation of the Phoenician I-Shpania, meaning "island of rabbits", "land of rabbits" or "edge", a reference to Spain's location at the end of the Mediterranean; Roman coins struck in the region from the reign of Hadrian show a female figure with a rabbit at her feet,[14] and Strabo called it the "land of the rabbits".[15]		Hispania may derive from the poetic use of the term Hesperia, reflecting the Greek perception of Italy as a "western land" or "land of the setting sun" (Hesperia, Ἑσπερία in Greek) and Spain, being still further west, as Hesperia ultima.[16]		There is the claim that "Hispania" derives from the Basque word Ezpanna meaning "edge" or "border", another reference to the fact that the Iberian Peninsula constitutes the southwest corner of the European continent.[16]		Two 15th-century Spanish Jewish scholars, Don Isaac Abravanel and Solomon ibn Verga, gave an explanation now considered folkloric. Both men wrote in two different published works that the first Jews to reach Spain were brought by ship by Phiros who was confederate with the king of Babylon when he laid siege to Jerusalem. Phiros was a Grecian by birth, but who had been given a kingdom in Spain. Phiros became related by marriage to Espan, the nephew of king Heracles, who also ruled over a kingdom in Spain. Heracles later renounced his throne in preference for his native Greece, leaving his kingdom to his nephew, Espan, from whom the country of España (Spain) took its name. Based upon their testimonies, this eponym would have already been in use in Spain by c. 350 BCE.[17]		Iberia enters written records as a land populated largely by the Iberians, Basques and Celts. Early on its coastal areas were settled by Phoenicians who founded Western Europe's most ancient cities Cadiz and Malaga. Phoenician influence expanded as much of the Peninsula was eventually incorporated into the Carthaginian Empire, becoming a major theater of the Punic Wars against the expanding Roman Empire. After an arduous conquest, the peninsula came fully under Roman Rule. During the early Middle Ages it came under Germanic rule but later, much of it was conquered by Moorish invaders from North Africa. In a process that took centuries, the small Christian kingdoms in the north gradually regained control of the peninsula. The last Moorish kingdom fell in the same year Columbus reached the Americas. A global empire began which saw Spain become the strongest kingdom in Europe, the leading world power for a century and a half, and the largest overseas empire for three centuries.		Continued wars and other problems eventually led to a diminished status. The Napoleonic invasions of Spain led to chaos, triggering independence movements that tore apart most of the empire and left the country politically unstable. Prior to the Second World War, Spain suffered a devastating civil war and came under the rule of an authoritarian government, which oversaw a period of stagnation that was followed by a surge in the growth of the economy. Eventually democracy was peacefully restored in the form of a parliamentary constitutional monarchy. Spain joined the European Union, experiencing a cultural renaissance and steady economic growth until the beginning of the 21st century, that started a new globalized world with economic and ecological challenges.		Archaeological research at Atapuerca indicates the Iberian Peninsula was populated by hominids 1.2 million years ago.[19] In Atapuerca fossils have been found of the earliest known hominins in Europe, the Homo antecessor. Modern humans first arrived in Iberia, from the north on foot, about 35,000 years ago.[20][not in citation given] The best known artefacts of these prehistoric human settlements are the famous paintings in the Altamira cave of Cantabria in northern Iberia, which were created from 35,600 to 13,500 BCE by Cro-Magnon.[18][21] Archaeological and genetic evidence suggests that the Iberian Peninsula acted as one of several major refugia from which northern Europe was repopulated following the end of the last ice age.		The largest groups inhabiting the Iberian Peninsula before the Roman conquest were the Iberians and the Celts. The Iberians inhabited the Mediterranean side of the peninsula, from the northeast to the southeast. The Celts inhabited much of the inner and Atlantic sides of the peninsula, from the northwest to the southwest. Basques occupied the western area of the Pyrenees mountain range and adjacent areas, the Phoenician-influenced Tartessians culture flourished in the southwest and the Lusitanians and Vettones occupied areas in the central west. A number of cities were founded along the coast by Phoenicians, and trading outposts were established by Greeks in the North East. Eventually, Phoenician-Carthaginians expanded inland conquering about over half of modern-day Spain.		During the Second Punic War, roughly between 210 and 205 BC the expanding Roman Republic captured Carthaginian trading colonies along the Mediterranean coast. Although it took the Romans nearly two centuries to complete the conquest of the Iberian Peninsula, they retained control of it for over six centuries. Roman rule was bound together by law, language, and the Roman road.[22]		The cultures of the Celtic and Iberian populations were gradually Romanised (Latinised) at different rates depending on what part of Hispania they lived in, with local leaders being admitted into the Roman aristocratic class.[i][23] Hispania served as a granary for the Roman market, and its harbors exported gold, wool, olive oil, and wine. Agricultural production increased with the introduction of irrigation projects, some of which remain in use. Emperors Hadrian, Trajan, Theodosius I, and the philosopher Seneca were born in Hispania.[j] Christianity was introduced into Hispania in the 1st century AD and it became popular in the cities in the 2nd century AD.[23] Most of Spain's present languages and religion, and the basis of its laws, originate from this period.[22]		The weakening of the Western Roman Empire's jurisdiction in Hispania began in 409, when the Germanic Suebi and Vandals, together with the Sarmatian Alans entered the peninsula at the invitation of a Roman usurper. These tribes who had crossed the Rhinein early 407 and ravaged Gaul. The Suebi established a kingdom in what is today modern Galicia and northern Portugal whereas the Vandals established themselves in southern Spain by 420 before crossing over to North Africa in 429 and taking Carthage in 439. As the western empire disintegrated, the social and economic base became greatly simplified: but even in modified form, the successor regimes maintained many of the institutions and laws of the late empire, including Christianity and assimilation to the evolving Roman culture.		The Byzantines established an occidental province, Spania, in the south, with the intention of reviving Roman rule throughout Iberia. Eventually, however, Hispania was reunited under Visigothic rule.		Isidore of Seville, born in Murcia, Archbishop of Seville, was an influential cleric and philosopher and was much studied in the Middle Ages in Europe. His theories were also vital to the conversion of the Visigothic Kingdom from an Arian domain to a Catholic one in the Councils of Toledo. This Gothic kingdom was the first independent Christian kingdom ruling in the Iberian Peninsula, and in the Reconquista it was the referent for the different kingdoms fighting against the Muslim rule.		In the 8th century, nearly all of the Iberian Peninsula was conquered (711–718) by largely Moorish Muslim armies from North Africa. These conquests were part of the expansion of the Umayyad Caliphate. Only a small area in the mountainous north-west of the peninsula managed to resist the initial invasion.		Under Islamic law, Christians and Jews were given the subordinate status of dhimmi. This status permitted Christians and Jews to practice their religions as People of the Book but they were required to pay a special tax and had legal and social rights inferior to those of Muslims.[24][25]		Conversion to Islam proceeded at an increasing pace. The muladíes (Muslims of ethnic Iberian origin) are believed to have comprised the majority of the population of Al-Andalus by the end of the 10th century.[26][27]		The Muslim community in the Iberian Peninsula was itself diverse and beset by social tensions. The Berber people of North Africa, who had provided the bulk of the invading armies, clashed with the Arab leadership from the Middle East.[k] Over time, large Moorish populations became established, especially in the Guadalquivir River valley, the coastal plain of Valencia, the Ebro River valley and (towards the end of this period) in the mountainous region of Granada.[27]		Córdoba, the capital of the caliphate since Abd-ar-Rahman III, was the largest, richest and most sophisticated city in western Europe. Mediterranean trade and cultural exchange flourished. Muslims imported a rich intellectual tradition from the Middle East and North Africa. Muslim and Jewish scholars played an important part in reviving and expanding classical Greek learning in Western Europe. Some important philosophers at the time were Averroes, Ibn Arabi and Maimonides. The Romanised cultures of the Iberian Peninsula interacted with Muslim and Jewish cultures in complex ways, giving the region a distinctive culture.[27] Outside the cities, where the vast majority lived, the land ownership system from Roman times remained largely intact as Muslim leaders rarely dispossessed landowners and the introduction of new crops and techniques led to an expansion of agriculture.		In the 11th century, the Muslim holdings fractured into rival Taifa kingdoms, allowing the small Christian states the opportunity to greatly enlarge their territories.[27] The arrival from North Africa of the Islamic ruling sects of the Almoravids and the Almohads restored unity upon the Muslim holdings, with a stricter, less tolerant application of Islam, and saw a revival in Muslim fortunes. This re-united Islamic state experienced more than a century of successes that partially reversed Christian gains.		The Reconquista (Reconquest) was the centuries-long period in which Christian rule was re-established over the Iberian Peninsula. The Reconquista is viewed as beginning with the Battle of Covadonga won by Don Pelayo in 722 and was concurrent with the period of Muslim rule on the Iberian Peninsula. The Christian army's victory over Muslim forces led to the creation of the Christian Kingdom of Asturias along the northwestern coastal mountains. Shortly after, in 739, Muslim forces were driven from Galicia, which was to eventually host one of medieval Europe's holiest sites, Santiago de Compostela and was incorporated into the new Christian kingdom. The Kingdom of León was the strongest Christian kingdom for centuries. In 1188 the first modern parliamentary session in Europe was held in León (Cortes of León). The Kingdom of Castile, formed from Leonese territory, was its successor as strongest kingdom. The kings and the nobility fought for power and influence in this period. The example of the Roman emperors influenced the political objective of the Crown, while the nobles benefited from feudalism.		Muslim armies had also moved north of the Pyrenees but they were defeated by Frankish forces at the Battle of Poitiers, Frankia and pushed out of the verz southernmost regionofFrance along the seacoast by the 760s. Later, Frankish forces established Christian counties on the southern side of the Pyrenees. These areas were to grow into the kingdoms of Navarre and Aragon.[28] For several centuries, the fluctuating frontier between the Muslim and Christian controlled areas of Iberia was along the Ebro and Douro valleys.		The County of Barcelona and the Kingdom of Aragon entered in a dynastic union and gained territory and power in the Mediterranean. In 1229 Majorca was conquered, so was Valencia in 1238.		The break-up of Al-Andalus into the competing taifa kingdoms helped the long embattled Iberian Christian kingdoms gain the initiative. The capture of the strategically central city of Toledo in 1085 marked a significant shift in the balance of power in favour of the Christian kingdoms. Following a great Muslim resurgence in the 12th century, the great Moorish strongholds in the south fell to Christian Spain in the 13th century—Córdoba in 1236 and Seville in 1248. In the 13th and 14th centuries, the Marinid dynasty of Morocco invaded and established some enclaves on the southern coast but failed in their attempt to re-establish North African rule in Iberia and were soon driven out. After 800 years of Muslim presence in Spain, the last Nasrid sultanate of Granada, a tributary state would finally surrender in 1492 to the Catholic monarchs Queen Isabella I of Castile[29] and King Ferdinand II of Aragon.[30][31][32]		From the mid 13th century, literature and philosophy started to flourish again in the Christian peninsular kingdoms, based on Roman and Gothic traditions. An important philosopher from this time is Ramon Llull. Abraham Cresques was a prominent Jewish cartographer. Roman law and its institutions were the model for the legislators. The king Alfonso X of Castile focused on strengthening this Roman and Gothic past, and also on linking the Iberian Christian kingdoms with the rest of medieval European Christendom. Alfonso worked for being elected emperor of the Holy Roman Empire and published the Siete Partidas code. The Toledo School of Translators is the name that commonly describes the group of scholars who worked together in the city of Toledo during the 12th and 13th centuries, to translate many of the philosophical and scientific works from Classical Arabic, Ancient Greek, and Ancient Hebrew. The Islamic transmission of the classics is the main Islamic contributions to Medieval Europe. The Castilian language—more commonly known (especially later in history and at present) as "Spanish" after becoming the national language and lingua franca of Spain—evolved from Vulgar Latin, as did other Romance languages of Spain like the Catalan, Asturian and Galician languages, as well as other Romance languages in Latin Europe. Basque, the only non-Romance language in Spain, continued evolving from Early Basque to Medieval. The Glosas Emilianenses founded in the monasteries of San Millán de la Cogolla contain the first written words in both Basque and Spanish, having the first become an influence in the formation of the second as an evolution of Latin.		The 13th century also witnessed the Crown of Aragon, centred in Spain's north east, expand its reach across islands in the Mediterranean, to Sicily and even Athens.[33] Around this time the universities of Palencia (1212/1263) and Salamanca (1218/1254) were established. The Black Death of 1348 and 1349 devastated Spain.[34]		In 1469, the crowns of the Christian kingdoms of Castile and Aragon were united by the marriage of Isabella I of Castile and Ferdinand II of Aragon. 1478 commenced the completion of the conquest of the Canary Islands and in 1492, the combined forces of Castile and Aragon captured the Emirate of Granada from its last ruler Muhammad XII, ending the last remnant of a 781-year presence of Islamic rule in Iberia. That same year, Spain's Jews were ordered to convert to Catholicism or face expulsion from Spanish territories during the Spanish Inquisition.[35] The Treaty of Granada guaranteed religious tolerance towards Muslims,[36] for a few years before Islam was outlawed in 1502 in the Kingdom of Castile and 1527 in the Kingdom of Aragon, leading to Spain's Muslim population becoming nominally Christian Moriscos. A few decades after the Morisco rebellion of Granada known as the War of the Alpujarras, a significant proportion of Spain's formerly-Muslim population was expelled, settling primarily in North Africa. [l][37]		The year 1492 also marked the arrival of Christopher Columbus in the New World, during a voyage funded by Isabella. Columbus's first voyage crossed the Atlantic and reached the Caribbean Islands, beginning the European exploration and conquest of the Americas, although Columbus remained convinced that he had reached the Orient. The colonisation of the Americas started, with conquistadores like Hernán Cortés and Francisco Pizarro. Miscegenation was the rule between the native and the Spanish cultures and people.		As Renaissance New Monarchs, Isabella and Ferdinand centralised royal power at the expense of local nobility, and the word España, whose root is the ancient name Hispania, began to be commonly used to designate the whole of the two kingdoms.[37] With their wide-ranging political, legal, religious and military reforms, Spain emerged as the first world power.		The unification of the crowns of Aragon and Castile by the marriage of their sovereigns laid the basis for modern Spain and the Spanish Empire, although each kingdom of Spain remained a separate country, in social, political, laws, currency and language.[38][39]		There were two big revolts against the new Habsburg monarch and the more authoritarian and imperial-style crown: Revolt of the Comuneros in Castile and Revolt of the Brotherhoods in Majorca and Valencia. After years of combat, Comuneros Juan López de Padilla, Juan Bravo and Francisco Maldonado were executed and María Pacheco went into exile. Germana de Foix also finished with the revolt in the Mediterranean.		Spain was Europe's leading power throughout the 16th century and most of the 17th century, a position reinforced by trade and wealth from colonial possessions and became the world's leading maritime power. It reached its apogee during the reigns of the first two Spanish Habsburgs—Charles I (1516–1556) and Philip II (1556–1598). This period saw the Italian Wars, the Revolt of the Comuneros, the Dutch Revolt, the Morisco Revolt, clashes with the Ottomans, the Anglo-Spanish War and wars with France.[40]		Through exploration and conquest or royal marriage alliances and inheritance, the Spanish Empire expanded to include vast areas in the Americas, islands in the Asia-Pacific area, areas of Italy, cities in Northern Africa, as well as parts of what are now France, Germany, Belgium, Luxembourg, and the Netherlands. The first circumnavigation of the world was carried out in 1519–1521. It was the first empire on which it was said that the sun never set. This was an Age of Discovery, with daring explorations by sea and by land, the opening-up of new trade routes across oceans, conquests and the beginnings of European colonialism. Spanish explorers brought back precious metals, spices, luxuries, and previously unknown plants, and played a leading part in transforming the European understanding of the globe.[41] The cultural efflorescence witnessed during this period is now referred to as the Spanish Golden Age. The expansion of the empire caused immense upheaval in the Americas as the collapse of societies and empires and new diseases from Europe devastated American indigenous populations. The rise of humanism, the Counter-Reformation and new geographical discoveries and conquests raised issues that were addressed by the intellectual movement now known as the School of Salamanca, which developed the first modern theories of what are now known as international law and human rights.		In the late 16th century and first half of the 17th century, Spain was confronted by unrelenting challenges from all sides. Barbary pirates, under the aegis of the rapidly growing Ottoman Empire, disrupted life in many coastal areas through their slave raids and the renewed threat of an Islamic invasion.[42] This was at a time when Spain was often at war with France.		The Protestant Reformation dragged the kingdom ever more deeply into the mire of religiously charged wars. The result was a country forced into ever expanding military efforts across Europe and in the Mediterranean.[43]		By the middle decades of a war- and plague-ridden 17th-century Europe, the Spanish Habsburgs had enmeshed the country in continent-wide religious-political conflicts. These conflicts drained it of resources and undermined the economy generally. Spain managed to hold on to most of the scattered Habsburg empire, and help the imperial forces of the Holy Roman Empire reverse a large part of the advances made by Protestant forces, but it was finally forced to recognise the separation of Portugal (with whom it had been united in a personal union of the crowns from 1580 to 1640) and the Netherlands, and eventually suffered some serious military reverses to France in the latter stages of the immensely destructive, Europe-wide Thirty Years' War.[44]		In the latter half of the 17th century, Spain went into a gradual decline, during which it surrendered several small territories to France and the Netherlands; however, it maintained and enlarged its vast overseas empire, which remained intact until the beginning of the 19th century.		The decline culminated in a controversy over succession to the throne which consumed the first years of the 18th century. The War of the Spanish Succession was a wide-ranging international conflict combined with a civil war, and was to cost the kingdom its European possessions and its position as one of the leading powers on the Continent.[45] During this war, a new dynasty originating in France, the Bourbons, was installed. Long united only by the Crown, a true Spanish state was established when the first Bourbon king, Philip V, united the crowns of Castile and Aragon into a single state, abolishing many of the old regional privileges and laws.[46]		The 18th century saw a gradual recovery and an increase in prosperity through much of the empire. The new Bourbon monarchy drew on the French system of modernising the administration and the economy. Enlightenment ideas began to gain ground among some of the kingdom's elite and monarchy. Military assistance for the rebellious British colonies in the American War of Independence improved the kingdom's international standing.[47]		In 1793, Spain went to war against the revolutionary new French Republic as a member of the first Coalition. The subsequent War of the Pyrenees polarised the country in a reaction against the gallicised elites and following defeat in the field, peace was made with France in 1795 at the Peace of Basel in which Spain lost control over two-thirds of the island of Hispaniola. The Prime Minister, Manuel Godoy, then ensured that Spain allied herself with France in the brief War of the Third Coalition which ended with the British victory at the Battle of Trafalgar in 1805. In 1807, a secret treaty between Napoleon and the unpopular prime minister led to a new declaration of war against Britain and Portugal. Napoleon's troops entered the country to invade Portugal but instead occupied Spain's major fortresses. The ridiculed Spanish king abdicated in favour of Napoleon's brother, Joseph Bonaparte.		Joseph Bonaparte was seen as a puppet monarch and was regarded with scorn by the Spanish. The 2 May 1808 revolt was one of many nationalist uprisings across the country against the Bonapartist regime.[48] These revolts marked the beginning of a devastating war of independence against the Napoleonic regime.[49] Napoleon was forced to intervene personally, defeating several Spanish armies and forcing a British army to retreat. However, further military action by Spanish armies, guerrillas and Wellington's British-Portuguese forces, combined with Napoleon's disastrous invasion of Russia, led to the ousting of the French imperial armies from Spain in 1814, and the return of King Ferdinand VII.[50]		During the war, in 1810, a revolutionary body, the Cortes of Cádiz, was assembled to co-ordinate the effort against the Bonapartist regime and to prepare a constitution.[51] It met as one body, and its members represented the entire Spanish empire.[52] In 1812 a constitution for universal representation under a constitutional monarchy was declared but after the fall of the Bonapartist regime Ferdinand VII dismissed the Cortes Generales and was determined to rule as an absolute monarch. These events foreshadowed the conflict between conservatives and liberals in the 19th and early 20th centuries.		Spain's conquest by France benefited Latin American anti-colonialists who resented the Imperial Spanish government's policies that favoured Spanish-born citizens (Peninsulars) over those born overseas (Criollos) and demanded retroversion of the sovereignty to the people. Starting in 1809 Spain's American colonies began a series of revolutions and declared independence, leading to the Spanish American wars of independence that ended Spanish control over its mainland colonies in the Americas. King Ferdinand VII's attempt to re-assert control proved futile as he faced opposition not only in the colonies but also in Spain and army revolts followed, led by liberal officers. By the end of 1826, the only American colonies Spain held were Cuba and Puerto Rico.		The Napoleonic War left Spain economically ruined, deeply divided and politically unstable. In the 1830s and 1840s Anti-liberal forces known as Carlists fought against liberals in the Carlist Wars. Liberal forces won, but the conflict between progressive and conservative liberals ended in a weak early constitutional period. After the Glorious Revolution of 1868 and the short-lived First Spanish Republic, a more stable monarchic period began characterised by the practice of turnismo (the rotation of government control between progressive and conservative liberals within the Spanish government).		In the late 19th century nationalist movements arose in the Philippines and Cuba. In 1895 and 1896 the Cuban War of Independence and the Philippine Revolution broke out and eventually the United States became involved. The Spanish–American War was fought in the spring of 1898 and resulted in Spain losing the last of its once vast colonial empire outside of North Africa. El Desastre (the Disaster), as the war became known in Spain, gave added impetus to the Generation of '98 who were conducting an analysis of the country.		Although the period around the turn of the century was one of increasing prosperity, the 20th century brought little peace; Spain played a minor part in the scramble for Africa, with the colonisation of Western Sahara, Spanish Morocco and Equatorial Guinea. It remained neutral during World War I (see Spain in World War I). The heavy losses suffered during the Rif War in Morocco brought discredit to the government and undermined the monarchy.		A period of authoritarian rule under General Miguel Primo de Rivera (1923–1931) ended with the establishment of the Second Spanish Republic. The Republic offered political autonomy to the linguistically distinct regions of Basque Country, Catalonia and Galicia and gave voting rights to women.		The Spanish Civil War broke out in 1936. For three years the Nationalist forces led by General Francisco Franco and supported by Nazi Germany and Fascist Italy fought the Republican side, which was supported by the Soviet Union, Mexico and International Brigades but it was not supported by the Western powers due to the British-led policy of Non-Intervention. The civil war was viciously fought and there were many atrocities committed by all sides. The war claimed the lives of over 500,000 people and caused the flight of up to a half-million citizens from the country.[53][54] In 1939, General Franco emerged victorious and became a dictator.		The state as established under Franco was nominally neutral in the Second World War, although sympathetic to the Axis. The only legal party under Franco's post civil war regime was the Falange Española Tradicionalista y de las JONS, formed in 1937; the party emphasised falangism, a form of fascism that emphasised anti-communism, nationalism and Roman Catholicism. Given Franco's opposition to competing political parties, the party was renamed the National Movement (Movimiento Nacional) in 1949.		After World War II Spain was politically and economically isolated, and was kept out of the United Nations. This changed in 1955, during the Cold War period, when it became strategically important for the US to establish a military presence on the Iberian Peninsula as a counter to any possible move by the Soviet Union into the Mediterranean basin. In the 1960s, Spain registered an unprecedented rate of economic growth which was propelled by industrialisation, a mass internal migration from rural areas to cities and the creation of a mass tourism industry. Franco's rule was also characterised by authoritarianism, promotion of a unitary national identity, the favouring of a very conservative form of Roman Catholicism known as National Catholicism, and discriminatory language policies.		In 1962 a group of politicians involved in the opposition to Franco's regime inside the country and in the exile met in the congress of the European Movement in Munich, where they made a resolution in favour of democracy.[55][56][57]		With Franco's death in November 1975, Juan Carlos succeeded to the position of King of Spain and head of state in accordance with the franquist law. With the approval of the new Spanish Constitution of 1978 and the restoration of democracy, the State devolved much authority to the regions and created an internal organisation based on autonomous communities. Spanish 1977 Amnesty Law let people of Franco´s regime continue inside institutions without consequences, even responsibles of some crimes during transition to democracy like the Massacre of 3 March 1976 in Vitoria or 1977 Massacre of Atocha.		In the Basque Country, moderate Basque nationalism has coexisted with a radical nationalist movement led by the armed terrorist organisation ETA.[58] The group was formed in 1959 during Franco's rule but has continued to wage its violent campaign even after the restoration of democracy and the return of a large measure of regional autonomy. On 23 February 1981, rebel elements among the security forces seized the Cortes in an attempt to impose a military backed government. King Juan Carlos took personal command of the military and successfully ordered the coup plotters, via national television, to surrender.		During the 1980s the democratic restoration made possible a growing open society. New cultural movements based on freedom appeared, like La Movida Madrileña and a culture of human rights arose with Gregorio Peces-Barba. On 30 May 1982 Spain joined NATO, following a referendum after a strong social opposition. That year the Spanish Socialist Workers Party (PSOE) came to power, the first left-wing government in 43 years. In 1986 Spain joined the European Economic Community, which later became the European Union. The PSOE was replaced in government by the Partido Popular (PP) in 1996 after scandals around participation of the government of Felipe González in the Dirty war against ETA; at that point the PSOE had served almost 14 consecutive years in office.		On 1 January 2002, Spain fully adopted the euro, and Spain experienced strong economic growth, well above the EU average during the early 2000s. However, well publicised concerns issued by many economic commentators at the height of the boom warned that extraordinary property prices and a high foreign trade deficit were likely to lead to a painful economic collapse.[59]		In 2002 Prestige oil spill happened with big ecological consequences in the Spanish atlantic coastline. In 2003 José María Aznar supported US president George W. Bush in its preventive war against Sadam Hussein´s Iraq. A strong movement against war rose in Spanish society. On 11 March 2004 a local Islamist terrorist group inspired by Al-Qaeda carried out the largest terrorist attack in Spanish history when they killed 191 people and wounded more than 1,800 others by bombing commuter trains in Madrid.[60] Though initial suspicions focused on the Basque terrorist group ETA, evidence soon emerged indicating Islamist involvement. Because of the proximity of the 2004 election, the issue of responsibility quickly became a political controversy, with the main competing parties PP and PSOE exchanging accusations over the handling of the incident.[61] At 14 March elections, PSOE, led by José Luis Rodríguez Zapatero won the elections.		The proportion of Spain's foreign born population increased rapidly from around 1 in 50 in 2000 to almost 1 in 8 in 2010 but has since declined. In 2005 the Spanish government legalised same sex marriage. Decentralisation was supported with much resistance of Constitutional Court and conservative opposition, so did gender politics like quotas or the law against gender violence. Government talks with ETA happened, and the band announced its permanent cease of violence in 2010.		The bursting of the Spanish property bubble in 2008 led to the 2008–16 Spanish financial crisis and high levels of unemployment, cuts in government spending and corruption in Royal family and People's Party served as a backdrop to the 2011–12 Spanish protests. Catalan independentism was also on rise. In 2011 Mariano Rajoy's conservative People's Party won elections with 44.6% of votes and Rajoy became the Spanish Prime Minister after having been the leader of the opposition from 2004 to 2011 with a program of cutting social spends. On 19 June 2014, the monarch, Juan Carlos, abdicated in favour of his son, who became Felipe VI. Bipartidism in Spanish politics got to an end with the entrance of new forces in representative institutions. In 2015, left-wing mayors got control of biggest cities in the country as former judge and former co-founder of the labour law office where the 1977 Massacre of Atocha took place Manuela Carmena in Madrid, co-founder and spokesperson of the Platform for People Affected by Mortgages Ada Colau in Barcelona, Valencia or Zaragoza, the first time that happens since the Spanish Second Republic. Even though, in general election of the same year, conservative People's Party revalidated its majority in the parliament.		In February 2016, the government of Spain announced it will rename streets named after Franco's administration officials with names of women.[62]		At 505,992 km2 (195,365 sq mi), Spain is the world's fifty-second largest country and Europe's fourth largest country. It is some 47,000 km2 (18,000 sq mi) smaller than France and 81,000 km2 (31,000 sq mi) larger than the US state of California. Mount Teide (Tenerife) is the highest mountain peak in Spain and is the third largest volcano in the world from its base. Spain is a transcontinental country.		Spain lies between latitudes 26° and 44° N, and longitudes 19° W and 5° E.		On the west, Spain is bordered by Portugal; on the south, it is bordered by Gibraltar (a British overseas territory) and Morocco, through its exclaves in North Africa (Ceuta and Melilla, and the peninsula of Vélez de la Gomera). On the northeast, along the Pyrenees mountain range, it is bordered by France and the Principality of Andorra. Along the Pyrenees in Girona, a small exclave town called Llívia is surrounded by France.		Extending to 1,214 km (754 mi), the Portugal–Spain border is the longest uninterrupted border within the European Union.[63]		Spain also includes the Balearic Islands in the Mediterranean Sea, the Canary Islands in the Atlantic Ocean and a number of uninhabited islands on the Mediterranean side of the Strait of Gibraltar, known as plazas de soberanía ("places of sovereignty", or territories under Spanish sovereignty), such as the Chafarinas Islands and Alhucemas. The peninsula of Vélez de la Gomera is also regarded as a plaza de soberanía. The isle of Alborán, located in the Mediterranean between Spain and North Africa, is also administered by Spain, specifically by the municipality of Almería, Andalusia. The little Pheasant Island in the River Bidasoa is a Spanish-French condominium.		Largest inhabited islands of Spain:		Mainland Spain is a mountainous country, dominated by high plateaus and mountain chains. After the Pyrenees, the main mountain ranges are the Cordillera Cantábrica (Cantabrian Range), Sistema Ibérico (Iberian System), Sistema Central (Central System), Montes de Toledo, Sierra Morena and the Sistema Bético (Baetic System) whose highest peak, the 3,478-metre-high (11,411-foot) Mulhacén, located in Sierra Nevada, is the highest elevation in the Iberian Peninsula. The highest point in Spain is the Teide, a 3,718-metre (12,198 ft) active volcano in the Canary Islands. The Meseta Central (often translated as "Inner Plateau") is a vast plateau in the heart of peninsular Spain.		There are several major rivers in Spain such as the Tagus (Tajo), Ebro, Guadiana, Douro (Duero), Guadalquivir, Júcar, Segura, Turia and Minho (Miño). Alluvial plains are found along the coast, the largest of which is that of the Guadalquivir in Andalusia.		Three main climatic zones can be separated, according to geographical situation and orographic conditions:[64][65][66]		Apart from these main types, other sub-types can be found, like the alpine and continental climates (Dfc, Dfb / Dsc, Dsb) in the Pyrenees as well as parts of the Cantabrian Range, the Central System, Sierra Nevada and the Iberian System, and a typical desert climate (BWk, BWh) in the zone of Almería, Murcia and eastern Canary Islands. Low-lying areas of the Canary Islands average above 18.0 °C (64.4 °F) during their coldest month, thus having a tropical climate.		The fauna presents a wide diversity that is due in large part to the geographical position of the Iberian peninsula between the Atlantic and the Mediterranean and between Africa and Eurasia, and the great diversity of habitats and biotopes, the result of a considerable variety of climates and well differentiated regions.		The vegetation of Spain is varied due to several factors including the diversity of the relief, the climate and latitude. Spain includes different phytogeographic regions, each with its own floristic characteristics resulting largely from the interaction of climate, topography, soil type and fire, biotic factors.		According to the Democracy Index of the EIU, Spain is one of the 19 full democracies in the world.		The Spanish Constitution of 1978 is the culmination of the Spanish transition to democracy. The constitutional history of Spain dates back to the constitution of 1812. Impatient with the slow pace of democratic political reforms in 1976 and 1977, Spain's new King Juan Carlos, known for his formidable personality, dismissed Carlos Arias Navarro and appointed the reformer Adolfo Suárez as Prime Minister.[67][68] The resulting general election in 1977 convened the Constituent Cortes (the Spanish Parliament, in its capacity as a constitutional assembly) for the purpose of drafting and approving the constitution of 1978.[69] After a national referendum on 6 December 1978, 88% of voters approved of the new constitution.		As a result, Spain is now composed of 17 autonomous communities and two autonomous cities with varying degrees of autonomy thanks to its Constitution, which nevertheless explicitly states the indivisible unity of the Spanish nation. The constitution also specifies that Spain has no state religion and that all are free to practice and believe as they wish.		The Spanish administration approved legislation in 2007 aimed at furthering equality between genders in Spanish political and economic life (Gender Equality Act).[70][71] However, in the legislative branch, as of May 2017 only 140 of the 350 members of the Congress were women (40%).[72] It places Spain 12th on a list of countries ranked by proportion of women in the lower house. In the Senate, there are only 101 women out of 263 (38.0%).[73] The Gender Empowerment Measure of Spain in the United Nations Human Development Report is 0.794, 12th in the world.[74]		Spain is a constitutional monarchy, with a hereditary monarch and a bicameral parliament, the Cortes Generales (General Courts). The executive branch consists of a Council of Ministers of Spain presided over by the Prime Minister, nominated and appointed by the monarch and confirmed by the Congress of Deputies following legislative elections. By political custom established by King Juan Carlos since the ratification of the 1978 Constitution, the king's nominees have all been from parties who maintain a plurality of seats in the Congress.		The legislative branch is made up of the Congress of Deputies (Congreso de los Diputados) with 350 members, elected by popular vote on block lists by proportional representation to serve four-year terms, and a Senate (Senado) with 259 seats of which 208 are directly elected by popular vote and the other 51 appointed by the regional legislatures to also serve four-year terms.		Spain is organisationally structured as a so-called Estado de las Autonomías ("State of Autonomies"); it is one of the most decentralised countries in Europe, along with Switzerland, Germany and Belgium;[75] for example, all autonomous communities have their own elected parliaments, governments, public administrations, budgets, and resources. Health and education systems among others are managed by the Spanish communities, and in addition, the Basque Country and Navarre also manage their own public finances based on foral provisions. In Catalonia, the Basque Country, Navarre and the Canary Islands, a full-fledged autonomous police corps replaces some of the State police functions (see Mossos d'Esquadra, Ertzaintza, Policía Foral/Foruzaingoa and Policía Canaria).		The Government respects the human rights of its citizens; although there are a few problems in some areas, the law and judiciary provide effective means of addressing individual instances of abuse. There are allegations that a few members of the security forces abused detainees and mistreated foreigners and illegal immigrants.[76] According to Amnesty International (AI), government investigations of such alleged abuses are often lengthy and punishments were light.[77] Violence against women was a problem, which the Government took steps to address.[78][79]		Spain provides one of the highest degrees of liberty in the world for its LGBT community. Among the countries studied by Pew Research Center in 2013, Spain is rated first in acceptance of homosexuality, with an 88% of society supporting the gay community compared to 11% who do not.[80]		The Spanish State is integrated by 17 autonomous communities and 2 autonomous cities, both groups being the highest or first-order administrative division in the country. Autonomous communities are integrated by provinces, of which there are 50 in total, and in turn, provinces are integrated by municipalities. In Catalonia, two additional divisions exist, the comarques (sing. comarca) and the vegueries (sing. vegueria) both of which have administrative powers; comarques being aggregations of municipalities, and the vegueries being aggregations of comarques. The concept of a comarca exists in all autonomous communities, however, unlike Catalonia, these are merely historical or geographical subdivisions.		Spain's autonomous communities are the first level administrative divisions of the country. They were created after the current constitution came into effect (in 1978) in recognition of the right to self-government of the "nationalities and regions of Spain".[81] The autonomous communities were to be integrated into adjacent provinces with common historical, cultural, and economical traits. This territorial organisation, based on devolution, is literally known in Spain as the "State of Autonomies".		The basic institutional law of each autonomous community is the Statute of Autonomy. The Statutes of Autonomy establish the name of the community according to its historical and contemporary identity, the limits of its territories, the name and organisation of the institutions of government and the rights they enjoy according to the constitution.[82]		The governments of all autonomous communities must be based on a division of powers comprising:		Catalonia, Galicia and the Basque Country, which identified themselves as nationalities, were granted self-government through a rapid process. Andalusia also took that denomination in its first Statute of Autonomy, even though it followed the longer process stipulated in the constitution for the rest of the country. Progressively, other communities in revisions to their Statutes of Autonomy have also taken that denomination in accordance to their historical and modern identities, such as the Valencian Community,[83] the Canary Islands,[84] the Balearic Islands,[85] and Aragon.[86]		The autonomous communities have wide legislative and executive autonomy, with their own parliaments and regional governments. The distribution of powers may be different for every community, as laid out in their Statutes of Autonomy, since devolution was intended to be asymmetrical. Only two communities—the Basque Country and Navarre—have full fiscal autonomy. Aside of fiscal autonomy, the nationalities—Andalusia, the Basque Country, Catalonia, and Galicia—were devolved more powers than the rest of the communities, among them the ability of the regional president to dissolve the parliament and call for elections at any time. In addition, the Basque Country, Catalonia and Navarre have police corps of their own: Ertzaintza, Mossos d'Esquadra and the Policía Foral respectively. Other communities have more limited forces or none at all, like the Policía Autónoma Andaluza[87] in Andalusia or the BESCAM in Madrid.		Nonetheless, recent amendments to existing Statutes of Autonomy or the promulgation of new Statutes altogether, have reduced the asymmetry between the powers originally granted to the nationalities and the rest of the regions.		Finally, along with the 17 autonomous communities, two autonomous cities are also part of the State of Autonomies and are first-order territorial divisions: Ceuta and Melilla. These are two exclaves located in the northern African coast.		Autonomous communities are subdivided into provinces, which served as their territorial building blocks. In turn, provinces are integrated by municipalities. The existence of both the provinces and the municipalities is guaranteed and protected by the constitution, not necessarily by the Statutes of Autonomy themselves. Municipalities are granted autonomy to manage their internal affairs, and provinces are the territorial divisions designed to carry out the activities of the State.[88]		The current provincial division structure is based—with minor changes—on the 1833 territorial division by Javier de Burgos, and in all, the Spanish territory is divided into 50 provinces. The communities of Asturias, Cantabria, La Rioja, the Balearic Islands, Madrid, Murcia and Navarre are the only communities that are integrated by a single province, which is coextensive with the community itself. In these cases, the administrative institutions of the province are replaced by the governmental institutions of the community.		After the return of democracy following the death of Franco in 1975, Spain's foreign policy priorities were to break out of the diplomatic isolation of the Franco years and expand diplomatic relations, enter the European Community, and define security relations with the West.		As a member of NATO since 1982, Spain has established itself as a participant in multilateral international security activities. Spain's EU membership represents an important part of its foreign policy. Even on many international issues beyond western Europe, Spain prefers to co-ordinate its efforts with its EU partners through the European political co-operation mechanisms.[vague]		Spain has maintained its special relations with Hispanic America and the Philippines. Its policy emphasises the concept of an Ibero-American community, essentially the renewal of the historically liberal concept of "Hispanidad" or "Hispanismo", as it is often referred to in English, which has sought to link the Iberian Peninsula with Hispanic America through language, commerce, history and culture.		Spain claims Gibraltar, a 6-square-kilometre (2.3 sq mi) Overseas Territory of the United Kingdom in the southernmost part of the Iberian Peninsula. Then a Spanish town, it was conquered by an Anglo-Dutch force in 1704 during the War of the Spanish Succession on behalf of Archduke Charles, pretender to the Spanish throne.		The legal situation concerning Gibraltar was settled in 1713 by the Treaty of Utrecht, in which Spain ceded the territory in perpetuity to the British Crown[90] stating that, should the British abandon this post, it would be offered to Spain first. Since the 1940s Spain has called for the return of Gibraltar. The overwhelming majority of Gibraltarians strongly oppose this, along with any proposal of shared sovereignty.[91] UN resolutions call on the United Kingdom and Spain, both EU members, to reach an agreement over the status of Gibraltar.[92][93]		The Spanish claim makes a distinction between the isthmus that connects the Rock to the Spanish mainland on the one hand, and the Rock and city of Gibraltar on the other. While the Rock and city were ceded by the Treaty of Utrecht, Spain asserts that the "occupation of the isthmus is illegal and against the principles of International Law".[94] The United Kingdom relies on de facto arguments of possession by prescription in relation to the isthmus,[95] as there has been "continuous possession [of the isthmus] over a long period".[96]		Another claim by Spain is about the Savage Islands, a claim not recognised by Portugal. Spain claims that they are rocks rather than islands, therefore claiming that there is no Portuguese territorial waters around the disputed islands. On 5 July 2013, Spain sent a letter to the UN expressing these views.[97][98]		Spain claims the sovereignty over the Perejil Island, a small, uninhabited rocky islet located in the South shore of the Strait of Gibraltar. The island lies 250 metres (820 ft) just off the coast of Morocco, 8 kilometres (5.0 mi) from Ceuta and 13.5 kilometres (8.4 mi) from mainland Spain. Its sovereignty is disputed between Spain and Morocco. It was the subject of an armed incident between the two countries in 2002. The incident ended when both countries agreed to return to the status quo ante which existed prior to the Moroccan occupation of the island. The islet is now deserted and without any sign of sovereignty.		Besides the Perejil Island, the Spanish-held territories claimed by other countries are two: Morocco claims the Spanish cities of Ceuta and Melilla and the plazas de soberanía islets off the northern coast of Africa; and Portugal does not recognise Spain's sovereignty over the territory of Olivenza.		The armed forces of Spain are known as the Spanish Armed Forces (Fuerzas Armadas Españolas). Their Commander-in-chief is the King of Spain, Felipe VI.[99]		The Spanish Armed Forces are divided into three branches:[100]		Spain's capitalist mixed economy is the 14th largest worldwide and the 5th largest in the European Union, as well as the Eurozone's 4th largest.		The centre-right government of former prime minister José María Aznar worked successfully to gain admission to the group of countries launching the euro in 1999. Unemployment stood at 7.6% in October 2006, lower than many other European countries, and significantly below Spain's early 1990s unemployment rate of at over 20%. Perennial weak points of Spain's economy include a large informal economy,[101][102][103] and an education system which OECD reports place among the poorest for developed countries, together with the United States and UK.[104]		By the mid-1990s the economy had recommenced the growth that had been disrupted by the global recession of the early 1990s. The strong economic growth helped the government to reduce the government debt as a percentage of GDP and Spain's high unemployment rate began to steadily decline. With the government budget in balance and inflation under control Spain was admitted into the Eurozone in 1999.		Since the 1990s some Spanish companies have gained multinational status, often expanding their activities in culturally close Latin America. Spain is the second biggest foreign investor there, after the United States. Spanish companies have also expanded into Asia, especially China and India.[105] This early global expansion is a competitive advantage over its competitors and European neighbours. The reason for this early expansion is the booming interest towards Spanish language and culture in Asia and Africa and a corporate culture that learned to take risks in unstable markets.		Spanish companies invested in fields like renewable energy commercialisation (Iberdrola was the world's largest renewable energy operator[106]), technology companies like Telefónica, Abengoa, Mondragon Corporation, Movistar, Hisdesat, Indra, train manufacturers like CAF, Talgo, global corporations such as the textile company Inditex, petroleum companies like Repsol and infrastructure, with six of the ten biggest international construction firms specialising in transport being Spanish, like Ferrovial, Acciona, ACS, OHL and FCC.[107]		In 2005 the Economist Intelligence Unit's quality of life survey placed Spain among the top 10 in the world.[108] In 2013 the same survey (now called the "Where-to-be-born index"), ranked Spain 28th in the world.[109]		In 2010, the Basque city of Bilbao was awarded with the Lee Kuan Yew World City Prize,[110] and its mayor at the time, Iñaki Azkuna, was awarded the World Mayor Prize in 2012.[111] The Basque capital city of Vitoria-Gasteiz received the European Green Capital Award in 2012.[112]		Crop areas were farmed in two highly diverse manners. Areas relying on non-irrigated cultivation (secano), which made up 85% of the entire crop area, depended solely on rainfall as a source of water. They included the humid regions of the north and the northwest, as well as vast arid zones that had not been irrigated. The much more productive regions devoted to irrigated cultivation (regadío) accounted for 3 million hectares in 1986, and the government hoped that this area would eventually double, as it already had doubled since 1950. Particularly noteworthy was the development in Almería—one of the most arid and desolate provinces of Spain—of winter crops of various fruits and vegetables for export to Europe.		Though only about 17% of Spain's cultivated land was irrigated, it was estimated to be the source of between 40–45% of the gross value of crop production and of 50% of the value of agricultural exports. More than half of the irrigated area was planted in corn, fruit trees, and vegetables. Other agricultural products that benefited from irrigation included grapes, cotton, sugar beets, potatoes, legumes, olive trees, mangos, strawberries, tomatoes, and fodder grasses. Depending on the nature of the crop, it was possible to harvest two successive crops in the same year on about 10% of the country's irrigated land.		Citrus fruits, vegetables, cereal grains, olive oil, and wine—Spain's traditional agricultural products—continued to be important in the 1980s. In 1983 they represented 12%, 12%, 8%, 6%, and 4%, respectively, of the country's agricultural production. Because of the changed diet of an increasingly affluent population, there was a notable increase in the consumption of livestock, poultry, and dairy products. Meat production for domestic consumption became the single most important agricultural activity, accounting for 30% of all farm-related production in 1983. Increased attention to livestock was the reason that Spain became a net importer of grains. Ideal growing conditions, combined with proximity to important north European markets, made citrus fruits Spain's leading export. Fresh vegetables and fruits produced through intensive irrigation farming also became important export commodities, as did sunflower seed oil that was produced to compete with the more expensive olive oils in oversupply throughout the Mediterranean countries of the European Community.		The climate of Spain, its geographic location, popular coastlines, diverse landscapes, historical legacy, vibrant culture and excellent infrastructure, has made Spain's international tourist industry among the largest in the world. In the last five decades, international tourism in Spain has grown to become the second largest in the world in terms of spending, worth approximately 40 billion Euros or about 5% of GDP in 2006.[113][114]		Spain is one of the world's leading countries in the development and production of renewable energy. In 2010 Spain became the solar power world leader when it overtook the United States with a massive power station plant called La Florida, near Alvarado, Badajoz.[115][116] Spain is also Europe's main producer of wind energy. In 2010 its wind turbines generated 42,976 GWh, which accounted for 16.4% of all electrical energy produced in Spain.[117][118][119] On 9 November 2010, wind energy reached an instantaneous historic peak covering 53% of mainland electricity demand[120] and generating an amount of energy that is equivalent to that of 14 nuclear reactors.[121] Other renewable energies used in Spain are hydroelectric, biomass and marine (2 power plants under construction).[122]		Non-renewable energy sources used in Spain are nuclear (8 operative reactors), gas, coal, and oil. Fossil fuels together generated 58% of Spain's electricity in 2009, just below the OECD mean of 61%. Nuclear power generated another 19%, and wind and hydro about 12% each.[123]		The Spanish road system is mainly centralised, with six highways connecting Madrid to the Basque Country, Catalonia, Valencia, West Andalusia, Extremadura and Galicia. Additionally, there are highways along the Atlantic (Ferrol to Vigo), Cantabrian (Oviedo to San Sebastián) and Mediterranean (Girona to Cádiz) coasts. Spain aims to put one million electric cars on the road by 2014 as part of the government's plan to save energy and boost energy efficiency.[124] The former Minister of Industry Miguel Sebastián said that "the electric vehicle is the future and the engine of an industrial revolution."[125]		Spain has the most extensive high-speed rail network in Europe, and the second-most extensive in the world after China.[126][127] As of October 2010, Spain has a total of 3,500 km (2,174.80 mi) of high-speed tracks linking Málaga, Seville, Madrid, Barcelona, Valencia and Valladolid, with the trains reaching speeds up to 300 km/h (190 mph). On average, the Spanish high-speed train is the fastest one in the world, followed by the Japanese bullet train and the French TGV.[128] Regarding punctuality, it is second in the world (98.54% on-time arrival) after the Japanese Shinkansen (99%).[129] Should the aims of the ambitious AVE programme (Spanish high speed trains) be met, by 2020 Spain will have 7,000 km (4,300 mi) of high-speed trains linking almost all provincial cities to Madrid in less than three hours and Barcelona within four hours.		There are 47 public airports in Spain. The busiest one is the airport of Madrid (Barajas), with 50 million passengers in 2011, being the world's 15th busiest airport, as well as the European Union's fourth busiest. The airport of Barcelona (El Prat) is also important, with 35 million passengers in 2011, being the world's 31st-busiest airport. Other main airports are located in Majorca (23 million passengers), Málaga (13 million passengers), Las Palmas (Gran Canaria) (11 million passengers), Alicante (10 million passengers) and smaller, with the number of passengers between 4 and 10 million, for example Tenerife (two airports), Valencia, Seville, Bilbao, Ibiza, Lanzarote, Fuerteventura. Also, more than 30 airports with the number of passengers below 4 million.		In the 19th and 20th centuries science in Spain was held back by severe political instability and consequent economic underdevelopment. Despite the conditions, some important scientists and engineers emerged. The most notable were Miguel Servet, Santiago Ramón y Cajal, Narcís Monturiol, Celedonio Calatayud, Juan de la Cierva, Leonardo Torres y Quevedo, Margarita Salas and Severo Ochoa.		Water supply and sanitation in Spain is characterised by universal access and generally good service quality, while tariffs are among the lowest in the EU.[130] Almost half of the population is served by private or mixed private-public water companies, which operate under concession contracts with municipalities. The largest of the private water companies, with a market share of about 50% of the private concessions, is Aguas de Barcelona (Agbar). However, the large cities are all served by public companies except Barcelona and Valencia. The largest public company is Canal de Isabel II, which serves the metropolitan area of Madrid.		Droughts affect water supply in Southern Spain, which increasingly is turning towards seawater desalination to meet its water needs.		In 2008 the population of Spain officially reached 46 million people, as recorded by the Padrón municipal (Spain's Municipal Register).[131] Spain's population density, at 91/km² (235/sq mi), is lower than that of most Western European countries and its distribution across the country is very unequal. With the exception of the region surrounding the capital, Madrid, the most populated areas lie around the coast. The population of Spain more than doubled since 1900, when it stood at 18.6 million, principally due to the spectacular demographic boom in the 1960s and early 1970s.[132]		Native Spaniards make up 88% of the total population of Spain. After the birth rate plunged in the 1980s and Spain's population growth rate dropped, the population again trended upward, based initially on the return of many Spaniards who had emigrated to other European countries during the 1970s, and more recently, fuelled by large numbers of immigrants who make up 12% of the population. The immigrants originate mainly in Latin America (39%), North Africa (16%), Eastern Europe (15%), and Sub-Saharan Africa (4%).[133] In 2005, Spain instituted a three-month amnesty programme through which certain hitherto undocumented aliens were granted legal residency.		In 2008, Spain granted citizenship to 84,170 persons, mostly to people from Ecuador, Colombia and Morocco.[134] A sizeable portion of foreign residents in Spain also comes from other Western and Central European countries. These are mostly British, French, German, Dutch, and Norwegian. They reside primarily on the Mediterranean coast and the Balearic islands, where many choose to live their retirement or telecommute.		Substantial populations descended from Spanish colonists and immigrants exist in other parts of the world, most notably in Latin America. Beginning in the late 15th century, large numbers of Iberian colonists settled in what became Latin America and at present most white Latin Americans (who make up about one-third of Latin America's population) are of Spanish or Portuguese origin. Around 240,000 Spaniards emigrated in the 16th century, mostly to Peru and Mexico.[135] Another 450,000 left in the 17th century.[136] Between 1846 and 1932 it is estimated that nearly 5 million Spaniards emigrated to the Americas, especially to Argentina and Brazil.[137] Approximately two million Spaniards migrated to other Western European countries between 1960 and 1975. During the same period perhaps 300,000 went to Latin America.[138]		Source: "Áreas urbanas +50", Ministry of Public Works and Transport (2013)[142]		The Spanish Constitution of 1978, in its second article, recognises several contemporary entities—nationalities—[m] and regions, within the context of the Spanish nation.		Spain is de facto a plurinational state.[147][148] The idendity of Spain rather accrues of an overlap of different territorial and ethnolinguistic identities than of a sole Spanish identity. In some cases some of the territorial identities may conflict with the dominant Spanish culture. Distinct traditional identities within Spain include the Basques, Catalans, Galicians, Andalusians and Valencians,[149] although to some extent all of the 17 autonomous communities may claim a distinct local identity.		It is this last feature of "shared identity" between the more local level or autonomous community and the Spanish level which makes the identity question in Spain complex and far from univocal.		Spain has a number of descendants of populations from former colonies, especially Latin America and North Africa. Smaller numbers of immigrants from several Sub-Saharan countries have recently been settling in Spain. There are also sizeable numbers of Asian immigrants, most of whom are of Middle Eastern, South Asian and Chinese origin. The single largest group of immigrants are European; represented by large numbers of Romanians, Britons, Germans, French and others.[150]		The arrival of the gitanos, a Romani people, began in the 16th century; estimates of the Spanish Roma population range from 750,000 to over one million.[151][152][153][154][155] There are also the mercheros (also quinquis), a formerly nomadic minority group. Their origin is unclear.		Historically, Sephardi Jews and Moriscos are the main minority groups originated in Spain and with a contribution to Spanish culture.[156] The Spanish government is offering Spanish nationality to Sephardi Jews.[157]		According to the Spanish government there were 5.7 million foreign residents in Spain in 2011, or 12% of the total population. According to residence permit data for 2011, more than 860,000 were Romanian, about 770,000 were Moroccan, approximately 390,000 were British, and 360,000 were Ecuadorian.[158] Other sizeable foreign communities are Colombian, Bolivian, German, Italian, Bulgarian, and Chinese. There are more than 200,000 migrants from Sub-Saharan Africa living in Spain, principally Senegaleses and Nigerians.[159] Since 2000, Spain has experienced high population growth as a result of immigration flows, despite a birth rate that is only half the replacement level. This sudden and ongoing inflow of immigrants, particularly those arriving illegally by sea, has caused noticeable social tension.[160]		Within the EU, Spain had the 2nd highest immigration rate in percentage terms after Cyprus, but by a great margin, the highest in absolute numbers, up to 2008.[161] The number of immigrants in Spain had grown up from 500,000 people in 1996 to 5.2 million in 2008 out of a total population of 46 million.[162][163] In 2005 alone, a regularisation programme increased the legal immigrant population by 700,000 people.[164] There are a number of reasons for the high level of immigration, including Spain's cultural ties with Latin America, its geographical position, the porosity of its borders, the large size of its underground economy and the strength of the agricultural and construction sectors, which demand more low cost labour than can be offered by the national workforce.		Another statistically significant factor is the large number of residents of EU origin typically retiring to Spain's Mediterranean coast. In fact, Spain was Europe's largest absorber of migrants from 2002 to 2007, with its immigrant population more than doubling as 2.5 million people arrived.[165] In 2008, prior to the onset of the economic crisis, the Financial Times reported that Spain was the most favoured destination for Western Europeans considering a move from their own country and seeking jobs elsewhere in the EU.[166]		In 2008, the government instituted a "Plan of Voluntary Return" which encouraged unemployed immigrants from outside the EU to return to their home countries and receive several incentives, including the right to keep their unemployment benefits and transfer whatever they contributed to the Spanish Social Security.[167] The programme had little effect; during its first two months, just 1,400 immigrants took up the offer.[168] What the programme failed to do, the sharp and prolonged economic crisis has done from 2010 to 2011 in that tens of thousands of immigrants have left the country due to lack of jobs. In 2011 alone, more than half a million people left Spain.[169] For the first time in decades the net migration rate was expected to be negative, and nine out of 10 emigrants were foreigners.[169]		Spain is openly multilingual,[170] and the constitution establishes that the nation will protect "all Spaniards and the peoples of Spain in the exercise of human rights, their cultures and traditions, languages and institutions.[171]		Spanish (español)—officially recognised in the constitution as Castilian (castellano)—is the official language of the entire country, and it is the right and duty of every Spaniard to know the language. The constitution also establishes that "all other Spanish languages"—that is, all other languages of Spain—will also be official in their respective autonomous communities in accordance to their Statutes, their organic regional legislations, and that the "richness of the distinct linguistic modalities of Spain represents a patrimony which will be the object of special respect and protection."[172]		The other official languages of Spain, co-official with Spanish are:		As a percentage of the general population, Basque is spoken by 2%, Catalan (or Valencian) by 17%, and Galician by 7% of all Spaniards.[173]		In Catalonia, Aranese (aranés), a local variety of the Occitan language, has been declared co-official along with Catalan and Spanish since 2006. Occitan itself is spoken only in the comarca of Val d'Aran by roughly 6,700 people. Other Romance minority languages, though not official, have special recognition, such as the Astur-Leonese group (Asturian – asturianu, also called bable – in Asturias[174] and Leonese – llionés – in Castile and León) and Aragonese (aragonés) in Aragon.		In the North African Spanish autonomous city of Melilla, Riff Berber is spoken by a significant part of the population. In the tourist areas of the Mediterranean coast and the islands, English and German are widely spoken by tourists, foreign residents, and tourism workers.[175]		State education in Spain is free and compulsory from the age of six to sixteen. The current education system was established by the 2006 educational law, LOE (Ley Orgánica de Educación), or Fundamental Law for the Education.[176] In 2014, the LOE was partially modified by the newer and controversial LOMCE law (Ley Orgánica para la Mejora de la Calidad Educativa), or Fundamental Law for the Improvement of the Education System, commonly called Ley Wert (Wert Law).[177] Since 1970 to 2014, Spain has had seven different educational laws (LGE, LOECE, LODE, LOGSE, LOPEG, LOE and LOMCE).[178]		Institución Libre de Enseñanza was an educational project that developed in Spain for the half a century of about 1876–1936 by Francisco Giner de los Ríos and Gumersindo de Azcárate. The institute was inspired by the philosophy of Krausism. Concepción Arenal in feminism and Santiago Ramón y Cajal in neuroscience were in the movement.		The health care system of Spain (Spanish National Health System) is considered one of the best in the world, in 7th position in the ranking elaborated by the World Health Organization.[179] The health care is public, universal and free for any legal citizen of Spain.[180] The total health spending is 9.4% of the GDP, slightly above the average of 9.3% of the OECD.		Roman Catholicism has long been the main religion of Spain, and although it no longer has official status by law, in all public schools in Spain students have to choose either a religion or ethics class. Catholicism is the religion most commonly taught, although the teaching of Islam,[181] Judaism,[182] and evangelical Christianity[183] is also recognised in law. According to a June 2016 study by the Spanish Centre for Sociological Research about 68% of Spaniards self-identify as Catholics, 2% other faith, and about 27% identify with no religion. Most Spaniards do not participate regularly in religious services. This same study shows that of the Spaniards who identify themselves as religious, 59% hardly ever or never go to church, 16% go to church some times a year, 9% some time per month and 15% every Sunday or multiple times per week.[4] Recent polls and surveys have revealed that atheists and agnostics comprise anywhere from 20% to 27% of the Spanish population.[4][184][185]		Altogether, about 9% of the entire Spanish population attends religious services at least once per month.[4] Though Spanish society has become considerably more secular in recent decades, the influx of Latin American immigrants, who tend to be strong Catholic practitioners, has helped the Catholic Church to recover.		There have been four Spanish Popes. Damasus I, Calixtus III, Alexander VI and Benedict XIII. Spanish mysticism was an important intellectual fight against Protestantism with Teresa of Ávila, a reformist nun, ahead. The Society of Jesus was founded by Ignatius of Loyola and Francisco Javier. In the 1960s, Jesuits Pedro Arrupe and Ignacio Ellacuría were inside the movement of Liberation Theology.		Protestant churches have about 1,200,000 members.[186] There are about 105,000 Jehovah's Witnesses. The Church of Jesus Christ of Latter-day Saints has approximately 46,000 adherents in 133 congregations in all regions of the country and has a temple in the Moratalaz District of Madrid.[187]		A study made by the Union of Islamic Communities of Spain demonstrated that there were about 1,700,000 inhabitants of Muslim background living in Spain as of 2012[update], accounting for 3–4% of the total population of Spain. The vast majority was composed of immigrants and descendants originating from Morocco and other African countries. More than 514,000 (30%) of them had Spanish nationality.[188]		The recent waves of immigration have also led to an increasing number of Hindus, Buddhists, Sikhs and Muslims. After the Reconquista in 1492, Muslims did not live in Spain for centuries. Late 19th-century colonial expansion in northwestern Africa gave a number of residents in Spanish Morocco and Western Sahara full citizenship. Their ranks have since been bolstered by recent immigration, especially from Morocco and Algeria.		Judaism was practically non-existent in Spain from the 1492 expulsion until the 19th century, when Jews were again permitted to enter the country. Currently there are around 62,000 Jews in Spain, or 0.14% of the total population. Most are arrivals in the past century, while some are descendants of earlier Spanish Jews. Approximately 80,000 Jews are thought to have lived in Spain prior to its expulsion.[189]		Culturally, Spain is a Western country. Almost every aspect of Spanish life is permeated by its Roman heritage, making Spain one of the major Latin countries of Europe. Spanish culture is marked by strong historic ties to Catholicism, which played a pivotal role in the country's formation and subsequent identity. Spanish art, architecture, cuisine, and music has been shaped by successive waves of foreign invaders, as well as by the country's Mediterranean climate and geography. The centuries-long colonial era globalised Spanish language and culture, with Spain also absorbing the cultural and commercial products of its diverse empire.		It should be noted that after Italy (49) and China (45), Spain is the third country in the world with the most World Heritage Sites. At the present time it has 44 recognised sites, including the landscape of Monte Perdido in the Pyrenees, which is shared with France, the Prehistoric Rock Art Sites of the Côa Valley and Siega Verde, which is shared with Portugal (the Portuguese part being in the Côa Valley, Guarda), and the Heritage of Mercury, shared with Slovenia.[190] In addition, Spain has also 14 Intangible cultural heritage, or "Human treasures", Spain ranks first in Europe according to UNESCO's Intangible Cultural Heritage List, tied with Croatia.[191]		The earliest recorded examples of vernacular Romance-based literature date from the same time and location, the rich mix of Muslim, Jewish, and Christian cultures in Muslim Spain, in which Maimonides, Averroes, and others worked, the Kharjas (Jarchas).		During the Reconquista, the epic poem Cantar de Mio Cid was written about a real man—his battles, conquests, and daily life.		Other major plays from the medieval times were Mester de Juglaría, Mester de Clerecía, Coplas por la muerte de su padre or El Libro de buen amor (The Book of Good Love).		During the Renaissance the major plays are La Celestina and El Lazarillo de Tormes, while many religious literature was created with poets as Luis de León, San Juan de la Cruz, Santa Teresa de Jesús, etc.		The Baroque is the most important period for Spanish culture. We are in the times of the Spanish Empire. The famous Don Quijote de La Mancha by Miguel de Cervantes was written in this time. Other writers from the period are: Francisco de Quevedo, Lope de Vega, Calderón de la Barca or Tirso de Molina.		During the Enlightenment we find names such as Leandro Fernández de Moratín, Benito Jerónimo Feijóo, Gaspar Melchor de Jovellanos or Leandro Fernández de Moratín.		During the Romanticism, José Zorrilla created one of the most emblematic figures in European literature in Don Juan Tenorio. Other writers from this period are Gustavo Adolfo Bécquer, José de Espronceda, Rosalía de Castro or Mariano José de Larra.		In Realism we find names such as Benito Pérez Galdós, Emilia Pardo Bazán, Leopoldo Alas (Clarín), Concepción Arenal, Vicente Blasco Ibáñez and Menéndez Pelayo. Realism offered depictions of contemporary life and society 'as they were'. In the spirit of general "Realism", Realist authors opted for depictions of everyday and banal activities and experiences, instead of romanticised or stylised presentations.		The group that has become known as the Generation of 1898 was marked by the destruction of Spain's fleet in Cuba by US gunboats in 1898, which provoked a cultural crisis in Spain. The "Disaster" of 1898 led established writers to seek practical political, economic, and social solutions in essays grouped under the literary heading of Regeneracionismo. For a group of younger writers, among them Miguel de Unamuno, Pío Baroja, and José Martínez Ruiz (Azorín), the Disaster and its cultural repercussions inspired a deeper, more radical literary shift that affected both form and content. These writers, along with Ramón del Valle-Inclán, Antonio Machado, Ramiro de Maeztu, and Ángel Ganivet, came to be known as the Generation of '98.		The Generation of 1914 or Novecentismo. The next supposed "generation" of Spanish writers following those of '98 already calls into question the value of such terminology. By the year 1914—the year of the outbreak of the First World War and of the publication of the first major work of the generation's leading voice, José Ortega y Gasset—a number of slightly younger writers had established their own place within the Spanish cultural field.		Leading voices include the poet Juan Ramón Jiménez, the academics and essayists Ramón Menéndez Pidal, Gregorio Marañón, Manuel Azaña, Maria Zambrano, Eugeni d'Ors, Clara Campoamor and Ortega y Gasset, and the novelists Gabriel Miró, Ramón Pérez de Ayala, and Ramón Gómez de la Serna. While still driven by the national and existential questions that obsessed the writers of '98, they approached these topics with a greater sense of distance and objectivity. Salvador de Madariaga, another prominent intellectual and writer, was one of the founders of the College of Europe and the composer of the constitutive manifest of the Liberal International.		The Generation of 1927, where poets Pedro Salinas, Jorge Guillén, Federico García Lorca, Vicente Aleixandre, Dámaso Alonso. All were scholars of their national literary heritage, again evidence of the impact of the calls of regeneracionistas and the Generation of 1898 for Spanish intelligence to turn at least partially inwards.		The two main writers in the second half of the 20th century were the Nobel Prize in Literature laureate Camilo José Cela and Miguel Delibes from Generation of '36. Spain is one of the countries with the most number of laureates with the Nobel Prize in Literature, and with Latin American laureates they made the Spanish language literature one of the most laureates of all. The Spanish writers are: José Echegaray, Jacinto Benavente, Juan Ramón Jiménez, Vicente Aleixandre and Camilo José Cela. The Portuguese writer José Saramago, also awarded with the prize, lived for many years in Spain and spoke both Portuguese and Spanish. Saramago was also well known by his Iberist ideas.		The Generation of '50 are also known as the children of the civil war. Rosa Chacel, Gloria Fuertes, Jaime Gil de Biedma, Juan Goytisolo, Carmen Martín Gaite, Ana María Matute, Juan Marsé, Blas de Otero, Gabriel Celaya, Antonio Gamoneda, Rafael Sánchez Ferlosio or Ignacio Aldecoa.		Artists from Spain have been highly influential in the development of various European artistic movements. Due to historical, geographical and generational diversity, Spanish art has known a great number of influences. The Moorish heritage in Spain, especially in Andalusia, is still evident today and European influences include Italy, Germany and France, especially during the Baroque and Neoclassical periods.		During the Golden Age we find painters such as El Greco, José de Ribera, Bartolomé Esteban Murillo and Francisco Zurbarán. Also inside Baroque period Diego Velázquez created some of the most famous Spanish portraits, like Las Meninas or Las Hilanderas.		Francisco Goya painted during a historical period that includes the Spanish Independence War, the fights between liberals and absolutists, and the raise of state-nations.		Joaquín Sorolla is a well-known impressionist painter and there are many important Spanish painters belonging to the modernism art movement, including Pablo Picasso, Salvador Dalí, Juan Gris and Joan Miró.		The Plateresque style extended from beginnings of the 16th century until the last third of the century and its stylistic influence pervaded the works of all great Spanish artists of the time. Alonso Berruguete (Valladolid School) is called the "Prince of Spanish sculpture". His main works were the upper stalls of the choir of the Cathedral of Toledo, the tomb of Cardinal Tavera in the same Cathedral, and the altarpiece of the Visitation in the church of Santa Úrsula in the same locality. Other notable sculptors were Bartolomé Ordóñez, Diego de Siloé, Juan de Juni and Damián Forment.		There were two Schools of special flair and talent: the Seville School, to which Juan Martínez Montañés belonged, whose most celebrated works are the Crucifix in the Cathedral of Seville, another in Vergara, and a Saint John; and the Granada School, to which Alonso Cano belonged, to whom an Immaculate Conception and a Virgin of Rosary, are attributed.		Other notable Andalusian Baroque sculptors were Pedro de Mena, Pedro Roldán and his daughter Luisa Roldán, Juan de Mesa and Pedro Duque Cornejo. In the 20th century the most important Spanish sculptors were Julio González, Pablo Gargallo, Eduardo Chillida and Pablo Serrano.		Spanish cinema has achieved major international success including Oscars for recent films such as Pan's Labyrinth and Volver.[192] In the long history of Spanish cinema, the great filmmaker Luis Buñuel was the first to achieve world recognition, followed by Pedro Almodóvar in the 1980s (La Movida Madrileña). Mario Camus and Pilar Miró worked together in Curro Jiménez.		Spanish cinema has also seen international success over the years with films by directors like Segundo de Chomón, Florián Rey, Luis García Berlanga, Carlos Saura, Julio Medem, Isabel Coixet, Alejandro Amenábar, Icíar Bollaín and brothers David Trueba and Fernando Trueba.		Actresses Sara Montiel and Penélope Cruz or actor Antonio Banderas are among those who have become Hollywood stars.		Due to its historical and geographical diversity, Spanish architecture has drawn from a host of influences. An important provincial city founded by the Romans and with an extensive Roman era infrastructure, Córdoba became the cultural capital, including fine Arabic style architecture, during the time of the Islamic Umayyad dynasty.[193] Later Arab style architecture continued to be developed under successive Islamic dynasties, ending with the Nasrid, which built its famed palace complex in Granada.		Simultaneously, the Christian kingdoms gradually emerged and developed their own styles; developing a pre-Romanesque style when for a while isolated from contemporary mainstream European architectural influences during the earlier Middle Ages, they later integrated the Romanesque and Gothic streams. There was then an extraordinary flowering of the Gothic style that resulted in numerous instances being built throughout the entire territory. The Mudéjar style, from the 12th to 17th centuries, was developed by introducing Arab style motifs, patterns and elements into European architecture.		The arrival of Modernism in the academic arena produced much of the architecture of the 20th century. An influential style centred in Barcelona, known as modernisme, produced a number of important architects, of which Gaudí is one. The International style was led by groups like GATEPAC. Spain is currently experiencing a revolution in contemporary architecture and Spanish architects like Rafael Moneo, Santiago Calatrava, Ricardo Bofill as well as many others have gained worldwide renown.		Spanish music is often considered abroad to be synonymous with flamenco, a West Andalusian musical genre, which, contrary to popular belief, is not widespread outside that region. Various regional styles of folk music abound in Aragon, Catalonia, Valencia, Castile, the Basque Country, Galicia, Cantabria and Asturias. Pop, rock, hip hop and heavy metal are also popular.		In the field of classical music, Spain has produced a number of noted composers such as Isaac Albéniz, Manuel de Falla and Enrique Granados and singers and performers such as Plácido Domingo, José Carreras, Montserrat Caballé, Alicia de Larrocha, Alfredo Kraus, Pablo Casals, Ricardo Viñes, José Iturbi, Pablo de Sarasate, Jordi Savall and Teresa Berganza. In Spain there are over forty professional orchestras, including the Orquestra Simfònica de Barcelona, Orquesta Nacional de España and the Orquesta Sinfónica de Madrid. Major opera houses include the Teatro Real, the Gran Teatre del Liceu, Teatro Arriaga and the El Palau de les Arts Reina Sofía.		Thousands of music fans also travel to Spain each year for internationally recognised summer music festivals Sónar which often features the top up and coming pop and techno acts, and Benicàssim which tends to feature alternative rock and dance acts.[194] Both festivals mark Spain as an international music presence and reflect the tastes of young people in the country.		The most popular traditional musical instrument, the guitar, originated in Spain.[195] Typical of the north are the traditional bag pipers or gaiteros, mainly in Asturias and Galicia.		Spanish cuisine consists of a great variety of dishes which stem from differences in geography, culture and climate. It is heavily influenced by seafood available from the waters that surround the country, and reflects the country's deep Mediterranean roots. Spain's extensive history with many cultural influences has led to a unique cuisine. In particular, three main divisions are easily identified:		Mediterranean Spain – all such coastal regions, from Catalonia to Andalusia – heavy use of seafood, such as pescaíto frito (fried fish); several cold soups like gazpacho; and many rice-based dishes like paella from Valencia[196] and arròs negre (black rice) from Catalonia.[197]		Inner Spain – Castile – hot, thick soups such as the bread and garlic-based Castilian soup, along with substantious stews such as cocido madrileño. Food is traditionally conserved by salting, like Spanish ham, or immersed in olive oil, like Manchego cheese.		Atlantic Spain – the whole Northern coast, including Asturian, Basque, Cantabrian and Galician cuisine – vegetable and fish-based stews like caldo gallego and marmitako. Also, the lightly cured lacón ham. The best known cuisine of the northern countries often rely on ocean seafood, like the Basque-style cod, albacore or anchovy or the Galician octopus-based polbo á feira and shellfish dishes.		While varieties of football had been played in Spain as far back as Roman times, sport in Spain has been dominated by English style association football since the early 20th century. Real Madrid C.F. and FC Barcelona are two of the most successful football clubs in the world. The country's national football team won the UEFA European Football Championship in 1964, 2008 and 2012 and the FIFA World Cup in 2010, and is the first team to ever win three back-to-back major international tournaments.		Basketball, tennis, cycling, handball, futsal, motorcycling and, lately, Formula One are also important due to the presence of Spanish champions in all these disciplines. Today, Spain is a major world sports powerhouse, especially since the 1992 Summer Olympics that were hosted in Barcelona, which stimulated a great deal of interest in sports in the country. The tourism industry has led to an improvement in sports infrastructure, especially for water sports, golf and skiing.		Rafael Nadal is the leading Spanish tennis player and has won several Grand Slam titles including the Wimbledon 2010 men's singles. In north Spain, the game of pelota is very popular. Alberto Contador is the leading Spanish cyclist and has won several Grand Tour titles including two Tour de France titles.		Public holidays celebrated in Spain include a mix of religious (Roman Catholic), national and regional observances. Each municipality is allowed to declare a maximum of 14 public holidays per year; up to nine of these are chosen by the national government and at least two are chosen locally.[198] Spain's National Day (Fiesta Nacional de España) is 12 October, the anniversary of the Discovery of America and commemorate Our Lady of the Pillar feast, patroness of Aragon and throughout Spain.		There are many festivals and festivities in Spain. Some of them are known worldwide, and every year millions of people from all over the world go to Spain to experience one of these festivals. One of the most famous is San Fermín, in Pamplona. While its most famous event is the encierro, or the running of the bulls, which happens at 8:00 am from 7 to 14 July, the week-long celebration involves many other traditional and folkloric events. Its events were central to the plot of The Sun Also Rises, by Ernest Hemingway, which brought it to the general attention of English-speaking people. As a result, it has become one of the most internationally renowned fiestas in Spain, with over 1,000,000 people attending every year.		Other festivals include the carnivals in the Canary Islands, the Falles in Valencia or the Holy Week in Andalusia and Castile and León.		1. All twenty-eight member states of the European Union are also members of the WTO in their own right:		2. Special administrative regions of the People's Republic of China, participates as "Hong Kong, China" and "Macao China". 3. Officially the Republic of China, participates as "Separate Customs Territory of Taiwan, Penghu, Kinmen and Matsu", and "Chinese Taipei" in short.		
Coastal morphodynamics (i.e. the dynamics of beach morphology) refers to the study of the interaction and adjustment of the seafloor topography and fluid hydrodynamic processes, seafloor morphologies and sequences of change dynamics involving the motion of sediment. Hydrodynamic processes include those of waves, tides and wind-induced currents.		While hydrodynamic processes respond instantaneously to morphological change, morphological change requires the redistribution of sediment. As sediment takes a finite time to move, there is a lag in the morphological response to hydrodynamic forcing. Sediment can therefore be considered to be a time-dependent coupling mechanism. Since the boundary conditions of hydrodynamic forcing change regularly, this may mean that the beach never attains equilibrium. Morphodynamic processes exhibit positive and negative feedbacks (such that beaches can, over different timescales, be considered to be both self-forcing and self-organised systems), nonlinearities and threshold behaviour.		This systems approach to the coast was first developed by Wright and Thom in 1977 and finalized by Wright and Short in 1984. According to their dynamic and morphological characteristics, exposed sandy beaches can be classified into several morphodynamic types (Wright and Short, 1984; Short, 1996). There is a large scale of morphodynamic states, this scale ranges from the "dissipative state" to the "reflective extremes".		Dissipative beaches are flat, have fine sand, incorporating waves that tend to break far from the intertidal zone and dissipate force progressively along wide surf zones. Dissipative beaches are wide and flat in profile, with a wide shoaling and surf zone, composed of finer sediment, and characterised by spilling breakers.		Reflective beaches are steep, and are known for their coarse sand; they have no surf zone, and the waves break brusquely on the intertidal zone. Reflective beaches are typically steep in profile with a narrow shoaling and surf zone, composed of coarse sediment, and characterised by surging breakers. Coarser sediment allows percolation during the swash part of the wave cycle, thus reducing the strength of backwash and allowing material to be deposited in the swash zone		Depending on beach state, near bottom currents show variations in the relative dominance of motions due to: incident waves, subharmonic oscillations, infragravity oscillations, and mean longshore and rip currents. On reflective beaches, incident waves and subharmonic edge waves are dominant. In highly dissipative surf zones, shoreward decay of incident waves is accompanied by shoreward growth of infragravity energy; in the inner surf zone, currents associated with infragravity standing waves dominate. On intermediate states with pronounced bar-trough (straight or crescentic) topographies, incident wave orbital velocities are generally dominant but significant roles are also played by subharmonic and infragravity standing waves, longshore currents, and rips. The strongest rips and associated feeder currents occur in association with intermediate transverse bar and rip topographies.		Transitions between beach states are often caused by changes in wave energy, with storms causing reflective beach profiles to flatten (offshore movement of sediment under steeper waves), thus adopting a more dissipative profile. Morphodynamic processes are also associated with other coastal landforms, for example spur and groove formation topography on coral reefs and tidal flats in infilling estuaries.		
A freshwater marsh is a marsh that contains fresh water. Freshwater marshes are usually found near the mouths of rivers and are present in areas with low drainage.[1] It is the counterpart to the salt marsh, an upper coastal intertidal zone of bio-habitat which is regularly flushed with sea water.		Freshwater marshes are non-tidal biomes containing little or no peat (unlike bogs and fens, both a kind of mire and mires consisting heavily of moist, biologically active peat). They are most common in the Gulf Coast region, specifically in Florida. They can be one of two principal types: either fresh water mineralized marshes, which derive their water from groundwater, streams and surface runoff; or poorly mineralized fresh water marshes whose moisture comes mostly from regular direct precipitation. Freshwater marshes support an independent pH-neutral ecosystem which encourages biodiversity. Common species include ducks, geese, swans, songbirds, swallows, coots, and black ducks. Although shallow marshes do not tend to support many fish, deeper ones are home to many species, including such large fish as the northern pike and carp. Some of the most common plants in these areas are cattails, water lilies, arrowheads, and rushes.[2]		The Florida Everglades represent the largest contiguous freshwater marsh in the entire world.[3] This immense marsh covers 4,200 square miles (11,000 km2) and is located in the southern tip of Florida. Continued human development, including drainage for development and polluted agriculture runoff, as well as alterations in the water cycle threaten the existence of the Everglades. The remaining parts of the Everglades are grasses, sedges and other emergent hydrophytes.[4]				
